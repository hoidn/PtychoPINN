2025-08-02 12:18:17.510674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754162297.522726  352164 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754162297.526325  352164 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754162297.536889  352164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754162297.536912  352164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754162297.536914  352164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754162297.536916  352164 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-02 12:18:17.539852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-02 12:18:19,993 - INFO - Configuration setup complete
2025-08-02 12:18:19,993 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('probe_study_fresh/gs1_hybrid/train_data.npz'), test_data_file=PosixPath('probe_study_fresh/gs1_hybrid/test_data.npz'), batch_size=16, nepochs=2, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=500, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('probe_study_fresh/gs1_hybrid/trained_model'))
2025-08-02 12:18:19,993 - INFO - Parameter interpretation: --n-images=500 refers to individual images (gridsize=1)
2025-08-02 12:18:19,993 - INFO - Starting training with n_images=500, stitching=disabled
2025-08-02 12:18:19,993 - INFO - Loading data from probe_study_fresh/gs1_hybrid/train_data.npz with n_images=500
2025-08-02 12:18:20,023 - INFO - Using sequential slicing for gridsize=1: selecting first 500 images
2025-08-02 12:18:20,023 - INFO - Loading data from probe_study_fresh/gs1_hybrid/test_data.npz with n_images=None
2025-08-02 12:18:20,030 - INFO - Using sequential slicing for gridsize=1: selecting first 100 images
2025-08-02 12:18:20,031 - INFO - Loaded test data from probe_study_fresh/gs1_hybrid/test_data.npz
2025-08-02 12:18:20,033 - INFO - 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
I0000 00:00:1754162300.170860  352164 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1754162300.172326  352164 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11487 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754162300.882747  352164 service.cc:152] XLA service 0x1314c430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1754162300.882776  352164 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-02 12:18:20.897702: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1754162300.915437  352164 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1754162301.049470  352164 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
neighbor-sampled diffraction shape (500, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(500, 64, 64, 1) Y_I=(500, 64, 64, 1) Y_phi=(500, 64, 64, 1) norm_Y_I=() coords_nominal=(500, 1, 2, 1) coords_true=(500, 1, 2, 1) nn_indices=(500, 1) mean=249.500 global_offsets=(500, 1, 2, 1) mean=110.441 local_offsets=(500, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
2025-08-02 12:18:23,127 - INFO - 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (100, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(100, 64, 64, 1) Y_I=(100, 64, 64, 1) Y_phi=(100, 64, 64, 1) norm_Y_I=() coords_nominal=(100, 1, 2, 1) coords_true=(100, 1, 2, 1) nn_indices=(100, 1) mean=49.500 global_offsets=(100, 1, 2, 1) mean=109.441 local_offsets=(100, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input (InputLayer)  │ (None, 64, 64, 1) │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler    │ (None, 64, 64, 1) │          0 │ input[0][0]       │
│ (IntensityScaler)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 64, 64,    │        640 │ intensity_scaler… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 64, 64,    │     36,928 │ conv2d[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d       │ (None, 32, 32,    │          0 │ conv2d_1[0][0]    │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 32, 32,    │     73,856 │ max_pooling2d[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 32, 32,    │    147,584 │ conv2d_2[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 16, 16,    │          0 │ conv2d_3[0][0]    │
│ (MaxPooling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 16, 16,    │    295,168 │ max_pooling2d_1[… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 16, 16,    │    590,080 │ conv2d_4[0][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_2     │ (None, 8, 8, 256) │          0 │ conv2d_5[0][0]    │
│ (MaxPooling2D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 8, 8, 128) │    147,584 │ conv2d_8[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ conv2d_16[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d       │ (None, 16, 16,    │          0 │ conv2d_9[0][0]    │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_3     │ (None, 16, 16,    │          0 │ conv2d_17[0][0]   │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d_3[… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_10[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_18[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_1     │ (None, 32, 32,    │          0 │ conv2d_11[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_4     │ (None, 32, 32,    │          0 │ conv2d_19[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_1          │ (None, 32, 32, 4) │          0 │ up_sampling2d_1[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_3          │ (None, 32, 32, 4) │          0 │ up_sampling2d_4[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_1[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_20 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_3[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_12[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_21 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_20[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_2     │ (None, 64, 64,    │          0 │ conv2d_13[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_5     │ (None, 64, 64,    │          0 │ conv2d_21[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item (GetItem)  │ (None, 32, 32,    │          0 │ up_sampling2d_1[… │
│                     │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 64, 64, 1) │        577 │ up_sampling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_2          │ (None, 32, 32,    │          0 │ up_sampling2d_4[… │
│ (GetItem)           │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 64, 64, 1) │        577 │ up_sampling2d_5[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 32, 32, 1) │        541 │ get_item[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu (Silu)         │ (None, 64, 64, 1) │          0 │ conv2d_7[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 32, 32, 1) │        541 │ get_item_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu_1 (Silu)       │ (None, 64, 64, 1) │          0 │ conv2d_15[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp                 │ (None, 32, 32, 1) │          0 │ conv2d_6[0][0]    │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer   │ (None, 64, 64, 1) │          0 │ silu[0][0]        │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phi                 │ (None, 32, 32, 1) │          0 │ conv2d_14[0][0]   │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer_1 │ (None, 64, 64, 1) │          0 │ silu_1[0][0]      │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp_padded          │ (None, 64, 64, 1) │          0 │ amp[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 64, 64, 1) │          0 │ silu[0][0],       │
│                     │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phase_padded        │ (None, 64, 64, 1) │          0 │ phi[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 64, 64, 1) │          0 │ silu_1[0][0],     │
│ (Multiply)          │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add (Add)           │ (None, 64, 64, 1) │          0 │ amp_padded[0][0], │
│                     │                   │            │ multiply[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_1 (Add)         │ (None, 64, 64, 1) │          0 │ phase_padded[0][… │
│                     │                   │            │ multiply_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ obj                 │ (None, 64, 64, 1) │          0 │ add[0][0],        │
│ (CombineComplexLay… │                   │            │ add_1[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_positions     │ (None, 1, 2, 1)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_obj_2        │ (None, 74, 74, 1) │          0 │ obj[0][0],        │
│ (ReassemblePatches… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_objs_with_o… │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (ExtractPatchesPos… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ probe_illumination  │ [(None, 64, 64,   │          0 │ padded_objs_with… │
│ (ProbeIllumination) │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_amplitude      │ [(None, 64, 64,   │          0 │ probe_illuminati… │
│ (PadAndDiffractLay… │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_diff_channels  │ (None, 64, 64, 1) │          0 │ pred_amplitude[0… │
│ (FlatToChannelLaye… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler_i… │ (None, 64, 64, 1) │          0 │ pred_diff_channe… │
│ (IntensityScaler_i… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ trimmed_obj         │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (TrimReconstructio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_intensity      │ (None, 64, 64, 1) │          0 │ intensity_scaler… │
│ (SquareLayer)       │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-02 12:18:24.136085: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-02 12:18:24.136096: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
I0000 00:00:1754162304.136111  352164 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1754162304.150502  352164 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-02 12:18:24.150596: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1754162304.151070  352164 cupti_tracer.cc:1249] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 500
nepochs: 2
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: probe_study_fresh/gs1_hybrid/trained_model
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.005-0.010j
  std: 0.782
  min: -2.681-0.479j
  max: 2.700-0.360j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: probe_study_fresh/gs1_hybrid/test_data.npz
train_data_file_path: probe_study_fresh/gs1_hybrid/train_data.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/2
input shape (None, 64, 64, 1)
2025-08-02 12:18:25,344 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-02 12:18:27,402 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-02 12:18:31.155251: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-02 12:18:31.188712: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-02 12:18:31.205258: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-02 12:18:31.432386: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:29[0m 7s/step - intensity_scaler_inv_loss: 93.1126 - loss: -3049464.7500 - pred_intensity_loss: -3049464.7500 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 154.1937 - loss: -2936448.5000 - pred_intensity_loss: -2936448.5000 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 139.2120 - loss: -2952901.0000 - pred_intensity_loss: -2952901.0000 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 128.0341 - loss: -2961101.2500 - pred_intensity_loss: -2961101.2500 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 120.1808 - loss: -2959442.5000 - pred_intensity_loss: -2959442.5000 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 114.1936 - loss: -2959979.5000 - pred_intensity_loss: -2959979.5000 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 109.5257 - loss: -2959408.7500 - pred_intensity_loss: -2959408.7500 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 105.4562 - loss: -2958845.0000 - pred_intensity_loss: -2958845.0000 - trimmed_obj_loss: 0.0000e+002025-08-02 12:18:33.855588: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-02 12:18:33.901126: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-02 12:18:33.998170: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-02 12:18:34.199994: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 93ms/step - intensity_scaler_inv_loss: 104.5352 - loss: -2958469.7500 - pred_intensity_loss: -2958385.2500 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-02 12:18:35,166 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m11s[0m 138ms/step - intensity_scaler_inv_loss: 77.8242 - loss: -2947586.7500 - pred_intensity_loss: -2945048.5000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 51.3897 - val_loss: -3046564.5000 - val_pred_intensity_loss: -3042589.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/2
[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 58.2952 - loss: -2851678.2500 - pred_intensity_loss: -2851678.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 53.7801 - loss: -2969983.7500 - pred_intensity_loss: -2969983.7500 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 52.4521 - loss: -3002812.7500 - pred_intensity_loss: -3002812.7500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 52.3094 - loss: -2992625.0000 - pred_intensity_loss: -2992625.0000 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 52.2328 - loss: -2985986.0000 - pred_intensity_loss: -2985986.0000 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 52.0103 - loss: -2981882.2500 - pred_intensity_loss: -2981882.2500 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 51.9571 - loss: -2976776.0000 - pred_intensity_loss: -2976776.0000 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 51.8659 - loss: -2975638.0000 - pred_intensity_loss: -2975638.0000 - trimmed_obj_loss: 0.0000e+00[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 16ms/step - intensity_scaler_inv_loss: 51.3312 - loss: -2968434.2500 - pred_intensity_loss: -2971464.5000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 41.0434 - val_loss: -3049856.7500 - val_pred_intensity_loss: -3045880.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 978ms/stepinput shape (None, 64, 64, 1)
[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 442ms/step[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 447ms/step
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
Object stitching failed: unsupported operand type(s) for /: 'NoneType' and 'int'
2025-08-02 12:18:38,936 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-02 12:18:40,135 - INFO - Outputs saved to probe_study_fresh/gs1_hybrid/trained_model
