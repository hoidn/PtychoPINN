[2025-08-26 17:22:21] === Starting Complete Generalization Study ===
[2025-08-26 17:22:21] Training sizes: 128
[2025-08-26 17:22:21] Number of trials per size: 1
[2025-08-26 17:22:21] Output directory: 3way_synthetic_ptychi_1e4_cheat
[2025-08-26 17:22:21] Total training runs planned: 2
[2025-08-26 17:22:21] Validating environment...
[2025-08-26 17:22:21] Environment validation passed
[2025-08-26 17:22:21] Configuration saved to: 3way_synthetic_ptychi_1e4_cheat/study_config.txt
[2025-08-26 17:22:21] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 17:22:21] === STEP 2: Model Training ===
[2025-08-26 17:22:21] Training models sequentially with 1 trials per training size
[2025-08-26 17:22:21] Starting training for train_size=128, test_size=128 (1 trials)
[2025-08-26 17:22:21] Training models for train_size=128, test_size=128 (Trial 1/1)
[2025-08-26 17:22:21] EXECUTING: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 17:22:21] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 17:22:22.211085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254142.223207 3347194 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254142.227202 3347194 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254142.238469 3347194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254142.238479 3347194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254142.238481 3347194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254142.238482 3347194 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:22:22.241352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:22:25,039 - INFO - Configuration setup complete
2025-08-26 17:22:25,039 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 17:22:25,039 - INFO - Parameter interpretation: --n-images=128 refers to individual images (gridsize=1)
2025-08-26 17:22:25,039 - INFO - Starting training with n_images=128, stitching=disabled
2025-08-26 17:22:25,039 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 17:22:25,358 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:22:25,676 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 17:22:25,677 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=None
2025-08-26 17:22:25,994 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:22:25,994 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/train.npz
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:22:25,995 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:22:25,995 - INFO - Generating 128 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:22:25,995 - INFO - Sampled 128 seed points from 2576 total points
2025-08-26 17:22:25,995 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:22:25,995 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:22:25,995 - INFO - Generated 128 groups efficiently
I0000 00:00:1756254146.128200 3347194 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254146.129483 3347194 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1160.992 global_offsets=(128, 1, 2, 1) mean=94.531 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:22:26,526 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:22:26,526 - INFO - Generating 128 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:22:26,526 - INFO - Sampled 128 seed points from 2576 total points
2025-08-26 17:22:26,526 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:22:26,526 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:22:26,526 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1374.938 global_offsets=(128, 1, 2, 1) mean=96.272 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:22:27.191488: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:22:27.191497: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254147.191512 3347194 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756254147.208685 3347194 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:22:27.208758: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756254147.209089 3347194 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756254147.911603 3347194 service.cc:152] XLA service 0x3e826e40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254147.911621 3347194 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:22:27.941492: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254147.960050 3347194 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254148.511615 3347194 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 17:22:29,019 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 17:22:30,870 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 17:22:34.383047: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:22:34.447061: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:22:34.460932: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:22:34.752140: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m47s[0m 7s/step - intensity_scaler_inv_loss: 0.6525 - loss: 0.6151 - pred_intensity_loss: 0.6151 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 1.6705 - loss: 12.1427 - pred_intensity_loss: 12.1427 - trimmed_obj_loss: 0.0000e+002025-08-26 17:22:36.942904: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:22:36.988723: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:22:37.026224: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:22:37.173117: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 329ms/step - intensity_scaler_inv_loss: 1.5033 - loss: 10.2354 - pred_intensity_loss: 10.1922 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 17:22:38,115 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m10s[0m 507ms/step - intensity_scaler_inv_loss: 1.1409 - loss: 6.3425 - pred_intensity_loss: 5.9967 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5496 - val_loss: -0.1179 - val_pred_intensity_loss: -0.1179 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.5774 - loss: -0.0789 - pred_intensity_loss: -0.0789 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5688 - loss: -0.1083 - pred_intensity_loss: -0.1083 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5426 - loss: -0.1561 - pred_intensity_loss: -0.1636 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5044 - val_loss: -0.2327 - val_pred_intensity_loss: -0.2327 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5186 - loss: -0.1892 - pred_intensity_loss: -0.1892 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5182 - loss: -0.2059 - pred_intensity_loss: -0.2059 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5176 - loss: -0.2198 - pred_intensity_loss: -0.2210 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4971 - val_loss: -0.2538 - val_pred_intensity_loss: -0.2538 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5209 - loss: -0.2054 - pred_intensity_loss: -0.2054 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5163 - loss: -0.2296 - pred_intensity_loss: -0.2296 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5086 - loss: -0.2455 - pred_intensity_loss: -0.2452 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4850 - val_loss: -0.2773 - val_pred_intensity_loss: -0.2773 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5030 - loss: -0.2748 - pred_intensity_loss: -0.2748 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4989 - loss: -0.2692 - pred_intensity_loss: -0.2692 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5029 - loss: -0.2580 - pred_intensity_loss: -0.2562 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4847 - val_loss: -0.2841 - val_pred_intensity_loss: -0.2841 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5005 - loss: -0.2497 - pred_intensity_loss: -0.2497 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5034 - loss: -0.2630 - pred_intensity_loss: -0.2630 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4973 - loss: -0.2694 - pred_intensity_loss: -0.2683 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4772 - val_loss: -0.2910 - val_pred_intensity_loss: -0.2910 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4876 - loss: -0.2702 - pred_intensity_loss: -0.2702 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4940 - loss: -0.2755 - pred_intensity_loss: -0.2755 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4941 - loss: -0.2808 - pred_intensity_loss: -0.2821 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4767 - val_loss: -0.3067 - val_pred_intensity_loss: -0.3067 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4910 - loss: -0.3174 - pred_intensity_loss: -0.3174 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4915 - loss: -0.3085 - pred_intensity_loss: -0.3085 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4876 - loss: -0.3020 - pred_intensity_loss: -0.3009 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4723 - val_loss: -0.3166 - val_pred_intensity_loss: -0.3166 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4837 - loss: -0.3085 - pred_intensity_loss: -0.3085 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4845 - loss: -0.3069 - pred_intensity_loss: -0.3069 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4794 - loss: -0.3261 - pred_intensity_loss: -0.3301 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4721 - val_loss: -0.3327 - val_pred_intensity_loss: -0.3327 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4902 - loss: -0.3545 - pred_intensity_loss: -0.3545 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4794 - loss: -0.3371 - pred_intensity_loss: -0.3371 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4767 - loss: -0.3470 - pred_intensity_loss: -0.3478 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4636 - val_loss: -0.3466 - val_pred_intensity_loss: -0.3466 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4661 - loss: -0.3899 - pred_intensity_loss: -0.3899 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4692 - loss: -0.3751 - pred_intensity_loss: -0.3751 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4680 - loss: -0.3701 - pred_intensity_loss: -0.3718 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4792 - val_loss: -0.3506 - val_pred_intensity_loss: -0.3506 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4802 - loss: -0.3440 - pred_intensity_loss: -0.3440 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4703 - loss: -0.3518 - pred_intensity_loss: -0.3518 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4658 - loss: -0.3713 - pred_intensity_loss: -0.3706 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4623 - val_loss: -0.3728 - val_pred_intensity_loss: -0.3728 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4703 - loss: -0.4141 - pred_intensity_loss: -0.4141 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4637 - loss: -0.4082 - pred_intensity_loss: -0.4082 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4598 - loss: -0.3925 - pred_intensity_loss: -0.3922 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4571 - val_loss: -0.3781 - val_pred_intensity_loss: -0.3781 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4659 - loss: -0.3994 - pred_intensity_loss: -0.3994 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4629 - loss: -0.3961 - pred_intensity_loss: -0.3961 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4568 - loss: -0.4008 - pred_intensity_loss: -0.4015 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4528 - val_loss: -0.3895 - val_pred_intensity_loss: -0.3895 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.3935 - pred_intensity_loss: -0.3935 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4551 - loss: -0.4025 - pred_intensity_loss: -0.4025 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4556 - loss: -0.4081 - pred_intensity_loss: -0.4057 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4489 - val_loss: -0.3928 - val_pred_intensity_loss: -0.3928 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 29ms/step - intensity_scaler_inv_loss: 0.4533 - loss: -0.3646 - pred_intensity_loss: -0.3646 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4020 - pred_intensity_loss: -0.4020 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4533 - loss: -0.4127 - pred_intensity_loss: -0.4117 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4485 - val_loss: -0.3985 - val_pred_intensity_loss: -0.3985 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4407 - pred_intensity_loss: -0.4407 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4531 - loss: -0.4232 - pred_intensity_loss: -0.4232 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4515 - loss: -0.4175 - pred_intensity_loss: -0.4170 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4458 - val_loss: -0.4031 - val_pred_intensity_loss: -0.4031 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4539 - loss: -0.4168 - pred_intensity_loss: -0.4168 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4509 - loss: -0.4144 - pred_intensity_loss: -0.4144 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4505 - loss: -0.4213 - pred_intensity_loss: -0.4231 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4453 - val_loss: -0.4039 - val_pred_intensity_loss: -0.4039 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4133 - pred_intensity_loss: -0.4133 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4492 - loss: -0.4213 - pred_intensity_loss: -0.4213 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4243 - pred_intensity_loss: -0.4250 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4455 - val_loss: -0.4062 - val_pred_intensity_loss: -0.4062 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.4291 - pred_intensity_loss: -0.4291 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4190 - pred_intensity_loss: -0.4190 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4264 - pred_intensity_loss: -0.4281 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4470 - val_loss: -0.4097 - val_pred_intensity_loss: -0.4097 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4508 - loss: -0.3871 - pred_intensity_loss: -0.3871 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4494 - loss: -0.4167 - pred_intensity_loss: -0.4167 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4476 - loss: -0.4292 - pred_intensity_loss: -0.4270 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4456 - val_loss: -0.4097 - val_pred_intensity_loss: -0.4097 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4469 - loss: -0.4120 - pred_intensity_loss: -0.4120 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4159 - pred_intensity_loss: -0.4159 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4302 - pred_intensity_loss: -0.4308 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4125 - val_pred_intensity_loss: -0.4125 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4494 - loss: -0.4490 - pred_intensity_loss: -0.4490 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4487 - loss: -0.4278 - pred_intensity_loss: -0.4278 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4318 - pred_intensity_loss: -0.4363 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4427 - val_loss: -0.4144 - val_pred_intensity_loss: -0.4144 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.4275 - pred_intensity_loss: -0.4275 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4469 - loss: -0.4383 - pred_intensity_loss: -0.4383 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4339 - pred_intensity_loss: -0.4347 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4439 - val_loss: -0.4139 - val_pred_intensity_loss: -0.4139 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4415 - loss: -0.4446 - pred_intensity_loss: -0.4446 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4317 - pred_intensity_loss: -0.4317 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4344 - pred_intensity_loss: -0.4330 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4455 - val_loss: -0.4153 - val_pred_intensity_loss: -0.4153 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4451 - loss: -0.4244 - pred_intensity_loss: -0.4244 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4317 - pred_intensity_loss: -0.4317 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4463 - loss: -0.4356 - pred_intensity_loss: -0.4358 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4428 - val_loss: -0.4163 - val_pred_intensity_loss: -0.4163 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4787 - pred_intensity_loss: -0.4787 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4514 - pred_intensity_loss: -0.4514 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4462 - loss: -0.4364 - pred_intensity_loss: -0.4367 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4399 - val_loss: -0.4164 - val_pred_intensity_loss: -0.4164 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4440 - pred_intensity_loss: -0.4440 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4456 - pred_intensity_loss: -0.4456 - trimmed_obj_loss: 0.0000e+00
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4368 - pred_intensity_loss: -0.4369 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4425 - val_loss: -0.4146 - val_pred_intensity_loss: -0.4146 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4522 - loss: -0.4323 - pred_intensity_loss: -0.4323 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4318 - pred_intensity_loss: -0.4318 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4385 - pred_intensity_loss: -0.4372 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4422 - val_loss: -0.4185 - val_pred_intensity_loss: -0.4185 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4482 - loss: -0.5187 - pred_intensity_loss: -0.5187 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4677 - pred_intensity_loss: -0.4677 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4397 - pred_intensity_loss: -0.4416 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4415 - val_loss: -0.4186 - val_pred_intensity_loss: -0.4186 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4462 - loss: -0.3978 - pred_intensity_loss: -0.3978 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4253 - pred_intensity_loss: -0.4253 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4409 - pred_intensity_loss: -0.4420 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4415 - val_loss: -0.4197 - val_pred_intensity_loss: -0.4197 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4481 - pred_intensity_loss: -0.4481 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4520 - pred_intensity_loss: -0.4520 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4416 - pred_intensity_loss: -0.4425 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4414 - val_loss: -0.4201 - val_pred_intensity_loss: -0.4201 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4393 - pred_intensity_loss: -0.4393 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4391 - pred_intensity_loss: -0.4391 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4418 - pred_intensity_loss: -0.4409 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4411 - val_loss: -0.4203 - val_pred_intensity_loss: -0.4203 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4474 - pred_intensity_loss: -0.4474 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4432 - loss: -0.4330 - pred_intensity_loss: -0.4330 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4424 - pred_intensity_loss: -0.4411 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4406 - val_loss: -0.4207 - val_pred_intensity_loss: -0.4207 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4434 - pred_intensity_loss: -0.4434 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4437 - pred_intensity_loss: -0.4437 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4430 - pred_intensity_loss: -0.4459 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4420 - val_loss: -0.4211 - val_pred_intensity_loss: -0.4211 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4415 - pred_intensity_loss: -0.4415 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4343 - pred_intensity_loss: -0.4343 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4434 - pred_intensity_loss: -0.4463 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4410 - val_loss: -0.4217 - val_pred_intensity_loss: -0.4217 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4402 - loss: -0.4264 - pred_intensity_loss: -0.4264 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4421 - loss: -0.4404 - pred_intensity_loss: -0.4404 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4439 - pred_intensity_loss: -0.4442 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4401 - val_loss: -0.4214 - val_pred_intensity_loss: -0.4214 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4491 - pred_intensity_loss: -0.4491 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4425 - pred_intensity_loss: -0.4425 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4441 - pred_intensity_loss: -0.4486 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4414 - val_loss: -0.4219 - val_pred_intensity_loss: -0.4219 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4492 - pred_intensity_loss: -0.4492 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4449 - pred_intensity_loss: -0.4449 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4439 - pred_intensity_loss: -0.4425 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4434 - val_loss: -0.4211 - val_pred_intensity_loss: -0.4211 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4507 - loss: -0.4459 - pred_intensity_loss: -0.4459 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4383 - pred_intensity_loss: -0.4383 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4441 - pred_intensity_loss: -0.4429 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4416 - val_loss: -0.4220 - val_pred_intensity_loss: -0.4220 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4587 - pred_intensity_loss: -0.4587 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4425 - pred_intensity_loss: -0.4425 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4444 - pred_intensity_loss: -0.4443 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4417 - val_loss: -0.4221 - val_pred_intensity_loss: -0.4221 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4415 - loss: -0.4220 - pred_intensity_loss: -0.4220 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4343 - pred_intensity_loss: -0.4343 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4445 - pred_intensity_loss: -0.4445 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4421 - val_loss: -0.4223 - val_pred_intensity_loss: -0.4223 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4401 - pred_intensity_loss: -0.4401 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4439 - pred_intensity_loss: -0.4439 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4446 - pred_intensity_loss: -0.4489 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4401 - val_loss: -0.4225 - val_pred_intensity_loss: -0.4225 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4393 - loss: -0.4529 - pred_intensity_loss: -0.4529 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4424 - loss: -0.4498 - pred_intensity_loss: -0.4498 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.4454 - pred_intensity_loss: -0.4443 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4396 - val_loss: -0.4224 - val_pred_intensity_loss: -0.4224 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4394 - loss: -0.4600 - pred_intensity_loss: -0.4600 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4415 - loss: -0.4501 - pred_intensity_loss: -0.4501 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4460 - pred_intensity_loss: -0.4467 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4398 - val_loss: -0.4233 - val_pred_intensity_loss: -0.4233 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4402 - loss: -0.4605 - pred_intensity_loss: -0.4605 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4428 - pred_intensity_loss: -0.4428 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4424 - loss: -0.4465 - pred_intensity_loss: -0.4447 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4400 - val_loss: -0.4230 - val_pred_intensity_loss: -0.4230 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.4671 - pred_intensity_loss: -0.4671 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4522 - pred_intensity_loss: -0.4522 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4424 - loss: -0.4469 - pred_intensity_loss: -0.4483 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4393 - val_loss: -0.4234 - val_pred_intensity_loss: -0.4234 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4671 - pred_intensity_loss: -0.4671 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.4535 - pred_intensity_loss: -0.4535 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4469 - pred_intensity_loss: -0.4470 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4406 - val_loss: -0.4230 - val_pred_intensity_loss: -0.4230 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4084 - pred_intensity_loss: -0.4084 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4293 - pred_intensity_loss: -0.4293 - trimmed_obj_loss: 0.0000e+00
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4422 - loss: -0.4470 - pred_intensity_loss: -0.4472 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4400 - val_loss: -0.4231 - val_pred_intensity_loss: -0.4231 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4374 - loss: -0.4154 - pred_intensity_loss: -0.4154 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4401 - loss: -0.4357 - pred_intensity_loss: -0.4357 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4479 - pred_intensity_loss: -0.4483 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4394 - val_loss: -0.4235 - val_pred_intensity_loss: -0.4235 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 932ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 524288 into shape (6,6,64,64,1)
2025-08-26 17:22:48,994 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 17:22:50,352 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run
[2025-08-26 17:22:51] SUCCESS: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 17:22:51] EXECUTING: Baseline training (n_images=128, trial=1)
[2025-08-26 17:22:51] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/train.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 17:22:51.947104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254171.958522 3354844 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254171.962268 3354844 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254171.973615 3354844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254171.973625 3354844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254171.973626 3354844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254171.973627 3354844 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:22:51.976737: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:22:54,536 - INFO - Configuration setup complete
2025-08-26 17:22:54,536 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 17:22:54,536 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 17:22:54,537 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 17:22:54,537 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1/
2025-08-26 17:22:54,537 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756254174.645028 3354844 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254174.646252 3354844 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 17:22:54,680 - INFO - 
[2/6] Loading data...
2025-08-26 17:22:54,681 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 17:22:54,681 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 17:22:55,000 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 17:22:55,000 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=None
2025-08-26 17:22:55,323 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 17:22:55,323 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:22:55,323 - INFO - Generating 128 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:22:55,323 - INFO - Sampled 128 seed points from 2576 total points
2025-08-26 17:22:55,323 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:22:55,323 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:22:55,323 - INFO - Generated 128 groups efficiently
2025-08-26 17:22:55,694 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:22:55,694 - INFO - Generating 128 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:22:55,694 - INFO - Sampled 128 seed points from 2576 total points
2025-08-26 17:22:55,694 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:22:55,694 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:22:55,694 - INFO - Generated 128 groups efficiently
2025-08-26 17:22:55,706 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-08-26 17:22:55,706 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 17:22:55,708 - INFO - Final training input shape: (128, 64, 64, 1)
2025-08-26 17:22:55,708 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 17:22:55,708 - INFO - Training with 128 images
DEBUG: Setting timestamp to 08/26/2025, 17:22:54 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
timestamp: 08/26/2025, 17:22:54
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1287.664 global_offsets=(128, 1, 2, 1) mean=91.447 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1426.688 global_offsets=(128, 1, 2, 1) mean=94.905 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254178.500242 3354983 service.cc:152] XLA service 0x716244008a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254178.500264 3354983 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:22:58.567315: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254178.979818 3354983 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254181.879229 3354983 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m38s[0m 6s/step - conv2d_12_loss: 0.5641 - conv2d_19_loss: 0.2306 - loss: 0.7946[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.8668 - conv2d_19_loss: 0.2752 - loss: 1.1420[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 417ms/step - conv2d_12_loss: 0.8539 - conv2d_19_loss: 0.2687 - loss: 1.1248[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 534ms/step - conv2d_12_loss: 0.7951 - conv2d_19_loss: 0.2468 - loss: 1.0599 - val_conv2d_12_loss: 0.5071 - val_conv2d_19_loss: 0.2125 - val_loss: 0.7197 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.5067 - conv2d_19_loss: 0.2223 - loss: 0.7290[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.4876 - conv2d_19_loss: 0.2224 - loss: 0.7099[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.4088 - conv2d_19_loss: 0.2174 - loss: 0.6408 - val_conv2d_12_loss: 0.2620 - val_conv2d_19_loss: 0.2134 - val_loss: 0.4754 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.2642 - conv2d_19_loss: 0.2251 - loss: 0.4893[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2056 - conv2d_19_loss: 0.2196 - loss: 0.4252[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.1581 - conv2d_19_loss: 0.2164 - loss: 0.3787 - val_conv2d_12_loss: 0.1253 - val_conv2d_19_loss: 0.2131 - val_loss: 0.3384 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.1255 - conv2d_19_loss: 0.2085 - loss: 0.3340[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.1123 - conv2d_19_loss: 0.2132 - loss: 0.3255[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0965 - conv2d_19_loss: 0.2175 - loss: 0.3146 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2125 - val_loss: 0.2963 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2218 - loss: 0.3060[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0776 - conv2d_19_loss: 0.2143 - loss: 0.2919[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0731 - conv2d_19_loss: 0.2171 - loss: 0.2902 - val_conv2d_12_loss: 0.0661 - val_conv2d_19_loss: 0.2125 - val_loss: 0.2786 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0677 - conv2d_19_loss: 0.2206 - loss: 0.2883[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0661 - conv2d_19_loss: 0.2215 - loss: 0.2877[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0635 - conv2d_19_loss: 0.2163 - loss: 0.2805 - val_conv2d_12_loss: 0.0604 - val_conv2d_19_loss: 0.2123 - val_loss: 0.2727 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0602 - conv2d_19_loss: 0.2227 - loss: 0.2829[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0600 - conv2d_19_loss: 0.2213 - loss: 0.2813[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0585 - conv2d_19_loss: 0.2165 - loss: 0.2755 - val_conv2d_12_loss: 0.0558 - val_conv2d_19_loss: 0.2123 - val_loss: 0.2681 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0583 - conv2d_19_loss: 0.2259 - loss: 0.2843[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0565 - conv2d_19_loss: 0.2192 - loss: 0.2757[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0550 - conv2d_19_loss: 0.2163 - loss: 0.2718 - val_conv2d_12_loss: 0.0530 - val_conv2d_19_loss: 0.2124 - val_loss: 0.2654 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0527 - conv2d_19_loss: 0.2161 - loss: 0.2688[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.2191 - loss: 0.2721[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.2158 - loss: 0.2692 - val_conv2d_12_loss: 0.0509 - val_conv2d_19_loss: 0.2123 - val_loss: 0.2631 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0529 - conv2d_19_loss: 0.2264 - loss: 0.2793[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0514 - conv2d_19_loss: 0.2196 - loss: 0.2710[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0503 - conv2d_19_loss: 0.2164 - loss: 0.2671 - val_conv2d_12_loss: 0.0491 - val_conv2d_19_loss: 0.2123 - val_loss: 0.2614 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0498 - conv2d_19_loss: 0.2192 - loss: 0.2689[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0492 - conv2d_19_loss: 0.2187 - loss: 0.2678[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0484 - conv2d_19_loss: 0.2161 - loss: 0.2652 - val_conv2d_12_loss: 0.0471 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2593 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.2175 - loss: 0.2654[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0473 - conv2d_19_loss: 0.2178 - loss: 0.2651[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0466 - conv2d_19_loss: 0.2168 - loss: 0.2632 - val_conv2d_12_loss: 0.0453 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2575 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0446 - conv2d_19_loss: 0.2162 - loss: 0.2608[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0452 - conv2d_19_loss: 0.2181 - loss: 0.2632[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0447 - conv2d_19_loss: 0.2166 - loss: 0.2614 - val_conv2d_12_loss: 0.0433 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2556 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0410 - conv2d_19_loss: 0.2069 - loss: 0.2480[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.2134 - loss: 0.2559[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.2160 - loss: 0.2594 - val_conv2d_12_loss: 0.0415 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2537 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2105 - loss: 0.2506[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0408 - conv2d_19_loss: 0.2133 - loss: 0.2541[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0411 - conv2d_19_loss: 0.2162 - loss: 0.2577 - val_conv2d_12_loss: 0.0400 - val_conv2d_19_loss: 0.2121 - val_loss: 0.2521 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2189 - loss: 0.2592[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.2171 - loss: 0.2577[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.2166 - loss: 0.2568 - val_conv2d_12_loss: 0.0399 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2520 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.2184 - loss: 0.2591[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.2192 - loss: 0.2596[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.2167 - loss: 0.2562 - val_conv2d_12_loss: 0.0391 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2512 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2201 - loss: 0.2600[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2195 - loss: 0.2593[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2170 - loss: 0.2559 - val_conv2d_12_loss: 0.0390 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2510 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.2199 - loss: 0.2596[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2200 - loss: 0.2597[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2176 - loss: 0.2558 - val_conv2d_12_loss: 0.0393 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2513 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0410 - conv2d_19_loss: 0.2212 - loss: 0.2622[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.2158 - loss: 0.2555
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2166 - loss: 0.2558 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2124 - val_loss: 0.2511 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2173 - loss: 0.2565[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2178 - loss: 0.2572[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2167 - loss: 0.2557 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2508 - learning_rate: 5.0000e-04
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.2024 - loss: 0.2386[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2088 - loss: 0.2465[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2171 - loss: 0.2557 - val_conv2d_12_loss: 0.0388 - val_conv2d_19_loss: 0.2122 - val_loss: 0.2510 - learning_rate: 5.0000e-04
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2141 - loss: 0.2522[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2149 - loss: 0.2535
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2166 - loss: 0.2557 - val_conv2d_12_loss: 0.0389 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2508 - learning_rate: 5.0000e-04
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2103 - loss: 0.2482[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2134 - loss: 0.2520[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2161 - loss: 0.2556 - val_conv2d_12_loss: 0.0388 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2508 - learning_rate: 2.5000e-04
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2113 - loss: 0.2494[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2148 - loss: 0.2536
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2166 - loss: 0.2556 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2507 - learning_rate: 2.5000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2152 - loss: 0.2549[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2148 - loss: 0.2541[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2160 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.2500e-04
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2217 - loss: 0.2616[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2168 - loss: 0.2559[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2168 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.2500e-04
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2117 - loss: 0.2499[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2134 - loss: 0.2520
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2171 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.2500e-04
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.2222 - loss: 0.2629[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2195 - loss: 0.2593[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2155 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.2202 - loss: 0.2602[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2169 - loss: 0.2563[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2162 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2128 - loss: 0.2508[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2159 - loss: 0.2548[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2165 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2248 - loss: 0.2649[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2188 - loss: 0.2581[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2161 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.2266 - loss: 0.2666[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2214 - loss: 0.2613[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2154 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.2263 - loss: 0.2669[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2178 - loss: 0.2571[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2168 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2113 - loss: 0.2496[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2127 - loss: 0.2510[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2168 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2507 - learning_rate: 1.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2039 - loss: 0.2416[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2096 - loss: 0.2479[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2173 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2198 - loss: 0.2593[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2210 - loss: 0.2609[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2147 - loss: 0.2555 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2138 - loss: 0.2532[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2141 - loss: 0.2531[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2169 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2508 - learning_rate: 1.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2211 - loss: 0.2615[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2164 - loss: 0.2557[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2170 - loss: 0.2555 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2127 - loss: 0.2508[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2158 - loss: 0.2545[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2157 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2507 - learning_rate: 1.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2112 - loss: 0.2505[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2139 - loss: 0.2530[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2162 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0414 - conv2d_19_loss: 0.2300 - loss: 0.2714[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2177 - loss: 0.2570[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2167 - loss: 0.2555 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2174 - loss: 0.2567[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2207 - loss: 0.2606[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2159 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2507 - learning_rate: 1.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2065 - loss: 0.2438[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2140 - loss: 0.2525[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2169 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2156 - loss: 0.2543[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2162 - loss: 0.2551[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2168 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.2278 - loss: 0.2690[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2230 - loss: 0.2631[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2154 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0411 - conv2d_19_loss: 0.2255 - loss: 0.2666[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0396 - conv2d_19_loss: 0.2189 - loss: 0.2585[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2167 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2114 - loss: 0.2494[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2137 - loss: 0.2522[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2166 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2506 - learning_rate: 1.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2082 - loss: 0.2463[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2131 - loss: 0.2518[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2155 - loss: 0.2554 - val_conv2d_12_loss: 0.0387 - val_conv2d_19_loss: 0.2120 - val_loss: 0.2507 - learning_rate: 1.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2166 - loss: 0.2549[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2183 - loss: 0.2575[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2156 - loss: 0.2554 - val_conv2d_12_loss: 0.0386 - val_conv2d_19_loss: 0.2119 - val_loss: 0.2506 - learning_rate: 1.0000e-04
2025-08-26 17:23:12,607 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 17:23:12,728 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1/baseline_model.h5
2025-08-26 17:23:12,728 - INFO - 
[5/6] Performing inference and stitching...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 801ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
2025-08-26 17:23:16,003 - INFO - Stitched object shape: (1, 192, 192, 1, 1)
2025-08-26 17:23:16,003 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 17:23:16,004 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 17:23:16,004 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:23:16,004 - INFO - Calculated ground truth crop region: rows [22:125], cols [23:209]
2025-08-26 17:23:16,004 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 186)
2025-08-26 17:23:16,004 - INFO - Center-cropping from (192, 192) to (103, 186)
2025-08-26 17:23:16,004 - INFO - Final aligned shape: (103, 186)
2025-08-26 17:23:16,004 - INFO - --- Alignment complete ---
2025-08-26 17:23:16,004 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 186, 1), Ground Truth=(103, 186, 1)
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
2025-08-26 17:23:16,025 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 17:23:16,025 - INFO -   MAE:  (np.float32(0.09595281), np.float64(0.23201297198052875))
2025-08-26 17:23:16,025 - INFO -   PSNR: (63.227314454254405, 59.65509742286062)
2025-08-26 17:23:16,066 - INFO - Metrics and reconstruction images saved.
2025-08-26 17:23:16,066 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.067549
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.565236, std=0.044033, shape=(99, 182, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.529470, std=0.159496, shape=(99, 182, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.264904, shape=(99, 182)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.021810, shape=(99, 182)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.558]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.067549
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.565236, std=0.044033, shape=(99, 182, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.529470, std=0.159496, shape=(99, 182, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.264904, shape=(99, 182)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.021810, shape=(99, 182)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.558]
performed by index method
performed by index method
performed by index method
[2025-08-26 17:23:17] SUCCESS: Baseline training (n_images=128, trial=1)
[2025-08-26 17:23:17] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 17:23:17] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/train.npz' \
                '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 128 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 17:23:34] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 17:23:34] Completed training for train_size=128 (Trial 1/1)
[2025-08-26 17:23:34] Completed all trials for train_size=128
[2025-08-26 17:23:34] Model training phase completed
[2025-08-26 17:23:34] === STEP 3: Model Comparison ===
[2025-08-26 17:23:34] Running comparisons for train_size=128, test_size=128 (1 trials)
[2025-08-26 17:23:34] Using test subset size 128 (3-way comparison mode with Pty-chi)
[2025-08-26 17:23:34] EXECUTING: Model comparison (train_size=128, trial=1)
[2025-08-26 17:23:34] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/train.npz' --output_dir '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1' --skip-registration --tike_recon_path '3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 128
2025-08-26 17:23:34.523297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254214.535022 3362615 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254214.539042 3362615 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254214.550089 3362615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254214.550098 3362615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254214.550100 3362615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254214.550101 3362615 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:23:34.552963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:23:36,819 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 17:23:36,820 - INFO - Registration: disabled
2025-08-26 17:23:36,820 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 17:23:36,820 - INFO - Initializing configuration before data loading...
2025-08-26 17:23:36,820 - INFO - Initialized with gridsize=1, n_images=128
2025-08-26 17:23:36,820 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/train.npz...
2025-08-26 17:23:36,820 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 17:23:37,141 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)2025-08-26 17:23:37,141 - INFO - diff3d shape: (2576, 64, 64)

probeGuess shape: (64, 64)2025-08-26 17:23:37,141 - INFO - probeGuess shape: (64, 64)

scan_index shape: (2576,)2025-08-26 17:23:37,141 - INFO - scan_index shape: (2576,)

objectGuess shape: (232, 232)2025-08-26 17:23:37,141 - INFO - objectGuess shape: (232, 232)

xcoords shape: (2576,)2025-08-26 17:23:37,141 - INFO - xcoords shape: (2576,)

ycoords shape: (2576,)2025-08-26 17:23:37,141 - INFO - ycoords shape: (2576,)

xcoords_start shape: (2576,)2025-08-26 17:23:37,141 - INFO - xcoords_start shape: (2576,)

ycoords_start shape: (2576,)2025-08-26 17:23:37,141 - INFO - ycoords_start shape: (2576,)

2025-08-26 17:23:37,141 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 17:23:37,141 - INFO - DEBUG:
 nsamples: 2576, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 17:23:37,141 - INFO - nsamples: 2576, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 17:23:37,141 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:23:37,141 - INFO - Generating 2576 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:23:37,141 - INFO - Using all 2576 points as seeds
2025-08-26 17:23:37,141 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:23:37,141 - INFO - Successfully generated 2576 groups with shape (2576, 1)
2025-08-26 17:23:37,141 - INFO - Generated 2576 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 17:23:37,148 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756254217.287831 3362615 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254217.289062 3362615 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 17:23:37,373 - INFO - neighbor-sampled diffraction shape
 (2576, 64, 64, 1)2025-08-26 17:23:37,373 - INFO - (2576, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 17:23:37,546 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 17:23:37,942 - INFO - INFO:
 None2025-08-26 17:23:37,942 - INFO - None

<PtychoDataContainer X=(2576, 64, 64, 1) Y_I=(2576, 64, 64, 1) Y_phi=(2576, 64, 64, 1) norm_Y_I=() coords_nominal=(2576, 1, 2, 1) coords_true=(2576, 1, 2, 1) nn_indices=(2576, 1) mean=1287.500 global_offsets=(2576, 1, 2, 1) mean=94.803 local_offsets=(2576, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 17:23:37,942 - INFO - <PtychoDataContainer X=(2576, 64, 64, 1) Y_I=(2576, 64, 64, 1) Y_phi=(2576, 64, 64, 1) norm_Y_I=() coords_nominal=(2576, 1, 2, 1) coords_true=(2576, 1, 2, 1) nn_indices=(2576, 1) mean=1287.500 global_offsets=(2576, 1, 2, 1) mean=94.803 local_offsets=(2576, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 17:23:37,943 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run...
2025-08-26 17:23:37,943 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run
Model: "functional"
2025-08-26 17:23:38,707 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 17:23:38,728 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 17:23:38,728 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 17:23:38,728 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:23:38,728 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 17:23:38,728 - INFO - None

2025-08-26 17:23:38.728993: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:23:38.729002: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254218.729017 3362615 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756254218.746124 3362615 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:23:38.746212: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756254218.746287 3362615 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:23:38,897 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:23:38,897 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:23:39,384 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_run
2025-08-26 17:23:39,385 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1...
2025-08-26 17:23:39,385 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_run/08-26-2025-17.22.54_baseline_gs1/baseline_model.h5
2025-08-26 17:23:39,472 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 17:23:39,477 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 17:23:39,479 - INFO - Loaded Pty-chi (ePIE) reconstruction: (197, 282) (complex64)
2025-08-26 17:23:39,479 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 17:23:39,479 - INFO - Pty-chi (ePIE) computation time: 12.84s
2025-08-26 17:23:39,479 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756254220.557381 3362757 service.cc:152] XLA service 0x7e17dc00e9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254220.557401 3362757 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:23:40.638309: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254220.788277 3362757 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254222.138383 3362757 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3:29[0m 3s/step2025-08-26 17:23:42,147 - INFO - [1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3:29[0m 3s/step
[1m12/81[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step 2025-08-26 17:23:42,198 - INFO - [1m12/81[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m23/81[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:23:42,248 - INFO - [1m23/81[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m35/81[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:23:42,302 - INFO - [1m35/81[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m47/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:23:42,357 - INFO - [1m47/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m59/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:23:42,410 - INFO - [1m59/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m71/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:23:42,464 - INFO - [1m71/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 5ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 25ms/step2025-08-26 17:23:44,130 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 25ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m5s[0m 25ms/step
2025-08-26 17:23:44,143 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m5s[0m 25ms/step
2025-08-26 17:23:44,234 - INFO - PtychoPINN inference completed in 4.76s
2025-08-26 17:23:44,234 - INFO - Reassembling PtychoPINN patches...
2025-08-26 17:23:46,149 - INFO - Running inference with Baseline model...
[1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m44s[0m 562ms/step2025-08-26 17:23:46,747 - INFO - [1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m44s[0m 562ms/step
[1m14/81[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step   2025-08-26 17:23:46,798 - INFO - [1m14/81[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m27/81[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:23:46,851 - INFO - [1m27/81[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m40/81[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:23:46,905 - INFO - [1m40/81[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m53/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:23:46,958 - INFO - [1m53/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m66/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:23:47,011 - INFO - [1m66/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step
[1m79/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step2025-08-26 17:23:47,064 - INFO - [1m79/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step2025-08-26 17:23:47,596 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step
2025-08-26 17:23:47,609 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step
2025-08-26 17:23:47,703 - INFO - Baseline inference completed in 1.55s
2025-08-26 17:23:47,821 - INFO - Reassembling baseline patches...
2025-08-26 17:23:47,851 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 17:23:47,929 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/reconstructions.npz
2025-08-26 17:23:47,929 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/reconstructions_metadata.txt
2025-08-26 17:23:47,929 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 17:23:47,929 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 17:23:47,929 - INFO - Ground truth original shape: (232, 232)
2025-08-26 17:23:47,929 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:23:47,930 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:23:47,930 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 187)
2025-08-26 17:23:47,930 - INFO - Center-cropping from (192, 192) to (103, 187)
2025-08-26 17:23:47,930 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:23:47,930 - INFO - --- Alignment complete ---
2025-08-26 17:23:47,930 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:23:47,930 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:23:47,930 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 187)
2025-08-26 17:23:47,930 - INFO - Center-cropping from (192, 192) to (103, 187)
2025-08-26 17:23:47,930 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:23:47,930 - INFO - --- Alignment complete ---
2025-08-26 17:23:47,930 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:23:47,930 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:23:47,930 - INFO - Initial shapes: Recon=(197, 282), Cropped GT=(103, 187)
2025-08-26 17:23:47,930 - INFO - Center-cropping from (197, 282) to (103, 187)
2025-08-26 17:23:47,930 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:23:47,930 - INFO - --- Alignment complete ---
2025-08-26 17:23:47,930 - INFO - Skipping registration (--skip-registration specified)
2025-08-26 17:23:47,930 - INFO - Final evaluation shapes: PINN (103, 187), Baseline (103, 187), Pty-chi (ePIE) (103, 187), GT (103, 187)
Amplitude normalization scale factor: 0.7234682025-08-26 17:23:47,933 - INFO - Amplitude normalization scale factor: 0.723468

mean scale adjustment:2025-08-26 17:23:47,933 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,933 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,933 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,933 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:23:47,934 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.781287, std=0.056878, shape=(99, 183, 1)2025-08-26 17:23:47,934 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.781287, std=0.056878, shape=(99, 183, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:23:47,934 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.212491, shape=(99, 183)2025-08-26 17:23:47,934 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.212491, shape=(99, 183)

performed by index method2025-08-26 17:23:47,935 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,937 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,939 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:23:47,940 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,940 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,941 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,941 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:23:47,941 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

performed by index method2025-08-26 17:23:47,944 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,946 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,948 - INFO - performed by index method

2025-08-26 17:23:47,950 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.705, phase=0.907, MS-SSIM: amp=0.868, phase=0.840
Amplitude normalization scale factor: 0.9788542025-08-26 17:23:47,952 - INFO - Amplitude normalization scale factor: 0.978854

mean scale adjustment:2025-08-26 17:23:47,952 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,952 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,952 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,952 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:23:47,952 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.577447, std=0.006068, shape=(99, 183, 1)2025-08-26 17:23:47,953 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.577447, std=0.006068, shape=(99, 183, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:23:47,953 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.001317, shape=(99, 183)2025-08-26 17:23:47,953 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.001317, shape=(99, 183)

performed by index method2025-08-26 17:23:47,953 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,955 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,957 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:23:47,959 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,959 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,959 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,959 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:23:47,959 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

performed by index method2025-08-26 17:23:47,962 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,964 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,966 - INFO - performed by index method

2025-08-26 17:23:47,968 - INFO - Baseline evaluation complete. SSIM: amp=0.095, phase=0.563, MS-SSIM: amp=0.094, phase=0.027
Amplitude normalization scale factor: 0.4934792025-08-26 17:23:47,970 - INFO - Amplitude normalization scale factor: 0.493479

mean scale adjustment:2025-08-26 17:23:47,970 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,970 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,970 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,970 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:23:47,971 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.145411, std=0.323406, shape=(99, 183, 1)2025-08-26 17:23:47,971 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.145411, std=0.323406, shape=(99, 183, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:23:47,971 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.283151, shape=(99, 183)2025-08-26 17:23:47,971 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.283151, shape=(99, 183)

performed by index method2025-08-26 17:23:47,971 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,973 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,975 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:23:47,977 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,977 - INFO - 1

mean scale adjustment:2025-08-26 17:23:47,977 - INFO - mean scale adjustment:
 12025-08-26 17:23:47,977 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:23:47,977 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
2025-08-26 17:23:47,979 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
performed by index method2025-08-26 17:23:47,981 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,983 - INFO - performed by index method

performed by index method2025-08-26 17:23:47,984 - INFO - performed by index method

2025-08-26 17:23:47,986 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=-0.071, phase=0.264, MS-SSIM: amp=nan, phase=nan
2025-08-26 17:23:47,988 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 17:23:47,988 - INFO - --- Comparison Metrics ---

         model             metric  amplitude     phase     value
    PtychoPINN                mae   0.017690  0.093711       NaN
    PtychoPINN                mse   0.000574  0.014986       NaN
    PtychoPINN               psnr  80.542593 66.374041       NaN
    PtychoPINN               ssim   0.704977  0.907237       NaN
    PtychoPINN            ms_ssim   0.868274  0.840124       NaN
    PtychoPINN              frc50  14.000000 21.000000       NaN
      Baseline                mae   0.038463  0.232232       NaN
      Baseline                mse   0.001976  0.070191       NaN
      Baseline               psnr  75.171857 59.668004       NaN
      Baseline               ssim   0.094609  0.563258       NaN
      Baseline            ms_ssim   0.094352  0.027038       NaN
      Baseline              frc50   3.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.121921  0.316172       NaN
Pty-chi (ePIE)                mse   0.027778  0.159953       NaN
Pty-chi (ePIE)               psnr  63.693795 56.090888       NaN
Pty-chi (ePIE)               ssim  -0.070595  0.263610       NaN
Pty-chi (ePIE)            ms_ssim        NaN       NaN       NaN
Pty-chi (ePIE)              frc50   1.000000  2.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  4.755539
      Baseline computation_time_s        NaN       NaN  1.553418
Pty-chi (ePIE) computation_time_s        NaN       NaN 12.8363852025-08-26 17:23:47,989 - INFO - model             metric  amplitude     phase     value
    PtychoPINN                mae   0.017690  0.093711       NaN
    PtychoPINN                mse   0.000574  0.014986       NaN
    PtychoPINN               psnr  80.542593 66.374041       NaN
    PtychoPINN               ssim   0.704977  0.907237       NaN
    PtychoPINN            ms_ssim   0.868274  0.840124       NaN
    PtychoPINN              frc50  14.000000 21.000000       NaN
      Baseline                mae   0.038463  0.232232       NaN
      Baseline                mse   0.001976  0.070191       NaN
      Baseline               psnr  75.171857 59.668004       NaN
      Baseline               ssim   0.094609  0.563258       NaN
      Baseline            ms_ssim   0.094352  0.027038       NaN
      Baseline              frc50   3.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.121921  0.316172       NaN
Pty-chi (ePIE)                mse   0.027778  0.159953       NaN
Pty-chi (ePIE)               psnr  63.693795 56.090888       NaN
Pty-chi (ePIE)               ssim  -0.070595  0.263610       NaN
Pty-chi (ePIE)            ms_ssim        NaN       NaN       NaN
Pty-chi (ePIE)              frc50   1.000000  2.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  4.755539
      Baseline computation_time_s        NaN       NaN  1.553418
Pty-chi (ePIE) computation_time_s        NaN       NaN 12.836385

2025-08-26 17:23:47,990 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/pinn_frc_curves.csv
2025-08-26 17:23:47,991 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/baseline_frc_curves.csv
2025-08-26 17:23:47,991 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 17:23:48,022 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/reconstructions_aligned.npz
2025-08-26 17:23:48,022 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 17:23:48,022 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 17:23:48,228 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.706, 0.863) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,228 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.577, 0.578) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,228 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.382, 0.183) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,229 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.080, 0.084) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,229 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.825, 1.749) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,230 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.466, 0.271) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,238 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.502, 0.617) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,238 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.482, 0.215) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:23:48,947 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1/comparison_plot.png
2025-08-26 17:23:48,947 - INFO - 
Comparison complete!
2025-08-26 17:23:48,947 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_cheat/train_128/trial_1
[2025-08-26 17:23:49] SUCCESS: Model comparison (train_size=128, trial=1)
[2025-08-26 17:23:49] Completed comparisons for train_size=128
[2025-08-26 17:23:49] Model comparison phase completed
[2025-08-26 17:23:49] === STEP 4: Results Aggregation ===
[2025-08-26 17:23:49] EXECUTING: PSNR phase generalization plot
[2025-08-26 17:23:49] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
17:23:50 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:50 - INFO - Analyzing psnr_phase
17:23:50 - INFO - Discovered 1 comparison files
17:23:50 - INFO - Single-trial data detected - using legacy aggregation
17:23:50 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:50 - INFO - Made 1 out-of-range replacements with NaN
17:23:50 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:50 - INFO - Loaded 3 trial records
17:23:50 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:50 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:50 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:50 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:50 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:50 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:50 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:50 - INFO - NaN exclusion summary:
17:23:50 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:50 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:50 - INFO - Extracted 1 data points for psnr_phase (using mean)
17:23:50 - WARNING - Missing expected model types: {'baseline'}
17:23:50 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/psnr_phase_generalization.png
17:23:50 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:50 - INFO - Processing complete!
17:23:50 - INFO - Outputs:
17:23:50 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/psnr_phase_generalization.png
17:23:50 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:50 - INFO - Summary: 1 models, 1 training sizes
17:23:50 - INFO - Training sizes: [np.int64(128)]
17:23:50 - INFO - Model types: ['pinn']
[2025-08-26 17:23:50] SUCCESS: PSNR phase generalization plot
[2025-08-26 17:23:50] EXECUTING: FRC amplitude generalization plot
[2025-08-26 17:23:50] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
17:23:51 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:51 - INFO - Analyzing frc50_amp
17:23:51 - INFO - Discovered 1 comparison files
17:23:51 - INFO - Single-trial data detected - using legacy aggregation
17:23:51 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:51 - INFO - Made 1 out-of-range replacements with NaN
17:23:51 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:51 - INFO - Loaded 3 trial records
17:23:51 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:51 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:51 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:51 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:51 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:51 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:51 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:51 - INFO - NaN exclusion summary:
17:23:51 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:51 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:51 - INFO - Extracted 1 data points for frc50_amp (using mean)
17:23:51 - WARNING - Missing expected model types: {'baseline'}
17:23:51 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/frc50_amp_generalization.png
17:23:51 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:51 - INFO - Processing complete!
17:23:51 - INFO - Outputs:
17:23:51 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/frc50_amp_generalization.png
17:23:51 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:51 - INFO - Summary: 1 models, 1 training sizes
17:23:51 - INFO - Training sizes: [np.int64(128)]
17:23:51 - INFO - Model types: ['pinn']
[2025-08-26 17:23:51] SUCCESS: FRC amplitude generalization plot
[2025-08-26 17:23:51] EXECUTING: MAE amplitude generalization plot
[2025-08-26 17:23:51] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
17:23:51 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:51 - INFO - Analyzing mae_amp
17:23:51 - INFO - Discovered 1 comparison files
17:23:51 - INFO - Single-trial data detected - using legacy aggregation
17:23:51 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:51 - INFO - Made 1 out-of-range replacements with NaN
17:23:51 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:51 - INFO - Loaded 3 trial records
17:23:51 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:51 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:51 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:51 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:51 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:51 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:51 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:51 - INFO - NaN exclusion summary:
17:23:51 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:51 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:51 - INFO - Extracted 1 data points for mae_amp (using mean)
17:23:51 - WARNING - Missing expected model types: {'baseline'}
17:23:51 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/mae_amp_generalization.png
17:23:51 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:51 - INFO - Processing complete!
17:23:51 - INFO - Outputs:
17:23:51 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/mae_amp_generalization.png
17:23:51 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:51 - INFO - Summary: 1 models, 1 training sizes
17:23:51 - INFO - Training sizes: [np.int64(128)]
17:23:51 - INFO - Model types: ['pinn']
[2025-08-26 17:23:51] SUCCESS: MAE amplitude generalization plot
[2025-08-26 17:23:51] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 17:23:51] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
17:23:52 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:52 - INFO - Analyzing ssim_amp
17:23:52 - INFO - Discovered 1 comparison files
17:23:52 - INFO - Single-trial data detected - using legacy aggregation
17:23:52 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:52 - INFO - Made 1 out-of-range replacements with NaN
17:23:52 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:52 - INFO - Loaded 3 trial records
17:23:52 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:52 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:52 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:52 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:52 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:52 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:52 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:52 - INFO - NaN exclusion summary:
17:23:52 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:52 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:52 - INFO - Extracted 1 data points for ssim_amp (using mean)
17:23:52 - WARNING - Missing expected model types: {'baseline'}
17:23:52 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/ssim_amp_generalization.png
17:23:52 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:52 - INFO - Processing complete!
17:23:52 - INFO - Outputs:
17:23:52 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/ssim_amp_generalization.png
17:23:52 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:52 - INFO - Summary: 1 models, 1 training sizes
17:23:52 - INFO - Training sizes: [np.int64(128)]
17:23:52 - INFO - Model types: ['pinn']
[2025-08-26 17:23:52] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 17:23:52] EXECUTING: SSIM phase generalization plot
[2025-08-26 17:23:52] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
17:23:52 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:52 - INFO - Analyzing ssim_phase
17:23:52 - INFO - Discovered 1 comparison files
17:23:52 - INFO - Single-trial data detected - using legacy aggregation
17:23:52 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:52 - INFO - Made 1 out-of-range replacements with NaN
17:23:52 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:52 - INFO - Loaded 3 trial records
17:23:52 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:52 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:52 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:52 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:52 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:52 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:52 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:52 - INFO - NaN exclusion summary:
17:23:52 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:52 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:52 - INFO - Extracted 1 data points for ssim_phase (using mean)
17:23:52 - WARNING - Missing expected model types: {'baseline'}
17:23:53 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/ssim_phase_generalization.png
17:23:53 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:53 - INFO - Processing complete!
17:23:53 - INFO - Outputs:
17:23:53 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/ssim_phase_generalization.png
17:23:53 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:53 - INFO - Summary: 1 models, 1 training sizes
17:23:53 - INFO - Training sizes: [np.int64(128)]
17:23:53 - INFO - Model types: ['pinn']
[2025-08-26 17:23:53] SUCCESS: SSIM phase generalization plot
[2025-08-26 17:23:53] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 17:23:53] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
17:23:53 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:53 - INFO - Analyzing ms_ssim_amp
17:23:53 - INFO - Discovered 1 comparison files
17:23:53 - INFO - Single-trial data detected - using legacy aggregation
17:23:53 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:53 - INFO - Made 1 out-of-range replacements with NaN
17:23:53 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:53 - INFO - Loaded 3 trial records
17:23:53 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:53 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:53 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:53 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:53 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:53 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:53 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:53 - INFO - NaN exclusion summary:
17:23:53 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:53 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:53 - INFO - Extracted 1 data points for ms_ssim_amp (using mean)
17:23:53 - WARNING - Missing expected model types: {'baseline'}
17:23:53 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/ms_ssim_amp_generalization.png
17:23:53 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:53 - INFO - Processing complete!
17:23:53 - INFO - Outputs:
17:23:53 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/ms_ssim_amp_generalization.png
17:23:53 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:53 - INFO - Summary: 1 models, 1 training sizes
17:23:53 - INFO - Training sizes: [np.int64(128)]
17:23:53 - INFO - Model types: ['pinn']
[2025-08-26 17:23:53] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 17:23:53] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 17:23:53] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
17:23:54 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat
17:23:54 - INFO - Analyzing ms_ssim_phase
17:23:54 - INFO - Discovered 1 comparison files
17:23:54 - INFO - Single-trial data detected - using legacy aggregation
17:23:54 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.070595]
17:23:54 - INFO - Made 1 out-of-range replacements with NaN
17:23:54 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:23:54 - INFO - Loaded 3 trial records
17:23:54 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:23:54 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:23:54 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:23:54 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:23:54 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:23:54 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:23:54 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:23:54 - INFO - NaN exclusion summary:
17:23:54 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:23:54 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:23:54 - INFO - Extracted 1 data points for ms_ssim_phase (using mean)
17:23:54 - WARNING - Missing expected model types: {'baseline'}
17:23:54 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat/ms_ssim_phase_generalization.png
17:23:54 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat/results.csv (13 metric entries)
17:23:54 - INFO - Processing complete!
17:23:54 - INFO - Outputs:
17:23:54 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat/ms_ssim_phase_generalization.png
17:23:54 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat/results.csv
17:23:54 - INFO - Summary: 1 models, 1 training sizes
17:23:54 - INFO - Training sizes: [np.int64(128)]
17:23:54 - INFO - Model types: ['pinn']
[2025-08-26 17:23:54] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 17:23:54] Results aggregation completed
[2025-08-26 17:23:54] === Generating Summary Report ===
[2025-08-26 17:23:54] Summary report generated: 3way_synthetic_ptychi_1e4_cheat/STUDY_SUMMARY.md
[2025-08-26 17:23:54] === Study Completed Successfully ===
[2025-08-26 17:23:54] Training sizes tested: 1
[2025-08-26 17:23:54] Trials per size: 1
[2025-08-26 17:23:54] Total trials completed: 1
[2025-08-26 17:23:54] Total runtime: 00:01:33
[2025-08-26 17:23:54] Results directory: 3way_synthetic_ptychi_1e4_cheat
[2025-08-26 17:23:54] Summary report: 3way_synthetic_ptychi_1e4_cheat/STUDY_SUMMARY.md
