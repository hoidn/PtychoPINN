2025-08-02 11:44:28.363559: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754160268.374896  332632 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754160268.378291  332632 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754160268.388570  332632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754160268.388585  332632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754160268.388587  332632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754160268.388589  332632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-02 11:44:28.391615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-02 11:44:30,716 - INFO - Configuration setup complete
2025-08-02 11:44:30,716 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('test_prep_quick/gs2_hybrid/train_data.npz'), test_data_file=PosixPath('test_prep_quick/gs2_hybrid/test_data.npz'), batch_size=16, nepochs=2, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=500, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('test_prep_quick/gs2_hybrid/trained_model'))
2025-08-02 11:44:30,716 - INFO - Parameter interpretation: --n-images=500 refers to neighbor groups (gridsize=2, total patterns=2000)
2025-08-02 11:44:30,716 - INFO - Starting training with n_images=500, stitching=disabled
2025-08-02 11:44:30,716 - INFO - Loading data from test_prep_quick/gs2_hybrid/train_data.npz with n_images=500
2025-08-02 11:44:30,744 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-02 11:44:30,745 - INFO - Loading data from test_prep_quick/gs2_hybrid/test_data.npz with n_images=None
2025-08-02 11:44:30,751 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-02 11:44:30,751 - INFO - Loaded test data from test_prep_quick/gs2_hybrid/test_data.npz
2025-08-02 11:44:30,752 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-02 11:44:30,752 - INFO - Efficiently sampling 500 groups for gridsize=2
2025-08-02 11:44:30,760 - INFO - Efficiently generated 500 groups without O(NÂ²) computation
2025-08-02 11:44:30,760 - INFO - Selected 500 groups for training
2025-08-02 11:44:30,764 - INFO - 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
I0000 00:00:1754160270.885021  332632 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1754160270.886253  332632 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11487 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754160271.563495  332632 service.cc:152] XLA service 0x3b36d5f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1754160271.563528  332632 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-02 11:44:31.577944: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1754160271.595111  332632 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1754160271.720899  332632 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(500, 64, 64, 4) Y_I=(500, 64, 64, 4) Y_phi=(500, 64, 64, 4) norm_Y_I=() coords_nominal=(500, 1, 2, 4) coords_true=(500, 1, 2, 4) nn_indices=(500, 4) mean=247.509 global_offsets=(500, 1, 2, 1) mean=110.407 local_offsets=(500, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.092>
2025-08-02 11:44:38,631 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-02 11:44:38,631 - WARNING - Requested 500 groups but only 100 points available. Using 100.
2025-08-02 11:44:38,631 - INFO - Efficiently sampling 100 groups for gridsize=2
2025-08-02 11:44:38,632 - INFO - Efficiently generated 100 groups without O(NÂ²) computation
2025-08-02 11:44:38,632 - INFO - Selected 100 groups for training
2025-08-02 11:44:38,633 - INFO - 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(100, 64, 64, 4) Y_I=(100, 64, 64, 4) Y_phi=(100, 64, 64, 4) norm_Y_I=() coords_nominal=(100, 1, 2, 4) coords_true=(100, 1, 2, 4) nn_indices=(100, 4) mean=49.975 global_offsets=(100, 1, 2, 1) mean=109.139 local_offsets=(100, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 4) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 4) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚      2,368 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 4) â”‚      2,308 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 4) â”‚      2,164 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 4) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 4) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 4) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 4) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 4) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 4)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 78, 78, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 68, 68, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 68, 68,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 68,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 68, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 4) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 4) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 4) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,336,854 (8.91 MB)
 Trainable params: 2,336,854 (8.91 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-02 11:44:40.589353: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-02 11:44:40.589364: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
I0000 00:00:1754160280.589383  332632 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1754160280.604136  332632 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-02 11:44:40.604216: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1754160280.604920  332632 cupti_tracer.cc:1249] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 68
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 2
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 500
nepochs: 2
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: test_prep_quick/gs2_hybrid/trained_model
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.005-0.010j
  std: 0.782
  min: -2.681-0.479j
  max: 2.700-0.360j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: test_prep_quick/gs2_hybrid/test_data.npz
train_data_file_path: test_prep_quick/gs2_hybrid/train_data.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/2
input shape (None, 64, 64, 1)
2025-08-02 11:44:41,781 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-02 11:44:43,653 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-02 11:44:47.468765: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-02 11:44:47.583876: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-02 11:44:47.602160: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-02 11:44:47.768463: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m 1/30[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3:27[0m 7s/step - intensity_scaler_inv_loss: 107.3142 - loss: -2976240.5000 - pred_intensity_loss: -2976240.5000 - trimmed_obj_loss: 0.0000e+00[1m 4/30[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 175.9271 - loss: -2845873.7500 - pred_intensity_loss: -2845873.7500 - trimmed_obj_loss: 0.0000e+00[1m 8/30[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 160.5750 - loss: -2873395.7500 - pred_intensity_loss: -2873395.7500 - trimmed_obj_loss: 0.0000e+00[1m12/30[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 150.2886 - loss: -2880074.7500 - pred_intensity_loss: -2880074.7500 - trimmed_obj_loss: 0.0000e+00[1m16/30[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 142.6861 - loss: -2885045.2500 - pred_intensity_loss: -2885045.2500 - trimmed_obj_loss: 0.0000e+00[1m20/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 136.9034 - loss: -2887023.7500 - pred_intensity_loss: -2887023.7500 - trimmed_obj_loss: 0.0000e+00[1m24/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 132.5481 - loss: -2889524.7500 - pred_intensity_loss: -2889524.7500 - trimmed_obj_loss: 0.0000e+00[1m28/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 129.1389 - loss: -2892342.5000 - pred_intensity_loss: -2892342.5000 - trimmed_obj_loss: 0.0000e+002025-08-02 11:44:50.600153: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-02 11:44:50.601049: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-02 11:44:50.626957: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-02 11:44:50.963322: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m30/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 108ms/step - intensity_scaler_inv_loss: 127.6788 - loss: -2894149.7500 - pred_intensity_loss: -2894237.7500 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-02 11:44:51,992 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m30/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m12s[0m 159ms/step - intensity_scaler_inv_loss: 107.1048 - loss: -2922452.0000 - pred_intensity_loss: -2925088.7500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 95.3353 - val_loss: -2973583.7500 - val_pred_intensity_loss: -2968497.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/2
[1m 1/30[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 43ms/step - intensity_scaler_inv_loss: 92.8675 - loss: -2809550.0000 - pred_intensity_loss: -2809550.0000 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 95.5999 - loss: -2917514.0000 - pred_intensity_loss: -2917514.0000 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 96.0019 - loss: -2936403.5000 - pred_intensity_loss: -2936403.5000 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 95.6581 - loss: -2937923.5000 - pred_intensity_loss: -2937923.5000 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 95.4172 - loss: -2939366.7500 - pred_intensity_loss: -2939366.7500 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 95.2491 - loss: -2939071.2500 - pred_intensity_loss: -2939071.2500 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 95.0626 - loss: -2938223.7500 - pred_intensity_loss: -2938223.7500 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 94.9318 - loss: -2937994.0000 - pred_intensity_loss: -2937994.0000 - trimmed_obj_loss: 0.0000e+00[1m30/30[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 17ms/step - intensity_scaler_inv_loss: 94.3307 - loss: -2944568.2500 - pred_intensity_loss: -2946819.2500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 94.2775 - val_loss: -2974459.0000 - val_pred_intensity_loss: -2969356.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
DEBUG: Setting probe to tf.Tensor(
[[[ 2.5769069e-09-8.8118152e-10j]
  [-2.7000304e-09-3.5604175e-10j]
  [ 2.7232085e-09+3.2656072e-11j]
  ...
  [-9.9190767e-10+2.5363456e-09j]
  [ 2.7232085e-09+3.2656072e-11j]
  [-2.7000304e-09-3.5604175e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 ...

 [[-9.9190767e-10+2.5363456e-09j]
  [-5.7877803e-10+2.6611926e-09j]
  [ 1.1697352e-09-2.4594005e-09j]
  ...
  [-2.6417395e-09-6.6192318e-10j]
  [ 1.1697352e-09-2.4594005e-09j]
  [-5.7877803e-10+2.6611926e-09j]]

 [[ 2.7232085e-09+3.2656072e-11j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.7231155e-09-3.9657562e-11j]
  ...
  [ 1.1697352e-09-2.4594005e-09j]
  [ 2.7231155e-09-3.9657562e-11j]
  [-2.6638698e-09+5.6632898e-10j]]

 [[-2.7000304e-09-3.5604175e-10j]
  [ 2.5484332e-09-9.6042641e-10j]
  [-2.6638698e-09+5.6632898e-10j]
  ...
  [-5.7877803e-10+2.6611926e-09j]
  [-2.6638698e-09+5.6632898e-10j]
  [ 2.5484332e-09-9.6042641e-10j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (128, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 1s/stepinput shape (None, 64, 64, 1)
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 431ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 436ms/step
Object stitching failed: unsupported operand type(s) for /: 'NoneType' and 'int'
Object stitching failed: unsupported operand type(s) for /: 'NoneType' and 'int'
2025-08-02 11:44:56,013 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-02 11:44:57,176 - INFO - Outputs saved to test_prep_quick/gs2_hybrid/trained_model
