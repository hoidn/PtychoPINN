Files Requiring Updates:
  - Location: "PtychoDataContainer.py"
    Reason for modification: "Adapting the data structure to handle multiple probe tensors instead of a single global tensor."
    Key changes needed: 
      - "Modify the PtychoDataContainer class to manage a list of probe tensors."
      - "Add an attribute for probe indices to map each sample to a specific probe tensor."
    Dependencies affected: 
      - "Any module or function that instantiates or utilizes PtychoDataContainer will need updates to handle the new structure."
  - Location: "model_training.py"
    Reason for modification: "To update the training process to handle multiple datasets with associated probe tensors."
    Key changes needed:
      - "Update the data loading and batching logic to interleave samples from multiple datasets during training."
      - "Adjust the data feeding to the model to select the correct probe tensor based on per-sample probe indices."
    Dependencies affected: 
      - "Depends on the revised PtychoDataContainer."
      - "Model input functions and possibly loss functions or metrics that might utilize probe data."
  - Location: "model_testing.py"
    Reason for modification: "Ensure that test set handling incorporates the usage of multiple probes correctly without shuffling."
    Key changes needed:
      - "Modify how the test data sets are loaded and kept separate to ensure they use the correct probe without shuffling."
    Dependencies affected:
      - "Depends on modifications in PtychoDataContainer for correct probe indexing."
      - "Data handling and preparation logic specific to testing scenarios."

Architectural Impact Assessment:
  - "The proposed changes require significant adjustments in data handling both at the level of data container and training/testing process. Moving from a singular to multiple probes impacts how data is accessed and utilized throughout the model's lifecycle."
  - "The storage and computational overhead might increase due to handling multiple probes, especially if they are large or the number of samples is significant."
  - "Interleaving multiple datasets could introduce additional complexity in managing batch size and data uniformity across different training epochs."

Questions for Clarification:
  - "Should there be limits on the number of different probes that can be handled in one training instance or is this bound only by memory constraints?"
  - "Is there any specific performance metric or constraint that we need to target or maintain post these architectural changes?"
  - "How should error handling be dealt for cases when a probe index does not exist or is incorrectly mapped?"