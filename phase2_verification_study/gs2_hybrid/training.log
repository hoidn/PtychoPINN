2025-08-06 23:07:26.784500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754546846.796350  641833 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754546846.799857  641833 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754546846.810822  641833 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546846.810837  641833 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546846.810839  641833 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546846.810841  641833 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-06 23:07:26.813772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-06 23:07:29,151 - INFO - Configuration setup complete
2025-08-06 23:07:29,151 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0, use_batched_patch_extraction=True, patch_extraction_batch_size=256), train_data_file=PosixPath('phase2_verification_study/gs2_hybrid/train_data.npz'), test_data_file=PosixPath('phase2_verification_study/gs2_hybrid/test_data.npz'), batch_size=16, nepochs=2, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=500, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('phase2_verification_study/gs2_hybrid/trained_model'))
2025-08-06 23:07:29,151 - INFO - Parameter interpretation: --n-images=500 refers to neighbor groups (gridsize=2, total patterns=2000)
2025-08-06 23:07:29,151 - INFO - Starting training with n_images=500, stitching=disabled
2025-08-06 23:07:29,151 - INFO - Loading data from phase2_verification_study/gs2_hybrid/train_data.npz with n_images=500
2025-08-06 23:07:29,393 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-06 23:07:29,393 - INFO - Loading data from phase2_verification_study/gs2_hybrid/test_data.npz with n_images=None
2025-08-06 23:07:29,444 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-06 23:07:29,444 - INFO - Loaded test data from phase2_verification_study/gs2_hybrid/test_data.npz
2025-08-06 23:07:29,445 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-06 23:07:29,445 - INFO - Efficiently sampling 500 groups for gridsize=2
2025-08-06 23:07:29,453 - INFO - Efficiently generated 500 groups without O(N²) computation
2025-08-06 23:07:29,453 - INFO - Selected 500 groups for training
2025-08-06 23:07:29,459 - INFO - Using pre-computed 'Y' array from the input file.
I0000 00:00:1754546849.624773  641833 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1754546849.626009  641833 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21626 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(500, 64, 64, 4) Y_I=(500, 64, 64, 4) Y_phi=(500, 64, 64, 4) norm_Y_I=() coords_nominal=(500, 1, 2, 4) coords_true=(500, 1, 2, 4) nn_indices=(500, 4) mean=980.250 global_offsets=(500, 1, 2, 1) mean=110.597 local_offsets=(500, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.092>
2025-08-06 23:07:30,197 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-06 23:07:30,197 - WARNING - Requested 500 groups but only 400 points available. Using 400.
2025-08-06 23:07:30,198 - INFO - Efficiently sampling 400 groups for gridsize=2
2025-08-06 23:07:30,203 - INFO - Efficiently generated 400 groups without O(N²) computation
2025-08-06 23:07:30,204 - INFO - Selected 400 groups for training
2025-08-06 23:07:30,206 - INFO - Using pre-computed 'Y' array from the input file.
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(400, 64, 64, 4) Y_I=(400, 64, 64, 4) Y_phi=(400, 64, 64, 4) norm_Y_I=() coords_nominal=(400, 1, 2, 4) coords_true=(400, 1, 2, 4) nn_indices=(400, 4) mean=200.037 global_offsets=(400, 1, 2, 1) mean=114.329 local_offsets=(400, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input (InputLayer)  │ (None, 64, 64, 4) │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler    │ (None, 64, 64, 4) │          0 │ input[0][0]       │
│ (IntensityScaler)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 64, 64,    │      2,368 │ intensity_scaler… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 64, 64,    │     36,928 │ conv2d[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d       │ (None, 32, 32,    │          0 │ conv2d_1[0][0]    │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 32, 32,    │     73,856 │ max_pooling2d[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 32, 32,    │    147,584 │ conv2d_2[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 16, 16,    │          0 │ conv2d_3[0][0]    │
│ (MaxPooling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 16, 16,    │    295,168 │ max_pooling2d_1[… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 16, 16,    │    590,080 │ conv2d_4[0][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_2     │ (None, 8, 8, 256) │          0 │ conv2d_5[0][0]    │
│ (MaxPooling2D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 8, 8, 128) │    147,584 │ conv2d_8[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ conv2d_16[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d       │ (None, 16, 16,    │          0 │ conv2d_9[0][0]    │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_3     │ (None, 16, 16,    │          0 │ conv2d_17[0][0]   │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d_3[… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_10[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_18[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_1     │ (None, 32, 32,    │          0 │ conv2d_11[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_4     │ (None, 32, 32,    │          0 │ conv2d_19[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_1          │ (None, 32, 32, 4) │          0 │ up_sampling2d_1[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_3          │ (None, 32, 32, 4) │          0 │ up_sampling2d_4[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_1[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_20 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_3[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_12[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_21 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_20[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_2     │ (None, 64, 64,    │          0 │ conv2d_13[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_5     │ (None, 64, 64,    │          0 │ conv2d_21[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item (GetItem)  │ (None, 32, 32,    │          0 │ up_sampling2d_1[… │
│                     │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 64, 64, 1) │        577 │ up_sampling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_2          │ (None, 32, 32,    │          0 │ up_sampling2d_4[… │
│ (GetItem)           │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 64, 64, 4) │      2,308 │ up_sampling2d_5[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 32, 32, 1) │        541 │ get_item[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu (Silu)         │ (None, 64, 64, 1) │          0 │ conv2d_7[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 32, 32, 4) │      2,164 │ get_item_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu_1 (Silu)       │ (None, 64, 64, 4) │          0 │ conv2d_15[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp                 │ (None, 32, 32, 1) │          0 │ conv2d_6[0][0]    │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer   │ (None, 64, 64, 1) │          0 │ silu[0][0]        │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phi                 │ (None, 32, 32, 4) │          0 │ conv2d_14[0][0]   │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer_1 │ (None, 64, 64, 1) │          0 │ silu_1[0][0]      │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp_padded          │ (None, 64, 64, 1) │          0 │ amp[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 64, 64, 1) │          0 │ silu[0][0],       │
│                     │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phase_padded        │ (None, 64, 64, 4) │          0 │ phi[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 64, 64, 4) │          0 │ silu_1[0][0],     │
│ (Multiply)          │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add (Add)           │ (None, 64, 64, 1) │          0 │ amp_padded[0][0], │
│                     │                   │            │ multiply[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_1 (Add)         │ (None, 64, 64, 4) │          0 │ phase_padded[0][… │
│                     │                   │            │ multiply_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ obj                 │ (None, 64, 64, 1) │          0 │ add[0][0],        │
│ (CombineComplexLay… │                   │            │ add_1[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_positions     │ (None, 1, 2, 4)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_obj_2        │ (None, 78, 78, 1) │          0 │ obj[0][0],        │
│ (ReassemblePatches… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_objs_with_o… │ (None, 68, 68, 1) │          0 │ padded_obj_2[0][… │
│ (ExtractPatchesPos… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ probe_illumination  │ [(None, 68, 68,   │          0 │ padded_objs_with… │
│ (ProbeIllumination) │ 1), (None, 68,    │            │                   │
│                     │ 68, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_amplitude      │ [(None, 64, 64,   │          0 │ probe_illuminati… │
│ (PadAndDiffractLay… │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_diff_channels  │ (None, 64, 64, 4) │          0 │ pred_amplitude[0… │
│ (FlatToChannelLaye… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler_i… │ (None, 64, 64, 4) │          0 │ pred_diff_channe… │
│ (IntensityScaler_i… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ trimmed_obj         │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (TrimReconstructio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_intensity      │ (None, 64, 64, 4) │          0 │ intensity_scaler… │
│ (SquareLayer)       │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,336,854 (8.91 MB)
 Trainable params: 2,336,854 (8.91 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-06 23:07:31.020968: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-06 23:07:31.020977: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754546851.020992  641833 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1754546851.034898  641833 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-06 23:07:31.034975: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1754546851.035043  641833 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1754546851.728934  641833 service.cc:152] XLA service 0x265fc270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1754546851.728962  641833 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-06 23:07:31.739598: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1754546851.757069  641833 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1754546852.326194  641833 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 68
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 2
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 500
nepochs: 2
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: phase2_verification_study/gs2_hybrid/trained_model
pad_object: True
patch_extraction_batch_size: 256
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.004-0.007j
  std: 0.782
  min: -2.723-0.064j
  max: 2.723-0.030j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: phase2_verification_study/gs2_hybrid/test_data.npz
train_data_file_path: phase2_verification_study/gs2_hybrid/train_data.npz
tv_weight: 0.0
use_batched_patch_extraction: True
use_xla_translate: True
Epoch 1/2
input shape (None, 64, 64, 1)
2025-08-06 23:07:32,885 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-06 23:07:34,800 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-06 23:07:38.595611: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:07:38.635038: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:07:38.670725: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:07:39.015695: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:31[0m 7s/step - intensity_scaler_inv_loss: 330.7464 - loss: -2233139.0000 - pred_intensity_loss: -2233139.0000 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 352.4748 - loss: -2198565.0000 - pred_intensity_loss: -2198565.0000 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 356.1901 - loss: -2219048.2500 - pred_intensity_loss: -2219048.2500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 359.5243 - loss: -2251174.5000 - pred_intensity_loss: -2251174.5000 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 360.9489 - loss: -2276537.0000 - pred_intensity_loss: -2276537.0000 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 361.0160 - loss: -2293701.5000 - pred_intensity_loss: -2293701.5000 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 360.2425 - loss: -2309024.7500 - pred_intensity_loss: -2309024.7500 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 359.2622 - loss: -2323682.2500 - pred_intensity_loss: -2323682.2500 - trimmed_obj_loss: 0.0000e+002025-08-06 23:07:41.857719: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:07:41.872520: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:07:41.916665: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:07:42.093847: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 104ms/step - intensity_scaler_inv_loss: 359.0042 - loss: -2326796.0000 - pred_intensity_loss: -2326765.5000 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-06 23:07:43,122 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m12s[0m 156ms/step - intensity_scaler_inv_loss: 351.5246 - loss: -2417098.2500 - pred_intensity_loss: -2416185.0000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 298.8748 - val_loss: -2520450.5000 - val_pred_intensity_loss: -2481609.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/2
[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 41ms/step - intensity_scaler_inv_loss: 298.7478 - loss: -2433359.7500 - pred_intensity_loss: -2433359.7500 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 319.3369 - loss: -2465010.2500 - pred_intensity_loss: -2465010.2500 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 323.4124 - loss: -2492679.2500 - pred_intensity_loss: -2492679.2500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 325.3595 - loss: -2500404.5000 - pred_intensity_loss: -2500404.5000 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 325.8351 - loss: -2508147.7500 - pred_intensity_loss: -2508147.7500 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 326.2324 - loss: -2516976.2500 - pred_intensity_loss: -2516976.2500 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 326.4632 - loss: -2526904.2500 - pred_intensity_loss: -2526904.2500 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 326.4831 - loss: -2538255.7500 - pred_intensity_loss: -2538255.7500 - trimmed_obj_loss: 0.0000e+00[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 17ms/step - intensity_scaler_inv_loss: 326.0724 - loss: -2622674.7500 - pred_intensity_loss: -2624479.2500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 321.7759 - val_loss: -2728052.2500 - val_pred_intensity_loss: -2684258.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (128, 64, 64, 1)
[1m 1/13[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m12s[0m 1s/step[1m11/13[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 5ms/stepinput shape (None, 64, 64, 1)
[1m13/13[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 45ms/step[1m13/13[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 46ms/step
Object stitching failed: cannot reshape array of size 1638400 into shape (11,11,64,64,1)
Object stitching failed: cannot reshape array of size 1638400 into shape (11,11,64,64,1)
2025-08-06 23:07:46,499 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-06 23:07:47,926 - INFO - Outputs saved to phase2_verification_study/gs2_hybrid/trained_model
