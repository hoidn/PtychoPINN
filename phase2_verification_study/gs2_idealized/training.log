2025-08-06 23:08:02.592678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754546882.604298  643526 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754546882.607710  643526 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754546882.618341  643526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546882.618353  643526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546882.618355  643526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546882.618357  643526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-06 23:08:02.621197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-06 23:08:04,981 - INFO - Configuration setup complete
2025-08-06 23:08:04,981 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0, use_batched_patch_extraction=True, patch_extraction_batch_size=256), train_data_file=PosixPath('phase2_verification_study/gs2_idealized/train_data.npz'), test_data_file=PosixPath('phase2_verification_study/gs2_idealized/test_data.npz'), batch_size=16, nepochs=2, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=500, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('phase2_verification_study/gs2_idealized/trained_model'))
2025-08-06 23:08:04,981 - INFO - Parameter interpretation: --n-images=500 refers to neighbor groups (gridsize=2, total patterns=2000)
2025-08-06 23:08:04,981 - INFO - Starting training with n_images=500, stitching=disabled
2025-08-06 23:08:04,981 - INFO - Loading data from phase2_verification_study/gs2_idealized/train_data.npz with n_images=500
2025-08-06 23:08:05,200 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-06 23:08:05,200 - INFO - Loading data from phase2_verification_study/gs2_idealized/test_data.npz with n_images=None
2025-08-06 23:08:05,246 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
2025-08-06 23:08:05,247 - INFO - Loaded test data from phase2_verification_study/gs2_idealized/test_data.npz
2025-08-06 23:08:05,247 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-06 23:08:05,247 - INFO - Efficiently sampling 500 groups for gridsize=2
2025-08-06 23:08:05,256 - INFO - Efficiently generated 500 groups without O(N²) computation
2025-08-06 23:08:05,256 - INFO - Selected 500 groups for training
2025-08-06 23:08:05,261 - INFO - Using pre-computed 'Y' array from the input file.
I0000 00:00:1754546885.425369  643526 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1754546885.426605  643526 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21626 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(500, 64, 64, 4) Y_I=(500, 64, 64, 4) Y_phi=(500, 64, 64, 4) norm_Y_I=() coords_nominal=(500, 1, 2, 4) coords_true=(500, 1, 2, 4) nn_indices=(500, 4) mean=1009.434 global_offsets=(500, 1, 2, 1) mean=110.897 local_offsets=(500, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
2025-08-06 23:08:06,018 - INFO - Using grouping-aware subsampling strategy for gridsize=2
2025-08-06 23:08:06,018 - WARNING - Requested 500 groups but only 400 points available. Using 400.
2025-08-06 23:08:06,018 - INFO - Efficiently sampling 400 groups for gridsize=2
2025-08-06 23:08:06,024 - INFO - Efficiently generated 400 groups without O(N²) computation
2025-08-06 23:08:06,024 - INFO - Selected 400 groups for training
2025-08-06 23:08:06,027 - INFO - Using pre-computed 'Y' array from the input file.
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(400, 64, 64, 4) Y_I=(400, 64, 64, 4) Y_phi=(400, 64, 64, 4) norm_Y_I=() coords_nominal=(400, 1, 2, 4) coords_true=(400, 1, 2, 4) nn_indices=(400, 4) mean=200.037 global_offsets=(400, 1, 2, 1) mean=114.329 local_offsets=(400, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input (InputLayer)  │ (None, 64, 64, 4) │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler    │ (None, 64, 64, 4) │          0 │ input[0][0]       │
│ (IntensityScaler)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 64, 64,    │      2,368 │ intensity_scaler… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 64, 64,    │     36,928 │ conv2d[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d       │ (None, 32, 32,    │          0 │ conv2d_1[0][0]    │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 32, 32,    │     73,856 │ max_pooling2d[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 32, 32,    │    147,584 │ conv2d_2[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 16, 16,    │          0 │ conv2d_3[0][0]    │
│ (MaxPooling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 16, 16,    │    295,168 │ max_pooling2d_1[… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 16, 16,    │    590,080 │ conv2d_4[0][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_2     │ (None, 8, 8, 256) │          0 │ conv2d_5[0][0]    │
│ (MaxPooling2D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 8, 8, 128) │    147,584 │ conv2d_8[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ conv2d_16[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d       │ (None, 16, 16,    │          0 │ conv2d_9[0][0]    │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_3     │ (None, 16, 16,    │          0 │ conv2d_17[0][0]   │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d_3[… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_10[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_18[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_1     │ (None, 32, 32,    │          0 │ conv2d_11[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_4     │ (None, 32, 32,    │          0 │ conv2d_19[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_1          │ (None, 32, 32, 4) │          0 │ up_sampling2d_1[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_3          │ (None, 32, 32, 4) │          0 │ up_sampling2d_4[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_1[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_20 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_3[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_12[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_21 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_20[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_2     │ (None, 64, 64,    │          0 │ conv2d_13[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_5     │ (None, 64, 64,    │          0 │ conv2d_21[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item (GetItem)  │ (None, 32, 32,    │          0 │ up_sampling2d_1[… │
│                     │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 64, 64, 1) │        577 │ up_sampling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_2          │ (None, 32, 32,    │          0 │ up_sampling2d_4[… │
│ (GetItem)           │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 64, 64, 4) │      2,308 │ up_sampling2d_5[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 32, 32, 1) │        541 │ get_item[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu (Silu)         │ (None, 64, 64, 1) │          0 │ conv2d_7[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 32, 32, 4) │      2,164 │ get_item_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu_1 (Silu)       │ (None, 64, 64, 4) │          0 │ conv2d_15[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp                 │ (None, 32, 32, 1) │          0 │ conv2d_6[0][0]    │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer   │ (None, 64, 64, 1) │          0 │ silu[0][0]        │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phi                 │ (None, 32, 32, 4) │          0 │ conv2d_14[0][0]   │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer_1 │ (None, 64, 64, 1) │          0 │ silu_1[0][0]      │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp_padded          │ (None, 64, 64, 1) │          0 │ amp[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 64, 64, 1) │          0 │ silu[0][0],       │
│                     │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phase_padded        │ (None, 64, 64, 4) │          0 │ phi[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 64, 64, 4) │          0 │ silu_1[0][0],     │
│ (Multiply)          │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add (Add)           │ (None, 64, 64, 1) │          0 │ amp_padded[0][0], │
│                     │                   │            │ multiply[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_1 (Add)         │ (None, 64, 64, 4) │          0 │ phase_padded[0][… │
│                     │                   │            │ multiply_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ obj                 │ (None, 64, 64, 1) │          0 │ add[0][0],        │
│ (CombineComplexLay… │                   │            │ add_1[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_positions     │ (None, 1, 2, 4)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_obj_2        │ (None, 78, 78, 1) │          0 │ obj[0][0],        │
│ (ReassemblePatches… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_objs_with_o… │ (None, 68, 68, 1) │          0 │ padded_obj_2[0][… │
│ (ExtractPatchesPos… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ probe_illumination  │ [(None, 68, 68,   │          0 │ padded_objs_with… │
│ (ProbeIllumination) │ 1), (None, 68,    │            │                   │
│                     │ 68, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_amplitude      │ [(None, 64, 64,   │          0 │ probe_illuminati… │
│ (PadAndDiffractLay… │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_diff_channels  │ (None, 64, 64, 4) │          0 │ pred_amplitude[0… │
│ (FlatToChannelLaye… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler_i… │ (None, 64, 64, 4) │          0 │ pred_diff_channe… │
│ (IntensityScaler_i… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ trimmed_obj         │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (TrimReconstructio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_intensity      │ (None, 64, 64, 4) │          0 │ intensity_scaler… │
│ (SquareLayer)       │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,336,854 (8.91 MB)
 Trainable params: 2,336,854 (8.91 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-06 23:08:06.838452: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-06 23:08:06.838462: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754546886.838478  643526 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1754546886.852735  643526 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-06 23:08:06.852807: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1754546886.852877  643526 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1754546887.560155  643526 service.cc:152] XLA service 0x22a8fcb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1754546887.560178  643526 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-06 23:08:07.570765: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1754546887.588138  643526 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1754546888.169777  643526 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 68
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 2
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 500
nepochs: 2
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: phase2_verification_study/gs2_idealized/trained_model
pad_object: True
patch_extraction_batch_size: 256
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.250+0.000j
  std: 0.741
  min: 0.000+0.000j
  max: 2.723+0.000j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: phase2_verification_study/gs2_idealized/test_data.npz
train_data_file_path: phase2_verification_study/gs2_idealized/train_data.npz
tv_weight: 0.0
use_batched_patch_extraction: True
use_xla_translate: True
Epoch 1/2
input shape (None, 64, 64, 1)
2025-08-06 23:08:08,745 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-06 23:08:10,661 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-06 23:08:14.537114: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:08:14.552791: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:08:14.561803: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:08:14.778454: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:29[0m 7s/step - intensity_scaler_inv_loss: 140.7242 - loss: -407350.9062 - pred_intensity_loss: -407350.9062 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 155.4309 - loss: -747492.6250 - pred_intensity_loss: -747492.6250 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 166.3414 - loss: -1075499.7500 - pred_intensity_loss: -1075499.7500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 175.0261 - loss: -1309390.2500 - pred_intensity_loss: -1309390.2500 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 185.9116 - loss: -1491506.3750 - pred_intensity_loss: -1491506.3750 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 196.4279 - loss: -1629914.1250 - pred_intensity_loss: -1629914.1250 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 205.6936 - loss: -1742777.6250 - pred_intensity_loss: -1742777.6250 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 213.5788 - loss: -1842430.5000 - pred_intensity_loss: -1842430.5000 - trimmed_obj_loss: 0.0000e+002025-08-06 23:08:17.597230: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:08:17.612625: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 164 bytes spill stores, 164 bytes spill loads

2025-08-06 23:08:17.636231: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:08:17.967218: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3648 bytes spill stores, 3648 bytes spill loads

[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 107ms/step - intensity_scaler_inv_loss: 215.3557 - loss: -1865257.8750 - pred_intensity_loss: -1865598.1250 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-06 23:08:18,995 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
