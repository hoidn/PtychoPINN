2025-08-06 23:06:19.838136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1754546779.849643  638456 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1754546779.853159  638456 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1754546779.863968  638456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546779.863984  638456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546779.863986  638456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1754546779.863988  638456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-06 23:06:19.867106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-06 23:06:22,208 - INFO - Configuration setup complete
2025-08-06 23:06:22,208 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0, use_batched_patch_extraction=True, patch_extraction_batch_size=256), train_data_file=PosixPath('phase2_verification_study/gs1_hybrid/train_data.npz'), test_data_file=PosixPath('phase2_verification_study/gs1_hybrid/test_data.npz'), batch_size=16, nepochs=2, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=500, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('phase2_verification_study/gs1_hybrid/trained_model'))
2025-08-06 23:06:22,208 - INFO - Parameter interpretation: --n-images=500 refers to individual images (gridsize=1)
2025-08-06 23:06:22,208 - INFO - Starting training with n_images=500, stitching=disabled
2025-08-06 23:06:22,208 - INFO - Loading data from phase2_verification_study/gs1_hybrid/train_data.npz with n_images=500
2025-08-06 23:06:22,272 - INFO - Using sequential slicing for gridsize=1: selecting first 500 images
2025-08-06 23:06:22,272 - INFO - Loading data from phase2_verification_study/gs1_hybrid/test_data.npz with n_images=None
2025-08-06 23:06:22,287 - INFO - Using sequential slicing for gridsize=1: selecting first 100 images
2025-08-06 23:06:22,287 - INFO - Loaded test data from phase2_verification_study/gs1_hybrid/test_data.npz
I0000 00:00:1754546782.428559  638456 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1754546782.429910  638456 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21626 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (500, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(500, 64, 64, 1) Y_I=(500, 64, 64, 1) Y_phi=(500, 64, 64, 1) norm_Y_I=() coords_nominal=(500, 1, 2, 1) coords_true=(500, 1, 2, 1) nn_indices=(500, 1) mean=249.500 global_offsets=(500, 1, 2, 1) mean=110.441 local_offsets=(500, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (100, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(100, 64, 64, 1) Y_I=(100, 64, 64, 1) Y_phi=(100, 64, 64, 1) norm_Y_I=() coords_nominal=(100, 1, 2, 1) coords_true=(100, 1, 2, 1) nn_indices=(100, 1) mean=49.500 global_offsets=(100, 1, 2, 1) mean=114.415 local_offsets=(100, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.092>
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input (InputLayer)  │ (None, 64, 64, 1) │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler    │ (None, 64, 64, 1) │          0 │ input[0][0]       │
│ (IntensityScaler)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 64, 64,    │        640 │ intensity_scaler… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 64, 64,    │     36,928 │ conv2d[0][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d       │ (None, 32, 32,    │          0 │ conv2d_1[0][0]    │
│ (MaxPooling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 32, 32,    │     73,856 │ max_pooling2d[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 32, 32,    │    147,584 │ conv2d_2[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_1     │ (None, 16, 16,    │          0 │ conv2d_3[0][0]    │
│ (MaxPooling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 16, 16,    │    295,168 │ max_pooling2d_1[… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 16, 16,    │    590,080 │ conv2d_4[0][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling2d_2     │ (None, 8, 8, 256) │          0 │ conv2d_5[0][0]    │
│ (MaxPooling2D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 8, 8, 128) │    295,040 │ max_pooling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 8, 8, 128) │    147,584 │ conv2d_8[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ conv2d_16[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d       │ (None, 16, 16,    │          0 │ conv2d_9[0][0]    │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_3     │ (None, 16, 16,    │          0 │ conv2d_17[0][0]   │
│ (UpSampling2D)      │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 16, 16,    │     73,792 │ up_sampling2d_3[… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_10[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 16, 16,    │     36,928 │ conv2d_18[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_1     │ (None, 32, 32,    │          0 │ conv2d_11[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_4     │ (None, 32, 32,    │          0 │ conv2d_19[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_1          │ (None, 32, 32, 4) │          0 │ up_sampling2d_1[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_3          │ (None, 32, 32, 4) │          0 │ up_sampling2d_4[… │
│ (GetItem)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_1[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_20 (Conv2D)  │ (None, 32, 32,    │      2,368 │ get_item_3[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_12[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_21 (Conv2D)  │ (None, 32, 32,    │     36,928 │ conv2d_20[0][0]   │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_2     │ (None, 64, 64,    │          0 │ conv2d_13[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ up_sampling2d_5     │ (None, 64, 64,    │          0 │ conv2d_21[0][0]   │
│ (UpSampling2D)      │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item (GetItem)  │ (None, 32, 32,    │          0 │ up_sampling2d_1[… │
│                     │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 64, 64, 1) │        577 │ up_sampling2d_2[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ get_item_2          │ (None, 32, 32,    │          0 │ up_sampling2d_4[… │
│ (GetItem)           │ 60)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 64, 64, 1) │        577 │ up_sampling2d_5[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 32, 32, 1) │        541 │ get_item[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu (Silu)         │ (None, 64, 64, 1) │          0 │ conv2d_7[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 32, 32, 1) │        541 │ get_item_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ silu_1 (Silu)       │ (None, 64, 64, 1) │          0 │ conv2d_15[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp                 │ (None, 32, 32, 1) │          0 │ conv2d_6[0][0]    │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer   │ (None, 64, 64, 1) │          0 │ silu[0][0]        │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phi                 │ (None, 32, 32, 1) │          0 │ conv2d_14[0][0]   │
│ (ActivationLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ center_mask_layer_1 │ (None, 64, 64, 1) │          0 │ silu_1[0][0]      │
│ (CenterMaskLayer)   │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ amp_padded          │ (None, 64, 64, 1) │          0 │ amp[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply (Multiply) │ (None, 64, 64, 1) │          0 │ silu[0][0],       │
│                     │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ phase_padded        │ (None, 64, 64, 1) │          0 │ phi[0][0]         │
│ (ZeroPadding2D)     │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ multiply_1          │ (None, 64, 64, 1) │          0 │ silu_1[0][0],     │
│ (Multiply)          │                   │            │ center_mask_laye… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add (Add)           │ (None, 64, 64, 1) │          0 │ amp_padded[0][0], │
│                     │                   │            │ multiply[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_1 (Add)         │ (None, 64, 64, 1) │          0 │ phase_padded[0][… │
│                     │                   │            │ multiply_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ obj                 │ (None, 64, 64, 1) │          0 │ add[0][0],        │
│ (CombineComplexLay… │                   │            │ add_1[0][0]       │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input_positions     │ (None, 1, 2, 1)   │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_obj_2        │ (None, 74, 74, 1) │          0 │ obj[0][0],        │
│ (ReassemblePatches… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ padded_objs_with_o… │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (ExtractPatchesPos… │                   │            │ input_positions[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ probe_illumination  │ [(None, 64, 64,   │          0 │ padded_objs_with… │
│ (ProbeIllumination) │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_amplitude      │ [(None, 64, 64,   │          0 │ probe_illuminati… │
│ (PadAndDiffractLay… │ 1), (None, 64,    │            │                   │
│                     │ 64, 1)]           │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_diff_channels  │ (None, 64, 64, 1) │          0 │ pred_amplitude[0… │
│ (FlatToChannelLaye… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ intensity_scaler_i… │ (None, 64, 64, 1) │          0 │ pred_diff_channe… │
│ (IntensityScaler_i… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ trimmed_obj         │ (None, 64, 64, 1) │          0 │ padded_obj_2[0][… │
│ (TrimReconstructio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ pred_intensity      │ (None, 64, 64, 1) │          0 │ intensity_scaler… │
│ (SquareLayer)       │                   │            │                   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-06 23:06:23.547076: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-06 23:06:23.547086: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1754546783.547100  638456 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1754546783.561503  638456 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-06 23:06:23.561589: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1754546783.561717  638456 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1754546784.253556  638456 service.cc:152] XLA service 0x12e48920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1754546784.253583  638456 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-06 23:06:24.265644: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1754546784.283796  638456 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1754546784.872372  638456 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 500
nepochs: 2
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: phase2_verification_study/gs1_hybrid/trained_model
pad_object: True
patch_extraction_batch_size: 256
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.004-0.007j
  std: 0.782
  min: -2.723-0.064j
  max: 2.723-0.030j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: phase2_verification_study/gs1_hybrid/test_data.npz
train_data_file_path: phase2_verification_study/gs1_hybrid/train_data.npz
tv_weight: 0.0
use_batched_patch_extraction: True
use_xla_translate: True
Epoch 1/2
input shape (None, 64, 64, 1)
2025-08-06 23:06:25,398 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-06 23:06:27,280 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-06 23:06:30.907577: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-06 23:06:30.938960: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:06:30.968180: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-06 23:06:31.180063: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m3:19[0m 7s/step - intensity_scaler_inv_loss: 73.4727 - loss: -3125663.5000 - pred_intensity_loss: -3125663.5000 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 122.7797 - loss: -2948542.0000 - pred_intensity_loss: -2948542.0000 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 108.1307 - loss: -2938347.7500 - pred_intensity_loss: -2938347.7500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 98.8925 - loss: -2946087.0000 - pred_intensity_loss: -2946087.0000 - trimmed_obj_loss: 0.0000e+00 [1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 92.1432 - loss: -2959950.5000 - pred_intensity_loss: -2959950.5000 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 86.6505 - loss: -2972467.2500 - pred_intensity_loss: -2972467.2500 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 82.1354 - loss: -2985419.0000 - pred_intensity_loss: -2985419.0000 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 78.4050 - loss: -2997152.7500 - pred_intensity_loss: -2997152.7500 - trimmed_obj_loss: 0.0000e+002025-08-06 23:06:33.587086: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-06 23:06:33.654963: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-06 23:06:33.666988: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-06 23:06:33.990540: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 94ms/step - intensity_scaler_inv_loss: 77.5699 - loss: -2999555.0000 - pred_intensity_loss: -2999445.2500 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-06 23:06:34,950 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m11s[0m 140ms/step - intensity_scaler_inv_loss: 53.3512 - loss: -3069222.7500 - pred_intensity_loss: -3065928.2500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 31.8103 - val_loss: -3086397.7500 - val_pred_intensity_loss: -3092261.5000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/2
[1m 1/30[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 27.5769 - loss: -2990695.0000 - pred_intensity_loss: -2990695.0000 - trimmed_obj_loss: 0.0000e+00[1m 5/30[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 31.9555 - loss: -3104942.7500 - pred_intensity_loss: -3104942.7500 - trimmed_obj_loss: 0.0000e+00[1m 9/30[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 32.5670 - loss: -3107719.7500 - pred_intensity_loss: -3107719.7500 - trimmed_obj_loss: 0.0000e+00[1m13/30[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 32.9780 - loss: -3118167.7500 - pred_intensity_loss: -3118167.7500 - trimmed_obj_loss: 0.0000e+00[1m17/30[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 33.2374 - loss: -3113921.0000 - pred_intensity_loss: -3113921.0000 - trimmed_obj_loss: 0.0000e+00[1m21/30[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 33.4351 - loss: -3109830.0000 - pred_intensity_loss: -3109830.0000 - trimmed_obj_loss: 0.0000e+00[1m25/30[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 33.5438 - loss: -3107641.2500 - pred_intensity_loss: -3107641.2500 - trimmed_obj_loss: 0.0000e+00[1m29/30[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 33.5704 - loss: -3105097.0000 - pred_intensity_loss: -3105097.0000 - trimmed_obj_loss: 0.0000e+00[1m30/30[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m1s[0m 16ms/step - intensity_scaler_inv_loss: 33.6387 - loss: -3086274.5000 - pred_intensity_loss: -3086387.0000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 32.1571 - val_loss: -3086051.5000 - val_pred_intensity_loss: -3091908.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
DEBUG: Setting probe to tf.Tensor(
[[[ 2.1582449e-09+1.6609965e-09j]
  [-1.3435764e-10+2.7200879e-09j]
  [-2.4460696e-09-1.1973609e-09j]
  ...
  [ 2.2215485e-09+1.5753262e-09j]
  [ 2.4909448e-09+1.1009652e-09j]
  [ 2.4990836e-09+1.0823638e-09j]]

 [[ 2.3984827e-09-1.2900429e-09j]
  [ 2.0489848e-09+1.7940435e-09j]
  [-1.7671616e-10+2.7176648e-09j]
  ...
  [-2.6006610e-09-8.0838908e-10j]
  [ 1.9989714e-09+1.8496062e-09j]
  [ 1.6206089e-09+2.1887343e-09j]]

 [[ 2.6201157e-09-7.4291551e-10j]
  [-2.6765694e-09+5.0289789e-10j]
  [-1.5219896e-09-2.2584239e-09j]
  ...
  [-1.5905454e-09+2.2106776e-09j]
  [-2.5539186e-09+9.4574293e-10j]
  [ 1.0931964e-09-2.4943640e-09j]]

 ...

 [[-2.3626279e-09-1.3545923e-09j]
  [ 2.7228064e-09+5.7053601e-11j]
  [-8.0837864e-10+2.6006641e-09j]
  ...
  [ 2.0918718e-09+1.7438473e-09j]
  [-2.4329199e-09+1.2238592e-09j]
  [-1.9271682e-09-1.9243058e-09j]]

 [[-6.1248823e-10-2.6536366e-09j]
  [-1.9286095e-09+1.9228612e-09j]
  [-8.1987722e-10+2.5970621e-09j]
  ...
  [ 1.1958804e-09+2.4467939e-09j]
  [-2.2008297e-09-1.6041442e-09j]
  [-3.7193551e-10-2.6978870e-09j]]

 [[ 1.9098230e-09+1.9415216e-09j]
  [-2.6714766e-09-5.2928578e-10j]
  [-2.7092886e-09-2.7692251e-10j]
  ...
  [-2.7166969e-09-1.9101724e-10j]
  [ 1.4765349e-09-2.2884001e-09j]
  [ 1.8434217e-09+2.0046762e-09j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m2s[0m 929ms/stepinput shape (None, 64, 64, 1)
[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 328ms/step[1m4/4[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 333ms/step
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
Object stitching failed: unsupported operand type(s) for /: 'NoneType' and 'int'
2025-08-06 23:06:38,367 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-06 23:06:39,761 - INFO - Outputs saved to phase2_verification_study/gs1_hybrid/trained_model
