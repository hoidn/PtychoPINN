[2025-07-27 21:06:42] === Starting Complete Generalization Study ===
[2025-07-27 21:06:42] Training sizes: 256 2048
[2025-07-27 21:06:42] Number of trials per size: 3
[2025-07-27 21:06:42] Output directory: 3way_bothhalves_full_2xtest
[2025-07-27 21:06:42] Total training runs planned: 12
[2025-07-27 21:06:42] Validating environment...
[2025-07-27 21:06:42] Environment validation passed
[2025-07-27 21:06:42] Configuration saved to: 3way_bothhalves_full_2xtest/study_config.txt
[2025-07-27 21:06:42] Skipping dataset preparation (--skip-data-prep)
[2025-07-27 21:06:42] === STEP 2: Model Training ===
[2025-07-27 21:06:42] Training models sequentially with 3 trials per training size
[2025-07-27 21:06:42] Starting training for train_size=256, test_size=512 (3 trials)
[2025-07-27 21:06:42] Training models for train_size=256, test_size=512 (Trial 1/3)
[2025-07-27 21:06:42] EXECUTING: PtychoPINN training (n_images=256, trial=1)
[2025-07-27 21:06:42] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run' \
            --nepochs 50
2025-07-27 21:06:43.032005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:06:43.032033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:06:43.032848: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:06:43.036895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:06:43.502514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:06:44.546975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.581631: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.584817: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:06:44.744611: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.747835: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.750855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.872081: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.873490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.874678: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:06:44.874817: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:06:44.876106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:06:44,904 - INFO - Configuration setup complete
2025-07-27 21:06:44,904 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run'))
2025-07-27 21:06:44,904 - INFO - Parameter interpretation: --n-images=256 refers to individual images (gridsize=1)
2025-07-27 21:06:44,904 - INFO - Starting training with n_images=256, stitching=disabled
2025-07-27 21:06:44,904 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:06:44,936 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
2025-07-27 21:06:44,937 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:06:45,010 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:06:45,010 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:07:02,946 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:07:03.061217: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:07:03.061231: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:07:03.061254: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:07:03.077914: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:07:03.078359: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:07:03,079 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:07:03,682 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:07:03,688 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:07:04,657 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:07:04,664 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:07:05.322281: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:07:05.344705: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x39139350
2025-07-27 21:07:06.521493: I external/local_xla/xla/service/service.cc:168] XLA service 0x7e0c58039160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:07:06.521521: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:07:06.524621: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675626.591538 3696955 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:36 - loss: 759175424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 166.9198 - distribution_lambda_loss: 759175424.0000 6/16 [==========>...................] - ETA: 0s - loss: 58521636864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1434.3763 - distribution_lambda_loss: 58521636864.000011/16 [===================>..........] - ETA: 0s - loss: 32383891456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 899.5120 - distribution_lambda_loss: 32383891456.0000 16/16 [==============================] - ETA: 0s - loss: 23616747520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 713.9965 - distribution_lambda_loss: 23616747520.0000input shape (None, 64, 64, 1)
16/16 [==============================] - 8s 126ms/step - loss: 23616747520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 713.9965 - distribution_lambda_loss: 23616747520.0000 - val_loss: 472953120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 225.4408 - val_distribution_lambda_loss: 472953120.0000 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 492298560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 230.3677 - distribution_lambda_loss: 492298560.0000 6/16 [==========>...................] - ETA: 0s - loss: 399408512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 183.7057 - distribution_lambda_loss: 399408512.000011/16 [===================>..........] - ETA: 0s - loss: 379878464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 170.8859 - distribution_lambda_loss: 379878464.000016/16 [==============================] - 0s 12ms/step - loss: 373089184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 171.3357 - distribution_lambda_loss: 373089184.0000 - val_loss: 335559040.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 159.2239 - val_distribution_lambda_loss: 335559040.0000 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 328297888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 158.6538 - distribution_lambda_loss: 328297888.0000 6/16 [==========>...................] - ETA: 0s - loss: 343258080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 157.8912 - distribution_lambda_loss: 343258080.000011/16 [===================>..........] - ETA: 0s - loss: 339827616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 158.5915 - distribution_lambda_loss: 339827616.000016/16 [==============================] - ETA: 0s - loss: 340854592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 158.0163 - distribution_lambda_loss: 340854592.000016/16 [==============================] - 0s 12ms/step - loss: 340854592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 158.0163 - distribution_lambda_loss: 340854592.0000 - val_loss: 330032288.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 154.6954 - val_distribution_lambda_loss: 330032288.0000 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 318668768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 154.4163 - distribution_lambda_loss: 318668768.0000 6/16 [==========>...................] - ETA: 0s - loss: 326756224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 153.9835 - distribution_lambda_loss: 326756224.000011/16 [===================>..........] - ETA: 0s - loss: 323344352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 152.5985 - distribution_lambda_loss: 323344352.000016/16 [==============================] - 0s 12ms/step - loss: 331845024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 154.3212 - distribution_lambda_loss: 331845024.0000 - val_loss: 323438944.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 151.5865 - val_distribution_lambda_loss: 323438944.0000 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 343412160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 154.0009 - distribution_lambda_loss: 343412160.0000 6/16 [==========>...................] - ETA: 0s - loss: 338505344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 155.6311 - distribution_lambda_loss: 338505344.000011/16 [===================>..........] - ETA: 0s - loss: 328689024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 152.5683 - distribution_lambda_loss: 328689024.000016/16 [==============================] - 0s 12ms/step - loss: 324105888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 151.1225 - distribution_lambda_loss: 324105888.0000 - val_loss: 314207680.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 144.9502 - val_distribution_lambda_loss: 314207680.0000 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 267061344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 135.9858 - distribution_lambda_loss: 267061344.0000 6/16 [==========>...................] - ETA: 0s - loss: 306568736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 144.2309 - distribution_lambda_loss: 306568736.000011/16 [===================>..........] - ETA: 0s - loss: 311315008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 144.6835 - distribution_lambda_loss: 311315008.000016/16 [==============================] - 0s 12ms/step - loss: 307204960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 143.9186 - distribution_lambda_loss: 307204960.0000 - val_loss: 292560992.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 140.1671 - val_distribution_lambda_loss: 292560992.0000 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 251500848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 133.3687 - distribution_lambda_loss: 251500848.0000 6/16 [==========>...................] - ETA: 0s - loss: 273870464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 135.1662 - distribution_lambda_loss: 273870464.000011/16 [===================>..........] - ETA: 0s - loss: 288923936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 138.7915 - distribution_lambda_loss: 288923936.000016/16 [==============================] - ETA: 0s - loss: 282455968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 136.6399 - distribution_lambda_loss: 282455968.000016/16 [==============================] - 0s 12ms/step - loss: 282455968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 136.6399 - distribution_lambda_loss: 282455968.0000 - val_loss: 264156784.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 126.3093 - val_distribution_lambda_loss: 264156784.0000 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 261865072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 127.0361 - distribution_lambda_loss: 261865072.0000 6/16 [==========>...................] - ETA: 0s - loss: 263634384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 130.3237 - distribution_lambda_loss: 263634384.000011/16 [===================>..........] - ETA: 0s - loss: 257668608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.7673 - distribution_lambda_loss: 257668608.000016/16 [==============================] - ETA: 0s - loss: 256851696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.9169 - distribution_lambda_loss: 256851696.000016/16 [==============================] - 0s 12ms/step - loss: 256851696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.9169 - distribution_lambda_loss: 256851696.0000 - val_loss: 246145456.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 129.3676 - val_distribution_lambda_loss: 246145456.0000 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 249684320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.5892 - distribution_lambda_loss: 249684320.0000 6/16 [==========>...................] - ETA: 0s - loss: 228015952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 123.1273 - distribution_lambda_loss: 228015952.000011/16 [===================>..........] - ETA: 0s - loss: 240196752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 125.5761 - distribution_lambda_loss: 240196752.000016/16 [==============================] - ETA: 0s - loss: 236831216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.5992 - distribution_lambda_loss: 236831216.000016/16 [==============================] - 0s 12ms/step - loss: 236831216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.5992 - distribution_lambda_loss: 236831216.0000 - val_loss: 232049216.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 125.1133 - val_distribution_lambda_loss: 232049216.0000 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 225893632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 122.9290 - distribution_lambda_loss: 225893632.0000 6/16 [==========>...................] - ETA: 0s - loss: 240177168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 125.8461 - distribution_lambda_loss: 240177168.000011/16 [===================>..........] - ETA: 0s - loss: 230946864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 122.8949 - distribution_lambda_loss: 230946864.000016/16 [==============================] - 0s 12ms/step - loss: 222824256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 121.0215 - distribution_lambda_loss: 222824256.0000 - val_loss: 221655232.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 122.4463 - val_distribution_lambda_loss: 221655232.0000 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 218945120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 120.6101 - distribution_lambda_loss: 218945120.0000 6/16 [==========>...................] - ETA: 0s - loss: 207706896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 117.6515 - distribution_lambda_loss: 207706896.000011/16 [===================>..........] - ETA: 0s - loss: 212555632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 118.5103 - distribution_lambda_loss: 212555632.000016/16 [==============================] - ETA: 0s - loss: 213205856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 118.8808 - distribution_lambda_loss: 213205856.000016/16 [==============================] - 0s 12ms/step - loss: 213205856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 118.8808 - distribution_lambda_loss: 213205856.0000 - val_loss: 215400768.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 116.8084 - val_distribution_lambda_loss: 215400768.0000 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 203283024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.4983 - distribution_lambda_loss: 203283024.0000 6/16 [==========>...................] - ETA: 0s - loss: 195083968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.1888 - distribution_lambda_loss: 195083968.000011/16 [===================>..........] - ETA: 0s - loss: 203490752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 115.7870 - distribution_lambda_loss: 203490752.000016/16 [==============================] - 0s 12ms/step - loss: 205741232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 116.7048 - distribution_lambda_loss: 205741232.0000 - val_loss: 211615424.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 115.4253 - val_distribution_lambda_loss: 211615424.0000 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 200167712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.2084 - distribution_lambda_loss: 200167712.0000 6/16 [==========>...................] - ETA: 0s - loss: 210228624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 118.1798 - distribution_lambda_loss: 210228624.000011/16 [===================>..........] - ETA: 0s - loss: 200476736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 115.6281 - distribution_lambda_loss: 200476736.000016/16 [==============================] - 0s 12ms/step - loss: 199173040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 115.3376 - distribution_lambda_loss: 199173040.0000 - val_loss: 201113440.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 113.4858 - val_distribution_lambda_loss: 201113440.0000 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 217908176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 119.1066 - distribution_lambda_loss: 217908176.0000 6/16 [==========>...................] - ETA: 0s - loss: 196912512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 114.9040 - distribution_lambda_loss: 196912512.000011/16 [===================>..........] - ETA: 0s - loss: 195584576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 114.4192 - distribution_lambda_loss: 195584576.000016/16 [==============================] - 0s 12ms/step - loss: 192661344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5355 - distribution_lambda_loss: 192661344.0000 - val_loss: 197067344.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 115.4244 - val_distribution_lambda_loss: 197067344.0000 - lr: 0.0010
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 166982976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7155 - distribution_lambda_loss: 166982976.0000 6/16 [==========>...................] - ETA: 0s - loss: 187996480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.5578 - distribution_lambda_loss: 187996480.000011/16 [===================>..........] - ETA: 0s - loss: 189215232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.9781 - distribution_lambda_loss: 189215232.000016/16 [==============================] - 0s 12ms/step - loss: 187623280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.5768 - distribution_lambda_loss: 187623280.0000 - val_loss: 193110672.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 114.4434 - val_distribution_lambda_loss: 193110672.0000 - lr: 0.0010
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 167176576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0579 - distribution_lambda_loss: 167176576.0000 6/16 [==========>...................] - ETA: 0s - loss: 170731568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.5196 - distribution_lambda_loss: 170731568.000011/16 [===================>..........] - ETA: 0s - loss: 184098416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.5381 - distribution_lambda_loss: 184098416.000016/16 [==============================] - 0s 12ms/step - loss: 183628976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.5204 - distribution_lambda_loss: 183628976.0000 - val_loss: 191010368.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 110.2310 - val_distribution_lambda_loss: 191010368.0000 - lr: 0.0010
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 158745008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2360 - distribution_lambda_loss: 158745008.0000 6/16 [==========>...................] - ETA: 0s - loss: 175627696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.4157 - distribution_lambda_loss: 175627696.000011/16 [===================>..........] - ETA: 0s - loss: 178761104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.7151 - distribution_lambda_loss: 178761104.000016/16 [==============================] - 0s 12ms/step - loss: 181268336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.4171 - distribution_lambda_loss: 181268336.0000 - val_loss: 184255008.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 110.0441 - val_distribution_lambda_loss: 184255008.0000 - lr: 0.0010
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 170541808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.3318 - distribution_lambda_loss: 170541808.0000 6/16 [==========>...................] - ETA: 0s - loss: 171873584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.2036 - distribution_lambda_loss: 171873584.000011/16 [===================>..........] - ETA: 0s - loss: 175815104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.1198 - distribution_lambda_loss: 175815104.000016/16 [==============================] - 0s 12ms/step - loss: 176659520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.9372 - distribution_lambda_loss: 176659520.0000 - val_loss: 181240752.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 110.9095 - val_distribution_lambda_loss: 181240752.0000 - lr: 0.0010
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 145916768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5627 - distribution_lambda_loss: 145916768.0000 6/16 [==========>...................] - ETA: 0s - loss: 163537616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9525 - distribution_lambda_loss: 163537616.000011/16 [===================>..........] - ETA: 0s - loss: 176504720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.8411 - distribution_lambda_loss: 176504720.000016/16 [==============================] - ETA: 0s - loss: 173792848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.0111 - distribution_lambda_loss: 173792848.000016/16 [==============================] - 0s 12ms/step - loss: 173792848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.0111 - distribution_lambda_loss: 173792848.0000 - val_loss: 178719312.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 110.2317 - val_distribution_lambda_loss: 178719312.0000 - lr: 0.0010
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 159048944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3166 - distribution_lambda_loss: 159048944.0000 6/16 [==========>...................] - ETA: 0s - loss: 166538016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.1962 - distribution_lambda_loss: 166538016.000011/16 [===================>..........] - ETA: 0s - loss: 173020688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.0633 - distribution_lambda_loss: 173020688.000016/16 [==============================] - 0s 12ms/step - loss: 171243280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.4504 - distribution_lambda_loss: 171243280.0000 - val_loss: 175470432.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 110.3733 - val_distribution_lambda_loss: 175470432.0000 - lr: 0.0010
Epoch 21/50
 1/16 [>.............................] - ETA: 0s - loss: 147852912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4723 - distribution_lambda_loss: 147852912.0000 6/16 [==========>...................] - ETA: 0s - loss: 162794128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3275 - distribution_lambda_loss: 162794128.000011/16 [===================>..........] - ETA: 0s - loss: 171663520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.0704 - distribution_lambda_loss: 171663520.000016/16 [==============================] - 0s 12ms/step - loss: 169535376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.0678 - distribution_lambda_loss: 169535376.0000 - val_loss: 173356320.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 108.9839 - val_distribution_lambda_loss: 173356320.0000 - lr: 0.0010
Epoch 22/50
 1/16 [>.............................] - ETA: 0s - loss: 161425504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6096 - distribution_lambda_loss: 161425504.0000 6/16 [==========>...................] - ETA: 0s - loss: 168276560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9909 - distribution_lambda_loss: 168276560.000011/16 [===================>..........] - ETA: 0s - loss: 168002496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6764 - distribution_lambda_loss: 168002496.000016/16 [==============================] - 0s 12ms/step - loss: 167855104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7541 - distribution_lambda_loss: 167855104.0000 - val_loss: 173449840.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 108.3187 - val_distribution_lambda_loss: 173449840.0000 - lr: 0.0010
Epoch 23/50
 1/16 [>.............................] - ETA: 0s - loss: 171890832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.4955 - distribution_lambda_loss: 171890832.0000 6/16 [==========>...................] - ETA: 0s - loss: 167659968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7475 - distribution_lambda_loss: 167659968.000011/16 [===================>..........] - ETA: 0s - loss: 165830160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.2483 - distribution_lambda_loss: 165830160.000016/16 [==============================] - 0s 12ms/step - loss: 166084352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.0599 - distribution_lambda_loss: 166084352.0000 - val_loss: 172514272.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 108.3569 - val_distribution_lambda_loss: 172514272.0000 - lr: 0.0010
Epoch 24/50
 1/16 [>.............................] - ETA: 0s - loss: 160341312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.1935 - distribution_lambda_loss: 160341312.0000 6/16 [==========>...................] - ETA: 0s - loss: 171123584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.6102 - distribution_lambda_loss: 171123584.000011/16 [===================>..........] - ETA: 0s - loss: 164128832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4826 - distribution_lambda_loss: 164128832.000016/16 [==============================] - 0s 12ms/step - loss: 164308240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.6886 - distribution_lambda_loss: 164308240.0000 - val_loss: 169447904.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 107.5482 - val_distribution_lambda_loss: 169447904.0000 - lr: 0.0010
Epoch 25/50
 1/16 [>.............................] - ETA: 0s - loss: 179053824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5840 - distribution_lambda_loss: 179053824.0000 6/16 [==========>...................] - ETA: 0s - loss: 166208688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.0755 - distribution_lambda_loss: 166208688.000011/16 [===================>..........] - ETA: 0s - loss: 162068208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4810 - distribution_lambda_loss: 162068208.000016/16 [==============================] - 0s 12ms/step - loss: 163254528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4805 - distribution_lambda_loss: 163254528.0000 - val_loss: 168343040.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.8024 - val_distribution_lambda_loss: 168343040.0000 - lr: 0.0010
Epoch 26/50
 1/16 [>.............................] - ETA: 0s - loss: 173175552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.1548 - distribution_lambda_loss: 173175552.0000 6/16 [==========>...................] - ETA: 0s - loss: 153776528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8594 - distribution_lambda_loss: 153776528.000011/16 [===================>..........] - ETA: 0s - loss: 161645328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1449 - distribution_lambda_loss: 161645328.000016/16 [==============================] - 0s 12ms/step - loss: 161606928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9640 - distribution_lambda_loss: 161606928.0000 - val_loss: 168439312.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 109.0827 - val_distribution_lambda_loss: 168439312.0000 - lr: 0.0010
Epoch 27/50
 1/16 [>.............................] - ETA: 0s - loss: 179861456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.4889 - distribution_lambda_loss: 179861456.0000 6/16 [==========>...................] - ETA: 0s - loss: 158195904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.1509 - distribution_lambda_loss: 158195904.000011/16 [===================>..........] - ETA: 0s - loss: 160914288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0995 - distribution_lambda_loss: 160914288.000016/16 [==============================] - ETA: 0s - loss: 160629936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8146 - distribution_lambda_loss: 160629936.0000
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 12ms/step - loss: 160629936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8146 - distribution_lambda_loss: 160629936.0000 - val_loss: 171214272.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 111.2593 - val_distribution_lambda_loss: 171214272.0000 - lr: 0.0010
Epoch 28/50
 1/16 [>.............................] - ETA: 0s - loss: 168603104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.0553 - distribution_lambda_loss: 168603104.0000 6/16 [==========>...................] - ETA: 0s - loss: 167952768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.2212 - distribution_lambda_loss: 167952768.000011/16 [===================>..........] - ETA: 0s - loss: 163114336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9116 - distribution_lambda_loss: 163114336.000016/16 [==============================] - 0s 12ms/step - loss: 160136384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8459 - distribution_lambda_loss: 160136384.0000 - val_loss: 166103120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 107.0001 - val_distribution_lambda_loss: 166103120.0000 - lr: 5.0000e-04
Epoch 29/50
 1/16 [>.............................] - ETA: 0s - loss: 191628464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 115.5531 - distribution_lambda_loss: 191628464.0000 6/16 [==========>...................] - ETA: 0s - loss: 157519824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0339 - distribution_lambda_loss: 157519824.000011/16 [===================>..........] - ETA: 0s - loss: 156876720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9634 - distribution_lambda_loss: 156876720.000016/16 [==============================] - 0s 12ms/step - loss: 158472544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.2779 - distribution_lambda_loss: 158472544.0000 - val_loss: 165217872.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 107.5152 - val_distribution_lambda_loss: 165217872.0000 - lr: 5.0000e-04
Epoch 30/50
 1/16 [>.............................] - ETA: 0s - loss: 179227232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.4915 - distribution_lambda_loss: 179227232.0000 6/16 [==========>...................] - ETA: 0s - loss: 155135344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0651 - distribution_lambda_loss: 155135344.000011/16 [===================>..........] - ETA: 0s - loss: 157458112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0047 - distribution_lambda_loss: 157458112.000016/16 [==============================] - 0s 12ms/step - loss: 157362336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9863 - distribution_lambda_loss: 157362336.0000 - val_loss: 165575920.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.8412 - val_distribution_lambda_loss: 165575920.0000 - lr: 5.0000e-04
Epoch 31/50
 1/16 [>.............................] - ETA: 0s - loss: 133043184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3500 - distribution_lambda_loss: 133043184.0000 6/16 [==========>...................] - ETA: 0s - loss: 154290960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8016 - distribution_lambda_loss: 154290960.000011/16 [===================>..........] - ETA: 0s - loss: 153140800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4988 - distribution_lambda_loss: 153140800.000016/16 [==============================] - 0s 12ms/step - loss: 156630048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6930 - distribution_lambda_loss: 156630048.0000 - val_loss: 163807712.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.3130 - val_distribution_lambda_loss: 163807712.0000 - lr: 5.0000e-04
Epoch 32/50
 1/16 [>.............................] - ETA: 0s - loss: 144426576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2895 - distribution_lambda_loss: 144426576.0000 6/16 [==========>...................] - ETA: 0s - loss: 159976416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6746 - distribution_lambda_loss: 159976416.000011/16 [===================>..........] - ETA: 0s - loss: 154891264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2738 - distribution_lambda_loss: 154891264.000016/16 [==============================] - 0s 12ms/step - loss: 155924624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6072 - distribution_lambda_loss: 155924624.0000 - val_loss: 163153920.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.9769 - val_distribution_lambda_loss: 163153920.0000 - lr: 5.0000e-04
Epoch 33/50
 1/16 [>.............................] - ETA: 0s - loss: 167886704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.1074 - distribution_lambda_loss: 167886704.0000 6/16 [==========>...................] - ETA: 0s - loss: 155722992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0595 - distribution_lambda_loss: 155722992.000011/16 [===================>..........] - ETA: 0s - loss: 156785488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9779 - distribution_lambda_loss: 156785488.000016/16 [==============================] - 0s 12ms/step - loss: 155633456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4733 - distribution_lambda_loss: 155633456.0000 - val_loss: 163253360.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.0492 - val_distribution_lambda_loss: 163253360.0000 - lr: 5.0000e-04
Epoch 34/50
 1/16 [>.............................] - ETA: 0s - loss: 143265312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8896 - distribution_lambda_loss: 143265312.0000 6/16 [==========>...................] - ETA: 0s - loss: 153229184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9625 - distribution_lambda_loss: 153229184.000011/16 [===================>..........] - ETA: 0s - loss: 153380704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7390 - distribution_lambda_loss: 153380704.000016/16 [==============================] - 0s 12ms/step - loss: 155372224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4496 - distribution_lambda_loss: 155372224.0000 - val_loss: 162497008.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.7360 - val_distribution_lambda_loss: 162497008.0000 - lr: 5.0000e-04
Epoch 35/50
 1/16 [>.............................] - ETA: 0s - loss: 148592544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0389 - distribution_lambda_loss: 148592544.0000 6/16 [==========>...................] - ETA: 0s - loss: 156228032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5923 - distribution_lambda_loss: 156228032.000011/16 [===================>..........] - ETA: 0s - loss: 153045920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6272 - distribution_lambda_loss: 153045920.000016/16 [==============================] - 0s 12ms/step - loss: 154708144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2574 - distribution_lambda_loss: 154708144.0000 - val_loss: 161407584.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.5981 - val_distribution_lambda_loss: 161407584.0000 - lr: 5.0000e-04
Epoch 36/50
 1/16 [>.............................] - ETA: 0s - loss: 113973840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.5580 - distribution_lambda_loss: 113973840.0000 6/16 [==========>...................] - ETA: 0s - loss: 149567088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9888 - distribution_lambda_loss: 149567088.000011/16 [===================>..........] - ETA: 0s - loss: 153699776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9774 - distribution_lambda_loss: 153699776.000016/16 [==============================] - 0s 12ms/step - loss: 153998704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1114 - distribution_lambda_loss: 153998704.0000 - val_loss: 161268976.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.3870 - val_distribution_lambda_loss: 161268976.0000 - lr: 5.0000e-04
Epoch 37/50
 1/16 [>.............................] - ETA: 0s - loss: 132710920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.3257 - distribution_lambda_loss: 132710920.0000 6/16 [==========>...................] - ETA: 0s - loss: 146444336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5455 - distribution_lambda_loss: 146444336.000011/16 [===================>..........] - ETA: 0s - loss: 151698672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.2210 - distribution_lambda_loss: 151698672.000016/16 [==============================] - 0s 12ms/step - loss: 153657760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9149 - distribution_lambda_loss: 153657760.0000 - val_loss: 161386720.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.9914 - val_distribution_lambda_loss: 161386720.0000 - lr: 5.0000e-04
Epoch 38/50
 1/16 [>.............................] - ETA: 0s - loss: 139889456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4927 - distribution_lambda_loss: 139889456.0000 6/16 [==========>...................] - ETA: 0s - loss: 153682288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9148 - distribution_lambda_loss: 153682288.000011/16 [===================>..........] - ETA: 0s - loss: 151422352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.2863 - distribution_lambda_loss: 151422352.000016/16 [==============================] - 0s 12ms/step - loss: 153237712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8886 - distribution_lambda_loss: 153237712.0000 - val_loss: 160527808.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.9745 - val_distribution_lambda_loss: 160527808.0000 - lr: 5.0000e-04
Epoch 39/50
 1/16 [>.............................] - ETA: 0s - loss: 147159232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6160 - distribution_lambda_loss: 147159232.0000 6/16 [==========>...................] - ETA: 0s - loss: 156051024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.8862 - distribution_lambda_loss: 156051024.000011/16 [===================>..........] - ETA: 0s - loss: 152016240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5151 - distribution_lambda_loss: 152016240.000016/16 [==============================] - 0s 12ms/step - loss: 152361328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5948 - distribution_lambda_loss: 152361328.0000 - val_loss: 161530464.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 107.2797 - val_distribution_lambda_loss: 161530464.0000 - lr: 5.0000e-04
Epoch 40/50
 1/16 [>.............................] - ETA: 0s - loss: 174626576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.8116 - distribution_lambda_loss: 174626576.0000 6/16 [==========>...................] - ETA: 0s - loss: 160768720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.5808 - distribution_lambda_loss: 160768720.000011/16 [===================>..........] - ETA: 0s - loss: 156110704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0855 - distribution_lambda_loss: 156110704.000016/16 [==============================] - 0s 12ms/step - loss: 152398160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7851 - distribution_lambda_loss: 152398160.0000 - val_loss: 159354736.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.7907 - val_distribution_lambda_loss: 159354736.0000 - lr: 5.0000e-04
Epoch 41/50
 1/16 [>.............................] - ETA: 0s - loss: 158140864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9174 - distribution_lambda_loss: 158140864.0000 6/16 [==========>...................] - ETA: 0s - loss: 147313472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.2143 - distribution_lambda_loss: 147313472.000011/16 [===================>..........] - ETA: 0s - loss: 147897232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4271 - distribution_lambda_loss: 147897232.000016/16 [==============================] - 0s 12ms/step - loss: 151537616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5061 - distribution_lambda_loss: 151537616.0000 - val_loss: 160294832.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 107.6262 - val_distribution_lambda_loss: 160294832.0000 - lr: 5.0000e-04
Epoch 42/50
 1/16 [>.............................] - ETA: 0s - loss: 146935600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7726 - distribution_lambda_loss: 146935600.0000 6/16 [==========>...................] - ETA: 0s - loss: 155225680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.1219 - distribution_lambda_loss: 155225680.000011/16 [===================>..........] - ETA: 0s - loss: 153523504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1955 - distribution_lambda_loss: 153523504.000016/16 [==============================] - 0s 12ms/step - loss: 151544944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5571 - distribution_lambda_loss: 151544944.0000 - val_loss: 159272640.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.7557 - val_distribution_lambda_loss: 159272640.0000 - lr: 5.0000e-04
Epoch 43/50
 1/16 [>.............................] - ETA: 0s - loss: 144539008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4934 - distribution_lambda_loss: 144539008.0000 6/16 [==========>...................] - ETA: 0s - loss: 150035136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5710 - distribution_lambda_loss: 150035136.000011/16 [===================>..........] - ETA: 0s - loss: 152534032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6025 - distribution_lambda_loss: 152534032.000016/16 [==============================] - 0s 12ms/step - loss: 151246816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4061 - distribution_lambda_loss: 151246816.0000 - val_loss: 160373696.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.0039 - val_distribution_lambda_loss: 160373696.0000 - lr: 5.0000e-04
Epoch 44/50
 1/16 [>.............................] - ETA: 0s - loss: 148629360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4224 - distribution_lambda_loss: 148629360.0000 6/16 [==========>...................] - ETA: 0s - loss: 153080080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8684 - distribution_lambda_loss: 153080080.000011/16 [===================>..........] - ETA: 0s - loss: 149958928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7586 - distribution_lambda_loss: 149958928.0000
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
16/16 [==============================] - 0s 12ms/step - loss: 150928816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.3490 - distribution_lambda_loss: 150928816.0000 - val_loss: 159878080.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.0444 - val_distribution_lambda_loss: 159878080.0000 - lr: 5.0000e-04
Epoch 45/50
 1/16 [>.............................] - ETA: 0s - loss: 138197760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5935 - distribution_lambda_loss: 138197760.0000 6/16 [==========>...................] - ETA: 0s - loss: 143564752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9797 - distribution_lambda_loss: 143564752.000011/16 [===================>..........] - ETA: 0s - loss: 148461280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4261 - distribution_lambda_loss: 148461280.000016/16 [==============================] - 0s 12ms/step - loss: 149853440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9306 - distribution_lambda_loss: 149853440.0000 - val_loss: 157905952.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.7183 - val_distribution_lambda_loss: 157905952.0000 - lr: 2.5000e-04
Epoch 46/50
 1/16 [>.............................] - ETA: 0s - loss: 145217344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.3253 - distribution_lambda_loss: 145217344.0000 6/16 [==========>...................] - ETA: 0s - loss: 144419424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6892 - distribution_lambda_loss: 144419424.000011/16 [===================>..........] - ETA: 0s - loss: 149718352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9929 - distribution_lambda_loss: 149718352.000016/16 [==============================] - 0s 12ms/step - loss: 149260144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8282 - distribution_lambda_loss: 149260144.0000 - val_loss: 157461488.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.9953 - val_distribution_lambda_loss: 157461488.0000 - lr: 2.5000e-04
Epoch 47/50
 1/16 [>.............................] - ETA: 0s - loss: 152442464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0999 - distribution_lambda_loss: 152442464.0000 6/16 [==========>...................] - ETA: 0s - loss: 147204272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6561 - distribution_lambda_loss: 147204272.000011/16 [===================>..........] - ETA: 0s - loss: 147071472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1274 - distribution_lambda_loss: 147071472.000016/16 [==============================] - ETA: 0s - loss: 148740192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7318 - distribution_lambda_loss: 148740192.000016/16 [==============================] - 0s 12ms/step - loss: 148740192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7318 - distribution_lambda_loss: 148740192.0000 - val_loss: 157658720.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.5290 - val_distribution_lambda_loss: 157658720.0000 - lr: 2.5000e-04
Epoch 48/50
 1/16 [>.............................] - ETA: 0s - loss: 138821200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4364 - distribution_lambda_loss: 138821200.0000 6/16 [==========>...................] - ETA: 0s - loss: 143243248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9579 - distribution_lambda_loss: 143243248.000011/16 [===================>..........] - ETA: 0s - loss: 147336464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1961 - distribution_lambda_loss: 147336464.0000
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
16/16 [==============================] - 0s 12ms/step - loss: 148651520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6902 - distribution_lambda_loss: 148651520.0000 - val_loss: 157483296.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.3438 - val_distribution_lambda_loss: 157483296.0000 - lr: 2.5000e-04
Epoch 49/50
 1/16 [>.............................] - ETA: 0s - loss: 171313792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.4735 - distribution_lambda_loss: 171313792.0000 6/16 [==========>...................] - ETA: 0s - loss: 153525072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6030 - distribution_lambda_loss: 153525072.000011/16 [===================>..........] - ETA: 0s - loss: 150898352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7051 - distribution_lambda_loss: 150898352.000016/16 [==============================] - 0s 12ms/step - loss: 148223248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5671 - distribution_lambda_loss: 148223248.0000 - val_loss: 156877120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.1937 - val_distribution_lambda_loss: 156877120.0000 - lr: 1.2500e-04
Epoch 50/50
 1/16 [>.............................] - ETA: 0s - loss: 138149568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6805 - distribution_lambda_loss: 138149568.0000 6/16 [==========>...................] - ETA: 0s - loss: 148420816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8050 - distribution_lambda_loss: 148420816.000011/16 [===================>..........] - ETA: 0s - loss: 147323376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5033 - distribution_lambda_loss: 147323376.000016/16 [==============================] - 0s 12ms/step - loss: 147934320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5897 - distribution_lambda_loss: 147934320.0000 - val_loss: 156664480.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.4128 - val_distribution_lambda_loss: 156664480.0000 - lr: 1.2500e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:25  5/322 [..............................] - ETA: 5s    9/322 [..............................] - ETA: 5s 13/322 [>.............................] - ETA: 5s 17/322 [>.............................] - ETA: 4s 21/322 [>.............................] - ETA: 4s 25/322 [=>............................] - ETA: 4s 28/322 [=>............................] - ETA: 4s 32/322 [=>............................] - ETA: 4s 36/322 [==>...........................] - ETA: 4s 40/322 [==>...........................] - ETA: 4s 44/322 [===>..........................] - ETA: 4s 48/322 [===>..........................] - ETA: 4s 51/322 [===>..........................] - ETA: 4s 55/322 [====>.........................] - ETA: 4s 58/322 [====>.........................] - ETA: 4s 62/322 [====>.........................] - ETA: 4s 66/322 [=====>........................] - ETA: 4s 70/322 [=====>........................] - ETA: 4s 73/322 [=====>........................] - ETA: 4s 77/322 [======>.......................] - ETA: 3s 80/322 [======>.......................] - ETA: 3s 83/322 [======>.......................] - ETA: 3s 86/322 [=======>......................] - ETA: 3s 90/322 [=======>......................] - ETA: 3s 94/322 [=======>......................] - ETA: 3s 98/322 [========>.....................] - ETA: 3s102/322 [========>.....................] - ETA: 3s106/322 [========>.....................] - ETA: 3s110/322 [=========>....................] - ETA: 3s114/322 [=========>....................] - ETA: 3s118/322 [=========>....................] - ETA: 3s121/322 [==========>...................] - ETA: 3s125/322 [==========>...................] - ETA: 3s129/322 [===========>..................] - ETA: 3s133/322 [===========>..................] - ETA: 3s137/322 [===========>..................] - ETA: 2s141/322 [============>.................] - ETA: 2s144/322 [============>.................] - ETA: 2s147/322 [============>.................] - ETA: 2s150/322 [============>.................] - ETA: 2s154/322 [=============>................] - ETA: 2s158/322 [=============>................] - ETA: 2s162/322 [==============>...............] - ETA: 2s165/322 [==============>...............] - ETA: 2s168/322 [==============>...............] - ETA: 2s172/322 [===============>..............] - ETA: 2s176/322 [===============>..............] - ETA: 2s179/322 [===============>..............] - ETA: 2s182/322 [===============>..............] - ETA: 2s186/322 [================>.............] - ETA: 2s190/322 [================>.............] - ETA: 2s194/322 [=================>............] - ETA: 2s198/322 [=================>............] - ETA: 1s202/322 [=================>............] - ETA: 1s206/322 [==================>...........] - ETA: 1s210/322 [==================>...........] - ETA: 1s214/322 [==================>...........] - ETA: 1s218/322 [===================>..........] - ETA: 1s221/322 [===================>..........] - ETA: 1s225/322 [===================>..........] - ETA: 1s229/322 [====================>.........] - ETA: 1s232/322 [====================>.........] - ETA: 1s236/322 [====================>.........] - ETA: 1s240/322 [=====================>........] - ETA: 1s244/322 [=====================>........] - ETA: 1s248/322 [======================>.......] - ETA: 1s252/322 [======================>.......] - ETA: 1s256/322 [======================>.......] - ETA: 1s260/322 [=======================>......] - ETA: 1s264/322 [=======================>......] - ETA: 0s268/322 [=======================>......] - ETA: 0s272/322 [========================>.....] - ETA: 0s275/322 [========================>.....] - ETA: 0s279/322 [========================>.....] - ETA: 0s283/322 [=========================>....] - ETA: 0s287/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s295/322 [==========================>...] - ETA: 0s299/322 [==========================>...] - ETA: 0s303/322 [===========================>..] - ETA: 0s307/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s315/322 [============================>.] - ETA: 0s319/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 7s 16ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:07:28,917 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:07:31,942 - INFO - Assets written to: /tmp/tmpsv0ouxao/autoencoder/assets
2025-07-27 21:07:31,990 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:07:33,608 - INFO - Assets written to: /tmp/tmpsv0ouxao/diffraction_to_obj/assets
2025-07-27 21:07:34,601 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run
[2025-07-27 21:07:35] SUCCESS: PtychoPINN training (n_images=256, trial=1)
[2025-07-27 21:07:35] EXECUTING: Baseline training (n_images=256, trial=1)
[2025-07-27 21:07:35] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run' \
            --nepochs 50
2025-07-27 21:07:35.959346: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:07:35.959377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:07:35.960204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:07:35.964301: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:07:36.421047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:07:37.223053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.257929: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.260127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:07:37.513052: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.515286: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.517291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.629803: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.631129: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.632241: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:07:37.632367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:07:37.633503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:07:37,912 - INFO - Configuration setup complete
2025-07-27 21:07:37,912 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run'))
2025-07-27 21:07:37,912 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:07:37,913 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:07:37,913 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1/
2025-07-27 21:07:37,913 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:07:37,926 - INFO - 
[2/6] Loading data...
2025-07-27 21:07:37,926 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:07:37,926 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:07:37,959 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
2025-07-27 21:07:37,959 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:07:38,031 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:07:55,568 - INFO - Globally set intensity_scale to: 988.211669921875
2025-07-27 21:07:55,568 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:07:55,570 - INFO - Final training input shape: (256, 64, 64, 1)
2025-07-27 21:07:55,570 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:07:55,570 - INFO - Training with 256 images
DEBUG: Setting timestamp to 07/27/2025, 21:07:37 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:07:37
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.2117, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:07:56.918585: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:07:57.713084: I external/local_xla/xla/service/service.cc:168] XLA service 0x79e08447d850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:07:57.713113: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:07:57.716467: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675677.777003 3700742 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:06 - loss: 3.5813 - conv2d_12_loss: 1.2267 - conv2d_19_loss: 2.3546 6/16 [==========>...................] - ETA: 0s - loss: 7.1090 - conv2d_12_loss: 3.2766 - conv2d_19_loss: 3.8324  11/16 [===================>..........] - ETA: 0s - loss: 5.4675 - conv2d_12_loss: 2.3284 - conv2d_19_loss: 3.139116/16 [==============================] - ETA: 0s - loss: 4.9019 - conv2d_12_loss: 2.0055 - conv2d_19_loss: 2.896416/16 [==============================] - 6s 126ms/step - loss: 4.9019 - conv2d_12_loss: 2.0055 - conv2d_19_loss: 2.8964 - val_loss: 3.2794 - val_conv2d_12_loss: 1.0933 - val_conv2d_19_loss: 2.1861 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 3.2851 - conv2d_12_loss: 1.0949 - conv2d_19_loss: 2.1902 6/16 [==========>...................] - ETA: 0s - loss: 2.8416 - conv2d_12_loss: 0.8858 - conv2d_19_loss: 1.955811/16 [===================>..........] - ETA: 0s - loss: 2.1751 - conv2d_12_loss: 0.7245 - conv2d_19_loss: 1.450616/16 [==============================] - 0s 11ms/step - loss: 1.8546 - conv2d_12_loss: 0.6542 - conv2d_19_loss: 1.2004 - val_loss: 0.9713 - val_conv2d_12_loss: 0.4598 - val_conv2d_19_loss: 0.5115 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 0.9681 - conv2d_12_loss: 0.4606 - conv2d_19_loss: 0.5075 6/16 [==========>...................] - ETA: 0s - loss: 0.7830 - conv2d_12_loss: 0.3188 - conv2d_19_loss: 0.464211/16 [===================>..........] - ETA: 0s - loss: 0.7252 - conv2d_12_loss: 0.2815 - conv2d_19_loss: 0.443716/16 [==============================] - 0s 11ms/step - loss: 0.6912 - conv2d_12_loss: 0.2614 - conv2d_19_loss: 0.4298 - val_loss: 0.5647 - val_conv2d_12_loss: 0.1885 - val_conv2d_19_loss: 0.3762 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 0.5689 - conv2d_12_loss: 0.1851 - conv2d_19_loss: 0.3838 6/16 [==========>...................] - ETA: 0s - loss: 0.5566 - conv2d_12_loss: 0.1908 - conv2d_19_loss: 0.365911/16 [===================>..........] - ETA: 0s - loss: 0.5386 - conv2d_12_loss: 0.1846 - conv2d_19_loss: 0.353916/16 [==============================] - 0s 12ms/step - loss: 0.5196 - conv2d_12_loss: 0.1780 - conv2d_19_loss: 0.3416 - val_loss: 0.4732 - val_conv2d_12_loss: 0.1595 - val_conv2d_19_loss: 0.3137 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 0.4641 - conv2d_12_loss: 0.1575 - conv2d_19_loss: 0.3067 6/16 [==========>...................] - ETA: 0s - loss: 0.4511 - conv2d_12_loss: 0.1523 - conv2d_19_loss: 0.298811/16 [===================>..........] - ETA: 0s - loss: 0.4438 - conv2d_12_loss: 0.1479 - conv2d_19_loss: 0.295916/16 [==============================] - 0s 12ms/step - loss: 0.4355 - conv2d_12_loss: 0.1434 - conv2d_19_loss: 0.2921 - val_loss: 0.4132 - val_conv2d_12_loss: 0.1281 - val_conv2d_19_loss: 0.2851 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 0.4060 - conv2d_12_loss: 0.1264 - conv2d_19_loss: 0.2796 6/16 [==========>...................] - ETA: 0s - loss: 0.4054 - conv2d_12_loss: 0.1256 - conv2d_19_loss: 0.279911/16 [===================>..........] - ETA: 0s - loss: 0.3980 - conv2d_12_loss: 0.1221 - conv2d_19_loss: 0.275916/16 [==============================] - 0s 12ms/step - loss: 0.3903 - conv2d_12_loss: 0.1192 - conv2d_19_loss: 0.2711 - val_loss: 0.3777 - val_conv2d_12_loss: 0.1123 - val_conv2d_19_loss: 0.2654 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3658 - conv2d_12_loss: 0.1089 - conv2d_19_loss: 0.2569 6/16 [==========>...................] - ETA: 0s - loss: 0.3649 - conv2d_12_loss: 0.1088 - conv2d_19_loss: 0.256111/16 [===================>..........] - ETA: 0s - loss: 0.3666 - conv2d_12_loss: 0.1083 - conv2d_19_loss: 0.258316/16 [==============================] - 0s 11ms/step - loss: 0.3617 - conv2d_12_loss: 0.1068 - conv2d_19_loss: 0.2549 - val_loss: 0.3563 - val_conv2d_12_loss: 0.1049 - val_conv2d_19_loss: 0.2514 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3455 - conv2d_12_loss: 0.1025 - conv2d_19_loss: 0.2431 6/16 [==========>...................] - ETA: 0s - loss: 0.3532 - conv2d_12_loss: 0.1032 - conv2d_19_loss: 0.250111/16 [===================>..........] - ETA: 0s - loss: 0.3460 - conv2d_12_loss: 0.1009 - conv2d_19_loss: 0.245116/16 [==============================] - 0s 11ms/step - loss: 0.3427 - conv2d_12_loss: 0.0996 - conv2d_19_loss: 0.2431 - val_loss: 0.3412 - val_conv2d_12_loss: 0.0971 - val_conv2d_19_loss: 0.2441 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3406 - conv2d_12_loss: 0.0963 - conv2d_19_loss: 0.2443 6/16 [==========>...................] - ETA: 0s - loss: 0.3298 - conv2d_12_loss: 0.0945 - conv2d_19_loss: 0.235311/16 [===================>..........] - ETA: 0s - loss: 0.3303 - conv2d_12_loss: 0.0947 - conv2d_19_loss: 0.235516/16 [==============================] - 0s 12ms/step - loss: 0.3286 - conv2d_12_loss: 0.0938 - conv2d_19_loss: 0.2348 - val_loss: 0.3252 - val_conv2d_12_loss: 0.0919 - val_conv2d_19_loss: 0.2334 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3311 - conv2d_12_loss: 0.0923 - conv2d_19_loss: 0.2388 6/16 [==========>...................] - ETA: 0s - loss: 0.3156 - conv2d_12_loss: 0.0885 - conv2d_19_loss: 0.227111/16 [===================>..........] - ETA: 0s - loss: 0.3186 - conv2d_12_loss: 0.0890 - conv2d_19_loss: 0.229616/16 [==============================] - 0s 12ms/step - loss: 0.3174 - conv2d_12_loss: 0.0883 - conv2d_19_loss: 0.2290 - val_loss: 0.3188 - val_conv2d_12_loss: 0.0888 - val_conv2d_19_loss: 0.2299 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3289 - conv2d_12_loss: 0.0900 - conv2d_19_loss: 0.2389 6/16 [==========>...................] - ETA: 0s - loss: 0.3193 - conv2d_12_loss: 0.0878 - conv2d_19_loss: 0.231511/16 [===================>..........] - ETA: 0s - loss: 0.3144 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.227816/16 [==============================] - 0s 12ms/step - loss: 0.3137 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2272 - val_loss: 0.3167 - val_conv2d_12_loss: 0.0875 - val_conv2d_19_loss: 0.2292 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3002 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2165 6/16 [==========>...................] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.226611/16 [===================>..........] - ETA: 0s - loss: 0.3120 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.226416/16 [==============================] - 0s 12ms/step - loss: 0.3133 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2274 - val_loss: 0.3175 - val_conv2d_12_loss: 0.0879 - val_conv2d_19_loss: 0.2296 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3033 - conv2d_12_loss: 0.0833 - conv2d_19_loss: 0.2200 6/16 [==========>...................] - ETA: 0s - loss: 0.3081 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.222911/16 [===================>..........] - ETA: 0s - loss: 0.3087 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.223916/16 [==============================] - 0s 11ms/step - loss: 0.3124 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2267 - val_loss: 0.3164 - val_conv2d_12_loss: 0.0872 - val_conv2d_19_loss: 0.2292 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2269 6/16 [==========>...................] - ETA: 0s - loss: 0.3137 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.228011/16 [===================>..........] - ETA: 0s - loss: 0.3140 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.228016/16 [==============================] - 0s 11ms/step - loss: 0.3125 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2269 - val_loss: 0.3165 - val_conv2d_12_loss: 0.0869 - val_conv2d_19_loss: 0.2295 - lr: 0.0010
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3202 - conv2d_12_loss: 0.0883 - conv2d_19_loss: 0.2319 6/16 [==========>...................] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.226211/16 [===================>..........] - ETA: 0s - loss: 0.3123 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2268
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 11ms/step - loss: 0.3116 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2263 - val_loss: 0.3179 - val_conv2d_12_loss: 0.0871 - val_conv2d_19_loss: 0.2308 - lr: 0.0010
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3263 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2397 6/16 [==========>...................] - ETA: 0s - loss: 0.3147 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.229011/16 [===================>..........] - ETA: 0s - loss: 0.3109 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.225816/16 [==============================] - 0s 12ms/step - loss: 0.3111 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2259 - val_loss: 0.3149 - val_conv2d_12_loss: 0.0871 - val_conv2d_19_loss: 0.2278 - lr: 5.0000e-04
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3075 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2231 6/16 [==========>...................] - ETA: 0s - loss: 0.3154 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.229011/16 [===================>..........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.226416/16 [==============================] - 0s 11ms/step - loss: 0.3106 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2254 - val_loss: 0.3151 - val_conv2d_12_loss: 0.0868 - val_conv2d_19_loss: 0.2282 - lr: 5.0000e-04
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3067 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2227 6/16 [==========>...................] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.225111/16 [===================>..........] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2268
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
16/16 [==============================] - 0s 12ms/step - loss: 0.3106 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2256 - val_loss: 0.3151 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2284 - lr: 5.0000e-04
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2919 - conv2d_12_loss: 0.0801 - conv2d_19_loss: 0.2118 6/16 [==========>...................] - ETA: 0s - loss: 0.3056 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.221711/16 [===================>..........] - ETA: 0s - loss: 0.3072 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.223016/16 [==============================] - 0s 12ms/step - loss: 0.3104 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2254 - val_loss: 0.3146 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2279 - lr: 2.5000e-04
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3037 - conv2d_12_loss: 0.0826 - conv2d_19_loss: 0.2211 6/16 [==========>...................] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.224711/16 [===================>..........] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.225516/16 [==============================] - 0s 12ms/step - loss: 0.3105 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2255 - val_loss: 0.3149 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2282 - lr: 2.5000e-04
Epoch 21/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3312 - conv2d_12_loss: 0.0896 - conv2d_19_loss: 0.2417 6/16 [==========>...................] - ETA: 0s - loss: 0.3145 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.228611/16 [===================>..........] - ETA: 0s - loss: 0.3108 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2257
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
16/16 [==============================] - 0s 11ms/step - loss: 0.3102 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2253 - val_loss: 0.3145 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2278 - lr: 2.5000e-04
Epoch 22/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2865 - conv2d_12_loss: 0.0807 - conv2d_19_loss: 0.2058 6/16 [==========>...................] - ETA: 0s - loss: 0.3081 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.223811/16 [===================>..........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.224216/16 [==============================] - 0s 11ms/step - loss: 0.3101 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2252 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2277 - lr: 1.2500e-04
Epoch 23/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2996 - conv2d_12_loss: 0.0823 - conv2d_19_loss: 0.2173 6/16 [==========>...................] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.224911/16 [===================>..........] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.225516/16 [==============================] - 0s 11ms/step - loss: 0.3102 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2253 - val_loss: 0.3149 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2282 - lr: 1.2500e-04
Epoch 24/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3193 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2330 6/16 [==========>...................] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.226911/16 [===================>..........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2244
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001.
16/16 [==============================] - 0s 11ms/step - loss: 0.3102 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2252 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2278 - lr: 1.2500e-04
Epoch 25/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3008 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2168 6/16 [==========>...................] - ETA: 0s - loss: 0.3057 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.221511/16 [===================>..........] - ETA: 0s - loss: 0.3077 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.223216/16 [==============================] - 0s 11ms/step - loss: 0.3099 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0867 - val_conv2d_19_loss: 0.2277 - lr: 1.0000e-04
Epoch 26/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3013 - conv2d_12_loss: 0.0834 - conv2d_19_loss: 0.2179 6/16 [==========>...................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.225111/16 [===================>..........] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.224916/16 [==============================] - 0s 11ms/step - loss: 0.3100 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2251 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2278 - lr: 1.0000e-04
Epoch 27/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0834 - conv2d_19_loss: 0.2286 6/16 [==========>...................] - ETA: 0s - loss: 0.3151 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.229211/16 [===================>..........] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.224516/16 [==============================] - 0s 11ms/step - loss: 0.3100 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 - val_loss: 0.3143 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2277 - lr: 1.0000e-04
Epoch 28/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2261 6/16 [==========>...................] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.226211/16 [===================>..........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.224416/16 [==============================] - 0s 11ms/step - loss: 0.3100 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2278 - lr: 1.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:08:07,148 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1/baseline_model.h5
2025-07-27 21:08:07,148 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:38 11/322 [>.............................] - ETA: 1s   21/322 [>.............................] - ETA: 1s 31/322 [=>............................] - ETA: 1s 41/322 [==>...........................] - ETA: 1s 51/322 [===>..........................] - ETA: 1s 61/322 [====>.........................] - ETA: 1s 71/322 [=====>........................] - ETA: 1s 81/322 [======>.......................] - ETA: 1s 91/322 [=======>......................] - ETA: 1s101/322 [========>.....................] - ETA: 1s111/322 [=========>....................] - ETA: 1s121/322 [==========>...................] - ETA: 1s131/322 [===========>..................] - ETA: 1s141/322 [============>.................] - ETA: 0s151/322 [=============>................] - ETA: 0s161/322 [==============>...............] - ETA: 0s171/322 [==============>...............] - ETA: 0s181/322 [===============>..............] - ETA: 0s191/322 [================>.............] - ETA: 0s201/322 [=================>............] - ETA: 0s211/322 [==================>...........] - ETA: 0s221/322 [===================>..........] - ETA: 0s231/322 [====================>.........] - ETA: 0s241/322 [=====================>........] - ETA: 0s251/322 [======================>.......] - ETA: 0s261/322 [=======================>......] - ETA: 0s271/322 [========================>.....] - ETA: 0s281/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s301/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s321/322 [============================>.] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:08:10,612 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:08:10,612 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:08:10,612 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:08:10,612 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:08:10,613 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:08:10,613 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:08:10,613 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:08:10,613 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:08:10,613 - INFO - --- Alignment complete ---
2025-07-27 21:08:10,613 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:08:10,705 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:08:10,705 - INFO -   MAE:  (0.08503616, 0.2513027286755532)
2025-07-27 21:08:10,705 - INFO -   PSNR: (68.30542041329358, 58.98026719615521)
2025-07-27 21:08:10,806 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:08:10,806 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 0.978363
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.259875, std=0.000001, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.000014, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.978363
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.259875, std=0.000001, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.000014, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:08:11] SUCCESS: Baseline training (n_images=256, trial=1)
[2025-07-27 21:08:11] EXECUTING: Tike reconstruction (n_images=512, trial=1)
[2025-07-27 21:08:11] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_256/trial_1/tike_run' \
                --n-images 512 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:08:54] SUCCESS: Tike reconstruction (n_images=512, trial=1)
[2025-07-27 21:08:54] Completed training for train_size=256 (Trial 1/3)
[2025-07-27 21:08:54] Training models for train_size=256, test_size=512 (Trial 2/3)
[2025-07-27 21:08:54] EXECUTING: PtychoPINN training (n_images=256, trial=2)
[2025-07-27 21:08:54] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run' \
            --nepochs 50
2025-07-27 21:08:54.829505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:08:54.829536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:08:54.830364: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:08:54.834461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:08:55.296155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:08:56.323622: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.356989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.359161: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:08:56.518031: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.520309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.522557: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.643247: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.644461: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.645563: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:08:56.645708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:08:56.646849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:08:56,675 - INFO - Configuration setup complete
2025-07-27 21:08:56,675 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run'))
2025-07-27 21:08:56,675 - INFO - Parameter interpretation: --n-images=256 refers to individual images (gridsize=1)
2025-07-27 21:08:56,675 - INFO - Starting training with n_images=256, stitching=disabled
2025-07-27 21:08:56,675 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:08:56,708 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
2025-07-27 21:08:56,708 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:08:56,781 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:08:56,781 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:09:14,777 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:09:14.895516: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:09:14.895530: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:09:14.895552: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:09:14.912716: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:09:14.912776: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:09:14,914 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:09:15,516 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:09:15,522 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:09:16,503 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:09:16,509 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:09:17.175810: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:09:17.201680: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0xcfe1880
2025-07-27 21:09:18.376307: I external/local_xla/xla/service/service.cc:168] XLA service 0x74963a77b300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:09:18.376330: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:09:18.379666: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675758.445313 3703540 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:37 - loss: 711968256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 154.7995 - distribution_lambda_loss: 711968256.0000 6/16 [==========>...................] - ETA: 0s - loss: 99033948160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1855.4930 - distribution_lambda_loss: 99033948160.000011/16 [===================>..........] - ETA: 0s - loss: 54405038080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1101.1320 - distribution_lambda_loss: 54405038080.000016/16 [==============================] - ETA: 0s - loss: 39569715200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 843.9503 - distribution_lambda_loss: 39569715200.0000 input shape (None, 64, 64, 1)
16/16 [==============================] - 8s 127ms/step - loss: 39569715200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 843.9503 - distribution_lambda_loss: 39569715200.0000 - val_loss: 599748736.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 196.5104 - val_distribution_lambda_loss: 599748736.0000 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 599112320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 194.8734 - distribution_lambda_loss: 599112320.0000 6/16 [==========>...................] - ETA: 0s - loss: 536361056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 168.7904 - distribution_lambda_loss: 536361056.000011/16 [===================>..........] - ETA: 0s - loss: 496829120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 164.0477 - distribution_lambda_loss: 496829120.000016/16 [==============================] - 0s 12ms/step - loss: 460961984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 162.6183 - distribution_lambda_loss: 460961984.0000 - val_loss: 344463808.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 164.6358 - val_distribution_lambda_loss: 344463808.0000 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 330432576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 161.2867 - distribution_lambda_loss: 330432576.0000 6/16 [==========>...................] - ETA: 0s - loss: 315860096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 157.2502 - distribution_lambda_loss: 315860096.000011/16 [===================>..........] - ETA: 0s - loss: 304466848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 153.6774 - distribution_lambda_loss: 304466848.000016/16 [==============================] - 0s 12ms/step - loss: 291213248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 149.4387 - distribution_lambda_loss: 291213248.0000 - val_loss: 230287280.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 131.2736 - val_distribution_lambda_loss: 230287280.0000 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 220964768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 129.7144 - distribution_lambda_loss: 220964768.0000 6/16 [==========>...................] - ETA: 0s - loss: 220814032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 131.1896 - distribution_lambda_loss: 220814032.000011/16 [===================>..........] - ETA: 0s - loss: 207033232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 127.0633 - distribution_lambda_loss: 207033232.000016/16 [==============================] - 0s 12ms/step - loss: 199656752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 125.0390 - distribution_lambda_loss: 199656752.0000 - val_loss: 171143872.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 111.8459 - val_distribution_lambda_loss: 171143872.0000 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 164279808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.8376 - distribution_lambda_loss: 164279808.0000 6/16 [==========>...................] - ETA: 0s - loss: 161625328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5415 - distribution_lambda_loss: 161625328.000011/16 [===================>..........] - ETA: 0s - loss: 155829232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.7753 - distribution_lambda_loss: 155829232.000016/16 [==============================] - 0s 12ms/step - loss: 154043264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.6941 - distribution_lambda_loss: 154043264.0000 - val_loss: 150650976.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 112.6187 - val_distribution_lambda_loss: 150650976.0000 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 141731792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.9031 - distribution_lambda_loss: 141731792.0000 6/16 [==========>...................] - ETA: 0s - loss: 142858576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9961 - distribution_lambda_loss: 142858576.000011/16 [===================>..........] - ETA: 0s - loss: 140190096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2538 - distribution_lambda_loss: 140190096.000016/16 [==============================] - 0s 12ms/step - loss: 137358512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.0444 - distribution_lambda_loss: 137358512.0000 - val_loss: 132127712.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.6886 - val_distribution_lambda_loss: 132127712.0000 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 132746072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7506 - distribution_lambda_loss: 132746072.0000 6/16 [==========>...................] - ETA: 0s - loss: 126310904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6945 - distribution_lambda_loss: 126310904.0000 11/16 [===================>..........] - ETA: 0s - loss: 124342968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9642 - distribution_lambda_loss: 124342968.000016/16 [==============================] - 0s 12ms/step - loss: 123120496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.1934 - distribution_lambda_loss: 123120496.0000 - val_loss: 124403752.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 98.7924 - val_distribution_lambda_loss: 124403752.0000 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 125359224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7439 - distribution_lambda_loss: 125359224.0000 6/16 [==========>...................] - ETA: 0s - loss: 118425728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 94.8822 - distribution_lambda_loss: 118425728.000011/16 [===================>..........] - ETA: 0s - loss: 115981576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 94.1191 - distribution_lambda_loss: 115981576.000016/16 [==============================] - 0s 12ms/step - loss: 115641664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 93.8921 - distribution_lambda_loss: 115641664.0000 - val_loss: 116573792.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 93.3774 - val_distribution_lambda_loss: 116573792.0000 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 111675936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.3703 - distribution_lambda_loss: 111675936.0000 6/16 [==========>...................] - ETA: 0s - loss: 108054616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.7062 - distribution_lambda_loss: 108054616.000011/16 [===================>..........] - ETA: 0s - loss: 108932560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.5647 - distribution_lambda_loss: 108932560.000016/16 [==============================] - 0s 12ms/step - loss: 107205008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.7175 - distribution_lambda_loss: 107205008.0000 - val_loss: 109019232.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 86.4275 - val_distribution_lambda_loss: 109019232.0000 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 101086688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.8711 - distribution_lambda_loss: 101086688.0000 6/16 [==========>...................] - ETA: 0s - loss: 104569696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.3270 - distribution_lambda_loss: 104569696.000011/16 [===================>..........] - ETA: 0s - loss: 102777736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.2617 - distribution_lambda_loss: 102777736.000016/16 [==============================] - 0s 12ms/step - loss: 101478888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.5304 - distribution_lambda_loss: 101478888.0000 - val_loss: 112726176.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 82.6723 - val_distribution_lambda_loss: 112726176.0000 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 102884968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.9156 - distribution_lambda_loss: 102884968.0000 6/16 [==========>...................] - ETA: 0s - loss: 106371072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.0231 - distribution_lambda_loss: 106371072.000011/16 [===================>..........] - ETA: 0s - loss: 103783192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.4147 - distribution_lambda_loss: 103783192.000016/16 [==============================] - 0s 12ms/step - loss: 102046048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.5197 - distribution_lambda_loss: 102046048.0000 - val_loss: 102397424.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 88.1265 - val_distribution_lambda_loss: 102397424.0000 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 97936912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.2867 - distribution_lambda_loss: 97936912.0000 6/16 [==========>...................] - ETA: 0s - loss: 97966840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.3495 - distribution_lambda_loss: 97966840.000011/16 [===================>..........] - ETA: 0s - loss: 95992384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 83.8047 - distribution_lambda_loss: 95992384.000016/16 [==============================] - 0s 12ms/step - loss: 94429304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 82.9674 - distribution_lambda_loss: 94429304.0000 - val_loss: 96515840.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 80.2777 - val_distribution_lambda_loss: 96515840.0000 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 91402664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.8703 - distribution_lambda_loss: 91402664.0000 6/16 [==========>...................] - ETA: 0s - loss: 91985056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.6558 - distribution_lambda_loss: 91985056.000011/16 [===================>..........] - ETA: 0s - loss: 90487632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.0629 - distribution_lambda_loss: 90487632.000016/16 [==============================] - 0s 12ms/step - loss: 89119784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.5626 - distribution_lambda_loss: 89119784.0000 - val_loss: 93869736.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 82.3921 - val_distribution_lambda_loss: 93869736.0000 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 90906736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 82.4773 - distribution_lambda_loss: 90906736.0000 6/16 [==========>...................] - ETA: 0s - loss: 87150368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.9522 - distribution_lambda_loss: 87150368.000011/16 [===================>..........] - ETA: 0s - loss: 87376656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.7322 - distribution_lambda_loss: 87376656.000016/16 [==============================] - 0s 12ms/step - loss: 87011480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.4345 - distribution_lambda_loss: 87011480.0000 - val_loss: 91258832.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 81.0452 - val_distribution_lambda_loss: 91258832.0000 - lr: 0.0010
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 86581024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.1003 - distribution_lambda_loss: 86581024.0000 6/16 [==========>...................] - ETA: 0s - loss: 83770968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.6560 - distribution_lambda_loss: 83770968.000011/16 [===================>..........] - ETA: 0s - loss: 84703368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.1938 - distribution_lambda_loss: 84703368.000016/16 [==============================] - 0s 12ms/step - loss: 84982760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.2706 - distribution_lambda_loss: 84982760.0000 - val_loss: 89956016.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 78.7387 - val_distribution_lambda_loss: 89956016.0000 - lr: 0.0010
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 83064112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.3461 - distribution_lambda_loss: 83064112.0000 6/16 [==========>...................] - ETA: 0s - loss: 84718872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.9663 - distribution_lambda_loss: 84718872.000011/16 [===================>..........] - ETA: 0s - loss: 83237728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.3756 - distribution_lambda_loss: 83237728.000016/16 [==============================] - 0s 12ms/step - loss: 83990240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.8050 - distribution_lambda_loss: 83990240.0000 - val_loss: 87759920.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 77.4715 - val_distribution_lambda_loss: 87759920.0000 - lr: 0.0010
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 84330368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.9647 - distribution_lambda_loss: 84330368.0000 6/16 [==========>...................] - ETA: 0s - loss: 82167992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.8053 - distribution_lambda_loss: 82167992.000011/16 [===================>..........] - ETA: 0s - loss: 80963232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1656 - distribution_lambda_loss: 80963232.000016/16 [==============================] - ETA: 0s - loss: 80755160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1583 - distribution_lambda_loss: 80755160.000016/16 [==============================] - 0s 12ms/step - loss: 80755160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1583 - distribution_lambda_loss: 80755160.0000 - val_loss: 84529616.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 77.5843 - val_distribution_lambda_loss: 84529616.0000 - lr: 0.0010
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 77016208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.1958 - distribution_lambda_loss: 77016208.0000 6/16 [==========>...................] - ETA: 0s - loss: 79172408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.3105 - distribution_lambda_loss: 79172408.000011/16 [===================>..........] - ETA: 0s - loss: 79583560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.7045 - distribution_lambda_loss: 79583560.000016/16 [==============================] - 0s 12ms/step - loss: 79010824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.2465 - distribution_lambda_loss: 79010824.0000 - val_loss: 86090928.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 79.7867 - val_distribution_lambda_loss: 86090928.0000 - lr: 0.0010
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 81540800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.2502 - distribution_lambda_loss: 81540800.0000 6/16 [==========>...................] - ETA: 0s - loss: 78691536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.2878 - distribution_lambda_loss: 78691536.000011/16 [===================>..........] - ETA: 0s - loss: 78183632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.9733 - distribution_lambda_loss: 78183632.000016/16 [==============================] - 0s 12ms/step - loss: 78030344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.7810 - distribution_lambda_loss: 78030344.0000 - val_loss: 84225320.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 79.4361 - val_distribution_lambda_loss: 84225320.0000 - lr: 0.0010
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 80651168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.7161 - distribution_lambda_loss: 80651168.0000 6/16 [==========>...................] - ETA: 0s - loss: 79095232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.0555 - distribution_lambda_loss: 79095232.000011/16 [===================>..........] - ETA: 0s - loss: 77750608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.4597 - distribution_lambda_loss: 77750608.000016/16 [==============================] - 0s 12ms/step - loss: 77418272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.5253 - distribution_lambda_loss: 77418272.0000 - val_loss: 82053536.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 77.3374 - val_distribution_lambda_loss: 82053536.0000 - lr: 0.0010
Epoch 21/50
 1/16 [>.............................] - ETA: 0s - loss: 76943840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.8412 - distribution_lambda_loss: 76943840.0000 6/16 [==========>...................] - ETA: 0s - loss: 76206344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.9482 - distribution_lambda_loss: 76206344.000011/16 [===================>..........] - ETA: 0s - loss: 75227336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.5571 - distribution_lambda_loss: 75227336.000016/16 [==============================] - 0s 12ms/step - loss: 75201160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.2481 - distribution_lambda_loss: 75201160.0000 - val_loss: 80732496.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 77.9974 - val_distribution_lambda_loss: 80732496.0000 - lr: 0.0010
Epoch 22/50
 1/16 [>.............................] - ETA: 0s - loss: 74468080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.5848 - distribution_lambda_loss: 74468080.0000 6/16 [==========>...................] - ETA: 0s - loss: 73390432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.3203 - distribution_lambda_loss: 73390432.000011/16 [===================>..........] - ETA: 0s - loss: 72274536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.8129 - distribution_lambda_loss: 72274536.000016/16 [==============================] - 0s 12ms/step - loss: 73045656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.1724 - distribution_lambda_loss: 73045656.0000 - val_loss: 77764536.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 75.3471 - val_distribution_lambda_loss: 77764536.0000 - lr: 0.0010
Epoch 23/50
 1/16 [>.............................] - ETA: 0s - loss: 67727600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.4290 - distribution_lambda_loss: 67727600.0000 6/16 [==========>...................] - ETA: 0s - loss: 70901032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0983 - distribution_lambda_loss: 70901032.000011/16 [===================>..........] - ETA: 0s - loss: 71560056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.4692 - distribution_lambda_loss: 71560056.000016/16 [==============================] - 0s 12ms/step - loss: 71436768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.2556 - distribution_lambda_loss: 71436768.0000 - val_loss: 75565984.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.0755 - val_distribution_lambda_loss: 75565984.0000 - lr: 0.0010
Epoch 24/50
 1/16 [>.............................] - ETA: 0s - loss: 74621848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3466 - distribution_lambda_loss: 74621848.0000 6/16 [==========>...................] - ETA: 0s - loss: 71240200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3253 - distribution_lambda_loss: 71240200.000011/16 [===================>..........] - ETA: 0s - loss: 69573512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3556 - distribution_lambda_loss: 69573512.000016/16 [==============================] - 0s 12ms/step - loss: 69777000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3200 - distribution_lambda_loss: 69777000.0000 - val_loss: 79171016.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.9243 - val_distribution_lambda_loss: 79171016.0000 - lr: 0.0010
Epoch 25/50
 1/16 [>.............................] - ETA: 0s - loss: 74483296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.9567 - distribution_lambda_loss: 74483296.0000 6/16 [==========>...................] - ETA: 0s - loss: 71972840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.0379 - distribution_lambda_loss: 71972840.000011/16 [===================>..........] - ETA: 0s - loss: 70906496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3026 - distribution_lambda_loss: 70906496.0000
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 12ms/step - loss: 71107448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.2191 - distribution_lambda_loss: 71107448.0000 - val_loss: 76297960.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 74.1656 - val_distribution_lambda_loss: 76297960.0000 - lr: 0.0010
Epoch 26/50
 1/16 [>.............................] - ETA: 0s - loss: 68378960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.5218 - distribution_lambda_loss: 68378960.0000 6/16 [==========>...................] - ETA: 0s - loss: 67936280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.6710 - distribution_lambda_loss: 67936280.000011/16 [===================>..........] - ETA: 0s - loss: 67432352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.3478 - distribution_lambda_loss: 67432352.000016/16 [==============================] - 0s 12ms/step - loss: 67583096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.4442 - distribution_lambda_loss: 67583096.0000 - val_loss: 71836056.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.1230 - val_distribution_lambda_loss: 71836056.0000 - lr: 5.0000e-04
Epoch 27/50
 1/16 [>.............................] - ETA: 0s - loss: 66399588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5233 - distribution_lambda_loss: 66399588.0000 6/16 [==========>...................] - ETA: 0s - loss: 66026560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3618 - distribution_lambda_loss: 66026560.000011/16 [===================>..........] - ETA: 0s - loss: 65456700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.0074 - distribution_lambda_loss: 65456700.000016/16 [==============================] - 0s 12ms/step - loss: 65698504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2992 - distribution_lambda_loss: 65698504.0000 - val_loss: 70919448.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.5110 - val_distribution_lambda_loss: 70919448.0000 - lr: 5.0000e-04
Epoch 28/50
 1/16 [>.............................] - ETA: 0s - loss: 60440732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4544 - distribution_lambda_loss: 60440732.0000 6/16 [==========>...................] - ETA: 0s - loss: 65243028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9349 - distribution_lambda_loss: 65243028.000011/16 [===================>..........] - ETA: 0s - loss: 64911500.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7339 - distribution_lambda_loss: 64911500.000016/16 [==============================] - 0s 12ms/step - loss: 65010560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9082 - distribution_lambda_loss: 65010560.0000 - val_loss: 71095984.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.5667 - val_distribution_lambda_loss: 71095984.0000 - lr: 5.0000e-04
Epoch 29/50
 1/16 [>.............................] - ETA: 0s - loss: 60675568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4691 - distribution_lambda_loss: 60675568.0000 6/16 [==========>...................] - ETA: 0s - loss: 65043536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1511 - distribution_lambda_loss: 65043536.000011/16 [===================>..........] - ETA: 0s - loss: 65197244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.0682 - distribution_lambda_loss: 65197244.0000
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
16/16 [==============================] - 0s 12ms/step - loss: 65074592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9514 - distribution_lambda_loss: 65074592.0000 - val_loss: 71481544.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.3867 - val_distribution_lambda_loss: 71481544.0000 - lr: 5.0000e-04
Epoch 30/50
 1/16 [>.............................] - ETA: 0s - loss: 65293188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8857 - distribution_lambda_loss: 65293188.0000 6/16 [==========>...................] - ETA: 0s - loss: 65354512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2922 - distribution_lambda_loss: 65354512.000011/16 [===================>..........] - ETA: 0s - loss: 64025028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4098 - distribution_lambda_loss: 64025028.000016/16 [==============================] - 0s 12ms/step - loss: 64232392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4035 - distribution_lambda_loss: 64232392.0000 - val_loss: 69239768.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.9580 - val_distribution_lambda_loss: 69239768.0000 - lr: 2.5000e-04
Epoch 31/50
 1/16 [>.............................] - ETA: 0s - loss: 62037672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.0208 - distribution_lambda_loss: 62037672.0000 6/16 [==========>...................] - ETA: 0s - loss: 63714608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0514 - distribution_lambda_loss: 63714608.000011/16 [===================>..........] - ETA: 0s - loss: 62826060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6976 - distribution_lambda_loss: 62826060.000016/16 [==============================] - 0s 12ms/step - loss: 63205412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9948 - distribution_lambda_loss: 63205412.0000 - val_loss: 68916592.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.3548 - val_distribution_lambda_loss: 68916592.0000 - lr: 2.5000e-04
Epoch 32/50
 1/16 [>.............................] - ETA: 0s - loss: 66389920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1475 - distribution_lambda_loss: 66389920.0000 6/16 [==========>...................] - ETA: 0s - loss: 63140884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1096 - distribution_lambda_loss: 63140884.000011/16 [===================>..........] - ETA: 0s - loss: 63235324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9754 - distribution_lambda_loss: 63235324.000016/16 [==============================] - ETA: 0s - loss: 62880880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8192 - distribution_lambda_loss: 62880880.000016/16 [==============================] - 0s 12ms/step - loss: 62880880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8192 - distribution_lambda_loss: 62880880.0000 - val_loss: 68902408.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.3520 - val_distribution_lambda_loss: 68902408.0000 - lr: 2.5000e-04
Epoch 33/50
 1/16 [>.............................] - ETA: 0s - loss: 63981032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7752 - distribution_lambda_loss: 63981032.0000 6/16 [==========>...................] - ETA: 0s - loss: 62219296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4903 - distribution_lambda_loss: 62219296.000011/16 [===================>..........] - ETA: 0s - loss: 62821300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8350 - distribution_lambda_loss: 62821300.000016/16 [==============================] - 0s 12ms/step - loss: 62561480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6612 - distribution_lambda_loss: 62561480.0000 - val_loss: 68798856.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.6104 - val_distribution_lambda_loss: 68798856.0000 - lr: 2.5000e-04
Epoch 34/50
 1/16 [>.............................] - ETA: 0s - loss: 59883072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.8459 - distribution_lambda_loss: 59883072.0000 6/16 [==========>...................] - ETA: 0s - loss: 62337732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6082 - distribution_lambda_loss: 62337732.000011/16 [===================>..........] - ETA: 0s - loss: 62502376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5645 - distribution_lambda_loss: 62502376.000016/16 [==============================] - 0s 12ms/step - loss: 62468944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6153 - distribution_lambda_loss: 62468944.0000 - val_loss: 68357720.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.5517 - val_distribution_lambda_loss: 68357720.0000 - lr: 2.5000e-04
Epoch 35/50
 1/16 [>.............................] - ETA: 0s - loss: 60271872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.0818 - distribution_lambda_loss: 60271872.0000 6/16 [==========>...................] - ETA: 0s - loss: 61941684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4286 - distribution_lambda_loss: 61941684.000011/16 [===================>..........] - ETA: 0s - loss: 61973016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4180 - distribution_lambda_loss: 61973016.000016/16 [==============================] - ETA: 0s - loss: 62054248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3906 - distribution_lambda_loss: 62054248.000016/16 [==============================] - 0s 12ms/step - loss: 62054248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3906 - distribution_lambda_loss: 62054248.0000 - val_loss: 68042632.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.6903 - val_distribution_lambda_loss: 68042632.0000 - lr: 2.5000e-04
Epoch 36/50
 1/16 [>.............................] - ETA: 0s - loss: 62669544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7591 - distribution_lambda_loss: 62669544.0000 6/16 [==========>...................] - ETA: 0s - loss: 62503344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7186 - distribution_lambda_loss: 62503344.000011/16 [===================>..........] - ETA: 0s - loss: 61287232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1299 - distribution_lambda_loss: 61287232.000016/16 [==============================] - 0s 12ms/step - loss: 61670328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.2385 - distribution_lambda_loss: 61670328.0000 - val_loss: 67636344.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.1949 - val_distribution_lambda_loss: 67636344.0000 - lr: 2.5000e-04
Epoch 37/50
 1/16 [>.............................] - ETA: 0s - loss: 61119104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.9566 - distribution_lambda_loss: 61119104.0000 6/16 [==========>...................] - ETA: 0s - loss: 59514816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1016 - distribution_lambda_loss: 59514816.000011/16 [===================>..........] - ETA: 0s - loss: 61259652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.9243 - distribution_lambda_loss: 61259652.000016/16 [==============================] - 0s 12ms/step - loss: 61324988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.9614 - distribution_lambda_loss: 61324988.0000 - val_loss: 67437584.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.3198 - val_distribution_lambda_loss: 67437584.0000 - lr: 2.5000e-04
Epoch 38/50
 1/16 [>.............................] - ETA: 0s - loss: 61738100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1245 - distribution_lambda_loss: 61738100.0000 6/16 [==========>...................] - ETA: 0s - loss: 62202820.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4986 - distribution_lambda_loss: 62202820.000011/16 [===================>..........] - ETA: 0s - loss: 61725208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1357 - distribution_lambda_loss: 61725208.000016/16 [==============================] - 0s 12ms/step - loss: 61165816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.9016 - distribution_lambda_loss: 61165816.0000 - val_loss: 67310944.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.5591 - val_distribution_lambda_loss: 67310944.0000 - lr: 2.5000e-04
Epoch 39/50
 1/16 [>.............................] - ETA: 0s - loss: 62915168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6942 - distribution_lambda_loss: 62915168.0000 6/16 [==========>...................] - ETA: 0s - loss: 59747296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1012 - distribution_lambda_loss: 59747296.000011/16 [===================>..........] - ETA: 0s - loss: 60648284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7667 - distribution_lambda_loss: 60648284.000016/16 [==============================] - 0s 12ms/step - loss: 60797668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7215 - distribution_lambda_loss: 60797668.0000 - val_loss: 67085348.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.9574 - val_distribution_lambda_loss: 67085348.0000 - lr: 2.5000e-04
Epoch 40/50
 1/16 [>.............................] - ETA: 0s - loss: 60169124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9762 - distribution_lambda_loss: 60169124.0000 6/16 [==========>...................] - ETA: 0s - loss: 59538900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8145 - distribution_lambda_loss: 59538900.000011/16 [===================>..........] - ETA: 0s - loss: 60378688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3669 - distribution_lambda_loss: 60378688.000016/16 [==============================] - 0s 12ms/step - loss: 60530540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.5062 - distribution_lambda_loss: 60530540.0000 - val_loss: 67034584.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.9922 - val_distribution_lambda_loss: 67034584.0000 - lr: 2.5000e-04
Epoch 41/50
 1/16 [>.............................] - ETA: 0s - loss: 57169132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2226 - distribution_lambda_loss: 57169132.0000 6/16 [==========>...................] - ETA: 0s - loss: 60097452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4314 - distribution_lambda_loss: 60097452.000011/16 [===================>..........] - ETA: 0s - loss: 60534900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.5491 - distribution_lambda_loss: 60534900.000016/16 [==============================] - 0s 12ms/step - loss: 60658356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6654 - distribution_lambda_loss: 60658356.0000 - val_loss: 66853264.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.8397 - val_distribution_lambda_loss: 66853264.0000 - lr: 2.5000e-04
Epoch 42/50
 1/16 [>.............................] - ETA: 0s - loss: 59199092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.2128 - distribution_lambda_loss: 59199092.0000 6/16 [==========>...................] - ETA: 0s - loss: 59811108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2259 - distribution_lambda_loss: 59811108.000012/16 [=====================>........] - ETA: 0s - loss: 60082788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3734 - distribution_lambda_loss: 60082788.000016/16 [==============================] - 0s 12ms/step - loss: 60438904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.5833 - distribution_lambda_loss: 60438904.0000 - val_loss: 67329192.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.9591 - val_distribution_lambda_loss: 67329192.0000 - lr: 2.5000e-04
Epoch 43/50
 1/16 [>.............................] - ETA: 0s - loss: 57640732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.2362 - distribution_lambda_loss: 57640732.0000 6/16 [==========>...................] - ETA: 0s - loss: 59998340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1510 - distribution_lambda_loss: 59998340.000011/16 [===================>..........] - ETA: 0s - loss: 60519472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4408 - distribution_lambda_loss: 60519472.000016/16 [==============================] - 0s 12ms/step - loss: 60191504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2811 - distribution_lambda_loss: 60191504.0000 - val_loss: 66402604.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.1552 - val_distribution_lambda_loss: 66402604.0000 - lr: 2.5000e-04
Epoch 44/50
 1/16 [>.............................] - ETA: 0s - loss: 60796764.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1841 - distribution_lambda_loss: 60796764.0000 6/16 [==========>...................] - ETA: 0s - loss: 59533460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1877 - distribution_lambda_loss: 59533460.000011/16 [===================>..........] - ETA: 0s - loss: 59432524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1108 - distribution_lambda_loss: 59432524.000016/16 [==============================] - 0s 12ms/step - loss: 59768472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1959 - distribution_lambda_loss: 59768472.0000 - val_loss: 66601168.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.5014 - val_distribution_lambda_loss: 66601168.0000 - lr: 2.5000e-04
Epoch 45/50
 1/16 [>.............................] - ETA: 0s - loss: 60491800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7973 - distribution_lambda_loss: 60491800.0000 6/16 [==========>...................] - ETA: 0s - loss: 59138572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8171 - distribution_lambda_loss: 59138572.000011/16 [===================>..........] - ETA: 0s - loss: 60327792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4364 - distribution_lambda_loss: 60327792.000016/16 [==============================] - 0s 12ms/step - loss: 59799640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1249 - distribution_lambda_loss: 59799640.0000 - val_loss: 65980028.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.7134 - val_distribution_lambda_loss: 65980028.0000 - lr: 2.5000e-04
Epoch 46/50
 1/16 [>.............................] - ETA: 0s - loss: 58302048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.6350 - distribution_lambda_loss: 58302048.0000 6/16 [==========>...................] - ETA: 0s - loss: 59037360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7113 - distribution_lambda_loss: 59037360.000011/16 [===================>..........] - ETA: 0s - loss: 59589040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1234 - distribution_lambda_loss: 59589040.000016/16 [==============================] - ETA: 0s - loss: 59488020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0370 - distribution_lambda_loss: 59488020.000016/16 [==============================] - 0s 12ms/step - loss: 59488020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0370 - distribution_lambda_loss: 59488020.0000 - val_loss: 66302564.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0471 - val_distribution_lambda_loss: 66302564.0000 - lr: 2.5000e-04
Epoch 47/50
 1/16 [>.............................] - ETA: 0s - loss: 58729872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6500 - distribution_lambda_loss: 58729872.0000 6/16 [==========>...................] - ETA: 0s - loss: 59650572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3165 - distribution_lambda_loss: 59650572.000011/16 [===================>..........] - ETA: 0s - loss: 58840396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7777 - distribution_lambda_loss: 58840396.000016/16 [==============================] - 0s 12ms/step - loss: 59125700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8556 - distribution_lambda_loss: 59125700.0000 - val_loss: 65544596.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.4390 - val_distribution_lambda_loss: 65544596.0000 - lr: 2.5000e-04
Epoch 48/50
 1/16 [>.............................] - ETA: 0s - loss: 57172892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0577 - distribution_lambda_loss: 57172892.0000 6/16 [==========>...................] - ETA: 0s - loss: 58394940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.5348 - distribution_lambda_loss: 58394940.000011/16 [===================>..........] - ETA: 0s - loss: 58655116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7049 - distribution_lambda_loss: 58655116.000016/16 [==============================] - 0s 12ms/step - loss: 58753984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.6299 - distribution_lambda_loss: 58753984.0000 - val_loss: 67194552.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.2348 - val_distribution_lambda_loss: 67194552.0000 - lr: 2.5000e-04
Epoch 49/50
 1/16 [>.............................] - ETA: 0s - loss: 57432040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.3547 - distribution_lambda_loss: 57432040.0000 6/16 [==========>...................] - ETA: 0s - loss: 59110492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7369 - distribution_lambda_loss: 59110492.000011/16 [===================>..........] - ETA: 0s - loss: 60449776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4187 - distribution_lambda_loss: 60449776.0000
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
16/16 [==============================] - 0s 12ms/step - loss: 60002864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3174 - distribution_lambda_loss: 60002864.0000 - val_loss: 66025060.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.2487 - val_distribution_lambda_loss: 66025060.0000 - lr: 2.5000e-04
Epoch 50/50
 1/16 [>.............................] - ETA: 0s - loss: 66529968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3738 - distribution_lambda_loss: 66529968.0000 6/16 [==========>...................] - ETA: 0s - loss: 60629196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4784 - distribution_lambda_loss: 60629196.000011/16 [===================>..........] - ETA: 0s - loss: 59113676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.6464 - distribution_lambda_loss: 59113676.000016/16 [==============================] - 0s 12ms/step - loss: 58623160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.4789 - distribution_lambda_loss: 58623160.0000 - val_loss: 65049856.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.5816 - val_distribution_lambda_loss: 65049856.0000 - lr: 1.2500e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:29  4/322 [..............................] - ETA: 5s    8/322 [..............................] - ETA: 5s 12/322 [>.............................] - ETA: 5s 16/322 [>.............................] - ETA: 5s 19/322 [>.............................] - ETA: 5s 23/322 [=>............................] - ETA: 4s 27/322 [=>............................] - ETA: 4s 31/322 [=>............................] - ETA: 4s 35/322 [==>...........................] - ETA: 4s 39/322 [==>...........................] - ETA: 4s 43/322 [===>..........................] - ETA: 4s 46/322 [===>..........................] - ETA: 4s 50/322 [===>..........................] - ETA: 4s 53/322 [===>..........................] - ETA: 4s 56/322 [====>.........................] - ETA: 4s 59/322 [====>.........................] - ETA: 4s 62/322 [====>.........................] - ETA: 4s 66/322 [=====>........................] - ETA: 4s 69/322 [=====>........................] - ETA: 4s 73/322 [=====>........................] - ETA: 4s 76/322 [======>.......................] - ETA: 4s 80/322 [======>.......................] - ETA: 4s 84/322 [======>.......................] - ETA: 3s 87/322 [=======>......................] - ETA: 3s 90/322 [=======>......................] - ETA: 3s 94/322 [=======>......................] - ETA: 3s 98/322 [========>.....................] - ETA: 3s102/322 [========>.....................] - ETA: 3s105/322 [========>.....................] - ETA: 3s109/322 [=========>....................] - ETA: 3s113/322 [=========>....................] - ETA: 3s117/322 [=========>....................] - ETA: 3s120/322 [==========>...................] - ETA: 3s123/322 [==========>...................] - ETA: 3s127/322 [==========>...................] - ETA: 3s131/322 [===========>..................] - ETA: 3s135/322 [===========>..................] - ETA: 3s139/322 [===========>..................] - ETA: 3s143/322 [============>.................] - ETA: 2s147/322 [============>.................] - ETA: 2s151/322 [=============>................] - ETA: 2s155/322 [=============>................] - ETA: 2s158/322 [=============>................] - ETA: 2s161/322 [==============>...............] - ETA: 2s165/322 [==============>...............] - ETA: 2s168/322 [==============>...............] - ETA: 2s172/322 [===============>..............] - ETA: 2s176/322 [===============>..............] - ETA: 2s180/322 [===============>..............] - ETA: 2s184/322 [================>.............] - ETA: 2s188/322 [================>.............] - ETA: 2s192/322 [================>.............] - ETA: 2s196/322 [=================>............] - ETA: 2s199/322 [=================>............] - ETA: 2s203/322 [=================>............] - ETA: 1s207/322 [==================>...........] - ETA: 1s211/322 [==================>...........] - ETA: 1s215/322 [===================>..........] - ETA: 1s218/322 [===================>..........] - ETA: 1s222/322 [===================>..........] - ETA: 1s225/322 [===================>..........] - ETA: 1s228/322 [====================>.........] - ETA: 1s231/322 [====================>.........] - ETA: 1s235/322 [====================>.........] - ETA: 1s239/322 [=====================>........] - ETA: 1s243/322 [=====================>........] - ETA: 1s246/322 [=====================>........] - ETA: 1s250/322 [======================>.......] - ETA: 1s254/322 [======================>.......] - ETA: 1s258/322 [=======================>......] - ETA: 1s262/322 [=======================>......] - ETA: 0s265/322 [=======================>......] - ETA: 0s268/322 [=======================>......] - ETA: 0s272/322 [========================>.....] - ETA: 0s276/322 [========================>.....] - ETA: 0s280/322 [=========================>....] - ETA: 0s284/322 [=========================>....] - ETA: 0s287/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s295/322 [==========================>...] - ETA: 0s299/322 [==========================>...] - ETA: 0s303/322 [===========================>..] - ETA: 0s307/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s314/322 [============================>.] - ETA: 0s318/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 7s 16ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:09:40,880 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:09:43,934 - INFO - Assets written to: /tmp/tmpxxf8m_mz/autoencoder/assets
2025-07-27 21:09:43,982 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:09:45,612 - INFO - Assets written to: /tmp/tmpxxf8m_mz/diffraction_to_obj/assets
2025-07-27 21:09:46,615 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run
[2025-07-27 21:09:47] SUCCESS: PtychoPINN training (n_images=256, trial=2)
[2025-07-27 21:09:47] EXECUTING: Baseline training (n_images=256, trial=2)
[2025-07-27 21:09:47] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run' \
            --nepochs 50
2025-07-27 21:09:47.998713: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:09:47.998740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:09:47.999564: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:09:48.003924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:09:48.474908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:09:49.301397: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.334829: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.337115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:09:49.595495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.597812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.599942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.713428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.714634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.715745: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:09:49.715883: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:09:49.717001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:09:49,996 - INFO - Configuration setup complete
2025-07-27 21:09:49,996 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run'))
2025-07-27 21:09:49,997 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:09:49,997 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:09:49,997 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1/
2025-07-27 21:09:49,997 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:09:50,010 - INFO - 
[2/6] Loading data...
2025-07-27 21:09:50,010 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:09:50,010 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:09:50,043 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
2025-07-27 21:09:50,043 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:09:50,120 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:10:07,601 - INFO - Globally set intensity_scale to: 988.211669921875
2025-07-27 21:10:07,601 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:10:07,603 - INFO - Final training input shape: (256, 64, 64, 1)
2025-07-27 21:10:07,603 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:10:07,603 - INFO - Training with 256 images
DEBUG: Setting timestamp to 07/27/2025, 21:09:49 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:09:49
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.2117, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:10:08.942832: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:10:09.717339: I external/local_xla/xla/service/service.cc:168] XLA service 0x7531fac63bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:10:09.717363: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:10:09.720987: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675809.785369 3707400 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:06 - loss: 3.5861 - conv2d_12_loss: 1.2298 - conv2d_19_loss: 2.3564 6/16 [==========>...................] - ETA: 0s - loss: 3.1224 - conv2d_12_loss: 0.9918 - conv2d_19_loss: 2.1306  11/16 [===================>..........] - ETA: 0s - loss: 2.7848 - conv2d_12_loss: 0.8118 - conv2d_19_loss: 1.973016/16 [==============================] - ETA: 0s - loss: 2.3694 - conv2d_12_loss: 0.6875 - conv2d_19_loss: 1.681916/16 [==============================] - 6s 127ms/step - loss: 2.3694 - conv2d_12_loss: 0.6875 - conv2d_19_loss: 1.6819 - val_loss: 1.2170 - val_conv2d_12_loss: 0.3842 - val_conv2d_19_loss: 0.8328 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 1.2235 - conv2d_12_loss: 0.3855 - conv2d_19_loss: 0.8380 6/16 [==========>...................] - ETA: 0s - loss: 0.9754 - conv2d_12_loss: 0.3031 - conv2d_19_loss: 0.672411/16 [===================>..........] - ETA: 0s - loss: 0.8917 - conv2d_12_loss: 0.2758 - conv2d_19_loss: 0.616016/16 [==============================] - 0s 12ms/step - loss: 0.8481 - conv2d_12_loss: 0.2601 - conv2d_19_loss: 0.5879 - val_loss: 0.6923 - val_conv2d_12_loss: 0.2216 - val_conv2d_19_loss: 0.4706 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 0.6989 - conv2d_12_loss: 0.2206 - conv2d_19_loss: 0.4782 6/16 [==========>...................] - ETA: 0s - loss: 0.6487 - conv2d_12_loss: 0.1922 - conv2d_19_loss: 0.456611/16 [===================>..........] - ETA: 0s - loss: 0.6195 - conv2d_12_loss: 0.1792 - conv2d_19_loss: 0.440216/16 [==============================] - 0s 11ms/step - loss: 0.5941 - conv2d_12_loss: 0.1707 - conv2d_19_loss: 0.4235 - val_loss: 0.5038 - val_conv2d_12_loss: 0.1439 - val_conv2d_19_loss: 0.3599 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 0.4995 - conv2d_12_loss: 0.1404 - conv2d_19_loss: 0.3592 6/16 [==========>...................] - ETA: 0s - loss: 0.4780 - conv2d_12_loss: 0.1365 - conv2d_19_loss: 0.341511/16 [===================>..........] - ETA: 0s - loss: 0.4608 - conv2d_12_loss: 0.1328 - conv2d_19_loss: 0.328016/16 [==============================] - 0s 11ms/step - loss: 0.4486 - conv2d_12_loss: 0.1295 - conv2d_19_loss: 0.3192 - val_loss: 0.4140 - val_conv2d_12_loss: 0.1184 - val_conv2d_19_loss: 0.2956 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3962 - conv2d_12_loss: 0.1161 - conv2d_19_loss: 0.2801 6/16 [==========>...................] - ETA: 0s - loss: 0.4004 - conv2d_12_loss: 0.1157 - conv2d_19_loss: 0.284711/16 [===================>..........] - ETA: 0s - loss: 0.3936 - conv2d_12_loss: 0.1135 - conv2d_19_loss: 0.280116/16 [==============================] - 0s 11ms/step - loss: 0.3893 - conv2d_12_loss: 0.1118 - conv2d_19_loss: 0.2776 - val_loss: 0.3760 - val_conv2d_12_loss: 0.1066 - val_conv2d_19_loss: 0.2694 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3708 - conv2d_12_loss: 0.1048 - conv2d_19_loss: 0.2660 6/16 [==========>...................] - ETA: 0s - loss: 0.3670 - conv2d_12_loss: 0.1041 - conv2d_19_loss: 0.262911/16 [===================>..........] - ETA: 0s - loss: 0.3621 - conv2d_12_loss: 0.1028 - conv2d_19_loss: 0.259316/16 [==============================] - 0s 12ms/step - loss: 0.3534 - conv2d_12_loss: 0.1011 - conv2d_19_loss: 0.2523 - val_loss: 0.3401 - val_conv2d_12_loss: 0.1000 - val_conv2d_19_loss: 0.2401 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3365 - conv2d_12_loss: 0.0979 - conv2d_19_loss: 0.2386 6/16 [==========>...................] - ETA: 0s - loss: 0.3328 - conv2d_12_loss: 0.0960 - conv2d_19_loss: 0.236711/16 [===================>..........] - ETA: 0s - loss: 0.3303 - conv2d_12_loss: 0.0951 - conv2d_19_loss: 0.235216/16 [==============================] - 0s 11ms/step - loss: 0.3277 - conv2d_12_loss: 0.0939 - conv2d_19_loss: 0.2337 - val_loss: 0.3279 - val_conv2d_12_loss: 0.0961 - val_conv2d_19_loss: 0.2318 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3314 - conv2d_12_loss: 0.0969 - conv2d_19_loss: 0.2345 6/16 [==========>...................] - ETA: 0s - loss: 0.3174 - conv2d_12_loss: 0.0905 - conv2d_19_loss: 0.226911/16 [===================>..........] - ETA: 0s - loss: 0.3187 - conv2d_12_loss: 0.0898 - conv2d_19_loss: 0.228916/16 [==============================] - 0s 11ms/step - loss: 0.3185 - conv2d_12_loss: 0.0895 - conv2d_19_loss: 0.2290 - val_loss: 0.3200 - val_conv2d_12_loss: 0.0877 - val_conv2d_19_loss: 0.2323 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2281 6/16 [==========>...................] - ETA: 0s - loss: 0.3144 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.228511/16 [===================>..........] - ETA: 0s - loss: 0.3163 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.229916/16 [==============================] - 0s 11ms/step - loss: 0.3147 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2284 - val_loss: 0.3186 - val_conv2d_12_loss: 0.0878 - val_conv2d_19_loss: 0.2308 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3263 - conv2d_12_loss: 0.0872 - conv2d_19_loss: 0.2390 6/16 [==========>...................] - ETA: 0s - loss: 0.3221 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.234511/16 [===================>..........] - ETA: 0s - loss: 0.3185 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.231316/16 [==============================] - 0s 11ms/step - loss: 0.3145 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2287 - val_loss: 0.3235 - val_conv2d_12_loss: 0.0877 - val_conv2d_19_loss: 0.2358 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3250 - conv2d_12_loss: 0.0897 - conv2d_19_loss: 0.2353 6/16 [==========>...................] - ETA: 0s - loss: 0.3168 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.230211/16 [===================>..........] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.227916/16 [==============================] - 0s 11ms/step - loss: 0.3131 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2277 - val_loss: 0.3180 - val_conv2d_12_loss: 0.0882 - val_conv2d_19_loss: 0.2298 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2232 6/16 [==========>...................] - ETA: 0s - loss: 0.3152 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.228911/16 [===================>..........] - ETA: 0s - loss: 0.3127 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.227316/16 [==============================] - 0s 11ms/step - loss: 0.3123 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2269 - val_loss: 0.3163 - val_conv2d_12_loss: 0.0870 - val_conv2d_19_loss: 0.2293 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2891 - conv2d_12_loss: 0.0801 - conv2d_19_loss: 0.2090 6/16 [==========>...................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.224111/16 [===================>..........] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.225316/16 [==============================] - 0s 11ms/step - loss: 0.3128 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2272 - val_loss: 0.3155 - val_conv2d_12_loss: 0.0868 - val_conv2d_19_loss: 0.2286 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3054 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2216 6/16 [==========>...................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.226311/16 [===================>..........] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.226416/16 [==============================] - 0s 11ms/step - loss: 0.3122 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2267 - val_loss: 0.3214 - val_conv2d_12_loss: 0.0870 - val_conv2d_19_loss: 0.2344 - lr: 0.0010
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3138 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2293 6/16 [==========>...................] - ETA: 0s - loss: 0.3190 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.233711/16 [===================>..........] - ETA: 0s - loss: 0.3227 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2363
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 11ms/step - loss: 0.3209 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2350 - val_loss: 0.3170 - val_conv2d_12_loss: 0.0869 - val_conv2d_19_loss: 0.2301 - lr: 0.0010
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3160 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2293 6/16 [==========>...................] - ETA: 0s - loss: 0.3182 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.232111/16 [===================>..........] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.225816/16 [==============================] - 0s 11ms/step - loss: 0.3112 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2264 - val_loss: 0.3144 - val_conv2d_12_loss: 0.0865 - val_conv2d_19_loss: 0.2279 - lr: 5.0000e-04
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3220 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2348 6/16 [==========>...................] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.225211/16 [===================>..........] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.226516/16 [==============================] - 0s 11ms/step - loss: 0.3103 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2255 - val_loss: 0.3146 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2281 - lr: 5.0000e-04
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3148 - conv2d_12_loss: 0.0874 - conv2d_19_loss: 0.2274 6/16 [==========>...................] - ETA: 0s - loss: 0.3072 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.222811/16 [===================>..........] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.223616/16 [==============================] - 0s 11ms/step - loss: 0.3108 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2258 - val_loss: 0.3140 - val_conv2d_12_loss: 0.0863 - val_conv2d_19_loss: 0.2277 - lr: 5.0000e-04
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3084 - conv2d_12_loss: 0.0833 - conv2d_19_loss: 0.2252 6/16 [==========>...................] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.223911/16 [===================>..........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.226216/16 [==============================] - 0s 11ms/step - loss: 0.3109 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2255 - val_loss: 0.3149 - val_conv2d_12_loss: 0.0868 - val_conv2d_19_loss: 0.2282 - lr: 5.0000e-04
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3151 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2284 6/16 [==========>...................] - ETA: 0s - loss: 0.3175 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.231111/16 [===================>..........] - ETA: 0s - loss: 0.3130 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2273
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
16/16 [==============================] - 0s 11ms/step - loss: 0.3105 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2255 - val_loss: 0.3147 - val_conv2d_12_loss: 0.0865 - val_conv2d_19_loss: 0.2282 - lr: 5.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:10:17,689 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1/baseline_model.h5
2025-07-27 21:10:17,689 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:38 12/322 [>.............................] - ETA: 1s   22/322 [=>............................] - ETA: 1s 32/322 [=>............................] - ETA: 1s 42/322 [==>...........................] - ETA: 1s 52/322 [===>..........................] - ETA: 1s 62/322 [====>.........................] - ETA: 1s 72/322 [=====>........................] - ETA: 1s 82/322 [======>.......................] - ETA: 1s 92/322 [=======>......................] - ETA: 1s102/322 [========>.....................] - ETA: 1s112/322 [=========>....................] - ETA: 1s122/322 [==========>...................] - ETA: 1s132/322 [===========>..................] - ETA: 1s142/322 [============>.................] - ETA: 0s152/322 [=============>................] - ETA: 0s162/322 [==============>...............] - ETA: 0s172/322 [===============>..............] - ETA: 0s182/322 [===============>..............] - ETA: 0s192/322 [================>.............] - ETA: 0s202/322 [=================>............] - ETA: 0s212/322 [==================>...........] - ETA: 0s222/322 [===================>..........] - ETA: 0s232/322 [====================>.........] - ETA: 0s242/322 [=====================>........] - ETA: 0s252/322 [======================>.......] - ETA: 0s262/322 [=======================>......] - ETA: 0s272/322 [========================>.....] - ETA: 0s282/322 [=========================>....] - ETA: 0s292/322 [==========================>...] - ETA: 0s302/322 [===========================>..] - ETA: 0s312/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:10:21,152 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:10:21,153 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:10:21,153 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:10:21,153 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:10:21,153 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:10:21,153 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:10:21,153 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:10:21,153 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:10:21,153 - INFO - --- Alignment complete ---
2025-07-27 21:10:21,153 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:10:21,244 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:10:21,244 - INFO -   MAE:  (0.084969655, 0.25116840968625576)
2025-07-27 21:10:21,244 - INFO -   PSNR: (68.30957422072831, 58.98274200335686)
2025-07-27 21:10:21,346 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:10:21,346 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 0.980835
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.256699, std=0.000593, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.000910, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.980835
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.256699, std=0.000593, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.000910, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:10:22] SUCCESS: Baseline training (n_images=256, trial=2)
[2025-07-27 21:10:22] EXECUTING: Tike reconstruction (n_images=512, trial=2)
[2025-07-27 21:10:22] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_256/trial_2/tike_run' \
                --n-images 512 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:11:05] SUCCESS: Tike reconstruction (n_images=512, trial=2)
[2025-07-27 21:11:05] Completed training for train_size=256 (Trial 2/3)
[2025-07-27 21:11:05] Training models for train_size=256, test_size=512 (Trial 3/3)
[2025-07-27 21:11:05] EXECUTING: PtychoPINN training (n_images=256, trial=3)
[2025-07-27 21:11:05] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run' \
            --nepochs 50
2025-07-27 21:11:05.924571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:11:05.924601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:11:05.925431: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:11:05.929578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:11:06.429388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:11:07.527213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.561003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.563236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:11:07.727598: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.729847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.732005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.848418: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.849937: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.851171: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:11:07.851310: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:11:07.852447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:11:07,881 - INFO - Configuration setup complete
2025-07-27 21:11:07,881 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run'))
2025-07-27 21:11:07,881 - INFO - Parameter interpretation: --n-images=256 refers to individual images (gridsize=1)
2025-07-27 21:11:07,881 - INFO - Starting training with n_images=256, stitching=disabled
2025-07-27 21:11:07,881 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:11:07,915 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
2025-07-27 21:11:07,915 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:11:07,990 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:11:07,990 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:11:26,433 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:11:26.560453: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:11:26.560468: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:11:26.560492: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:11:26.577401: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:11:26.577487: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:11:26,579 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:11:27,248 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:11:27,255 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:11:28,290 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:11:28,297 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:11:29.011033: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:11:29.011524: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x1ba7eea0
2025-07-27 21:11:30.263705: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f2c34367f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:11:30.263733: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:11:30.266882: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675890.337739 3709913 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:44 - loss: 696071680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 175.5472 - distribution_lambda_loss: 696071680.0000 5/16 [========>.....................] - ETA: 0s - loss: 26547349504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1061.4652 - distribution_lambda_loss: 26547349504.000010/16 [=================>............] - ETA: 0s - loss: 13615828992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 614.5747 - distribution_lambda_loss: 13615828992.0000 15/16 [===========================>..] - ETA: 0s - loss: 9289155584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 466.7091 - distribution_lambda_loss: 9289155584.0000  16/16 [==============================] - ETA: 0s - loss: 9180632064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 462.7570 - distribution_lambda_loss: 9180632064.0000input shape (None, 64, 64, 1)
16/16 [==============================] - 9s 134ms/step - loss: 9180632064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 462.7570 - distribution_lambda_loss: 9180632064.0000 - val_loss: 489832896.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 197.1149 - val_distribution_lambda_loss: 489832896.0000 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 512387904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 199.6619 - distribution_lambda_loss: 512387904.0000 6/16 [==========>...................] - ETA: 0s - loss: 535311776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 203.4751 - distribution_lambda_loss: 535311776.000011/16 [===================>..........] - ETA: 0s - loss: 484267648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 192.3277 - distribution_lambda_loss: 484267648.000016/16 [==============================] - ETA: 0s - loss: 460756672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 185.2039 - distribution_lambda_loss: 460756672.000016/16 [==============================] - 0s 14ms/step - loss: 460756672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 185.2039 - distribution_lambda_loss: 460756672.0000 - val_loss: 331173952.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 155.9059 - val_distribution_lambda_loss: 331173952.0000 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 334927520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 158.3012 - distribution_lambda_loss: 334927520.0000 6/16 [==========>...................] - ETA: 0s - loss: 338494816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 160.4980 - distribution_lambda_loss: 338494816.000011/16 [===================>..........] - ETA: 0s - loss: 313947776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 154.0988 - distribution_lambda_loss: 313947776.000016/16 [==============================] - ETA: 0s - loss: 294494912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 149.0669 - distribution_lambda_loss: 294494912.000016/16 [==============================] - 0s 13ms/step - loss: 294494912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 149.0669 - distribution_lambda_loss: 294494912.0000 - val_loss: 238962320.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 150.4584 - val_distribution_lambda_loss: 238962320.0000 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 260017024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 155.9598 - distribution_lambda_loss: 260017024.0000 6/16 [==========>...................] - ETA: 0s - loss: 215413712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 131.4553 - distribution_lambda_loss: 215413712.000011/16 [===================>..........] - ETA: 0s - loss: 205786432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.7094 - distribution_lambda_loss: 205786432.000016/16 [==============================] - ETA: 0s - loss: 196613936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 126.1356 - distribution_lambda_loss: 196613936.000016/16 [==============================] - 0s 13ms/step - loss: 196613936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 126.1356 - distribution_lambda_loss: 196613936.0000 - val_loss: 168726560.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 113.7519 - val_distribution_lambda_loss: 168726560.0000 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 163169712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.1384 - distribution_lambda_loss: 163169712.0000 6/16 [==========>...................] - ETA: 0s - loss: 161999328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.8033 - distribution_lambda_loss: 161999328.000011/16 [===================>..........] - ETA: 0s - loss: 155690576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.1006 - distribution_lambda_loss: 155690576.000016/16 [==============================] - ETA: 0s - loss: 151272000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.5831 - distribution_lambda_loss: 151272000.000016/16 [==============================] - 0s 13ms/step - loss: 151272000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.5831 - distribution_lambda_loss: 151272000.0000 - val_loss: 146631680.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 108.6552 - val_distribution_lambda_loss: 146631680.0000 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 136427072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.8877 - distribution_lambda_loss: 136427072.0000 6/16 [==========>...................] - ETA: 0s - loss: 135312384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7895 - distribution_lambda_loss: 135312384.000011/16 [===================>..........] - ETA: 0s - loss: 131790544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4203 - distribution_lambda_loss: 131790544.000015/16 [===========================>..] - ETA: 0s - loss: 130702256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6725 - distribution_lambda_loss: 130702256.000016/16 [==============================] - 0s 13ms/step - loss: 130625824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6283 - distribution_lambda_loss: 130625824.0000 - val_loss: 132132664.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.2178 - val_distribution_lambda_loss: 132132664.0000 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 125113256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0089 - distribution_lambda_loss: 125113256.0000 6/16 [==========>...................] - ETA: 0s - loss: 121588032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4491 - distribution_lambda_loss: 121588032.0000 11/16 [===================>..........] - ETA: 0s - loss: 117964192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.4552 - distribution_lambda_loss: 117964192.000016/16 [==============================] - ETA: 0s - loss: 117227096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.7448 - distribution_lambda_loss: 117227096.000016/16 [==============================] - 0s 14ms/step - loss: 117227096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.7448 - distribution_lambda_loss: 117227096.0000 - val_loss: 118650400.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 94.9857 - val_distribution_lambda_loss: 118650400.0000 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 120581728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.8486 - distribution_lambda_loss: 120581728.0000 6/16 [==========>...................] - ETA: 0s - loss: 111013256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.9623 - distribution_lambda_loss: 111013256.000011/16 [===================>..........] - ETA: 0s - loss: 108190368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.5589 - distribution_lambda_loss: 108190368.000016/16 [==============================] - ETA: 0s - loss: 107369992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.0311 - distribution_lambda_loss: 107369992.000016/16 [==============================] - 0s 13ms/step - loss: 107369992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.0311 - distribution_lambda_loss: 107369992.0000 - val_loss: 109662960.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 87.7270 - val_distribution_lambda_loss: 109662960.0000 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 107281872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.4367 - distribution_lambda_loss: 107281872.0000 6/16 [==========>...................] - ETA: 0s - loss: 103491968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.0860 - distribution_lambda_loss: 103491968.000011/16 [===================>..........] - ETA: 0s - loss: 102104352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.8747 - distribution_lambda_loss: 102104352.000016/16 [==============================] - ETA: 0s - loss: 101253616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.5086 - distribution_lambda_loss: 101253616.000016/16 [==============================] - 0s 13ms/step - loss: 101253616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.5086 - distribution_lambda_loss: 101253616.0000 - val_loss: 104156064.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 86.1988 - val_distribution_lambda_loss: 104156064.0000 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 103501200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.0183 - distribution_lambda_loss: 103501200.0000 5/16 [========>.....................] - ETA: 0s - loss: 98112752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.9381 - distribution_lambda_loss: 98112752.0000  10/16 [=================>............] - ETA: 0s - loss: 97034312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.5414 - distribution_lambda_loss: 97034312.000015/16 [===========================>..] - ETA: 0s - loss: 97163904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.5047 - distribution_lambda_loss: 97163904.000016/16 [==============================] - 0s 14ms/step - loss: 97160296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.4369 - distribution_lambda_loss: 97160296.0000 - val_loss: 100397368.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 86.0049 - val_distribution_lambda_loss: 100397368.0000 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 96383920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.0627 - distribution_lambda_loss: 96383920.0000 6/16 [==========>...................] - ETA: 0s - loss: 94768056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.8600 - distribution_lambda_loss: 94768056.000011/16 [===================>..........] - ETA: 0s - loss: 94918992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.2994 - distribution_lambda_loss: 94918992.000016/16 [==============================] - ETA: 0s - loss: 92798568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 83.3298 - distribution_lambda_loss: 92798568.000016/16 [==============================] - 0s 13ms/step - loss: 92798568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 83.3298 - distribution_lambda_loss: 92798568.0000 - val_loss: 94698416.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 83.3419 - val_distribution_lambda_loss: 94698416.0000 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 91831168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 82.9447 - distribution_lambda_loss: 91831168.0000 6/16 [==========>...................] - ETA: 0s - loss: 90924096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.4871 - distribution_lambda_loss: 90924096.000011/16 [===================>..........] - ETA: 0s - loss: 90586576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.8891 - distribution_lambda_loss: 90586576.000016/16 [==============================] - ETA: 0s - loss: 89616752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.2891 - distribution_lambda_loss: 89616752.000016/16 [==============================] - 0s 13ms/step - loss: 89616752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.2891 - distribution_lambda_loss: 89616752.0000 - val_loss: 96519344.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 84.3726 - val_distribution_lambda_loss: 96519344.0000 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 91641728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 82.8761 - distribution_lambda_loss: 91641728.0000 6/16 [==========>...................] - ETA: 0s - loss: 88321960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.3210 - distribution_lambda_loss: 88321960.000011/16 [===================>..........] - ETA: 0s - loss: 87095296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.1394 - distribution_lambda_loss: 87095296.000016/16 [==============================] - ETA: 0s - loss: 86401056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.4615 - distribution_lambda_loss: 86401056.000016/16 [==============================] - 0s 13ms/step - loss: 86401056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.4615 - distribution_lambda_loss: 86401056.0000 - val_loss: 89843416.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 80.6256 - val_distribution_lambda_loss: 89843416.0000 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 85008984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.7874 - distribution_lambda_loss: 85008984.0000 6/16 [==========>...................] - ETA: 0s - loss: 84667736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.5761 - distribution_lambda_loss: 84667736.000011/16 [===================>..........] - ETA: 0s - loss: 84942648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.7326 - distribution_lambda_loss: 84942648.000015/16 [===========================>..] - ETA: 0s - loss: 84665552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.5418 - distribution_lambda_loss: 84665552.000016/16 [==============================] - 0s 14ms/step - loss: 84663224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.4968 - distribution_lambda_loss: 84663224.0000 - val_loss: 89665824.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 82.9234 - val_distribution_lambda_loss: 89665824.0000 - lr: 0.0010
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 77873536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.7284 - distribution_lambda_loss: 77873536.0000 6/16 [==========>...................] - ETA: 0s - loss: 83173008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.5784 - distribution_lambda_loss: 83173008.000011/16 [===================>..........] - ETA: 0s - loss: 81638560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.9969 - distribution_lambda_loss: 81638560.000016/16 [==============================] - ETA: 0s - loss: 81145512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.7396 - distribution_lambda_loss: 81145512.000016/16 [==============================] - 0s 14ms/step - loss: 81145512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.7396 - distribution_lambda_loss: 81145512.0000 - val_loss: 86129848.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 78.0618 - val_distribution_lambda_loss: 86129848.0000 - lr: 0.0010
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 75295264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.4416 - distribution_lambda_loss: 75295264.0000 6/16 [==========>...................] - ETA: 0s - loss: 79799448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.6885 - distribution_lambda_loss: 79799448.000011/16 [===================>..........] - ETA: 0s - loss: 80160224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.0175 - distribution_lambda_loss: 80160224.000016/16 [==============================] - ETA: 0s - loss: 80269248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1945 - distribution_lambda_loss: 80269248.000016/16 [==============================] - 0s 13ms/step - loss: 80269248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1945 - distribution_lambda_loss: 80269248.0000 - val_loss: 83440840.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 76.2629 - val_distribution_lambda_loss: 83440840.0000 - lr: 0.0010
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 78078928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.6238 - distribution_lambda_loss: 78078928.0000 6/16 [==========>...................] - ETA: 0s - loss: 79522992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.7922 - distribution_lambda_loss: 79522992.000011/16 [===================>..........] - ETA: 0s - loss: 79511160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.7554 - distribution_lambda_loss: 79511160.000016/16 [==============================] - ETA: 0s - loss: 78546192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.1303 - distribution_lambda_loss: 78546192.000016/16 [==============================] - 0s 13ms/step - loss: 78546192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.1303 - distribution_lambda_loss: 78546192.0000 - val_loss: 86916600.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 82.8007 - val_distribution_lambda_loss: 86916600.0000 - lr: 0.0010
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 80200368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.6496 - distribution_lambda_loss: 80200368.0000 6/16 [==========>...................] - ETA: 0s - loss: 80887448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.2480 - distribution_lambda_loss: 80887448.000011/16 [===================>..........] - ETA: 0s - loss: 79921136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.8274 - distribution_lambda_loss: 79921136.000015/16 [===========================>..] - ETA: 0s - loss: 79119024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.5540 - distribution_lambda_loss: 79119024.000016/16 [==============================] - 0s 13ms/step - loss: 79195640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.5924 - distribution_lambda_loss: 79195640.0000 - val_loss: 81289792.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 75.2762 - val_distribution_lambda_loss: 81289792.0000 - lr: 0.0010
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 72224064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.8091 - distribution_lambda_loss: 72224064.0000 6/16 [==========>...................] - ETA: 0s - loss: 75534808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.3028 - distribution_lambda_loss: 75534808.000011/16 [===================>..........] - ETA: 0s - loss: 76263344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.8663 - distribution_lambda_loss: 76263344.000016/16 [==============================] - ETA: 0s - loss: 75727968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.7326 - distribution_lambda_loss: 75727968.000016/16 [==============================] - 0s 13ms/step - loss: 75727968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.7326 - distribution_lambda_loss: 75727968.0000 - val_loss: 83234832.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 79.5033 - val_distribution_lambda_loss: 83234832.0000 - lr: 0.0010
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 77983680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.8508 - distribution_lambda_loss: 77983680.0000 6/16 [==========>...................] - ETA: 0s - loss: 77961960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 75.2474 - distribution_lambda_loss: 77961960.000011/16 [===================>..........] - ETA: 0s - loss: 75802400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.8953 - distribution_lambda_loss: 75802400.000016/16 [==============================] - ETA: 0s - loss: 75598312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.8633 - distribution_lambda_loss: 75598312.0000
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 14ms/step - loss: 75598312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.8633 - distribution_lambda_loss: 75598312.0000 - val_loss: 81744672.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.4323 - val_distribution_lambda_loss: 81744672.0000 - lr: 0.0010
Epoch 21/50
 1/16 [>.............................] - ETA: 0s - loss: 69598704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.7981 - distribution_lambda_loss: 69598704.0000 6/16 [==========>...................] - ETA: 0s - loss: 73882872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.5752 - distribution_lambda_loss: 73882872.000010/16 [=================>............] - ETA: 0s - loss: 73361432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.4213 - distribution_lambda_loss: 73361432.000015/16 [===========================>..] - ETA: 0s - loss: 72647552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.1137 - distribution_lambda_loss: 72647552.000016/16 [==============================] - 0s 14ms/step - loss: 72596544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.0890 - distribution_lambda_loss: 72596544.0000 - val_loss: 78500648.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 75.7467 - val_distribution_lambda_loss: 78500648.0000 - lr: 5.0000e-04
Epoch 22/50
 1/16 [>.............................] - ETA: 0s - loss: 67469360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.6829 - distribution_lambda_loss: 67469360.0000 6/16 [==========>...................] - ETA: 0s - loss: 73302912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.8120 - distribution_lambda_loss: 73302912.000011/16 [===================>..........] - ETA: 0s - loss: 72131600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.9193 - distribution_lambda_loss: 72131600.000016/16 [==============================] - ETA: 0s - loss: 71354040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.5492 - distribution_lambda_loss: 71354040.000016/16 [==============================] - 0s 14ms/step - loss: 71354040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.5492 - distribution_lambda_loss: 71354040.0000 - val_loss: 77621136.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.4998 - val_distribution_lambda_loss: 77621136.0000 - lr: 5.0000e-04
Epoch 23/50
 1/16 [>.............................] - ETA: 0s - loss: 72691560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.3027 - distribution_lambda_loss: 72691560.0000 6/16 [==========>...................] - ETA: 0s - loss: 70755016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3786 - distribution_lambda_loss: 70755016.000011/16 [===================>..........] - ETA: 0s - loss: 70979672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3178 - distribution_lambda_loss: 70979672.000016/16 [==============================] - ETA: 0s - loss: 70700584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.2955 - distribution_lambda_loss: 70700584.000016/16 [==============================] - 0s 14ms/step - loss: 70700584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.2955 - distribution_lambda_loss: 70700584.0000 - val_loss: 77443632.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.3463 - val_distribution_lambda_loss: 77443632.0000 - lr: 5.0000e-04
Epoch 24/50
 1/16 [>.............................] - ETA: 0s - loss: 70862976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.6619 - distribution_lambda_loss: 70862976.0000 6/16 [==========>...................] - ETA: 0s - loss: 70524584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0142 - distribution_lambda_loss: 70524584.000011/16 [===================>..........] - ETA: 0s - loss: 70060256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.8894 - distribution_lambda_loss: 70060256.000016/16 [==============================] - ETA: 0s - loss: 70526840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.1340 - distribution_lambda_loss: 70526840.000016/16 [==============================] - 0s 13ms/step - loss: 70526840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.1340 - distribution_lambda_loss: 70526840.0000 - val_loss: 76604088.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 72.9390 - val_distribution_lambda_loss: 76604088.0000 - lr: 5.0000e-04
Epoch 25/50
 1/16 [>.............................] - ETA: 0s - loss: 67310344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.2569 - distribution_lambda_loss: 67310344.0000 6/16 [==========>...................] - ETA: 0s - loss: 70526024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.1328 - distribution_lambda_loss: 70526024.000010/16 [=================>............] - ETA: 0s - loss: 69719728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.7405 - distribution_lambda_loss: 69719728.000015/16 [===========================>..] - ETA: 0s - loss: 69770232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.7824 - distribution_lambda_loss: 69770232.000016/16 [==============================] - 0s 14ms/step - loss: 69841304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.7990 - distribution_lambda_loss: 69841304.0000 - val_loss: 75191416.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.4586 - val_distribution_lambda_loss: 75191416.0000 - lr: 5.0000e-04
Epoch 26/50
 1/16 [>.............................] - ETA: 0s - loss: 71103360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.8828 - distribution_lambda_loss: 71103360.0000 6/16 [==========>...................] - ETA: 0s - loss: 70462712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.3454 - distribution_lambda_loss: 70462712.000011/16 [===================>..........] - ETA: 0s - loss: 68987016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.5364 - distribution_lambda_loss: 68987016.000016/16 [==============================] - ETA: 0s - loss: 68979832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.4364 - distribution_lambda_loss: 68979832.000016/16 [==============================] - 0s 14ms/step - loss: 68979832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.4364 - distribution_lambda_loss: 68979832.0000 - val_loss: 75179096.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.2387 - val_distribution_lambda_loss: 75179096.0000 - lr: 5.0000e-04
Epoch 27/50
 1/16 [>.............................] - ETA: 0s - loss: 68878168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.5393 - distribution_lambda_loss: 68878168.0000 6/16 [==========>...................] - ETA: 0s - loss: 68293512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9539 - distribution_lambda_loss: 68293512.000011/16 [===================>..........] - ETA: 0s - loss: 68426192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0976 - distribution_lambda_loss: 68426192.000016/16 [==============================] - ETA: 0s - loss: 68338272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0974 - distribution_lambda_loss: 68338272.000016/16 [==============================] - 0s 13ms/step - loss: 68338272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0974 - distribution_lambda_loss: 68338272.0000 - val_loss: 73757584.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.7669 - val_distribution_lambda_loss: 73757584.0000 - lr: 5.0000e-04
Epoch 28/50
 1/16 [>.............................] - ETA: 0s - loss: 68364632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0834 - distribution_lambda_loss: 68364632.0000 6/16 [==========>...................] - ETA: 0s - loss: 68487544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0537 - distribution_lambda_loss: 68487544.000011/16 [===================>..........] - ETA: 0s - loss: 68642320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0923 - distribution_lambda_loss: 68642320.000016/16 [==============================] - ETA: 0s - loss: 67994936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.8116 - distribution_lambda_loss: 67994936.000016/16 [==============================] - 0s 14ms/step - loss: 67994936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.8116 - distribution_lambda_loss: 67994936.0000 - val_loss: 74530240.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.6324 - val_distribution_lambda_loss: 74530240.0000 - lr: 5.0000e-04
Epoch 29/50
 1/16 [>.............................] - ETA: 0s - loss: 65867304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.8504 - distribution_lambda_loss: 65867304.0000 6/16 [==========>...................] - ETA: 0s - loss: 68771832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3448 - distribution_lambda_loss: 68771832.000011/16 [===================>..........] - ETA: 0s - loss: 67905432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.7813 - distribution_lambda_loss: 67905432.000016/16 [==============================] - ETA: 0s - loss: 67980072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9079 - distribution_lambda_loss: 67980072.0000
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
16/16 [==============================] - 0s 14ms/step - loss: 67980072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9079 - distribution_lambda_loss: 67980072.0000 - val_loss: 74096192.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.1318 - val_distribution_lambda_loss: 74096192.0000 - lr: 5.0000e-04
Epoch 30/50
 1/16 [>.............................] - ETA: 0s - loss: 75191376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.9121 - distribution_lambda_loss: 75191376.0000 6/16 [==========>...................] - ETA: 0s - loss: 69771544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.6117 - distribution_lambda_loss: 69771544.000011/16 [===================>..........] - ETA: 0s - loss: 67272160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.4384 - distribution_lambda_loss: 67272160.000016/16 [==============================] - ETA: 0s - loss: 66725072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.1268 - distribution_lambda_loss: 66725072.000016/16 [==============================] - 0s 14ms/step - loss: 66725072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.1268 - distribution_lambda_loss: 66725072.0000 - val_loss: 72695736.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.5256 - val_distribution_lambda_loss: 72695736.0000 - lr: 2.5000e-04
Epoch 31/50
 1/16 [>.............................] - ETA: 0s - loss: 69627792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0286 - distribution_lambda_loss: 69627792.0000 6/16 [==========>...................] - ETA: 0s - loss: 66295616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.0566 - distribution_lambda_loss: 66295616.000010/16 [=================>............] - ETA: 0s - loss: 66692532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.3308 - distribution_lambda_loss: 66692532.000015/16 [===========================>..] - ETA: 0s - loss: 66002432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.8605 - distribution_lambda_loss: 66002432.000016/16 [==============================] - 0s 13ms/step - loss: 65971088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.8431 - distribution_lambda_loss: 65971088.0000 - val_loss: 72293416.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.3019 - val_distribution_lambda_loss: 72293416.0000 - lr: 2.5000e-04
Epoch 32/50
 1/16 [>.............................] - ETA: 0s - loss: 65338172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3487 - distribution_lambda_loss: 65338172.0000 6/16 [==========>...................] - ETA: 0s - loss: 66259524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.8251 - distribution_lambda_loss: 66259524.000011/16 [===================>..........] - ETA: 0s - loss: 65590480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.5660 - distribution_lambda_loss: 65590480.000016/16 [==============================] - ETA: 0s - loss: 65657180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.6322 - distribution_lambda_loss: 65657180.000016/16 [==============================] - 0s 13ms/step - loss: 65657180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.6322 - distribution_lambda_loss: 65657180.0000 - val_loss: 72090080.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 72.3363 - val_distribution_lambda_loss: 72090080.0000 - lr: 2.5000e-04
Epoch 33/50
 1/16 [>.............................] - ETA: 0s - loss: 63528116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.9120 - distribution_lambda_loss: 63528116.0000 6/16 [==========>...................] - ETA: 0s - loss: 67215000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.6842 - distribution_lambda_loss: 67215000.000011/16 [===================>..........] - ETA: 0s - loss: 65993712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.0359 - distribution_lambda_loss: 65993712.000016/16 [==============================] - ETA: 0s - loss: 65472092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.6612 - distribution_lambda_loss: 65472092.000016/16 [==============================] - 0s 13ms/step - loss: 65472092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.6612 - distribution_lambda_loss: 65472092.0000 - val_loss: 71510744.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.6160 - val_distribution_lambda_loss: 71510744.0000 - lr: 2.5000e-04
Epoch 34/50
 1/16 [>.............................] - ETA: 0s - loss: 64891364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.4116 - distribution_lambda_loss: 64891364.0000 6/16 [==========>...................] - ETA: 0s - loss: 64863040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3531 - distribution_lambda_loss: 64863040.000011/16 [===================>..........] - ETA: 0s - loss: 64903564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2266 - distribution_lambda_loss: 64903564.000016/16 [==============================] - ETA: 0s - loss: 65080864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.4369 - distribution_lambda_loss: 65080864.000016/16 [==============================] - 0s 13ms/step - loss: 65080864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.4369 - distribution_lambda_loss: 65080864.0000 - val_loss: 71386424.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0508 - val_distribution_lambda_loss: 71386424.0000 - lr: 2.5000e-04
Epoch 35/50
 1/16 [>.............................] - ETA: 0s - loss: 65734588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.3010 - distribution_lambda_loss: 65734588.0000 6/16 [==========>...................] - ETA: 0s - loss: 65669868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.6789 - distribution_lambda_loss: 65669868.000011/16 [===================>..........] - ETA: 0s - loss: 64799332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2575 - distribution_lambda_loss: 64799332.000016/16 [==============================] - ETA: 0s - loss: 64988728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1752 - distribution_lambda_loss: 64988728.000016/16 [==============================] - 0s 13ms/step - loss: 64988728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1752 - distribution_lambda_loss: 64988728.0000 - val_loss: 71706064.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 72.3200 - val_distribution_lambda_loss: 71706064.0000 - lr: 2.5000e-04
Epoch 36/50
 1/16 [>.............................] - ETA: 0s - loss: 68887008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.9956 - distribution_lambda_loss: 68887008.0000 6/16 [==========>...................] - ETA: 0s - loss: 65053616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3224 - distribution_lambda_loss: 65053616.000011/16 [===================>..........] - ETA: 0s - loss: 64808320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2823 - distribution_lambda_loss: 64808320.000016/16 [==============================] - ETA: 0s - loss: 64668232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1984 - distribution_lambda_loss: 64668232.000016/16 [==============================] - 0s 13ms/step - loss: 64668232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1984 - distribution_lambda_loss: 64668232.0000 - val_loss: 70889800.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.1220 - val_distribution_lambda_loss: 70889800.0000 - lr: 2.5000e-04
Epoch 37/50
 1/16 [>.............................] - ETA: 0s - loss: 66873384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.8722 - distribution_lambda_loss: 66873384.0000 5/16 [========>.....................] - ETA: 0s - loss: 63959112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7172 - distribution_lambda_loss: 63959112.000010/16 [=================>............] - ETA: 0s - loss: 63910548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6658 - distribution_lambda_loss: 63910548.000014/16 [=========================>....] - ETA: 0s - loss: 64180704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.8168 - distribution_lambda_loss: 64180704.000016/16 [==============================] - 0s 14ms/step - loss: 64318400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.8438 - distribution_lambda_loss: 64318400.0000 - val_loss: 70270496.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.4789 - val_distribution_lambda_loss: 70270496.0000 - lr: 2.5000e-04
Epoch 38/50
 1/16 [>.............................] - ETA: 0s - loss: 59774528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1835 - distribution_lambda_loss: 59774528.0000 6/16 [==========>...................] - ETA: 0s - loss: 64042860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7909 - distribution_lambda_loss: 64042860.000011/16 [===================>..........] - ETA: 0s - loss: 64274780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9178 - distribution_lambda_loss: 64274780.000016/16 [==============================] - ETA: 0s - loss: 64136732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.8862 - distribution_lambda_loss: 64136732.000016/16 [==============================] - 0s 14ms/step - loss: 64136732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.8862 - distribution_lambda_loss: 64136732.0000 - val_loss: 70324864.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.5167 - val_distribution_lambda_loss: 70324864.0000 - lr: 2.5000e-04
Epoch 39/50
 1/16 [>.............................] - ETA: 0s - loss: 60744132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5745 - distribution_lambda_loss: 60744132.0000 6/16 [==========>...................] - ETA: 0s - loss: 64036556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9991 - distribution_lambda_loss: 64036556.000011/16 [===================>..........] - ETA: 0s - loss: 64435940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9959 - distribution_lambda_loss: 64435940.000016/16 [==============================] - ETA: 0s - loss: 63744988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7969 - distribution_lambda_loss: 63744988.0000
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
16/16 [==============================] - 0s 13ms/step - loss: 63744988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7969 - distribution_lambda_loss: 63744988.0000 - val_loss: 71309200.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.1355 - val_distribution_lambda_loss: 71309200.0000 - lr: 2.5000e-04
Epoch 40/50
 1/16 [>.............................] - ETA: 0s - loss: 68777032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8525 - distribution_lambda_loss: 68777032.0000 6/16 [==========>...................] - ETA: 0s - loss: 65964096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.4207 - distribution_lambda_loss: 65964096.000011/16 [===================>..........] - ETA: 0s - loss: 64066572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5409 - distribution_lambda_loss: 64066572.000016/16 [==============================] - ETA: 0s - loss: 63633928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4799 - distribution_lambda_loss: 63633928.000016/16 [==============================] - 0s 13ms/step - loss: 63633928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4799 - distribution_lambda_loss: 63633928.0000 - val_loss: 69136000.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0696 - val_distribution_lambda_loss: 69136000.0000 - lr: 1.2500e-04
Epoch 41/50
 1/16 [>.............................] - ETA: 0s - loss: 66583352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3016 - distribution_lambda_loss: 66583352.0000 6/16 [==========>...................] - ETA: 0s - loss: 61414644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5197 - distribution_lambda_loss: 61414644.000011/16 [===================>..........] - ETA: 0s - loss: 62503128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9172 - distribution_lambda_loss: 62503128.000016/16 [==============================] - ETA: 0s - loss: 63012340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2378 - distribution_lambda_loss: 63012340.000016/16 [==============================] - 0s 13ms/step - loss: 63012340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2378 - distribution_lambda_loss: 63012340.0000 - val_loss: 69258720.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.7357 - val_distribution_lambda_loss: 69258720.0000 - lr: 1.2500e-04
Epoch 42/50
 1/16 [>.............................] - ETA: 0s - loss: 62233544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1115 - distribution_lambda_loss: 62233544.0000 6/16 [==========>...................] - ETA: 0s - loss: 62344320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7456 - distribution_lambda_loss: 62344320.000011/16 [===================>..........] - ETA: 0s - loss: 62789392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1002 - distribution_lambda_loss: 62789392.000016/16 [==============================] - ETA: 0s - loss: 62827540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2797 - distribution_lambda_loss: 62827540.0000
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001.
16/16 [==============================] - 0s 14ms/step - loss: 62827540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2797 - distribution_lambda_loss: 62827540.0000 - val_loss: 69178248.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.5111 - val_distribution_lambda_loss: 69178248.0000 - lr: 1.2500e-04
Epoch 43/50
 1/16 [>.............................] - ETA: 0s - loss: 64228352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1054 - distribution_lambda_loss: 64228352.0000 6/16 [==========>...................] - ETA: 0s - loss: 62708628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9815 - distribution_lambda_loss: 62708628.000011/16 [===================>..........] - ETA: 0s - loss: 62370908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7545 - distribution_lambda_loss: 62370908.000016/16 [==============================] - ETA: 0s - loss: 62709084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0733 - distribution_lambda_loss: 62709084.000016/16 [==============================] - 0s 13ms/step - loss: 62709084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0733 - distribution_lambda_loss: 62709084.0000 - val_loss: 68778912.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0438 - val_distribution_lambda_loss: 68778912.0000 - lr: 1.0000e-04
Epoch 44/50
 1/16 [>.............................] - ETA: 0s - loss: 64411904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6052 - distribution_lambda_loss: 64411904.0000 6/16 [==========>...................] - ETA: 0s - loss: 62999680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9432 - distribution_lambda_loss: 62999680.000011/16 [===================>..........] - ETA: 0s - loss: 62397312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9042 - distribution_lambda_loss: 62397312.000016/16 [==============================] - ETA: 0s - loss: 62566680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8592 - distribution_lambda_loss: 62566680.000016/16 [==============================] - 0s 13ms/step - loss: 62566680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8592 - distribution_lambda_loss: 62566680.0000 - val_loss: 68966128.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.1092 - val_distribution_lambda_loss: 68966128.0000 - lr: 1.0000e-04
Epoch 45/50
 1/16 [>.............................] - ETA: 0s - loss: 61413448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6040 - distribution_lambda_loss: 61413448.0000 6/16 [==========>...................] - ETA: 0s - loss: 62248412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0584 - distribution_lambda_loss: 62248412.000011/16 [===================>..........] - ETA: 0s - loss: 62466108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1760 - distribution_lambda_loss: 62466108.000016/16 [==============================] - ETA: 0s - loss: 62383832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9909 - distribution_lambda_loss: 62383832.000016/16 [==============================] - 0s 13ms/step - loss: 62383832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9909 - distribution_lambda_loss: 62383832.0000 - val_loss: 68828840.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.2924 - val_distribution_lambda_loss: 68828840.0000 - lr: 1.0000e-04
Epoch 46/50
 1/16 [>.............................] - ETA: 0s - loss: 61740488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5535 - distribution_lambda_loss: 61740488.0000 6/16 [==========>...................] - ETA: 0s - loss: 62528752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6096 - distribution_lambda_loss: 62528752.000011/16 [===================>..........] - ETA: 0s - loss: 62113240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1242 - distribution_lambda_loss: 62113240.000016/16 [==============================] - ETA: 0s - loss: 62432620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1492 - distribution_lambda_loss: 62432620.000016/16 [==============================] - 0s 13ms/step - loss: 62432620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1492 - distribution_lambda_loss: 62432620.0000 - val_loss: 68590784.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.8024 - val_distribution_lambda_loss: 68590784.0000 - lr: 1.0000e-04
Epoch 47/50
 1/16 [>.............................] - ETA: 0s - loss: 65760512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1419 - distribution_lambda_loss: 65760512.0000 6/16 [==========>...................] - ETA: 0s - loss: 61543804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5881 - distribution_lambda_loss: 61543804.000011/16 [===================>..........] - ETA: 0s - loss: 61805052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7472 - distribution_lambda_loss: 61805052.000016/16 [==============================] - ETA: 0s - loss: 62096716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8172 - distribution_lambda_loss: 62096716.000016/16 [==============================] - 0s 12ms/step - loss: 62096716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8172 - distribution_lambda_loss: 62096716.0000 - val_loss: 68427088.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.4321 - val_distribution_lambda_loss: 68427088.0000 - lr: 1.0000e-04
Epoch 48/50
 1/16 [>.............................] - ETA: 0s - loss: 58791432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6892 - distribution_lambda_loss: 58791432.0000 6/16 [==========>...................] - ETA: 0s - loss: 60964516.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1481 - distribution_lambda_loss: 60964516.000011/16 [===================>..........] - ETA: 0s - loss: 61598276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6886 - distribution_lambda_loss: 61598276.000016/16 [==============================] - ETA: 0s - loss: 61960288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7209 - distribution_lambda_loss: 61960288.000016/16 [==============================] - 0s 12ms/step - loss: 61960288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7209 - distribution_lambda_loss: 61960288.0000 - val_loss: 68216840.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 68.9860 - val_distribution_lambda_loss: 68216840.0000 - lr: 1.0000e-04
Epoch 49/50
 1/16 [>.............................] - ETA: 0s - loss: 66064936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.5656 - distribution_lambda_loss: 66064936.0000 6/16 [==========>...................] - ETA: 0s - loss: 61269116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.2601 - distribution_lambda_loss: 61269116.000011/16 [===================>..........] - ETA: 0s - loss: 61473268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5014 - distribution_lambda_loss: 61473268.000016/16 [==============================] - ETA: 0s - loss: 61854988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6351 - distribution_lambda_loss: 61854988.000016/16 [==============================] - 0s 13ms/step - loss: 61854988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6351 - distribution_lambda_loss: 61854988.0000 - val_loss: 68115704.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.5395 - val_distribution_lambda_loss: 68115704.0000 - lr: 1.0000e-04
Epoch 50/50
 1/16 [>.............................] - ETA: 0s - loss: 64309968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.8170 - distribution_lambda_loss: 64309968.0000 6/16 [==========>...................] - ETA: 0s - loss: 61849840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0600 - distribution_lambda_loss: 61849840.000011/16 [===================>..........] - ETA: 0s - loss: 61866064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9422 - distribution_lambda_loss: 61866064.000016/16 [==============================] - 0s 12ms/step - loss: 61850124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7790 - distribution_lambda_loss: 61850124.0000 - val_loss: 68081568.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0006 - val_distribution_lambda_loss: 68081568.0000 - lr: 1.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:36  5/322 [..............................] - ETA: 5s    8/322 [..............................] - ETA: 5s 11/322 [>.............................] - ETA: 5s 15/322 [>.............................] - ETA: 5s 18/322 [>.............................] - ETA: 5s 21/322 [>.............................] - ETA: 5s 24/322 [=>............................] - ETA: 5s 28/322 [=>............................] - ETA: 4s 31/322 [=>............................] - ETA: 4s 35/322 [==>...........................] - ETA: 4s 39/322 [==>...........................] - ETA: 4s 42/322 [==>...........................] - ETA: 4s 46/322 [===>..........................] - ETA: 4s 49/322 [===>..........................] - ETA: 4s 52/322 [===>..........................] - ETA: 4s 56/322 [====>.........................] - ETA: 4s 60/322 [====>.........................] - ETA: 4s 64/322 [====>.........................] - ETA: 4s 68/322 [=====>........................] - ETA: 4s 72/322 [=====>........................] - ETA: 4s 75/322 [=====>........................] - ETA: 4s 79/322 [======>.......................] - ETA: 4s 83/322 [======>.......................] - ETA: 3s 87/322 [=======>......................] - ETA: 3s 91/322 [=======>......................] - ETA: 3s 95/322 [=======>......................] - ETA: 3s 99/322 [========>.....................] - ETA: 3s102/322 [========>.....................] - ETA: 3s106/322 [========>.....................] - ETA: 3s110/322 [=========>....................] - ETA: 3s114/322 [=========>....................] - ETA: 3s117/322 [=========>....................] - ETA: 3s121/322 [==========>...................] - ETA: 3s125/322 [==========>...................] - ETA: 3s128/322 [==========>...................] - ETA: 3s132/322 [===========>..................] - ETA: 3s136/322 [===========>..................] - ETA: 3s139/322 [===========>..................] - ETA: 3s143/322 [============>.................] - ETA: 2s147/322 [============>.................] - ETA: 2s150/322 [============>.................] - ETA: 2s154/322 [=============>................] - ETA: 2s158/322 [=============>................] - ETA: 2s162/322 [==============>...............] - ETA: 2s166/322 [==============>...............] - ETA: 2s170/322 [==============>...............] - ETA: 2s174/322 [===============>..............] - ETA: 2s177/322 [===============>..............] - ETA: 2s181/322 [===============>..............] - ETA: 2s185/322 [================>.............] - ETA: 2s189/322 [================>.............] - ETA: 2s192/322 [================>.............] - ETA: 2s196/322 [=================>............] - ETA: 2s200/322 [=================>............] - ETA: 1s203/322 [=================>............] - ETA: 1s207/322 [==================>...........] - ETA: 1s211/322 [==================>...........] - ETA: 1s215/322 [===================>..........] - ETA: 1s218/322 [===================>..........] - ETA: 1s222/322 [===================>..........] - ETA: 1s226/322 [====================>.........] - ETA: 1s230/322 [====================>.........] - ETA: 1s234/322 [====================>.........] - ETA: 1s238/322 [=====================>........] - ETA: 1s242/322 [=====================>........] - ETA: 1s246/322 [=====================>........] - ETA: 1s250/322 [======================>.......] - ETA: 1s254/322 [======================>.......] - ETA: 1s258/322 [=======================>......] - ETA: 1s262/322 [=======================>......] - ETA: 0s265/322 [=======================>......] - ETA: 0s269/322 [========================>.....] - ETA: 0s272/322 [========================>.....] - ETA: 0s276/322 [========================>.....] - ETA: 0s279/322 [========================>.....] - ETA: 0s283/322 [=========================>....] - ETA: 0s287/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s295/322 [==========================>...] - ETA: 0s299/322 [==========================>...] - ETA: 0s302/322 [===========================>..] - ETA: 0s306/322 [===========================>..] - ETA: 0s310/322 [===========================>..] - ETA: 0s314/322 [============================>.] - ETA: 0s318/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 7s 16ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:11:54,334 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:11:57,367 - INFO - Assets written to: /tmp/tmpcqhphwvj/autoencoder/assets
2025-07-27 21:11:57,415 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:11:59,044 - INFO - Assets written to: /tmp/tmpcqhphwvj/diffraction_to_obj/assets
2025-07-27 21:12:00,047 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run
[2025-07-27 21:12:01] SUCCESS: PtychoPINN training (n_images=256, trial=3)
[2025-07-27 21:12:01] EXECUTING: Baseline training (n_images=256, trial=3)
[2025-07-27 21:12:01] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 256 \
            --output_dir '3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run' \
            --nepochs 50
2025-07-27 21:12:01.403030: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:12:01.403058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:12:01.403883: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:12:01.408024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:12:01.875110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:12:02.672285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:02.703207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:02.704517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:12:02.967124: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:02.968628: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:02.971559: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:03.092776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:03.094050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:03.095192: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:12:03.095332: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:12:03.096493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:12:03,378 - INFO - Configuration setup complete
2025-07-27 21:12:03,378 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run'))
2025-07-27 21:12:03,378 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:12:03,378 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:12:03,378 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1/
2025-07-27 21:12:03,378 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:12:03,392 - INFO - 
[2/6] Loading data...
2025-07-27 21:12:03,392 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:12:03,392 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=256
2025-07-27 21:12:03,425 - INFO - Using sequential slicing for gridsize=1: selecting first 256 images
2025-07-27 21:12:03,425 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:12:03,498 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:12:21,234 - INFO - Globally set intensity_scale to: 988.211669921875
2025-07-27 21:12:21,234 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:12:21,236 - INFO - Final training input shape: (256, 64, 64, 1)
2025-07-27 21:12:21,236 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:12:21,236 - INFO - Training with 256 images
DEBUG: Setting timestamp to 07/27/2025, 21:12:03 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:12:03
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=97.207 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 256 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.2117, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:12:22.594753: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:12:23.398737: I external/local_xla/xla/service/service.cc:168] XLA service 0x702958462650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:12:23.398759: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:12:23.402228: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753675943.462286 3713784 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 1/16 [>.............................] - ETA: 1:06 - loss: 3.5949 - conv2d_12_loss: 1.2357 - conv2d_19_loss: 2.3592 6/16 [==========>...................] - ETA: 0s - loss: 4.9687 - conv2d_12_loss: 0.8730 - conv2d_19_loss: 4.0957  11/16 [===================>..........] - ETA: 0s - loss: 3.9957 - conv2d_12_loss: 0.7119 - conv2d_19_loss: 3.283916/16 [==============================] - ETA: 0s - loss: 3.6280 - conv2d_12_loss: 0.6148 - conv2d_19_loss: 3.013216/16 [==============================] - 6s 125ms/step - loss: 3.6280 - conv2d_12_loss: 0.6148 - conv2d_19_loss: 3.0132 - val_loss: 2.5884 - val_conv2d_12_loss: 0.3062 - val_conv2d_19_loss: 2.2822 - lr: 0.0010
Epoch 2/50
 1/16 [>.............................] - ETA: 0s - loss: 2.5858 - conv2d_12_loss: 0.3037 - conv2d_19_loss: 2.2821 6/16 [==========>...................] - ETA: 0s - loss: 2.5190 - conv2d_12_loss: 0.2634 - conv2d_19_loss: 2.255711/16 [===================>..........] - ETA: 0s - loss: 2.4422 - conv2d_12_loss: 0.2413 - conv2d_19_loss: 2.200916/16 [==============================] - 0s 11ms/step - loss: 2.3269 - conv2d_12_loss: 0.2278 - conv2d_19_loss: 2.0991 - val_loss: 1.3036 - val_conv2d_12_loss: 0.1717 - val_conv2d_19_loss: 1.1320 - lr: 0.0010
Epoch 3/50
 1/16 [>.............................] - ETA: 0s - loss: 1.2870 - conv2d_12_loss: 0.1679 - conv2d_19_loss: 1.1191 6/16 [==========>...................] - ETA: 0s - loss: 1.0188 - conv2d_12_loss: 0.1664 - conv2d_19_loss: 0.852411/16 [===================>..........] - ETA: 0s - loss: 0.8971 - conv2d_12_loss: 0.1586 - conv2d_19_loss: 0.738516/16 [==============================] - 0s 11ms/step - loss: 0.8356 - conv2d_12_loss: 0.1535 - conv2d_19_loss: 0.6821 - val_loss: 0.7009 - val_conv2d_12_loss: 0.1317 - val_conv2d_19_loss: 0.5692 - lr: 0.0010
Epoch 4/50
 1/16 [>.............................] - ETA: 0s - loss: 0.7007 - conv2d_12_loss: 0.1311 - conv2d_19_loss: 0.5696 6/16 [==========>...................] - ETA: 0s - loss: 0.6308 - conv2d_12_loss: 0.1271 - conv2d_19_loss: 0.503711/16 [===================>..........] - ETA: 0s - loss: 0.6155 - conv2d_12_loss: 0.1243 - conv2d_19_loss: 0.491216/16 [==============================] - 0s 11ms/step - loss: 0.6054 - conv2d_12_loss: 0.1221 - conv2d_19_loss: 0.4833 - val_loss: 0.5436 - val_conv2d_12_loss: 0.1136 - val_conv2d_19_loss: 0.4300 - lr: 0.0010
Epoch 5/50
 1/16 [>.............................] - ETA: 0s - loss: 0.5564 - conv2d_12_loss: 0.1174 - conv2d_19_loss: 0.4390 6/16 [==========>...................] - ETA: 0s - loss: 0.5454 - conv2d_12_loss: 0.1127 - conv2d_19_loss: 0.432711/16 [===================>..........] - ETA: 0s - loss: 0.5277 - conv2d_12_loss: 0.1091 - conv2d_19_loss: 0.418516/16 [==============================] - 0s 11ms/step - loss: 0.5185 - conv2d_12_loss: 0.1076 - conv2d_19_loss: 0.4109 - val_loss: 0.4755 - val_conv2d_12_loss: 0.1022 - val_conv2d_19_loss: 0.3734 - lr: 0.0010
Epoch 6/50
 1/16 [>.............................] - ETA: 0s - loss: 0.4747 - conv2d_12_loss: 0.1004 - conv2d_19_loss: 0.3744 6/16 [==========>...................] - ETA: 0s - loss: 0.4667 - conv2d_12_loss: 0.1003 - conv2d_19_loss: 0.366411/16 [===================>..........] - ETA: 0s - loss: 0.4546 - conv2d_12_loss: 0.0988 - conv2d_19_loss: 0.355816/16 [==============================] - 0s 11ms/step - loss: 0.4445 - conv2d_12_loss: 0.0976 - conv2d_19_loss: 0.3469 - val_loss: 0.4134 - val_conv2d_12_loss: 0.0958 - val_conv2d_19_loss: 0.3177 - lr: 0.0010
Epoch 7/50
 1/16 [>.............................] - ETA: 0s - loss: 0.4146 - conv2d_12_loss: 0.0944 - conv2d_19_loss: 0.3201 6/16 [==========>...................] - ETA: 0s - loss: 0.3999 - conv2d_12_loss: 0.0929 - conv2d_19_loss: 0.307111/16 [===================>..........] - ETA: 0s - loss: 0.3954 - conv2d_12_loss: 0.0918 - conv2d_19_loss: 0.303616/16 [==============================] - 0s 11ms/step - loss: 0.3924 - conv2d_12_loss: 0.0911 - conv2d_19_loss: 0.3013 - val_loss: 0.3805 - val_conv2d_12_loss: 0.0892 - val_conv2d_19_loss: 0.2913 - lr: 0.0010
Epoch 8/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3792 - conv2d_12_loss: 0.0885 - conv2d_19_loss: 0.2907 6/16 [==========>...................] - ETA: 0s - loss: 0.3749 - conv2d_12_loss: 0.0890 - conv2d_19_loss: 0.286011/16 [===================>..........] - ETA: 0s - loss: 0.3666 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.279116/16 [==============================] - 0s 11ms/step - loss: 0.3626 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2755 - val_loss: 0.3596 - val_conv2d_12_loss: 0.0903 - val_conv2d_19_loss: 0.2693 - lr: 0.0010
Epoch 9/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3368 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2525 6/16 [==========>...................] - ETA: 0s - loss: 0.3454 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.259411/16 [===================>..........] - ETA: 0s - loss: 0.3438 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.257616/16 [==============================] - 0s 11ms/step - loss: 0.3427 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2565 - val_loss: 0.3403 - val_conv2d_12_loss: 0.0871 - val_conv2d_19_loss: 0.2532 - lr: 0.0010
Epoch 10/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3384 - conv2d_12_loss: 0.0872 - conv2d_19_loss: 0.2511 6/16 [==========>...................] - ETA: 0s - loss: 0.3360 - conv2d_12_loss: 0.0870 - conv2d_19_loss: 0.249011/16 [===================>..........] - ETA: 0s - loss: 0.3297 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.244116/16 [==============================] - 0s 11ms/step - loss: 0.3276 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2422 - val_loss: 0.3233 - val_conv2d_12_loss: 0.0872 - val_conv2d_19_loss: 0.2361 - lr: 0.0010
Epoch 11/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3140 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2293 6/16 [==========>...................] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.231211/16 [===================>..........] - ETA: 0s - loss: 0.3180 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.231716/16 [==============================] - 0s 11ms/step - loss: 0.3166 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2306 - val_loss: 0.3183 - val_conv2d_12_loss: 0.0881 - val_conv2d_19_loss: 0.2301 - lr: 0.0010
Epoch 12/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3196 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2334 6/16 [==========>...................] - ETA: 0s - loss: 0.3211 - conv2d_12_loss: 0.0870 - conv2d_19_loss: 0.234111/16 [===================>..........] - ETA: 0s - loss: 0.3148 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.228916/16 [==============================] - 0s 11ms/step - loss: 0.3138 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2282 - val_loss: 0.3189 - val_conv2d_12_loss: 0.0890 - val_conv2d_19_loss: 0.2298 - lr: 0.0010
Epoch 13/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3276 - conv2d_12_loss: 0.0906 - conv2d_19_loss: 0.2370 6/16 [==========>...................] - ETA: 0s - loss: 0.3181 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.230511/16 [===================>..........] - ETA: 0s - loss: 0.3146 - conv2d_12_loss: 0.0869 - conv2d_19_loss: 0.2276
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
16/16 [==============================] - 0s 11ms/step - loss: 0.3158 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2285 - val_loss: 0.3207 - val_conv2d_12_loss: 0.0910 - val_conv2d_19_loss: 0.2297 - lr: 0.0010
Epoch 14/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3025 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2152 6/16 [==========>...................] - ETA: 0s - loss: 0.3120 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.225411/16 [===================>..........] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.227116/16 [==============================] - 0s 11ms/step - loss: 0.3131 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2271 - val_loss: 0.3177 - val_conv2d_12_loss: 0.0881 - val_conv2d_19_loss: 0.2296 - lr: 5.0000e-04
Epoch 15/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.2245 6/16 [==========>...................] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.226311/16 [===================>..........] - ETA: 0s - loss: 0.3154 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.229416/16 [==============================] - 0s 11ms/step - loss: 0.3118 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2267 - val_loss: 0.3178 - val_conv2d_12_loss: 0.0889 - val_conv2d_19_loss: 0.2289 - lr: 5.0000e-04
Epoch 16/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3047 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2197 6/16 [==========>...................] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.224411/16 [===================>..........] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.226116/16 [==============================] - 0s 11ms/step - loss: 0.3119 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2263 - val_loss: 0.3151 - val_conv2d_12_loss: 0.0869 - val_conv2d_19_loss: 0.2282 - lr: 5.0000e-04
Epoch 17/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2994 - conv2d_12_loss: 0.0822 - conv2d_19_loss: 0.2172 6/16 [==========>...................] - ETA: 0s - loss: 0.3072 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.222911/16 [===================>..........] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.225916/16 [==============================] - 0s 11ms/step - loss: 0.3114 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2261 - val_loss: 0.3147 - val_conv2d_12_loss: 0.0862 - val_conv2d_19_loss: 0.2285 - lr: 5.0000e-04
Epoch 18/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3004 - conv2d_12_loss: 0.0822 - conv2d_19_loss: 0.2182 6/16 [==========>...................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.224211/16 [===================>..........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.226416/16 [==============================] - 0s 11ms/step - loss: 0.3111 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2263 - val_loss: 0.3149 - val_conv2d_12_loss: 0.0866 - val_conv2d_19_loss: 0.2283 - lr: 5.0000e-04
Epoch 19/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3306 - conv2d_12_loss: 0.0911 - conv2d_19_loss: 0.2395 6/16 [==========>...................] - ETA: 0s - loss: 0.3162 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.230411/16 [===================>..........] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.225316/16 [==============================] - 0s 11ms/step - loss: 0.3107 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2261 - val_loss: 0.3145 - val_conv2d_12_loss: 0.0864 - val_conv2d_19_loss: 0.2281 - lr: 5.0000e-04
Epoch 20/50
 1/16 [>.............................] - ETA: 0s - loss: 0.2885 - conv2d_12_loss: 0.0798 - conv2d_19_loss: 0.2088 6/16 [==========>...................] - ETA: 0s - loss: 0.3078 - conv2d_12_loss: 0.0836 - conv2d_19_loss: 0.224111/16 [===================>..........] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.225016/16 [==============================] - 0s 11ms/step - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258 - val_loss: 0.3141 - val_conv2d_12_loss: 0.0863 - val_conv2d_19_loss: 0.2279 - lr: 5.0000e-04
Epoch 21/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2278 6/16 [==========>...................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.224811/16 [===================>..........] - ETA: 0s - loss: 0.3108 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.225516/16 [==============================] - 0s 11ms/step - loss: 0.3111 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2258 - val_loss: 0.3155 - val_conv2d_12_loss: 0.0878 - val_conv2d_19_loss: 0.2276 - lr: 5.0000e-04
Epoch 22/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3204 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2333 6/16 [==========>...................] - ETA: 0s - loss: 0.3078 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.224011/16 [===================>..........] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.224116/16 [==============================] - 0s 11ms/step - loss: 0.3111 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2257 - val_loss: 0.3137 - val_conv2d_12_loss: 0.0862 - val_conv2d_19_loss: 0.2276 - lr: 5.0000e-04
Epoch 23/50
 1/16 [>.............................] - ETA: 0s - loss: 0.3146 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2289 6/16 [==========>...................] - ETA: 0s - loss: 0.3149 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.228711/16 [===================>..........] - ETA: 0s - loss: 0.3123 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.226316/16 [==============================] - 0s 11ms/step - loss: 0.3112 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2256 - val_loss: 0.3158 - val_conv2d_12_loss: 0.0879 - val_conv2d_19_loss: 0.2279 - lr: 5.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:12:31,901 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1/baseline_model.h5
2025-07-27 21:12:31,901 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:41 12/322 [>.............................] - ETA: 1s   22/322 [=>............................] - ETA: 1s 32/322 [=>............................] - ETA: 1s 42/322 [==>...........................] - ETA: 1s 52/322 [===>..........................] - ETA: 1s 62/322 [====>.........................] - ETA: 1s 72/322 [=====>........................] - ETA: 1s 82/322 [======>.......................] - ETA: 1s 92/322 [=======>......................] - ETA: 1s102/322 [========>.....................] - ETA: 1s112/322 [=========>....................] - ETA: 1s122/322 [==========>...................] - ETA: 1s132/322 [===========>..................] - ETA: 0s142/322 [============>.................] - ETA: 0s152/322 [=============>................] - ETA: 0s162/322 [==============>...............] - ETA: 0s172/322 [===============>..............] - ETA: 0s182/322 [===============>..............] - ETA: 0s192/322 [================>.............] - ETA: 0s202/322 [=================>............] - ETA: 0s212/322 [==================>...........] - ETA: 0s222/322 [===================>..........] - ETA: 0s232/322 [====================>.........] - ETA: 0s242/322 [=====================>........] - ETA: 0s252/322 [======================>.......] - ETA: 0s262/322 [=======================>......] - ETA: 0s272/322 [========================>.....] - ETA: 0s282/322 [=========================>....] - ETA: 0s292/322 [==========================>...] - ETA: 0s302/322 [===========================>..] - ETA: 0s312/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:12:35,348 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:12:35,348 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:12:35,348 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:12:35,348 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:12:35,348 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:12:35,348 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:12:35,348 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:12:35,348 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:12:35,348 - INFO - --- Alignment complete ---
2025-07-27 21:12:35,348 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:12:35,438 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:12:35,438 - INFO -   MAE:  (0.08503618, 0.2513031472896753)
2025-07-27 21:12:35,438 - INFO -   PSNR: (68.30541843551237, 58.980248899817155)
2025-07-27 21:12:35,540 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:12:35,540 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 0.968385
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.272857, std=0.000000, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.968385
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.272857, std=0.000000, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:12:36] SUCCESS: Baseline training (n_images=256, trial=3)
[2025-07-27 21:12:36] EXECUTING: Tike reconstruction (n_images=512, trial=3)
[2025-07-27 21:12:36] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_256/trial_3/tike_run' \
                --n-images 512 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:13:20] SUCCESS: Tike reconstruction (n_images=512, trial=3)
[2025-07-27 21:13:20] Completed training for train_size=256 (Trial 3/3)
[2025-07-27 21:13:20] Completed all trials for train_size=256
[2025-07-27 21:13:20] Starting training for train_size=2048, test_size=4096 (3 trials)
[2025-07-27 21:13:20] Training models for train_size=2048, test_size=4096 (Trial 1/3)
[2025-07-27 21:13:20] EXECUTING: PtychoPINN training (n_images=2048, trial=1)
[2025-07-27 21:13:20] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run' \
            --nepochs 50
2025-07-27 21:13:20.518472: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:13:20.518503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:13:20.519349: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:13:20.523720: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:13:20.996475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:13:22.034073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.067788: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.069975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:13:22.229642: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.231972: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.234363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.352018: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.353250: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.354359: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:13:22.354500: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:13:22.355668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:13:22,383 - INFO - Configuration setup complete
2025-07-27 21:13:22,383 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run'))
2025-07-27 21:13:22,383 - INFO - Parameter interpretation: --n-images=2048 refers to individual images (gridsize=1)
2025-07-27 21:13:22,384 - INFO - Starting training with n_images=2048, stitching=disabled
2025-07-27 21:13:22,384 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:13:22,417 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
2025-07-27 21:13:22,417 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:13:22,491 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:13:22,491 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:13:43,574 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:13:43.691204: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:13:43.691218: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:13:43.691242: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:13:43.708207: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:13:43.708282: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:13:43,710 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:13:44,383 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:13:44,390 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:13:45,376 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:13:45,383 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:13:46.045191: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:13:46.354310: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x25b59e90
2025-07-27 21:13:47.249458: I external/local_xla/xla/service/service.cc:168] XLA service 0x7c2fce7681b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:13:47.249488: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:13:47.252710: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676027.318850 3716383 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 13:10 - loss: 780332288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 162.9268 - distribution_lambda_loss: 780332288.0000  6/122 [>.............................] - ETA: 1s - loss: 25635776512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1019.9556 - distribution_lambda_loss: 25635776512.0000 11/122 [=>............................] - ETA: 1s - loss: 14603317248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 712.0034 - distribution_lambda_loss: 14603317248.0000  16/122 [==>...........................] - ETA: 1s - loss: 10885629952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 619.4921 - distribution_lambda_loss: 10885629952.0000 21/122 [====>.........................] - ETA: 1s - loss: 8493383680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 529.6756 - distribution_lambda_loss: 8493383680.0000   26/122 [=====>........................] - ETA: 1s - loss: 6968369664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 460.4692 - distribution_lambda_loss: 6968369664.0000 31/122 [======>.......................] - ETA: 0s - loss: 5922238976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 412.1176 - distribution_lambda_loss: 5922238976.0000 36/122 [=======>......................] - ETA: 0s - loss: 5155043328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 377.1703 - distribution_lambda_loss: 5155043328.0000 41/122 [=========>....................] - ETA: 0s - loss: 4572979200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 352.8297 - distribution_lambda_loss: 4572979200.0000 46/122 [==========>...................] - ETA: 0s - loss: 4117415424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 333.8100 - distribution_lambda_loss: 4117415424.0000 51/122 [===========>..................] - ETA: 0s - loss: 3749050112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 316.8608 - distribution_lambda_loss: 3749050112.0000 56/122 [============>.................] - ETA: 0s - loss: 3444190976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 302.4457 - distribution_lambda_loss: 3444190976.0000 61/122 [==============>...............] - ETA: 0s - loss: 3192569856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 290.7160 - distribution_lambda_loss: 3192569856.0000 66/122 [===============>..............] - ETA: 0s - loss: 2976562432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 280.3239 - distribution_lambda_loss: 2976562432.0000 71/122 [================>.............] - ETA: 0s - loss: 2791706112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 271.8135 - distribution_lambda_loss: 2791706112.0000 76/122 [=================>............] - ETA: 0s - loss: 2630937344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 264.2769 - distribution_lambda_loss: 2630937344.0000 81/122 [==================>...........] - ETA: 0s - loss: 2488957696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 257.3970 - distribution_lambda_loss: 2488957696.0000 86/122 [====================>.........] - ETA: 0s - loss: 2361181952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 250.8955 - distribution_lambda_loss: 2361181952.0000 91/122 [=====================>........] - ETA: 0s - loss: 2246299648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 244.9466 - distribution_lambda_loss: 2246299648.0000 96/122 [======================>.......] - ETA: 0s - loss: 2141715328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 239.1946 - distribution_lambda_loss: 2141715328.0000101/122 [=======================>......] - ETA: 0s - loss: 2045548672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 233.4441 - distribution_lambda_loss: 2045548672.0000106/122 [=========================>....] - ETA: 0s - loss: 1957845376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 227.9431 - distribution_lambda_loss: 1957845376.0000111/122 [==========================>...] - ETA: 0s - loss: 1877148032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 222.7041 - distribution_lambda_loss: 1877148032.0000116/122 [===========================>..] - ETA: 0s - loss: 1802850048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 217.7232 - distribution_lambda_loss: 1802850048.0000121/122 [============================>.] - ETA: 0s - loss: 1734378368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 213.0344 - distribution_lambda_loss: 1734378368.0000122/122 [==============================] - ETA: 0s - loss: 1726997248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 212.5258 - distribution_lambda_loss: 1726997248.0000input shape (None, 64, 64, 1)
122/122 [==============================] - 10s 27ms/step - loss: 1726997248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 212.5258 - distribution_lambda_loss: 1726997248.0000 - val_loss: 142922384.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.1133 - val_distribution_lambda_loss: 142922384.0000 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 136201760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1289 - distribution_lambda_loss: 136201760.0000  6/122 [>.............................] - ETA: 1s - loss: 139118544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0028 - distribution_lambda_loss: 139118544.0000 11/122 [=>............................] - ETA: 1s - loss: 133839872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1523 - distribution_lambda_loss: 133839872.0000 16/122 [==>...........................] - ETA: 1s - loss: 130521776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9922 - distribution_lambda_loss: 130521776.0000  21/122 [====>.........................] - ETA: 1s - loss: 129862720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7389 - distribution_lambda_loss: 129862720.0000 26/122 [=====>........................] - ETA: 0s - loss: 128098512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0193 - distribution_lambda_loss: 128098512.0000 31/122 [======>.......................] - ETA: 0s - loss: 126470648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.3494 - distribution_lambda_loss: 126470648.0000 36/122 [=======>......................] - ETA: 0s - loss: 124989472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.7099 - distribution_lambda_loss: 124989472.0000 41/122 [=========>....................] - ETA: 0s - loss: 123418696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.0237 - distribution_lambda_loss: 123418696.0000 46/122 [==========>...................] - ETA: 0s - loss: 121773880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.4300 - distribution_lambda_loss: 121773880.0000 51/122 [===========>..................] - ETA: 0s - loss: 120299688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 94.8045 - distribution_lambda_loss: 120299688.0000 56/122 [============>.................] - ETA: 0s - loss: 118931584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 94.2127 - distribution_lambda_loss: 118931584.0000 61/122 [==============>...............] - ETA: 0s - loss: 117840008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 93.7134 - distribution_lambda_loss: 117840008.0000 66/122 [===============>..............] - ETA: 0s - loss: 116663664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 93.2158 - distribution_lambda_loss: 116663664.0000 71/122 [================>.............] - ETA: 0s - loss: 115483760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.7008 - distribution_lambda_loss: 115483760.0000 76/122 [=================>............] - ETA: 0s - loss: 114562456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.3036 - distribution_lambda_loss: 114562456.0000 81/122 [==================>...........] - ETA: 0s - loss: 113956432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.0571 - distribution_lambda_loss: 113956432.0000 86/122 [====================>.........] - ETA: 0s - loss: 113605856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.8677 - distribution_lambda_loss: 113605856.0000 91/122 [=====================>........] - ETA: 0s - loss: 113089816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.6200 - distribution_lambda_loss: 113089816.0000 96/122 [======================>.......] - ETA: 0s - loss: 112380512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 91.2949 - distribution_lambda_loss: 112380512.0000101/122 [=======================>......] - ETA: 0s - loss: 111717064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.9630 - distribution_lambda_loss: 111717064.0000106/122 [=========================>....] - ETA: 0s - loss: 110905752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.6273 - distribution_lambda_loss: 110905752.0000111/122 [==========================>...] - ETA: 0s - loss: 110013632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.2122 - distribution_lambda_loss: 110013632.0000116/122 [===========================>..] - ETA: 0s - loss: 109339624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.9025 - distribution_lambda_loss: 109339624.0000121/122 [============================>.] - ETA: 0s - loss: 108595824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.5438 - distribution_lambda_loss: 108595824.0000122/122 [==============================] - 1s 11ms/step - loss: 108519240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.5214 - distribution_lambda_loss: 108519240.0000 - val_loss: 93959160.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 82.6260 - val_distribution_lambda_loss: 93959160.0000 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 91633304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 82.6226 - distribution_lambda_loss: 91633304.0000  6/122 [>.............................] - ETA: 1s - loss: 91077536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.2622 - distribution_lambda_loss: 91077536.0000 11/122 [=>............................] - ETA: 1s - loss: 91866248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.6862 - distribution_lambda_loss: 91866248.0000 16/122 [==>...........................] - ETA: 1s - loss: 91004416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.2970 - distribution_lambda_loss: 91004416.0000 21/122 [====>.........................] - ETA: 1s - loss: 90919744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 81.2275 - distribution_lambda_loss: 90919744.0000 26/122 [=====>........................] - ETA: 0s - loss: 90621488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.9765 - distribution_lambda_loss: 90621488.0000 31/122 [======>.......................] - ETA: 0s - loss: 89920600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.6246 - distribution_lambda_loss: 89920600.0000 36/122 [=======>......................] - ETA: 0s - loss: 89081576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.1753 - distribution_lambda_loss: 89081576.0000 41/122 [=========>....................] - ETA: 0s - loss: 89096184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.1892 - distribution_lambda_loss: 89096184.0000 46/122 [==========>...................] - ETA: 0s - loss: 88893264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.1095 - distribution_lambda_loss: 88893264.0000 51/122 [===========>..................] - ETA: 0s - loss: 88397048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.8058 - distribution_lambda_loss: 88397048.0000 56/122 [============>.................] - ETA: 0s - loss: 88094376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.6490 - distribution_lambda_loss: 88094376.0000 61/122 [==============>...............] - ETA: 0s - loss: 87451400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.3614 - distribution_lambda_loss: 87451400.0000 66/122 [===============>..............] - ETA: 0s - loss: 86975552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.1342 - distribution_lambda_loss: 86975552.0000 71/122 [================>.............] - ETA: 0s - loss: 86863768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.0299 - distribution_lambda_loss: 86863768.0000 76/122 [=================>............] - ETA: 0s - loss: 86499776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.8291 - distribution_lambda_loss: 86499776.0000 81/122 [==================>...........] - ETA: 0s - loss: 86076224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.5993 - distribution_lambda_loss: 86076224.0000 86/122 [====================>.........] - ETA: 0s - loss: 85533520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.3541 - distribution_lambda_loss: 85533520.0000 91/122 [=====================>........] - ETA: 0s - loss: 85082360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.1255 - distribution_lambda_loss: 85082360.0000 96/122 [======================>.......] - ETA: 0s - loss: 84745528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.9521 - distribution_lambda_loss: 84745528.0000101/122 [=======================>......] - ETA: 0s - loss: 84414536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.7776 - distribution_lambda_loss: 84414536.0000106/122 [=========================>....] - ETA: 0s - loss: 84090520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.6418 - distribution_lambda_loss: 84090520.0000111/122 [==========================>...] - ETA: 0s - loss: 83828376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.5087 - distribution_lambda_loss: 83828376.0000116/122 [===========================>..] - ETA: 0s - loss: 83444712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.2975 - distribution_lambda_loss: 83444712.0000121/122 [============================>.] - ETA: 0s - loss: 83207392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.1799 - distribution_lambda_loss: 83207392.0000122/122 [==============================] - 1s 11ms/step - loss: 83219384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.1768 - distribution_lambda_loss: 83219384.0000 - val_loss: 79984280.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 74.7272 - val_distribution_lambda_loss: 79984280.0000 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 72819328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.6740 - distribution_lambda_loss: 72819328.0000  6/122 [>.............................] - ETA: 1s - loss: 75821896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.2697 - distribution_lambda_loss: 75821896.0000 11/122 [=>............................] - ETA: 1s - loss: 76065800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.3422 - distribution_lambda_loss: 76065800.0000 16/122 [==>...........................] - ETA: 1s - loss: 75398432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.0240 - distribution_lambda_loss: 75398432.0000 21/122 [====>.........................] - ETA: 1s - loss: 75824592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.2794 - distribution_lambda_loss: 75824592.0000 26/122 [=====>........................] - ETA: 0s - loss: 77094528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.8396 - distribution_lambda_loss: 77094528.0000 31/122 [======>.......................] - ETA: 0s - loss: 77815888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.1796 - distribution_lambda_loss: 77815888.0000 36/122 [=======>......................] - ETA: 0s - loss: 77774824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.1637 - distribution_lambda_loss: 77774824.0000 41/122 [=========>....................] - ETA: 0s - loss: 77288720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.9650 - distribution_lambda_loss: 77288720.0000 46/122 [==========>...................] - ETA: 0s - loss: 76763856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.7705 - distribution_lambda_loss: 76763856.0000 51/122 [===========>..................] - ETA: 0s - loss: 76611768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.6577 - distribution_lambda_loss: 76611768.0000 56/122 [============>.................] - ETA: 0s - loss: 76252064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.5108 - distribution_lambda_loss: 76252064.0000 61/122 [==============>...............] - ETA: 0s - loss: 76007728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.3662 - distribution_lambda_loss: 76007728.0000 66/122 [===============>..............] - ETA: 0s - loss: 75886000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.3463 - distribution_lambda_loss: 75886000.0000 71/122 [================>.............] - ETA: 0s - loss: 75515128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.2371 - distribution_lambda_loss: 75515128.0000 76/122 [=================>............] - ETA: 0s - loss: 75389744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.1578 - distribution_lambda_loss: 75389744.0000 81/122 [==================>...........] - ETA: 0s - loss: 75169704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.0368 - distribution_lambda_loss: 75169704.0000 86/122 [====================>.........] - ETA: 0s - loss: 74898808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.9051 - distribution_lambda_loss: 74898808.0000 91/122 [=====================>........] - ETA: 0s - loss: 74600888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.7555 - distribution_lambda_loss: 74600888.0000 96/122 [======================>.......] - ETA: 0s - loss: 74527272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.7271 - distribution_lambda_loss: 74527272.0000101/122 [=======================>......] - ETA: 0s - loss: 74414144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.6993 - distribution_lambda_loss: 74414144.0000106/122 [=========================>....] - ETA: 0s - loss: 74292464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.6045 - distribution_lambda_loss: 74292464.0000111/122 [==========================>...] - ETA: 0s - loss: 74103304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.5291 - distribution_lambda_loss: 74103304.0000116/122 [===========================>..] - ETA: 0s - loss: 74081440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.5234 - distribution_lambda_loss: 74081440.0000121/122 [============================>.] - ETA: 0s - loss: 73880760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.4385 - distribution_lambda_loss: 73880760.0000122/122 [==============================] - 1s 11ms/step - loss: 73865088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.4380 - distribution_lambda_loss: 73865088.0000 - val_loss: 73488312.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 72.2618 - val_distribution_lambda_loss: 73488312.0000 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 72469280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2545 - distribution_lambda_loss: 72469280.0000  6/122 [>.............................] - ETA: 1s - loss: 71146400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.8974 - distribution_lambda_loss: 71146400.0000 11/122 [=>............................] - ETA: 1s - loss: 70049008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3561 - distribution_lambda_loss: 70049008.0000 16/122 [==>...........................] - ETA: 1s - loss: 69909296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.4490 - distribution_lambda_loss: 69909296.0000 21/122 [====>.........................] - ETA: 1s - loss: 70039520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.5153 - distribution_lambda_loss: 70039520.0000 26/122 [=====>........................] - ETA: 0s - loss: 69529192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.2416 - distribution_lambda_loss: 69529192.0000 31/122 [======>.......................] - ETA: 0s - loss: 69911360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3641 - distribution_lambda_loss: 69911360.0000 36/122 [=======>......................] - ETA: 0s - loss: 69523912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.2089 - distribution_lambda_loss: 69523912.0000 41/122 [=========>....................] - ETA: 0s - loss: 69301664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.1323 - distribution_lambda_loss: 69301664.0000 46/122 [==========>...................] - ETA: 0s - loss: 68912152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9668 - distribution_lambda_loss: 68912152.0000 51/122 [===========>..................] - ETA: 0s - loss: 68791144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.8621 - distribution_lambda_loss: 68791144.0000 56/122 [============>.................] - ETA: 0s - loss: 68676592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.7995 - distribution_lambda_loss: 68676592.0000 61/122 [==============>...............] - ETA: 0s - loss: 68661832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.7783 - distribution_lambda_loss: 68661832.0000 66/122 [===============>..............] - ETA: 0s - loss: 68458712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.6901 - distribution_lambda_loss: 68458712.0000 71/122 [================>.............] - ETA: 0s - loss: 68384448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.6794 - distribution_lambda_loss: 68384448.0000 76/122 [=================>............] - ETA: 0s - loss: 68604400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.7371 - distribution_lambda_loss: 68604400.0000 81/122 [==================>...........] - ETA: 0s - loss: 68563584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.7225 - distribution_lambda_loss: 68563584.0000 86/122 [====================>.........] - ETA: 0s - loss: 68463152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.6726 - distribution_lambda_loss: 68463152.0000 91/122 [=====================>........] - ETA: 0s - loss: 68296952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.5903 - distribution_lambda_loss: 68296952.0000 96/122 [======================>.......] - ETA: 0s - loss: 68228008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.5779 - distribution_lambda_loss: 68228008.0000101/122 [=======================>......] - ETA: 0s - loss: 68029832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.4932 - distribution_lambda_loss: 68029832.0000106/122 [=========================>....] - ETA: 0s - loss: 68018928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.4728 - distribution_lambda_loss: 68018928.0000111/122 [==========================>...] - ETA: 0s - loss: 67906064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.4256 - distribution_lambda_loss: 67906064.0000116/122 [===========================>..] - ETA: 0s - loss: 67827880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.3743 - distribution_lambda_loss: 67827880.0000121/122 [============================>.] - ETA: 0s - loss: 67767960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.3550 - distribution_lambda_loss: 67767960.0000122/122 [==============================] - 1s 11ms/step - loss: 67749392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.3467 - distribution_lambda_loss: 67749392.0000 - val_loss: 68445752.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 69.0263 - val_distribution_lambda_loss: 68445752.0000 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 62155352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3138 - distribution_lambda_loss: 62155352.0000  6/122 [>.............................] - ETA: 1s - loss: 65100620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7343 - distribution_lambda_loss: 65100620.0000 11/122 [=>............................] - ETA: 1s - loss: 65300508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7232 - distribution_lambda_loss: 65300508.0000 16/122 [==>...........................] - ETA: 1s - loss: 65073428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7140 - distribution_lambda_loss: 65073428.0000 21/122 [====>.........................] - ETA: 1s - loss: 64644420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6365 - distribution_lambda_loss: 64644420.0000 26/122 [=====>........................] - ETA: 1s - loss: 64503044.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6458 - distribution_lambda_loss: 64503044.0000 31/122 [======>.......................] - ETA: 0s - loss: 64394712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5681 - distribution_lambda_loss: 64394712.0000 36/122 [=======>......................] - ETA: 0s - loss: 64233808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4631 - distribution_lambda_loss: 64233808.0000 41/122 [=========>....................] - ETA: 0s - loss: 64061184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4106 - distribution_lambda_loss: 64061184.0000 46/122 [==========>...................] - ETA: 0s - loss: 63911652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.3527 - distribution_lambda_loss: 63911652.0000 51/122 [===========>..................] - ETA: 0s - loss: 63796740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2840 - distribution_lambda_loss: 63796740.0000 56/122 [============>.................] - ETA: 0s - loss: 63630376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2277 - distribution_lambda_loss: 63630376.0000 61/122 [==============>...............] - ETA: 0s - loss: 63633148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2053 - distribution_lambda_loss: 63633148.0000 66/122 [===============>..............] - ETA: 0s - loss: 63574472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1987 - distribution_lambda_loss: 63574472.0000 71/122 [================>.............] - ETA: 0s - loss: 63533056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1302 - distribution_lambda_loss: 63533056.0000 76/122 [=================>............] - ETA: 0s - loss: 63588964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1424 - distribution_lambda_loss: 63588964.0000 81/122 [==================>...........] - ETA: 0s - loss: 63603212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1657 - distribution_lambda_loss: 63603212.0000 86/122 [====================>.........] - ETA: 0s - loss: 63641236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1857 - distribution_lambda_loss: 63641236.0000 91/122 [=====================>........] - ETA: 0s - loss: 63623136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2052 - distribution_lambda_loss: 63623136.0000 96/122 [======================>.......] - ETA: 0s - loss: 63674368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2064 - distribution_lambda_loss: 63674368.0000101/122 [=======================>......] - ETA: 0s - loss: 63681732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1912 - distribution_lambda_loss: 63681732.0000106/122 [=========================>....] - ETA: 0s - loss: 63651324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1602 - distribution_lambda_loss: 63651324.0000111/122 [==========================>...] - ETA: 0s - loss: 63608960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1345 - distribution_lambda_loss: 63608960.0000116/122 [===========================>..] - ETA: 0s - loss: 63484384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0595 - distribution_lambda_loss: 63484384.0000121/122 [============================>.] - ETA: 0s - loss: 63360484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0135 - distribution_lambda_loss: 63360484.0000122/122 [==============================] - 1s 11ms/step - loss: 63351284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0194 - distribution_lambda_loss: 63351284.0000 - val_loss: 65610268.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.1829 - val_distribution_lambda_loss: 65610268.0000 - lr: 0.0010
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 61968864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7341 - distribution_lambda_loss: 61968864.0000  6/122 [>.............................] - ETA: 1s - loss: 62197632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.9029 - distribution_lambda_loss: 62197632.0000 11/122 [=>............................] - ETA: 1s - loss: 61225732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7556 - distribution_lambda_loss: 61225732.0000 16/122 [==>...........................] - ETA: 1s - loss: 60948232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6821 - distribution_lambda_loss: 60948232.0000 21/122 [====>.........................] - ETA: 1s - loss: 60292352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3788 - distribution_lambda_loss: 60292352.0000 26/122 [=====>........................] - ETA: 0s - loss: 60856132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6379 - distribution_lambda_loss: 60856132.0000 31/122 [======>.......................] - ETA: 0s - loss: 60826668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6889 - distribution_lambda_loss: 60826668.0000 36/122 [=======>......................] - ETA: 0s - loss: 60786324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6277 - distribution_lambda_loss: 60786324.0000 41/122 [=========>....................] - ETA: 0s - loss: 60901680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6818 - distribution_lambda_loss: 60901680.0000 46/122 [==========>...................] - ETA: 0s - loss: 60730100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6043 - distribution_lambda_loss: 60730100.0000 51/122 [===========>..................] - ETA: 0s - loss: 60804472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6126 - distribution_lambda_loss: 60804472.0000 56/122 [============>.................] - ETA: 0s - loss: 60808836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6501 - distribution_lambda_loss: 60808836.0000 61/122 [==============>...............] - ETA: 0s - loss: 60855876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.7058 - distribution_lambda_loss: 60855876.0000 66/122 [===============>..............] - ETA: 0s - loss: 60772920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.6170 - distribution_lambda_loss: 60772920.0000 71/122 [================>.............] - ETA: 0s - loss: 60483440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4740 - distribution_lambda_loss: 60483440.0000 76/122 [=================>............] - ETA: 0s - loss: 60510788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.5191 - distribution_lambda_loss: 60510788.0000 81/122 [==================>...........] - ETA: 0s - loss: 60446784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4970 - distribution_lambda_loss: 60446784.0000 86/122 [====================>.........] - ETA: 0s - loss: 60401344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4281 - distribution_lambda_loss: 60401344.0000 91/122 [=====================>........] - ETA: 0s - loss: 60321940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4016 - distribution_lambda_loss: 60321940.0000 96/122 [======================>.......] - ETA: 0s - loss: 60279548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3568 - distribution_lambda_loss: 60279548.0000101/122 [=======================>......] - ETA: 0s - loss: 60251196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.3345 - distribution_lambda_loss: 60251196.0000106/122 [=========================>....] - ETA: 0s - loss: 60104928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2824 - distribution_lambda_loss: 60104928.0000111/122 [==========================>...] - ETA: 0s - loss: 59973200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2109 - distribution_lambda_loss: 59973200.0000116/122 [===========================>..] - ETA: 0s - loss: 59976376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2051 - distribution_lambda_loss: 59976376.0000121/122 [============================>.] - ETA: 0s - loss: 59929140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1830 - distribution_lambda_loss: 59929140.0000122/122 [==============================] - 1s 11ms/step - loss: 59896564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1702 - distribution_lambda_loss: 59896564.0000 - val_loss: 60984684.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 64.2782 - val_distribution_lambda_loss: 60984684.0000 - lr: 0.0010
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 63058572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0097 - distribution_lambda_loss: 63058572.0000  6/122 [>.............................] - ETA: 1s - loss: 58736324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.3324 - distribution_lambda_loss: 58736324.0000 11/122 [=>............................] - ETA: 1s - loss: 58011176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9896 - distribution_lambda_loss: 58011176.0000 16/122 [==>...........................] - ETA: 1s - loss: 57872912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9149 - distribution_lambda_loss: 57872912.0000 21/122 [====>.........................] - ETA: 1s - loss: 57848948.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0157 - distribution_lambda_loss: 57848948.0000 26/122 [=====>........................] - ETA: 0s - loss: 58175044.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.1404 - distribution_lambda_loss: 58175044.0000 31/122 [======>.......................] - ETA: 0s - loss: 57731164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9863 - distribution_lambda_loss: 57731164.0000 36/122 [=======>......................] - ETA: 0s - loss: 57841560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0467 - distribution_lambda_loss: 57841560.0000 41/122 [=========>....................] - ETA: 0s - loss: 57636872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0148 - distribution_lambda_loss: 57636872.0000 46/122 [==========>...................] - ETA: 0s - loss: 58329204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.3179 - distribution_lambda_loss: 58329204.0000 51/122 [===========>..................] - ETA: 0s - loss: 58406328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.3962 - distribution_lambda_loss: 58406328.0000 56/122 [============>.................] - ETA: 0s - loss: 58459564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.4081 - distribution_lambda_loss: 58459564.0000 61/122 [==============>...............] - ETA: 0s - loss: 58515364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.4157 - distribution_lambda_loss: 58515364.0000 66/122 [===============>..............] - ETA: 0s - loss: 58399868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.3439 - distribution_lambda_loss: 58399868.0000 71/122 [================>.............] - ETA: 0s - loss: 58286972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.2886 - distribution_lambda_loss: 58286972.0000 76/122 [=================>............] - ETA: 0s - loss: 58050904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.1518 - distribution_lambda_loss: 58050904.0000 81/122 [==================>...........] - ETA: 0s - loss: 57876152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0441 - distribution_lambda_loss: 57876152.0000 86/122 [====================>.........] - ETA: 0s - loss: 57913088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.0625 - distribution_lambda_loss: 57913088.0000 91/122 [=====================>........] - ETA: 0s - loss: 57746668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9569 - distribution_lambda_loss: 57746668.0000 96/122 [======================>.......] - ETA: 0s - loss: 57690596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9435 - distribution_lambda_loss: 57690596.0000101/122 [=======================>......] - ETA: 0s - loss: 57742372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9460 - distribution_lambda_loss: 57742372.0000106/122 [=========================>....] - ETA: 0s - loss: 57684928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9347 - distribution_lambda_loss: 57684928.0000111/122 [==========================>...] - ETA: 0s - loss: 57733200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.9338 - distribution_lambda_loss: 57733200.0000116/122 [===========================>..] - ETA: 0s - loss: 57607160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.8712 - distribution_lambda_loss: 57607160.0000121/122 [============================>.] - ETA: 0s - loss: 57581728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.8454 - distribution_lambda_loss: 57581728.0000122/122 [==============================] - 1s 11ms/step - loss: 57576728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.8397 - distribution_lambda_loss: 57576728.0000 - val_loss: 59380752.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 64.6952 - val_distribution_lambda_loss: 59380752.0000 - lr: 0.0010
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 54957636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6973 - distribution_lambda_loss: 54957636.0000  6/122 [>.............................] - ETA: 1s - loss: 55656428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5088 - distribution_lambda_loss: 55656428.0000 11/122 [=>............................] - ETA: 1s - loss: 55950352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.8314 - distribution_lambda_loss: 55950352.0000 16/122 [==>...........................] - ETA: 1s - loss: 55778992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7209 - distribution_lambda_loss: 55778992.0000 21/122 [====>.........................] - ETA: 1s - loss: 55573088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7182 - distribution_lambda_loss: 55573088.0000 26/122 [=====>........................] - ETA: 0s - loss: 55533332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7121 - distribution_lambda_loss: 55533332.0000 31/122 [======>.......................] - ETA: 0s - loss: 55561520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6615 - distribution_lambda_loss: 55561520.0000 36/122 [=======>......................] - ETA: 0s - loss: 55321212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5552 - distribution_lambda_loss: 55321212.0000 41/122 [=========>....................] - ETA: 0s - loss: 55341036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5784 - distribution_lambda_loss: 55341036.0000 46/122 [==========>...................] - ETA: 0s - loss: 55129116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4866 - distribution_lambda_loss: 55129116.0000 51/122 [===========>..................] - ETA: 0s - loss: 55155924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4661 - distribution_lambda_loss: 55155924.0000 56/122 [============>.................] - ETA: 0s - loss: 55154708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4589 - distribution_lambda_loss: 55154708.0000 61/122 [==============>...............] - ETA: 0s - loss: 55094332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4407 - distribution_lambda_loss: 55094332.0000 66/122 [===============>..............] - ETA: 0s - loss: 55041984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4098 - distribution_lambda_loss: 55041984.0000 71/122 [================>.............] - ETA: 0s - loss: 55037372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4197 - distribution_lambda_loss: 55037372.0000 76/122 [=================>............] - ETA: 0s - loss: 55088996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4462 - distribution_lambda_loss: 55088996.0000 81/122 [==================>...........] - ETA: 0s - loss: 55259488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5249 - distribution_lambda_loss: 55259488.0000 86/122 [====================>.........] - ETA: 0s - loss: 55352000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5758 - distribution_lambda_loss: 55352000.0000 91/122 [=====================>........] - ETA: 0s - loss: 55294556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5496 - distribution_lambda_loss: 55294556.0000 96/122 [======================>.......] - ETA: 0s - loss: 55191872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5113 - distribution_lambda_loss: 55191872.0000101/122 [=======================>......] - ETA: 0s - loss: 55197196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5160 - distribution_lambda_loss: 55197196.0000106/122 [=========================>....] - ETA: 0s - loss: 55129860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4597 - distribution_lambda_loss: 55129860.0000111/122 [==========================>...] - ETA: 0s - loss: 55112440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4256 - distribution_lambda_loss: 55112440.0000116/122 [===========================>..] - ETA: 0s - loss: 55132672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4467 - distribution_lambda_loss: 55132672.0000121/122 [============================>.] - ETA: 0s - loss: 55104688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4024 - distribution_lambda_loss: 55104688.0000122/122 [==============================] - 1s 11ms/step - loss: 55121108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4130 - distribution_lambda_loss: 55121108.0000 - val_loss: 58319192.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 65.3313 - val_distribution_lambda_loss: 58319192.0000 - lr: 0.0010
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 52215132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6984 - distribution_lambda_loss: 52215132.0000  6/122 [>.............................] - ETA: 1s - loss: 52991364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.5092 - distribution_lambda_loss: 52991364.0000 11/122 [=>............................] - ETA: 1s - loss: 54024756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7988 - distribution_lambda_loss: 54024756.0000 16/122 [==>...........................] - ETA: 1s - loss: 54374528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9197 - distribution_lambda_loss: 54374528.0000 21/122 [====>.........................] - ETA: 1s - loss: 54447444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9989 - distribution_lambda_loss: 54447444.0000 26/122 [=====>........................] - ETA: 0s - loss: 54668176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.2168 - distribution_lambda_loss: 54668176.0000 31/122 [======>.......................] - ETA: 0s - loss: 54547092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.0795 - distribution_lambda_loss: 54547092.0000 36/122 [=======>......................] - ETA: 0s - loss: 54525692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.1339 - distribution_lambda_loss: 54525692.0000 41/122 [=========>....................] - ETA: 0s - loss: 54360684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9753 - distribution_lambda_loss: 54360684.0000 46/122 [==========>...................] - ETA: 0s - loss: 54192284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9506 - distribution_lambda_loss: 54192284.0000 51/122 [===========>..................] - ETA: 0s - loss: 54097288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8511 - distribution_lambda_loss: 54097288.0000 56/122 [============>.................] - ETA: 0s - loss: 54149548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8871 - distribution_lambda_loss: 54149548.0000 61/122 [==============>...............] - ETA: 0s - loss: 54299924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9656 - distribution_lambda_loss: 54299924.0000 66/122 [===============>..............] - ETA: 0s - loss: 54296084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9326 - distribution_lambda_loss: 54296084.0000 71/122 [================>.............] - ETA: 0s - loss: 54276400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9053 - distribution_lambda_loss: 54276400.0000 76/122 [=================>............] - ETA: 0s - loss: 54378976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9613 - distribution_lambda_loss: 54378976.0000 81/122 [==================>...........] - ETA: 0s - loss: 54293720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9175 - distribution_lambda_loss: 54293720.0000 86/122 [====================>.........] - ETA: 0s - loss: 54289516.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9107 - distribution_lambda_loss: 54289516.0000 91/122 [=====================>........] - ETA: 0s - loss: 54127064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8340 - distribution_lambda_loss: 54127064.0000 96/122 [======================>.......] - ETA: 0s - loss: 54031828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7961 - distribution_lambda_loss: 54031828.0000101/122 [=======================>......] - ETA: 0s - loss: 53933452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7399 - distribution_lambda_loss: 53933452.0000106/122 [=========================>....] - ETA: 0s - loss: 53852908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6831 - distribution_lambda_loss: 53852908.0000111/122 [==========================>...] - ETA: 0s - loss: 53975672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7291 - distribution_lambda_loss: 53975672.0000116/122 [===========================>..] - ETA: 0s - loss: 54033564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7483 - distribution_lambda_loss: 54033564.0000121/122 [============================>.] - ETA: 0s - loss: 54082068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7595 - distribution_lambda_loss: 54082068.0000122/122 [==============================] - 1s 11ms/step - loss: 54076404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7581 - distribution_lambda_loss: 54076404.0000 - val_loss: 55454980.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 61.6476 - val_distribution_lambda_loss: 55454980.0000 - lr: 0.0010
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 50105712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.3545 - distribution_lambda_loss: 50105712.0000  6/122 [>.............................] - ETA: 1s - loss: 50543692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1696 - distribution_lambda_loss: 50543692.0000 11/122 [=>............................] - ETA: 1s - loss: 51490212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4311 - distribution_lambda_loss: 51490212.0000 16/122 [==>...........................] - ETA: 1s - loss: 51998100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5596 - distribution_lambda_loss: 51998100.0000 21/122 [====>.........................] - ETA: 1s - loss: 51460572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.3672 - distribution_lambda_loss: 51460572.0000 26/122 [=====>........................] - ETA: 0s - loss: 51573948.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4039 - distribution_lambda_loss: 51573948.0000 31/122 [======>.......................] - ETA: 0s - loss: 51162680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1850 - distribution_lambda_loss: 51162680.0000 36/122 [=======>......................] - ETA: 0s - loss: 51252160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.2445 - distribution_lambda_loss: 51252160.0000 41/122 [=========>....................] - ETA: 0s - loss: 51333624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.2652 - distribution_lambda_loss: 51333624.0000 46/122 [==========>...................] - ETA: 0s - loss: 51409056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.3114 - distribution_lambda_loss: 51409056.0000 51/122 [===========>..................] - ETA: 0s - loss: 51268256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.2328 - distribution_lambda_loss: 51268256.0000 56/122 [============>.................] - ETA: 0s - loss: 51462028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.3049 - distribution_lambda_loss: 51462028.0000 61/122 [==============>...............] - ETA: 0s - loss: 51570092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.3360 - distribution_lambda_loss: 51570092.0000 66/122 [===============>..............] - ETA: 0s - loss: 51518048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.2964 - distribution_lambda_loss: 51518048.0000 71/122 [================>.............] - ETA: 0s - loss: 51701404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4219 - distribution_lambda_loss: 51701404.0000 76/122 [=================>............] - ETA: 0s - loss: 51788356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4664 - distribution_lambda_loss: 51788356.0000 81/122 [==================>...........] - ETA: 0s - loss: 51847528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5004 - distribution_lambda_loss: 51847528.0000 86/122 [====================>.........] - ETA: 0s - loss: 51905376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5391 - distribution_lambda_loss: 51905376.0000 91/122 [=====================>........] - ETA: 0s - loss: 51822704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4989 - distribution_lambda_loss: 51822704.0000 96/122 [======================>.......] - ETA: 0s - loss: 51950512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5309 - distribution_lambda_loss: 51950512.0000101/122 [=======================>......] - ETA: 0s - loss: 52003020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5371 - distribution_lambda_loss: 52003020.0000106/122 [=========================>....] - ETA: 0s - loss: 52013364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5184 - distribution_lambda_loss: 52013364.0000111/122 [==========================>...] - ETA: 0s - loss: 52052684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5417 - distribution_lambda_loss: 52052684.0000116/122 [===========================>..] - ETA: 0s - loss: 52007368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5231 - distribution_lambda_loss: 52007368.0000121/122 [============================>.] - ETA: 0s - loss: 51983644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.5020 - distribution_lambda_loss: 51983644.0000122/122 [==============================] - 1s 11ms/step - loss: 51964264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4883 - distribution_lambda_loss: 51964264.0000 - val_loss: 53629580.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 60.4221 - val_distribution_lambda_loss: 53629580.0000 - lr: 0.0010
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 48493344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.9049 - distribution_lambda_loss: 48493344.0000  6/122 [>.............................] - ETA: 1s - loss: 48883124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.3710 - distribution_lambda_loss: 48883124.0000 11/122 [=>............................] - ETA: 1s - loss: 49887964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4258 - distribution_lambda_loss: 49887964.0000 16/122 [==>...........................] - ETA: 1s - loss: 50077720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4366 - distribution_lambda_loss: 50077720.0000 21/122 [====>.........................] - ETA: 1s - loss: 50090428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4476 - distribution_lambda_loss: 50090428.0000 26/122 [=====>........................] - ETA: 0s - loss: 50340224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6132 - distribution_lambda_loss: 50340224.0000 31/122 [======>.......................] - ETA: 0s - loss: 50301564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5531 - distribution_lambda_loss: 50301564.0000 36/122 [=======>......................] - ETA: 0s - loss: 50212980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5000 - distribution_lambda_loss: 50212980.0000 41/122 [=========>....................] - ETA: 0s - loss: 50582576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7460 - distribution_lambda_loss: 50582576.0000 46/122 [==========>...................] - ETA: 0s - loss: 50794648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8007 - distribution_lambda_loss: 50794648.0000 51/122 [===========>..................] - ETA: 0s - loss: 50998768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8886 - distribution_lambda_loss: 50998768.0000 56/122 [============>.................] - ETA: 0s - loss: 50943788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8865 - distribution_lambda_loss: 50943788.0000 61/122 [==============>...............] - ETA: 0s - loss: 50991512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8768 - distribution_lambda_loss: 50991512.0000 66/122 [===============>..............] - ETA: 0s - loss: 50782280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7743 - distribution_lambda_loss: 50782280.0000 71/122 [================>.............] - ETA: 0s - loss: 50937836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8299 - distribution_lambda_loss: 50937836.0000 76/122 [=================>............] - ETA: 0s - loss: 50806816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7571 - distribution_lambda_loss: 50806816.0000 81/122 [==================>...........] - ETA: 0s - loss: 50837964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7717 - distribution_lambda_loss: 50837964.0000 86/122 [====================>.........] - ETA: 0s - loss: 50762204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7082 - distribution_lambda_loss: 50762204.0000 91/122 [=====================>........] - ETA: 0s - loss: 50746380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6810 - distribution_lambda_loss: 50746380.0000 96/122 [======================>.......] - ETA: 0s - loss: 50652940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6360 - distribution_lambda_loss: 50652940.0000101/122 [=======================>......] - ETA: 0s - loss: 50588544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6066 - distribution_lambda_loss: 50588544.0000106/122 [=========================>....] - ETA: 0s - loss: 50673788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6355 - distribution_lambda_loss: 50673788.0000111/122 [==========================>...] - ETA: 0s - loss: 50662196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6325 - distribution_lambda_loss: 50662196.0000116/122 [===========================>..] - ETA: 0s - loss: 50646412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6302 - distribution_lambda_loss: 50646412.0000121/122 [============================>.] - ETA: 0s - loss: 50610548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6169 - distribution_lambda_loss: 50610548.0000122/122 [==============================] - 1s 11ms/step - loss: 50581896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6019 - distribution_lambda_loss: 50581896.0000 - val_loss: 53100836.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 59.6074 - val_distribution_lambda_loss: 53100836.0000 - lr: 0.0010
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 50660176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.9285 - distribution_lambda_loss: 50660176.0000  6/122 [>.............................] - ETA: 1s - loss: 50370348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.0465 - distribution_lambda_loss: 50370348.0000 11/122 [=>............................] - ETA: 1s - loss: 49182820.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.5758 - distribution_lambda_loss: 49182820.0000 16/122 [==>...........................] - ETA: 1s - loss: 49440028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.6431 - distribution_lambda_loss: 49440028.0000 21/122 [====>.........................] - ETA: 1s - loss: 49758536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8364 - distribution_lambda_loss: 49758536.0000 26/122 [=====>........................] - ETA: 0s - loss: 49272600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.6252 - distribution_lambda_loss: 49272600.0000 31/122 [======>.......................] - ETA: 0s - loss: 49282440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.6631 - distribution_lambda_loss: 49282440.0000 36/122 [=======>......................] - ETA: 0s - loss: 49533280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8077 - distribution_lambda_loss: 49533280.0000 41/122 [=========>....................] - ETA: 0s - loss: 49304724.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7691 - distribution_lambda_loss: 49304724.0000 46/122 [==========>...................] - ETA: 0s - loss: 49345988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8291 - distribution_lambda_loss: 49345988.0000 51/122 [===========>..................] - ETA: 0s - loss: 49175220.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7676 - distribution_lambda_loss: 49175220.0000 56/122 [============>.................] - ETA: 0s - loss: 49129724.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7704 - distribution_lambda_loss: 49129724.0000 61/122 [==============>...............] - ETA: 0s - loss: 49169696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7941 - distribution_lambda_loss: 49169696.0000 66/122 [===============>..............] - ETA: 0s - loss: 49327916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8594 - distribution_lambda_loss: 49327916.0000 71/122 [================>.............] - ETA: 0s - loss: 49169584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7849 - distribution_lambda_loss: 49169584.0000 76/122 [=================>............] - ETA: 0s - loss: 49207604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7983 - distribution_lambda_loss: 49207604.0000 81/122 [==================>...........] - ETA: 0s - loss: 49323328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8669 - distribution_lambda_loss: 49323328.0000 86/122 [====================>.........] - ETA: 0s - loss: 49479976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9105 - distribution_lambda_loss: 49479976.0000 91/122 [=====================>........] - ETA: 0s - loss: 49487136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9274 - distribution_lambda_loss: 49487136.0000 96/122 [======================>.......] - ETA: 0s - loss: 49499548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9484 - distribution_lambda_loss: 49499548.0000101/122 [=======================>......] - ETA: 0s - loss: 49690928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.0302 - distribution_lambda_loss: 49690928.0000106/122 [=========================>....] - ETA: 0s - loss: 49686464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.0018 - distribution_lambda_loss: 49686464.0000111/122 [==========================>...] - ETA: 0s - loss: 49678252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9980 - distribution_lambda_loss: 49678252.0000116/122 [===========================>..] - ETA: 0s - loss: 49665364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9854 - distribution_lambda_loss: 49665364.0000121/122 [============================>.] - ETA: 0s - loss: 49526204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9257 - distribution_lambda_loss: 49526204.0000122/122 [==============================] - 1s 11ms/step - loss: 49515944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9160 - distribution_lambda_loss: 49515944.0000 - val_loss: 51768376.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 60.4406 - val_distribution_lambda_loss: 51768376.0000 - lr: 0.0010
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 45382240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0971 - distribution_lambda_loss: 45382240.0000  6/122 [>.............................] - ETA: 1s - loss: 49141600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9145 - distribution_lambda_loss: 49141600.0000 11/122 [=>............................] - ETA: 1s - loss: 49537432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.6988 - distribution_lambda_loss: 49537432.0000 16/122 [==>...........................] - ETA: 1s - loss: 49195584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7014 - distribution_lambda_loss: 49195584.0000 21/122 [====>.........................] - ETA: 1s - loss: 48972032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.6273 - distribution_lambda_loss: 48972032.0000 26/122 [=====>........................] - ETA: 1s - loss: 48648276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.4075 - distribution_lambda_loss: 48648276.0000 31/122 [======>.......................] - ETA: 0s - loss: 48344272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3253 - distribution_lambda_loss: 48344272.0000 36/122 [=======>......................] - ETA: 0s - loss: 48506892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3041 - distribution_lambda_loss: 48506892.0000 41/122 [=========>....................] - ETA: 0s - loss: 48679748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3865 - distribution_lambda_loss: 48679748.0000 46/122 [==========>...................] - ETA: 0s - loss: 48966424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.4752 - distribution_lambda_loss: 48966424.0000 51/122 [===========>..................] - ETA: 0s - loss: 48937460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.4417 - distribution_lambda_loss: 48937460.0000 56/122 [============>.................] - ETA: 0s - loss: 48837752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3742 - distribution_lambda_loss: 48837752.0000 61/122 [==============>...............] - ETA: 0s - loss: 48695500.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3576 - distribution_lambda_loss: 48695500.0000 66/122 [===============>..............] - ETA: 0s - loss: 48741844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3835 - distribution_lambda_loss: 48741844.0000 71/122 [================>.............] - ETA: 0s - loss: 48625296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3641 - distribution_lambda_loss: 48625296.0000 76/122 [=================>............] - ETA: 0s - loss: 48518988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3046 - distribution_lambda_loss: 48518988.0000 81/122 [==================>...........] - ETA: 0s - loss: 48511360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2918 - distribution_lambda_loss: 48511360.0000 86/122 [====================>.........] - ETA: 0s - loss: 48625260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.3382 - distribution_lambda_loss: 48625260.0000 91/122 [=====================>........] - ETA: 0s - loss: 48501340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2721 - distribution_lambda_loss: 48501340.0000 96/122 [======================>.......] - ETA: 0s - loss: 48522128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2926 - distribution_lambda_loss: 48522128.0000101/122 [=======================>......] - ETA: 0s - loss: 48390036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2150 - distribution_lambda_loss: 48390036.0000106/122 [=========================>....] - ETA: 0s - loss: 48299212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1933 - distribution_lambda_loss: 48299212.0000111/122 [==========================>...] - ETA: 0s - loss: 48315172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1672 - distribution_lambda_loss: 48315172.0000116/122 [===========================>..] - ETA: 0s - loss: 48266464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1545 - distribution_lambda_loss: 48266464.0000121/122 [============================>.] - ETA: 0s - loss: 48252436.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1415 - distribution_lambda_loss: 48252436.0000122/122 [==============================] - 1s 11ms/step - loss: 48227420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1284 - distribution_lambda_loss: 48227420.0000 - val_loss: 50448136.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 57.8808 - val_distribution_lambda_loss: 50448136.0000 - lr: 0.0010
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 45902728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1431 - distribution_lambda_loss: 45902728.0000  6/122 [>.............................] - ETA: 1s - loss: 46614928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3839 - distribution_lambda_loss: 46614928.0000 11/122 [=>............................] - ETA: 1s - loss: 46049440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0165 - distribution_lambda_loss: 46049440.0000 16/122 [==>...........................] - ETA: 1s - loss: 46394864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1869 - distribution_lambda_loss: 46394864.0000 21/122 [====>.........................] - ETA: 1s - loss: 46735660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.2896 - distribution_lambda_loss: 46735660.0000 26/122 [=====>........................] - ETA: 0s - loss: 47384624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5616 - distribution_lambda_loss: 47384624.0000 31/122 [======>.......................] - ETA: 0s - loss: 47641696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7082 - distribution_lambda_loss: 47641696.0000 36/122 [=======>......................] - ETA: 0s - loss: 47813976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7592 - distribution_lambda_loss: 47813976.0000 41/122 [=========>....................] - ETA: 0s - loss: 47774724.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7509 - distribution_lambda_loss: 47774724.0000 46/122 [==========>...................] - ETA: 0s - loss: 47611224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6946 - distribution_lambda_loss: 47611224.0000 51/122 [===========>..................] - ETA: 0s - loss: 47471672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6040 - distribution_lambda_loss: 47471672.0000 56/122 [============>.................] - ETA: 0s - loss: 47435164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6474 - distribution_lambda_loss: 47435164.0000 61/122 [==============>...............] - ETA: 0s - loss: 47499224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6451 - distribution_lambda_loss: 47499224.0000 66/122 [===============>..............] - ETA: 0s - loss: 47735296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.8067 - distribution_lambda_loss: 47735296.0000 71/122 [================>.............] - ETA: 0s - loss: 47856852.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.8516 - distribution_lambda_loss: 47856852.0000 76/122 [=================>............] - ETA: 0s - loss: 47810096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.8149 - distribution_lambda_loss: 47810096.0000 81/122 [==================>...........] - ETA: 0s - loss: 47703888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7644 - distribution_lambda_loss: 47703888.0000 86/122 [====================>.........] - ETA: 0s - loss: 47628956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7194 - distribution_lambda_loss: 47628956.0000 91/122 [=====================>........] - ETA: 0s - loss: 47682680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7581 - distribution_lambda_loss: 47682680.0000 96/122 [======================>.......] - ETA: 0s - loss: 47565228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7148 - distribution_lambda_loss: 47565228.0000101/122 [=======================>......] - ETA: 0s - loss: 47526616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6714 - distribution_lambda_loss: 47526616.0000106/122 [=========================>....] - ETA: 0s - loss: 47519996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6766 - distribution_lambda_loss: 47519996.0000111/122 [==========================>...] - ETA: 0s - loss: 47474964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6418 - distribution_lambda_loss: 47474964.0000116/122 [===========================>..] - ETA: 0s - loss: 47573028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6598 - distribution_lambda_loss: 47573028.0000121/122 [============================>.] - ETA: 0s - loss: 47434664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6055 - distribution_lambda_loss: 47434664.0000122/122 [==============================] - 1s 11ms/step - loss: 47432348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6089 - distribution_lambda_loss: 47432348.0000 - val_loss: 50441380.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 57.6647 - val_distribution_lambda_loss: 50441380.0000 - lr: 0.0010
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 44237864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2096 - distribution_lambda_loss: 44237864.0000  6/122 [>.............................] - ETA: 1s - loss: 48074236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4627 - distribution_lambda_loss: 48074236.0000 11/122 [=>............................] - ETA: 1s - loss: 46861552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1371 - distribution_lambda_loss: 46861552.0000 16/122 [==>...........................] - ETA: 1s - loss: 46768720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0583 - distribution_lambda_loss: 46768720.0000 21/122 [====>.........................] - ETA: 1s - loss: 45892672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.6720 - distribution_lambda_loss: 45892672.0000 26/122 [=====>........................] - ETA: 0s - loss: 45939656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.7521 - distribution_lambda_loss: 45939656.0000 31/122 [======>.......................] - ETA: 0s - loss: 46037148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.7422 - distribution_lambda_loss: 46037148.0000 36/122 [=======>......................] - ETA: 0s - loss: 46445640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9554 - distribution_lambda_loss: 46445640.0000 41/122 [=========>....................] - ETA: 0s - loss: 46224020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.8712 - distribution_lambda_loss: 46224020.0000 46/122 [==========>...................] - ETA: 0s - loss: 46090008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.8317 - distribution_lambda_loss: 46090008.0000 51/122 [===========>..................] - ETA: 0s - loss: 46575948.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0343 - distribution_lambda_loss: 46575948.0000 56/122 [============>.................] - ETA: 0s - loss: 46566932.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0551 - distribution_lambda_loss: 46566932.0000 61/122 [==============>...............] - ETA: 0s - loss: 46445400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0285 - distribution_lambda_loss: 46445400.0000 66/122 [===============>..............] - ETA: 0s - loss: 46376120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9608 - distribution_lambda_loss: 46376120.0000 71/122 [================>.............] - ETA: 0s - loss: 46420316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0337 - distribution_lambda_loss: 46420316.0000 76/122 [=================>............] - ETA: 0s - loss: 46339060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9824 - distribution_lambda_loss: 46339060.0000 81/122 [==================>...........] - ETA: 0s - loss: 46370976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9846 - distribution_lambda_loss: 46370976.0000 86/122 [====================>.........] - ETA: 0s - loss: 46438756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0366 - distribution_lambda_loss: 46438756.0000 91/122 [=====================>........] - ETA: 0s - loss: 46471524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0227 - distribution_lambda_loss: 46471524.0000 96/122 [======================>.......] - ETA: 0s - loss: 46490448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0410 - distribution_lambda_loss: 46490448.0000101/122 [=======================>......] - ETA: 0s - loss: 46442312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9915 - distribution_lambda_loss: 46442312.0000106/122 [=========================>....] - ETA: 0s - loss: 46389200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9611 - distribution_lambda_loss: 46389200.0000111/122 [==========================>...] - ETA: 0s - loss: 46380112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9497 - distribution_lambda_loss: 46380112.0000116/122 [===========================>..] - ETA: 0s - loss: 46340448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9325 - distribution_lambda_loss: 46340448.0000121/122 [============================>.] - ETA: 0s - loss: 46367396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9363 - distribution_lambda_loss: 46367396.0000122/122 [==============================] - 1s 11ms/step - loss: 46371564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9457 - distribution_lambda_loss: 46371564.0000 - val_loss: 50157688.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 56.7526 - val_distribution_lambda_loss: 50157688.0000 - lr: 0.0010
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 49522288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6731 - distribution_lambda_loss: 49522288.0000  6/122 [>.............................] - ETA: 1s - loss: 47126992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3685 - distribution_lambda_loss: 47126992.0000 11/122 [=>............................] - ETA: 1s - loss: 47890328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5606 - distribution_lambda_loss: 47890328.0000 16/122 [==>...........................] - ETA: 1s - loss: 46875392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1038 - distribution_lambda_loss: 46875392.0000 21/122 [====>.........................] - ETA: 1s - loss: 46643244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0996 - distribution_lambda_loss: 46643244.0000 26/122 [=====>........................] - ETA: 0s - loss: 47033156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1967 - distribution_lambda_loss: 47033156.0000 31/122 [======>.......................] - ETA: 0s - loss: 46509352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9416 - distribution_lambda_loss: 46509352.0000 36/122 [=======>......................] - ETA: 0s - loss: 46523136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9408 - distribution_lambda_loss: 46523136.0000 41/122 [=========>....................] - ETA: 0s - loss: 46280980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.8210 - distribution_lambda_loss: 46280980.0000 46/122 [==========>...................] - ETA: 0s - loss: 46169452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.7251 - distribution_lambda_loss: 46169452.0000 51/122 [===========>..................] - ETA: 0s - loss: 46043964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.6968 - distribution_lambda_loss: 46043964.0000 56/122 [============>.................] - ETA: 0s - loss: 45976168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.6351 - distribution_lambda_loss: 45976168.0000 61/122 [==============>...............] - ETA: 0s - loss: 45648572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5081 - distribution_lambda_loss: 45648572.0000 66/122 [===============>..............] - ETA: 0s - loss: 45642536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5173 - distribution_lambda_loss: 45642536.0000 71/122 [================>.............] - ETA: 0s - loss: 45626352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5350 - distribution_lambda_loss: 45626352.0000 76/122 [=================>............] - ETA: 0s - loss: 45700704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5605 - distribution_lambda_loss: 45700704.0000 81/122 [==================>...........] - ETA: 0s - loss: 45640096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5005 - distribution_lambda_loss: 45640096.0000 86/122 [====================>.........] - ETA: 0s - loss: 45614576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5107 - distribution_lambda_loss: 45614576.0000 91/122 [=====================>........] - ETA: 0s - loss: 45580076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4795 - distribution_lambda_loss: 45580076.0000 96/122 [======================>.......] - ETA: 0s - loss: 45666660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5087 - distribution_lambda_loss: 45666660.0000101/122 [=======================>......] - ETA: 0s - loss: 45589636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4662 - distribution_lambda_loss: 45589636.0000106/122 [=========================>....] - ETA: 0s - loss: 45614448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4702 - distribution_lambda_loss: 45614448.0000111/122 [==========================>...] - ETA: 0s - loss: 45528976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4307 - distribution_lambda_loss: 45528976.0000116/122 [===========================>..] - ETA: 0s - loss: 45503532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4165 - distribution_lambda_loss: 45503532.0000121/122 [============================>.] - ETA: 0s - loss: 45653628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4783 - distribution_lambda_loss: 45653628.0000122/122 [==============================] - 1s 11ms/step - loss: 45635452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.4634 - distribution_lambda_loss: 45635452.0000 - val_loss: 49290944.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 57.2880 - val_distribution_lambda_loss: 49290944.0000 - lr: 0.0010
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 49777100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1347 - distribution_lambda_loss: 49777100.0000  6/122 [>.............................] - ETA: 1s - loss: 43082392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1343 - distribution_lambda_loss: 43082392.0000 11/122 [=>............................] - ETA: 1s - loss: 43714980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2801 - distribution_lambda_loss: 43714980.0000 16/122 [==>...........................] - ETA: 1s - loss: 43800728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4944 - distribution_lambda_loss: 43800728.0000 21/122 [====>.........................] - ETA: 1s - loss: 44193812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6550 - distribution_lambda_loss: 44193812.0000 26/122 [=====>........................] - ETA: 0s - loss: 44269656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6981 - distribution_lambda_loss: 44269656.0000 31/122 [======>.......................] - ETA: 0s - loss: 44690008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.9122 - distribution_lambda_loss: 44690008.0000 36/122 [=======>......................] - ETA: 0s - loss: 44647644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.8903 - distribution_lambda_loss: 44647644.0000 41/122 [=========>....................] - ETA: 0s - loss: 44997468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1185 - distribution_lambda_loss: 44997468.0000 46/122 [==========>...................] - ETA: 0s - loss: 44918800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0884 - distribution_lambda_loss: 44918800.0000 51/122 [===========>..................] - ETA: 0s - loss: 44881896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0275 - distribution_lambda_loss: 44881896.0000 56/122 [============>.................] - ETA: 0s - loss: 44986728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1186 - distribution_lambda_loss: 44986728.0000 61/122 [==============>...............] - ETA: 0s - loss: 44834864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0325 - distribution_lambda_loss: 44834864.0000 66/122 [===============>..............] - ETA: 0s - loss: 44880504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0441 - distribution_lambda_loss: 44880504.0000 71/122 [================>.............] - ETA: 0s - loss: 44860388.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0488 - distribution_lambda_loss: 44860388.0000 76/122 [=================>............] - ETA: 0s - loss: 44924604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0438 - distribution_lambda_loss: 44924604.0000 81/122 [==================>...........] - ETA: 0s - loss: 45021540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1262 - distribution_lambda_loss: 45021540.0000 86/122 [====================>.........] - ETA: 0s - loss: 44922320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0526 - distribution_lambda_loss: 44922320.0000 91/122 [=====================>........] - ETA: 0s - loss: 44913108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0592 - distribution_lambda_loss: 44913108.0000 96/122 [======================>.......] - ETA: 0s - loss: 44841424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.9991 - distribution_lambda_loss: 44841424.0000101/122 [=======================>......] - ETA: 0s - loss: 44931464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0490 - distribution_lambda_loss: 44931464.0000106/122 [=========================>....] - ETA: 0s - loss: 44937900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0401 - distribution_lambda_loss: 44937900.0000111/122 [==========================>...] - ETA: 0s - loss: 44905976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0114 - distribution_lambda_loss: 44905976.0000116/122 [===========================>..] - ETA: 0s - loss: 44911756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0223 - distribution_lambda_loss: 44911756.0000121/122 [============================>.] - ETA: 0s - loss: 44894776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0167 - distribution_lambda_loss: 44894776.0000122/122 [==============================] - 1s 11ms/step - loss: 44870616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0075 - distribution_lambda_loss: 44870616.0000 - val_loss: 47947492.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.7479 - val_distribution_lambda_loss: 47947492.0000 - lr: 0.0010
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 43843160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1675 - distribution_lambda_loss: 43843160.0000  6/122 [>.............................] - ETA: 1s - loss: 43784300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1806 - distribution_lambda_loss: 43784300.0000 11/122 [=>............................] - ETA: 1s - loss: 44143012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5189 - distribution_lambda_loss: 44143012.0000 16/122 [==>...........................] - ETA: 1s - loss: 44101800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5759 - distribution_lambda_loss: 44101800.0000 21/122 [====>.........................] - ETA: 1s - loss: 43882032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5519 - distribution_lambda_loss: 43882032.0000 26/122 [=====>........................] - ETA: 1s - loss: 43675540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4389 - distribution_lambda_loss: 43675540.0000 32/122 [======>.......................] - ETA: 0s - loss: 43918732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5599 - distribution_lambda_loss: 43918732.0000 37/122 [========>.....................] - ETA: 0s - loss: 44112384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5903 - distribution_lambda_loss: 44112384.0000 42/122 [=========>....................] - ETA: 0s - loss: 44019368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5734 - distribution_lambda_loss: 44019368.0000 47/122 [==========>...................] - ETA: 0s - loss: 43953576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4949 - distribution_lambda_loss: 43953576.0000 52/122 [===========>..................] - ETA: 0s - loss: 44202308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6666 - distribution_lambda_loss: 44202308.0000 57/122 [=============>................] - ETA: 0s - loss: 44380268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.7508 - distribution_lambda_loss: 44380268.0000 62/122 [==============>...............] - ETA: 0s - loss: 44272344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.7002 - distribution_lambda_loss: 44272344.0000 67/122 [===============>..............] - ETA: 0s - loss: 44257732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6905 - distribution_lambda_loss: 44257732.0000 72/122 [================>.............] - ETA: 0s - loss: 44252260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6642 - distribution_lambda_loss: 44252260.0000 77/122 [=================>............] - ETA: 0s - loss: 44291300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6747 - distribution_lambda_loss: 44291300.0000 82/122 [===================>..........] - ETA: 0s - loss: 44043932.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5062 - distribution_lambda_loss: 44043932.0000 87/122 [====================>.........] - ETA: 0s - loss: 43909904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4334 - distribution_lambda_loss: 43909904.0000 92/122 [=====================>........] - ETA: 0s - loss: 43882148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4006 - distribution_lambda_loss: 43882148.0000 97/122 [======================>.......] - ETA: 0s - loss: 43837208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3802 - distribution_lambda_loss: 43837208.0000102/122 [========================>.....] - ETA: 0s - loss: 43882896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3758 - distribution_lambda_loss: 43882896.0000107/122 [=========================>....] - ETA: 0s - loss: 43815012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3389 - distribution_lambda_loss: 43815012.0000112/122 [==========================>...] - ETA: 0s - loss: 43780520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3252 - distribution_lambda_loss: 43780520.0000117/122 [===========================>..] - ETA: 0s - loss: 43819760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3446 - distribution_lambda_loss: 43819760.0000122/122 [==============================] - 1s 11ms/step - loss: 43890656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3857 - distribution_lambda_loss: 43890656.0000 - val_loss: 46220720.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 56.1845 - val_distribution_lambda_loss: 46220720.0000 - lr: 0.0010
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 44569772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.8366 - distribution_lambda_loss: 44569772.0000  6/122 [>.............................] - ETA: 1s - loss: 43100584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9693 - distribution_lambda_loss: 43100584.0000 11/122 [=>............................] - ETA: 1s - loss: 42697752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7348 - distribution_lambda_loss: 42697752.0000 16/122 [==>...........................] - ETA: 1s - loss: 42537748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6389 - distribution_lambda_loss: 42537748.0000 21/122 [====>.........................] - ETA: 1s - loss: 42657108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6887 - distribution_lambda_loss: 42657108.0000 26/122 [=====>........................] - ETA: 0s - loss: 42563844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5680 - distribution_lambda_loss: 42563844.0000 31/122 [======>.......................] - ETA: 0s - loss: 42622160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7042 - distribution_lambda_loss: 42622160.0000 36/122 [=======>......................] - ETA: 0s - loss: 42712528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7147 - distribution_lambda_loss: 42712528.0000 41/122 [=========>....................] - ETA: 0s - loss: 42892900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8235 - distribution_lambda_loss: 42892900.0000 46/122 [==========>...................] - ETA: 0s - loss: 42935292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8142 - distribution_lambda_loss: 42935292.0000 51/122 [===========>..................] - ETA: 0s - loss: 42952604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8087 - distribution_lambda_loss: 42952604.0000 56/122 [============>.................] - ETA: 0s - loss: 43079244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9079 - distribution_lambda_loss: 43079244.0000 61/122 [==============>...............] - ETA: 0s - loss: 43208200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9845 - distribution_lambda_loss: 43208200.0000 66/122 [===============>..............] - ETA: 0s - loss: 43224676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9710 - distribution_lambda_loss: 43224676.0000 71/122 [================>.............] - ETA: 0s - loss: 43256604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0259 - distribution_lambda_loss: 43256604.0000 76/122 [=================>............] - ETA: 0s - loss: 43235828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9896 - distribution_lambda_loss: 43235828.0000 81/122 [==================>...........] - ETA: 0s - loss: 43296984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0183 - distribution_lambda_loss: 43296984.0000 86/122 [====================>.........] - ETA: 0s - loss: 43410400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1095 - distribution_lambda_loss: 43410400.0000 91/122 [=====================>........] - ETA: 0s - loss: 43432140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1230 - distribution_lambda_loss: 43432140.0000 96/122 [======================>.......] - ETA: 0s - loss: 43498840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1834 - distribution_lambda_loss: 43498840.0000101/122 [=======================>......] - ETA: 0s - loss: 43492376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1487 - distribution_lambda_loss: 43492376.0000106/122 [=========================>....] - ETA: 0s - loss: 43472548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1577 - distribution_lambda_loss: 43472548.0000111/122 [==========================>...] - ETA: 0s - loss: 43463616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1403 - distribution_lambda_loss: 43463616.0000116/122 [===========================>..] - ETA: 0s - loss: 43415076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1072 - distribution_lambda_loss: 43415076.0000121/122 [============================>.] - ETA: 0s - loss: 43377924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0802 - distribution_lambda_loss: 43377924.0000122/122 [==============================] - 1s 11ms/step - loss: 43389360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0832 - distribution_lambda_loss: 43389360.0000 - val_loss: 45746336.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.1474 - val_distribution_lambda_loss: 45746336.0000 - lr: 0.0010
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 46497272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5817 - distribution_lambda_loss: 46497272.0000  6/122 [>.............................] - ETA: 1s - loss: 43479076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9246 - distribution_lambda_loss: 43479076.0000 11/122 [=>............................] - ETA: 1s - loss: 42989472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6363 - distribution_lambda_loss: 42989472.0000 16/122 [==>...........................] - ETA: 1s - loss: 42749548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5909 - distribution_lambda_loss: 42749548.0000 21/122 [====>.........................] - ETA: 1s - loss: 42529116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4649 - distribution_lambda_loss: 42529116.0000 26/122 [=====>........................] - ETA: 0s - loss: 42878480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7028 - distribution_lambda_loss: 42878480.0000 31/122 [======>.......................] - ETA: 0s - loss: 42510960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5362 - distribution_lambda_loss: 42510960.0000 36/122 [=======>......................] - ETA: 0s - loss: 42346936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4992 - distribution_lambda_loss: 42346936.0000 41/122 [=========>....................] - ETA: 0s - loss: 42403548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5078 - distribution_lambda_loss: 42403548.0000 46/122 [==========>...................] - ETA: 0s - loss: 42503580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6262 - distribution_lambda_loss: 42503580.0000 51/122 [===========>..................] - ETA: 0s - loss: 42569432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5968 - distribution_lambda_loss: 42569432.0000 56/122 [============>.................] - ETA: 0s - loss: 42498468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5923 - distribution_lambda_loss: 42498468.0000 61/122 [==============>...............] - ETA: 0s - loss: 42612036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6534 - distribution_lambda_loss: 42612036.0000 66/122 [===============>..............] - ETA: 0s - loss: 42449252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5758 - distribution_lambda_loss: 42449252.0000 71/122 [================>.............] - ETA: 0s - loss: 42476520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5970 - distribution_lambda_loss: 42476520.0000 76/122 [=================>............] - ETA: 0s - loss: 42421444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5527 - distribution_lambda_loss: 42421444.0000 81/122 [==================>...........] - ETA: 0s - loss: 42506640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6026 - distribution_lambda_loss: 42506640.0000 86/122 [====================>.........] - ETA: 0s - loss: 42465008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5839 - distribution_lambda_loss: 42465008.0000 91/122 [=====================>........] - ETA: 0s - loss: 42467324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5768 - distribution_lambda_loss: 42467324.0000 96/122 [======================>.......] - ETA: 0s - loss: 42487496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5735 - distribution_lambda_loss: 42487496.0000101/122 [=======================>......] - ETA: 0s - loss: 42497036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5728 - distribution_lambda_loss: 42497036.0000106/122 [=========================>....] - ETA: 0s - loss: 42421808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5417 - distribution_lambda_loss: 42421808.0000111/122 [==========================>...] - ETA: 0s - loss: 42481964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5590 - distribution_lambda_loss: 42481964.0000116/122 [===========================>..] - ETA: 0s - loss: 42447812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5245 - distribution_lambda_loss: 42447812.0000121/122 [============================>.] - ETA: 0s - loss: 42389184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5172 - distribution_lambda_loss: 42389184.0000122/122 [==============================] - 1s 11ms/step - loss: 42406248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5144 - distribution_lambda_loss: 42406248.0000 - val_loss: 44400820.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.8548 - val_distribution_lambda_loss: 44400820.0000 - lr: 0.0010
Epoch 22/50
  1/122 [..............................] - ETA: 1s - loss: 46391152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5079 - distribution_lambda_loss: 46391152.0000  6/122 [>.............................] - ETA: 1s - loss: 42310364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5175 - distribution_lambda_loss: 42310364.0000 11/122 [=>............................] - ETA: 1s - loss: 41711740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1687 - distribution_lambda_loss: 41711740.0000 16/122 [==>...........................] - ETA: 1s - loss: 41345788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9319 - distribution_lambda_loss: 41345788.0000 21/122 [====>.........................] - ETA: 1s - loss: 41389888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9638 - distribution_lambda_loss: 41389888.0000 26/122 [=====>........................] - ETA: 1s - loss: 41350632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8721 - distribution_lambda_loss: 41350632.0000 31/122 [======>.......................] - ETA: 0s - loss: 41183472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7914 - distribution_lambda_loss: 41183472.0000 36/122 [=======>......................] - ETA: 0s - loss: 41232304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8337 - distribution_lambda_loss: 41232304.0000 41/122 [=========>....................] - ETA: 0s - loss: 41280276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8426 - distribution_lambda_loss: 41280276.0000 46/122 [==========>...................] - ETA: 0s - loss: 41126292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7681 - distribution_lambda_loss: 41126292.0000 51/122 [===========>..................] - ETA: 0s - loss: 41239788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8428 - distribution_lambda_loss: 41239788.0000 56/122 [============>.................] - ETA: 0s - loss: 41134852.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8037 - distribution_lambda_loss: 41134852.0000 61/122 [==============>...............] - ETA: 0s - loss: 41157144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8076 - distribution_lambda_loss: 41157144.0000 66/122 [===============>..............] - ETA: 0s - loss: 41180324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8454 - distribution_lambda_loss: 41180324.0000 71/122 [================>.............] - ETA: 0s - loss: 41219600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8420 - distribution_lambda_loss: 41219600.0000 76/122 [=================>............] - ETA: 0s - loss: 41248552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8653 - distribution_lambda_loss: 41248552.0000 81/122 [==================>...........] - ETA: 0s - loss: 41236728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8484 - distribution_lambda_loss: 41236728.0000 86/122 [====================>.........] - ETA: 0s - loss: 41246296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8569 - distribution_lambda_loss: 41246296.0000 91/122 [=====================>........] - ETA: 0s - loss: 41251996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8476 - distribution_lambda_loss: 41251996.0000 96/122 [======================>.......] - ETA: 0s - loss: 41228068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8332 - distribution_lambda_loss: 41228068.0000101/122 [=======================>......] - ETA: 0s - loss: 41287416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8432 - distribution_lambda_loss: 41287416.0000106/122 [=========================>....] - ETA: 0s - loss: 41320588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8852 - distribution_lambda_loss: 41320588.0000111/122 [==========================>...] - ETA: 0s - loss: 41364864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8988 - distribution_lambda_loss: 41364864.0000116/122 [===========================>..] - ETA: 0s - loss: 41466804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9679 - distribution_lambda_loss: 41466804.0000121/122 [============================>.] - ETA: 0s - loss: 41486904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9683 - distribution_lambda_loss: 41486904.0000122/122 [==============================] - 1s 11ms/step - loss: 41487348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9682 - distribution_lambda_loss: 41487348.0000 - val_loss: 45106756.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 58.3646 - val_distribution_lambda_loss: 45106756.0000 - lr: 0.0010
Epoch 23/50
  1/122 [..............................] - ETA: 1s - loss: 45410124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1796 - distribution_lambda_loss: 45410124.0000  6/122 [>.............................] - ETA: 1s - loss: 41592204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9883 - distribution_lambda_loss: 41592204.0000 11/122 [=>............................] - ETA: 1s - loss: 41407352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9817 - distribution_lambda_loss: 41407352.0000 16/122 [==>...........................] - ETA: 1s - loss: 41291200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9747 - distribution_lambda_loss: 41291200.0000 21/122 [====>.........................] - ETA: 1s - loss: 41003412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8079 - distribution_lambda_loss: 41003412.0000 26/122 [=====>........................] - ETA: 1s - loss: 41234920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8224 - distribution_lambda_loss: 41234920.0000 31/122 [======>.......................] - ETA: 0s - loss: 41062460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7954 - distribution_lambda_loss: 41062460.0000 36/122 [=======>......................] - ETA: 0s - loss: 41143344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7949 - distribution_lambda_loss: 41143344.0000 41/122 [=========>....................] - ETA: 0s - loss: 40952264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7022 - distribution_lambda_loss: 40952264.0000 46/122 [==========>...................] - ETA: 0s - loss: 40994092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7426 - distribution_lambda_loss: 40994092.0000 51/122 [===========>..................] - ETA: 0s - loss: 41128432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7728 - distribution_lambda_loss: 41128432.0000 56/122 [============>.................] - ETA: 0s - loss: 41150648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8202 - distribution_lambda_loss: 41150648.0000 61/122 [==============>...............] - ETA: 0s - loss: 41250488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8474 - distribution_lambda_loss: 41250488.0000 66/122 [===============>..............] - ETA: 0s - loss: 41218968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8587 - distribution_lambda_loss: 41218968.0000 71/122 [================>.............] - ETA: 0s - loss: 41174804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8104 - distribution_lambda_loss: 41174804.0000 76/122 [=================>............] - ETA: 0s - loss: 41133236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7955 - distribution_lambda_loss: 41133236.0000 81/122 [==================>...........] - ETA: 0s - loss: 41119828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7742 - distribution_lambda_loss: 41119828.0000 86/122 [====================>.........] - ETA: 0s - loss: 41032844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7294 - distribution_lambda_loss: 41032844.0000 91/122 [=====================>........] - ETA: 0s - loss: 40963096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6888 - distribution_lambda_loss: 40963096.0000 96/122 [======================>.......] - ETA: 0s - loss: 40960996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6852 - distribution_lambda_loss: 40960996.0000101/122 [=======================>......] - ETA: 0s - loss: 41041060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7271 - distribution_lambda_loss: 41041060.0000106/122 [=========================>....] - ETA: 0s - loss: 41093564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7560 - distribution_lambda_loss: 41093564.0000111/122 [==========================>...] - ETA: 0s - loss: 41082588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7473 - distribution_lambda_loss: 41082588.0000116/122 [===========================>..] - ETA: 0s - loss: 41087848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7594 - distribution_lambda_loss: 41087848.0000121/122 [============================>.] - ETA: 0s - loss: 40988316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6934 - distribution_lambda_loss: 40988316.0000122/122 [==============================] - 1s 11ms/step - loss: 40974872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6900 - distribution_lambda_loss: 40974872.0000 - val_loss: 41997740.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 53.7509 - val_distribution_lambda_loss: 41997740.0000 - lr: 0.0010
Epoch 24/50
  1/122 [..............................] - ETA: 1s - loss: 39363720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.3864 - distribution_lambda_loss: 39363720.0000  6/122 [>.............................] - ETA: 1s - loss: 40776400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4562 - distribution_lambda_loss: 40776400.0000 11/122 [=>............................] - ETA: 1s - loss: 40227032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3905 - distribution_lambda_loss: 40227032.0000 16/122 [==>...........................] - ETA: 1s - loss: 40150280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1420 - distribution_lambda_loss: 40150280.0000 21/122 [====>.........................] - ETA: 1s - loss: 40463020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3598 - distribution_lambda_loss: 40463020.0000 26/122 [=====>........................] - ETA: 0s - loss: 40301256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2333 - distribution_lambda_loss: 40301256.0000 31/122 [======>.......................] - ETA: 0s - loss: 40379160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2904 - distribution_lambda_loss: 40379160.0000 36/122 [=======>......................] - ETA: 0s - loss: 40629452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3912 - distribution_lambda_loss: 40629452.0000 41/122 [=========>....................] - ETA: 0s - loss: 40499348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3047 - distribution_lambda_loss: 40499348.0000 46/122 [==========>...................] - ETA: 0s - loss: 40531684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3068 - distribution_lambda_loss: 40531684.0000 51/122 [===========>..................] - ETA: 0s - loss: 40437088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2565 - distribution_lambda_loss: 40437088.0000 56/122 [============>.................] - ETA: 0s - loss: 40358084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2440 - distribution_lambda_loss: 40358084.0000 61/122 [==============>...............] - ETA: 0s - loss: 40412540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2729 - distribution_lambda_loss: 40412540.0000 66/122 [===============>..............] - ETA: 0s - loss: 40375780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2492 - distribution_lambda_loss: 40375780.0000 71/122 [================>.............] - ETA: 0s - loss: 40286516.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1938 - distribution_lambda_loss: 40286516.0000 76/122 [=================>............] - ETA: 0s - loss: 40304504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2270 - distribution_lambda_loss: 40304504.0000 81/122 [==================>...........] - ETA: 0s - loss: 40419344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2897 - distribution_lambda_loss: 40419344.0000 86/122 [====================>.........] - ETA: 0s - loss: 40420672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3040 - distribution_lambda_loss: 40420672.0000 91/122 [=====================>........] - ETA: 0s - loss: 40412580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2916 - distribution_lambda_loss: 40412580.0000 96/122 [======================>.......] - ETA: 0s - loss: 40345556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2473 - distribution_lambda_loss: 40345556.0000101/122 [=======================>......] - ETA: 0s - loss: 40361424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2704 - distribution_lambda_loss: 40361424.0000106/122 [=========================>....] - ETA: 0s - loss: 40857480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6531 - distribution_lambda_loss: 40857480.0000111/122 [==========================>...] - ETA: 0s - loss: 41235544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8640 - distribution_lambda_loss: 41235544.0000116/122 [===========================>..] - ETA: 0s - loss: 41333068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9401 - distribution_lambda_loss: 41333068.0000121/122 [============================>.] - ETA: 0s - loss: 41441920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.0347 - distribution_lambda_loss: 41441920.0000122/122 [==============================] - 1s 11ms/step - loss: 41424412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.0243 - distribution_lambda_loss: 41424412.0000 - val_loss: 43660808.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 54.2642 - val_distribution_lambda_loss: 43660808.0000 - lr: 0.0010
Epoch 25/50
  1/122 [..............................] - ETA: 1s - loss: 43001520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7983 - distribution_lambda_loss: 43001520.0000  6/122 [>.............................] - ETA: 1s - loss: 42115012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2511 - distribution_lambda_loss: 42115012.0000 11/122 [=>............................] - ETA: 1s - loss: 41722752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2055 - distribution_lambda_loss: 41722752.0000 16/122 [==>...........................] - ETA: 1s - loss: 41272384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8531 - distribution_lambda_loss: 41272384.0000 21/122 [====>.........................] - ETA: 1s - loss: 41034848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7392 - distribution_lambda_loss: 41034848.0000 26/122 [=====>........................] - ETA: 1s - loss: 40937700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6990 - distribution_lambda_loss: 40937700.0000 31/122 [======>.......................] - ETA: 0s - loss: 40810928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5494 - distribution_lambda_loss: 40810928.0000 36/122 [=======>......................] - ETA: 0s - loss: 40622048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4945 - distribution_lambda_loss: 40622048.0000 41/122 [=========>....................] - ETA: 0s - loss: 40599260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4517 - distribution_lambda_loss: 40599260.0000 46/122 [==========>...................] - ETA: 0s - loss: 40594960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4645 - distribution_lambda_loss: 40594960.0000 52/122 [===========>..................] - ETA: 0s - loss: 40627328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4698 - distribution_lambda_loss: 40627328.0000 57/122 [=============>................] - ETA: 0s - loss: 40510752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3995 - distribution_lambda_loss: 40510752.0000 62/122 [==============>...............] - ETA: 0s - loss: 40442016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3496 - distribution_lambda_loss: 40442016.0000 67/122 [===============>..............] - ETA: 0s - loss: 40362680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3354 - distribution_lambda_loss: 40362680.0000 72/122 [================>.............] - ETA: 0s - loss: 40335972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3093 - distribution_lambda_loss: 40335972.0000 77/122 [=================>............] - ETA: 0s - loss: 40340528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3186 - distribution_lambda_loss: 40340528.0000 82/122 [===================>..........] - ETA: 0s - loss: 40346548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3107 - distribution_lambda_loss: 40346548.0000 87/122 [====================>.........] - ETA: 0s - loss: 40366788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3400 - distribution_lambda_loss: 40366788.0000 92/122 [=====================>........] - ETA: 0s - loss: 40501756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4031 - distribution_lambda_loss: 40501756.0000 97/122 [======================>.......] - ETA: 0s - loss: 40695556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5405 - distribution_lambda_loss: 40695556.0000102/122 [========================>.....] - ETA: 0s - loss: 40693644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5133 - distribution_lambda_loss: 40693644.0000107/122 [=========================>....] - ETA: 0s - loss: 40634972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4816 - distribution_lambda_loss: 40634972.0000112/122 [==========================>...] - ETA: 0s - loss: 40680508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5037 - distribution_lambda_loss: 40680508.0000117/122 [===========================>..] - ETA: 0s - loss: 40646980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4785 - distribution_lambda_loss: 40646980.0000
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 40638592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4629 - distribution_lambda_loss: 40638592.0000 - val_loss: 42707216.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.2107 - val_distribution_lambda_loss: 42707216.0000 - lr: 0.0010
Epoch 26/50
  1/122 [..............................] - ETA: 1s - loss: 42026384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8743 - distribution_lambda_loss: 42026384.0000  6/122 [>.............................] - ETA: 1s - loss: 39869564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8697 - distribution_lambda_loss: 39869564.0000 11/122 [=>............................] - ETA: 1s - loss: 39101096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.3913 - distribution_lambda_loss: 39101096.0000 16/122 [==>...........................] - ETA: 1s - loss: 39186180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5398 - distribution_lambda_loss: 39186180.0000 21/122 [====>.........................] - ETA: 1s - loss: 38900308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.3460 - distribution_lambda_loss: 38900308.0000 26/122 [=====>........................] - ETA: 0s - loss: 38610436.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1334 - distribution_lambda_loss: 38610436.0000 31/122 [======>.......................] - ETA: 0s - loss: 38404188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0007 - distribution_lambda_loss: 38404188.0000 36/122 [=======>......................] - ETA: 0s - loss: 38314152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9692 - distribution_lambda_loss: 38314152.0000 41/122 [=========>....................] - ETA: 0s - loss: 38427368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0490 - distribution_lambda_loss: 38427368.0000 46/122 [==========>...................] - ETA: 0s - loss: 38314124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9590 - distribution_lambda_loss: 38314124.0000 51/122 [===========>..................] - ETA: 0s - loss: 38275708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9429 - distribution_lambda_loss: 38275708.0000 56/122 [============>.................] - ETA: 0s - loss: 38291528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9641 - distribution_lambda_loss: 38291528.0000 61/122 [==============>...............] - ETA: 0s - loss: 38382392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0232 - distribution_lambda_loss: 38382392.0000 66/122 [===============>..............] - ETA: 0s - loss: 38412284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0357 - distribution_lambda_loss: 38412284.0000 71/122 [================>.............] - ETA: 0s - loss: 38371272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0010 - distribution_lambda_loss: 38371272.0000 76/122 [=================>............] - ETA: 0s - loss: 38306540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9712 - distribution_lambda_loss: 38306540.0000 81/122 [==================>...........] - ETA: 0s - loss: 38285480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9615 - distribution_lambda_loss: 38285480.0000 86/122 [====================>.........] - ETA: 0s - loss: 38289508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9708 - distribution_lambda_loss: 38289508.0000 91/122 [=====================>........] - ETA: 0s - loss: 38264992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9485 - distribution_lambda_loss: 38264992.0000 96/122 [======================>.......] - ETA: 0s - loss: 38254976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9377 - distribution_lambda_loss: 38254976.0000101/122 [=======================>......] - ETA: 0s - loss: 38261256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9361 - distribution_lambda_loss: 38261256.0000106/122 [=========================>....] - ETA: 0s - loss: 38257816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9199 - distribution_lambda_loss: 38257816.0000111/122 [==========================>...] - ETA: 0s - loss: 38239992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9126 - distribution_lambda_loss: 38239992.0000116/122 [===========================>..] - ETA: 0s - loss: 38204272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8963 - distribution_lambda_loss: 38204272.0000121/122 [============================>.] - ETA: 0s - loss: 38189680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8864 - distribution_lambda_loss: 38189680.0000122/122 [==============================] - 1s 11ms/step - loss: 38181396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8801 - distribution_lambda_loss: 38181396.0000 - val_loss: 39661696.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 53.3082 - val_distribution_lambda_loss: 39661696.0000 - lr: 5.0000e-04
Epoch 27/50
  1/122 [..............................] - ETA: 1s - loss: 38132508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.4358 - distribution_lambda_loss: 38132508.0000  6/122 [>.............................] - ETA: 1s - loss: 38350000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1767 - distribution_lambda_loss: 38350000.0000 11/122 [=>............................] - ETA: 1s - loss: 37604900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6666 - distribution_lambda_loss: 37604900.0000 16/122 [==>...........................] - ETA: 1s - loss: 37910216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8269 - distribution_lambda_loss: 37910216.0000 21/122 [====>.........................] - ETA: 1s - loss: 37924472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8351 - distribution_lambda_loss: 37924472.0000 26/122 [=====>........................] - ETA: 0s - loss: 37840656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7938 - distribution_lambda_loss: 37840656.0000 31/122 [======>.......................] - ETA: 0s - loss: 37872580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7682 - distribution_lambda_loss: 37872580.0000 36/122 [=======>......................] - ETA: 0s - loss: 38024664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8311 - distribution_lambda_loss: 38024664.0000 41/122 [=========>....................] - ETA: 0s - loss: 37891072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7258 - distribution_lambda_loss: 37891072.0000 46/122 [==========>...................] - ETA: 0s - loss: 37776680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6728 - distribution_lambda_loss: 37776680.0000 51/122 [===========>..................] - ETA: 0s - loss: 37818256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6778 - distribution_lambda_loss: 37818256.0000 56/122 [============>.................] - ETA: 0s - loss: 37704916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6028 - distribution_lambda_loss: 37704916.0000 61/122 [==============>...............] - ETA: 0s - loss: 37664688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5661 - distribution_lambda_loss: 37664688.0000 66/122 [===============>..............] - ETA: 0s - loss: 37676460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5671 - distribution_lambda_loss: 37676460.0000 71/122 [================>.............] - ETA: 0s - loss: 37666828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5831 - distribution_lambda_loss: 37666828.0000 76/122 [=================>............] - ETA: 0s - loss: 37626900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5694 - distribution_lambda_loss: 37626900.0000 81/122 [==================>...........] - ETA: 0s - loss: 37650564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5743 - distribution_lambda_loss: 37650564.0000 86/122 [====================>.........] - ETA: 0s - loss: 37631660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5497 - distribution_lambda_loss: 37631660.0000 91/122 [=====================>........] - ETA: 0s - loss: 37612812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5346 - distribution_lambda_loss: 37612812.0000 96/122 [======================>.......] - ETA: 0s - loss: 37601028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5162 - distribution_lambda_loss: 37601028.0000101/122 [=======================>......] - ETA: 0s - loss: 37563480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5033 - distribution_lambda_loss: 37563480.0000106/122 [=========================>....] - ETA: 0s - loss: 37543196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4929 - distribution_lambda_loss: 37543196.0000111/122 [==========================>...] - ETA: 0s - loss: 37569952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4946 - distribution_lambda_loss: 37569952.0000116/122 [===========================>..] - ETA: 0s - loss: 37593784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5029 - distribution_lambda_loss: 37593784.0000121/122 [============================>.] - ETA: 0s - loss: 37592060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5128 - distribution_lambda_loss: 37592060.0000122/122 [==============================] - 1s 11ms/step - loss: 37594540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5152 - distribution_lambda_loss: 37594540.0000 - val_loss: 39492032.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.5399 - val_distribution_lambda_loss: 39492032.0000 - lr: 5.0000e-04
Epoch 28/50
  1/122 [..............................] - ETA: 1s - loss: 38074424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8674 - distribution_lambda_loss: 38074424.0000  6/122 [>.............................] - ETA: 1s - loss: 37459408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3631 - distribution_lambda_loss: 37459408.0000 11/122 [=>............................] - ETA: 1s - loss: 37156292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1718 - distribution_lambda_loss: 37156292.0000 16/122 [==>...........................] - ETA: 1s - loss: 37389120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2992 - distribution_lambda_loss: 37389120.0000 21/122 [====>.........................] - ETA: 1s - loss: 37322096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2448 - distribution_lambda_loss: 37322096.0000 26/122 [=====>........................] - ETA: 0s - loss: 37631812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4377 - distribution_lambda_loss: 37631812.0000 31/122 [======>.......................] - ETA: 0s - loss: 37623088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4772 - distribution_lambda_loss: 37623088.0000 36/122 [=======>......................] - ETA: 0s - loss: 37533540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4557 - distribution_lambda_loss: 37533540.0000 41/122 [=========>....................] - ETA: 0s - loss: 37360380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3786 - distribution_lambda_loss: 37360380.0000 46/122 [==========>...................] - ETA: 0s - loss: 37422508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3727 - distribution_lambda_loss: 37422508.0000 51/122 [===========>..................] - ETA: 0s - loss: 37293432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2937 - distribution_lambda_loss: 37293432.0000 56/122 [============>.................] - ETA: 0s - loss: 37322432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3074 - distribution_lambda_loss: 37322432.0000 61/122 [==============>...............] - ETA: 0s - loss: 37316212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3241 - distribution_lambda_loss: 37316212.0000 66/122 [===============>..............] - ETA: 0s - loss: 37283944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3089 - distribution_lambda_loss: 37283944.0000 71/122 [================>.............] - ETA: 0s - loss: 37273684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2980 - distribution_lambda_loss: 37273684.0000 76/122 [=================>............] - ETA: 0s - loss: 37227808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2716 - distribution_lambda_loss: 37227808.0000 81/122 [==================>...........] - ETA: 0s - loss: 37350620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3415 - distribution_lambda_loss: 37350620.0000 86/122 [====================>.........] - ETA: 0s - loss: 37329580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3220 - distribution_lambda_loss: 37329580.0000 91/122 [=====================>........] - ETA: 0s - loss: 37296300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3044 - distribution_lambda_loss: 37296300.0000 96/122 [======================>.......] - ETA: 0s - loss: 37307736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3209 - distribution_lambda_loss: 37307736.0000101/122 [=======================>......] - ETA: 0s - loss: 37261468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2861 - distribution_lambda_loss: 37261468.0000106/122 [=========================>....] - ETA: 0s - loss: 37291736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2951 - distribution_lambda_loss: 37291736.0000111/122 [==========================>...] - ETA: 0s - loss: 37234984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2609 - distribution_lambda_loss: 37234984.0000116/122 [===========================>..] - ETA: 0s - loss: 37281996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2842 - distribution_lambda_loss: 37281996.0000121/122 [============================>.] - ETA: 0s - loss: 37266320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2788 - distribution_lambda_loss: 37266320.0000122/122 [==============================] - 1s 11ms/step - loss: 37262364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2727 - distribution_lambda_loss: 37262364.0000 - val_loss: 39036456.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.9286 - val_distribution_lambda_loss: 39036456.0000 - lr: 5.0000e-04
Epoch 29/50
  1/122 [..............................] - ETA: 1s - loss: 35078752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4362 - distribution_lambda_loss: 35078752.0000  6/122 [>.............................] - ETA: 1s - loss: 37469364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2208 - distribution_lambda_loss: 37469364.0000 11/122 [=>............................] - ETA: 1s - loss: 37205188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1983 - distribution_lambda_loss: 37205188.0000 16/122 [==>...........................] - ETA: 1s - loss: 37414432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3154 - distribution_lambda_loss: 37414432.0000 21/122 [====>.........................] - ETA: 1s - loss: 37320140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2739 - distribution_lambda_loss: 37320140.0000 26/122 [=====>........................] - ETA: 0s - loss: 37188068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2306 - distribution_lambda_loss: 37188068.0000 31/122 [======>.......................] - ETA: 0s - loss: 37124140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2218 - distribution_lambda_loss: 37124140.0000 36/122 [=======>......................] - ETA: 0s - loss: 37075824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1889 - distribution_lambda_loss: 37075824.0000 41/122 [=========>....................] - ETA: 0s - loss: 37004864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1407 - distribution_lambda_loss: 37004864.0000 46/122 [==========>...................] - ETA: 0s - loss: 37034000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1558 - distribution_lambda_loss: 37034000.0000 51/122 [===========>..................] - ETA: 0s - loss: 36985048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1033 - distribution_lambda_loss: 36985048.0000 56/122 [============>.................] - ETA: 0s - loss: 37040216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1170 - distribution_lambda_loss: 37040216.0000 61/122 [==============>...............] - ETA: 0s - loss: 37079560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1393 - distribution_lambda_loss: 37079560.0000 66/122 [===============>..............] - ETA: 0s - loss: 37164064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2020 - distribution_lambda_loss: 37164064.0000 71/122 [================>.............] - ETA: 0s - loss: 37151052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1961 - distribution_lambda_loss: 37151052.0000 76/122 [=================>............] - ETA: 0s - loss: 37103556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1668 - distribution_lambda_loss: 37103556.0000 81/122 [==================>...........] - ETA: 0s - loss: 37074380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1406 - distribution_lambda_loss: 37074380.0000 86/122 [====================>.........] - ETA: 0s - loss: 37020424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1231 - distribution_lambda_loss: 37020424.0000 91/122 [=====================>........] - ETA: 0s - loss: 37053324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1496 - distribution_lambda_loss: 37053324.0000 96/122 [======================>.......] - ETA: 0s - loss: 37028324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1372 - distribution_lambda_loss: 37028324.0000101/122 [=======================>......] - ETA: 0s - loss: 37034120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1353 - distribution_lambda_loss: 37034120.0000106/122 [=========================>....] - ETA: 0s - loss: 37032256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1378 - distribution_lambda_loss: 37032256.0000111/122 [==========================>...] - ETA: 0s - loss: 37037616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1333 - distribution_lambda_loss: 37037616.0000116/122 [===========================>..] - ETA: 0s - loss: 37010292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1060 - distribution_lambda_loss: 37010292.0000121/122 [============================>.] - ETA: 0s - loss: 36986464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0877 - distribution_lambda_loss: 36986464.0000122/122 [==============================] - 1s 11ms/step - loss: 36975512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0801 - distribution_lambda_loss: 36975512.0000 - val_loss: 38720908.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.0629 - val_distribution_lambda_loss: 38720908.0000 - lr: 5.0000e-04
Epoch 30/50
  1/122 [..............................] - ETA: 1s - loss: 36425792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0261 - distribution_lambda_loss: 36425792.0000  6/122 [>.............................] - ETA: 1s - loss: 36051108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5842 - distribution_lambda_loss: 36051108.0000 11/122 [=>............................] - ETA: 1s - loss: 36378632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7432 - distribution_lambda_loss: 36378632.0000 16/122 [==>...........................] - ETA: 1s - loss: 36502232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7982 - distribution_lambda_loss: 36502232.0000 21/122 [====>.........................] - ETA: 1s - loss: 36401016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7130 - distribution_lambda_loss: 36401016.0000 26/122 [=====>........................] - ETA: 0s - loss: 36342152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6647 - distribution_lambda_loss: 36342152.0000 31/122 [======>.......................] - ETA: 0s - loss: 36583152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8347 - distribution_lambda_loss: 36583152.0000 36/122 [=======>......................] - ETA: 0s - loss: 36541136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7839 - distribution_lambda_loss: 36541136.0000 41/122 [=========>....................] - ETA: 0s - loss: 36381292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6742 - distribution_lambda_loss: 36381292.0000 46/122 [==========>...................] - ETA: 0s - loss: 36457276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6950 - distribution_lambda_loss: 36457276.0000 51/122 [===========>..................] - ETA: 0s - loss: 36481484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7150 - distribution_lambda_loss: 36481484.0000 56/122 [============>.................] - ETA: 0s - loss: 36506460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7345 - distribution_lambda_loss: 36506460.0000 61/122 [==============>...............] - ETA: 0s - loss: 36510228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7301 - distribution_lambda_loss: 36510228.0000 66/122 [===============>..............] - ETA: 0s - loss: 36531824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7352 - distribution_lambda_loss: 36531824.0000 71/122 [================>.............] - ETA: 0s - loss: 36475820.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7098 - distribution_lambda_loss: 36475820.0000 76/122 [=================>............] - ETA: 0s - loss: 36473508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7198 - distribution_lambda_loss: 36473508.0000 81/122 [==================>...........] - ETA: 0s - loss: 36472620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7252 - distribution_lambda_loss: 36472620.0000 86/122 [====================>.........] - ETA: 0s - loss: 36464088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7244 - distribution_lambda_loss: 36464088.0000 91/122 [=====================>........] - ETA: 0s - loss: 36517880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7527 - distribution_lambda_loss: 36517880.0000 96/122 [======================>.......] - ETA: 0s - loss: 36535180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7718 - distribution_lambda_loss: 36535180.0000101/122 [=======================>......] - ETA: 0s - loss: 36536152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7831 - distribution_lambda_loss: 36536152.0000106/122 [=========================>....] - ETA: 0s - loss: 36532912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7681 - distribution_lambda_loss: 36532912.0000111/122 [==========================>...] - ETA: 0s - loss: 36490748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7299 - distribution_lambda_loss: 36490748.0000116/122 [===========================>..] - ETA: 0s - loss: 36516540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7424 - distribution_lambda_loss: 36516540.0000121/122 [============================>.] - ETA: 0s - loss: 36569776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7784 - distribution_lambda_loss: 36569776.0000122/122 [==============================] - 1s 11ms/step - loss: 36578640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7856 - distribution_lambda_loss: 36578640.0000 - val_loss: 38755020.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.2266 - val_distribution_lambda_loss: 38755020.0000 - lr: 5.0000e-04
Epoch 31/50
  1/122 [..............................] - ETA: 1s - loss: 35438088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0580 - distribution_lambda_loss: 35438088.0000  6/122 [>.............................] - ETA: 1s - loss: 36842628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9432 - distribution_lambda_loss: 36842628.0000 11/122 [=>............................] - ETA: 1s - loss: 36998640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0350 - distribution_lambda_loss: 36998640.0000 16/122 [==>...........................] - ETA: 1s - loss: 36492356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7746 - distribution_lambda_loss: 36492356.0000 21/122 [====>.........................] - ETA: 1s - loss: 36408156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6837 - distribution_lambda_loss: 36408156.0000 26/122 [=====>........................] - ETA: 0s - loss: 36672124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8194 - distribution_lambda_loss: 36672124.0000 31/122 [======>.......................] - ETA: 0s - loss: 36621260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8093 - distribution_lambda_loss: 36621260.0000 36/122 [=======>......................] - ETA: 0s - loss: 36533840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7254 - distribution_lambda_loss: 36533840.0000 41/122 [=========>....................] - ETA: 0s - loss: 36380012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6285 - distribution_lambda_loss: 36380012.0000 46/122 [==========>...................] - ETA: 0s - loss: 36340784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5964 - distribution_lambda_loss: 36340784.0000 51/122 [===========>..................] - ETA: 0s - loss: 36353824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5975 - distribution_lambda_loss: 36353824.0000 56/122 [============>.................] - ETA: 0s - loss: 36316212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5736 - distribution_lambda_loss: 36316212.0000 61/122 [==============>...............] - ETA: 0s - loss: 36272364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5624 - distribution_lambda_loss: 36272364.0000 66/122 [===============>..............] - ETA: 0s - loss: 36289296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5765 - distribution_lambda_loss: 36289296.0000 71/122 [================>.............] - ETA: 0s - loss: 36299468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5778 - distribution_lambda_loss: 36299468.0000 76/122 [=================>............] - ETA: 0s - loss: 36262172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5618 - distribution_lambda_loss: 36262172.0000 81/122 [==================>...........] - ETA: 0s - loss: 36321596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6086 - distribution_lambda_loss: 36321596.0000 86/122 [====================>.........] - ETA: 0s - loss: 36386248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6367 - distribution_lambda_loss: 36386248.0000 91/122 [=====================>........] - ETA: 0s - loss: 36415708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6541 - distribution_lambda_loss: 36415708.0000 96/122 [======================>.......] - ETA: 0s - loss: 36414188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6668 - distribution_lambda_loss: 36414188.0000101/122 [=======================>......] - ETA: 0s - loss: 36409772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6791 - distribution_lambda_loss: 36409772.0000106/122 [=========================>....] - ETA: 0s - loss: 36469784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7086 - distribution_lambda_loss: 36469784.0000111/122 [==========================>...] - ETA: 0s - loss: 36454344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6919 - distribution_lambda_loss: 36454344.0000116/122 [===========================>..] - ETA: 0s - loss: 36390296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6569 - distribution_lambda_loss: 36390296.0000121/122 [============================>.] - ETA: 0s - loss: 36388448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6579 - distribution_lambda_loss: 36388448.0000122/122 [==============================] - 1s 11ms/step - loss: 36370732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6460 - distribution_lambda_loss: 36370732.0000 - val_loss: 38090220.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.6308 - val_distribution_lambda_loss: 38090220.0000 - lr: 5.0000e-04
Epoch 32/50
  1/122 [..............................] - ETA: 1s - loss: 34722344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6619 - distribution_lambda_loss: 34722344.0000  6/122 [>.............................] - ETA: 1s - loss: 35398532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0160 - distribution_lambda_loss: 35398532.0000 11/122 [=>............................] - ETA: 1s - loss: 35728548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1769 - distribution_lambda_loss: 35728548.0000 16/122 [==>...........................] - ETA: 1s - loss: 35812024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2675 - distribution_lambda_loss: 35812024.0000 21/122 [====>.........................] - ETA: 1s - loss: 35598292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1164 - distribution_lambda_loss: 35598292.0000 26/122 [=====>........................] - ETA: 0s - loss: 35698108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1852 - distribution_lambda_loss: 35698108.0000 31/122 [======>.......................] - ETA: 0s - loss: 35821152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2757 - distribution_lambda_loss: 35821152.0000 36/122 [=======>......................] - ETA: 0s - loss: 35801496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2644 - distribution_lambda_loss: 35801496.0000 41/122 [=========>....................] - ETA: 0s - loss: 35754840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2558 - distribution_lambda_loss: 35754840.0000 46/122 [==========>...................] - ETA: 0s - loss: 35783548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2614 - distribution_lambda_loss: 35783548.0000 51/122 [===========>..................] - ETA: 0s - loss: 35773816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2413 - distribution_lambda_loss: 35773816.0000 56/122 [============>.................] - ETA: 0s - loss: 35826704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2857 - distribution_lambda_loss: 35826704.0000 61/122 [==============>...............] - ETA: 0s - loss: 35930364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3307 - distribution_lambda_loss: 35930364.0000 66/122 [===============>..............] - ETA: 0s - loss: 35865016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3075 - distribution_lambda_loss: 35865016.0000 71/122 [================>.............] - ETA: 0s - loss: 35874332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3224 - distribution_lambda_loss: 35874332.0000 76/122 [=================>............] - ETA: 0s - loss: 35885848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3320 - distribution_lambda_loss: 35885848.0000 81/122 [==================>...........] - ETA: 0s - loss: 35928704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3672 - distribution_lambda_loss: 35928704.0000 86/122 [====================>.........] - ETA: 0s - loss: 35948328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3689 - distribution_lambda_loss: 35948328.0000 91/122 [=====================>........] - ETA: 0s - loss: 35939368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3595 - distribution_lambda_loss: 35939368.0000 96/122 [======================>.......] - ETA: 0s - loss: 35932716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3549 - distribution_lambda_loss: 35932716.0000101/122 [=======================>......] - ETA: 0s - loss: 35925352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3518 - distribution_lambda_loss: 35925352.0000106/122 [=========================>....] - ETA: 0s - loss: 35924404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3365 - distribution_lambda_loss: 35924404.0000111/122 [==========================>...] - ETA: 0s - loss: 35948384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3547 - distribution_lambda_loss: 35948384.0000116/122 [===========================>..] - ETA: 0s - loss: 36036708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4051 - distribution_lambda_loss: 36036708.0000121/122 [============================>.] - ETA: 0s - loss: 36048580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4062 - distribution_lambda_loss: 36048580.0000122/122 [==============================] - 1s 11ms/step - loss: 36061552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4193 - distribution_lambda_loss: 36061552.0000 - val_loss: 38025976.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.6839 - val_distribution_lambda_loss: 38025976.0000 - lr: 5.0000e-04
Epoch 33/50
  1/122 [..............................] - ETA: 1s - loss: 35170360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0494 - distribution_lambda_loss: 35170360.0000  6/122 [>.............................] - ETA: 1s - loss: 35486480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1288 - distribution_lambda_loss: 35486480.0000 11/122 [=>............................] - ETA: 1s - loss: 35547296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0578 - distribution_lambda_loss: 35547296.0000 16/122 [==>...........................] - ETA: 1s - loss: 35875868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2352 - distribution_lambda_loss: 35875868.0000 21/122 [====>.........................] - ETA: 1s - loss: 35727748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1571 - distribution_lambda_loss: 35727748.0000 26/122 [=====>........................] - ETA: 0s - loss: 35765208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2095 - distribution_lambda_loss: 35765208.0000 31/122 [======>.......................] - ETA: 0s - loss: 35993696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3517 - distribution_lambda_loss: 35993696.0000 36/122 [=======>......................] - ETA: 0s - loss: 35861036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2474 - distribution_lambda_loss: 35861036.0000 41/122 [=========>....................] - ETA: 0s - loss: 35888168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2757 - distribution_lambda_loss: 35888168.0000 46/122 [==========>...................] - ETA: 0s - loss: 35811168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2083 - distribution_lambda_loss: 35811168.0000 51/122 [===========>..................] - ETA: 0s - loss: 35771424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2043 - distribution_lambda_loss: 35771424.0000 56/122 [============>.................] - ETA: 0s - loss: 35865524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2445 - distribution_lambda_loss: 35865524.0000 61/122 [==============>...............] - ETA: 0s - loss: 35841828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2484 - distribution_lambda_loss: 35841828.0000 66/122 [===============>..............] - ETA: 0s - loss: 35813040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2405 - distribution_lambda_loss: 35813040.0000 71/122 [================>.............] - ETA: 0s - loss: 35766460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2010 - distribution_lambda_loss: 35766460.0000 76/122 [=================>............] - ETA: 0s - loss: 35818088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2422 - distribution_lambda_loss: 35818088.0000 82/122 [===================>..........] - ETA: 0s - loss: 35802328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2274 - distribution_lambda_loss: 35802328.0000 87/122 [====================>.........] - ETA: 0s - loss: 35784628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2214 - distribution_lambda_loss: 35784628.0000 92/122 [=====================>........] - ETA: 0s - loss: 35834728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2596 - distribution_lambda_loss: 35834728.0000 97/122 [======================>.......] - ETA: 0s - loss: 35894996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2985 - distribution_lambda_loss: 35894996.0000102/122 [========================>.....] - ETA: 0s - loss: 35920180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3148 - distribution_lambda_loss: 35920180.0000107/122 [=========================>....] - ETA: 0s - loss: 35912464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3030 - distribution_lambda_loss: 35912464.0000112/122 [==========================>...] - ETA: 0s - loss: 35935372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3216 - distribution_lambda_loss: 35935372.0000117/122 [===========================>..] - ETA: 0s - loss: 35898460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2918 - distribution_lambda_loss: 35898460.0000122/122 [==============================] - 1s 11ms/step - loss: 35927300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3122 - distribution_lambda_loss: 35927300.0000 - val_loss: 37909092.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.5721 - val_distribution_lambda_loss: 37909092.0000 - lr: 5.0000e-04
Epoch 34/50
  1/122 [..............................] - ETA: 1s - loss: 38723408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.2012 - distribution_lambda_loss: 38723408.0000  6/122 [>.............................] - ETA: 1s - loss: 36750368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9366 - distribution_lambda_loss: 36750368.0000 11/122 [=>............................] - ETA: 1s - loss: 36217256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5495 - distribution_lambda_loss: 36217256.0000 16/122 [==>...........................] - ETA: 1s - loss: 35942088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4148 - distribution_lambda_loss: 35942088.0000 21/122 [====>.........................] - ETA: 1s - loss: 35804308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2608 - distribution_lambda_loss: 35804308.0000 26/122 [=====>........................] - ETA: 0s - loss: 35994836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4646 - distribution_lambda_loss: 35994836.0000 31/122 [======>.......................] - ETA: 0s - loss: 35937816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3607 - distribution_lambda_loss: 35937816.0000 36/122 [=======>......................] - ETA: 0s - loss: 35900844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3174 - distribution_lambda_loss: 35900844.0000 41/122 [=========>....................] - ETA: 0s - loss: 35901388.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3158 - distribution_lambda_loss: 35901388.0000 47/122 [==========>...................] - ETA: 0s - loss: 35922180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3083 - distribution_lambda_loss: 35922180.0000 52/122 [===========>..................] - ETA: 0s - loss: 35987080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3388 - distribution_lambda_loss: 35987080.0000 57/122 [=============>................] - ETA: 0s - loss: 36152544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4772 - distribution_lambda_loss: 36152544.0000 62/122 [==============>...............] - ETA: 0s - loss: 36137944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4611 - distribution_lambda_loss: 36137944.0000 67/122 [===============>..............] - ETA: 0s - loss: 36065152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3994 - distribution_lambda_loss: 36065152.0000 72/122 [================>.............] - ETA: 0s - loss: 36003288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3752 - distribution_lambda_loss: 36003288.0000 77/122 [=================>............] - ETA: 0s - loss: 35940092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3207 - distribution_lambda_loss: 35940092.0000 82/122 [===================>..........] - ETA: 0s - loss: 35902888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3070 - distribution_lambda_loss: 35902888.0000 87/122 [====================>.........] - ETA: 0s - loss: 35859632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2633 - distribution_lambda_loss: 35859632.0000 92/122 [=====================>........] - ETA: 0s - loss: 35882764.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2832 - distribution_lambda_loss: 35882764.0000 97/122 [======================>.......] - ETA: 0s - loss: 35843060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2629 - distribution_lambda_loss: 35843060.0000102/122 [========================>.....] - ETA: 0s - loss: 35873012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2939 - distribution_lambda_loss: 35873012.0000107/122 [=========================>....] - ETA: 0s - loss: 35934772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3153 - distribution_lambda_loss: 35934772.0000112/122 [==========================>...] - ETA: 0s - loss: 35930740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3165 - distribution_lambda_loss: 35930740.0000117/122 [===========================>..] - ETA: 0s - loss: 35945912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3325 - distribution_lambda_loss: 35945912.0000122/122 [==============================] - ETA: 0s - loss: 35936456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3335 - distribution_lambda_loss: 35936456.0000122/122 [==============================] - 1s 11ms/step - loss: 35936456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3335 - distribution_lambda_loss: 35936456.0000 - val_loss: 38237192.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.4513 - val_distribution_lambda_loss: 38237192.0000 - lr: 5.0000e-04
Epoch 35/50
  1/122 [..............................] - ETA: 1s - loss: 34793064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5338 - distribution_lambda_loss: 34793064.0000  6/122 [>.............................] - ETA: 1s - loss: 35078844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7572 - distribution_lambda_loss: 35078844.0000 11/122 [=>............................] - ETA: 1s - loss: 35374832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9429 - distribution_lambda_loss: 35374832.0000 16/122 [==>...........................] - ETA: 1s - loss: 35112148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7552 - distribution_lambda_loss: 35112148.0000 21/122 [====>.........................] - ETA: 1s - loss: 35150780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7988 - distribution_lambda_loss: 35150780.0000 26/122 [=====>........................] - ETA: 0s - loss: 35529040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0632 - distribution_lambda_loss: 35529040.0000 31/122 [======>.......................] - ETA: 0s - loss: 35300180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9537 - distribution_lambda_loss: 35300180.0000 36/122 [=======>......................] - ETA: 0s - loss: 35378844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9591 - distribution_lambda_loss: 35378844.0000 41/122 [=========>....................] - ETA: 0s - loss: 35299864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8893 - distribution_lambda_loss: 35299864.0000 46/122 [==========>...................] - ETA: 0s - loss: 35421992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9865 - distribution_lambda_loss: 35421992.0000 51/122 [===========>..................] - ETA: 0s - loss: 35363608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9235 - distribution_lambda_loss: 35363608.0000 56/122 [============>.................] - ETA: 0s - loss: 35365884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9062 - distribution_lambda_loss: 35365884.0000 61/122 [==============>...............] - ETA: 0s - loss: 35355192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9127 - distribution_lambda_loss: 35355192.0000 66/122 [===============>..............] - ETA: 0s - loss: 35352328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9011 - distribution_lambda_loss: 35352328.0000 71/122 [================>.............] - ETA: 0s - loss: 35355332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8962 - distribution_lambda_loss: 35355332.0000 76/122 [=================>............] - ETA: 0s - loss: 35389024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9212 - distribution_lambda_loss: 35389024.0000 81/122 [==================>...........] - ETA: 0s - loss: 35404156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9351 - distribution_lambda_loss: 35404156.0000 86/122 [====================>.........] - ETA: 0s - loss: 35312356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8898 - distribution_lambda_loss: 35312356.0000 91/122 [=====================>........] - ETA: 0s - loss: 35367844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9056 - distribution_lambda_loss: 35367844.0000 96/122 [======================>.......] - ETA: 0s - loss: 35314588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8839 - distribution_lambda_loss: 35314588.0000101/122 [=======================>......] - ETA: 0s - loss: 35332876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8945 - distribution_lambda_loss: 35332876.0000106/122 [=========================>....] - ETA: 0s - loss: 35453304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9731 - distribution_lambda_loss: 35453304.0000111/122 [==========================>...] - ETA: 0s - loss: 35485460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9945 - distribution_lambda_loss: 35485460.0000116/122 [===========================>..] - ETA: 0s - loss: 35447368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9717 - distribution_lambda_loss: 35447368.0000121/122 [============================>.] - ETA: 0s - loss: 35454200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9799 - distribution_lambda_loss: 35454200.0000122/122 [==============================] - 1s 11ms/step - loss: 35439044.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9690 - distribution_lambda_loss: 35439044.0000 - val_loss: 37227112.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.9907 - val_distribution_lambda_loss: 37227112.0000 - lr: 5.0000e-04
Epoch 36/50
  1/122 [..............................] - ETA: 1s - loss: 32045396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.4280 - distribution_lambda_loss: 32045396.0000  6/122 [>.............................] - ETA: 1s - loss: 34481456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3017 - distribution_lambda_loss: 34481456.0000 11/122 [=>............................] - ETA: 1s - loss: 35114372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8096 - distribution_lambda_loss: 35114372.0000 16/122 [==>...........................] - ETA: 1s - loss: 35508908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0048 - distribution_lambda_loss: 35508908.0000 21/122 [====>.........................] - ETA: 1s - loss: 35741716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1976 - distribution_lambda_loss: 35741716.0000 26/122 [=====>........................] - ETA: 0s - loss: 35505160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0568 - distribution_lambda_loss: 35505160.0000 31/122 [======>.......................] - ETA: 0s - loss: 35400796.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9819 - distribution_lambda_loss: 35400796.0000 36/122 [=======>......................] - ETA: 0s - loss: 35353036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9361 - distribution_lambda_loss: 35353036.0000 41/122 [=========>....................] - ETA: 0s - loss: 35206880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8306 - distribution_lambda_loss: 35206880.0000 46/122 [==========>...................] - ETA: 0s - loss: 35163412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7942 - distribution_lambda_loss: 35163412.0000 51/122 [===========>..................] - ETA: 0s - loss: 35198560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8250 - distribution_lambda_loss: 35198560.0000 56/122 [============>.................] - ETA: 0s - loss: 35279400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8376 - distribution_lambda_loss: 35279400.0000 61/122 [==============>...............] - ETA: 0s - loss: 35279068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8589 - distribution_lambda_loss: 35279068.0000 66/122 [===============>..............] - ETA: 0s - loss: 35362432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9044 - distribution_lambda_loss: 35362432.0000 71/122 [================>.............] - ETA: 0s - loss: 35286348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8625 - distribution_lambda_loss: 35286348.0000 76/122 [=================>............] - ETA: 0s - loss: 35269988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8634 - distribution_lambda_loss: 35269988.0000 81/122 [==================>...........] - ETA: 0s - loss: 35263448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8550 - distribution_lambda_loss: 35263448.0000 86/122 [====================>.........] - ETA: 0s - loss: 35271696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8462 - distribution_lambda_loss: 35271696.0000 91/122 [=====================>........] - ETA: 0s - loss: 35213660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8209 - distribution_lambda_loss: 35213660.0000 96/122 [======================>.......] - ETA: 0s - loss: 35248596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8381 - distribution_lambda_loss: 35248596.0000101/122 [=======================>......] - ETA: 0s - loss: 35258020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8346 - distribution_lambda_loss: 35258020.0000106/122 [=========================>....] - ETA: 0s - loss: 35257244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8476 - distribution_lambda_loss: 35257244.0000111/122 [==========================>...] - ETA: 0s - loss: 35299380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8703 - distribution_lambda_loss: 35299380.0000116/122 [===========================>..] - ETA: 0s - loss: 35345164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8874 - distribution_lambda_loss: 35345164.0000121/122 [============================>.] - ETA: 0s - loss: 35379396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9174 - distribution_lambda_loss: 35379396.0000122/122 [==============================] - 1s 11ms/step - loss: 35382420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9229 - distribution_lambda_loss: 35382420.0000 - val_loss: 37712936.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.3569 - val_distribution_lambda_loss: 37712936.0000 - lr: 5.0000e-04
Epoch 37/50
  1/122 [..............................] - ETA: 1s - loss: 34158112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.6473 - distribution_lambda_loss: 34158112.0000  6/122 [>.............................] - ETA: 1s - loss: 35523676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6719 - distribution_lambda_loss: 35523676.0000 11/122 [=>............................] - ETA: 1s - loss: 35201652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7070 - distribution_lambda_loss: 35201652.0000 16/122 [==>...........................] - ETA: 1s - loss: 35121016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6434 - distribution_lambda_loss: 35121016.0000 21/122 [====>.........................] - ETA: 1s - loss: 35283408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7361 - distribution_lambda_loss: 35283408.0000 26/122 [=====>........................] - ETA: 0s - loss: 35088356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6660 - distribution_lambda_loss: 35088356.0000 31/122 [======>.......................] - ETA: 0s - loss: 35067568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6541 - distribution_lambda_loss: 35067568.0000 36/122 [=======>......................] - ETA: 0s - loss: 35104448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6550 - distribution_lambda_loss: 35104448.0000 41/122 [=========>....................] - ETA: 0s - loss: 35033312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6345 - distribution_lambda_loss: 35033312.0000 46/122 [==========>...................] - ETA: 0s - loss: 34968472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5721 - distribution_lambda_loss: 34968472.0000 51/122 [===========>..................] - ETA: 0s - loss: 34991456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5953 - distribution_lambda_loss: 34991456.0000 56/122 [============>.................] - ETA: 0s - loss: 34937072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5984 - distribution_lambda_loss: 34937072.0000 61/122 [==============>...............] - ETA: 0s - loss: 34896456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5446 - distribution_lambda_loss: 34896456.0000 66/122 [===============>..............] - ETA: 0s - loss: 34936656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5757 - distribution_lambda_loss: 34936656.0000 71/122 [================>.............] - ETA: 0s - loss: 34946304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5715 - distribution_lambda_loss: 34946304.0000 76/122 [=================>............] - ETA: 0s - loss: 34892484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5500 - distribution_lambda_loss: 34892484.0000 81/122 [==================>...........] - ETA: 0s - loss: 34937232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5897 - distribution_lambda_loss: 34937232.0000 86/122 [====================>.........] - ETA: 0s - loss: 34996568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6237 - distribution_lambda_loss: 34996568.0000 91/122 [=====================>........] - ETA: 0s - loss: 34963972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6012 - distribution_lambda_loss: 34963972.0000 96/122 [======================>.......] - ETA: 0s - loss: 34974020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6110 - distribution_lambda_loss: 34974020.0000101/122 [=======================>......] - ETA: 0s - loss: 34942288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5924 - distribution_lambda_loss: 34942288.0000106/122 [=========================>....] - ETA: 0s - loss: 34940988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5898 - distribution_lambda_loss: 34940988.0000111/122 [==========================>...] - ETA: 0s - loss: 34947224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6009 - distribution_lambda_loss: 34947224.0000116/122 [===========================>..] - ETA: 0s - loss: 35029336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6538 - distribution_lambda_loss: 35029336.0000121/122 [============================>.] - ETA: 0s - loss: 35016672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6517 - distribution_lambda_loss: 35016672.0000122/122 [==============================] - 1s 11ms/step - loss: 35005604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6477 - distribution_lambda_loss: 35005604.0000 - val_loss: 36680648.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.2926 - val_distribution_lambda_loss: 36680648.0000 - lr: 5.0000e-04
Epoch 38/50
  1/122 [..............................] - ETA: 1s - loss: 36329848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9277 - distribution_lambda_loss: 36329848.0000  6/122 [>.............................] - ETA: 1s - loss: 34326156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9237 - distribution_lambda_loss: 34326156.0000 11/122 [=>............................] - ETA: 1s - loss: 34486076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2453 - distribution_lambda_loss: 34486076.0000 16/122 [==>...........................] - ETA: 1s - loss: 34738104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3997 - distribution_lambda_loss: 34738104.0000 21/122 [====>.........................] - ETA: 1s - loss: 34616920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3334 - distribution_lambda_loss: 34616920.0000 26/122 [=====>........................] - ETA: 0s - loss: 34606308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3304 - distribution_lambda_loss: 34606308.0000 31/122 [======>.......................] - ETA: 0s - loss: 34406928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2140 - distribution_lambda_loss: 34406928.0000 36/122 [=======>......................] - ETA: 0s - loss: 34459540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2594 - distribution_lambda_loss: 34459540.0000 41/122 [=========>....................] - ETA: 0s - loss: 34465144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2803 - distribution_lambda_loss: 34465144.0000 46/122 [==========>...................] - ETA: 0s - loss: 34500208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3140 - distribution_lambda_loss: 34500208.0000 51/122 [===========>..................] - ETA: 0s - loss: 34361968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1906 - distribution_lambda_loss: 34361968.0000 56/122 [============>.................] - ETA: 0s - loss: 34462912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2829 - distribution_lambda_loss: 34462912.0000 61/122 [==============>...............] - ETA: 0s - loss: 34485092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2709 - distribution_lambda_loss: 34485092.0000 66/122 [===============>..............] - ETA: 0s - loss: 34577628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3378 - distribution_lambda_loss: 34577628.0000 71/122 [================>.............] - ETA: 0s - loss: 34578420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3487 - distribution_lambda_loss: 34578420.0000 76/122 [=================>............] - ETA: 0s - loss: 34555860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3231 - distribution_lambda_loss: 34555860.0000 81/122 [==================>...........] - ETA: 0s - loss: 34581700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3248 - distribution_lambda_loss: 34581700.0000 86/122 [====================>.........] - ETA: 0s - loss: 34640552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3784 - distribution_lambda_loss: 34640552.0000 91/122 [=====================>........] - ETA: 0s - loss: 34684484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4045 - distribution_lambda_loss: 34684484.0000 96/122 [======================>.......] - ETA: 0s - loss: 34629264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3647 - distribution_lambda_loss: 34629264.0000101/122 [=======================>......] - ETA: 0s - loss: 34613684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3588 - distribution_lambda_loss: 34613684.0000106/122 [=========================>....] - ETA: 0s - loss: 34653632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3813 - distribution_lambda_loss: 34653632.0000111/122 [==========================>...] - ETA: 0s - loss: 34670132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3911 - distribution_lambda_loss: 34670132.0000116/122 [===========================>..] - ETA: 0s - loss: 34649536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3862 - distribution_lambda_loss: 34649536.0000121/122 [============================>.] - ETA: 0s - loss: 34677896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3996 - distribution_lambda_loss: 34677896.0000122/122 [==============================] - 1s 11ms/step - loss: 34690176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4074 - distribution_lambda_loss: 34690176.0000 - val_loss: 36951732.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2985 - val_distribution_lambda_loss: 36951732.0000 - lr: 5.0000e-04
Epoch 39/50
  1/122 [..............................] - ETA: 1s - loss: 33489842.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9885 - distribution_lambda_loss: 33489842.0000  6/122 [>.............................] - ETA: 1s - loss: 33626704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7500 - distribution_lambda_loss: 33626704.0000 11/122 [=>............................] - ETA: 1s - loss: 34338712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1953 - distribution_lambda_loss: 34338712.0000 16/122 [==>...........................] - ETA: 1s - loss: 34331004.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1687 - distribution_lambda_loss: 34331004.0000 21/122 [====>.........................] - ETA: 1s - loss: 34271660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1074 - distribution_lambda_loss: 34271660.0000 26/122 [=====>........................] - ETA: 0s - loss: 34478908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2227 - distribution_lambda_loss: 34478908.0000 31/122 [======>.......................] - ETA: 0s - loss: 34455920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2086 - distribution_lambda_loss: 34455920.0000 36/122 [=======>......................] - ETA: 0s - loss: 34608272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2859 - distribution_lambda_loss: 34608272.0000 41/122 [=========>....................] - ETA: 0s - loss: 34626908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3341 - distribution_lambda_loss: 34626908.0000 46/122 [==========>...................] - ETA: 0s - loss: 34711212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3862 - distribution_lambda_loss: 34711212.0000 51/122 [===========>..................] - ETA: 0s - loss: 34751316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4048 - distribution_lambda_loss: 34751316.0000 56/122 [============>.................] - ETA: 0s - loss: 34881084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5346 - distribution_lambda_loss: 34881084.0000 61/122 [==============>...............] - ETA: 0s - loss: 34806832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4842 - distribution_lambda_loss: 34806832.0000 66/122 [===============>..............] - ETA: 0s - loss: 34806100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4909 - distribution_lambda_loss: 34806100.0000 71/122 [================>.............] - ETA: 0s - loss: 34783660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4556 - distribution_lambda_loss: 34783660.0000 76/122 [=================>............] - ETA: 0s - loss: 34840052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4940 - distribution_lambda_loss: 34840052.0000 81/122 [==================>...........] - ETA: 0s - loss: 34775136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4567 - distribution_lambda_loss: 34775136.0000 86/122 [====================>.........] - ETA: 0s - loss: 34861500.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5117 - distribution_lambda_loss: 34861500.0000 91/122 [=====================>........] - ETA: 0s - loss: 34848920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5083 - distribution_lambda_loss: 34848920.0000 96/122 [======================>.......] - ETA: 0s - loss: 34811864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4873 - distribution_lambda_loss: 34811864.0000101/122 [=======================>......] - ETA: 0s - loss: 34853416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5209 - distribution_lambda_loss: 34853416.0000106/122 [=========================>....] - ETA: 0s - loss: 34789780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4670 - distribution_lambda_loss: 34789780.0000111/122 [==========================>...] - ETA: 0s - loss: 34846112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5045 - distribution_lambda_loss: 34846112.0000116/122 [===========================>..] - ETA: 0s - loss: 34813392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4768 - distribution_lambda_loss: 34813392.0000121/122 [============================>.] - ETA: 0s - loss: 34835312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4881 - distribution_lambda_loss: 34835312.0000122/122 [==============================] - 1s 11ms/step - loss: 34837012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4886 - distribution_lambda_loss: 34837012.0000 - val_loss: 36640424.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.3261 - val_distribution_lambda_loss: 36640424.0000 - lr: 5.0000e-04
Epoch 40/50
  1/122 [..............................] - ETA: 1s - loss: 33271704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0021 - distribution_lambda_loss: 33271704.0000  6/122 [>.............................] - ETA: 1s - loss: 34227248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9406 - distribution_lambda_loss: 34227248.0000 11/122 [=>............................] - ETA: 1s - loss: 34473884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2161 - distribution_lambda_loss: 34473884.0000 16/122 [==>...........................] - ETA: 1s - loss: 33907580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.8759 - distribution_lambda_loss: 33907580.0000 21/122 [====>.........................] - ETA: 1s - loss: 34218908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0694 - distribution_lambda_loss: 34218908.0000 26/122 [=====>........................] - ETA: 0s - loss: 34283704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1248 - distribution_lambda_loss: 34283704.0000 31/122 [======>.......................] - ETA: 0s - loss: 34199636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0474 - distribution_lambda_loss: 34199636.0000 36/122 [=======>......................] - ETA: 0s - loss: 34142888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0096 - distribution_lambda_loss: 34142888.0000 41/122 [=========>....................] - ETA: 0s - loss: 34250516.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1351 - distribution_lambda_loss: 34250516.0000 46/122 [==========>...................] - ETA: 0s - loss: 34453008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2558 - distribution_lambda_loss: 34453008.0000 51/122 [===========>..................] - ETA: 0s - loss: 34418360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2314 - distribution_lambda_loss: 34418360.0000 56/122 [============>.................] - ETA: 0s - loss: 34419960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2331 - distribution_lambda_loss: 34419960.0000 61/122 [==============>...............] - ETA: 0s - loss: 34344068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1782 - distribution_lambda_loss: 34344068.0000 66/122 [===============>..............] - ETA: 0s - loss: 34308872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1547 - distribution_lambda_loss: 34308872.0000 71/122 [================>.............] - ETA: 0s - loss: 34335752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1656 - distribution_lambda_loss: 34335752.0000 76/122 [=================>............] - ETA: 0s - loss: 34351884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1715 - distribution_lambda_loss: 34351884.0000 81/122 [==================>...........] - ETA: 0s - loss: 34310544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1510 - distribution_lambda_loss: 34310544.0000 86/122 [====================>.........] - ETA: 0s - loss: 34317680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1493 - distribution_lambda_loss: 34317680.0000 91/122 [=====================>........] - ETA: 0s - loss: 34319552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1425 - distribution_lambda_loss: 34319552.0000 96/122 [======================>.......] - ETA: 0s - loss: 34308348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1417 - distribution_lambda_loss: 34308348.0000101/122 [=======================>......] - ETA: 0s - loss: 34355936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1497 - distribution_lambda_loss: 34355936.0000106/122 [=========================>....] - ETA: 0s - loss: 34346748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1535 - distribution_lambda_loss: 34346748.0000111/122 [==========================>...] - ETA: 0s - loss: 34403460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1940 - distribution_lambda_loss: 34403460.0000116/122 [===========================>..] - ETA: 0s - loss: 34442588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2012 - distribution_lambda_loss: 34442588.0000121/122 [============================>.] - ETA: 0s - loss: 34468400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2358 - distribution_lambda_loss: 34468400.0000122/122 [==============================] - 1s 11ms/step - loss: 34464208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2254 - distribution_lambda_loss: 34464208.0000 - val_loss: 36650248.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 49.6361 - val_distribution_lambda_loss: 36650248.0000 - lr: 5.0000e-04
Epoch 41/50
  1/122 [..............................] - ETA: 1s - loss: 35978228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4002 - distribution_lambda_loss: 35978228.0000  6/122 [>.............................] - ETA: 1s - loss: 34550732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3676 - distribution_lambda_loss: 34550732.0000 11/122 [=>............................] - ETA: 1s - loss: 34544124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1904 - distribution_lambda_loss: 34544124.0000 16/122 [==>...........................] - ETA: 1s - loss: 34420312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1124 - distribution_lambda_loss: 34420312.0000 21/122 [====>.........................] - ETA: 1s - loss: 34401128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1484 - distribution_lambda_loss: 34401128.0000 26/122 [=====>........................] - ETA: 0s - loss: 34095000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9463 - distribution_lambda_loss: 34095000.0000 31/122 [======>.......................] - ETA: 0s - loss: 34002952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.8752 - distribution_lambda_loss: 34002952.0000 36/122 [=======>......................] - ETA: 0s - loss: 34117728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9940 - distribution_lambda_loss: 34117728.0000 41/122 [=========>....................] - ETA: 0s - loss: 34066276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9107 - distribution_lambda_loss: 34066276.0000 46/122 [==========>...................] - ETA: 0s - loss: 34168416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9758 - distribution_lambda_loss: 34168416.0000 51/122 [===========>..................] - ETA: 0s - loss: 34189444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9928 - distribution_lambda_loss: 34189444.0000 56/122 [============>.................] - ETA: 0s - loss: 34195872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9799 - distribution_lambda_loss: 34195872.0000 61/122 [==============>...............] - ETA: 0s - loss: 34241692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0415 - distribution_lambda_loss: 34241692.0000 66/122 [===============>..............] - ETA: 0s - loss: 34232548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0443 - distribution_lambda_loss: 34232548.0000 71/122 [================>.............] - ETA: 0s - loss: 34249492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0462 - distribution_lambda_loss: 34249492.0000 76/122 [=================>............] - ETA: 0s - loss: 34244628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0463 - distribution_lambda_loss: 34244628.0000 81/122 [==================>...........] - ETA: 0s - loss: 34221284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0117 - distribution_lambda_loss: 34221284.0000 86/122 [====================>.........] - ETA: 0s - loss: 34115736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9446 - distribution_lambda_loss: 34115736.0000 91/122 [=====================>........] - ETA: 0s - loss: 34148292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9612 - distribution_lambda_loss: 34148292.0000 96/122 [======================>.......] - ETA: 0s - loss: 34125796.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9522 - distribution_lambda_loss: 34125796.0000101/122 [=======================>......] - ETA: 0s - loss: 34099788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9308 - distribution_lambda_loss: 34099788.0000106/122 [=========================>....] - ETA: 0s - loss: 34099384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9256 - distribution_lambda_loss: 34099384.0000111/122 [==========================>...] - ETA: 0s - loss: 34132276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9457 - distribution_lambda_loss: 34132276.0000116/122 [===========================>..] - ETA: 0s - loss: 34167880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9688 - distribution_lambda_loss: 34167880.0000121/122 [============================>.] - ETA: 0s - loss: 34150312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9563 - distribution_lambda_loss: 34150312.0000122/122 [==============================] - 1s 11ms/step - loss: 34143544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9503 - distribution_lambda_loss: 34143544.0000 - val_loss: 35921332.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.0250 - val_distribution_lambda_loss: 35921332.0000 - lr: 5.0000e-04
Epoch 42/50
  1/122 [..............................] - ETA: 1s - loss: 36886384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8615 - distribution_lambda_loss: 36886384.0000  6/122 [>.............................] - ETA: 1s - loss: 34492452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1727 - distribution_lambda_loss: 34492452.0000 11/122 [=>............................] - ETA: 1s - loss: 34132404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9106 - distribution_lambda_loss: 34132404.0000 16/122 [==>...........................] - ETA: 1s - loss: 34055668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9085 - distribution_lambda_loss: 34055668.0000 21/122 [====>.........................] - ETA: 1s - loss: 34073996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9240 - distribution_lambda_loss: 34073996.0000 26/122 [=====>........................] - ETA: 0s - loss: 33859640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7443 - distribution_lambda_loss: 33859640.0000 31/122 [======>.......................] - ETA: 0s - loss: 33865100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7677 - distribution_lambda_loss: 33865100.0000 36/122 [=======>......................] - ETA: 0s - loss: 33931572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7844 - distribution_lambda_loss: 33931572.0000 41/122 [=========>....................] - ETA: 0s - loss: 33880944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7816 - distribution_lambda_loss: 33880944.0000 46/122 [==========>...................] - ETA: 0s - loss: 33756980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6820 - distribution_lambda_loss: 33756980.0000 51/122 [===========>..................] - ETA: 0s - loss: 33791704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7245 - distribution_lambda_loss: 33791704.0000 56/122 [============>.................] - ETA: 0s - loss: 33733732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6716 - distribution_lambda_loss: 33733732.0000 61/122 [==============>...............] - ETA: 0s - loss: 33780276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7006 - distribution_lambda_loss: 33780276.0000 66/122 [===============>..............] - ETA: 0s - loss: 33736592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6586 - distribution_lambda_loss: 33736592.0000 71/122 [================>.............] - ETA: 0s - loss: 33797444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7100 - distribution_lambda_loss: 33797444.0000 76/122 [=================>............] - ETA: 0s - loss: 33851320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7192 - distribution_lambda_loss: 33851320.0000 81/122 [==================>...........] - ETA: 0s - loss: 33910096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7598 - distribution_lambda_loss: 33910096.0000 86/122 [====================>.........] - ETA: 0s - loss: 33921300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7706 - distribution_lambda_loss: 33921300.0000 91/122 [=====================>........] - ETA: 0s - loss: 33845972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7187 - distribution_lambda_loss: 33845972.0000 96/122 [======================>.......] - ETA: 0s - loss: 33830900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7244 - distribution_lambda_loss: 33830900.0000101/122 [=======================>......] - ETA: 0s - loss: 33887728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7684 - distribution_lambda_loss: 33887728.0000106/122 [=========================>....] - ETA: 0s - loss: 33887848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7663 - distribution_lambda_loss: 33887848.0000111/122 [==========================>...] - ETA: 0s - loss: 33846840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7395 - distribution_lambda_loss: 33846840.0000116/122 [===========================>..] - ETA: 0s - loss: 33831032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7199 - distribution_lambda_loss: 33831032.0000121/122 [============================>.] - ETA: 0s - loss: 33801804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7109 - distribution_lambda_loss: 33801804.0000122/122 [==============================] - 1s 11ms/step - loss: 33807396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7119 - distribution_lambda_loss: 33807396.0000 - val_loss: 35837768.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.5085 - val_distribution_lambda_loss: 35837768.0000 - lr: 5.0000e-04
Epoch 43/50
  1/122 [..............................] - ETA: 1s - loss: 33708056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9351 - distribution_lambda_loss: 33708056.0000  6/122 [>.............................] - ETA: 1s - loss: 33818812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.9087 - distribution_lambda_loss: 33818812.0000 11/122 [=>............................] - ETA: 1s - loss: 33654236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6425 - distribution_lambda_loss: 33654236.0000 16/122 [==>...........................] - ETA: 1s - loss: 33754976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.8030 - distribution_lambda_loss: 33754976.0000 21/122 [====>.........................] - ETA: 1s - loss: 33655816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5969 - distribution_lambda_loss: 33655816.0000 26/122 [=====>........................] - ETA: 0s - loss: 33760152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7343 - distribution_lambda_loss: 33760152.0000 31/122 [======>.......................] - ETA: 0s - loss: 33862240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7556 - distribution_lambda_loss: 33862240.0000 36/122 [=======>......................] - ETA: 0s - loss: 33764444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7247 - distribution_lambda_loss: 33764444.0000 41/122 [=========>....................] - ETA: 0s - loss: 33812272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7337 - distribution_lambda_loss: 33812272.0000 46/122 [==========>...................] - ETA: 0s - loss: 33792908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.7156 - distribution_lambda_loss: 33792908.0000 51/122 [===========>..................] - ETA: 0s - loss: 33672080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6042 - distribution_lambda_loss: 33672080.0000 56/122 [============>.................] - ETA: 0s - loss: 33709364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6327 - distribution_lambda_loss: 33709364.0000 61/122 [==============>...............] - ETA: 0s - loss: 33698156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6314 - distribution_lambda_loss: 33698156.0000 66/122 [===============>..............] - ETA: 0s - loss: 33726544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6611 - distribution_lambda_loss: 33726544.0000 71/122 [================>.............] - ETA: 0s - loss: 33666484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6230 - distribution_lambda_loss: 33666484.0000 76/122 [=================>............] - ETA: 0s - loss: 33676312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6131 - distribution_lambda_loss: 33676312.0000 81/122 [==================>...........] - ETA: 0s - loss: 33610096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5807 - distribution_lambda_loss: 33610096.0000 86/122 [====================>.........] - ETA: 0s - loss: 33562816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5386 - distribution_lambda_loss: 33562816.0000 91/122 [=====================>........] - ETA: 0s - loss: 33542234.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5210 - distribution_lambda_loss: 33542234.0000 96/122 [======================>.......] - ETA: 0s - loss: 33523406.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5142 - distribution_lambda_loss: 33523406.0000101/122 [=======================>......] - ETA: 0s - loss: 33531486.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5030 - distribution_lambda_loss: 33531486.0000106/122 [=========================>....] - ETA: 0s - loss: 33540634.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5268 - distribution_lambda_loss: 33540634.0000111/122 [==========================>...] - ETA: 0s - loss: 33590316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5492 - distribution_lambda_loss: 33590316.0000116/122 [===========================>..] - ETA: 0s - loss: 33623512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5896 - distribution_lambda_loss: 33623512.0000121/122 [============================>.] - ETA: 0s - loss: 33663680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5979 - distribution_lambda_loss: 33663680.0000122/122 [==============================] - 1s 11ms/step - loss: 33666772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6087 - distribution_lambda_loss: 33666772.0000 - val_loss: 35665272.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.2564 - val_distribution_lambda_loss: 35665272.0000 - lr: 5.0000e-04
Epoch 44/50
  1/122 [..............................] - ETA: 1s - loss: 34285324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5653 - distribution_lambda_loss: 34285324.0000  6/122 [>.............................] - ETA: 1s - loss: 33350142.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2418 - distribution_lambda_loss: 33350142.0000 11/122 [=>............................] - ETA: 1s - loss: 33095304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1789 - distribution_lambda_loss: 33095304.0000 16/122 [==>...........................] - ETA: 1s - loss: 33012268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0587 - distribution_lambda_loss: 33012268.0000 21/122 [====>.........................] - ETA: 1s - loss: 33281846.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2949 - distribution_lambda_loss: 33281846.0000 26/122 [=====>........................] - ETA: 1s - loss: 33502018.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4637 - distribution_lambda_loss: 33502018.0000 31/122 [======>.......................] - ETA: 0s - loss: 33392678.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3830 - distribution_lambda_loss: 33392678.0000 36/122 [=======>......................] - ETA: 0s - loss: 33443432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4328 - distribution_lambda_loss: 33443432.0000 41/122 [=========>....................] - ETA: 0s - loss: 33412674.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4051 - distribution_lambda_loss: 33412674.0000 46/122 [==========>...................] - ETA: 0s - loss: 33350484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3888 - distribution_lambda_loss: 33350484.0000 51/122 [===========>..................] - ETA: 0s - loss: 33345430.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3675 - distribution_lambda_loss: 33345430.0000 56/122 [============>.................] - ETA: 0s - loss: 33382268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4049 - distribution_lambda_loss: 33382268.0000 61/122 [==============>...............] - ETA: 0s - loss: 33406474.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4172 - distribution_lambda_loss: 33406474.0000 66/122 [===============>..............] - ETA: 0s - loss: 33461466.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4303 - distribution_lambda_loss: 33461466.0000 71/122 [================>.............] - ETA: 0s - loss: 33588440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5426 - distribution_lambda_loss: 33588440.0000 76/122 [=================>............] - ETA: 0s - loss: 33701416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5916 - distribution_lambda_loss: 33701416.0000 81/122 [==================>...........] - ETA: 0s - loss: 33696444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6062 - distribution_lambda_loss: 33696444.0000 86/122 [====================>.........] - ETA: 0s - loss: 33691908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6089 - distribution_lambda_loss: 33691908.0000 91/122 [=====================>........] - ETA: 0s - loss: 33703332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6127 - distribution_lambda_loss: 33703332.0000 96/122 [======================>.......] - ETA: 0s - loss: 33669020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6019 - distribution_lambda_loss: 33669020.0000101/122 [=======================>......] - ETA: 0s - loss: 33640660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5652 - distribution_lambda_loss: 33640660.0000106/122 [=========================>....] - ETA: 0s - loss: 33618020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5621 - distribution_lambda_loss: 33618020.0000111/122 [==========================>...] - ETA: 0s - loss: 33604916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5439 - distribution_lambda_loss: 33604916.0000116/122 [===========================>..] - ETA: 0s - loss: 33588736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5359 - distribution_lambda_loss: 33588736.0000121/122 [============================>.] - ETA: 0s - loss: 33588496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5234 - distribution_lambda_loss: 33588496.0000122/122 [==============================] - 1s 11ms/step - loss: 33578272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5214 - distribution_lambda_loss: 33578272.0000 - val_loss: 35497048.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 49.4160 - val_distribution_lambda_loss: 35497048.0000 - lr: 5.0000e-04
Epoch 45/50
  1/122 [..............................] - ETA: 1s - loss: 33645860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9945 - distribution_lambda_loss: 33645860.0000  6/122 [>.............................] - ETA: 1s - loss: 33402616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2966 - distribution_lambda_loss: 33402616.0000 11/122 [=>............................] - ETA: 1s - loss: 33358310.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4096 - distribution_lambda_loss: 33358310.0000 16/122 [==>...........................] - ETA: 1s - loss: 33522804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4644 - distribution_lambda_loss: 33522804.0000 21/122 [====>.........................] - ETA: 1s - loss: 33414482.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4010 - distribution_lambda_loss: 33414482.0000 26/122 [=====>........................] - ETA: 0s - loss: 33565484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5188 - distribution_lambda_loss: 33565484.0000 31/122 [======>.......................] - ETA: 0s - loss: 33468766.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4842 - distribution_lambda_loss: 33468766.0000 36/122 [=======>......................] - ETA: 0s - loss: 33471492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4736 - distribution_lambda_loss: 33471492.0000 41/122 [=========>....................] - ETA: 0s - loss: 33450474.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4244 - distribution_lambda_loss: 33450474.0000 46/122 [==========>...................] - ETA: 0s - loss: 33372934.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3790 - distribution_lambda_loss: 33372934.0000 51/122 [===========>..................] - ETA: 0s - loss: 33380728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3775 - distribution_lambda_loss: 33380728.0000 56/122 [============>.................] - ETA: 0s - loss: 33331676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3401 - distribution_lambda_loss: 33331676.0000 61/122 [==============>...............] - ETA: 0s - loss: 33390464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3820 - distribution_lambda_loss: 33390464.0000 66/122 [===============>..............] - ETA: 0s - loss: 33374906.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3844 - distribution_lambda_loss: 33374906.0000 71/122 [================>.............] - ETA: 0s - loss: 33379880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3842 - distribution_lambda_loss: 33379880.0000 76/122 [=================>............] - ETA: 0s - loss: 33349274.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3708 - distribution_lambda_loss: 33349274.0000 81/122 [==================>...........] - ETA: 0s - loss: 33299640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3339 - distribution_lambda_loss: 33299640.0000 86/122 [====================>.........] - ETA: 0s - loss: 33289424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3206 - distribution_lambda_loss: 33289424.0000 91/122 [=====================>........] - ETA: 0s - loss: 33284090.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3238 - distribution_lambda_loss: 33284090.0000 96/122 [======================>.......] - ETA: 0s - loss: 33289272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3378 - distribution_lambda_loss: 33289272.0000101/122 [=======================>......] - ETA: 0s - loss: 33283126.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3103 - distribution_lambda_loss: 33283126.0000106/122 [=========================>....] - ETA: 0s - loss: 33287100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3174 - distribution_lambda_loss: 33287100.0000111/122 [==========================>...] - ETA: 0s - loss: 33306288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3319 - distribution_lambda_loss: 33306288.0000116/122 [===========================>..] - ETA: 0s - loss: 33314172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3362 - distribution_lambda_loss: 33314172.0000121/122 [============================>.] - ETA: 0s - loss: 33313752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3278 - distribution_lambda_loss: 33313752.0000122/122 [==============================] - 1s 11ms/step - loss: 33311512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3283 - distribution_lambda_loss: 33311512.0000 - val_loss: 35068736.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 49.1383 - val_distribution_lambda_loss: 35068736.0000 - lr: 5.0000e-04
Epoch 46/50
  1/122 [..............................] - ETA: 1s - loss: 36186832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6328 - distribution_lambda_loss: 36186832.0000  6/122 [>.............................] - ETA: 1s - loss: 33262848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9994 - distribution_lambda_loss: 33262848.0000 11/122 [=>............................] - ETA: 1s - loss: 33348440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2858 - distribution_lambda_loss: 33348440.0000 16/122 [==>...........................] - ETA: 1s - loss: 33069420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1540 - distribution_lambda_loss: 33069420.0000 21/122 [====>.........................] - ETA: 1s - loss: 33188804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2608 - distribution_lambda_loss: 33188804.0000 26/122 [=====>........................] - ETA: 0s - loss: 33230850.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2354 - distribution_lambda_loss: 33230850.0000 31/122 [======>.......................] - ETA: 0s - loss: 33095080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1152 - distribution_lambda_loss: 33095080.0000 36/122 [=======>......................] - ETA: 0s - loss: 33024598.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0882 - distribution_lambda_loss: 33024598.0000 41/122 [=========>....................] - ETA: 0s - loss: 33028264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0827 - distribution_lambda_loss: 33028264.0000 46/122 [==========>...................] - ETA: 0s - loss: 33145366.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1810 - distribution_lambda_loss: 33145366.0000 51/122 [===========>..................] - ETA: 0s - loss: 33120528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1552 - distribution_lambda_loss: 33120528.0000 56/122 [============>.................] - ETA: 0s - loss: 33174886.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2067 - distribution_lambda_loss: 33174886.0000 61/122 [==============>...............] - ETA: 0s - loss: 33322920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2986 - distribution_lambda_loss: 33322920.0000 66/122 [===============>..............] - ETA: 0s - loss: 33324660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3280 - distribution_lambda_loss: 33324660.0000 71/122 [================>.............] - ETA: 0s - loss: 33285794.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2997 - distribution_lambda_loss: 33285794.0000 76/122 [=================>............] - ETA: 0s - loss: 33259372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2802 - distribution_lambda_loss: 33259372.0000 81/122 [==================>...........] - ETA: 0s - loss: 33281476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2998 - distribution_lambda_loss: 33281476.0000 86/122 [====================>.........] - ETA: 0s - loss: 33196624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2352 - distribution_lambda_loss: 33196624.0000 91/122 [=====================>........] - ETA: 0s - loss: 33215758.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2585 - distribution_lambda_loss: 33215758.0000 96/122 [======================>.......] - ETA: 0s - loss: 33244402.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2656 - distribution_lambda_loss: 33244402.0000101/122 [=======================>......] - ETA: 0s - loss: 33202364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2390 - distribution_lambda_loss: 33202364.0000106/122 [=========================>....] - ETA: 0s - loss: 33217864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2589 - distribution_lambda_loss: 33217864.0000111/122 [==========================>...] - ETA: 0s - loss: 33231306.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2588 - distribution_lambda_loss: 33231306.0000116/122 [===========================>..] - ETA: 0s - loss: 33231232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2623 - distribution_lambda_loss: 33231232.0000121/122 [============================>.] - ETA: 0s - loss: 33204958.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2499 - distribution_lambda_loss: 33204958.0000122/122 [==============================] - 1s 11ms/step - loss: 33203026.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2456 - distribution_lambda_loss: 33203026.0000 - val_loss: 34816372.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 49.1976 - val_distribution_lambda_loss: 34816372.0000 - lr: 5.0000e-04
Epoch 47/50
  1/122 [..............................] - ETA: 1s - loss: 34184280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1400 - distribution_lambda_loss: 34184280.0000  6/122 [>.............................] - ETA: 1s - loss: 32988642.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9812 - distribution_lambda_loss: 32988642.0000 11/122 [=>............................] - ETA: 1s - loss: 33164162.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2109 - distribution_lambda_loss: 33164162.0000 16/122 [==>...........................] - ETA: 1s - loss: 33554968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4644 - distribution_lambda_loss: 33554968.0000 21/122 [====>.........................] - ETA: 1s - loss: 33466934.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4417 - distribution_lambda_loss: 33466934.0000 26/122 [=====>........................] - ETA: 0s - loss: 33243378.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2670 - distribution_lambda_loss: 33243378.0000 31/122 [======>.......................] - ETA: 0s - loss: 32999552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1195 - distribution_lambda_loss: 32999552.0000 36/122 [=======>......................] - ETA: 0s - loss: 32945444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0589 - distribution_lambda_loss: 32945444.0000 41/122 [=========>....................] - ETA: 0s - loss: 32801590.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9543 - distribution_lambda_loss: 32801590.0000 46/122 [==========>...................] - ETA: 0s - loss: 32854492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0360 - distribution_lambda_loss: 32854492.0000 51/122 [===========>..................] - ETA: 0s - loss: 32865988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0144 - distribution_lambda_loss: 32865988.0000 56/122 [============>.................] - ETA: 0s - loss: 32909604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0846 - distribution_lambda_loss: 32909604.0000 61/122 [==============>...............] - ETA: 0s - loss: 32941200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0763 - distribution_lambda_loss: 32941200.0000 66/122 [===============>..............] - ETA: 0s - loss: 33010390.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1572 - distribution_lambda_loss: 33010390.0000 71/122 [================>.............] - ETA: 0s - loss: 33029860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1334 - distribution_lambda_loss: 33029860.0000 76/122 [=================>............] - ETA: 0s - loss: 33060966.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1796 - distribution_lambda_loss: 33060966.0000 81/122 [==================>...........] - ETA: 0s - loss: 33069180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1603 - distribution_lambda_loss: 33069180.0000 86/122 [====================>.........] - ETA: 0s - loss: 33004466.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1258 - distribution_lambda_loss: 33004466.0000 91/122 [=====================>........] - ETA: 0s - loss: 33028346.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1187 - distribution_lambda_loss: 33028346.0000 96/122 [======================>.......] - ETA: 0s - loss: 33053886.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1495 - distribution_lambda_loss: 33053886.0000101/122 [=======================>......] - ETA: 0s - loss: 33078558.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1456 - distribution_lambda_loss: 33078558.0000106/122 [=========================>....] - ETA: 0s - loss: 33135438.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1908 - distribution_lambda_loss: 33135438.0000111/122 [==========================>...] - ETA: 0s - loss: 33190832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2283 - distribution_lambda_loss: 33190832.0000116/122 [===========================>..] - ETA: 0s - loss: 33234850.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2670 - distribution_lambda_loss: 33234850.0000121/122 [============================>.] - ETA: 0s - loss: 33248928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2649 - distribution_lambda_loss: 33248928.0000122/122 [==============================] - 1s 11ms/step - loss: 33248848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2670 - distribution_lambda_loss: 33248848.0000 - val_loss: 35687568.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.7828 - val_distribution_lambda_loss: 35687568.0000 - lr: 5.0000e-04
Epoch 48/50
  1/122 [..............................] - ETA: 1s - loss: 33508468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7307 - distribution_lambda_loss: 33508468.0000  6/122 [>.............................] - ETA: 1s - loss: 33337174.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3249 - distribution_lambda_loss: 33337174.0000 11/122 [=>............................] - ETA: 1s - loss: 33564580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.6434 - distribution_lambda_loss: 33564580.0000 16/122 [==>...........................] - ETA: 1s - loss: 33639900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4770 - distribution_lambda_loss: 33639900.0000 21/122 [====>.........................] - ETA: 1s - loss: 33616880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5150 - distribution_lambda_loss: 33616880.0000 26/122 [=====>........................] - ETA: 0s - loss: 33600348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.4654 - distribution_lambda_loss: 33600348.0000 31/122 [======>.......................] - ETA: 0s - loss: 33385320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3180 - distribution_lambda_loss: 33385320.0000 36/122 [=======>......................] - ETA: 0s - loss: 33314902.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2530 - distribution_lambda_loss: 33314902.0000 41/122 [=========>....................] - ETA: 0s - loss: 33160182.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1708 - distribution_lambda_loss: 33160182.0000 46/122 [==========>...................] - ETA: 0s - loss: 33123070.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1566 - distribution_lambda_loss: 33123070.0000 51/122 [===========>..................] - ETA: 0s - loss: 33127654.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1421 - distribution_lambda_loss: 33127654.0000 56/122 [============>.................] - ETA: 0s - loss: 33118736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1464 - distribution_lambda_loss: 33118736.0000 61/122 [==============>...............] - ETA: 0s - loss: 33086972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1336 - distribution_lambda_loss: 33086972.0000 66/122 [===============>..............] - ETA: 0s - loss: 33147620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1677 - distribution_lambda_loss: 33147620.0000 71/122 [================>.............] - ETA: 0s - loss: 33220666.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2162 - distribution_lambda_loss: 33220666.0000 76/122 [=================>............] - ETA: 0s - loss: 33192650.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2226 - distribution_lambda_loss: 33192650.0000 81/122 [==================>...........] - ETA: 0s - loss: 33209192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2235 - distribution_lambda_loss: 33209192.0000 86/122 [====================>.........] - ETA: 0s - loss: 33235602.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2590 - distribution_lambda_loss: 33235602.0000 91/122 [=====================>........] - ETA: 0s - loss: 33179434.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2074 - distribution_lambda_loss: 33179434.0000 96/122 [======================>.......] - ETA: 0s - loss: 33139936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1970 - distribution_lambda_loss: 33139936.0000101/122 [=======================>......] - ETA: 0s - loss: 33097292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1578 - distribution_lambda_loss: 33097292.0000106/122 [=========================>....] - ETA: 0s - loss: 33078428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1520 - distribution_lambda_loss: 33078428.0000111/122 [==========================>...] - ETA: 0s - loss: 33065940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1463 - distribution_lambda_loss: 33065940.0000116/122 [===========================>..] - ETA: 0s - loss: 33077082.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1572 - distribution_lambda_loss: 33077082.0000121/122 [============================>.] - ETA: 0s - loss: 33028934.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1193 - distribution_lambda_loss: 33028934.0000122/122 [==============================] - 1s 11ms/step - loss: 33036060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1240 - distribution_lambda_loss: 33036060.0000 - val_loss: 34766884.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 49.2354 - val_distribution_lambda_loss: 34766884.0000 - lr: 5.0000e-04
Epoch 49/50
  1/122 [..............................] - ETA: 1s - loss: 32437756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.6482 - distribution_lambda_loss: 32437756.0000  6/122 [>.............................] - ETA: 1s - loss: 31507590.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 46.9653 - distribution_lambda_loss: 31507590.0000 11/122 [=>............................] - ETA: 1s - loss: 31735134.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.1435 - distribution_lambda_loss: 31735134.0000 16/122 [==>...........................] - ETA: 1s - loss: 31936578.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.2974 - distribution_lambda_loss: 31936578.0000 21/122 [====>.........................] - ETA: 1s - loss: 32076190.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.3835 - distribution_lambda_loss: 32076190.0000 26/122 [=====>........................] - ETA: 0s - loss: 32191394.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.4920 - distribution_lambda_loss: 32191394.0000 31/122 [======>.......................] - ETA: 0s - loss: 32250192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.4983 - distribution_lambda_loss: 32250192.0000 36/122 [=======>......................] - ETA: 0s - loss: 32495100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7164 - distribution_lambda_loss: 32495100.0000 41/122 [=========>....................] - ETA: 0s - loss: 32491532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.6850 - distribution_lambda_loss: 32491532.0000 46/122 [==========>...................] - ETA: 0s - loss: 32431124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.6719 - distribution_lambda_loss: 32431124.0000 51/122 [===========>..................] - ETA: 0s - loss: 32457710.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.6592 - distribution_lambda_loss: 32457710.0000 56/122 [============>.................] - ETA: 0s - loss: 32512486.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7326 - distribution_lambda_loss: 32512486.0000 61/122 [==============>...............] - ETA: 0s - loss: 32500590.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7167 - distribution_lambda_loss: 32500590.0000 66/122 [===============>..............] - ETA: 0s - loss: 32572908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7694 - distribution_lambda_loss: 32572908.0000 71/122 [================>.............] - ETA: 0s - loss: 32538220.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7301 - distribution_lambda_loss: 32538220.0000 76/122 [=================>............] - ETA: 0s - loss: 32535454.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7456 - distribution_lambda_loss: 32535454.0000 81/122 [==================>...........] - ETA: 0s - loss: 32548668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7629 - distribution_lambda_loss: 32548668.0000 86/122 [====================>.........] - ETA: 0s - loss: 32523988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7324 - distribution_lambda_loss: 32523988.0000 91/122 [=====================>........] - ETA: 0s - loss: 32513494.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7319 - distribution_lambda_loss: 32513494.0000 96/122 [======================>.......] - ETA: 0s - loss: 32536310.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7460 - distribution_lambda_loss: 32536310.0000101/122 [=======================>......] - ETA: 0s - loss: 32595958.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7731 - distribution_lambda_loss: 32595958.0000106/122 [=========================>....] - ETA: 0s - loss: 32573576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7619 - distribution_lambda_loss: 32573576.0000111/122 [==========================>...] - ETA: 0s - loss: 32572396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7540 - distribution_lambda_loss: 32572396.0000116/122 [===========================>..] - ETA: 0s - loss: 32607388.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.7967 - distribution_lambda_loss: 32607388.0000121/122 [============================>.] - ETA: 0s - loss: 32642786.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8103 - distribution_lambda_loss: 32642786.0000122/122 [==============================] - 1s 11ms/step - loss: 32635750.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8082 - distribution_lambda_loss: 32635750.0000 - val_loss: 35337952.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.5851 - val_distribution_lambda_loss: 35337952.0000 - lr: 5.0000e-04
Epoch 50/50
  1/122 [..............................] - ETA: 1s - loss: 33249252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1834 - distribution_lambda_loss: 33249252.0000  6/122 [>.............................] - ETA: 1s - loss: 33685084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.5152 - distribution_lambda_loss: 33685084.0000 11/122 [=>............................] - ETA: 1s - loss: 32904946.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0135 - distribution_lambda_loss: 32904946.0000 16/122 [==>...........................] - ETA: 1s - loss: 33212548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2061 - distribution_lambda_loss: 33212548.0000 21/122 [====>.........................] - ETA: 1s - loss: 33449472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.3397 - distribution_lambda_loss: 33449472.0000 26/122 [=====>........................] - ETA: 0s - loss: 33301056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.2170 - distribution_lambda_loss: 33301056.0000 31/122 [======>.......................] - ETA: 0s - loss: 33324458.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1985 - distribution_lambda_loss: 33324458.0000 36/122 [=======>......................] - ETA: 0s - loss: 33148438.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1396 - distribution_lambda_loss: 33148438.0000 41/122 [=========>....................] - ETA: 0s - loss: 33115336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0872 - distribution_lambda_loss: 33115336.0000 46/122 [==========>...................] - ETA: 0s - loss: 33109858.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.1142 - distribution_lambda_loss: 33109858.0000 51/122 [===========>..................] - ETA: 0s - loss: 33075380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0656 - distribution_lambda_loss: 33075380.0000 56/122 [============>.................] - ETA: 0s - loss: 33034926.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0576 - distribution_lambda_loss: 33034926.0000 61/122 [==============>...............] - ETA: 0s - loss: 33024998.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.0414 - distribution_lambda_loss: 33024998.0000 66/122 [===============>..............] - ETA: 0s - loss: 32933264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9950 - distribution_lambda_loss: 32933264.0000 71/122 [================>.............] - ETA: 0s - loss: 32831704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.9010 - distribution_lambda_loss: 32831704.0000 76/122 [=================>............] - ETA: 0s - loss: 32761050.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8700 - distribution_lambda_loss: 32761050.0000 81/122 [==================>...........] - ETA: 0s - loss: 32757286.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8540 - distribution_lambda_loss: 32757286.0000 86/122 [====================>.........] - ETA: 0s - loss: 32748064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8641 - distribution_lambda_loss: 32748064.0000 91/122 [=====================>........] - ETA: 0s - loss: 32777146.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8667 - distribution_lambda_loss: 32777146.0000 96/122 [======================>.......] - ETA: 0s - loss: 32750552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8651 - distribution_lambda_loss: 32750552.0000101/122 [=======================>......] - ETA: 0s - loss: 32695564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8291 - distribution_lambda_loss: 32695564.0000106/122 [=========================>....] - ETA: 0s - loss: 32705696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8425 - distribution_lambda_loss: 32705696.0000111/122 [==========================>...] - ETA: 0s - loss: 32687404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8288 - distribution_lambda_loss: 32687404.0000116/122 [===========================>..] - ETA: 0s - loss: 32749212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8658 - distribution_lambda_loss: 32749212.0000121/122 [============================>.] - ETA: 0s - loss: 32774234.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8823 - distribution_lambda_loss: 32774234.0000
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 32783982.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8896 - distribution_lambda_loss: 32783982.0000 - val_loss: 35987920.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.6229 - val_distribution_lambda_loss: 35987920.0000 - lr: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:31  5/322 [..............................] - ETA: 5s    8/322 [..............................] - ETA: 5s 12/322 [>.............................] - ETA: 5s 15/322 [>.............................] - ETA: 5s 19/322 [>.............................] - ETA: 5s 22/322 [=>............................] - ETA: 4s 26/322 [=>............................] - ETA: 4s 29/322 [=>............................] - ETA: 4s 32/322 [=>............................] - ETA: 4s 35/322 [==>...........................] - ETA: 4s 38/322 [==>...........................] - ETA: 4s 41/322 [==>...........................] - ETA: 4s 44/322 [===>..........................] - ETA: 4s 48/322 [===>..........................] - ETA: 4s 52/322 [===>..........................] - ETA: 4s 55/322 [====>.........................] - ETA: 4s 59/322 [====>.........................] - ETA: 4s 62/322 [====>.........................] - ETA: 4s 66/322 [=====>........................] - ETA: 4s 69/322 [=====>........................] - ETA: 4s 72/322 [=====>........................] - ETA: 4s 76/322 [======>.......................] - ETA: 4s 79/322 [======>.......................] - ETA: 4s 82/322 [======>.......................] - ETA: 4s 86/322 [=======>......................] - ETA: 4s 89/322 [=======>......................] - ETA: 3s 93/322 [=======>......................] - ETA: 3s 97/322 [========>.....................] - ETA: 3s100/322 [========>.....................] - ETA: 3s104/322 [========>.....................] - ETA: 3s107/322 [========>.....................] - ETA: 3s111/322 [=========>....................] - ETA: 3s115/322 [=========>....................] - ETA: 3s119/322 [==========>...................] - ETA: 3s123/322 [==========>...................] - ETA: 3s126/322 [==========>...................] - ETA: 3s130/322 [===========>..................] - ETA: 3s134/322 [===========>..................] - ETA: 3s138/322 [===========>..................] - ETA: 3s142/322 [============>.................] - ETA: 3s146/322 [============>.................] - ETA: 2s150/322 [============>.................] - ETA: 2s154/322 [=============>................] - ETA: 2s158/322 [=============>................] - ETA: 2s161/322 [==============>...............] - ETA: 2s165/322 [==============>...............] - ETA: 2s168/322 [==============>...............] - ETA: 2s172/322 [===============>..............] - ETA: 2s176/322 [===============>..............] - ETA: 2s179/322 [===============>..............] - ETA: 2s182/322 [===============>..............] - ETA: 2s185/322 [================>.............] - ETA: 2s189/322 [================>.............] - ETA: 2s193/322 [================>.............] - ETA: 2s197/322 [=================>............] - ETA: 2s201/322 [=================>............] - ETA: 2s204/322 [==================>...........] - ETA: 1s208/322 [==================>...........] - ETA: 1s211/322 [==================>...........] - ETA: 1s215/322 [===================>..........] - ETA: 1s218/322 [===================>..........] - ETA: 1s222/322 [===================>..........] - ETA: 1s226/322 [====================>.........] - ETA: 1s229/322 [====================>.........] - ETA: 1s233/322 [====================>.........] - ETA: 1s236/322 [====================>.........] - ETA: 1s239/322 [=====================>........] - ETA: 1s243/322 [=====================>........] - ETA: 1s246/322 [=====================>........] - ETA: 1s249/322 [======================>.......] - ETA: 1s252/322 [======================>.......] - ETA: 1s255/322 [======================>.......] - ETA: 1s259/322 [=======================>......] - ETA: 1s262/322 [=======================>......] - ETA: 1s266/322 [=======================>......] - ETA: 0s270/322 [========================>.....] - ETA: 0s273/322 [========================>.....] - ETA: 0s277/322 [========================>.....] - ETA: 0s281/322 [=========================>....] - ETA: 0s285/322 [=========================>....] - ETA: 0s289/322 [=========================>....] - ETA: 0s292/322 [==========================>...] - ETA: 0s296/322 [==========================>...] - ETA: 0s299/322 [==========================>...] - ETA: 0s302/322 [===========================>..] - ETA: 0s306/322 [===========================>..] - ETA: 0s310/322 [===========================>..] - ETA: 0s313/322 [============================>.] - ETA: 0s317/322 [============================>.] - ETA: 0s320/322 [============================>.] - ETA: 0s322/322 [==============================] - 7s 17ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:15:05,851 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:15:08,914 - INFO - Assets written to: /tmp/tmp2muax74o/autoencoder/assets
2025-07-27 21:15:08,962 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:15:10,600 - INFO - Assets written to: /tmp/tmp2muax74o/diffraction_to_obj/assets
2025-07-27 21:15:11,678 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run
[2025-07-27 21:15:12] SUCCESS: PtychoPINN training (n_images=2048, trial=1)
[2025-07-27 21:15:12] EXECUTING: Baseline training (n_images=2048, trial=1)
[2025-07-27 21:15:12] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run' \
            --nepochs 50
2025-07-27 21:15:13.054126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:15:13.054155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:15:13.054995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:15:13.059440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:15:13.532643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:15:14.340751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.374532: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.376736: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:15:14.635517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.637802: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.639871: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.754140: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.755467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.756583: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:15:14.756730: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:15:14.757873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:15:15,042 - INFO - Configuration setup complete
2025-07-27 21:15:15,042 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run'))
2025-07-27 21:15:15,042 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:15:15,042 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:15:15,043 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1/
2025-07-27 21:15:15,043 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:15:15,056 - INFO - 
[2/6] Loading data...
2025-07-27 21:15:15,056 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:15:15,056 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:15:15,090 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
2025-07-27 21:15:15,090 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:15:15,163 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:15:35,767 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-07-27 21:15:35,767 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:15:35,769 - INFO - Final training input shape: (2048, 64, 64, 1)
2025-07-27 21:15:35,769 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:15:35,769 - INFO - Training with 2048 images
DEBUG: Setting timestamp to 07/27/2025, 21:15:15 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:15:15
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:15:37.181960: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:15:37.974757: I external/local_xla/xla/service/service.cc:168] XLA service 0x79838c922080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:15:37.974782: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:15:37.978509: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676138.039917 3720258 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 8:59 - loss: 3.5781 - conv2d_12_loss: 1.2214 - conv2d_19_loss: 2.3567  6/122 [>.............................] - ETA: 1s - loss: 2.9044 - conv2d_12_loss: 1.1158 - conv2d_19_loss: 1.7886   11/122 [=>............................] - ETA: 1s - loss: 2.5599 - conv2d_12_loss: 0.9536 - conv2d_19_loss: 1.6063 16/122 [==>...........................] - ETA: 1s - loss: 2.1423 - conv2d_12_loss: 0.7845 - conv2d_19_loss: 1.3578 21/122 [====>.........................] - ETA: 1s - loss: 1.8517 - conv2d_12_loss: 0.6670 - conv2d_19_loss: 1.1846 26/122 [=====>........................] - ETA: 1s - loss: 1.6437 - conv2d_12_loss: 0.5844 - conv2d_19_loss: 1.0593 31/122 [======>.......................] - ETA: 0s - loss: 1.4843 - conv2d_12_loss: 0.5204 - conv2d_19_loss: 0.9639 36/122 [=======>......................] - ETA: 0s - loss: 1.3570 - conv2d_12_loss: 0.4703 - conv2d_19_loss: 0.8867 41/122 [=========>....................] - ETA: 0s - loss: 1.2513 - conv2d_12_loss: 0.4302 - conv2d_19_loss: 0.8211 46/122 [==========>...................] - ETA: 0s - loss: 1.1638 - conv2d_12_loss: 0.3976 - conv2d_19_loss: 0.7662 51/122 [===========>..................] - ETA: 0s - loss: 1.0909 - conv2d_12_loss: 0.3708 - conv2d_19_loss: 0.7202 56/122 [============>.................] - ETA: 0s - loss: 1.0295 - conv2d_12_loss: 0.3483 - conv2d_19_loss: 0.6812 61/122 [==============>...............] - ETA: 0s - loss: 0.9769 - conv2d_12_loss: 0.3291 - conv2d_19_loss: 0.6477 66/122 [===============>..............] - ETA: 0s - loss: 0.9312 - conv2d_12_loss: 0.3127 - conv2d_19_loss: 0.6185 71/122 [================>.............] - ETA: 0s - loss: 0.8919 - conv2d_12_loss: 0.2983 - conv2d_19_loss: 0.5936 76/122 [=================>............] - ETA: 0s - loss: 0.8574 - conv2d_12_loss: 0.2857 - conv2d_19_loss: 0.5717 81/122 [==================>...........] - ETA: 0s - loss: 0.8260 - conv2d_12_loss: 0.2743 - conv2d_19_loss: 0.5517 86/122 [====================>.........] - ETA: 0s - loss: 0.7974 - conv2d_12_loss: 0.2640 - conv2d_19_loss: 0.5333 91/122 [=====================>........] - ETA: 0s - loss: 0.7721 - conv2d_12_loss: 0.2548 - conv2d_19_loss: 0.5173 96/122 [======================>.......] - ETA: 0s - loss: 0.7492 - conv2d_12_loss: 0.2465 - conv2d_19_loss: 0.5027101/122 [=======================>......] - ETA: 0s - loss: 0.7289 - conv2d_12_loss: 0.2388 - conv2d_19_loss: 0.4901106/122 [=========================>....] - ETA: 0s - loss: 0.7106 - conv2d_12_loss: 0.2318 - conv2d_19_loss: 0.4788111/122 [==========================>...] - ETA: 0s - loss: 0.6936 - conv2d_12_loss: 0.2254 - conv2d_19_loss: 0.4682116/122 [===========================>..] - ETA: 0s - loss: 0.6781 - conv2d_12_loss: 0.2195 - conv2d_19_loss: 0.4586121/122 [============================>.] - ETA: 0s - loss: 0.6632 - conv2d_12_loss: 0.2140 - conv2d_19_loss: 0.4492122/122 [==============================] - ETA: 0s - loss: 0.6615 - conv2d_12_loss: 0.2134 - conv2d_19_loss: 0.4481122/122 [==============================] - 8s 27ms/step - loss: 0.6615 - conv2d_12_loss: 0.2134 - conv2d_19_loss: 0.4481 - val_loss: 0.3153 - val_conv2d_12_loss: 0.0861 - val_conv2d_19_loss: 0.2291 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 0.3233 - conv2d_12_loss: 0.0883 - conv2d_19_loss: 0.2350  6/122 [>.............................] - ETA: 1s - loss: 0.3155 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2284 11/122 [=>............................] - ETA: 1s - loss: 0.3199 - conv2d_12_loss: 0.0884 - conv2d_19_loss: 0.2315 16/122 [==>...........................] - ETA: 1s - loss: 0.3181 - conv2d_12_loss: 0.0878 - conv2d_19_loss: 0.2303 21/122 [====>.........................] - ETA: 1s - loss: 0.3188 - conv2d_12_loss: 0.0882 - conv2d_19_loss: 0.2307 26/122 [=====>........................] - ETA: 0s - loss: 0.3181 - conv2d_12_loss: 0.0881 - conv2d_19_loss: 0.2301 31/122 [======>.......................] - ETA: 0s - loss: 0.3182 - conv2d_12_loss: 0.0878 - conv2d_19_loss: 0.2304 36/122 [=======>......................] - ETA: 0s - loss: 0.3181 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2303 41/122 [=========>....................] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0872 - conv2d_19_loss: 0.2293 46/122 [==========>...................] - ETA: 0s - loss: 0.3164 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2293 51/122 [===========>..................] - ETA: 0s - loss: 0.3156 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2287 56/122 [============>.................] - ETA: 0s - loss: 0.3154 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2287 61/122 [==============>...............] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2292 66/122 [===============>..............] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2297 71/122 [================>.............] - ETA: 0s - loss: 0.3170 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2304 76/122 [=================>............] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2300 81/122 [==================>...........] - ETA: 0s - loss: 0.3163 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2298 86/122 [====================>.........] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2297 91/122 [=====================>........] - ETA: 0s - loss: 0.3164 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2296 96/122 [======================>.......] - ETA: 0s - loss: 0.3162 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2294101/122 [=======================>......] - ETA: 0s - loss: 0.3162 - conv2d_12_loss: 0.0869 - conv2d_19_loss: 0.2293106/122 [=========================>....] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2290111/122 [==========================>...] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2291116/122 [===========================>..] - ETA: 0s - loss: 0.3155 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2288121/122 [============================>.] - ETA: 0s - loss: 0.3155 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2289122/122 [==============================] - 1s 11ms/step - loss: 0.3155 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2289 - val_loss: 0.3129 - val_conv2d_12_loss: 0.0857 - val_conv2d_19_loss: 0.2271 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 0.3077 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2211  6/122 [>.............................] - ETA: 1s - loss: 0.3120 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2260 11/122 [=>............................] - ETA: 1s - loss: 0.3113 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2259 16/122 [==>...........................] - ETA: 1s - loss: 0.3128 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2271 21/122 [====>.........................] - ETA: 1s - loss: 0.3134 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2278 26/122 [=====>........................] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2296 31/122 [======>.......................] - ETA: 0s - loss: 0.3141 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2285 36/122 [=======>......................] - ETA: 0s - loss: 0.3155 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2302 41/122 [=========>....................] - ETA: 0s - loss: 0.3206 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2351 46/122 [==========>...................] - ETA: 0s - loss: 0.3271 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2411 51/122 [===========>..................] - ETA: 0s - loss: 0.3287 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2426 56/122 [============>.................] - ETA: 0s - loss: 0.3291 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2429 61/122 [==============>...............] - ETA: 0s - loss: 0.3301 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2440 66/122 [===============>..............] - ETA: 0s - loss: 0.3295 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2435 71/122 [================>.............] - ETA: 0s - loss: 0.3292 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2430 76/122 [=================>............] - ETA: 0s - loss: 0.3293 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2426 81/122 [==================>...........] - ETA: 0s - loss: 0.3287 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2420 86/122 [====================>.........] - ETA: 0s - loss: 0.3284 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2417 91/122 [=====================>........] - ETA: 0s - loss: 0.3282 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2414 96/122 [======================>.......] - ETA: 0s - loss: 0.3278 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2411101/122 [=======================>......] - ETA: 0s - loss: 0.3266 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2400106/122 [=========================>....] - ETA: 0s - loss: 0.3259 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2394111/122 [==========================>...] - ETA: 0s - loss: 0.3253 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2388116/122 [===========================>..] - ETA: 0s - loss: 0.3247 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2383121/122 [============================>.] - ETA: 0s - loss: 0.3243 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2379122/122 [==============================] - 1s 11ms/step - loss: 0.3243 - conv2d_12_loss: 0.0864 - conv2d_19_loss: 0.2379 - val_loss: 0.3115 - val_conv2d_12_loss: 0.0845 - val_conv2d_19_loss: 0.2270 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 0.3053 - conv2d_12_loss: 0.0832 - conv2d_19_loss: 0.2220  6/122 [>.............................] - ETA: 1s - loss: 0.3080 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2224 11/122 [=>............................] - ETA: 1s - loss: 0.3081 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2230 16/122 [==>...........................] - ETA: 1s - loss: 0.3096 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2242 21/122 [====>.........................] - ETA: 1s - loss: 0.3099 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2247 26/122 [=====>........................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2260 31/122 [======>.......................] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2258 36/122 [=======>......................] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2263 41/122 [=========>....................] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2256 46/122 [==========>...................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2255 51/122 [===========>..................] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2253 56/122 [============>.................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2253 61/122 [==============>...............] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2254 66/122 [===============>..............] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2256 71/122 [================>.............] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2253 76/122 [=================>............] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2255 81/122 [==================>...........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2259 86/122 [====================>.........] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2255 91/122 [=====================>........] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2257 96/122 [======================>.......] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2260101/122 [=======================>......] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2260106/122 [=========================>....] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2259111/122 [==========================>...] - ETA: 0s - loss: 0.3120 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2263116/122 [===========================>..] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2262121/122 [============================>.] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2261122/122 [==============================] - 1s 11ms/step - loss: 0.3116 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2261 - val_loss: 0.3086 - val_conv2d_12_loss: 0.0835 - val_conv2d_19_loss: 0.2250 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 0.3154 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2303  6/122 [>.............................] - ETA: 1s - loss: 0.3073 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2224 11/122 [=>............................] - ETA: 1s - loss: 0.3098 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2242 16/122 [==>...........................] - ETA: 1s - loss: 0.3079 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2225 21/122 [====>.........................] - ETA: 1s - loss: 0.3074 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2225 26/122 [=====>........................] - ETA: 0s - loss: 0.3087 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2237 31/122 [======>.......................] - ETA: 0s - loss: 0.3084 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2235 36/122 [=======>......................] - ETA: 0s - loss: 0.3071 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2224 41/122 [=========>....................] - ETA: 0s - loss: 0.3076 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2227 46/122 [==========>...................] - ETA: 0s - loss: 0.3072 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2224 51/122 [===========>..................] - ETA: 0s - loss: 0.3079 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2229 56/122 [============>.................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2244 61/122 [==============>...............] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2247 66/122 [===============>..............] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2242 71/122 [================>.............] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2242 76/122 [=================>............] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2241 81/122 [==================>...........] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2245 86/122 [====================>.........] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2244 91/122 [=====================>........] - ETA: 0s - loss: 0.3084 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2241 96/122 [======================>.......] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2240101/122 [=======================>......] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2238106/122 [=========================>....] - ETA: 0s - loss: 0.3075 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2235111/122 [==========================>...] - ETA: 0s - loss: 0.3071 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2232116/122 [===========================>..] - ETA: 0s - loss: 0.3068 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2230121/122 [============================>.] - ETA: 0s - loss: 0.3066 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2228122/122 [==============================] - 1s 11ms/step - loss: 0.3066 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2228 - val_loss: 0.2968 - val_conv2d_12_loss: 0.0812 - val_conv2d_19_loss: 0.2155 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 0.2905 - conv2d_12_loss: 0.0805 - conv2d_19_loss: 0.2100  6/122 [>.............................] - ETA: 1s - loss: 0.2889 - conv2d_12_loss: 0.0795 - conv2d_19_loss: 0.2094 11/122 [=>............................] - ETA: 1s - loss: 0.3016 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2151 16/122 [==>...........................] - ETA: 1s - loss: 0.3041 - conv2d_12_loss: 0.0884 - conv2d_19_loss: 0.2157 21/122 [====>.........................] - ETA: 1s - loss: 0.3050 - conv2d_12_loss: 0.0898 - conv2d_19_loss: 0.2153 26/122 [=====>........................] - ETA: 0s - loss: 0.3043 - conv2d_12_loss: 0.0885 - conv2d_19_loss: 0.2158 31/122 [======>.......................] - ETA: 0s - loss: 0.3060 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2184 36/122 [=======>......................] - ETA: 0s - loss: 0.3072 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2206 41/122 [=========>....................] - ETA: 0s - loss: 0.3057 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2198 46/122 [==========>...................] - ETA: 0s - loss: 0.3038 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2190 51/122 [===========>..................] - ETA: 0s - loss: 0.3038 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2197 56/122 [============>.................] - ETA: 0s - loss: 0.3045 - conv2d_12_loss: 0.0834 - conv2d_19_loss: 0.2211 61/122 [==============>...............] - ETA: 0s - loss: 0.3052 - conv2d_12_loss: 0.0830 - conv2d_19_loss: 0.2222 66/122 [===============>..............] - ETA: 0s - loss: 0.3044 - conv2d_12_loss: 0.0825 - conv2d_19_loss: 0.2219 71/122 [================>.............] - ETA: 0s - loss: 0.3036 - conv2d_12_loss: 0.0821 - conv2d_19_loss: 0.2216 76/122 [=================>............] - ETA: 0s - loss: 0.3022 - conv2d_12_loss: 0.0815 - conv2d_19_loss: 0.2207 81/122 [==================>...........] - ETA: 0s - loss: 0.3001 - conv2d_12_loss: 0.0809 - conv2d_19_loss: 0.2192 86/122 [====================>.........] - ETA: 0s - loss: 0.2983 - conv2d_12_loss: 0.0803 - conv2d_19_loss: 0.2180 91/122 [=====================>........] - ETA: 0s - loss: 0.2984 - conv2d_12_loss: 0.0800 - conv2d_19_loss: 0.2184 96/122 [======================>.......] - ETA: 0s - loss: 0.2979 - conv2d_12_loss: 0.0798 - conv2d_19_loss: 0.2182101/122 [=======================>......] - ETA: 0s - loss: 0.2969 - conv2d_12_loss: 0.0795 - conv2d_19_loss: 0.2174106/122 [=========================>....] - ETA: 0s - loss: 0.2953 - conv2d_12_loss: 0.0791 - conv2d_19_loss: 0.2162111/122 [==========================>...] - ETA: 0s - loss: 0.2938 - conv2d_12_loss: 0.0787 - conv2d_19_loss: 0.2151116/122 [===========================>..] - ETA: 0s - loss: 0.2923 - conv2d_12_loss: 0.0783 - conv2d_19_loss: 0.2140121/122 [============================>.] - ETA: 0s - loss: 0.2908 - conv2d_12_loss: 0.0779 - conv2d_19_loss: 0.2129122/122 [==============================] - 1s 11ms/step - loss: 0.2907 - conv2d_12_loss: 0.0779 - conv2d_19_loss: 0.2129 - val_loss: 0.2575 - val_conv2d_12_loss: 0.0694 - val_conv2d_19_loss: 0.1881 - lr: 0.0010
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 0.2460 - conv2d_12_loss: 0.0664 - conv2d_19_loss: 0.1796  6/122 [>.............................] - ETA: 1s - loss: 0.2557 - conv2d_12_loss: 0.0686 - conv2d_19_loss: 0.1870 11/122 [=>............................] - ETA: 1s - loss: 0.2558 - conv2d_12_loss: 0.0679 - conv2d_19_loss: 0.1879 16/122 [==>...........................] - ETA: 1s - loss: 0.2542 - conv2d_12_loss: 0.0674 - conv2d_19_loss: 0.1867 21/122 [====>.........................] - ETA: 1s - loss: 0.2551 - conv2d_12_loss: 0.0680 - conv2d_19_loss: 0.1871 26/122 [=====>........................] - ETA: 0s - loss: 0.2539 - conv2d_12_loss: 0.0677 - conv2d_19_loss: 0.1862 31/122 [======>.......................] - ETA: 0s - loss: 0.2531 - conv2d_12_loss: 0.0677 - conv2d_19_loss: 0.1854 36/122 [=======>......................] - ETA: 0s - loss: 0.2531 - conv2d_12_loss: 0.0677 - conv2d_19_loss: 0.1854 41/122 [=========>....................] - ETA: 0s - loss: 0.2529 - conv2d_12_loss: 0.0675 - conv2d_19_loss: 0.1855 46/122 [==========>...................] - ETA: 0s - loss: 0.2518 - conv2d_12_loss: 0.0671 - conv2d_19_loss: 0.1847 51/122 [===========>..................] - ETA: 0s - loss: 0.2515 - conv2d_12_loss: 0.0670 - conv2d_19_loss: 0.1844 56/122 [============>.................] - ETA: 0s - loss: 0.2498 - conv2d_12_loss: 0.0666 - conv2d_19_loss: 0.1832 61/122 [==============>...............] - ETA: 0s - loss: 0.2483 - conv2d_12_loss: 0.0663 - conv2d_19_loss: 0.1819 66/122 [===============>..............] - ETA: 0s - loss: 0.2468 - conv2d_12_loss: 0.0660 - conv2d_19_loss: 0.1808 71/122 [================>.............] - ETA: 0s - loss: 0.2457 - conv2d_12_loss: 0.0657 - conv2d_19_loss: 0.1800 76/122 [=================>............] - ETA: 0s - loss: 0.2445 - conv2d_12_loss: 0.0655 - conv2d_19_loss: 0.1790 81/122 [==================>...........] - ETA: 0s - loss: 0.2434 - conv2d_12_loss: 0.0653 - conv2d_19_loss: 0.1781 86/122 [====================>.........] - ETA: 0s - loss: 0.2421 - conv2d_12_loss: 0.0650 - conv2d_19_loss: 0.1771 91/122 [=====================>........] - ETA: 0s - loss: 0.2408 - conv2d_12_loss: 0.0648 - conv2d_19_loss: 0.1760 96/122 [======================>.......] - ETA: 0s - loss: 0.2399 - conv2d_12_loss: 0.0647 - conv2d_19_loss: 0.1751101/122 [=======================>......] - ETA: 0s - loss: 0.2389 - conv2d_12_loss: 0.0647 - conv2d_19_loss: 0.1742106/122 [=========================>....] - ETA: 0s - loss: 0.2384 - conv2d_12_loss: 0.0647 - conv2d_19_loss: 0.1737111/122 [==========================>...] - ETA: 0s - loss: 0.2387 - conv2d_12_loss: 0.0651 - conv2d_19_loss: 0.1736116/122 [===========================>..] - ETA: 0s - loss: 0.2386 - conv2d_12_loss: 0.0653 - conv2d_19_loss: 0.1733121/122 [============================>.] - ETA: 0s - loss: 0.2380 - conv2d_12_loss: 0.0653 - conv2d_19_loss: 0.1727122/122 [==============================] - 1s 11ms/step - loss: 0.2379 - conv2d_12_loss: 0.0653 - conv2d_19_loss: 0.1726 - val_loss: 0.2283 - val_conv2d_12_loss: 0.0641 - val_conv2d_19_loss: 0.1642 - lr: 0.0010
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 0.2221 - conv2d_12_loss: 0.0630 - conv2d_19_loss: 0.1592  6/122 [>.............................] - ETA: 1s - loss: 0.2151 - conv2d_12_loss: 0.0607 - conv2d_19_loss: 0.1544 11/122 [=>............................] - ETA: 1s - loss: 0.2162 - conv2d_12_loss: 0.0604 - conv2d_19_loss: 0.1558 16/122 [==>...........................] - ETA: 1s - loss: 0.2143 - conv2d_12_loss: 0.0598 - conv2d_19_loss: 0.1545 21/122 [====>.........................] - ETA: 1s - loss: 0.2167 - conv2d_12_loss: 0.0598 - conv2d_19_loss: 0.1569 26/122 [=====>........................] - ETA: 0s - loss: 0.2173 - conv2d_12_loss: 0.0596 - conv2d_19_loss: 0.1578 31/122 [======>.......................] - ETA: 0s - loss: 0.2188 - conv2d_12_loss: 0.0594 - conv2d_19_loss: 0.1594 36/122 [=======>......................] - ETA: 0s - loss: 0.2187 - conv2d_12_loss: 0.0594 - conv2d_19_loss: 0.1593 41/122 [=========>....................] - ETA: 0s - loss: 0.2178 - conv2d_12_loss: 0.0593 - conv2d_19_loss: 0.1585 46/122 [==========>...................] - ETA: 0s - loss: 0.2159 - conv2d_12_loss: 0.0591 - conv2d_19_loss: 0.1568 51/122 [===========>..................] - ETA: 0s - loss: 0.2143 - conv2d_12_loss: 0.0587 - conv2d_19_loss: 0.1555 56/122 [============>.................] - ETA: 0s - loss: 0.2133 - conv2d_12_loss: 0.0586 - conv2d_19_loss: 0.1547 61/122 [==============>...............] - ETA: 0s - loss: 0.2123 - conv2d_12_loss: 0.0584 - conv2d_19_loss: 0.1540 66/122 [===============>..............] - ETA: 0s - loss: 0.2108 - conv2d_12_loss: 0.0581 - conv2d_19_loss: 0.1527 71/122 [================>.............] - ETA: 0s - loss: 0.2102 - conv2d_12_loss: 0.0578 - conv2d_19_loss: 0.1524 76/122 [=================>............] - ETA: 0s - loss: 0.2104 - conv2d_12_loss: 0.0576 - conv2d_19_loss: 0.1528 81/122 [==================>...........] - ETA: 0s - loss: 0.2118 - conv2d_12_loss: 0.0575 - conv2d_19_loss: 0.1543 86/122 [====================>.........] - ETA: 0s - loss: 0.2149 - conv2d_12_loss: 0.0575 - conv2d_19_loss: 0.1574 91/122 [=====================>........] - ETA: 0s - loss: 0.2192 - conv2d_12_loss: 0.0574 - conv2d_19_loss: 0.1619 96/122 [======================>.......] - ETA: 0s - loss: 0.2215 - conv2d_12_loss: 0.0573 - conv2d_19_loss: 0.1641101/122 [=======================>......] - ETA: 0s - loss: 0.2229 - conv2d_12_loss: 0.0573 - conv2d_19_loss: 0.1656106/122 [=========================>....] - ETA: 0s - loss: 0.2224 - conv2d_12_loss: 0.0571 - conv2d_19_loss: 0.1653111/122 [==========================>...] - ETA: 0s - loss: 0.2215 - conv2d_12_loss: 0.0569 - conv2d_19_loss: 0.1646116/122 [===========================>..] - ETA: 0s - loss: 0.2204 - conv2d_12_loss: 0.0568 - conv2d_19_loss: 0.1636121/122 [============================>.] - ETA: 0s - loss: 0.2194 - conv2d_12_loss: 0.0566 - conv2d_19_loss: 0.1628122/122 [==============================] - 1s 11ms/step - loss: 0.2192 - conv2d_12_loss: 0.0566 - conv2d_19_loss: 0.1626 - val_loss: 0.1922 - val_conv2d_12_loss: 0.0532 - val_conv2d_19_loss: 0.1389 - lr: 0.0010
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 0.1903 - conv2d_12_loss: 0.0526 - conv2d_19_loss: 0.1377  6/122 [>.............................] - ETA: 1s - loss: 0.1903 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1372 11/122 [=>............................] - ETA: 1s - loss: 0.1913 - conv2d_12_loss: 0.0533 - conv2d_19_loss: 0.1380 16/122 [==>...........................] - ETA: 1s - loss: 0.1915 - conv2d_12_loss: 0.0538 - conv2d_19_loss: 0.1377 21/122 [====>.........................] - ETA: 1s - loss: 0.1904 - conv2d_12_loss: 0.0539 - conv2d_19_loss: 0.1364 26/122 [=====>........................] - ETA: 0s - loss: 0.1892 - conv2d_12_loss: 0.0537 - conv2d_19_loss: 0.1356 31/122 [======>.......................] - ETA: 0s - loss: 0.1887 - conv2d_12_loss: 0.0535 - conv2d_19_loss: 0.1352 36/122 [=======>......................] - ETA: 0s - loss: 0.1864 - conv2d_12_loss: 0.0532 - conv2d_19_loss: 0.1333 41/122 [=========>....................] - ETA: 0s - loss: 0.1852 - conv2d_12_loss: 0.0530 - conv2d_19_loss: 0.1322 46/122 [==========>...................] - ETA: 0s - loss: 0.1843 - conv2d_12_loss: 0.0529 - conv2d_19_loss: 0.1314 51/122 [===========>..................] - ETA: 0s - loss: 0.1839 - conv2d_12_loss: 0.0527 - conv2d_19_loss: 0.1311 56/122 [============>.................] - ETA: 0s - loss: 0.1827 - conv2d_12_loss: 0.0524 - conv2d_19_loss: 0.1304 61/122 [==============>...............] - ETA: 0s - loss: 0.1820 - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.1297 66/122 [===============>..............] - ETA: 0s - loss: 0.1816 - conv2d_12_loss: 0.0524 - conv2d_19_loss: 0.1293 71/122 [================>.............] - ETA: 0s - loss: 0.1812 - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.1289 76/122 [=================>............] - ETA: 0s - loss: 0.1812 - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.1289 81/122 [==================>...........] - ETA: 0s - loss: 0.1805 - conv2d_12_loss: 0.0522 - conv2d_19_loss: 0.1284 86/122 [====================>.........] - ETA: 0s - loss: 0.1805 - conv2d_12_loss: 0.0522 - conv2d_19_loss: 0.1283 91/122 [=====================>........] - ETA: 0s - loss: 0.1807 - conv2d_12_loss: 0.0521 - conv2d_19_loss: 0.1285 96/122 [======================>.......] - ETA: 0s - loss: 0.1804 - conv2d_12_loss: 0.0520 - conv2d_19_loss: 0.1284101/122 [=======================>......] - ETA: 0s - loss: 0.1805 - conv2d_12_loss: 0.0519 - conv2d_19_loss: 0.1286106/122 [=========================>....] - ETA: 0s - loss: 0.1801 - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.1283111/122 [==========================>...] - ETA: 0s - loss: 0.1798 - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.1280116/122 [===========================>..] - ETA: 0s - loss: 0.1800 - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.1282121/122 [============================>.] - ETA: 0s - loss: 0.1800 - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.1282122/122 [==============================] - 1s 11ms/step - loss: 0.1800 - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.1282 - val_loss: 0.1798 - val_conv2d_12_loss: 0.0504 - val_conv2d_19_loss: 0.1294 - lr: 0.0010
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 0.1843 - conv2d_12_loss: 0.0522 - conv2d_19_loss: 0.1321  6/122 [>.............................] - ETA: 1s - loss: 0.1735 - conv2d_12_loss: 0.0504 - conv2d_19_loss: 0.1231 11/122 [=>............................] - ETA: 1s - loss: 0.1708 - conv2d_12_loss: 0.0501 - conv2d_19_loss: 0.1206 16/122 [==>...........................] - ETA: 1s - loss: 0.1702 - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.1201 21/122 [====>.........................] - ETA: 1s - loss: 0.1690 - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.1190 26/122 [=====>........................] - ETA: 0s - loss: 0.1685 - conv2d_12_loss: 0.0499 - conv2d_19_loss: 0.1187 31/122 [======>.......................] - ETA: 0s - loss: 0.1683 - conv2d_12_loss: 0.0498 - conv2d_19_loss: 0.1185 36/122 [=======>......................] - ETA: 0s - loss: 0.1665 - conv2d_12_loss: 0.0495 - conv2d_19_loss: 0.1171 41/122 [=========>....................] - ETA: 0s - loss: 0.1663 - conv2d_12_loss: 0.0493 - conv2d_19_loss: 0.1171 46/122 [==========>...................] - ETA: 0s - loss: 0.1667 - conv2d_12_loss: 0.0491 - conv2d_19_loss: 0.1175 51/122 [===========>..................] - ETA: 0s - loss: 0.1662 - conv2d_12_loss: 0.0489 - conv2d_19_loss: 0.1173 56/122 [============>.................] - ETA: 0s - loss: 0.1666 - conv2d_12_loss: 0.0489 - conv2d_19_loss: 0.1176 61/122 [==============>...............] - ETA: 0s - loss: 0.1656 - conv2d_12_loss: 0.0486 - conv2d_19_loss: 0.1170 66/122 [===============>..............] - ETA: 0s - loss: 0.1657 - conv2d_12_loss: 0.0486 - conv2d_19_loss: 0.1171 71/122 [================>.............] - ETA: 0s - loss: 0.1659 - conv2d_12_loss: 0.0486 - conv2d_19_loss: 0.1173 76/122 [=================>............] - ETA: 0s - loss: 0.1654 - conv2d_12_loss: 0.0484 - conv2d_19_loss: 0.1170 81/122 [==================>...........] - ETA: 0s - loss: 0.1647 - conv2d_12_loss: 0.0483 - conv2d_19_loss: 0.1165 86/122 [====================>.........] - ETA: 0s - loss: 0.1641 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1160 91/122 [=====================>........] - ETA: 0s - loss: 0.1639 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1157 96/122 [======================>.......] - ETA: 0s - loss: 0.1635 - conv2d_12_loss: 0.0482 - conv2d_19_loss: 0.1154101/122 [=======================>......] - ETA: 0s - loss: 0.1631 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1150106/122 [=========================>....] - ETA: 0s - loss: 0.1630 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1149111/122 [==========================>...] - ETA: 0s - loss: 0.1629 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1148116/122 [===========================>..] - ETA: 0s - loss: 0.1629 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1148121/122 [============================>.] - ETA: 0s - loss: 0.1629 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1148122/122 [==============================] - 1s 11ms/step - loss: 0.1630 - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.1149 - val_loss: 0.1845 - val_conv2d_12_loss: 0.0468 - val_conv2d_19_loss: 0.1376 - lr: 0.0010
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 0.1728 - conv2d_12_loss: 0.0441 - conv2d_19_loss: 0.1288  6/122 [>.............................] - ETA: 1s - loss: 0.1667 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1205 11/122 [=>............................] - ETA: 1s - loss: 0.1647 - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.1182 16/122 [==>...........................] - ETA: 1s - loss: 0.1614 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1153 21/122 [====>.........................] - ETA: 1s - loss: 0.1593 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1132 26/122 [=====>........................] - ETA: 0s - loss: 0.1561 - conv2d_12_loss: 0.0457 - conv2d_19_loss: 0.1104 31/122 [======>.......................] - ETA: 0s - loss: 0.1549 - conv2d_12_loss: 0.0457 - conv2d_19_loss: 0.1093 36/122 [=======>......................] - ETA: 0s - loss: 0.1562 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1101 41/122 [=========>....................] - ETA: 0s - loss: 0.1567 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1106 46/122 [==========>...................] - ETA: 0s - loss: 0.1565 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1105 51/122 [===========>..................] - ETA: 0s - loss: 0.1567 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1108 56/122 [============>.................] - ETA: 0s - loss: 0.1572 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1112 61/122 [==============>...............] - ETA: 0s - loss: 0.1575 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1114 66/122 [===============>..............] - ETA: 0s - loss: 0.1571 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1110 71/122 [================>.............] - ETA: 0s - loss: 0.1566 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1106 76/122 [=================>............] - ETA: 0s - loss: 0.1564 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1102 81/122 [==================>...........] - ETA: 0s - loss: 0.1563 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1100 86/122 [====================>.........] - ETA: 0s - loss: 0.1558 - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.1095 91/122 [=====================>........] - ETA: 0s - loss: 0.1555 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1092 96/122 [======================>.......] - ETA: 0s - loss: 0.1549 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1087101/122 [=======================>......] - ETA: 0s - loss: 0.1546 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1084106/122 [=========================>....] - ETA: 0s - loss: 0.1541 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1080111/122 [==========================>...] - ETA: 0s - loss: 0.1534 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1074116/122 [===========================>..] - ETA: 0s - loss: 0.1533 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1073121/122 [============================>.] - ETA: 0s - loss: 0.1530 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1071122/122 [==============================] - 1s 11ms/step - loss: 0.1529 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1071 - val_loss: 0.1512 - val_conv2d_12_loss: 0.0455 - val_conv2d_19_loss: 0.1056 - lr: 0.0010
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 0.1470 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1031  6/122 [>.............................] - ETA: 1s - loss: 0.1423 - conv2d_12_loss: 0.0445 - conv2d_19_loss: 0.0978 11/122 [=>............................] - ETA: 1s - loss: 0.1424 - conv2d_12_loss: 0.0443 - conv2d_19_loss: 0.0981 16/122 [==>...........................] - ETA: 1s - loss: 0.1436 - conv2d_12_loss: 0.0441 - conv2d_19_loss: 0.0995 21/122 [====>.........................] - ETA: 1s - loss: 0.1421 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.0982 26/122 [=====>........................] - ETA: 0s - loss: 0.1429 - conv2d_12_loss: 0.0441 - conv2d_19_loss: 0.0988 31/122 [======>.......................] - ETA: 0s - loss: 0.1440 - conv2d_12_loss: 0.0446 - conv2d_19_loss: 0.0994 36/122 [=======>......................] - ETA: 0s - loss: 0.1458 - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.1007 41/122 [=========>....................] - ETA: 0s - loss: 0.1461 - conv2d_12_loss: 0.0452 - conv2d_19_loss: 0.1010 46/122 [==========>...................] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0456 - conv2d_19_loss: 0.1018 51/122 [===========>..................] - ETA: 0s - loss: 0.1486 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1028 56/122 [============>.................] - ETA: 0s - loss: 0.1489 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1030 61/122 [==============>...............] - ETA: 0s - loss: 0.1495 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1035 66/122 [===============>..............] - ETA: 0s - loss: 0.1494 - conv2d_12_loss: 0.0457 - conv2d_19_loss: 0.1037 71/122 [================>.............] - ETA: 0s - loss: 0.1499 - conv2d_12_loss: 0.0457 - conv2d_19_loss: 0.1042 76/122 [=================>............] - ETA: 0s - loss: 0.1499 - conv2d_12_loss: 0.0455 - conv2d_19_loss: 0.1044 81/122 [==================>...........] - ETA: 0s - loss: 0.1505 - conv2d_12_loss: 0.0455 - conv2d_19_loss: 0.1050 86/122 [====================>.........] - ETA: 0s - loss: 0.1504 - conv2d_12_loss: 0.0454 - conv2d_19_loss: 0.1050 91/122 [=====================>........] - ETA: 0s - loss: 0.1500 - conv2d_12_loss: 0.0453 - conv2d_19_loss: 0.1047 96/122 [======================>.......] - ETA: 0s - loss: 0.1496 - conv2d_12_loss: 0.0452 - conv2d_19_loss: 0.1044101/122 [=======================>......] - ETA: 0s - loss: 0.1489 - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.1038106/122 [=========================>....] - ETA: 0s - loss: 0.1485 - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.1035111/122 [==========================>...] - ETA: 0s - loss: 0.1477 - conv2d_12_loss: 0.0448 - conv2d_19_loss: 0.1029116/122 [===========================>..] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0448 - conv2d_19_loss: 0.1026121/122 [============================>.] - ETA: 0s - loss: 0.1473 - conv2d_12_loss: 0.0448 - conv2d_19_loss: 0.1025122/122 [==============================] - 1s 11ms/step - loss: 0.1473 - conv2d_12_loss: 0.0448 - conv2d_19_loss: 0.1026 - val_loss: 0.1496 - val_conv2d_12_loss: 0.0453 - val_conv2d_19_loss: 0.1043 - lr: 0.0010
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 0.1316 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.0885  6/122 [>.............................] - ETA: 1s - loss: 0.1414 - conv2d_12_loss: 0.0435 - conv2d_19_loss: 0.0979 11/122 [=>............................] - ETA: 1s - loss: 0.1401 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.0970 16/122 [==>...........................] - ETA: 1s - loss: 0.1384 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.0957 21/122 [====>.........................] - ETA: 1s - loss: 0.1380 - conv2d_12_loss: 0.0428 - conv2d_19_loss: 0.0952 26/122 [=====>........................] - ETA: 0s - loss: 0.1373 - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.0947 31/122 [======>.......................] - ETA: 0s - loss: 0.1369 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0945 36/122 [=======>......................] - ETA: 0s - loss: 0.1362 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0941 41/122 [=========>....................] - ETA: 0s - loss: 0.1361 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0940 46/122 [==========>...................] - ETA: 0s - loss: 0.1358 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0938 51/122 [===========>..................] - ETA: 0s - loss: 0.1357 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0938 56/122 [============>.................] - ETA: 0s - loss: 0.1362 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0940 61/122 [==============>...............] - ETA: 0s - loss: 0.1363 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0941 66/122 [===============>..............] - ETA: 0s - loss: 0.1369 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0947 71/122 [================>.............] - ETA: 0s - loss: 0.1371 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0950 76/122 [=================>............] - ETA: 0s - loss: 0.1376 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0954 81/122 [==================>...........] - ETA: 0s - loss: 0.1377 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0955 86/122 [====================>.........] - ETA: 0s - loss: 0.1379 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0956 91/122 [=====================>........] - ETA: 0s - loss: 0.1381 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0958 96/122 [======================>.......] - ETA: 0s - loss: 0.1379 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0957101/122 [=======================>......] - ETA: 0s - loss: 0.1382 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0959106/122 [=========================>....] - ETA: 0s - loss: 0.1382 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0959111/122 [==========================>...] - ETA: 0s - loss: 0.1382 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0959116/122 [===========================>..] - ETA: 0s - loss: 0.1380 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0957121/122 [============================>.] - ETA: 0s - loss: 0.1380 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0957122/122 [==============================] - 1s 11ms/step - loss: 0.1379 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0956 - val_loss: 0.1434 - val_conv2d_12_loss: 0.0438 - val_conv2d_19_loss: 0.0996 - lr: 0.0010
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 0.1317 - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.0911  6/122 [>.............................] - ETA: 1s - loss: 0.1286 - conv2d_12_loss: 0.0414 - conv2d_19_loss: 0.0872 11/122 [=>............................] - ETA: 1s - loss: 0.1297 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0878 16/122 [==>...........................] - ETA: 1s - loss: 0.1291 - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.0867 21/122 [====>.........................] - ETA: 1s - loss: 0.1280 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0858 26/122 [=====>........................] - ETA: 0s - loss: 0.1290 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0865 31/122 [======>.......................] - ETA: 0s - loss: 0.1292 - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.0868 36/122 [=======>......................] - ETA: 0s - loss: 0.1300 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0877 41/122 [=========>....................] - ETA: 0s - loss: 0.1304 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0880 46/122 [==========>...................] - ETA: 0s - loss: 0.1307 - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.0883 51/122 [===========>..................] - ETA: 0s - loss: 0.1305 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0880 56/122 [============>.................] - ETA: 0s - loss: 0.1306 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0880 61/122 [==============>...............] - ETA: 0s - loss: 0.1308 - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.0883 66/122 [===============>..............] - ETA: 0s - loss: 0.1306 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0880 71/122 [================>.............] - ETA: 0s - loss: 0.1304 - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.0878 76/122 [=================>............] - ETA: 0s - loss: 0.1306 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0880 81/122 [==================>...........] - ETA: 0s - loss: 0.1301 - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.0877 86/122 [====================>.........] - ETA: 0s - loss: 0.1302 - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.0879 91/122 [=====================>........] - ETA: 0s - loss: 0.1300 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0877 96/122 [======================>.......] - ETA: 0s - loss: 0.1297 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0875101/122 [=======================>......] - ETA: 0s - loss: 0.1294 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0873106/122 [=========================>....] - ETA: 0s - loss: 0.1294 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0874111/122 [==========================>...] - ETA: 0s - loss: 0.1295 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0875116/122 [===========================>..] - ETA: 0s - loss: 0.1292 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0874121/122 [============================>.] - ETA: 0s - loss: 0.1290 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0871122/122 [==============================] - 1s 11ms/step - loss: 0.1290 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0871 - val_loss: 0.1352 - val_conv2d_12_loss: 0.0430 - val_conv2d_19_loss: 0.0922 - lr: 0.0010
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 0.1204 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0814  6/122 [>.............................] - ETA: 1s - loss: 0.1234 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0833 11/122 [=>............................] - ETA: 1s - loss: 0.1254 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0850 16/122 [==>...........................] - ETA: 1s - loss: 0.1274 - conv2d_12_loss: 0.0408 - conv2d_19_loss: 0.0867 21/122 [====>.........................] - ETA: 1s - loss: 0.1284 - conv2d_12_loss: 0.0409 - conv2d_19_loss: 0.0874 26/122 [=====>........................] - ETA: 0s - loss: 0.1290 - conv2d_12_loss: 0.0411 - conv2d_19_loss: 0.0880 31/122 [======>.......................] - ETA: 0s - loss: 0.1291 - conv2d_12_loss: 0.0411 - conv2d_19_loss: 0.0881 36/122 [=======>......................] - ETA: 0s - loss: 0.1280 - conv2d_12_loss: 0.0408 - conv2d_19_loss: 0.0873 41/122 [=========>....................] - ETA: 0s - loss: 0.1278 - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.0871 46/122 [==========>...................] - ETA: 0s - loss: 0.1268 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0863 51/122 [===========>..................] - ETA: 0s - loss: 0.1261 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0857 56/122 [============>.................] - ETA: 0s - loss: 0.1258 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0853 61/122 [==============>...............] - ETA: 0s - loss: 0.1253 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0847 66/122 [===============>..............] - ETA: 0s - loss: 0.1248 - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.0841 71/122 [================>.............] - ETA: 0s - loss: 0.1245 - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.0839 76/122 [=================>............] - ETA: 0s - loss: 0.1241 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0836 81/122 [==================>...........] - ETA: 0s - loss: 0.1237 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0833 86/122 [====================>.........] - ETA: 0s - loss: 0.1240 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0834 91/122 [=====================>........] - ETA: 0s - loss: 0.1236 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0832 96/122 [======================>.......] - ETA: 0s - loss: 0.1234 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0830101/122 [=======================>......] - ETA: 0s - loss: 0.1231 - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.0828106/122 [=========================>....] - ETA: 0s - loss: 0.1229 - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.0827111/122 [==========================>...] - ETA: 0s - loss: 0.1225 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0824116/122 [===========================>..] - ETA: 0s - loss: 0.1225 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0824121/122 [============================>.] - ETA: 0s - loss: 0.1226 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0824122/122 [==============================] - 1s 11ms/step - loss: 0.1225 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0824 - val_loss: 0.1308 - val_conv2d_12_loss: 0.0416 - val_conv2d_19_loss: 0.0892 - lr: 0.0010
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 0.1204 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0813  6/122 [>.............................] - ETA: 1s - loss: 0.1172 - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.0787 11/122 [=>............................] - ETA: 1s - loss: 0.1177 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0788 16/122 [==>...........................] - ETA: 1s - loss: 0.1187 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0796 21/122 [====>.........................] - ETA: 1s - loss: 0.1185 - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.0791 26/122 [=====>........................] - ETA: 0s - loss: 0.1180 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0788 31/122 [======>.......................] - ETA: 0s - loss: 0.1183 - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.0790 36/122 [=======>......................] - ETA: 0s - loss: 0.1178 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0786 41/122 [=========>....................] - ETA: 0s - loss: 0.1179 - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.0787 46/122 [==========>...................] - ETA: 0s - loss: 0.1180 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0787 51/122 [===========>..................] - ETA: 0s - loss: 0.1181 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0790 56/122 [============>.................] - ETA: 0s - loss: 0.1181 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0790 61/122 [==============>...............] - ETA: 0s - loss: 0.1184 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0793 66/122 [===============>..............] - ETA: 0s - loss: 0.1181 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0792 71/122 [================>.............] - ETA: 0s - loss: 0.1182 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0792 76/122 [=================>............] - ETA: 0s - loss: 0.1180 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0791 81/122 [==================>...........] - ETA: 0s - loss: 0.1182 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0792 86/122 [====================>.........] - ETA: 0s - loss: 0.1180 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0790 91/122 [=====================>........] - ETA: 0s - loss: 0.1180 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0790 96/122 [======================>.......] - ETA: 0s - loss: 0.1182 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0792101/122 [=======================>......] - ETA: 0s - loss: 0.1182 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0791106/122 [=========================>....] - ETA: 0s - loss: 0.1186 - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.0793111/122 [==========================>...] - ETA: 0s - loss: 0.1195 - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.0799116/122 [===========================>..] - ETA: 0s - loss: 0.1202 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0803121/122 [============================>.] - ETA: 0s - loss: 0.1209 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0807122/122 [==============================] - 1s 11ms/step - loss: 0.1209 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0807 - val_loss: 0.1551 - val_conv2d_12_loss: 0.0452 - val_conv2d_19_loss: 0.1099 - lr: 0.0010
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 0.1430 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.0999  6/122 [>.............................] - ETA: 1s - loss: 0.1281 - conv2d_12_loss: 0.0409 - conv2d_19_loss: 0.0872 11/122 [=>............................] - ETA: 1s - loss: 0.1247 - conv2d_12_loss: 0.0414 - conv2d_19_loss: 0.0833 16/122 [==>...........................] - ETA: 1s - loss: 0.1226 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0821 21/122 [====>.........................] - ETA: 1s - loss: 0.1221 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0818 26/122 [=====>........................] - ETA: 0s - loss: 0.1227 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0825 31/122 [======>.......................] - ETA: 0s - loss: 0.1234 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0832 36/122 [=======>......................] - ETA: 0s - loss: 0.1233 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0834 41/122 [=========>....................] - ETA: 0s - loss: 0.1230 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0832 46/122 [==========>...................] - ETA: 0s - loss: 0.1219 - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.0823 51/122 [===========>..................] - ETA: 0s - loss: 0.1209 - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.0814 56/122 [============>.................] - ETA: 0s - loss: 0.1204 - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.0810 61/122 [==============>...............] - ETA: 0s - loss: 0.1199 - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.0806 66/122 [===============>..............] - ETA: 0s - loss: 0.1192 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0800 71/122 [================>.............] - ETA: 0s - loss: 0.1187 - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.0797 76/122 [=================>............] - ETA: 0s - loss: 0.1179 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0790 81/122 [==================>...........] - ETA: 0s - loss: 0.1177 - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.0789 86/122 [====================>.........] - ETA: 0s - loss: 0.1177 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0789 91/122 [=====================>........] - ETA: 0s - loss: 0.1175 - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.0786 96/122 [======================>.......] - ETA: 0s - loss: 0.1174 - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.0785101/122 [=======================>......] - ETA: 0s - loss: 0.1174 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0785106/122 [=========================>....] - ETA: 0s - loss: 0.1175 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0785111/122 [==========================>...] - ETA: 0s - loss: 0.1171 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0782116/122 [===========================>..] - ETA: 0s - loss: 0.1168 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0779121/122 [============================>.] - ETA: 0s - loss: 0.1170 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0780
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 0.1169 - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.0780 - val_loss: 0.1310 - val_conv2d_12_loss: 0.0454 - val_conv2d_19_loss: 0.0856 - lr: 0.0010
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 0.1137 - conv2d_12_loss: 0.0432 - conv2d_19_loss: 0.0704  6/122 [>.............................] - ETA: 1s - loss: 0.1084 - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.0692 11/122 [=>............................] - ETA: 1s - loss: 0.1085 - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.0700 16/122 [==>...........................] - ETA: 1s - loss: 0.1084 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0702 21/122 [====>.........................] - ETA: 1s - loss: 0.1068 - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.0691 26/122 [=====>........................] - ETA: 0s - loss: 0.1059 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0684 31/122 [======>.......................] - ETA: 0s - loss: 0.1053 - conv2d_12_loss: 0.0372 - conv2d_19_loss: 0.0680 36/122 [=======>......................] - ETA: 0s - loss: 0.1048 - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.0677 41/122 [=========>....................] - ETA: 0s - loss: 0.1041 - conv2d_12_loss: 0.0369 - conv2d_19_loss: 0.0673 46/122 [==========>...................] - ETA: 0s - loss: 0.1043 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0675 51/122 [===========>..................] - ETA: 0s - loss: 0.1037 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0671 56/122 [============>.................] - ETA: 0s - loss: 0.1034 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0668 61/122 [==============>...............] - ETA: 0s - loss: 0.1032 - conv2d_12_loss: 0.0365 - conv2d_19_loss: 0.0667 66/122 [===============>..............] - ETA: 0s - loss: 0.1029 - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.0664 71/122 [================>.............] - ETA: 0s - loss: 0.1027 - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.0663 76/122 [=================>............] - ETA: 0s - loss: 0.1025 - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.0662 81/122 [==================>...........] - ETA: 0s - loss: 0.1023 - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.0661 86/122 [====================>.........] - ETA: 0s - loss: 0.1020 - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.0658 91/122 [=====================>........] - ETA: 0s - loss: 0.1018 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0657 96/122 [======================>.......] - ETA: 0s - loss: 0.1015 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0654101/122 [=======================>......] - ETA: 0s - loss: 0.1012 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0652106/122 [=========================>....] - ETA: 0s - loss: 0.1011 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0651111/122 [==========================>...] - ETA: 0s - loss: 0.1010 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0651116/122 [===========================>..] - ETA: 0s - loss: 0.1011 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0651121/122 [============================>.] - ETA: 0s - loss: 0.1012 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0653122/122 [==============================] - 1s 11ms/step - loss: 0.1012 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0653 - val_loss: 0.1165 - val_conv2d_12_loss: 0.0389 - val_conv2d_19_loss: 0.0776 - lr: 5.0000e-04
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 0.1034 - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.0672  6/122 [>.............................] - ETA: 1s - loss: 0.0999 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0639 11/122 [=>............................] - ETA: 1s - loss: 0.0997 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0640 16/122 [==>...........................] - ETA: 1s - loss: 0.0988 - conv2d_12_loss: 0.0355 - conv2d_19_loss: 0.0633 21/122 [====>.........................] - ETA: 1s - loss: 0.0984 - conv2d_12_loss: 0.0354 - conv2d_19_loss: 0.0630 26/122 [=====>........................] - ETA: 0s - loss: 0.0976 - conv2d_12_loss: 0.0353 - conv2d_19_loss: 0.0623 31/122 [======>.......................] - ETA: 0s - loss: 0.0978 - conv2d_12_loss: 0.0353 - conv2d_19_loss: 0.0625 36/122 [=======>......................] - ETA: 0s - loss: 0.0975 - conv2d_12_loss: 0.0352 - conv2d_19_loss: 0.0623 41/122 [=========>....................] - ETA: 0s - loss: 0.0970 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0620 46/122 [==========>...................] - ETA: 0s - loss: 0.0972 - conv2d_12_loss: 0.0351 - conv2d_19_loss: 0.0622 51/122 [===========>..................] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0620 56/122 [============>.................] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0620 61/122 [==============>...............] - ETA: 0s - loss: 0.0973 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0623 66/122 [===============>..............] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0620 71/122 [================>.............] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0620 76/122 [=================>............] - ETA: 0s - loss: 0.0972 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0622 81/122 [==================>...........] - ETA: 0s - loss: 0.0968 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0619 86/122 [====================>.........] - ETA: 0s - loss: 0.0967 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0618 91/122 [=====================>........] - ETA: 0s - loss: 0.0968 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0619 96/122 [======================>.......] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0619101/122 [=======================>......] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0620106/122 [=========================>....] - ETA: 0s - loss: 0.0968 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0619111/122 [==========================>...] - ETA: 0s - loss: 0.0967 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0618116/122 [===========================>..] - ETA: 0s - loss: 0.0967 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0618121/122 [============================>.] - ETA: 0s - loss: 0.0966 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0618122/122 [==============================] - 1s 11ms/step - loss: 0.0966 - conv2d_12_loss: 0.0348 - conv2d_19_loss: 0.0618 - val_loss: 0.1142 - val_conv2d_12_loss: 0.0383 - val_conv2d_19_loss: 0.0758 - lr: 5.0000e-04
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 0.1013 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0655  6/122 [>.............................] - ETA: 1s - loss: 0.0924 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0582 11/122 [=>............................] - ETA: 1s - loss: 0.0948 - conv2d_12_loss: 0.0348 - conv2d_19_loss: 0.0600 16/122 [==>...........................] - ETA: 1s - loss: 0.0940 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0595 21/122 [====>.........................] - ETA: 1s - loss: 0.0936 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0592 26/122 [=====>........................] - ETA: 0s - loss: 0.0927 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0586 31/122 [======>.......................] - ETA: 0s - loss: 0.0931 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0588 36/122 [=======>......................] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0586 41/122 [=========>....................] - ETA: 0s - loss: 0.0936 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0593 46/122 [==========>...................] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0346 - conv2d_19_loss: 0.0598 51/122 [===========>..................] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0598 56/122 [============>.................] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0599 61/122 [==============>...............] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0600 66/122 [===============>..............] - ETA: 0s - loss: 0.0945 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0601 71/122 [================>.............] - ETA: 0s - loss: 0.0946 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0601 76/122 [=================>............] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0599 81/122 [==================>...........] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0600 86/122 [====================>.........] - ETA: 0s - loss: 0.0945 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0600 91/122 [=====================>........] - ETA: 0s - loss: 0.0945 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0600 96/122 [======================>.......] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0600101/122 [=======================>......] - ETA: 0s - loss: 0.0944 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0600106/122 [=========================>....] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0599111/122 [==========================>...] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0599116/122 [===========================>..] - ETA: 0s - loss: 0.0946 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0602121/122 [============================>.] - ETA: 0s - loss: 0.0949 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0604122/122 [==============================] - 1s 11ms/step - loss: 0.0949 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0604 - val_loss: 0.1133 - val_conv2d_12_loss: 0.0381 - val_conv2d_19_loss: 0.0752 - lr: 5.0000e-04
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 0.1010 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0641  6/122 [>.............................] - ETA: 1s - loss: 0.0948 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0598 11/122 [=>............................] - ETA: 1s - loss: 0.0932 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0587 16/122 [==>...........................] - ETA: 1s - loss: 0.0933 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0589 21/122 [====>.........................] - ETA: 1s - loss: 0.0934 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0590 26/122 [=====>........................] - ETA: 0s - loss: 0.0931 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0589 31/122 [======>.......................] - ETA: 0s - loss: 0.0931 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0589 36/122 [=======>......................] - ETA: 0s - loss: 0.0930 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0589 41/122 [=========>....................] - ETA: 0s - loss: 0.0933 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0591 46/122 [==========>...................] - ETA: 0s - loss: 0.0934 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0592 51/122 [===========>..................] - ETA: 0s - loss: 0.0934 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0592 56/122 [============>.................] - ETA: 0s - loss: 0.0934 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0592 61/122 [==============>...............] - ETA: 0s - loss: 0.0931 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0589 66/122 [===============>..............] - ETA: 0s - loss: 0.0930 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0588 71/122 [================>.............] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0587 76/122 [=================>............] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0586 81/122 [==================>...........] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0586 86/122 [====================>.........] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0586 91/122 [=====================>........] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0586 96/122 [======================>.......] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0587101/122 [=======================>......] - ETA: 0s - loss: 0.0927 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0586106/122 [=========================>....] - ETA: 0s - loss: 0.0928 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0587111/122 [==========================>...] - ETA: 0s - loss: 0.0929 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0587116/122 [===========================>..] - ETA: 0s - loss: 0.0929 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0587121/122 [============================>.] - ETA: 0s - loss: 0.0927 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0586122/122 [==============================] - 1s 11ms/step - loss: 0.0927 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0585 - val_loss: 0.1137 - val_conv2d_12_loss: 0.0383 - val_conv2d_19_loss: 0.0754 - lr: 5.0000e-04
Epoch 22/50
  1/122 [..............................] - ETA: 1s - loss: 0.0999 - conv2d_12_loss: 0.0355 - conv2d_19_loss: 0.0644  6/122 [>.............................] - ETA: 1s - loss: 0.0888 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0560 11/122 [=>............................] - ETA: 1s - loss: 0.0896 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0565 16/122 [==>...........................] - ETA: 1s - loss: 0.0907 - conv2d_12_loss: 0.0335 - conv2d_19_loss: 0.0572 21/122 [====>.........................] - ETA: 1s - loss: 0.0906 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0570 26/122 [=====>........................] - ETA: 0s - loss: 0.0910 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0573 31/122 [======>.......................] - ETA: 0s - loss: 0.0912 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0576 36/122 [=======>......................] - ETA: 0s - loss: 0.0916 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0580 41/122 [=========>....................] - ETA: 0s - loss: 0.0915 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0578 46/122 [==========>...................] - ETA: 0s - loss: 0.0923 - conv2d_12_loss: 0.0340 - conv2d_19_loss: 0.0583 51/122 [===========>..................] - ETA: 0s - loss: 0.0921 - conv2d_12_loss: 0.0340 - conv2d_19_loss: 0.0580 56/122 [============>.................] - ETA: 0s - loss: 0.0917 - conv2d_12_loss: 0.0339 - conv2d_19_loss: 0.0578 61/122 [==============>...............] - ETA: 0s - loss: 0.0916 - conv2d_12_loss: 0.0339 - conv2d_19_loss: 0.0578 66/122 [===============>..............] - ETA: 0s - loss: 0.0916 - conv2d_12_loss: 0.0339 - conv2d_19_loss: 0.0577 71/122 [================>.............] - ETA: 0s - loss: 0.0913 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0575 76/122 [=================>............] - ETA: 0s - loss: 0.0914 - conv2d_12_loss: 0.0339 - conv2d_19_loss: 0.0575 81/122 [==================>...........] - ETA: 0s - loss: 0.0914 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0575 86/122 [====================>.........] - ETA: 0s - loss: 0.0911 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0573 91/122 [=====================>........] - ETA: 0s - loss: 0.0909 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0572 96/122 [======================>.......] - ETA: 0s - loss: 0.0909 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0571101/122 [=======================>......] - ETA: 0s - loss: 0.0907 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0570106/122 [=========================>....] - ETA: 0s - loss: 0.0908 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0571111/122 [==========================>...] - ETA: 0s - loss: 0.0910 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0572116/122 [===========================>..] - ETA: 0s - loss: 0.0910 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0572121/122 [============================>.] - ETA: 0s - loss: 0.0909 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0571122/122 [==============================] - 1s 11ms/step - loss: 0.0909 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0572 - val_loss: 0.1106 - val_conv2d_12_loss: 0.0377 - val_conv2d_19_loss: 0.0729 - lr: 5.0000e-04
Epoch 23/50
  1/122 [..............................] - ETA: 1s - loss: 0.0943 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0601  6/122 [>.............................] - ETA: 1s - loss: 0.0901 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0565 11/122 [=>............................] - ETA: 1s - loss: 0.0891 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0560 16/122 [==>...........................] - ETA: 1s - loss: 0.0891 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0561 21/122 [====>.........................] - ETA: 1s - loss: 0.0901 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0567 26/122 [=====>........................] - ETA: 1s - loss: 0.0902 - conv2d_12_loss: 0.0335 - conv2d_19_loss: 0.0567 31/122 [======>.......................] - ETA: 0s - loss: 0.0897 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0563 36/122 [=======>......................] - ETA: 0s - loss: 0.0891 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0559 41/122 [=========>....................] - ETA: 0s - loss: 0.0895 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0562 46/122 [==========>...................] - ETA: 0s - loss: 0.0893 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0560 51/122 [===========>..................] - ETA: 0s - loss: 0.0890 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0558 56/122 [============>.................] - ETA: 0s - loss: 0.0895 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0561 61/122 [==============>...............] - ETA: 0s - loss: 0.0895 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0561 66/122 [===============>..............] - ETA: 0s - loss: 0.0891 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0557 71/122 [================>.............] - ETA: 0s - loss: 0.0890 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0557 76/122 [=================>............] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555 81/122 [==================>...........] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555 86/122 [====================>.........] - ETA: 0s - loss: 0.0889 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0556 91/122 [=====================>........] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555 96/122 [======================>.......] - ETA: 0s - loss: 0.0887 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0554101/122 [=======================>......] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555106/122 [=========================>....] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555111/122 [==========================>...] - ETA: 0s - loss: 0.0889 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0556116/122 [===========================>..] - ETA: 0s - loss: 0.0889 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0555121/122 [============================>.] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555122/122 [==============================] - 1s 11ms/step - loss: 0.0889 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0555 - val_loss: 0.1107 - val_conv2d_12_loss: 0.0375 - val_conv2d_19_loss: 0.0731 - lr: 5.0000e-04
Epoch 24/50
  1/122 [..............................] - ETA: 1s - loss: 0.0906 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0563  6/122 [>.............................] - ETA: 1s - loss: 0.0883 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0550 11/122 [=>............................] - ETA: 1s - loss: 0.0875 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0545 16/122 [==>...........................] - ETA: 1s - loss: 0.0885 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0552 21/122 [====>.........................] - ETA: 1s - loss: 0.0879 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0547 26/122 [=====>........................] - ETA: 0s - loss: 0.0879 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0547 31/122 [======>.......................] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0545 36/122 [=======>......................] - ETA: 0s - loss: 0.0874 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0544 41/122 [=========>....................] - ETA: 0s - loss: 0.0874 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543 46/122 [==========>...................] - ETA: 0s - loss: 0.0872 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0542 51/122 [===========>..................] - ETA: 0s - loss: 0.0871 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0541 56/122 [============>.................] - ETA: 0s - loss: 0.0874 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543 61/122 [==============>...............] - ETA: 0s - loss: 0.0874 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0543 66/122 [===============>..............] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0545 71/122 [================>.............] - ETA: 0s - loss: 0.0877 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0546 76/122 [=================>............] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0545 81/122 [==================>...........] - ETA: 0s - loss: 0.0875 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0545 86/122 [====================>.........] - ETA: 0s - loss: 0.0873 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543 91/122 [=====================>........] - ETA: 0s - loss: 0.0872 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0542 96/122 [======================>.......] - ETA: 0s - loss: 0.0873 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543101/122 [=======================>......] - ETA: 0s - loss: 0.0873 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543106/122 [=========================>....] - ETA: 0s - loss: 0.0873 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0543111/122 [==========================>...] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0545116/122 [===========================>..] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0546121/122 [============================>.] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0546
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 0.0877 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0546 - val_loss: 0.1141 - val_conv2d_12_loss: 0.0376 - val_conv2d_19_loss: 0.0765 - lr: 5.0000e-04
Epoch 25/50
  1/122 [..............................] - ETA: 1s - loss: 0.0943 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0600  6/122 [>.............................] - ETA: 1s - loss: 0.0835 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0516 11/122 [=>............................] - ETA: 1s - loss: 0.0869 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0542 16/122 [==>...........................] - ETA: 1s - loss: 0.0851 - conv2d_12_loss: 0.0323 - conv2d_19_loss: 0.0528 21/122 [====>.........................] - ETA: 1s - loss: 0.0848 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0526 26/122 [=====>........................] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0523 31/122 [======>.......................] - ETA: 0s - loss: 0.0839 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0518 36/122 [=======>......................] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0515 41/122 [=========>....................] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0516 46/122 [==========>...................] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0514 51/122 [===========>..................] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0515 56/122 [============>.................] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0514 61/122 [==============>...............] - ETA: 0s - loss: 0.0832 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0511 66/122 [===============>..............] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0513 71/122 [================>.............] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0514 76/122 [=================>............] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0512 81/122 [==================>...........] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0512 86/122 [====================>.........] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0511 91/122 [=====================>........] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0511 96/122 [======================>.......] - ETA: 0s - loss: 0.0832 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0511101/122 [=======================>......] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0512106/122 [=========================>....] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0511111/122 [==========================>...] - ETA: 0s - loss: 0.0832 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0510116/122 [===========================>..] - ETA: 0s - loss: 0.0830 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0509121/122 [============================>.] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0508122/122 [==============================] - 1s 11ms/step - loss: 0.0829 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0508 - val_loss: 0.1071 - val_conv2d_12_loss: 0.0368 - val_conv2d_19_loss: 0.0703 - lr: 2.5000e-04
Epoch 26/50
  1/122 [..............................] - ETA: 1s - loss: 0.0803 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0484  6/122 [>.............................] - ETA: 1s - loss: 0.0796 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0481 11/122 [=>............................] - ETA: 1s - loss: 0.0794 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0480 16/122 [==>...........................] - ETA: 1s - loss: 0.0798 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0483 21/122 [====>.........................] - ETA: 1s - loss: 0.0793 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0479 26/122 [=====>........................] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0487 31/122 [======>.......................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0486 36/122 [=======>......................] - ETA: 0s - loss: 0.0802 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0485 41/122 [=========>....................] - ETA: 0s - loss: 0.0799 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0482 46/122 [==========>...................] - ETA: 0s - loss: 0.0802 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0485 51/122 [===========>..................] - ETA: 0s - loss: 0.0802 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0485 56/122 [============>.................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0486 61/122 [==============>...............] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0486 66/122 [===============>..............] - ETA: 0s - loss: 0.0806 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0489 71/122 [================>.............] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0488 76/122 [=================>............] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0487 81/122 [==================>...........] - ETA: 0s - loss: 0.0807 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0489 86/122 [====================>.........] - ETA: 0s - loss: 0.0807 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0489 91/122 [=====================>........] - ETA: 0s - loss: 0.0806 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0489 96/122 [======================>.......] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0488101/122 [=======================>......] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0487106/122 [=========================>....] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0488111/122 [==========================>...] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0489116/122 [===========================>..] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0488121/122 [============================>.] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0488122/122 [==============================] - 1s 11ms/step - loss: 0.0804 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0487 - val_loss: 0.1057 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.0690 - lr: 2.5000e-04
Epoch 27/50
  1/122 [..............................] - ETA: 1s - loss: 0.0797 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0479  6/122 [>.............................] - ETA: 1s - loss: 0.0782 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0470 11/122 [=>............................] - ETA: 1s - loss: 0.0787 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0473 16/122 [==>...........................] - ETA: 1s - loss: 0.0796 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0481 21/122 [====>.........................] - ETA: 1s - loss: 0.0795 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0479 26/122 [=====>........................] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0475 31/122 [======>.......................] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0475 36/122 [=======>......................] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0472 41/122 [=========>....................] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 46/122 [==========>...................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473 51/122 [===========>..................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473 56/122 [============>.................] - ETA: 0s - loss: 0.0783 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 61/122 [==============>...............] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0472 66/122 [===============>..............] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 71/122 [================>.............] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473 76/122 [=================>............] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0475 81/122 [==================>...........] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0475 86/122 [====================>.........] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0476 91/122 [=====================>........] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0475 96/122 [======================>.......] - ETA: 0s - loss: 0.0788 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0474101/122 [=======================>......] - ETA: 0s - loss: 0.0788 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0474106/122 [=========================>....] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0474111/122 [==========================>...] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473116/122 [===========================>..] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0474121/122 [============================>.] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0476122/122 [==============================] - 1s 11ms/step - loss: 0.0791 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0476 - val_loss: 0.1059 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.0694 - lr: 2.5000e-04
Epoch 28/50
  1/122 [..............................] - ETA: 1s - loss: 0.0824 - conv2d_12_loss: 0.0335 - conv2d_19_loss: 0.0489  6/122 [>.............................] - ETA: 1s - loss: 0.0774 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0457 11/122 [=>............................] - ETA: 1s - loss: 0.0765 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0455 16/122 [==>...........................] - ETA: 1s - loss: 0.0768 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0457 21/122 [====>.........................] - ETA: 1s - loss: 0.0779 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0467 26/122 [=====>........................] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 31/122 [======>.......................] - ETA: 0s - loss: 0.0781 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0469 36/122 [=======>......................] - ETA: 0s - loss: 0.0776 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0466 41/122 [=========>....................] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0465 46/122 [==========>...................] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0469 51/122 [===========>..................] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0470 56/122 [============>.................] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 61/122 [==============>...............] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0473 66/122 [===============>..............] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0473 71/122 [================>.............] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0472 76/122 [=================>............] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0473 81/122 [==================>...........] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473 86/122 [====================>.........] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0472 91/122 [=====================>........] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0473 96/122 [======================>.......] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0472101/122 [=======================>......] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0472106/122 [=========================>....] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0473111/122 [==========================>...] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0474116/122 [===========================>..] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0472121/122 [============================>.] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
122/122 [==============================] - 1s 11ms/step - loss: 0.0784 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0471 - val_loss: 0.1061 - val_conv2d_12_loss: 0.0367 - val_conv2d_19_loss: 0.0695 - lr: 2.5000e-04
Epoch 29/50
  1/122 [..............................] - ETA: 1s - loss: 0.0830 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0501  6/122 [>.............................] - ETA: 1s - loss: 0.0777 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0466 11/122 [=>............................] - ETA: 1s - loss: 0.0756 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0449 16/122 [==>...........................] - ETA: 1s - loss: 0.0759 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0453 21/122 [====>.........................] - ETA: 1s - loss: 0.0755 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0451 26/122 [=====>........................] - ETA: 0s - loss: 0.0758 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0452 31/122 [======>.......................] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0447 36/122 [=======>......................] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0448 41/122 [=========>....................] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0447 46/122 [==========>...................] - ETA: 0s - loss: 0.0749 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0444 51/122 [===========>..................] - ETA: 0s - loss: 0.0750 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0445 56/122 [============>.................] - ETA: 0s - loss: 0.0750 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0445 61/122 [==============>...............] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0446 66/122 [===============>..............] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0445 71/122 [================>.............] - ETA: 0s - loss: 0.0750 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0445 76/122 [=================>............] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0445 81/122 [==================>...........] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0446 86/122 [====================>.........] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0447 91/122 [=====================>........] - ETA: 0s - loss: 0.0754 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0447 96/122 [======================>.......] - ETA: 0s - loss: 0.0755 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0448101/122 [=======================>......] - ETA: 0s - loss: 0.0756 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0449106/122 [=========================>....] - ETA: 0s - loss: 0.0756 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0449111/122 [==========================>...] - ETA: 0s - loss: 0.0755 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0448116/122 [===========================>..] - ETA: 0s - loss: 0.0758 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0450121/122 [============================>.] - ETA: 0s - loss: 0.0759 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0451122/122 [==============================] - 1s 11ms/step - loss: 0.0759 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0451 - val_loss: 0.1046 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0684 - lr: 1.2500e-04
Epoch 30/50
  1/122 [..............................] - ETA: 1s - loss: 0.0739 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0444  6/122 [>.............................] - ETA: 1s - loss: 0.0773 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0460 11/122 [=>............................] - ETA: 1s - loss: 0.0772 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0459 16/122 [==>...........................] - ETA: 1s - loss: 0.0773 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0460 21/122 [====>.........................] - ETA: 1s - loss: 0.0770 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0458 26/122 [=====>........................] - ETA: 0s - loss: 0.0768 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0456 31/122 [======>.......................] - ETA: 0s - loss: 0.0764 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0453 36/122 [=======>......................] - ETA: 0s - loss: 0.0757 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0448 41/122 [=========>....................] - ETA: 0s - loss: 0.0754 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0446 46/122 [==========>...................] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 51/122 [===========>..................] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0444 56/122 [============>.................] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 61/122 [==============>...............] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 66/122 [===============>..............] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 71/122 [================>.............] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 76/122 [=================>............] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0445 81/122 [==================>...........] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 86/122 [====================>.........] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 91/122 [=====================>........] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446 96/122 [======================>.......] - ETA: 0s - loss: 0.0754 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0446101/122 [=======================>......] - ETA: 0s - loss: 0.0753 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0445106/122 [=========================>....] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0445111/122 [==========================>...] - ETA: 0s - loss: 0.0752 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0445116/122 [===========================>..] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0445121/122 [============================>.] - ETA: 0s - loss: 0.0751 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0444122/122 [==============================] - 1s 11ms/step - loss: 0.0750 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0444 - val_loss: 0.1039 - val_conv2d_12_loss: 0.0361 - val_conv2d_19_loss: 0.0678 - lr: 1.2500e-04
Epoch 31/50
  1/122 [..............................] - ETA: 1s - loss: 0.0646 - conv2d_12_loss: 0.0277 - conv2d_19_loss: 0.0369  6/122 [>.............................] - ETA: 1s - loss: 0.0716 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0418 11/122 [=>............................] - ETA: 1s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421 16/122 [==>...........................] - ETA: 1s - loss: 0.0730 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0428 21/122 [====>.........................] - ETA: 1s - loss: 0.0728 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0427 26/122 [=====>........................] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429 31/122 [======>.......................] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0427 36/122 [=======>......................] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0428 41/122 [=========>....................] - ETA: 0s - loss: 0.0730 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0430 46/122 [==========>...................] - ETA: 0s - loss: 0.0730 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0429 51/122 [===========>..................] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0430 56/122 [============>.................] - ETA: 0s - loss: 0.0737 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0434 61/122 [==============>...............] - ETA: 0s - loss: 0.0737 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0434 66/122 [===============>..............] - ETA: 0s - loss: 0.0737 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0434 71/122 [================>.............] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0435 76/122 [=================>............] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0435 81/122 [==================>...........] - ETA: 0s - loss: 0.0737 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0434 86/122 [====================>.........] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0434 91/122 [=====================>........] - ETA: 0s - loss: 0.0740 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0436 96/122 [======================>.......] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0436101/122 [=======================>......] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0435106/122 [=========================>....] - ETA: 0s - loss: 0.0741 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0436111/122 [==========================>...] - ETA: 0s - loss: 0.0743 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0438116/122 [===========================>..] - ETA: 0s - loss: 0.0745 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0439121/122 [============================>.] - ETA: 0s - loss: 0.0745 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0440122/122 [==============================] - 1s 11ms/step - loss: 0.0745 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0440 - val_loss: 0.1040 - val_conv2d_12_loss: 0.0361 - val_conv2d_19_loss: 0.0680 - lr: 1.2500e-04
Epoch 32/50
  1/122 [..............................] - ETA: 1s - loss: 0.0685 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0393  6/122 [>.............................] - ETA: 1s - loss: 0.0752 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0443 11/122 [=>............................] - ETA: 1s - loss: 0.0749 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0440 16/122 [==>...........................] - ETA: 1s - loss: 0.0735 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0431 21/122 [====>.........................] - ETA: 1s - loss: 0.0741 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0436 26/122 [=====>........................] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0435 31/122 [======>.......................] - ETA: 0s - loss: 0.0742 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0437 36/122 [=======>......................] - ETA: 0s - loss: 0.0740 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0435 41/122 [=========>....................] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0434 46/122 [==========>...................] - ETA: 0s - loss: 0.0742 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0436 51/122 [===========>..................] - ETA: 0s - loss: 0.0740 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0434 56/122 [============>.................] - ETA: 0s - loss: 0.0740 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0434 61/122 [==============>...............] - ETA: 0s - loss: 0.0741 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0435 66/122 [===============>..............] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0434 71/122 [================>.............] - ETA: 0s - loss: 0.0740 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0435 76/122 [=================>............] - ETA: 0s - loss: 0.0742 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0436 81/122 [==================>...........] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0435 86/122 [====================>.........] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0433 91/122 [=====================>........] - ETA: 0s - loss: 0.0737 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0433 96/122 [======================>.......] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0434101/122 [=======================>......] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0434106/122 [=========================>....] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0434111/122 [==========================>...] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0434116/122 [===========================>..] - ETA: 0s - loss: 0.0738 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0434121/122 [============================>.] - ETA: 0s - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0435122/122 [==============================] - 1s 11ms/step - loss: 0.0739 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0435 - val_loss: 0.1037 - val_conv2d_12_loss: 0.0360 - val_conv2d_19_loss: 0.0677 - lr: 1.2500e-04
Epoch 33/50
  1/122 [..............................] - ETA: 1s - loss: 0.0660 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0376  6/122 [>.............................] - ETA: 1s - loss: 0.0747 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0442 11/122 [=>............................] - ETA: 1s - loss: 0.0732 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0430 16/122 [==>...........................] - ETA: 1s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426 21/122 [====>.........................] - ETA: 1s - loss: 0.0730 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0427 26/122 [=====>........................] - ETA: 1s - loss: 0.0727 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0425 31/122 [======>.......................] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426 36/122 [=======>......................] - ETA: 0s - loss: 0.0730 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0427 41/122 [=========>....................] - ETA: 0s - loss: 0.0729 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0427 46/122 [==========>...................] - ETA: 0s - loss: 0.0727 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0426 51/122 [===========>..................] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429 56/122 [============>.................] - ETA: 0s - loss: 0.0732 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429 61/122 [==============>...............] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429 66/122 [===============>..............] - ETA: 0s - loss: 0.0730 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0428 71/122 [================>.............] - ETA: 0s - loss: 0.0727 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0426 76/122 [=================>............] - ETA: 0s - loss: 0.0726 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0425 81/122 [==================>...........] - ETA: 0s - loss: 0.0726 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0425 86/122 [====================>.........] - ETA: 0s - loss: 0.0727 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0426 91/122 [=====================>........] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0427 96/122 [======================>.......] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429101/122 [=======================>......] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0429106/122 [=========================>....] - ETA: 0s - loss: 0.0734 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0431111/122 [==========================>...] - ETA: 0s - loss: 0.0735 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0432116/122 [===========================>..] - ETA: 0s - loss: 0.0734 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0431121/122 [============================>.] - ETA: 0s - loss: 0.0734 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0431122/122 [==============================] - 1s 11ms/step - loss: 0.0734 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0431 - val_loss: 0.1033 - val_conv2d_12_loss: 0.0360 - val_conv2d_19_loss: 0.0674 - lr: 1.2500e-04
Epoch 34/50
  1/122 [..............................] - ETA: 1s - loss: 0.0711 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0413  6/122 [>.............................] - ETA: 1s - loss: 0.0728 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0424 11/122 [=>............................] - ETA: 1s - loss: 0.0718 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0418 16/122 [==>...........................] - ETA: 1s - loss: 0.0727 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0426 21/122 [====>.........................] - ETA: 1s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 26/122 [=====>........................] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0420 31/122 [======>.......................] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 36/122 [=======>......................] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 41/122 [=========>....................] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0423 46/122 [==========>...................] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0423 51/122 [===========>..................] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424 56/122 [============>.................] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424 61/122 [==============>...............] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424 66/122 [===============>..............] - ETA: 0s - loss: 0.0731 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0428 71/122 [================>.............] - ETA: 0s - loss: 0.0729 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0426 76/122 [=================>............] - ETA: 0s - loss: 0.0729 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426 81/122 [==================>...........] - ETA: 0s - loss: 0.0727 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0425 86/122 [====================>.........] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426 91/122 [=====================>........] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426 96/122 [======================>.......] - ETA: 0s - loss: 0.0729 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0427101/122 [=======================>......] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426106/122 [=========================>....] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426111/122 [==========================>...] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426116/122 [===========================>..] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0426121/122 [============================>.] - ETA: 0s - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0427122/122 [==============================] - 1s 11ms/step - loss: 0.0728 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0427 - val_loss: 0.1035 - val_conv2d_12_loss: 0.0359 - val_conv2d_19_loss: 0.0676 - lr: 1.2500e-04
Epoch 35/50
  1/122 [..............................] - ETA: 1s - loss: 0.0789 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0482  6/122 [>.............................] - ETA: 1s - loss: 0.0740 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0441 11/122 [=>............................] - ETA: 1s - loss: 0.0730 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0431 16/122 [==>...........................] - ETA: 1s - loss: 0.0721 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0424 21/122 [====>.........................] - ETA: 1s - loss: 0.0725 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0425 26/122 [=====>........................] - ETA: 0s - loss: 0.0720 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0421 31/122 [======>.......................] - ETA: 0s - loss: 0.0720 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0421 36/122 [=======>......................] - ETA: 0s - loss: 0.0720 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0421 41/122 [=========>....................] - ETA: 0s - loss: 0.0720 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421 46/122 [==========>...................] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421 51/122 [===========>..................] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 56/122 [============>.................] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424 61/122 [==============>...............] - ETA: 0s - loss: 0.0723 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 66/122 [===============>..............] - ETA: 0s - loss: 0.0723 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0422 71/122 [================>.............] - ETA: 0s - loss: 0.0723 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0422 76/122 [=================>............] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 81/122 [==================>...........] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 86/122 [====================>.........] - ETA: 0s - loss: 0.0724 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0423 91/122 [=====================>........] - ETA: 0s - loss: 0.0723 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0422 96/122 [======================>.......] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424101/122 [=======================>......] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424106/122 [=========================>....] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424111/122 [==========================>...] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424116/122 [===========================>..] - ETA: 0s - loss: 0.0726 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0425121/122 [============================>.] - ETA: 0s - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424122/122 [==============================] - 1s 11ms/step - loss: 0.0725 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0424 - val_loss: 0.1031 - val_conv2d_12_loss: 0.0358 - val_conv2d_19_loss: 0.0672 - lr: 1.2500e-04
Epoch 36/50
  1/122 [..............................] - ETA: 1s - loss: 0.0699 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0401  6/122 [>.............................] - ETA: 1s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397 11/122 [=>............................] - ETA: 1s - loss: 0.0697 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0402 16/122 [==>...........................] - ETA: 1s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0406 21/122 [====>.........................] - ETA: 1s - loss: 0.0706 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0410 26/122 [=====>........................] - ETA: 0s - loss: 0.0708 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0411 31/122 [======>.......................] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419 36/122 [=======>......................] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0416 41/122 [=========>....................] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0417 46/122 [==========>...................] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0415 51/122 [===========>..................] - ETA: 0s - loss: 0.0715 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0416 56/122 [============>.................] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0416 61/122 [==============>...............] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0418 66/122 [===============>..............] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0420 71/122 [================>.............] - ETA: 0s - loss: 0.0722 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0421 76/122 [=================>............] - ETA: 0s - loss: 0.0719 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0419 81/122 [==================>...........] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419 86/122 [====================>.........] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419 91/122 [=====================>........] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419 96/122 [======================>.......] - ETA: 0s - loss: 0.0719 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0420101/122 [=======================>......] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421106/122 [=========================>....] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421111/122 [==========================>...] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421116/122 [===========================>..] - ETA: 0s - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421121/122 [============================>.] - ETA: 0s - loss: 0.0722 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421122/122 [==============================] - 1s 11ms/step - loss: 0.0721 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0421 - val_loss: 0.1031 - val_conv2d_12_loss: 0.0359 - val_conv2d_19_loss: 0.0672 - lr: 1.2500e-04
Epoch 37/50
  1/122 [..............................] - ETA: 1s - loss: 0.0658 - conv2d_12_loss: 0.0283 - conv2d_19_loss: 0.0376  6/122 [>.............................] - ETA: 1s - loss: 0.0716 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0415 11/122 [=>............................] - ETA: 1s - loss: 0.0715 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0416 16/122 [==>...........................] - ETA: 1s - loss: 0.0705 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0410 21/122 [====>.........................] - ETA: 1s - loss: 0.0704 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0409 26/122 [=====>........................] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0408 31/122 [======>.......................] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 36/122 [=======>......................] - ETA: 0s - loss: 0.0703 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0407 41/122 [=========>....................] - ETA: 0s - loss: 0.0709 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0412 46/122 [==========>...................] - ETA: 0s - loss: 0.0712 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0414 51/122 [===========>..................] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0418 56/122 [============>.................] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0416 61/122 [==============>...............] - ETA: 0s - loss: 0.0715 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0417 66/122 [===============>..............] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 71/122 [================>.............] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 76/122 [=================>............] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 81/122 [==================>...........] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 86/122 [====================>.........] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 91/122 [=====================>........] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419 96/122 [======================>.......] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418101/122 [=======================>......] - ETA: 0s - loss: 0.0718 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0419106/122 [=========================>....] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418111/122 [==========================>...] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0417116/122 [===========================>..] - ETA: 0s - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418121/122 [============================>.] - ETA: 0s - loss: 0.0716 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0417122/122 [==============================] - 1s 11ms/step - loss: 0.0717 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0418 - val_loss: 0.1028 - val_conv2d_12_loss: 0.0358 - val_conv2d_19_loss: 0.0670 - lr: 1.2500e-04
Epoch 38/50
  1/122 [..............................] - ETA: 1s - loss: 0.0688 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0397  6/122 [>.............................] - ETA: 1s - loss: 0.0701 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0404 11/122 [=>............................] - ETA: 1s - loss: 0.0709 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0411 16/122 [==>...........................] - ETA: 1s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0408 21/122 [====>.........................] - ETA: 1s - loss: 0.0716 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0416 26/122 [=====>........................] - ETA: 0s - loss: 0.0715 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0416 31/122 [======>.......................] - ETA: 0s - loss: 0.0715 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0416 36/122 [=======>......................] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415 41/122 [=========>....................] - ETA: 0s - loss: 0.0712 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0414 46/122 [==========>...................] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0415 51/122 [===========>..................] - ETA: 0s - loss: 0.0711 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0413 56/122 [============>.................] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415 61/122 [==============>...............] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415 66/122 [===============>..............] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0415 71/122 [================>.............] - ETA: 0s - loss: 0.0712 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0414 76/122 [=================>............] - ETA: 0s - loss: 0.0711 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0414 81/122 [==================>...........] - ETA: 0s - loss: 0.0711 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0413 86/122 [====================>.........] - ETA: 0s - loss: 0.0711 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0413 91/122 [=====================>........] - ETA: 0s - loss: 0.0710 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0413 96/122 [======================>.......] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415101/122 [=======================>......] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415106/122 [=========================>....] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415111/122 [==========================>...] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415116/122 [===========================>..] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415121/122 [============================>.] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415122/122 [==============================] - 1s 11ms/step - loss: 0.0713 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0415 - val_loss: 0.1025 - val_conv2d_12_loss: 0.0357 - val_conv2d_19_loss: 0.0668 - lr: 1.2500e-04
Epoch 39/50
  1/122 [..............................] - ETA: 1s - loss: 0.0698 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0398  6/122 [>.............................] - ETA: 1s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 11/122 [=>............................] - ETA: 1s - loss: 0.0701 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0408 16/122 [==>...........................] - ETA: 1s - loss: 0.0693 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0402 21/122 [====>.........................] - ETA: 1s - loss: 0.0697 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0405 26/122 [=====>........................] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0407 31/122 [======>.......................] - ETA: 0s - loss: 0.0694 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0402 36/122 [=======>......................] - ETA: 0s - loss: 0.0697 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 41/122 [=========>....................] - ETA: 0s - loss: 0.0696 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0402 46/122 [==========>...................] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0407 51/122 [===========>..................] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0406 56/122 [============>.................] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0410 61/122 [==============>...............] - ETA: 0s - loss: 0.0706 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0410 66/122 [===============>..............] - ETA: 0s - loss: 0.0706 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0410 71/122 [================>.............] - ETA: 0s - loss: 0.0707 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0410 76/122 [=================>............] - ETA: 0s - loss: 0.0706 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0409 81/122 [==================>...........] - ETA: 0s - loss: 0.0706 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0409 86/122 [====================>.........] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409 91/122 [=====================>........] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0408 96/122 [======================>.......] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409101/122 [=======================>......] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0408106/122 [=========================>....] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0408111/122 [==========================>...] - ETA: 0s - loss: 0.0707 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0411116/122 [===========================>..] - ETA: 0s - loss: 0.0709 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0412121/122 [============================>.] - ETA: 0s - loss: 0.0709 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0412122/122 [==============================] - 1s 11ms/step - loss: 0.0709 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0412 - val_loss: 0.1026 - val_conv2d_12_loss: 0.0357 - val_conv2d_19_loss: 0.0670 - lr: 1.2500e-04
Epoch 40/50
  1/122 [..............................] - ETA: 1s - loss: 0.0687 - conv2d_12_loss: 0.0281 - conv2d_19_loss: 0.0406  6/122 [>.............................] - ETA: 1s - loss: 0.0697 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 11/122 [=>............................] - ETA: 1s - loss: 0.0703 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0408 16/122 [==>...........................] - ETA: 1s - loss: 0.0696 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0403 21/122 [====>.........................] - ETA: 1s - loss: 0.0694 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0401 26/122 [=====>........................] - ETA: 0s - loss: 0.0697 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 31/122 [======>.......................] - ETA: 0s - loss: 0.0698 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0404 36/122 [=======>......................] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0407 41/122 [=========>....................] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405 46/122 [==========>...................] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405 51/122 [===========>..................] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 56/122 [============>.................] - ETA: 0s - loss: 0.0698 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 61/122 [==============>...............] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405 66/122 [===============>..............] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0408 71/122 [================>.............] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0407 76/122 [=================>............] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0406 81/122 [==================>...........] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0406 86/122 [====================>.........] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0407 91/122 [=====================>........] - ETA: 0s - loss: 0.0703 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0408 96/122 [======================>.......] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0409101/122 [=======================>......] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409106/122 [=========================>....] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0408111/122 [==========================>...] - ETA: 0s - loss: 0.0703 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0408116/122 [===========================>..] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409121/122 [============================>.] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409122/122 [==============================] - 1s 11ms/step - loss: 0.0705 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0409 - val_loss: 0.1024 - val_conv2d_12_loss: 0.0358 - val_conv2d_19_loss: 0.0666 - lr: 1.2500e-04
Epoch 41/50
  1/122 [..............................] - ETA: 1s - loss: 0.0688 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0384  6/122 [>.............................] - ETA: 1s - loss: 0.0706 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0405 11/122 [=>............................] - ETA: 1s - loss: 0.0700 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0402 16/122 [==>...........................] - ETA: 1s - loss: 0.0706 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0407 21/122 [====>.........................] - ETA: 1s - loss: 0.0703 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0406 26/122 [=====>........................] - ETA: 0s - loss: 0.0708 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0410 31/122 [======>.......................] - ETA: 0s - loss: 0.0710 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0412 36/122 [=======>......................] - ETA: 0s - loss: 0.0713 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0413 41/122 [=========>....................] - ETA: 0s - loss: 0.0710 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0411 46/122 [==========>...................] - ETA: 0s - loss: 0.0707 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0409 51/122 [===========>..................] - ETA: 0s - loss: 0.0708 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0410 56/122 [============>.................] - ETA: 0s - loss: 0.0712 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0412 61/122 [==============>...............] - ETA: 0s - loss: 0.0714 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0414 66/122 [===============>..............] - ETA: 0s - loss: 0.0712 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0413 71/122 [================>.............] - ETA: 0s - loss: 0.0709 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0411 76/122 [=================>............] - ETA: 0s - loss: 0.0708 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0410 81/122 [==================>...........] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0408 86/122 [====================>.........] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0407 91/122 [=====================>........] - ETA: 0s - loss: 0.0704 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0407 96/122 [======================>.......] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0406101/122 [=======================>......] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0406106/122 [=========================>....] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405111/122 [==========================>...] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0406116/122 [===========================>..] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405121/122 [============================>.] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405122/122 [==============================] - 1s 11ms/step - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405 - val_loss: 0.1026 - val_conv2d_12_loss: 0.0357 - val_conv2d_19_loss: 0.0668 - lr: 1.2500e-04
Epoch 42/50
  1/122 [..............................] - ETA: 1s - loss: 0.0725 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0428  6/122 [>.............................] - ETA: 1s - loss: 0.0681 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0391 11/122 [=>............................] - ETA: 1s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 16/122 [==>...........................] - ETA: 1s - loss: 0.0710 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0411 21/122 [====>.........................] - ETA: 1s - loss: 0.0704 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0407 26/122 [=====>........................] - ETA: 0s - loss: 0.0707 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0410 31/122 [======>.......................] - ETA: 0s - loss: 0.0709 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0411 36/122 [=======>......................] - ETA: 0s - loss: 0.0705 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0408 41/122 [=========>....................] - ETA: 0s - loss: 0.0702 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0406 46/122 [==========>...................] - ETA: 0s - loss: 0.0701 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0406 51/122 [===========>..................] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 56/122 [============>.................] - ETA: 0s - loss: 0.0696 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0402 61/122 [==============>...............] - ETA: 0s - loss: 0.0697 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0403 66/122 [===============>..............] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405 71/122 [================>.............] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 76/122 [=================>............] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 81/122 [==================>...........] - ETA: 0s - loss: 0.0698 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0403 86/122 [====================>.........] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404 91/122 [=====================>........] - ETA: 0s - loss: 0.0698 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 96/122 [======================>.......] - ETA: 0s - loss: 0.0699 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404101/122 [=======================>......] - ETA: 0s - loss: 0.0700 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0405106/122 [=========================>....] - ETA: 0s - loss: 0.0698 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0404111/122 [==========================>...] - ETA: 0s - loss: 0.0697 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403116/122 [===========================>..] - ETA: 0s - loss: 0.0696 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0402121/122 [============================>.] - ETA: 0s - loss: 0.0695 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0401122/122 [==============================] - 1s 11ms/step - loss: 0.0695 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0401 - val_loss: 0.1021 - val_conv2d_12_loss: 0.0356 - val_conv2d_19_loss: 0.0666 - lr: 1.2500e-04
Epoch 43/50
  1/122 [..............................] - ETA: 1s - loss: 0.0842 - conv2d_12_loss: 0.0325 - conv2d_19_loss: 0.0517  6/122 [>.............................] - ETA: 1s - loss: 0.0708 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0413 11/122 [=>............................] - ETA: 1s - loss: 0.0701 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0407 16/122 [==>...........................] - ETA: 1s - loss: 0.0700 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0406 21/122 [====>.........................] - ETA: 1s - loss: 0.0696 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 26/122 [=====>........................] - ETA: 1s - loss: 0.0697 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0403 31/122 [======>.......................] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0398 36/122 [=======>......................] - ETA: 0s - loss: 0.0686 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0395 41/122 [=========>....................] - ETA: 0s - loss: 0.0687 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0395 46/122 [==========>...................] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 51/122 [===========>..................] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0397 56/122 [============>.................] - ETA: 0s - loss: 0.0689 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0396 61/122 [==============>...............] - ETA: 0s - loss: 0.0689 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0396 66/122 [===============>..............] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0397 71/122 [================>.............] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0397 76/122 [=================>............] - ETA: 0s - loss: 0.0692 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0398 81/122 [==================>...........] - ETA: 0s - loss: 0.0694 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0400 86/122 [====================>.........] - ETA: 0s - loss: 0.0694 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0400 91/122 [=====================>........] - ETA: 0s - loss: 0.0693 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0400 96/122 [======================>.......] - ETA: 0s - loss: 0.0693 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0400101/122 [=======================>......] - ETA: 0s - loss: 0.0694 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0400106/122 [=========================>....] - ETA: 0s - loss: 0.0694 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0400111/122 [==========================>...] - ETA: 0s - loss: 0.0693 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0399116/122 [===========================>..] - ETA: 0s - loss: 0.0692 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0399121/122 [============================>.] - ETA: 0s - loss: 0.0693 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0400122/122 [==============================] - 1s 11ms/step - loss: 0.0692 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0399 - val_loss: 0.1026 - val_conv2d_12_loss: 0.0356 - val_conv2d_19_loss: 0.0671 - lr: 1.2500e-04
Epoch 44/50
  1/122 [..............................] - ETA: 1s - loss: 0.0760 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0449  6/122 [>.............................] - ETA: 1s - loss: 0.0694 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0403 11/122 [=>............................] - ETA: 1s - loss: 0.0710 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0413 16/122 [==>...........................] - ETA: 1s - loss: 0.0707 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0409 21/122 [====>.........................] - ETA: 1s - loss: 0.0704 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0406 26/122 [=====>........................] - ETA: 0s - loss: 0.0692 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0398 31/122 [======>.......................] - ETA: 0s - loss: 0.0689 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397 36/122 [=======>......................] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397 41/122 [=========>....................] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 46/122 [==========>...................] - ETA: 0s - loss: 0.0689 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397 51/122 [===========>..................] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 56/122 [============>.................] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0398 61/122 [==============>...............] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 66/122 [===============>..............] - ETA: 0s - loss: 0.0686 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0395 71/122 [================>.............] - ETA: 0s - loss: 0.0687 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0395 76/122 [=================>............] - ETA: 0s - loss: 0.0687 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0395 81/122 [==================>...........] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 86/122 [====================>.........] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 91/122 [=====================>........] - ETA: 0s - loss: 0.0688 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0396 96/122 [======================>.......] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0397101/122 [=======================>......] - ETA: 0s - loss: 0.0691 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0398106/122 [=========================>....] - ETA: 0s - loss: 0.0692 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0398111/122 [==========================>...] - ETA: 0s - loss: 0.0691 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0398116/122 [===========================>..] - ETA: 0s - loss: 0.0690 - conv2d_12_loss: 0.0293 - conv2d_19_loss: 0.0397121/122 [============================>.] - ETA: 0s - loss: 0.0689 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001.
122/122 [==============================] - 1s 11ms/step - loss: 0.0689 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0397 - val_loss: 0.1026 - val_conv2d_12_loss: 0.0355 - val_conv2d_19_loss: 0.0671 - lr: 1.2500e-04
Epoch 45/50
  1/122 [..............................] - ETA: 1s - loss: 0.0686 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0390  6/122 [>.............................] - ETA: 1s - loss: 0.0667 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0382 11/122 [=>............................] - ETA: 1s - loss: 0.0667 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0382 16/122 [==>...........................] - ETA: 1s - loss: 0.0670 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0384 21/122 [====>.........................] - ETA: 1s - loss: 0.0680 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0391 26/122 [=====>........................] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 31/122 [======>.......................] - ETA: 0s - loss: 0.0686 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0394 36/122 [=======>......................] - ETA: 0s - loss: 0.0684 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0393 41/122 [=========>....................] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0391 46/122 [==========>...................] - ETA: 0s - loss: 0.0680 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0390 51/122 [===========>..................] - ETA: 0s - loss: 0.0682 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0392 56/122 [============>.................] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0391 61/122 [==============>...............] - ETA: 0s - loss: 0.0682 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 66/122 [===============>..............] - ETA: 0s - loss: 0.0684 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0393 71/122 [================>.............] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 76/122 [=================>............] - ETA: 0s - loss: 0.0682 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0391 81/122 [==================>...........] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 86/122 [====================>.........] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 91/122 [=====================>........] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 96/122 [======================>.......] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0393101/122 [=======================>......] - ETA: 0s - loss: 0.0684 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0393106/122 [=========================>....] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392111/122 [==========================>...] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392116/122 [===========================>..] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392121/122 [============================>.] - ETA: 0s - loss: 0.0682 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0391122/122 [==============================] - 1s 11ms/step - loss: 0.0682 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0391 - val_loss: 0.1016 - val_conv2d_12_loss: 0.0354 - val_conv2d_19_loss: 0.0661 - lr: 1.0000e-04
Epoch 46/50
  1/122 [..............................] - ETA: 1s - loss: 0.0603 - conv2d_12_loss: 0.0263 - conv2d_19_loss: 0.0340  6/122 [>.............................] - ETA: 1s - loss: 0.0652 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0372 11/122 [=>............................] - ETA: 1s - loss: 0.0665 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0381 16/122 [==>...........................] - ETA: 1s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0382 21/122 [====>.........................] - ETA: 1s - loss: 0.0676 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0388 26/122 [=====>........................] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0383 31/122 [======>.......................] - ETA: 0s - loss: 0.0670 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0384 36/122 [=======>......................] - ETA: 0s - loss: 0.0672 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0385 41/122 [=========>....................] - ETA: 0s - loss: 0.0674 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0386 46/122 [==========>...................] - ETA: 0s - loss: 0.0676 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0388 51/122 [===========>..................] - ETA: 0s - loss: 0.0678 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0389 56/122 [============>.................] - ETA: 0s - loss: 0.0674 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385 61/122 [==============>...............] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0390 66/122 [===============>..............] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 71/122 [================>.............] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 76/122 [=================>............] - ETA: 0s - loss: 0.0684 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 81/122 [==================>...........] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0392 86/122 [====================>.........] - ETA: 0s - loss: 0.0683 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0391 91/122 [=====================>........] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0390 96/122 [======================>.......] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0390101/122 [=======================>......] - ETA: 0s - loss: 0.0681 - conv2d_12_loss: 0.0291 - conv2d_19_loss: 0.0390106/122 [=========================>....] - ETA: 0s - loss: 0.0679 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0389111/122 [==========================>...] - ETA: 0s - loss: 0.0678 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0388116/122 [===========================>..] - ETA: 0s - loss: 0.0677 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0388121/122 [============================>.] - ETA: 0s - loss: 0.0676 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0387122/122 [==============================] - 1s 11ms/step - loss: 0.0677 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0387 - val_loss: 0.1020 - val_conv2d_12_loss: 0.0354 - val_conv2d_19_loss: 0.0666 - lr: 1.0000e-04
Epoch 47/50
  1/122 [..............................] - ETA: 1s - loss: 0.0613 - conv2d_12_loss: 0.0268 - conv2d_19_loss: 0.0345  6/122 [>.............................] - ETA: 1s - loss: 0.0656 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0372 11/122 [=>............................] - ETA: 1s - loss: 0.0673 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0385 16/122 [==>...........................] - ETA: 1s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0375 21/122 [====>.........................] - ETA: 1s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0375 26/122 [=====>........................] - ETA: 0s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0375 31/122 [======>.......................] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0378 36/122 [=======>......................] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 41/122 [=========>....................] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0382 46/122 [==========>...................] - ETA: 0s - loss: 0.0671 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0383 51/122 [===========>..................] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 56/122 [============>.................] - ETA: 0s - loss: 0.0670 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0383 61/122 [==============>...............] - ETA: 0s - loss: 0.0672 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0384 66/122 [===============>..............] - ETA: 0s - loss: 0.0674 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385 71/122 [================>.............] - ETA: 0s - loss: 0.0670 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0382 76/122 [=================>............] - ETA: 0s - loss: 0.0672 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0384 81/122 [==================>...........] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385 86/122 [====================>.........] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385 91/122 [=====================>........] - ETA: 0s - loss: 0.0672 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0384 96/122 [======================>.......] - ETA: 0s - loss: 0.0672 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0383101/122 [=======================>......] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385106/122 [=========================>....] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0385111/122 [==========================>...] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0384116/122 [===========================>..] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0384121/122 [============================>.] - ETA: 0s - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0384122/122 [==============================] - 1s 11ms/step - loss: 0.0673 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0384 - val_loss: 0.1015 - val_conv2d_12_loss: 0.0353 - val_conv2d_19_loss: 0.0662 - lr: 1.0000e-04
Epoch 48/50
  1/122 [..............................] - ETA: 1s - loss: 0.0630 - conv2d_12_loss: 0.0282 - conv2d_19_loss: 0.0347  6/122 [>.............................] - ETA: 1s - loss: 0.0640 - conv2d_12_loss: 0.0281 - conv2d_19_loss: 0.0359 11/122 [=>............................] - ETA: 1s - loss: 0.0643 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0363 16/122 [==>...........................] - ETA: 1s - loss: 0.0647 - conv2d_12_loss: 0.0281 - conv2d_19_loss: 0.0366 21/122 [====>.........................] - ETA: 1s - loss: 0.0645 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0365 26/122 [=====>........................] - ETA: 0s - loss: 0.0644 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0364 31/122 [======>.......................] - ETA: 0s - loss: 0.0649 - conv2d_12_loss: 0.0282 - conv2d_19_loss: 0.0367 36/122 [=======>......................] - ETA: 0s - loss: 0.0655 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0371 41/122 [=========>....................] - ETA: 0s - loss: 0.0659 - conv2d_12_loss: 0.0284 - conv2d_19_loss: 0.0375 46/122 [==========>...................] - ETA: 0s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0375 51/122 [===========>..................] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 56/122 [============>.................] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 61/122 [==============>...............] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 66/122 [===============>..............] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0376 71/122 [================>.............] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 76/122 [=================>............] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 81/122 [==================>...........] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 86/122 [====================>.........] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0378 91/122 [=====================>........] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 96/122 [======================>.......] - ETA: 0s - loss: 0.0667 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379101/122 [=======================>......] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0380106/122 [=========================>....] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0380111/122 [==========================>...] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0381116/122 [===========================>..] - ETA: 0s - loss: 0.0670 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0382121/122 [============================>.] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381122/122 [==============================] - 1s 11ms/step - loss: 0.0669 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0382 - val_loss: 0.1016 - val_conv2d_12_loss: 0.0354 - val_conv2d_19_loss: 0.0662 - lr: 1.0000e-04
Epoch 49/50
  1/122 [..............................] - ETA: 1s - loss: 0.0619 - conv2d_12_loss: 0.0274 - conv2d_19_loss: 0.0345  6/122 [>.............................] - ETA: 1s - loss: 0.0644 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0364 11/122 [=>............................] - ETA: 1s - loss: 0.0675 - conv2d_12_loss: 0.0289 - conv2d_19_loss: 0.0386 16/122 [==>...........................] - ETA: 1s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 21/122 [====>.........................] - ETA: 1s - loss: 0.0665 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0379 26/122 [=====>........................] - ETA: 0s - loss: 0.0660 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0375 31/122 [======>.......................] - ETA: 0s - loss: 0.0659 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0374 36/122 [=======>......................] - ETA: 0s - loss: 0.0661 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 41/122 [=========>....................] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0378 46/122 [==========>...................] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0380 51/122 [===========>..................] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 56/122 [============>.................] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0378 61/122 [==============>...............] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 66/122 [===============>..............] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 71/122 [================>.............] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 76/122 [=================>............] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 81/122 [==================>...........] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0376 86/122 [====================>.........] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 91/122 [=====================>........] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0377 96/122 [======================>.......] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379101/122 [=======================>......] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0378106/122 [=========================>....] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379111/122 [==========================>...] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379116/122 [===========================>..] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379121/122 [============================>.] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379122/122 [==============================] - 1s 11ms/step - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 - val_loss: 0.1016 - val_conv2d_12_loss: 0.0354 - val_conv2d_19_loss: 0.0662 - lr: 1.0000e-04
Epoch 50/50
  1/122 [..............................] - ETA: 1s - loss: 0.0700 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0403  6/122 [>.............................] - ETA: 1s - loss: 0.0706 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0408 11/122 [=>............................] - ETA: 1s - loss: 0.0695 - conv2d_12_loss: 0.0294 - conv2d_19_loss: 0.0401 16/122 [==>...........................] - ETA: 1s - loss: 0.0674 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0386 21/122 [====>.........................] - ETA: 1s - loss: 0.0665 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0379 26/122 [=====>........................] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0378 31/122 [======>.......................] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0378 36/122 [=======>......................] - ETA: 0s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0375 41/122 [=========>....................] - ETA: 0s - loss: 0.0660 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0376 46/122 [==========>...................] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0379 51/122 [===========>..................] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0380 56/122 [============>.................] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 61/122 [==============>...............] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 66/122 [===============>..............] - ETA: 0s - loss: 0.0669 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 71/122 [================>.............] - ETA: 0s - loss: 0.0668 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0381 76/122 [=================>............] - ETA: 0s - loss: 0.0667 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0380 81/122 [==================>...........] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0378 86/122 [====================>.........] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 91/122 [=====================>........] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379 96/122 [======================>.......] - ETA: 0s - loss: 0.0666 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0379101/122 [=======================>......] - ETA: 0s - loss: 0.0665 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0378106/122 [=========================>....] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0287 - conv2d_19_loss: 0.0377111/122 [==========================>...] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0378116/122 [===========================>..] - ETA: 0s - loss: 0.0664 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377121/122 [============================>.] - ETA: 0s - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377122/122 [==============================] - 1s 11ms/step - loss: 0.0663 - conv2d_12_loss: 0.0286 - conv2d_19_loss: 0.0377 - val_loss: 0.1014 - val_conv2d_12_loss: 0.0353 - val_conv2d_19_loss: 0.0661 - lr: 1.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:16:47,692 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1/baseline_model.h5
2025-07-27 21:16:47,692 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:41 12/322 [>.............................] - ETA: 1s   22/322 [=>............................] - ETA: 1s 32/322 [=>............................] - ETA: 1s 42/322 [==>...........................] - ETA: 1s 52/322 [===>..........................] - ETA: 1s 62/322 [====>.........................] - ETA: 1s 72/322 [=====>........................] - ETA: 1s 82/322 [======>.......................] - ETA: 1s 92/322 [=======>......................] - ETA: 1s102/322 [========>.....................] - ETA: 1s112/322 [=========>....................] - ETA: 1s122/322 [==========>...................] - ETA: 1s132/322 [===========>..................] - ETA: 0s142/322 [============>.................] - ETA: 0s152/322 [=============>................] - ETA: 0s162/322 [==============>...............] - ETA: 0s172/322 [===============>..............] - ETA: 0s182/322 [===============>..............] - ETA: 0s192/322 [================>.............] - ETA: 0s202/322 [=================>............] - ETA: 0s212/322 [==================>...........] - ETA: 0s222/322 [===================>..........] - ETA: 0s232/322 [====================>.........] - ETA: 0s242/322 [=====================>........] - ETA: 0s252/322 [======================>.......] - ETA: 0s262/322 [=======================>......] - ETA: 0s272/322 [========================>.....] - ETA: 0s282/322 [=========================>....] - ETA: 0s292/322 [==========================>...] - ETA: 0s302/322 [===========================>..] - ETA: 0s312/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:16:51,144 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:16:51,144 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:16:51,144 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:16:51,145 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:16:51,145 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:16:51,145 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:16:51,145 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:16:51,145 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:16:51,145 - INFO - --- Alignment complete ---
2025-07-27 21:16:51,145 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:16:51,236 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:16:51,236 - INFO -   MAE:  (0.037122224, 0.09245035897564172)
2025-07-27 21:16:51,236 - INFO -   PSNR: (74.39982489540381, 66.15501191677282)
2025-07-27 21:16:51,350 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:16:51,350 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.005393
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.226004, std=0.085327, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.256054, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.005393
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.226004, std=0.085327, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.256054, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:16:52] SUCCESS: Baseline training (n_images=2048, trial=1)
[2025-07-27 21:16:52] EXECUTING: Tike reconstruction (n_images=4096, trial=1)
[2025-07-27 21:16:52] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_2048/trial_1/tike_run' \
                --n-images 4096 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:20:18] SUCCESS: Tike reconstruction (n_images=4096, trial=1)
[2025-07-27 21:20:18] Completed training for train_size=2048 (Trial 1/3)
[2025-07-27 21:20:18] Training models for train_size=2048, test_size=4096 (Trial 2/3)
[2025-07-27 21:20:18] EXECUTING: PtychoPINN training (n_images=2048, trial=2)
[2025-07-27 21:20:18] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run' \
            --nepochs 50
2025-07-27 21:20:18.605951: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:20:18.605980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:20:18.606823: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:20:18.610982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:20:19.084562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:20:20.135055: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.168863: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.171239: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:20:20.332036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.334291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.336327: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.452744: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.453968: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.455097: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:20:20.455240: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:20:20.456383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:20:20,484 - INFO - Configuration setup complete
2025-07-27 21:20:20,484 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run'))
2025-07-27 21:20:20,484 - INFO - Parameter interpretation: --n-images=2048 refers to individual images (gridsize=1)
2025-07-27 21:20:20,485 - INFO - Starting training with n_images=2048, stitching=disabled
2025-07-27 21:20:20,485 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:20:20,518 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
2025-07-27 21:20:20,518 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:20:20,591 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:20:20,592 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:20:41,636 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:20:41.753056: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:20:41.753071: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:20:41.753094: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:20:41.769840: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:20:41.769917: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:20:41,771 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:20:42,447 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:20:42,454 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:20:43,437 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:20:43,443 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:20:44.108145: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:20:44.133811: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x26a8ad10
2025-07-27 21:20:45.302931: I external/local_xla/xla/service/service.cc:168] XLA service 0x747f433fb3c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:20:45.302961: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:20:45.306133: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676445.372733 3724022 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 13:09 - loss: 788394112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 168.4077 - distribution_lambda_loss: 788394112.0000  6/122 [>.............................] - ETA: 1s - loss: 7381248000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 598.8224 - distribution_lambda_loss: 7381248000.0000  11/122 [=>............................] - ETA: 1s - loss: 4503805440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 455.1798 - distribution_lambda_loss: 4503805440.0000 16/122 [==>...........................] - ETA: 1s - loss: 3266248448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 380.0137 - distribution_lambda_loss: 3266248448.0000 21/122 [====>.........................] - ETA: 1s - loss: 2594357760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 334.7530 - distribution_lambda_loss: 2594357760.0000 26/122 [=====>........................] - ETA: 0s - loss: 2168270336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 299.5237 - distribution_lambda_loss: 2168270336.0000 31/122 [======>.......................] - ETA: 0s - loss: 1884218368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 278.6815 - distribution_lambda_loss: 1884218368.0000 36/122 [=======>......................] - ETA: 0s - loss: 1674696192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 261.9566 - distribution_lambda_loss: 1674696192.0000 41/122 [=========>....................] - ETA: 0s - loss: 1517608320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 249.2202 - distribution_lambda_loss: 1517608320.0000 46/122 [==========>...................] - ETA: 0s - loss: 1391353984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 238.8336 - distribution_lambda_loss: 1391353984.0000 51/122 [===========>..................] - ETA: 0s - loss: 1294257664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 231.3978 - distribution_lambda_loss: 1294257664.0000 56/122 [============>.................] - ETA: 0s - loss: 1211210624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 224.3599 - distribution_lambda_loss: 1211210624.0000 61/122 [==============>...............] - ETA: 0s - loss: 1141107584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 218.5996 - distribution_lambda_loss: 1141107584.0000 66/122 [===============>..............] - ETA: 0s - loss: 1083176832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 213.8538 - distribution_lambda_loss: 1083176832.0000 71/122 [================>.............] - ETA: 0s - loss: 1033276800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 209.7662 - distribution_lambda_loss: 1033276800.0000 76/122 [=================>............] - ETA: 0s - loss: 990460032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 206.3278 - distribution_lambda_loss: 990460032.0000   81/122 [==================>...........] - ETA: 0s - loss: 950452608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 203.0463 - distribution_lambda_loss: 950452608.0000 86/122 [====================>.........] - ETA: 0s - loss: 915100416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 199.9345 - distribution_lambda_loss: 915100416.0000 91/122 [=====================>........] - ETA: 0s - loss: 882836608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 197.0427 - distribution_lambda_loss: 882836608.0000 96/122 [======================>.......] - ETA: 0s - loss: 854686144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 194.4487 - distribution_lambda_loss: 854686144.0000101/122 [=======================>......] - ETA: 0s - loss: 829030656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 192.0406 - distribution_lambda_loss: 829030656.0000106/122 [=========================>....] - ETA: 0s - loss: 806030528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 189.7410 - distribution_lambda_loss: 806030528.0000111/122 [==========================>...] - ETA: 0s - loss: 783945792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 187.5957 - distribution_lambda_loss: 783945792.0000116/122 [===========================>..] - ETA: 0s - loss: 763606592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 185.4465 - distribution_lambda_loss: 763606592.0000121/122 [============================>.] - ETA: 0s - loss: 745313664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 183.6034 - distribution_lambda_loss: 745313664.0000122/122 [==============================] - ETA: 0s - loss: 743330048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 183.4106 - distribution_lambda_loss: 743330048.0000input shape (None, 64, 64, 1)
122/122 [==============================] - 10s 27ms/step - loss: 743330048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 183.4106 - distribution_lambda_loss: 743330048.0000 - val_loss: 291749120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 131.8966 - val_distribution_lambda_loss: 291749120.0000 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 259908192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.2817 - distribution_lambda_loss: 259908192.0000  6/122 [>.............................] - ETA: 1s - loss: 287920096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 133.6464 - distribution_lambda_loss: 287920096.0000 11/122 [=>............................] - ETA: 1s - loss: 281759008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 131.8292 - distribution_lambda_loss: 281759008.0000 16/122 [==>...........................] - ETA: 1s - loss: 285695744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 132.6144 - distribution_lambda_loss: 285695744.0000 21/122 [====>.........................] - ETA: 1s - loss: 276899776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 130.8291 - distribution_lambda_loss: 276899776.0000 26/122 [=====>........................] - ETA: 0s - loss: 276390432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 130.6157 - distribution_lambda_loss: 276390432.0000 31/122 [======>.......................] - ETA: 0s - loss: 275823648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 130.6575 - distribution_lambda_loss: 275823648.0000 36/122 [=======>......................] - ETA: 0s - loss: 275551520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 131.2773 - distribution_lambda_loss: 275551520.0000 41/122 [=========>....................] - ETA: 0s - loss: 271908704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 130.3960 - distribution_lambda_loss: 271908704.0000 46/122 [==========>...................] - ETA: 0s - loss: 269982752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 129.8547 - distribution_lambda_loss: 269982752.0000 51/122 [===========>..................] - ETA: 0s - loss: 267936896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 129.4300 - distribution_lambda_loss: 267936896.0000 56/122 [============>.................] - ETA: 0s - loss: 263267920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 128.3661 - distribution_lambda_loss: 263267920.0000 61/122 [==============>...............] - ETA: 0s - loss: 260970224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 127.9023 - distribution_lambda_loss: 260970224.0000 66/122 [===============>..............] - ETA: 0s - loss: 256838096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 126.9140 - distribution_lambda_loss: 256838096.0000 71/122 [================>.............] - ETA: 0s - loss: 254002768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 126.2838 - distribution_lambda_loss: 254002768.0000 76/122 [=================>............] - ETA: 0s - loss: 251569904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 125.7692 - distribution_lambda_loss: 251569904.0000 81/122 [==================>...........] - ETA: 0s - loss: 249598080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 125.3266 - distribution_lambda_loss: 249598080.0000 86/122 [====================>.........] - ETA: 0s - loss: 247576832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.8652 - distribution_lambda_loss: 247576832.0000 91/122 [=====================>........] - ETA: 0s - loss: 245686208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.4824 - distribution_lambda_loss: 245686208.0000 96/122 [======================>.......] - ETA: 0s - loss: 243842480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.1483 - distribution_lambda_loss: 243842480.0000101/122 [=======================>......] - ETA: 0s - loss: 243095456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 124.0007 - distribution_lambda_loss: 243095456.0000106/122 [=========================>....] - ETA: 0s - loss: 241508432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 123.6277 - distribution_lambda_loss: 241508432.0000111/122 [==========================>...] - ETA: 0s - loss: 240363648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 123.4135 - distribution_lambda_loss: 240363648.0000116/122 [===========================>..] - ETA: 0s - loss: 239327088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 123.2127 - distribution_lambda_loss: 239327088.0000121/122 [============================>.] - ETA: 0s - loss: 238051568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 122.9224 - distribution_lambda_loss: 238051568.0000122/122 [==============================] - 1s 11ms/step - loss: 237954464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 122.8917 - distribution_lambda_loss: 237954464.0000 - val_loss: 206577264.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 116.0878 - val_distribution_lambda_loss: 206577264.0000 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 192498064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 111.6181 - distribution_lambda_loss: 192498064.0000  6/122 [>.............................] - ETA: 1s - loss: 206267184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 116.2992 - distribution_lambda_loss: 206267184.0000 11/122 [=>............................] - ETA: 1s - loss: 200547344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 114.7928 - distribution_lambda_loss: 200547344.0000 16/122 [==>...........................] - ETA: 1s - loss: 197882432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 114.0557 - distribution_lambda_loss: 197882432.0000 21/122 [====>.........................] - ETA: 1s - loss: 197524400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.9849 - distribution_lambda_loss: 197524400.0000 26/122 [=====>........................] - ETA: 0s - loss: 196500448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.8059 - distribution_lambda_loss: 196500448.0000 31/122 [======>.......................] - ETA: 0s - loss: 195753872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5975 - distribution_lambda_loss: 195753872.0000 36/122 [=======>......................] - ETA: 0s - loss: 196362096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5778 - distribution_lambda_loss: 196362096.0000 41/122 [=========>....................] - ETA: 0s - loss: 196105424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5733 - distribution_lambda_loss: 196105424.0000 46/122 [==========>...................] - ETA: 0s - loss: 195581648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.5088 - distribution_lambda_loss: 195581648.0000 51/122 [===========>..................] - ETA: 0s - loss: 195283344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.4671 - distribution_lambda_loss: 195283344.0000 56/122 [============>.................] - ETA: 0s - loss: 194262752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.3386 - distribution_lambda_loss: 194262752.0000 61/122 [==============>...............] - ETA: 0s - loss: 193955568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.2787 - distribution_lambda_loss: 193955568.0000 66/122 [===============>..............] - ETA: 0s - loss: 194007808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.2850 - distribution_lambda_loss: 194007808.0000 71/122 [================>.............] - ETA: 0s - loss: 194240976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.4062 - distribution_lambda_loss: 194240976.0000 76/122 [=================>............] - ETA: 0s - loss: 194078672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.4577 - distribution_lambda_loss: 194078672.0000 81/122 [==================>...........] - ETA: 0s - loss: 193822480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.3849 - distribution_lambda_loss: 193822480.0000 86/122 [====================>.........] - ETA: 0s - loss: 193576096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.2993 - distribution_lambda_loss: 193576096.0000 91/122 [=====================>........] - ETA: 0s - loss: 192771088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.0392 - distribution_lambda_loss: 192771088.0000 96/122 [======================>.......] - ETA: 0s - loss: 192481792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.9521 - distribution_lambda_loss: 192481792.0000101/122 [=======================>......] - ETA: 0s - loss: 192952976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.1141 - distribution_lambda_loss: 192952976.0000106/122 [=========================>....] - ETA: 0s - loss: 192963504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.1577 - distribution_lambda_loss: 192963504.0000111/122 [==========================>...] - ETA: 0s - loss: 192550288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.0862 - distribution_lambda_loss: 192550288.0000116/122 [===========================>..] - ETA: 0s - loss: 192112992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 113.0075 - distribution_lambda_loss: 192112992.0000121/122 [============================>.] - ETA: 0s - loss: 191901168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.9387 - distribution_lambda_loss: 191901168.0000122/122 [==============================] - 1s 11ms/step - loss: 191846672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.9315 - distribution_lambda_loss: 191846672.0000 - val_loss: 188260672.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 113.2586 - val_distribution_lambda_loss: 188260672.0000 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 171980208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6429 - distribution_lambda_loss: 171980208.0000  6/122 [>.............................] - ETA: 1s - loss: 178029232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.2657 - distribution_lambda_loss: 178029232.0000 11/122 [=>............................] - ETA: 1s - loss: 174330640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.3566 - distribution_lambda_loss: 174330640.0000 16/122 [==>...........................] - ETA: 1s - loss: 178490768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.2078 - distribution_lambda_loss: 178490768.0000 21/122 [====>.........................] - ETA: 1s - loss: 181624800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.3138 - distribution_lambda_loss: 181624800.0000 26/122 [=====>........................] - ETA: 0s - loss: 180670016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.2081 - distribution_lambda_loss: 180670016.0000 31/122 [======>.......................] - ETA: 0s - loss: 178287616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.6551 - distribution_lambda_loss: 178287616.0000 36/122 [=======>......................] - ETA: 0s - loss: 180415680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.2801 - distribution_lambda_loss: 180415680.0000 41/122 [=========>....................] - ETA: 0s - loss: 181181936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.4464 - distribution_lambda_loss: 181181936.0000 46/122 [==========>...................] - ETA: 0s - loss: 180696368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.3374 - distribution_lambda_loss: 180696368.0000 51/122 [===========>..................] - ETA: 0s - loss: 181808544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5697 - distribution_lambda_loss: 181808544.0000 56/122 [============>.................] - ETA: 0s - loss: 182385552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.8017 - distribution_lambda_loss: 182385552.0000 61/122 [==============>...............] - ETA: 0s - loss: 182340032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.8403 - distribution_lambda_loss: 182340032.0000 66/122 [===============>..............] - ETA: 0s - loss: 182540256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.9056 - distribution_lambda_loss: 182540256.0000 71/122 [================>.............] - ETA: 0s - loss: 181229344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5228 - distribution_lambda_loss: 181229344.0000 76/122 [=================>............] - ETA: 0s - loss: 181378672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5737 - distribution_lambda_loss: 181378672.0000 81/122 [==================>...........] - ETA: 0s - loss: 181495856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.6884 - distribution_lambda_loss: 181495856.0000 86/122 [====================>.........] - ETA: 0s - loss: 181288144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5630 - distribution_lambda_loss: 181288144.0000 91/122 [=====================>........] - ETA: 0s - loss: 181987120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.8195 - distribution_lambda_loss: 181987120.0000 96/122 [======================>.......] - ETA: 0s - loss: 181949808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.7832 - distribution_lambda_loss: 181949808.0000101/122 [=======================>......] - ETA: 0s - loss: 182098816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.8714 - distribution_lambda_loss: 182098816.0000106/122 [=========================>....] - ETA: 0s - loss: 181843024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.8304 - distribution_lambda_loss: 181843024.0000111/122 [==========================>...] - ETA: 0s - loss: 181351216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.7457 - distribution_lambda_loss: 181351216.0000116/122 [===========================>..] - ETA: 0s - loss: 180778208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.5560 - distribution_lambda_loss: 180778208.0000121/122 [============================>.] - ETA: 0s - loss: 180217664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.4073 - distribution_lambda_loss: 180217664.0000122/122 [==============================] - 1s 11ms/step - loss: 180233824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 110.4152 - distribution_lambda_loss: 180233824.0000 - val_loss: 179359392.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 111.2672 - val_distribution_lambda_loss: 179359392.0000 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 163938016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3898 - distribution_lambda_loss: 163938016.0000  6/122 [>.............................] - ETA: 1s - loss: 164316128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7475 - distribution_lambda_loss: 164316128.0000 11/122 [=>............................] - ETA: 1s - loss: 169945184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.3761 - distribution_lambda_loss: 169945184.0000 16/122 [==>...........................] - ETA: 1s - loss: 170260912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.8411 - distribution_lambda_loss: 170260912.0000 21/122 [====>.........................] - ETA: 1s - loss: 169369888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6046 - distribution_lambda_loss: 169369888.0000 26/122 [=====>........................] - ETA: 0s - loss: 171110080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.2412 - distribution_lambda_loss: 171110080.0000 31/122 [======>.......................] - ETA: 0s - loss: 171442928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.4406 - distribution_lambda_loss: 171442928.0000 36/122 [=======>......................] - ETA: 0s - loss: 171599472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.4522 - distribution_lambda_loss: 171599472.0000 41/122 [=========>....................] - ETA: 0s - loss: 173055744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.7285 - distribution_lambda_loss: 173055744.0000 46/122 [==========>...................] - ETA: 0s - loss: 173208496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.8984 - distribution_lambda_loss: 173208496.0000 51/122 [===========>..................] - ETA: 0s - loss: 174260928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.1949 - distribution_lambda_loss: 174260928.0000 56/122 [============>.................] - ETA: 0s - loss: 174504560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.2340 - distribution_lambda_loss: 174504560.0000 61/122 [==============>...............] - ETA: 0s - loss: 174566320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.2652 - distribution_lambda_loss: 174566320.0000 66/122 [===============>..............] - ETA: 0s - loss: 175557936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.5459 - distribution_lambda_loss: 175557936.0000 71/122 [================>.............] - ETA: 0s - loss: 176462976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.8096 - distribution_lambda_loss: 176462976.0000 76/122 [=================>............] - ETA: 0s - loss: 176871840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.9261 - distribution_lambda_loss: 176871840.0000 81/122 [==================>...........] - ETA: 0s - loss: 176868944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.8773 - distribution_lambda_loss: 176868944.0000 86/122 [====================>.........] - ETA: 0s - loss: 176290672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.7315 - distribution_lambda_loss: 176290672.0000 91/122 [=====================>........] - ETA: 0s - loss: 175554768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.4925 - distribution_lambda_loss: 175554768.0000 96/122 [======================>.......] - ETA: 0s - loss: 174571056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.1632 - distribution_lambda_loss: 174571056.0000101/122 [=======================>......] - ETA: 0s - loss: 174211456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.0677 - distribution_lambda_loss: 174211456.0000106/122 [=========================>....] - ETA: 0s - loss: 173783984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.9579 - distribution_lambda_loss: 173783984.0000111/122 [==========================>...] - ETA: 0s - loss: 173917216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.9939 - distribution_lambda_loss: 173917216.0000116/122 [===========================>..] - ETA: 0s - loss: 173874032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.9420 - distribution_lambda_loss: 173874032.0000121/122 [============================>.] - ETA: 0s - loss: 173489760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.8607 - distribution_lambda_loss: 173489760.0000122/122 [==============================] - 1s 11ms/step - loss: 173667920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.9075 - distribution_lambda_loss: 173667920.0000 - val_loss: 174226640.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 109.3331 - val_distribution_lambda_loss: 174226640.0000 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 176673200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 109.6384 - distribution_lambda_loss: 176673200.0000  6/122 [>.............................] - ETA: 1s - loss: 166991088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6016 - distribution_lambda_loss: 166991088.0000 11/122 [=>............................] - ETA: 1s - loss: 167818208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6361 - distribution_lambda_loss: 167818208.0000 16/122 [==>...........................] - ETA: 1s - loss: 169102064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9749 - distribution_lambda_loss: 169102064.0000 21/122 [====>.........................] - ETA: 1s - loss: 167686384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.4930 - distribution_lambda_loss: 167686384.0000 26/122 [=====>........................] - ETA: 0s - loss: 166622352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.2909 - distribution_lambda_loss: 166622352.0000 31/122 [======>.......................] - ETA: 0s - loss: 168946896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9550 - distribution_lambda_loss: 168946896.0000 36/122 [=======>......................] - ETA: 0s - loss: 169261744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9788 - distribution_lambda_loss: 169261744.0000 41/122 [=========>....................] - ETA: 0s - loss: 168298304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6342 - distribution_lambda_loss: 168298304.0000 46/122 [==========>...................] - ETA: 0s - loss: 167438000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.4312 - distribution_lambda_loss: 167438000.0000 51/122 [===========>..................] - ETA: 0s - loss: 167779728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.5631 - distribution_lambda_loss: 167779728.0000 56/122 [============>.................] - ETA: 0s - loss: 168985760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.8564 - distribution_lambda_loss: 168985760.0000 61/122 [==============>...............] - ETA: 0s - loss: 169459696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9318 - distribution_lambda_loss: 169459696.0000 66/122 [===============>..............] - ETA: 0s - loss: 170645840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.3427 - distribution_lambda_loss: 170645840.0000 71/122 [================>.............] - ETA: 0s - loss: 170642000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.3276 - distribution_lambda_loss: 170642000.0000 76/122 [=================>............] - ETA: 0s - loss: 170005040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.1343 - distribution_lambda_loss: 170005040.0000 81/122 [==================>...........] - ETA: 0s - loss: 168720480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7186 - distribution_lambda_loss: 168720480.0000 86/122 [====================>.........] - ETA: 0s - loss: 168820960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7056 - distribution_lambda_loss: 168820960.0000 91/122 [=====================>........] - ETA: 0s - loss: 169215984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7897 - distribution_lambda_loss: 169215984.0000 96/122 [======================>.......] - ETA: 0s - loss: 168938976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.6985 - distribution_lambda_loss: 168938976.0000101/122 [=======================>......] - ETA: 0s - loss: 169127776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7598 - distribution_lambda_loss: 169127776.0000106/122 [=========================>....] - ETA: 0s - loss: 169389152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.8667 - distribution_lambda_loss: 169389152.0000111/122 [==========================>...] - ETA: 0s - loss: 169122720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.8032 - distribution_lambda_loss: 169122720.0000116/122 [===========================>..] - ETA: 0s - loss: 169455120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9102 - distribution_lambda_loss: 169455120.0000121/122 [============================>.] - ETA: 0s - loss: 168982432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7923 - distribution_lambda_loss: 168982432.0000122/122 [==============================] - 1s 11ms/step - loss: 168862944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.7607 - distribution_lambda_loss: 168862944.0000 - val_loss: 169709952.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 109.3937 - val_distribution_lambda_loss: 169709952.0000 - lr: 0.0010
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 157962336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.1177 - distribution_lambda_loss: 157962336.0000  6/122 [>.............................] - ETA: 1s - loss: 160847824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.2592 - distribution_lambda_loss: 160847824.0000 11/122 [=>............................] - ETA: 1s - loss: 162974416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3219 - distribution_lambda_loss: 162974416.0000 16/122 [==>...........................] - ETA: 1s - loss: 161619728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8967 - distribution_lambda_loss: 161619728.0000 21/122 [====>.........................] - ETA: 1s - loss: 163320464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3077 - distribution_lambda_loss: 163320464.0000 26/122 [=====>........................] - ETA: 0s - loss: 162971072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.2136 - distribution_lambda_loss: 162971072.0000 31/122 [======>.......................] - ETA: 0s - loss: 163132656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3009 - distribution_lambda_loss: 163132656.0000 36/122 [=======>......................] - ETA: 0s - loss: 164705552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.8319 - distribution_lambda_loss: 164705552.0000 41/122 [=========>....................] - ETA: 0s - loss: 164889264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9589 - distribution_lambda_loss: 164889264.0000 46/122 [==========>...................] - ETA: 0s - loss: 164864816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9012 - distribution_lambda_loss: 164864816.0000 51/122 [===========>..................] - ETA: 0s - loss: 164676784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7690 - distribution_lambda_loss: 164676784.0000 56/122 [============>.................] - ETA: 0s - loss: 164524032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.6189 - distribution_lambda_loss: 164524032.0000 61/122 [==============>...............] - ETA: 0s - loss: 165304704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.8328 - distribution_lambda_loss: 165304704.0000 66/122 [===============>..............] - ETA: 0s - loss: 164595472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.6086 - distribution_lambda_loss: 164595472.0000 71/122 [================>.............] - ETA: 0s - loss: 163959328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4015 - distribution_lambda_loss: 163959328.0000 76/122 [=================>............] - ETA: 0s - loss: 163523456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.2933 - distribution_lambda_loss: 163523456.0000 81/122 [==================>...........] - ETA: 0s - loss: 163708640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3192 - distribution_lambda_loss: 163708640.0000 86/122 [====================>.........] - ETA: 0s - loss: 164847216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7002 - distribution_lambda_loss: 164847216.0000 91/122 [=====================>........] - ETA: 0s - loss: 164705568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.6249 - distribution_lambda_loss: 164705568.0000 96/122 [======================>.......] - ETA: 0s - loss: 165191552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7990 - distribution_lambda_loss: 165191552.0000101/122 [=======================>......] - ETA: 0s - loss: 165151712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.8452 - distribution_lambda_loss: 165151712.0000106/122 [=========================>....] - ETA: 0s - loss: 165385136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9051 - distribution_lambda_loss: 165385136.0000111/122 [==========================>...] - ETA: 0s - loss: 165384112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9212 - distribution_lambda_loss: 165384112.0000116/122 [===========================>..] - ETA: 0s - loss: 165656304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.0259 - distribution_lambda_loss: 165656304.0000121/122 [============================>.] - ETA: 0s - loss: 165536672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.0033 - distribution_lambda_loss: 165536672.0000122/122 [==============================] - 1s 11ms/step - loss: 165477904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.9728 - distribution_lambda_loss: 165477904.0000 - val_loss: 166397552.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.8074 - val_distribution_lambda_loss: 166397552.0000 - lr: 0.0010
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 166826784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.1935 - distribution_lambda_loss: 166826784.0000  6/122 [>.............................] - ETA: 1s - loss: 161620240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1608 - distribution_lambda_loss: 161620240.0000 11/122 [=>............................] - ETA: 1s - loss: 170238608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 108.8629 - distribution_lambda_loss: 170238608.0000 16/122 [==>...........................] - ETA: 1s - loss: 168316784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9171 - distribution_lambda_loss: 168316784.0000 21/122 [====>.........................] - ETA: 1s - loss: 165133728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7266 - distribution_lambda_loss: 165133728.0000 26/122 [=====>........................] - ETA: 0s - loss: 164693216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.6873 - distribution_lambda_loss: 164693216.0000 31/122 [======>.......................] - ETA: 0s - loss: 165346000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.0036 - distribution_lambda_loss: 165346000.0000 36/122 [=======>......................] - ETA: 0s - loss: 164527856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.8583 - distribution_lambda_loss: 164527856.0000 41/122 [=========>....................] - ETA: 0s - loss: 163551520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4559 - distribution_lambda_loss: 163551520.0000 46/122 [==========>...................] - ETA: 0s - loss: 162806624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.3317 - distribution_lambda_loss: 162806624.0000 51/122 [===========>..................] - ETA: 0s - loss: 161861600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9751 - distribution_lambda_loss: 161861600.0000 56/122 [============>.................] - ETA: 0s - loss: 161398544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7936 - distribution_lambda_loss: 161398544.0000 61/122 [==============>...............] - ETA: 0s - loss: 160131952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4107 - distribution_lambda_loss: 160131952.0000 66/122 [===============>..............] - ETA: 0s - loss: 160376096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5311 - distribution_lambda_loss: 160376096.0000 71/122 [================>.............] - ETA: 0s - loss: 160803840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6581 - distribution_lambda_loss: 160803840.0000 76/122 [=================>............] - ETA: 0s - loss: 160491648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5335 - distribution_lambda_loss: 160491648.0000 81/122 [==================>...........] - ETA: 0s - loss: 160081984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4311 - distribution_lambda_loss: 160081984.0000 86/122 [====================>.........] - ETA: 0s - loss: 160356736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4882 - distribution_lambda_loss: 160356736.0000 91/122 [=====================>........] - ETA: 0s - loss: 160158768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4351 - distribution_lambda_loss: 160158768.0000 96/122 [======================>.......] - ETA: 0s - loss: 160455696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5458 - distribution_lambda_loss: 160455696.0000101/122 [=======================>......] - ETA: 0s - loss: 160418512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5673 - distribution_lambda_loss: 160418512.0000106/122 [=========================>....] - ETA: 0s - loss: 160654624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6494 - distribution_lambda_loss: 160654624.0000111/122 [==========================>...] - ETA: 0s - loss: 160675312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6458 - distribution_lambda_loss: 160675312.0000116/122 [===========================>..] - ETA: 0s - loss: 160586240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6407 - distribution_lambda_loss: 160586240.0000121/122 [============================>.] - ETA: 0s - loss: 160554528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6738 - distribution_lambda_loss: 160554528.0000122/122 [==============================] - 1s 11ms/step - loss: 160702128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7139 - distribution_lambda_loss: 160702128.0000 - val_loss: 165652048.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.9086 - val_distribution_lambda_loss: 165652048.0000 - lr: 0.0010
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 183765696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 112.7148 - distribution_lambda_loss: 183765696.0000  6/122 [>.............................] - ETA: 1s - loss: 164946992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 107.9498 - distribution_lambda_loss: 164946992.0000 11/122 [=>............................] - ETA: 1s - loss: 162453696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7584 - distribution_lambda_loss: 162453696.0000 16/122 [==>...........................] - ETA: 1s - loss: 160823600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0938 - distribution_lambda_loss: 160823600.0000 21/122 [====>.........................] - ETA: 1s - loss: 159616592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7540 - distribution_lambda_loss: 159616592.0000 26/122 [=====>........................] - ETA: 1s - loss: 158933312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.3818 - distribution_lambda_loss: 158933312.0000 31/122 [======>.......................] - ETA: 0s - loss: 158959920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4918 - distribution_lambda_loss: 158959920.0000 36/122 [=======>......................] - ETA: 0s - loss: 160498864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0215 - distribution_lambda_loss: 160498864.0000 41/122 [=========>....................] - ETA: 0s - loss: 159309536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5208 - distribution_lambda_loss: 159309536.0000 46/122 [==========>...................] - ETA: 0s - loss: 159475504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.5961 - distribution_lambda_loss: 159475504.0000 51/122 [===========>..................] - ETA: 0s - loss: 159316576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4552 - distribution_lambda_loss: 159316576.0000 56/122 [============>.................] - ETA: 0s - loss: 159200352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4694 - distribution_lambda_loss: 159200352.0000 61/122 [==============>...............] - ETA: 0s - loss: 159254992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4671 - distribution_lambda_loss: 159254992.0000 66/122 [===============>..............] - ETA: 0s - loss: 160840000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8678 - distribution_lambda_loss: 160840000.0000 71/122 [================>.............] - ETA: 0s - loss: 161668080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1492 - distribution_lambda_loss: 161668080.0000 76/122 [=================>............] - ETA: 0s - loss: 161946016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1411 - distribution_lambda_loss: 161946016.0000 81/122 [==================>...........] - ETA: 0s - loss: 161648864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.0934 - distribution_lambda_loss: 161648864.0000 86/122 [====================>.........] - ETA: 0s - loss: 162141184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.2329 - distribution_lambda_loss: 162141184.0000 91/122 [=====================>........] - ETA: 0s - loss: 162144976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.2482 - distribution_lambda_loss: 162144976.0000 96/122 [======================>.......] - ETA: 0s - loss: 162121904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.2290 - distribution_lambda_loss: 162121904.0000101/122 [=======================>......] - ETA: 0s - loss: 161836784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1152 - distribution_lambda_loss: 161836784.0000106/122 [=========================>....] - ETA: 0s - loss: 161080576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8896 - distribution_lambda_loss: 161080576.0000111/122 [==========================>...] - ETA: 0s - loss: 161071328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8937 - distribution_lambda_loss: 161071328.0000116/122 [===========================>..] - ETA: 0s - loss: 161259296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9719 - distribution_lambda_loss: 161259296.0000121/122 [============================>.] - ETA: 0s - loss: 161116480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9530 - distribution_lambda_loss: 161116480.0000122/122 [==============================] - 1s 11ms/step - loss: 161055376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.9430 - distribution_lambda_loss: 161055376.0000 - val_loss: 164054608.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.4592 - val_distribution_lambda_loss: 164054608.0000 - lr: 0.0010
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 157502880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6868 - distribution_lambda_loss: 157502880.0000  6/122 [>.............................] - ETA: 1s - loss: 155020032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2304 - distribution_lambda_loss: 155020032.0000 11/122 [=>............................] - ETA: 1s - loss: 156846656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7345 - distribution_lambda_loss: 156846656.0000 16/122 [==>...........................] - ETA: 1s - loss: 157575104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9644 - distribution_lambda_loss: 157575104.0000 21/122 [====>.........................] - ETA: 1s - loss: 155004032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9679 - distribution_lambda_loss: 155004032.0000 26/122 [=====>........................] - ETA: 1s - loss: 154635072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9110 - distribution_lambda_loss: 154635072.0000 31/122 [======>.......................] - ETA: 0s - loss: 154058016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7668 - distribution_lambda_loss: 154058016.0000 36/122 [=======>......................] - ETA: 0s - loss: 153658800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5864 - distribution_lambda_loss: 153658800.0000 41/122 [=========>....................] - ETA: 0s - loss: 155215904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0863 - distribution_lambda_loss: 155215904.0000 46/122 [==========>...................] - ETA: 0s - loss: 154946352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0710 - distribution_lambda_loss: 154946352.0000 51/122 [===========>..................] - ETA: 0s - loss: 155782896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3610 - distribution_lambda_loss: 155782896.0000 56/122 [============>.................] - ETA: 0s - loss: 154943904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0765 - distribution_lambda_loss: 154943904.0000 61/122 [==============>...............] - ETA: 0s - loss: 154616224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0437 - distribution_lambda_loss: 154616224.0000 66/122 [===============>..............] - ETA: 0s - loss: 154961760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1004 - distribution_lambda_loss: 154961760.0000 71/122 [================>.............] - ETA: 0s - loss: 155183936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2266 - distribution_lambda_loss: 155183936.0000 76/122 [=================>............] - ETA: 0s - loss: 154878000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1450 - distribution_lambda_loss: 154878000.0000 81/122 [==================>...........] - ETA: 0s - loss: 155062672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2597 - distribution_lambda_loss: 155062672.0000 86/122 [====================>.........] - ETA: 0s - loss: 155086784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2450 - distribution_lambda_loss: 155086784.0000 91/122 [=====================>........] - ETA: 0s - loss: 154806592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1739 - distribution_lambda_loss: 154806592.0000 96/122 [======================>.......] - ETA: 0s - loss: 154678800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1536 - distribution_lambda_loss: 154678800.0000101/122 [=======================>......] - ETA: 0s - loss: 154740720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1431 - distribution_lambda_loss: 154740720.0000106/122 [=========================>....] - ETA: 0s - loss: 155175648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2951 - distribution_lambda_loss: 155175648.0000111/122 [==========================>...] - ETA: 0s - loss: 155198192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3128 - distribution_lambda_loss: 155198192.0000116/122 [===========================>..] - ETA: 0s - loss: 155563904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4455 - distribution_lambda_loss: 155563904.0000121/122 [============================>.] - ETA: 0s - loss: 156064816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5633 - distribution_lambda_loss: 156064816.0000122/122 [==============================] - 1s 11ms/step - loss: 155998736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5410 - distribution_lambda_loss: 155998736.0000 - val_loss: 160155072.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.1694 - val_distribution_lambda_loss: 160155072.0000 - lr: 0.0010
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 157957600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.7846 - distribution_lambda_loss: 157957600.0000  6/122 [>.............................] - ETA: 1s - loss: 154813792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3738 - distribution_lambda_loss: 154813792.0000 11/122 [=>............................] - ETA: 1s - loss: 152294064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7985 - distribution_lambda_loss: 152294064.0000 16/122 [==>...........................] - ETA: 1s - loss: 154597328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6493 - distribution_lambda_loss: 154597328.0000 21/122 [====>.........................] - ETA: 1s - loss: 156824080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.2224 - distribution_lambda_loss: 156824080.0000 26/122 [=====>........................] - ETA: 0s - loss: 156469376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0933 - distribution_lambda_loss: 156469376.0000 31/122 [======>.......................] - ETA: 0s - loss: 156448336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0363 - distribution_lambda_loss: 156448336.0000 36/122 [=======>......................] - ETA: 0s - loss: 156447856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9611 - distribution_lambda_loss: 156447856.0000 41/122 [=========>....................] - ETA: 0s - loss: 155710736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6218 - distribution_lambda_loss: 155710736.0000 46/122 [==========>...................] - ETA: 0s - loss: 154990592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3736 - distribution_lambda_loss: 154990592.0000 51/122 [===========>..................] - ETA: 0s - loss: 155208016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3969 - distribution_lambda_loss: 155208016.0000 56/122 [============>.................] - ETA: 0s - loss: 156778352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9756 - distribution_lambda_loss: 156778352.0000 61/122 [==============>...............] - ETA: 0s - loss: 155737888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6091 - distribution_lambda_loss: 155737888.0000 66/122 [===============>..............] - ETA: 0s - loss: 156429456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.8616 - distribution_lambda_loss: 156429456.0000 71/122 [================>.............] - ETA: 0s - loss: 156658912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.9592 - distribution_lambda_loss: 156658912.0000 76/122 [=================>............] - ETA: 0s - loss: 156021312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6936 - distribution_lambda_loss: 156021312.0000 81/122 [==================>...........] - ETA: 0s - loss: 155820384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6827 - distribution_lambda_loss: 155820384.0000 86/122 [====================>.........] - ETA: 0s - loss: 155956192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7590 - distribution_lambda_loss: 155956192.0000 91/122 [=====================>........] - ETA: 0s - loss: 156085280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7403 - distribution_lambda_loss: 156085280.0000 96/122 [======================>.......] - ETA: 0s - loss: 155922688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6856 - distribution_lambda_loss: 155922688.0000101/122 [=======================>......] - ETA: 0s - loss: 156077152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7626 - distribution_lambda_loss: 156077152.0000106/122 [=========================>....] - ETA: 0s - loss: 156013264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7171 - distribution_lambda_loss: 156013264.0000111/122 [==========================>...] - ETA: 0s - loss: 155758704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.6484 - distribution_lambda_loss: 155758704.0000116/122 [===========================>..] - ETA: 0s - loss: 155308048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5012 - distribution_lambda_loss: 155308048.0000121/122 [============================>.] - ETA: 0s - loss: 155190624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4482 - distribution_lambda_loss: 155190624.0000122/122 [==============================] - 1s 11ms/step - loss: 155188528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4449 - distribution_lambda_loss: 155188528.0000 - val_loss: 158058896.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 106.2290 - val_distribution_lambda_loss: 158058896.0000 - lr: 0.0010
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 154969024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7435 - distribution_lambda_loss: 154969024.0000  6/122 [>.............................] - ETA: 1s - loss: 159897552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1559 - distribution_lambda_loss: 159897552.0000 11/122 [=>............................] - ETA: 1s - loss: 153229296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.3784 - distribution_lambda_loss: 153229296.0000 16/122 [==>...........................] - ETA: 1s - loss: 152420496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4041 - distribution_lambda_loss: 152420496.0000 21/122 [====>.........................] - ETA: 1s - loss: 151852576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.2844 - distribution_lambda_loss: 151852576.0000 26/122 [=====>........................] - ETA: 1s - loss: 152674432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7597 - distribution_lambda_loss: 152674432.0000 31/122 [======>.......................] - ETA: 0s - loss: 154320704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2870 - distribution_lambda_loss: 154320704.0000 36/122 [=======>......................] - ETA: 0s - loss: 154942256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4443 - distribution_lambda_loss: 154942256.0000 41/122 [=========>....................] - ETA: 0s - loss: 154999952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4000 - distribution_lambda_loss: 154999952.0000 46/122 [==========>...................] - ETA: 0s - loss: 153675312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9270 - distribution_lambda_loss: 153675312.0000 51/122 [===========>..................] - ETA: 0s - loss: 153294000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7928 - distribution_lambda_loss: 153294000.0000 56/122 [============>.................] - ETA: 0s - loss: 153217248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7614 - distribution_lambda_loss: 153217248.0000 61/122 [==============>...............] - ETA: 0s - loss: 153539120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9074 - distribution_lambda_loss: 153539120.0000 66/122 [===============>..............] - ETA: 0s - loss: 153546576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9660 - distribution_lambda_loss: 153546576.0000 71/122 [================>.............] - ETA: 0s - loss: 154734768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2923 - distribution_lambda_loss: 154734768.0000 76/122 [=================>............] - ETA: 0s - loss: 154618000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.2094 - distribution_lambda_loss: 154618000.0000 81/122 [==================>...........] - ETA: 0s - loss: 154020624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0481 - distribution_lambda_loss: 154020624.0000 86/122 [====================>.........] - ETA: 0s - loss: 153232688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7988 - distribution_lambda_loss: 153232688.0000 91/122 [=====================>........] - ETA: 0s - loss: 153416864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9153 - distribution_lambda_loss: 153416864.0000 96/122 [======================>.......] - ETA: 0s - loss: 153115504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8251 - distribution_lambda_loss: 153115504.0000101/122 [=======================>......] - ETA: 0s - loss: 153224144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8715 - distribution_lambda_loss: 153224144.0000106/122 [=========================>....] - ETA: 0s - loss: 153595040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9939 - distribution_lambda_loss: 153595040.0000111/122 [==========================>...] - ETA: 0s - loss: 154012720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1368 - distribution_lambda_loss: 154012720.0000116/122 [===========================>..] - ETA: 0s - loss: 154027872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1222 - distribution_lambda_loss: 154027872.0000121/122 [============================>.] - ETA: 0s - loss: 153713024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0429 - distribution_lambda_loss: 153713024.0000122/122 [==============================] - 1s 11ms/step - loss: 153827824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0807 - distribution_lambda_loss: 153827824.0000 - val_loss: 157972432.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 105.7914 - val_distribution_lambda_loss: 157972432.0000 - lr: 0.0010
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 161236880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.3212 - distribution_lambda_loss: 161236880.0000  6/122 [>.............................] - ETA: 1s - loss: 152883056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5603 - distribution_lambda_loss: 152883056.0000 11/122 [=>............................] - ETA: 1s - loss: 152947568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5562 - distribution_lambda_loss: 152947568.0000 16/122 [==>...........................] - ETA: 1s - loss: 155649312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4082 - distribution_lambda_loss: 155649312.0000 21/122 [====>.........................] - ETA: 1s - loss: 153420176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8452 - distribution_lambda_loss: 153420176.0000 26/122 [=====>........................] - ETA: 0s - loss: 153428320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8728 - distribution_lambda_loss: 153428320.0000 31/122 [======>.......................] - ETA: 0s - loss: 153481424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0413 - distribution_lambda_loss: 153481424.0000 36/122 [=======>......................] - ETA: 0s - loss: 152890192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9269 - distribution_lambda_loss: 152890192.0000 41/122 [=========>....................] - ETA: 0s - loss: 152951920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8218 - distribution_lambda_loss: 152951920.0000 46/122 [==========>...................] - ETA: 0s - loss: 152020160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4468 - distribution_lambda_loss: 152020160.0000 51/122 [===========>..................] - ETA: 0s - loss: 151936640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4992 - distribution_lambda_loss: 151936640.0000 56/122 [============>.................] - ETA: 0s - loss: 151941648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4616 - distribution_lambda_loss: 151941648.0000 61/122 [==============>...............] - ETA: 0s - loss: 151811664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4702 - distribution_lambda_loss: 151811664.0000 66/122 [===============>..............] - ETA: 0s - loss: 152073312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6096 - distribution_lambda_loss: 152073312.0000 71/122 [================>.............] - ETA: 0s - loss: 151616288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4699 - distribution_lambda_loss: 151616288.0000 76/122 [=================>............] - ETA: 0s - loss: 152162864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6331 - distribution_lambda_loss: 152162864.0000 81/122 [==================>...........] - ETA: 0s - loss: 151916656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5445 - distribution_lambda_loss: 151916656.0000 86/122 [====================>.........] - ETA: 0s - loss: 151900000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5912 - distribution_lambda_loss: 151900000.0000 91/122 [=====================>........] - ETA: 0s - loss: 152039648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6567 - distribution_lambda_loss: 152039648.0000 96/122 [======================>.......] - ETA: 0s - loss: 152420816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7803 - distribution_lambda_loss: 152420816.0000101/122 [=======================>......] - ETA: 0s - loss: 152431424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7689 - distribution_lambda_loss: 152431424.0000106/122 [=========================>....] - ETA: 0s - loss: 152403840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7504 - distribution_lambda_loss: 152403840.0000111/122 [==========================>...] - ETA: 0s - loss: 152456144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7271 - distribution_lambda_loss: 152456144.0000116/122 [===========================>..] - ETA: 0s - loss: 152226512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6529 - distribution_lambda_loss: 152226512.0000121/122 [============================>.] - ETA: 0s - loss: 152471568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7751 - distribution_lambda_loss: 152471568.0000122/122 [==============================] - 1s 11ms/step - loss: 152394784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7616 - distribution_lambda_loss: 152394784.0000 - val_loss: 154573104.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.8117 - val_distribution_lambda_loss: 154573104.0000 - lr: 0.0010
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 131700736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5366 - distribution_lambda_loss: 131700736.0000  6/122 [>.............................] - ETA: 1s - loss: 143443776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5405 - distribution_lambda_loss: 143443776.0000 11/122 [=>............................] - ETA: 1s - loss: 150142736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.2593 - distribution_lambda_loss: 150142736.0000 16/122 [==>...........................] - ETA: 1s - loss: 152722208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.0873 - distribution_lambda_loss: 152722208.0000 21/122 [====>.........................] - ETA: 1s - loss: 153083808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9915 - distribution_lambda_loss: 153083808.0000 26/122 [=====>........................] - ETA: 0s - loss: 155160144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.7986 - distribution_lambda_loss: 155160144.0000 31/122 [======>.......................] - ETA: 0s - loss: 158012368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7790 - distribution_lambda_loss: 158012368.0000 36/122 [=======>......................] - ETA: 0s - loss: 157835456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.6016 - distribution_lambda_loss: 157835456.0000 41/122 [=========>....................] - ETA: 0s - loss: 157284432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4392 - distribution_lambda_loss: 157284432.0000 46/122 [==========>...................] - ETA: 0s - loss: 156032608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0149 - distribution_lambda_loss: 156032608.0000 51/122 [===========>..................] - ETA: 0s - loss: 154612368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5452 - distribution_lambda_loss: 154612368.0000 56/122 [============>.................] - ETA: 0s - loss: 154601584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.5344 - distribution_lambda_loss: 154601584.0000 61/122 [==============>...............] - ETA: 0s - loss: 152895152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9262 - distribution_lambda_loss: 152895152.0000 66/122 [===============>..............] - ETA: 0s - loss: 152324960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7118 - distribution_lambda_loss: 152324960.0000 71/122 [================>.............] - ETA: 0s - loss: 152120400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6168 - distribution_lambda_loss: 152120400.0000 76/122 [=================>............] - ETA: 0s - loss: 152345216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7984 - distribution_lambda_loss: 152345216.0000 81/122 [==================>...........] - ETA: 0s - loss: 152140608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7593 - distribution_lambda_loss: 152140608.0000 86/122 [====================>.........] - ETA: 0s - loss: 151858352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6882 - distribution_lambda_loss: 151858352.0000 91/122 [=====================>........] - ETA: 0s - loss: 151914368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7491 - distribution_lambda_loss: 151914368.0000 96/122 [======================>.......] - ETA: 0s - loss: 151571216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6181 - distribution_lambda_loss: 151571216.0000101/122 [=======================>......] - ETA: 0s - loss: 151599680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6116 - distribution_lambda_loss: 151599680.0000106/122 [=========================>....] - ETA: 0s - loss: 151329504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5176 - distribution_lambda_loss: 151329504.0000111/122 [==========================>...] - ETA: 0s - loss: 151651536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6473 - distribution_lambda_loss: 151651536.0000116/122 [===========================>..] - ETA: 0s - loss: 151329008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5356 - distribution_lambda_loss: 151329008.0000121/122 [============================>.] - ETA: 0s - loss: 151201888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4693 - distribution_lambda_loss: 151201888.0000122/122 [==============================] - 1s 11ms/step - loss: 151088288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.4287 - distribution_lambda_loss: 151088288.0000 - val_loss: 153349024.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.7517 - val_distribution_lambda_loss: 153349024.0000 - lr: 0.0010
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 149078160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.7656 - distribution_lambda_loss: 149078160.0000  6/122 [>.............................] - ETA: 1s - loss: 148613248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7924 - distribution_lambda_loss: 148613248.0000 11/122 [=>............................] - ETA: 1s - loss: 146250048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0295 - distribution_lambda_loss: 146250048.0000 16/122 [==>...........................] - ETA: 1s - loss: 146267616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0316 - distribution_lambda_loss: 146267616.0000 21/122 [====>.........................] - ETA: 1s - loss: 145644768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7121 - distribution_lambda_loss: 145644768.0000 26/122 [=====>........................] - ETA: 0s - loss: 146327232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0284 - distribution_lambda_loss: 146327232.0000 31/122 [======>.......................] - ETA: 0s - loss: 146552896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1866 - distribution_lambda_loss: 146552896.0000 36/122 [=======>......................] - ETA: 0s - loss: 146578496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.2202 - distribution_lambda_loss: 146578496.0000 41/122 [=========>....................] - ETA: 0s - loss: 147235280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3478 - distribution_lambda_loss: 147235280.0000 46/122 [==========>...................] - ETA: 0s - loss: 147351216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3562 - distribution_lambda_loss: 147351216.0000 51/122 [===========>..................] - ETA: 0s - loss: 147826752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5419 - distribution_lambda_loss: 147826752.0000 56/122 [============>.................] - ETA: 0s - loss: 148023184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6515 - distribution_lambda_loss: 148023184.0000 61/122 [==============>...............] - ETA: 0s - loss: 147917840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5860 - distribution_lambda_loss: 147917840.0000 66/122 [===============>..............] - ETA: 0s - loss: 148050912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6191 - distribution_lambda_loss: 148050912.0000 71/122 [================>.............] - ETA: 0s - loss: 148200000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7597 - distribution_lambda_loss: 148200000.0000 76/122 [=================>............] - ETA: 0s - loss: 148258672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7894 - distribution_lambda_loss: 148258672.0000 81/122 [==================>...........] - ETA: 0s - loss: 148410032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8309 - distribution_lambda_loss: 148410032.0000 86/122 [====================>.........] - ETA: 0s - loss: 148390320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7259 - distribution_lambda_loss: 148390320.0000 91/122 [=====================>........] - ETA: 0s - loss: 148950816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9329 - distribution_lambda_loss: 148950816.0000 96/122 [======================>.......] - ETA: 0s - loss: 148597200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8191 - distribution_lambda_loss: 148597200.0000101/122 [=======================>......] - ETA: 0s - loss: 148628384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7918 - distribution_lambda_loss: 148628384.0000106/122 [=========================>....] - ETA: 0s - loss: 148663120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7714 - distribution_lambda_loss: 148663120.0000111/122 [==========================>...] - ETA: 0s - loss: 148589952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7351 - distribution_lambda_loss: 148589952.0000116/122 [===========================>..] - ETA: 0s - loss: 148906896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8306 - distribution_lambda_loss: 148906896.0000121/122 [============================>.] - ETA: 0s - loss: 148491376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6931 - distribution_lambda_loss: 148491376.0000122/122 [==============================] - 1s 11ms/step - loss: 148467232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6846 - distribution_lambda_loss: 148467232.0000 - val_loss: 152898080.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.6763 - val_distribution_lambda_loss: 152898080.0000 - lr: 0.0010
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 156344096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.3506 - distribution_lambda_loss: 156344096.0000  6/122 [>.............................] - ETA: 1s - loss: 147756208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.0304 - distribution_lambda_loss: 147756208.0000 11/122 [=>............................] - ETA: 1s - loss: 151960480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.1708 - distribution_lambda_loss: 151960480.0000 16/122 [==>...........................] - ETA: 1s - loss: 151228672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7765 - distribution_lambda_loss: 151228672.0000 21/122 [====>.........................] - ETA: 1s - loss: 151451680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.7490 - distribution_lambda_loss: 151451680.0000 26/122 [=====>........................] - ETA: 0s - loss: 151341280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8853 - distribution_lambda_loss: 151341280.0000 31/122 [======>.......................] - ETA: 0s - loss: 149913488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.5649 - distribution_lambda_loss: 149913488.0000 36/122 [=======>......................] - ETA: 0s - loss: 149435952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.2096 - distribution_lambda_loss: 149435952.0000 41/122 [=========>....................] - ETA: 0s - loss: 148532304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7536 - distribution_lambda_loss: 148532304.0000 46/122 [==========>...................] - ETA: 0s - loss: 148021680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5903 - distribution_lambda_loss: 148021680.0000 51/122 [===========>..................] - ETA: 0s - loss: 148511696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7068 - distribution_lambda_loss: 148511696.0000 56/122 [============>.................] - ETA: 0s - loss: 148663024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8104 - distribution_lambda_loss: 148663024.0000 61/122 [==============>...............] - ETA: 0s - loss: 148009600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6785 - distribution_lambda_loss: 148009600.0000 66/122 [===============>..............] - ETA: 0s - loss: 147554832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4731 - distribution_lambda_loss: 147554832.0000 71/122 [================>.............] - ETA: 0s - loss: 148190704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6513 - distribution_lambda_loss: 148190704.0000 76/122 [=================>............] - ETA: 0s - loss: 147804256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4831 - distribution_lambda_loss: 147804256.0000 81/122 [==================>...........] - ETA: 0s - loss: 148372928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7160 - distribution_lambda_loss: 148372928.0000 86/122 [====================>.........] - ETA: 0s - loss: 148645040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8193 - distribution_lambda_loss: 148645040.0000 91/122 [=====================>........] - ETA: 0s - loss: 148633552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7574 - distribution_lambda_loss: 148633552.0000 96/122 [======================>.......] - ETA: 0s - loss: 148753552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8079 - distribution_lambda_loss: 148753552.0000101/122 [=======================>......] - ETA: 0s - loss: 148761232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8091 - distribution_lambda_loss: 148761232.0000106/122 [=========================>....] - ETA: 0s - loss: 148822624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8626 - distribution_lambda_loss: 148822624.0000111/122 [==========================>...] - ETA: 0s - loss: 149096592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9663 - distribution_lambda_loss: 149096592.0000116/122 [===========================>..] - ETA: 0s - loss: 148974976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9258 - distribution_lambda_loss: 148974976.0000121/122 [============================>.] - ETA: 0s - loss: 148809456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8407 - distribution_lambda_loss: 148809456.0000122/122 [==============================] - 1s 11ms/step - loss: 148670576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8012 - distribution_lambda_loss: 148670576.0000 - val_loss: 153685680.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.8447 - val_distribution_lambda_loss: 153685680.0000 - lr: 0.0010
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 142024000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6826 - distribution_lambda_loss: 142024000.0000  6/122 [>.............................] - ETA: 1s - loss: 151765200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.9757 - distribution_lambda_loss: 151765200.0000 11/122 [=>............................] - ETA: 1s - loss: 150697520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.6134 - distribution_lambda_loss: 150697520.0000 16/122 [==>...........................] - ETA: 1s - loss: 147501552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5233 - distribution_lambda_loss: 147501552.0000 21/122 [====>.........................] - ETA: 1s - loss: 145511344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7662 - distribution_lambda_loss: 145511344.0000 26/122 [=====>........................] - ETA: 1s - loss: 148363952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8682 - distribution_lambda_loss: 148363952.0000 31/122 [======>.......................] - ETA: 0s - loss: 146971136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3951 - distribution_lambda_loss: 146971136.0000 36/122 [=======>......................] - ETA: 0s - loss: 147278112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4426 - distribution_lambda_loss: 147278112.0000 41/122 [=========>....................] - ETA: 0s - loss: 147697744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5857 - distribution_lambda_loss: 147697744.0000 46/122 [==========>...................] - ETA: 0s - loss: 148123344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6350 - distribution_lambda_loss: 148123344.0000 51/122 [===========>..................] - ETA: 0s - loss: 148780416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8930 - distribution_lambda_loss: 148780416.0000 56/122 [============>.................] - ETA: 0s - loss: 148504496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7621 - distribution_lambda_loss: 148504496.0000 61/122 [==============>...............] - ETA: 0s - loss: 147920160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5825 - distribution_lambda_loss: 147920160.0000 66/122 [===============>..............] - ETA: 0s - loss: 148375648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7431 - distribution_lambda_loss: 148375648.0000 71/122 [================>.............] - ETA: 0s - loss: 148366576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7991 - distribution_lambda_loss: 148366576.0000 76/122 [=================>............] - ETA: 0s - loss: 148799392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.8911 - distribution_lambda_loss: 148799392.0000 81/122 [==================>...........] - ETA: 0s - loss: 148885600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9126 - distribution_lambda_loss: 148885600.0000 86/122 [====================>.........] - ETA: 0s - loss: 148419232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7501 - distribution_lambda_loss: 148419232.0000 91/122 [=====================>........] - ETA: 0s - loss: 148298160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.6864 - distribution_lambda_loss: 148298160.0000 96/122 [======================>.......] - ETA: 0s - loss: 148411056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7755 - distribution_lambda_loss: 148411056.0000101/122 [=======================>......] - ETA: 0s - loss: 148234032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.7058 - distribution_lambda_loss: 148234032.0000106/122 [=========================>....] - ETA: 0s - loss: 147734832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5387 - distribution_lambda_loss: 147734832.0000111/122 [==========================>...] - ETA: 0s - loss: 147251152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3274 - distribution_lambda_loss: 147251152.0000116/122 [===========================>..] - ETA: 0s - loss: 146966032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.2495 - distribution_lambda_loss: 146966032.0000121/122 [============================>.] - ETA: 0s - loss: 146665264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1331 - distribution_lambda_loss: 146665264.0000
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 146860464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1939 - distribution_lambda_loss: 146860464.0000 - val_loss: 156169248.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 109.1576 - val_distribution_lambda_loss: 156169248.0000 - lr: 0.0010
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 139900016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.3202 - distribution_lambda_loss: 139900016.0000  6/122 [>.............................] - ETA: 1s - loss: 149994736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 104.4441 - distribution_lambda_loss: 149994736.0000 11/122 [=>............................] - ETA: 1s - loss: 146345584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.9258 - distribution_lambda_loss: 146345584.0000 16/122 [==>...........................] - ETA: 1s - loss: 141584400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9183 - distribution_lambda_loss: 141584400.0000 21/122 [====>.........................] - ETA: 1s - loss: 141352992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7363 - distribution_lambda_loss: 141352992.0000 26/122 [=====>........................] - ETA: 1s - loss: 142703440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1921 - distribution_lambda_loss: 142703440.0000 31/122 [======>.......................] - ETA: 0s - loss: 144259472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5371 - distribution_lambda_loss: 144259472.0000 36/122 [=======>......................] - ETA: 0s - loss: 143664784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4510 - distribution_lambda_loss: 143664784.0000 41/122 [=========>....................] - ETA: 0s - loss: 144377152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6767 - distribution_lambda_loss: 144377152.0000 46/122 [==========>...................] - ETA: 0s - loss: 144755952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8832 - distribution_lambda_loss: 144755952.0000 51/122 [===========>..................] - ETA: 0s - loss: 143869632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5173 - distribution_lambda_loss: 143869632.0000 56/122 [============>.................] - ETA: 0s - loss: 143030800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2661 - distribution_lambda_loss: 143030800.0000 61/122 [==============>...............] - ETA: 0s - loss: 143462640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3024 - distribution_lambda_loss: 143462640.0000 66/122 [===============>..............] - ETA: 0s - loss: 143608880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3543 - distribution_lambda_loss: 143608880.0000 71/122 [================>.............] - ETA: 0s - loss: 143904560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4924 - distribution_lambda_loss: 143904560.0000 76/122 [=================>............] - ETA: 0s - loss: 144129120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5243 - distribution_lambda_loss: 144129120.0000 81/122 [==================>...........] - ETA: 0s - loss: 143530064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3465 - distribution_lambda_loss: 143530064.0000 86/122 [====================>.........] - ETA: 0s - loss: 143920944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4610 - distribution_lambda_loss: 143920944.0000 91/122 [=====================>........] - ETA: 0s - loss: 143998432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4439 - distribution_lambda_loss: 143998432.0000 96/122 [======================>.......] - ETA: 0s - loss: 143913904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4299 - distribution_lambda_loss: 143913904.0000101/122 [=======================>......] - ETA: 0s - loss: 144194880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4973 - distribution_lambda_loss: 144194880.0000106/122 [=========================>....] - ETA: 0s - loss: 143856096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3587 - distribution_lambda_loss: 143856096.0000111/122 [==========================>...] - ETA: 0s - loss: 144271376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5128 - distribution_lambda_loss: 144271376.0000116/122 [===========================>..] - ETA: 0s - loss: 144037152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4077 - distribution_lambda_loss: 144037152.0000121/122 [============================>.] - ETA: 0s - loss: 144259968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4980 - distribution_lambda_loss: 144259968.0000122/122 [==============================] - 1s 11ms/step - loss: 144190832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4857 - distribution_lambda_loss: 144190832.0000 - val_loss: 148733120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.9445 - val_distribution_lambda_loss: 148733120.0000 - lr: 5.0000e-04
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 148171696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3618 - distribution_lambda_loss: 148171696.0000  6/122 [>.............................] - ETA: 1s - loss: 141779312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7632 - distribution_lambda_loss: 141779312.0000 11/122 [=>............................] - ETA: 1s - loss: 143853680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2459 - distribution_lambda_loss: 143853680.0000 16/122 [==>...........................] - ETA: 1s - loss: 146707536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3419 - distribution_lambda_loss: 146707536.0000 21/122 [====>.........................] - ETA: 1s - loss: 144687760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5833 - distribution_lambda_loss: 144687760.0000 26/122 [=====>........................] - ETA: 0s - loss: 145027168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8864 - distribution_lambda_loss: 145027168.0000 31/122 [======>.......................] - ETA: 0s - loss: 145579632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.9558 - distribution_lambda_loss: 145579632.0000 36/122 [=======>......................] - ETA: 0s - loss: 145845360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0887 - distribution_lambda_loss: 145845360.0000 41/122 [=========>....................] - ETA: 0s - loss: 144976496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7096 - distribution_lambda_loss: 144976496.0000 46/122 [==========>...................] - ETA: 0s - loss: 144662416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5833 - distribution_lambda_loss: 144662416.0000 51/122 [===========>..................] - ETA: 0s - loss: 144867632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6724 - distribution_lambda_loss: 144867632.0000 56/122 [============>.................] - ETA: 0s - loss: 144294064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4582 - distribution_lambda_loss: 144294064.0000 61/122 [==============>...............] - ETA: 0s - loss: 143660384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3154 - distribution_lambda_loss: 143660384.0000 66/122 [===============>..............] - ETA: 0s - loss: 143295920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1963 - distribution_lambda_loss: 143295920.0000 71/122 [================>.............] - ETA: 0s - loss: 143066352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0700 - distribution_lambda_loss: 143066352.0000 76/122 [=================>............] - ETA: 0s - loss: 142762368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9934 - distribution_lambda_loss: 142762368.0000 81/122 [==================>...........] - ETA: 0s - loss: 142716000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0457 - distribution_lambda_loss: 142716000.0000 86/122 [====================>.........] - ETA: 0s - loss: 142779248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0369 - distribution_lambda_loss: 142779248.0000 91/122 [=====================>........] - ETA: 0s - loss: 142984704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0878 - distribution_lambda_loss: 142984704.0000 96/122 [======================>.......] - ETA: 0s - loss: 142728176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9991 - distribution_lambda_loss: 142728176.0000101/122 [=======================>......] - ETA: 0s - loss: 142723248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9902 - distribution_lambda_loss: 142723248.0000106/122 [=========================>....] - ETA: 0s - loss: 143204640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1393 - distribution_lambda_loss: 143204640.0000111/122 [==========================>...] - ETA: 0s - loss: 143199728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1413 - distribution_lambda_loss: 143199728.0000116/122 [===========================>..] - ETA: 0s - loss: 143048608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1098 - distribution_lambda_loss: 143048608.0000121/122 [============================>.] - ETA: 0s - loss: 143067232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0823 - distribution_lambda_loss: 143067232.0000122/122 [==============================] - 1s 11ms/step - loss: 143037776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0702 - distribution_lambda_loss: 143037776.0000 - val_loss: 148868272.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 103.4010 - val_distribution_lambda_loss: 148868272.0000 - lr: 5.0000e-04
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 136187472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9806 - distribution_lambda_loss: 136187472.0000  6/122 [>.............................] - ETA: 1s - loss: 146894512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.0511 - distribution_lambda_loss: 146894512.0000 11/122 [=>............................] - ETA: 1s - loss: 148584176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.1524 - distribution_lambda_loss: 148584176.0000 16/122 [==>...........................] - ETA: 1s - loss: 146476592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4589 - distribution_lambda_loss: 146476592.0000 21/122 [====>.........................] - ETA: 1s - loss: 145361936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.2166 - distribution_lambda_loss: 145361936.0000 26/122 [=====>........................] - ETA: 0s - loss: 144088416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7372 - distribution_lambda_loss: 144088416.0000 31/122 [======>.......................] - ETA: 0s - loss: 143839760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5605 - distribution_lambda_loss: 143839760.0000 36/122 [=======>......................] - ETA: 0s - loss: 144117440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5887 - distribution_lambda_loss: 144117440.0000 41/122 [=========>....................] - ETA: 0s - loss: 145186544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.9251 - distribution_lambda_loss: 145186544.0000 46/122 [==========>...................] - ETA: 0s - loss: 145523824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0543 - distribution_lambda_loss: 145523824.0000 51/122 [===========>..................] - ETA: 0s - loss: 144855984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8044 - distribution_lambda_loss: 144855984.0000 56/122 [============>.................] - ETA: 0s - loss: 144814656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8366 - distribution_lambda_loss: 144814656.0000 61/122 [==============>...............] - ETA: 0s - loss: 145063552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.9129 - distribution_lambda_loss: 145063552.0000 66/122 [===============>..............] - ETA: 0s - loss: 144346400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6108 - distribution_lambda_loss: 144346400.0000 71/122 [================>.............] - ETA: 0s - loss: 144014544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5054 - distribution_lambda_loss: 144014544.0000 76/122 [=================>............] - ETA: 0s - loss: 144206640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5969 - distribution_lambda_loss: 144206640.0000 81/122 [==================>...........] - ETA: 0s - loss: 144236944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6240 - distribution_lambda_loss: 144236944.0000 86/122 [====================>.........] - ETA: 0s - loss: 143890288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5123 - distribution_lambda_loss: 143890288.0000 91/122 [=====================>........] - ETA: 0s - loss: 143400720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3201 - distribution_lambda_loss: 143400720.0000 96/122 [======================>.......] - ETA: 0s - loss: 143104592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2035 - distribution_lambda_loss: 143104592.0000101/122 [=======================>......] - ETA: 0s - loss: 143067376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1960 - distribution_lambda_loss: 143067376.0000106/122 [=========================>....] - ETA: 0s - loss: 143273392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2706 - distribution_lambda_loss: 143273392.0000111/122 [==========================>...] - ETA: 0s - loss: 142779056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1133 - distribution_lambda_loss: 142779056.0000116/122 [===========================>..] - ETA: 0s - loss: 142653760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0374 - distribution_lambda_loss: 142653760.0000121/122 [============================>.] - ETA: 0s - loss: 142522528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9824 - distribution_lambda_loss: 142522528.0000122/122 [==============================] - 1s 11ms/step - loss: 142496784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9754 - distribution_lambda_loss: 142496784.0000 - val_loss: 147361392.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.1326 - val_distribution_lambda_loss: 147361392.0000 - lr: 5.0000e-04
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 158139808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.1004 - distribution_lambda_loss: 158139808.0000  6/122 [>.............................] - ETA: 1s - loss: 155693472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.8153 - distribution_lambda_loss: 155693472.0000 11/122 [=>............................] - ETA: 1s - loss: 145966704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.0526 - distribution_lambda_loss: 145966704.0000 16/122 [==>...........................] - ETA: 1s - loss: 145249840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8879 - distribution_lambda_loss: 145249840.0000 21/122 [====>.........................] - ETA: 1s - loss: 145836112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.1213 - distribution_lambda_loss: 145836112.0000 26/122 [=====>........................] - ETA: 0s - loss: 145297296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8302 - distribution_lambda_loss: 145297296.0000 31/122 [======>.......................] - ETA: 0s - loss: 144746912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6526 - distribution_lambda_loss: 144746912.0000 36/122 [=======>......................] - ETA: 0s - loss: 144423776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5947 - distribution_lambda_loss: 144423776.0000 41/122 [=========>....................] - ETA: 0s - loss: 144468000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7414 - distribution_lambda_loss: 144468000.0000 46/122 [==========>...................] - ETA: 0s - loss: 144126480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5954 - distribution_lambda_loss: 144126480.0000 51/122 [===========>..................] - ETA: 0s - loss: 143968944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5742 - distribution_lambda_loss: 143968944.0000 56/122 [============>.................] - ETA: 0s - loss: 144344896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.7001 - distribution_lambda_loss: 144344896.0000 61/122 [==============>...............] - ETA: 0s - loss: 143375584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3776 - distribution_lambda_loss: 143375584.0000 66/122 [===============>..............] - ETA: 0s - loss: 143143200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3292 - distribution_lambda_loss: 143143200.0000 71/122 [================>.............] - ETA: 0s - loss: 142853168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2046 - distribution_lambda_loss: 142853168.0000 76/122 [=================>............] - ETA: 0s - loss: 142527504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0848 - distribution_lambda_loss: 142527504.0000 81/122 [==================>...........] - ETA: 0s - loss: 142682624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1139 - distribution_lambda_loss: 142682624.0000 86/122 [====================>.........] - ETA: 0s - loss: 142532896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0834 - distribution_lambda_loss: 142532896.0000 91/122 [=====================>........] - ETA: 0s - loss: 142349632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0293 - distribution_lambda_loss: 142349632.0000 96/122 [======================>.......] - ETA: 0s - loss: 141906624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8296 - distribution_lambda_loss: 141906624.0000101/122 [=======================>......] - ETA: 0s - loss: 141702240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7384 - distribution_lambda_loss: 141702240.0000107/122 [=========================>....] - ETA: 0s - loss: 142310336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9164 - distribution_lambda_loss: 142310336.0000112/122 [==========================>...] - ETA: 0s - loss: 142483600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9618 - distribution_lambda_loss: 142483600.0000117/122 [===========================>..] - ETA: 0s - loss: 142393040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9146 - distribution_lambda_loss: 142393040.0000122/122 [==============================] - 1s 11ms/step - loss: 142335904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9231 - distribution_lambda_loss: 142335904.0000 - val_loss: 147567648.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.2787 - val_distribution_lambda_loss: 147567648.0000 - lr: 5.0000e-04
Epoch 22/50
  1/122 [..............................] - ETA: 1s - loss: 141999360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8633 - distribution_lambda_loss: 141999360.0000  6/122 [>.............................] - ETA: 1s - loss: 139009072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4649 - distribution_lambda_loss: 139009072.0000  11/122 [=>............................] - ETA: 1s - loss: 142444400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6198 - distribution_lambda_loss: 142444400.0000 16/122 [==>...........................] - ETA: 1s - loss: 143585312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1532 - distribution_lambda_loss: 143585312.0000 21/122 [====>.........................] - ETA: 1s - loss: 142478208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8978 - distribution_lambda_loss: 142478208.0000 26/122 [=====>........................] - ETA: 0s - loss: 141614144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6201 - distribution_lambda_loss: 141614144.0000 31/122 [======>.......................] - ETA: 0s - loss: 141960576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9083 - distribution_lambda_loss: 141960576.0000 36/122 [=======>......................] - ETA: 0s - loss: 141829968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9156 - distribution_lambda_loss: 141829968.0000 41/122 [=========>....................] - ETA: 0s - loss: 142760624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1880 - distribution_lambda_loss: 142760624.0000 46/122 [==========>...................] - ETA: 0s - loss: 142595280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1572 - distribution_lambda_loss: 142595280.0000 51/122 [===========>..................] - ETA: 0s - loss: 142661456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1404 - distribution_lambda_loss: 142661456.0000 56/122 [============>.................] - ETA: 0s - loss: 142791536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2185 - distribution_lambda_loss: 142791536.0000 61/122 [==============>...............] - ETA: 0s - loss: 142629120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2094 - distribution_lambda_loss: 142629120.0000 66/122 [===============>..............] - ETA: 0s - loss: 142507984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0826 - distribution_lambda_loss: 142507984.0000 71/122 [================>.............] - ETA: 0s - loss: 141954944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8950 - distribution_lambda_loss: 141954944.0000 76/122 [=================>............] - ETA: 0s - loss: 141813088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8467 - distribution_lambda_loss: 141813088.0000 81/122 [==================>...........] - ETA: 0s - loss: 142402464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0355 - distribution_lambda_loss: 142402464.0000 86/122 [====================>.........] - ETA: 0s - loss: 142489488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0756 - distribution_lambda_loss: 142489488.0000 91/122 [=====================>........] - ETA: 0s - loss: 142106368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9140 - distribution_lambda_loss: 142106368.0000 96/122 [======================>.......] - ETA: 0s - loss: 142122688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9290 - distribution_lambda_loss: 142122688.0000101/122 [=======================>......] - ETA: 0s - loss: 142367584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0165 - distribution_lambda_loss: 142367584.0000106/122 [=========================>....] - ETA: 0s - loss: 142080496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8842 - distribution_lambda_loss: 142080496.0000111/122 [==========================>...] - ETA: 0s - loss: 142181312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9365 - distribution_lambda_loss: 142181312.0000116/122 [===========================>..] - ETA: 0s - loss: 141884256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8241 - distribution_lambda_loss: 141884256.0000121/122 [============================>.] - ETA: 0s - loss: 141747280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7619 - distribution_lambda_loss: 141747280.0000122/122 [==============================] - 1s 11ms/step - loss: 141632272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7218 - distribution_lambda_loss: 141632272.0000 - val_loss: 146719712.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.7908 - val_distribution_lambda_loss: 146719712.0000 - lr: 5.0000e-04
Epoch 23/50
  1/122 [..............................] - ETA: 1s - loss: 145660512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8775 - distribution_lambda_loss: 145660512.0000  6/122 [>.............................] - ETA: 1s - loss: 148731488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.8810 - distribution_lambda_loss: 148731488.0000 11/122 [=>............................] - ETA: 1s - loss: 148136080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 103.3293 - distribution_lambda_loss: 148136080.0000 16/122 [==>...........................] - ETA: 1s - loss: 146689824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5192 - distribution_lambda_loss: 146689824.0000 21/122 [====>.........................] - ETA: 1s - loss: 144379824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.4199 - distribution_lambda_loss: 144379824.0000 26/122 [=====>........................] - ETA: 0s - loss: 143263072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2197 - distribution_lambda_loss: 143263072.0000 31/122 [======>.......................] - ETA: 0s - loss: 142906640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0266 - distribution_lambda_loss: 142906640.0000 36/122 [=======>......................] - ETA: 0s - loss: 143969088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.5857 - distribution_lambda_loss: 143969088.0000 41/122 [=========>....................] - ETA: 0s - loss: 144260864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6494 - distribution_lambda_loss: 144260864.0000 46/122 [==========>...................] - ETA: 0s - loss: 143322864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3394 - distribution_lambda_loss: 143322864.0000 51/122 [===========>..................] - ETA: 0s - loss: 142769760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1061 - distribution_lambda_loss: 142769760.0000 56/122 [============>.................] - ETA: 0s - loss: 142174320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9362 - distribution_lambda_loss: 142174320.0000 61/122 [==============>...............] - ETA: 0s - loss: 142166336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9694 - distribution_lambda_loss: 142166336.0000 66/122 [===============>..............] - ETA: 0s - loss: 142492384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9927 - distribution_lambda_loss: 142492384.0000 71/122 [================>.............] - ETA: 0s - loss: 142325632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9661 - distribution_lambda_loss: 142325632.0000 76/122 [=================>............] - ETA: 0s - loss: 141747584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7402 - distribution_lambda_loss: 141747584.0000 81/122 [==================>...........] - ETA: 0s - loss: 141557520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6642 - distribution_lambda_loss: 141557520.0000 86/122 [====================>.........] - ETA: 0s - loss: 141656960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7325 - distribution_lambda_loss: 141656960.0000 91/122 [=====================>........] - ETA: 0s - loss: 141709360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7571 - distribution_lambda_loss: 141709360.0000 96/122 [======================>.......] - ETA: 0s - loss: 141689328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7544 - distribution_lambda_loss: 141689328.0000101/122 [=======================>......] - ETA: 0s - loss: 141675104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7653 - distribution_lambda_loss: 141675104.0000106/122 [=========================>....] - ETA: 0s - loss: 141538464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7097 - distribution_lambda_loss: 141538464.0000111/122 [==========================>...] - ETA: 0s - loss: 141387664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6673 - distribution_lambda_loss: 141387664.0000116/122 [===========================>..] - ETA: 0s - loss: 141525872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7133 - distribution_lambda_loss: 141525872.0000121/122 [============================>.] - ETA: 0s - loss: 141182960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5889 - distribution_lambda_loss: 141182960.0000122/122 [==============================] - 1s 11ms/step - loss: 141250528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6147 - distribution_lambda_loss: 141250528.0000 - val_loss: 147631568.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 104.1586 - val_distribution_lambda_loss: 147631568.0000 - lr: 5.0000e-04
Epoch 24/50
  1/122 [..............................] - ETA: 1s - loss: 152341824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 106.4371 - distribution_lambda_loss: 152341824.0000  6/122 [>.............................] - ETA: 1s - loss: 141341088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8257 - distribution_lambda_loss: 141341088.0000 11/122 [=>............................] - ETA: 1s - loss: 140351680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.8356 - distribution_lambda_loss: 140351680.0000 16/122 [==>...........................] - ETA: 1s - loss: 139824208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6390 - distribution_lambda_loss: 139824208.0000 21/122 [====>.........................] - ETA: 1s - loss: 139880544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5766 - distribution_lambda_loss: 139880544.0000 26/122 [=====>........................] - ETA: 0s - loss: 140540064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6212 - distribution_lambda_loss: 140540064.0000 31/122 [======>.......................] - ETA: 0s - loss: 140297328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4308 - distribution_lambda_loss: 140297328.0000 36/122 [=======>......................] - ETA: 0s - loss: 139046544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9348 - distribution_lambda_loss: 139046544.0000  41/122 [=========>....................] - ETA: 0s - loss: 139651552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1889 - distribution_lambda_loss: 139651552.0000 46/122 [==========>...................] - ETA: 0s - loss: 138792176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8938 - distribution_lambda_loss: 138792176.0000  51/122 [===========>..................] - ETA: 0s - loss: 139357408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1097 - distribution_lambda_loss: 139357408.0000 56/122 [============>.................] - ETA: 0s - loss: 139340000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0703 - distribution_lambda_loss: 139340000.0000 61/122 [==============>...............] - ETA: 0s - loss: 139514960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1730 - distribution_lambda_loss: 139514960.0000 66/122 [===============>..............] - ETA: 0s - loss: 139868544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2873 - distribution_lambda_loss: 139868544.0000 71/122 [================>.............] - ETA: 0s - loss: 139982304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3734 - distribution_lambda_loss: 139982304.0000 76/122 [=================>............] - ETA: 0s - loss: 140399296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4672 - distribution_lambda_loss: 140399296.0000 81/122 [==================>...........] - ETA: 0s - loss: 141065952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7038 - distribution_lambda_loss: 141065952.0000 86/122 [====================>.........] - ETA: 0s - loss: 140960688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6752 - distribution_lambda_loss: 140960688.0000 91/122 [=====================>........] - ETA: 0s - loss: 140798608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5975 - distribution_lambda_loss: 140798608.0000 96/122 [======================>.......] - ETA: 0s - loss: 140697312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5826 - distribution_lambda_loss: 140697312.0000101/122 [=======================>......] - ETA: 0s - loss: 141057456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6577 - distribution_lambda_loss: 141057456.0000106/122 [=========================>....] - ETA: 0s - loss: 141050592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6434 - distribution_lambda_loss: 141050592.0000111/122 [==========================>...] - ETA: 0s - loss: 140891648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5837 - distribution_lambda_loss: 140891648.0000116/122 [===========================>..] - ETA: 0s - loss: 140916752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5939 - distribution_lambda_loss: 140916752.0000121/122 [============================>.] - ETA: 0s - loss: 140836592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5083 - distribution_lambda_loss: 140836592.0000122/122 [==============================] - 1s 11ms/step - loss: 140825856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5092 - distribution_lambda_loss: 140825856.0000 - val_loss: 145639264.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.3958 - val_distribution_lambda_loss: 145639264.0000 - lr: 5.0000e-04
Epoch 25/50
  1/122 [..............................] - ETA: 1s - loss: 127980304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.9594 - distribution_lambda_loss: 127980304.0000  6/122 [>.............................] - ETA: 1s - loss: 140989552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9581 - distribution_lambda_loss: 140989552.0000 11/122 [=>............................] - ETA: 1s - loss: 135990384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6509 - distribution_lambda_loss: 135990384.0000 16/122 [==>...........................] - ETA: 1s - loss: 135793456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6928 - distribution_lambda_loss: 135793456.0000 21/122 [====>.........................] - ETA: 1s - loss: 137105056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1889 - distribution_lambda_loss: 137105056.0000 26/122 [=====>........................] - ETA: 0s - loss: 137684272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6113 - distribution_lambda_loss: 137684272.0000 31/122 [======>.......................] - ETA: 0s - loss: 138677696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7821 - distribution_lambda_loss: 138677696.0000 36/122 [=======>......................] - ETA: 0s - loss: 138372224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6665 - distribution_lambda_loss: 138372224.0000 41/122 [=========>....................] - ETA: 0s - loss: 139712736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2550 - distribution_lambda_loss: 139712736.0000 46/122 [==========>...................] - ETA: 0s - loss: 138666992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7737 - distribution_lambda_loss: 138666992.0000  51/122 [===========>..................] - ETA: 0s - loss: 137438352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3371 - distribution_lambda_loss: 137438352.0000 56/122 [============>.................] - ETA: 0s - loss: 137508032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4023 - distribution_lambda_loss: 137508032.0000 61/122 [==============>...............] - ETA: 0s - loss: 137616592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4802 - distribution_lambda_loss: 137616592.0000 66/122 [===============>..............] - ETA: 0s - loss: 138158976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6397 - distribution_lambda_loss: 138158976.0000 71/122 [================>.............] - ETA: 0s - loss: 138685200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8543 - distribution_lambda_loss: 138685200.0000 76/122 [=================>............] - ETA: 0s - loss: 139071136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0143 - distribution_lambda_loss: 139071136.0000 81/122 [==================>...........] - ETA: 0s - loss: 139228736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0173 - distribution_lambda_loss: 139228736.0000 86/122 [====================>.........] - ETA: 0s - loss: 140036864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2865 - distribution_lambda_loss: 140036864.0000 91/122 [=====================>........] - ETA: 0s - loss: 139895296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2099 - distribution_lambda_loss: 139895296.0000 96/122 [======================>.......] - ETA: 0s - loss: 139753552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1023 - distribution_lambda_loss: 139753552.0000101/122 [=======================>......] - ETA: 0s - loss: 140385728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3216 - distribution_lambda_loss: 140385728.0000106/122 [=========================>....] - ETA: 0s - loss: 140565776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3856 - distribution_lambda_loss: 140565776.0000111/122 [==========================>...] - ETA: 0s - loss: 140730960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4524 - distribution_lambda_loss: 140730960.0000116/122 [===========================>..] - ETA: 0s - loss: 140456656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3866 - distribution_lambda_loss: 140456656.0000121/122 [============================>.] - ETA: 0s - loss: 140395040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3796 - distribution_lambda_loss: 140395040.0000122/122 [==============================] - 1s 11ms/step - loss: 140371760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3775 - distribution_lambda_loss: 140371760.0000 - val_loss: 146032544.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.4706 - val_distribution_lambda_loss: 146032544.0000 - lr: 5.0000e-04
Epoch 26/50
  1/122 [..............................] - ETA: 1s - loss: 121652248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.2060 - distribution_lambda_loss: 121652248.0000  6/122 [>.............................] - ETA: 1s - loss: 137823664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8060 - distribution_lambda_loss: 137823664.0000 11/122 [=>............................] - ETA: 1s - loss: 139539344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7338 - distribution_lambda_loss: 139539344.0000 16/122 [==>...........................] - ETA: 1s - loss: 139318800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1016 - distribution_lambda_loss: 139318800.0000 21/122 [====>.........................] - ETA: 1s - loss: 139875392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2740 - distribution_lambda_loss: 139875392.0000 26/122 [=====>........................] - ETA: 0s - loss: 142121600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9640 - distribution_lambda_loss: 142121600.0000 31/122 [======>.......................] - ETA: 0s - loss: 142997200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.2784 - distribution_lambda_loss: 142997200.0000 36/122 [=======>......................] - ETA: 0s - loss: 143927440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6847 - distribution_lambda_loss: 143927440.0000 41/122 [=========>....................] - ETA: 0s - loss: 143975824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6902 - distribution_lambda_loss: 143975824.0000 46/122 [==========>...................] - ETA: 0s - loss: 142793712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.3145 - distribution_lambda_loss: 142793712.0000 51/122 [===========>..................] - ETA: 0s - loss: 142023040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0079 - distribution_lambda_loss: 142023040.0000 56/122 [============>.................] - ETA: 0s - loss: 141247360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7322 - distribution_lambda_loss: 141247360.0000 61/122 [==============>...............] - ETA: 0s - loss: 140789568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5455 - distribution_lambda_loss: 140789568.0000 66/122 [===============>..............] - ETA: 0s - loss: 140599152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4623 - distribution_lambda_loss: 140599152.0000 71/122 [================>.............] - ETA: 0s - loss: 140582336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4177 - distribution_lambda_loss: 140582336.0000 76/122 [=================>............] - ETA: 0s - loss: 140890496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5324 - distribution_lambda_loss: 140890496.0000 81/122 [==================>...........] - ETA: 0s - loss: 140868480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.5479 - distribution_lambda_loss: 140868480.0000 86/122 [====================>.........] - ETA: 0s - loss: 140401232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3864 - distribution_lambda_loss: 140401232.0000 91/122 [=====================>........] - ETA: 0s - loss: 140364016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3317 - distribution_lambda_loss: 140364016.0000 96/122 [======================>.......] - ETA: 0s - loss: 140308096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2993 - distribution_lambda_loss: 140308096.0000101/122 [=======================>......] - ETA: 0s - loss: 140547936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4154 - distribution_lambda_loss: 140547936.0000106/122 [=========================>....] - ETA: 0s - loss: 140039504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2413 - distribution_lambda_loss: 140039504.0000111/122 [==========================>...] - ETA: 0s - loss: 140060960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2738 - distribution_lambda_loss: 140060960.0000116/122 [===========================>..] - ETA: 0s - loss: 139635056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1233 - distribution_lambda_loss: 139635056.0000121/122 [============================>.] - ETA: 0s - loss: 140077760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2736 - distribution_lambda_loss: 140077760.0000
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 140064288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2745 - distribution_lambda_loss: 140064288.0000 - val_loss: 146825632.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.7162 - val_distribution_lambda_loss: 146825632.0000 - lr: 5.0000e-04
Epoch 27/50
  1/122 [..............................] - ETA: 1s - loss: 135547536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7145 - distribution_lambda_loss: 135547536.0000  6/122 [>.............................] - ETA: 1s - loss: 137789040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9930 - distribution_lambda_loss: 137789040.0000 11/122 [=>............................] - ETA: 1s - loss: 134746832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2962 - distribution_lambda_loss: 134746832.0000 16/122 [==>...........................] - ETA: 1s - loss: 139065696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8853 - distribution_lambda_loss: 139065696.0000 21/122 [====>.........................] - ETA: 1s - loss: 139446896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9931 - distribution_lambda_loss: 139446896.0000 26/122 [=====>........................] - ETA: 0s - loss: 139218624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8617 - distribution_lambda_loss: 139218624.0000 31/122 [======>.......................] - ETA: 0s - loss: 139590096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1326 - distribution_lambda_loss: 139590096.0000 36/122 [=======>......................] - ETA: 0s - loss: 139421504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0957 - distribution_lambda_loss: 139421504.0000 41/122 [=========>....................] - ETA: 0s - loss: 139247856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0535 - distribution_lambda_loss: 139247856.0000 46/122 [==========>...................] - ETA: 0s - loss: 138597616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8692 - distribution_lambda_loss: 138597616.0000  51/122 [===========>..................] - ETA: 0s - loss: 139275152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0860 - distribution_lambda_loss: 139275152.0000 56/122 [============>.................] - ETA: 0s - loss: 140310416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4634 - distribution_lambda_loss: 140310416.0000 61/122 [==============>...............] - ETA: 0s - loss: 139822048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3257 - distribution_lambda_loss: 139822048.0000 66/122 [===============>..............] - ETA: 0s - loss: 139355056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1378 - distribution_lambda_loss: 139355056.0000 71/122 [================>.............] - ETA: 0s - loss: 139212160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0168 - distribution_lambda_loss: 139212160.0000 76/122 [=================>............] - ETA: 0s - loss: 138816176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8222 - distribution_lambda_loss: 138816176.0000  81/122 [==================>...........] - ETA: 0s - loss: 138872448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8614 - distribution_lambda_loss: 138872448.0000 86/122 [====================>.........] - ETA: 0s - loss: 138643280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8143 - distribution_lambda_loss: 138643280.0000 91/122 [=====================>........] - ETA: 0s - loss: 138354528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7204 - distribution_lambda_loss: 138354528.0000 96/122 [======================>.......] - ETA: 0s - loss: 138342320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7182 - distribution_lambda_loss: 138342320.0000101/122 [=======================>......] - ETA: 0s - loss: 138451920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7426 - distribution_lambda_loss: 138451920.0000106/122 [=========================>....] - ETA: 0s - loss: 138551488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7887 - distribution_lambda_loss: 138551488.0000111/122 [==========================>...] - ETA: 0s - loss: 138228128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6769 - distribution_lambda_loss: 138228128.0000116/122 [===========================>..] - ETA: 0s - loss: 138116816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6514 - distribution_lambda_loss: 138116816.0000121/122 [============================>.] - ETA: 0s - loss: 138369088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7432 - distribution_lambda_loss: 138369088.0000122/122 [==============================] - 1s 11ms/step - loss: 138529344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7972 - distribution_lambda_loss: 138529344.0000 - val_loss: 144804688.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 102.2178 - val_distribution_lambda_loss: 144804688.0000 - lr: 2.5000e-04
Epoch 28/50
  1/122 [..............................] - ETA: 1s - loss: 119350480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 92.3842 - distribution_lambda_loss: 119350480.0000  6/122 [>.............................] - ETA: 1s - loss: 132133152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0892 - distribution_lambda_loss: 132133152.0000 11/122 [=>............................] - ETA: 1s - loss: 134280768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6030 - distribution_lambda_loss: 134280768.0000 16/122 [==>...........................] - ETA: 1s - loss: 135653312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9353 - distribution_lambda_loss: 135653312.0000 21/122 [====>.........................] - ETA: 1s - loss: 137714752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5768 - distribution_lambda_loss: 137714752.0000 26/122 [=====>........................] - ETA: 0s - loss: 139022496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1588 - distribution_lambda_loss: 139022496.0000 31/122 [======>.......................] - ETA: 0s - loss: 137947200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7317 - distribution_lambda_loss: 137947200.0000  36/122 [=======>......................] - ETA: 0s - loss: 137518048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5199 - distribution_lambda_loss: 137518048.0000 41/122 [=========>....................] - ETA: 0s - loss: 137405376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5783 - distribution_lambda_loss: 137405376.0000 46/122 [==========>...................] - ETA: 0s - loss: 138264960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7861 - distribution_lambda_loss: 138264960.0000 51/122 [===========>..................] - ETA: 0s - loss: 138261648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7972 - distribution_lambda_loss: 138261648.0000 56/122 [============>.................] - ETA: 0s - loss: 138374224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7163 - distribution_lambda_loss: 138374224.0000 61/122 [==============>...............] - ETA: 0s - loss: 138690160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8281 - distribution_lambda_loss: 138690160.0000 66/122 [===============>..............] - ETA: 0s - loss: 138557120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7637 - distribution_lambda_loss: 138557120.0000 71/122 [================>.............] - ETA: 0s - loss: 138542848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7964 - distribution_lambda_loss: 138542848.0000 76/122 [=================>............] - ETA: 0s - loss: 137965408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5801 - distribution_lambda_loss: 137965408.0000 81/122 [==================>...........] - ETA: 0s - loss: 137622992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4352 - distribution_lambda_loss: 137622992.0000 86/122 [====================>.........] - ETA: 0s - loss: 137440640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3706 - distribution_lambda_loss: 137440640.0000 91/122 [=====================>........] - ETA: 0s - loss: 137441536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3750 - distribution_lambda_loss: 137441536.0000 96/122 [======================>.......] - ETA: 0s - loss: 137790448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5150 - distribution_lambda_loss: 137790448.0000101/122 [=======================>......] - ETA: 0s - loss: 137767792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5448 - distribution_lambda_loss: 137767792.0000106/122 [=========================>....] - ETA: 0s - loss: 137981376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6166 - distribution_lambda_loss: 137981376.0000111/122 [==========================>...] - ETA: 0s - loss: 138201216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7118 - distribution_lambda_loss: 138201216.0000116/122 [===========================>..] - ETA: 0s - loss: 137904336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6026 - distribution_lambda_loss: 137904336.0000121/122 [============================>.] - ETA: 0s - loss: 138231712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7405 - distribution_lambda_loss: 138231712.0000122/122 [==============================] - 1s 11ms/step - loss: 138250176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7417 - distribution_lambda_loss: 138250176.0000 - val_loss: 143658208.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 99.9420 - val_distribution_lambda_loss: 143658208.0000 - lr: 2.5000e-04
Epoch 29/50
  1/122 [..............................] - ETA: 1s - loss: 157703088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.1900 - distribution_lambda_loss: 157703088.0000  6/122 [>.............................] - ETA: 1s - loss: 136643440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2683 - distribution_lambda_loss: 136643440.0000  11/122 [=>............................] - ETA: 1s - loss: 142837808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6667 - distribution_lambda_loss: 142837808.0000 16/122 [==>...........................] - ETA: 1s - loss: 138263712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7268 - distribution_lambda_loss: 138263712.0000  21/122 [====>.........................] - ETA: 1s - loss: 139663200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2404 - distribution_lambda_loss: 139663200.0000 26/122 [=====>........................] - ETA: 1s - loss: 140107120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1970 - distribution_lambda_loss: 140107120.0000 31/122 [======>.......................] - ETA: 0s - loss: 139059120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8676 - distribution_lambda_loss: 139059120.0000  36/122 [=======>......................] - ETA: 0s - loss: 138970240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8656 - distribution_lambda_loss: 138970240.0000 41/122 [=========>....................] - ETA: 0s - loss: 137624816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4162 - distribution_lambda_loss: 137624816.0000 46/122 [==========>...................] - ETA: 0s - loss: 137637584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4430 - distribution_lambda_loss: 137637584.0000 51/122 [===========>..................] - ETA: 0s - loss: 137904256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6408 - distribution_lambda_loss: 137904256.0000 56/122 [============>.................] - ETA: 0s - loss: 138304896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7166 - distribution_lambda_loss: 138304896.0000 61/122 [==============>...............] - ETA: 0s - loss: 138528128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8639 - distribution_lambda_loss: 138528128.0000 66/122 [===============>..............] - ETA: 0s - loss: 138214160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7424 - distribution_lambda_loss: 138214160.0000 71/122 [================>.............] - ETA: 0s - loss: 138105984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6902 - distribution_lambda_loss: 138105984.0000 76/122 [=================>............] - ETA: 0s - loss: 138462320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9005 - distribution_lambda_loss: 138462320.0000 81/122 [==================>...........] - ETA: 0s - loss: 138669632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9231 - distribution_lambda_loss: 138669632.0000 86/122 [====================>.........] - ETA: 0s - loss: 138245360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7265 - distribution_lambda_loss: 138245360.0000 91/122 [=====================>........] - ETA: 0s - loss: 138012032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6432 - distribution_lambda_loss: 138012032.0000 96/122 [======================>.......] - ETA: 0s - loss: 137809104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5358 - distribution_lambda_loss: 137809104.0000101/122 [=======================>......] - ETA: 0s - loss: 137534848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4645 - distribution_lambda_loss: 137534848.0000106/122 [=========================>....] - ETA: 0s - loss: 137504080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4616 - distribution_lambda_loss: 137504080.0000111/122 [==========================>...] - ETA: 0s - loss: 137902608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6285 - distribution_lambda_loss: 137902608.0000116/122 [===========================>..] - ETA: 0s - loss: 138260928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7480 - distribution_lambda_loss: 138260928.0000121/122 [============================>.] - ETA: 0s - loss: 138124672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6943 - distribution_lambda_loss: 138124672.0000122/122 [==============================] - 1s 11ms/step - loss: 138033120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6649 - distribution_lambda_loss: 138033120.0000 - val_loss: 143869248.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.6573 - val_distribution_lambda_loss: 143869248.0000 - lr: 2.5000e-04
Epoch 30/50
  1/122 [..............................] - ETA: 1s - loss: 138756544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5093 - distribution_lambda_loss: 138756544.0000  6/122 [>.............................] - ETA: 1s - loss: 144288464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.3479 - distribution_lambda_loss: 144288464.0000 11/122 [=>............................] - ETA: 1s - loss: 139953728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8945 - distribution_lambda_loss: 139953728.0000  16/122 [==>...........................] - ETA: 1s - loss: 139012048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9036 - distribution_lambda_loss: 139012048.0000 21/122 [====>.........................] - ETA: 1s - loss: 138285648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5109 - distribution_lambda_loss: 138285648.0000 26/122 [=====>........................] - ETA: 0s - loss: 136910352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2318 - distribution_lambda_loss: 136910352.0000 31/122 [======>.......................] - ETA: 0s - loss: 138402064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7575 - distribution_lambda_loss: 138402064.0000 36/122 [=======>......................] - ETA: 0s - loss: 137683200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4997 - distribution_lambda_loss: 137683200.0000 41/122 [=========>....................] - ETA: 0s - loss: 137881280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6144 - distribution_lambda_loss: 137881280.0000 46/122 [==========>...................] - ETA: 0s - loss: 137847216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6183 - distribution_lambda_loss: 137847216.0000 51/122 [===========>..................] - ETA: 0s - loss: 137962608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7092 - distribution_lambda_loss: 137962608.0000 56/122 [============>.................] - ETA: 0s - loss: 137741200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6397 - distribution_lambda_loss: 137741200.0000 61/122 [==============>...............] - ETA: 0s - loss: 137700976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5993 - distribution_lambda_loss: 137700976.0000 66/122 [===============>..............] - ETA: 0s - loss: 137408384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4252 - distribution_lambda_loss: 137408384.0000 71/122 [================>.............] - ETA: 0s - loss: 137390272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4690 - distribution_lambda_loss: 137390272.0000 76/122 [=================>............] - ETA: 0s - loss: 137604288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5426 - distribution_lambda_loss: 137604288.0000 81/122 [==================>...........] - ETA: 0s - loss: 138129296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7424 - distribution_lambda_loss: 138129296.0000 86/122 [====================>.........] - ETA: 0s - loss: 138315648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8018 - distribution_lambda_loss: 138315648.0000 91/122 [=====================>........] - ETA: 0s - loss: 137673360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5526 - distribution_lambda_loss: 137673360.0000 96/122 [======================>.......] - ETA: 0s - loss: 136945904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3036 - distribution_lambda_loss: 136945904.0000101/122 [=======================>......] - ETA: 0s - loss: 137044032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3380 - distribution_lambda_loss: 137044032.0000106/122 [=========================>....] - ETA: 0s - loss: 137493760.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5007 - distribution_lambda_loss: 137493760.0000111/122 [==========================>...] - ETA: 0s - loss: 137219008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4038 - distribution_lambda_loss: 137219008.0000116/122 [===========================>..] - ETA: 0s - loss: 137645376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5621 - distribution_lambda_loss: 137645376.0000121/122 [============================>.] - ETA: 0s - loss: 137965632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6978 - distribution_lambda_loss: 137965632.0000122/122 [==============================] - 1s 11ms/step - loss: 137881392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6708 - distribution_lambda_loss: 137881392.0000 - val_loss: 143465264.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.7978 - val_distribution_lambda_loss: 143465264.0000 - lr: 2.5000e-04
Epoch 31/50
  1/122 [..............................] - ETA: 1s - loss: 126945744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.2485 - distribution_lambda_loss: 126945744.0000  6/122 [>.............................] - ETA: 1s - loss: 136344208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4677 - distribution_lambda_loss: 136344208.0000 11/122 [=>............................] - ETA: 1s - loss: 134219968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1080 - distribution_lambda_loss: 134219968.0000 16/122 [==>...........................] - ETA: 1s - loss: 133430632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9648 - distribution_lambda_loss: 133430632.0000 21/122 [====>.........................] - ETA: 1s - loss: 133383056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8102 - distribution_lambda_loss: 133383056.0000 26/122 [=====>........................] - ETA: 0s - loss: 134756992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3771 - distribution_lambda_loss: 134756992.0000 31/122 [======>.......................] - ETA: 0s - loss: 136175184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7898 - distribution_lambda_loss: 136175184.0000 36/122 [=======>......................] - ETA: 0s - loss: 136530880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9077 - distribution_lambda_loss: 136530880.0000 41/122 [=========>....................] - ETA: 0s - loss: 136901712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0137 - distribution_lambda_loss: 136901712.0000 46/122 [==========>...................] - ETA: 0s - loss: 136845088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1611 - distribution_lambda_loss: 136845088.0000 51/122 [===========>..................] - ETA: 0s - loss: 137273728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3182 - distribution_lambda_loss: 137273728.0000 56/122 [============>.................] - ETA: 0s - loss: 137194208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2840 - distribution_lambda_loss: 137194208.0000 61/122 [==============>...............] - ETA: 0s - loss: 137339776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3698 - distribution_lambda_loss: 137339776.0000 66/122 [===============>..............] - ETA: 0s - loss: 137629648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4573 - distribution_lambda_loss: 137629648.0000 71/122 [================>.............] - ETA: 0s - loss: 138161552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7412 - distribution_lambda_loss: 138161552.0000 76/122 [=================>............] - ETA: 0s - loss: 137927632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6132 - distribution_lambda_loss: 137927632.0000 81/122 [==================>...........] - ETA: 0s - loss: 138412048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8331 - distribution_lambda_loss: 138412048.0000 86/122 [====================>.........] - ETA: 0s - loss: 137964704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6635 - distribution_lambda_loss: 137964704.0000 91/122 [=====================>........] - ETA: 0s - loss: 137423648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5012 - distribution_lambda_loss: 137423648.0000 96/122 [======================>.......] - ETA: 0s - loss: 137752288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5949 - distribution_lambda_loss: 137752288.0000101/122 [=======================>......] - ETA: 0s - loss: 137766880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6142 - distribution_lambda_loss: 137766880.0000106/122 [=========================>....] - ETA: 0s - loss: 137798784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5702 - distribution_lambda_loss: 137798784.0000111/122 [==========================>...] - ETA: 0s - loss: 138530720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8655 - distribution_lambda_loss: 138530720.0000116/122 [===========================>..] - ETA: 0s - loss: 138543808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8838 - distribution_lambda_loss: 138543808.0000121/122 [============================>.] - ETA: 0s - loss: 138462432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8527 - distribution_lambda_loss: 138462432.0000122/122 [==============================] - 1s 11ms/step - loss: 138318112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8075 - distribution_lambda_loss: 138318112.0000 - val_loss: 143333712.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.8739 - val_distribution_lambda_loss: 143333712.0000 - lr: 2.5000e-04
Epoch 32/50
  1/122 [..............................] - ETA: 1s - loss: 144606528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.7556 - distribution_lambda_loss: 144606528.0000  6/122 [>.............................] - ETA: 1s - loss: 145709312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.5598 - distribution_lambda_loss: 145709312.0000 11/122 [=>............................] - ETA: 1s - loss: 141769392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1136 - distribution_lambda_loss: 141769392.0000 16/122 [==>...........................] - ETA: 1s - loss: 137114880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3427 - distribution_lambda_loss: 137114880.0000  21/122 [====>.........................] - ETA: 1s - loss: 134805936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5535 - distribution_lambda_loss: 134805936.0000 26/122 [=====>........................] - ETA: 0s - loss: 134657824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4000 - distribution_lambda_loss: 134657824.0000 31/122 [======>.......................] - ETA: 0s - loss: 134435712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3805 - distribution_lambda_loss: 134435712.0000 36/122 [=======>......................] - ETA: 0s - loss: 135301680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6295 - distribution_lambda_loss: 135301680.0000 41/122 [=========>....................] - ETA: 0s - loss: 136655104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1638 - distribution_lambda_loss: 136655104.0000 46/122 [==========>...................] - ETA: 0s - loss: 137245088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4095 - distribution_lambda_loss: 137245088.0000 51/122 [===========>..................] - ETA: 0s - loss: 137273840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4169 - distribution_lambda_loss: 137273840.0000 56/122 [============>.................] - ETA: 0s - loss: 138333184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8168 - distribution_lambda_loss: 138333184.0000 61/122 [==============>...............] - ETA: 0s - loss: 137643712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5201 - distribution_lambda_loss: 137643712.0000 66/122 [===============>..............] - ETA: 0s - loss: 138480272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7668 - distribution_lambda_loss: 138480272.0000 71/122 [================>.............] - ETA: 0s - loss: 138163872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6466 - distribution_lambda_loss: 138163872.0000 76/122 [=================>............] - ETA: 0s - loss: 138447888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7581 - distribution_lambda_loss: 138447888.0000 81/122 [==================>...........] - ETA: 0s - loss: 139011504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9540 - distribution_lambda_loss: 139011504.0000 86/122 [====================>.........] - ETA: 0s - loss: 138830784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9311 - distribution_lambda_loss: 138830784.0000 91/122 [=====================>........] - ETA: 0s - loss: 138335424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7490 - distribution_lambda_loss: 138335424.0000 96/122 [======================>.......] - ETA: 0s - loss: 138226256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7754 - distribution_lambda_loss: 138226256.0000101/122 [=======================>......] - ETA: 0s - loss: 138232656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7569 - distribution_lambda_loss: 138232656.0000106/122 [=========================>....] - ETA: 0s - loss: 138237840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7741 - distribution_lambda_loss: 138237840.0000111/122 [==========================>...] - ETA: 0s - loss: 137915296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6555 - distribution_lambda_loss: 137915296.0000116/122 [===========================>..] - ETA: 0s - loss: 137760832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6160 - distribution_lambda_loss: 137760832.0000121/122 [============================>.] - ETA: 0s - loss: 137391376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4886 - distribution_lambda_loss: 137391376.0000122/122 [==============================] - 1s 11ms/step - loss: 137322032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4620 - distribution_lambda_loss: 137322032.0000 - val_loss: 143045328.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.4308 - val_distribution_lambda_loss: 143045328.0000 - lr: 2.5000e-04
Epoch 33/50
  1/122 [..............................] - ETA: 1s - loss: 127632128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.4507 - distribution_lambda_loss: 127632128.0000  6/122 [>.............................] - ETA: 1s - loss: 141634192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.0591 - distribution_lambda_loss: 141634192.0000 11/122 [=>............................] - ETA: 1s - loss: 139540016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3252 - distribution_lambda_loss: 139540016.0000 16/122 [==>...........................] - ETA: 1s - loss: 133957080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1090 - distribution_lambda_loss: 133957080.0000  21/122 [====>.........................] - ETA: 1s - loss: 136764592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2464 - distribution_lambda_loss: 136764592.0000 26/122 [=====>........................] - ETA: 0s - loss: 135850016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8519 - distribution_lambda_loss: 135850016.0000 31/122 [======>.......................] - ETA: 0s - loss: 136196800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0860 - distribution_lambda_loss: 136196800.0000 36/122 [=======>......................] - ETA: 0s - loss: 137062704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4060 - distribution_lambda_loss: 137062704.0000 41/122 [=========>....................] - ETA: 0s - loss: 137543120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5250 - distribution_lambda_loss: 137543120.0000 46/122 [==========>...................] - ETA: 0s - loss: 137571904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5146 - distribution_lambda_loss: 137571904.0000 51/122 [===========>..................] - ETA: 0s - loss: 138716608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9130 - distribution_lambda_loss: 138716608.0000 56/122 [============>.................] - ETA: 0s - loss: 139226656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1213 - distribution_lambda_loss: 139226656.0000 61/122 [==============>...............] - ETA: 0s - loss: 138922720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9824 - distribution_lambda_loss: 138922720.0000  66/122 [===============>..............] - ETA: 0s - loss: 138648304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9175 - distribution_lambda_loss: 138648304.0000 71/122 [================>.............] - ETA: 0s - loss: 139060304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1134 - distribution_lambda_loss: 139060304.0000 76/122 [=================>............] - ETA: 0s - loss: 138075520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.7624 - distribution_lambda_loss: 138075520.0000  81/122 [==================>...........] - ETA: 0s - loss: 137805184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6545 - distribution_lambda_loss: 137805184.0000 86/122 [====================>.........] - ETA: 0s - loss: 137505584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5617 - distribution_lambda_loss: 137505584.0000 91/122 [=====================>........] - ETA: 0s - loss: 137109488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4121 - distribution_lambda_loss: 137109488.0000 96/122 [======================>.......] - ETA: 0s - loss: 137152160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4487 - distribution_lambda_loss: 137152160.0000101/122 [=======================>......] - ETA: 0s - loss: 137385328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4849 - distribution_lambda_loss: 137385328.0000106/122 [=========================>....] - ETA: 0s - loss: 137541552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5715 - distribution_lambda_loss: 137541552.0000111/122 [==========================>...] - ETA: 0s - loss: 137568656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5595 - distribution_lambda_loss: 137568656.0000116/122 [===========================>..] - ETA: 0s - loss: 137193216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4094 - distribution_lambda_loss: 137193216.0000121/122 [============================>.] - ETA: 0s - loss: 136943040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3395 - distribution_lambda_loss: 136943040.0000122/122 [==============================] - 1s 11ms/step - loss: 136938816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3402 - distribution_lambda_loss: 136938816.0000 - val_loss: 143068384.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.1312 - val_distribution_lambda_loss: 143068384.0000 - lr: 2.5000e-04
Epoch 34/50
  1/122 [..............................] - ETA: 1s - loss: 127720224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.2173 - distribution_lambda_loss: 127720224.0000  6/122 [>.............................] - ETA: 1s - loss: 132500664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.3430 - distribution_lambda_loss: 132500664.0000 11/122 [=>............................] - ETA: 1s - loss: 136385456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6821 - distribution_lambda_loss: 136385456.0000 16/122 [==>...........................] - ETA: 1s - loss: 135991424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7604 - distribution_lambda_loss: 135991424.0000 21/122 [====>.........................] - ETA: 1s - loss: 135036496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7357 - distribution_lambda_loss: 135036496.0000 26/122 [=====>........................] - ETA: 0s - loss: 136408496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0888 - distribution_lambda_loss: 136408496.0000 31/122 [======>.......................] - ETA: 0s - loss: 136755616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2106 - distribution_lambda_loss: 136755616.0000 36/122 [=======>......................] - ETA: 0s - loss: 135632368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7047 - distribution_lambda_loss: 135632368.0000 41/122 [=========>....................] - ETA: 0s - loss: 135368400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6079 - distribution_lambda_loss: 135368400.0000 46/122 [==========>...................] - ETA: 0s - loss: 135601872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6569 - distribution_lambda_loss: 135601872.0000 51/122 [===========>..................] - ETA: 0s - loss: 136332400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9538 - distribution_lambda_loss: 136332400.0000 56/122 [============>.................] - ETA: 0s - loss: 136220096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9753 - distribution_lambda_loss: 136220096.0000 61/122 [==============>...............] - ETA: 0s - loss: 136093040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8900 - distribution_lambda_loss: 136093040.0000 66/122 [===============>..............] - ETA: 0s - loss: 136428528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1229 - distribution_lambda_loss: 136428528.0000 71/122 [================>.............] - ETA: 0s - loss: 137341184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4356 - distribution_lambda_loss: 137341184.0000 76/122 [=================>............] - ETA: 0s - loss: 137731920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6001 - distribution_lambda_loss: 137731920.0000 81/122 [==================>...........] - ETA: 0s - loss: 137356544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4441 - distribution_lambda_loss: 137356544.0000 86/122 [====================>.........] - ETA: 0s - loss: 137380656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5034 - distribution_lambda_loss: 137380656.0000 91/122 [=====================>........] - ETA: 0s - loss: 137232144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4126 - distribution_lambda_loss: 137232144.0000 96/122 [======================>.......] - ETA: 0s - loss: 137428432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5257 - distribution_lambda_loss: 137428432.0000101/122 [=======================>......] - ETA: 0s - loss: 137632000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6274 - distribution_lambda_loss: 137632000.0000106/122 [=========================>....] - ETA: 0s - loss: 137135984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4583 - distribution_lambda_loss: 137135984.0000111/122 [==========================>...] - ETA: 0s - loss: 136998080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4033 - distribution_lambda_loss: 136998080.0000116/122 [===========================>..] - ETA: 0s - loss: 137004512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3791 - distribution_lambda_loss: 137004512.0000121/122 [============================>.] - ETA: 0s - loss: 136922048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3734 - distribution_lambda_loss: 136922048.0000122/122 [==============================] - 1s 11ms/step - loss: 137010928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3995 - distribution_lambda_loss: 137010928.0000 - val_loss: 142261952.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.0962 - val_distribution_lambda_loss: 142261952.0000 - lr: 2.5000e-04
Epoch 35/50
  1/122 [..............................] - ETA: 1s - loss: 152835104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.4724 - distribution_lambda_loss: 152835104.0000  6/122 [>.............................] - ETA: 1s - loss: 132376512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1121 - distribution_lambda_loss: 132376512.0000  11/122 [=>............................] - ETA: 1s - loss: 135568784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8913 - distribution_lambda_loss: 135568784.0000 16/122 [==>...........................] - ETA: 1s - loss: 134039648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3678 - distribution_lambda_loss: 134039648.0000 21/122 [====>.........................] - ETA: 1s - loss: 133540928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2022 - distribution_lambda_loss: 133540928.0000 26/122 [=====>........................] - ETA: 0s - loss: 134807744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6262 - distribution_lambda_loss: 134807744.0000 31/122 [======>.......................] - ETA: 0s - loss: 134244896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4779 - distribution_lambda_loss: 134244896.0000 36/122 [=======>......................] - ETA: 0s - loss: 135743936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0426 - distribution_lambda_loss: 135743936.0000 41/122 [=========>....................] - ETA: 0s - loss: 136042080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0490 - distribution_lambda_loss: 136042080.0000 46/122 [==========>...................] - ETA: 0s - loss: 136022624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0768 - distribution_lambda_loss: 136022624.0000 51/122 [===========>..................] - ETA: 0s - loss: 136150544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1308 - distribution_lambda_loss: 136150544.0000 56/122 [============>.................] - ETA: 0s - loss: 135636528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0237 - distribution_lambda_loss: 135636528.0000 61/122 [==============>...............] - ETA: 0s - loss: 135608848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0145 - distribution_lambda_loss: 135608848.0000 66/122 [===============>..............] - ETA: 0s - loss: 135329184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9214 - distribution_lambda_loss: 135329184.0000 71/122 [================>.............] - ETA: 0s - loss: 135710752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0770 - distribution_lambda_loss: 135710752.0000 76/122 [=================>............] - ETA: 0s - loss: 136000160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0936 - distribution_lambda_loss: 136000160.0000 81/122 [==================>...........] - ETA: 0s - loss: 136287472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2175 - distribution_lambda_loss: 136287472.0000 86/122 [====================>.........] - ETA: 0s - loss: 136359584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2446 - distribution_lambda_loss: 136359584.0000 91/122 [=====================>........] - ETA: 0s - loss: 136357968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2515 - distribution_lambda_loss: 136357968.0000 96/122 [======================>.......] - ETA: 0s - loss: 136475248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2610 - distribution_lambda_loss: 136475248.0000101/122 [=======================>......] - ETA: 0s - loss: 136771840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3336 - distribution_lambda_loss: 136771840.0000106/122 [=========================>....] - ETA: 0s - loss: 136872944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3484 - distribution_lambda_loss: 136872944.0000111/122 [==========================>...] - ETA: 0s - loss: 137029232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4041 - distribution_lambda_loss: 137029232.0000116/122 [===========================>..] - ETA: 0s - loss: 137031248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4315 - distribution_lambda_loss: 137031248.0000121/122 [============================>.] - ETA: 0s - loss: 136847184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3543 - distribution_lambda_loss: 136847184.0000122/122 [==============================] - 1s 11ms/step - loss: 136704544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3011 - distribution_lambda_loss: 136704544.0000 - val_loss: 142735776.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 99.0849 - val_distribution_lambda_loss: 142735776.0000 - lr: 2.5000e-04
Epoch 36/50
  1/122 [..............................] - ETA: 1s - loss: 147886144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8232 - distribution_lambda_loss: 147886144.0000  6/122 [>.............................] - ETA: 1s - loss: 134692208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9770 - distribution_lambda_loss: 134692208.0000 11/122 [=>............................] - ETA: 1s - loss: 138738144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8024 - distribution_lambda_loss: 138738144.0000 16/122 [==>...........................] - ETA: 1s - loss: 140630656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9126 - distribution_lambda_loss: 140630656.0000 21/122 [====>.........................] - ETA: 1s - loss: 138314416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.0010 - distribution_lambda_loss: 138314416.0000 26/122 [=====>........................] - ETA: 0s - loss: 134508144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7874 - distribution_lambda_loss: 134508144.0000  31/122 [======>.......................] - ETA: 0s - loss: 134533264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6314 - distribution_lambda_loss: 134533264.0000 36/122 [=======>......................] - ETA: 0s - loss: 135420688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9786 - distribution_lambda_loss: 135420688.0000 41/122 [=========>....................] - ETA: 0s - loss: 134787152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7646 - distribution_lambda_loss: 134787152.0000 46/122 [==========>...................] - ETA: 0s - loss: 134191056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4628 - distribution_lambda_loss: 134191056.0000 51/122 [===========>..................] - ETA: 0s - loss: 134855792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7247 - distribution_lambda_loss: 134855792.0000 56/122 [============>.................] - ETA: 0s - loss: 135439168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8868 - distribution_lambda_loss: 135439168.0000 61/122 [==============>...............] - ETA: 0s - loss: 134678784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6784 - distribution_lambda_loss: 134678784.0000 66/122 [===============>..............] - ETA: 0s - loss: 134825824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7424 - distribution_lambda_loss: 134825824.0000 71/122 [================>.............] - ETA: 0s - loss: 134882384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7391 - distribution_lambda_loss: 134882384.0000 76/122 [=================>............] - ETA: 0s - loss: 135631984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9865 - distribution_lambda_loss: 135631984.0000 81/122 [==================>...........] - ETA: 0s - loss: 135073200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7391 - distribution_lambda_loss: 135073200.0000 86/122 [====================>.........] - ETA: 0s - loss: 135358224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8198 - distribution_lambda_loss: 135358224.0000 91/122 [=====================>........] - ETA: 0s - loss: 135993328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0328 - distribution_lambda_loss: 135993328.0000 96/122 [======================>.......] - ETA: 0s - loss: 135984752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0321 - distribution_lambda_loss: 135984752.0000101/122 [=======================>......] - ETA: 0s - loss: 136861728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3403 - distribution_lambda_loss: 136861728.0000106/122 [=========================>....] - ETA: 0s - loss: 137000672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3918 - distribution_lambda_loss: 137000672.0000111/122 [==========================>...] - ETA: 0s - loss: 137035792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4304 - distribution_lambda_loss: 137035792.0000116/122 [===========================>..] - ETA: 0s - loss: 136616816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2611 - distribution_lambda_loss: 136616816.0000121/122 [============================>.] - ETA: 0s - loss: 136427088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1881 - distribution_lambda_loss: 136427088.0000122/122 [==============================] - 1s 11ms/step - loss: 136451584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1945 - distribution_lambda_loss: 136451584.0000 - val_loss: 141807328.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.1856 - val_distribution_lambda_loss: 141807328.0000 - lr: 2.5000e-04
Epoch 37/50
  1/122 [..............................] - ETA: 1s - loss: 138476576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2644 - distribution_lambda_loss: 138476576.0000  6/122 [>.............................] - ETA: 1s - loss: 138682576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2820 - distribution_lambda_loss: 138682576.0000 11/122 [=>............................] - ETA: 1s - loss: 138463600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9629 - distribution_lambda_loss: 138463600.0000  16/122 [==>...........................] - ETA: 1s - loss: 135967872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0540 - distribution_lambda_loss: 135967872.0000 21/122 [====>.........................] - ETA: 1s - loss: 136424720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3198 - distribution_lambda_loss: 136424720.0000 26/122 [=====>........................] - ETA: 0s - loss: 135792736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0839 - distribution_lambda_loss: 135792736.0000 31/122 [======>.......................] - ETA: 0s - loss: 136573584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2819 - distribution_lambda_loss: 136573584.0000 36/122 [=======>......................] - ETA: 0s - loss: 136140256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0687 - distribution_lambda_loss: 136140256.0000 41/122 [=========>....................] - ETA: 0s - loss: 136115632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0892 - distribution_lambda_loss: 136115632.0000 46/122 [==========>...................] - ETA: 0s - loss: 135809584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9815 - distribution_lambda_loss: 135809584.0000 51/122 [===========>..................] - ETA: 0s - loss: 136558448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2210 - distribution_lambda_loss: 136558448.0000 56/122 [============>.................] - ETA: 0s - loss: 136090832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0844 - distribution_lambda_loss: 136090832.0000 61/122 [==============>...............] - ETA: 0s - loss: 136790096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2994 - distribution_lambda_loss: 136790096.0000 66/122 [===============>..............] - ETA: 0s - loss: 137271552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4075 - distribution_lambda_loss: 137271552.0000 71/122 [================>.............] - ETA: 0s - loss: 137981344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.6963 - distribution_lambda_loss: 137981344.0000 76/122 [=================>............] - ETA: 0s - loss: 137462144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4865 - distribution_lambda_loss: 137462144.0000 81/122 [==================>...........] - ETA: 0s - loss: 137202976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4591 - distribution_lambda_loss: 137202976.0000 86/122 [====================>.........] - ETA: 0s - loss: 136873072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3332 - distribution_lambda_loss: 136873072.0000 91/122 [=====================>........] - ETA: 0s - loss: 137267792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5317 - distribution_lambda_loss: 137267792.0000 96/122 [======================>.......] - ETA: 0s - loss: 137358256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5455 - distribution_lambda_loss: 137358256.0000101/122 [=======================>......] - ETA: 0s - loss: 136932704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3817 - distribution_lambda_loss: 136932704.0000106/122 [=========================>....] - ETA: 0s - loss: 136965616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4188 - distribution_lambda_loss: 136965616.0000111/122 [==========================>...] - ETA: 0s - loss: 136753040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3445 - distribution_lambda_loss: 136753040.0000116/122 [===========================>..] - ETA: 0s - loss: 136558400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2862 - distribution_lambda_loss: 136558400.0000121/122 [============================>.] - ETA: 0s - loss: 136371856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2190 - distribution_lambda_loss: 136371856.0000122/122 [==============================] - 1s 11ms/step - loss: 136284416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1895 - distribution_lambda_loss: 136284416.0000 - val_loss: 141360512.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 99.9981 - val_distribution_lambda_loss: 141360512.0000 - lr: 2.5000e-04
Epoch 38/50
  1/122 [..............................] - ETA: 1s - loss: 141242208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8219 - distribution_lambda_loss: 141242208.0000  6/122 [>.............................] - ETA: 1s - loss: 143799088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.2190 - distribution_lambda_loss: 143799088.0000 11/122 [=>............................] - ETA: 1s - loss: 142809120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.8361 - distribution_lambda_loss: 142809120.0000 16/122 [==>...........................] - ETA: 1s - loss: 141615472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.1746 - distribution_lambda_loss: 141615472.0000 22/122 [====>.........................] - ETA: 1s - loss: 139941120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4310 - distribution_lambda_loss: 139941120.0000 27/122 [=====>........................] - ETA: 0s - loss: 139509488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3103 - distribution_lambda_loss: 139509488.0000 32/122 [======>.......................] - ETA: 0s - loss: 139549440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2479 - distribution_lambda_loss: 139549440.0000 37/122 [========>.....................] - ETA: 0s - loss: 140206144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.6136 - distribution_lambda_loss: 140206144.0000 42/122 [=========>....................] - ETA: 0s - loss: 138999136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.1886 - distribution_lambda_loss: 138999136.0000 47/122 [==========>...................] - ETA: 0s - loss: 137348048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5472 - distribution_lambda_loss: 137348048.0000  52/122 [===========>..................] - ETA: 0s - loss: 136958896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4384 - distribution_lambda_loss: 136958896.0000 57/122 [=============>................] - ETA: 0s - loss: 136562208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3289 - distribution_lambda_loss: 136562208.0000 62/122 [==============>...............] - ETA: 0s - loss: 136219840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2088 - distribution_lambda_loss: 136219840.0000 67/122 [===============>..............] - ETA: 0s - loss: 136433680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2881 - distribution_lambda_loss: 136433680.0000 72/122 [================>.............] - ETA: 0s - loss: 136533584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3259 - distribution_lambda_loss: 136533584.0000 77/122 [=================>............] - ETA: 0s - loss: 136292640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2955 - distribution_lambda_loss: 136292640.0000 82/122 [===================>..........] - ETA: 0s - loss: 135742208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0690 - distribution_lambda_loss: 135742208.0000 87/122 [====================>.........] - ETA: 0s - loss: 136019808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1406 - distribution_lambda_loss: 136019808.0000 92/122 [=====================>........] - ETA: 0s - loss: 136101536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1695 - distribution_lambda_loss: 136101536.0000 97/122 [======================>.......] - ETA: 0s - loss: 136372096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2151 - distribution_lambda_loss: 136372096.0000102/122 [========================>.....] - ETA: 0s - loss: 136412768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2824 - distribution_lambda_loss: 136412768.0000107/122 [=========================>....] - ETA: 0s - loss: 135778080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0100 - distribution_lambda_loss: 135778080.0000112/122 [==========================>...] - ETA: 0s - loss: 135760352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0054 - distribution_lambda_loss: 135760352.0000117/122 [===========================>..] - ETA: 0s - loss: 135919360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0594 - distribution_lambda_loss: 135919360.0000122/122 [==============================] - 1s 11ms/step - loss: 135963584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0741 - distribution_lambda_loss: 135963584.0000 - val_loss: 142170000.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.2612 - val_distribution_lambda_loss: 142170000.0000 - lr: 2.5000e-04
Epoch 39/50
  1/122 [..............................] - ETA: 1s - loss: 139371616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.2089 - distribution_lambda_loss: 139371616.0000  6/122 [>.............................] - ETA: 1s - loss: 140467456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.9223 - distribution_lambda_loss: 140467456.0000 11/122 [=>............................] - ETA: 1s - loss: 142864144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 101.6276 - distribution_lambda_loss: 142864144.0000 16/122 [==>...........................] - ETA: 1s - loss: 140045392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.4589 - distribution_lambda_loss: 140045392.0000 21/122 [====>.........................] - ETA: 1s - loss: 139615952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 100.3349 - distribution_lambda_loss: 139615952.0000 26/122 [=====>........................] - ETA: 0s - loss: 138010944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8470 - distribution_lambda_loss: 138010944.0000  31/122 [======>.......................] - ETA: 0s - loss: 136791872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3681 - distribution_lambda_loss: 136791872.0000 36/122 [=======>......................] - ETA: 0s - loss: 136529344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.3428 - distribution_lambda_loss: 136529344.0000 41/122 [=========>....................] - ETA: 0s - loss: 136338464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2700 - distribution_lambda_loss: 136338464.0000 46/122 [==========>...................] - ETA: 0s - loss: 136777488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.4204 - distribution_lambda_loss: 136777488.0000 51/122 [===========>..................] - ETA: 0s - loss: 135710192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0211 - distribution_lambda_loss: 135710192.0000 56/122 [============>.................] - ETA: 0s - loss: 135596912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0187 - distribution_lambda_loss: 135596912.0000 61/122 [==============>...............] - ETA: 0s - loss: 135617488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0059 - distribution_lambda_loss: 135617488.0000 66/122 [===============>..............] - ETA: 0s - loss: 136200224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1725 - distribution_lambda_loss: 136200224.0000 71/122 [================>.............] - ETA: 0s - loss: 136415456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.2494 - distribution_lambda_loss: 136415456.0000 76/122 [=================>............] - ETA: 0s - loss: 135617984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0089 - distribution_lambda_loss: 135617984.0000 81/122 [==================>...........] - ETA: 0s - loss: 135367024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8790 - distribution_lambda_loss: 135367024.0000 86/122 [====================>.........] - ETA: 0s - loss: 135495808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9295 - distribution_lambda_loss: 135495808.0000 91/122 [=====================>........] - ETA: 0s - loss: 135366784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8582 - distribution_lambda_loss: 135366784.0000 96/122 [======================>.......] - ETA: 0s - loss: 135761936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0131 - distribution_lambda_loss: 135761936.0000101/122 [=======================>......] - ETA: 0s - loss: 135187952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7849 - distribution_lambda_loss: 135187952.0000106/122 [=========================>....] - ETA: 0s - loss: 135207296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7969 - distribution_lambda_loss: 135207296.0000111/122 [==========================>...] - ETA: 0s - loss: 135344112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8256 - distribution_lambda_loss: 135344112.0000116/122 [===========================>..] - ETA: 0s - loss: 135685184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9747 - distribution_lambda_loss: 135685184.0000121/122 [============================>.] - ETA: 0s - loss: 135746448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0385 - distribution_lambda_loss: 135746448.0000
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
122/122 [==============================] - 1s 11ms/step - loss: 135887328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0742 - distribution_lambda_loss: 135887328.0000 - val_loss: 141531536.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.5819 - val_distribution_lambda_loss: 141531536.0000 - lr: 2.5000e-04
Epoch 40/50
  1/122 [..............................] - ETA: 1s - loss: 125526992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.5408 - distribution_lambda_loss: 125526992.0000  6/122 [>.............................] - ETA: 1s - loss: 132909160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3886 - distribution_lambda_loss: 132909160.0000 11/122 [=>............................] - ETA: 1s - loss: 130882632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.6197 - distribution_lambda_loss: 130882632.0000 16/122 [==>...........................] - ETA: 1s - loss: 132870768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8926 - distribution_lambda_loss: 132870768.0000 21/122 [====>.........................] - ETA: 1s - loss: 132606552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9825 - distribution_lambda_loss: 132606552.0000 26/122 [=====>........................] - ETA: 0s - loss: 133560888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1247 - distribution_lambda_loss: 133560888.0000 31/122 [======>.......................] - ETA: 0s - loss: 134703952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5957 - distribution_lambda_loss: 134703952.0000 36/122 [=======>......................] - ETA: 0s - loss: 135019392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6721 - distribution_lambda_loss: 135019392.0000 41/122 [=========>....................] - ETA: 0s - loss: 135058544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7273 - distribution_lambda_loss: 135058544.0000 46/122 [==========>...................] - ETA: 0s - loss: 134468960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5091 - distribution_lambda_loss: 134468960.0000 51/122 [===========>..................] - ETA: 0s - loss: 135316960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8056 - distribution_lambda_loss: 135316960.0000 56/122 [============>.................] - ETA: 0s - loss: 135143536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6650 - distribution_lambda_loss: 135143536.0000 61/122 [==============>...............] - ETA: 0s - loss: 134169096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3131 - distribution_lambda_loss: 134169096.0000 66/122 [===============>..............] - ETA: 0s - loss: 133991704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3011 - distribution_lambda_loss: 133991704.0000 71/122 [================>.............] - ETA: 0s - loss: 133976168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2404 - distribution_lambda_loss: 133976168.0000 76/122 [=================>............] - ETA: 0s - loss: 134531728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4756 - distribution_lambda_loss: 134531728.0000 81/122 [==================>...........] - ETA: 0s - loss: 134581088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5448 - distribution_lambda_loss: 134581088.0000 86/122 [====================>.........] - ETA: 0s - loss: 135249968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7710 - distribution_lambda_loss: 135249968.0000 91/122 [=====================>........] - ETA: 0s - loss: 134976880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7094 - distribution_lambda_loss: 134976880.0000 96/122 [======================>.......] - ETA: 0s - loss: 135444240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8720 - distribution_lambda_loss: 135444240.0000101/122 [=======================>......] - ETA: 0s - loss: 135273232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8299 - distribution_lambda_loss: 135273232.0000106/122 [=========================>....] - ETA: 0s - loss: 135343168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8456 - distribution_lambda_loss: 135343168.0000111/122 [==========================>...] - ETA: 0s - loss: 135283456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8338 - distribution_lambda_loss: 135283456.0000116/122 [===========================>..] - ETA: 0s - loss: 134913776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7304 - distribution_lambda_loss: 134913776.0000121/122 [============================>.] - ETA: 0s - loss: 135007360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7861 - distribution_lambda_loss: 135007360.0000122/122 [==============================] - 1s 11ms/step - loss: 134995616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7896 - distribution_lambda_loss: 134995616.0000 - val_loss: 140786240.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.6696 - val_distribution_lambda_loss: 140786240.0000 - lr: 1.2500e-04
Epoch 41/50
  1/122 [..............................] - ETA: 1s - loss: 145505808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 102.4278 - distribution_lambda_loss: 145505808.0000  6/122 [>.............................] - ETA: 1s - loss: 135623232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4998 - distribution_lambda_loss: 135623232.0000  11/122 [=>............................] - ETA: 1s - loss: 133445656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9638 - distribution_lambda_loss: 133445656.0000 16/122 [==>...........................] - ETA: 1s - loss: 133186736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0084 - distribution_lambda_loss: 133186736.0000 21/122 [====>.........................] - ETA: 1s - loss: 133517920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2058 - distribution_lambda_loss: 133517920.0000 26/122 [=====>........................] - ETA: 0s - loss: 132947200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9730 - distribution_lambda_loss: 132947200.0000 31/122 [======>.......................] - ETA: 0s - loss: 133496536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3474 - distribution_lambda_loss: 133496536.0000 36/122 [=======>......................] - ETA: 0s - loss: 134000000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4024 - distribution_lambda_loss: 134000000.0000 41/122 [=========>....................] - ETA: 0s - loss: 133697224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3389 - distribution_lambda_loss: 133697224.0000 46/122 [==========>...................] - ETA: 0s - loss: 134197360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4932 - distribution_lambda_loss: 134197360.0000 51/122 [===========>..................] - ETA: 0s - loss: 134792368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6713 - distribution_lambda_loss: 134792368.0000 56/122 [============>.................] - ETA: 0s - loss: 134126144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4317 - distribution_lambda_loss: 134126144.0000 61/122 [==============>...............] - ETA: 0s - loss: 134848272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6900 - distribution_lambda_loss: 134848272.0000 66/122 [===============>..............] - ETA: 0s - loss: 134986352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7687 - distribution_lambda_loss: 134986352.0000 71/122 [================>.............] - ETA: 0s - loss: 135114128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7911 - distribution_lambda_loss: 135114128.0000 76/122 [=================>............] - ETA: 0s - loss: 135397648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9093 - distribution_lambda_loss: 135397648.0000 81/122 [==================>...........] - ETA: 0s - loss: 135059904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7481 - distribution_lambda_loss: 135059904.0000 86/122 [====================>.........] - ETA: 0s - loss: 134640112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5780 - distribution_lambda_loss: 134640112.0000 91/122 [=====================>........] - ETA: 0s - loss: 134934976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7426 - distribution_lambda_loss: 134934976.0000 96/122 [======================>.......] - ETA: 0s - loss: 134824368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6493 - distribution_lambda_loss: 134824368.0000101/122 [=======================>......] - ETA: 0s - loss: 134736320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6016 - distribution_lambda_loss: 134736320.0000106/122 [=========================>....] - ETA: 0s - loss: 134447696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5717 - distribution_lambda_loss: 134447696.0000111/122 [==========================>...] - ETA: 0s - loss: 134740992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6709 - distribution_lambda_loss: 134740992.0000116/122 [===========================>..] - ETA: 0s - loss: 134708928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6796 - distribution_lambda_loss: 134708928.0000121/122 [============================>.] - ETA: 0s - loss: 134831856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7182 - distribution_lambda_loss: 134831856.0000122/122 [==============================] - 1s 11ms/step - loss: 134862672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7283 - distribution_lambda_loss: 134862672.0000 - val_loss: 141088256.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.0015 - val_distribution_lambda_loss: 141088256.0000 - lr: 1.2500e-04
Epoch 42/50
  1/122 [..............................] - ETA: 1s - loss: 136099744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9203 - distribution_lambda_loss: 136099744.0000  6/122 [>.............................] - ETA: 1s - loss: 128514232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.9762 - distribution_lambda_loss: 128514232.0000 11/122 [=>............................] - ETA: 1s - loss: 129806472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.8905 - distribution_lambda_loss: 129806472.0000 16/122 [==>...........................] - ETA: 1s - loss: 132784120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0484 - distribution_lambda_loss: 132784120.0000 21/122 [====>.........................] - ETA: 1s - loss: 132940432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9063 - distribution_lambda_loss: 132940432.0000 27/122 [=====>........................] - ETA: 0s - loss: 135916112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0187 - distribution_lambda_loss: 135916112.0000 32/122 [======>.......................] - ETA: 0s - loss: 134940304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5008 - distribution_lambda_loss: 134940304.0000 37/122 [========>.....................] - ETA: 0s - loss: 134678576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6636 - distribution_lambda_loss: 134678576.0000 42/122 [=========>....................] - ETA: 0s - loss: 135159040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8267 - distribution_lambda_loss: 135159040.0000 47/122 [==========>...................] - ETA: 0s - loss: 135239824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8703 - distribution_lambda_loss: 135239824.0000 52/122 [===========>..................] - ETA: 0s - loss: 135702304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1210 - distribution_lambda_loss: 135702304.0000 57/122 [=============>................] - ETA: 0s - loss: 135268048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0301 - distribution_lambda_loss: 135268048.0000 62/122 [==============>...............] - ETA: 0s - loss: 134938784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8511 - distribution_lambda_loss: 134938784.0000 67/122 [===============>..............] - ETA: 0s - loss: 134707488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7950 - distribution_lambda_loss: 134707488.0000 72/122 [================>.............] - ETA: 0s - loss: 135824128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1971 - distribution_lambda_loss: 135824128.0000 77/122 [=================>............] - ETA: 0s - loss: 135485328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0856 - distribution_lambda_loss: 135485328.0000 82/122 [===================>..........] - ETA: 0s - loss: 135313104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9716 - distribution_lambda_loss: 135313104.0000 87/122 [====================>.........] - ETA: 0s - loss: 135383888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9822 - distribution_lambda_loss: 135383888.0000 92/122 [=====================>........] - ETA: 0s - loss: 135565520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.0432 - distribution_lambda_loss: 135565520.0000 97/122 [======================>.......] - ETA: 0s - loss: 135284832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9184 - distribution_lambda_loss: 135284832.0000102/122 [========================>.....] - ETA: 0s - loss: 135418656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9748 - distribution_lambda_loss: 135418656.0000107/122 [=========================>....] - ETA: 0s - loss: 135241152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9235 - distribution_lambda_loss: 135241152.0000112/122 [==========================>...] - ETA: 0s - loss: 135050992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8562 - distribution_lambda_loss: 135050992.0000117/122 [===========================>..] - ETA: 0s - loss: 134933904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7994 - distribution_lambda_loss: 134933904.0000122/122 [==============================] - ETA: 0s - loss: 134656368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6905 - distribution_lambda_loss: 134656368.0000122/122 [==============================] - 1s 11ms/step - loss: 134656368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6905 - distribution_lambda_loss: 134656368.0000 - val_loss: 140759264.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.1134 - val_distribution_lambda_loss: 140759264.0000 - lr: 1.2500e-04
Epoch 43/50
  1/122 [..............................] - ETA: 1s - loss: 150272832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 105.0094 - distribution_lambda_loss: 150272832.0000  6/122 [>.............................] - ETA: 1s - loss: 137078256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.5637 - distribution_lambda_loss: 137078256.0000  11/122 [=>............................] - ETA: 1s - loss: 131682360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.3527 - distribution_lambda_loss: 131682360.0000 16/122 [==>...........................] - ETA: 1s - loss: 132022408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.5488 - distribution_lambda_loss: 132022408.0000 21/122 [====>.........................] - ETA: 1s - loss: 133715496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1869 - distribution_lambda_loss: 133715496.0000 26/122 [=====>........................] - ETA: 0s - loss: 134264048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4603 - distribution_lambda_loss: 134264048.0000 31/122 [======>.......................] - ETA: 0s - loss: 134396160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4550 - distribution_lambda_loss: 134396160.0000 36/122 [=======>......................] - ETA: 0s - loss: 134388096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5256 - distribution_lambda_loss: 134388096.0000 41/122 [=========>....................] - ETA: 0s - loss: 135310928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8549 - distribution_lambda_loss: 135310928.0000 46/122 [==========>...................] - ETA: 0s - loss: 134323664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6370 - distribution_lambda_loss: 134323664.0000 51/122 [===========>..................] - ETA: 0s - loss: 134421088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6309 - distribution_lambda_loss: 134421088.0000 56/122 [============>.................] - ETA: 0s - loss: 133840264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4124 - distribution_lambda_loss: 133840264.0000 61/122 [==============>...............] - ETA: 0s - loss: 134129600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5204 - distribution_lambda_loss: 134129600.0000 66/122 [===============>..............] - ETA: 0s - loss: 134413504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5701 - distribution_lambda_loss: 134413504.0000 71/122 [================>.............] - ETA: 0s - loss: 134242960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5536 - distribution_lambda_loss: 134242960.0000 76/122 [=================>............] - ETA: 0s - loss: 133813800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3719 - distribution_lambda_loss: 133813800.0000 81/122 [==================>...........] - ETA: 0s - loss: 133759864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3386 - distribution_lambda_loss: 133759864.0000 86/122 [====================>.........] - ETA: 0s - loss: 134061768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4489 - distribution_lambda_loss: 134061768.0000 91/122 [=====================>........] - ETA: 0s - loss: 134173944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5059 - distribution_lambda_loss: 134173944.0000 96/122 [======================>.......] - ETA: 0s - loss: 134003224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4502 - distribution_lambda_loss: 134003224.0000101/122 [=======================>......] - ETA: 0s - loss: 133886344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4279 - distribution_lambda_loss: 133886344.0000106/122 [=========================>....] - ETA: 0s - loss: 133977032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4382 - distribution_lambda_loss: 133977032.0000111/122 [==========================>...] - ETA: 0s - loss: 134365200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5877 - distribution_lambda_loss: 134365200.0000116/122 [===========================>..] - ETA: 0s - loss: 134600176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6892 - distribution_lambda_loss: 134600176.0000121/122 [============================>.] - ETA: 0s - loss: 134424848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6142 - distribution_lambda_loss: 134424848.0000122/122 [==============================] - 1s 11ms/step - loss: 134555776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6544 - distribution_lambda_loss: 134555776.0000 - val_loss: 140892640.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 101.2568 - val_distribution_lambda_loss: 140892640.0000 - lr: 1.2500e-04
Epoch 44/50
  1/122 [..............................] - ETA: 1s - loss: 129715328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3154 - distribution_lambda_loss: 129715328.0000  6/122 [>.............................] - ETA: 1s - loss: 136315840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.8020 - distribution_lambda_loss: 136315840.0000 11/122 [=>............................] - ETA: 1s - loss: 136211392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1838 - distribution_lambda_loss: 136211392.0000 16/122 [==>...........................] - ETA: 1s - loss: 135019136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6631 - distribution_lambda_loss: 135019136.0000 21/122 [====>.........................] - ETA: 1s - loss: 135270432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7013 - distribution_lambda_loss: 135270432.0000 26/122 [=====>........................] - ETA: 0s - loss: 134220448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4038 - distribution_lambda_loss: 134220448.0000 31/122 [======>.......................] - ETA: 0s - loss: 134017888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2747 - distribution_lambda_loss: 134017888.0000 36/122 [=======>......................] - ETA: 0s - loss: 134593568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4913 - distribution_lambda_loss: 134593568.0000 41/122 [=========>....................] - ETA: 0s - loss: 134535360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4823 - distribution_lambda_loss: 134535360.0000 46/122 [==========>...................] - ETA: 0s - loss: 133908328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3027 - distribution_lambda_loss: 133908328.0000 51/122 [===========>..................] - ETA: 0s - loss: 133341496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0283 - distribution_lambda_loss: 133341496.0000 56/122 [============>.................] - ETA: 0s - loss: 133542744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1748 - distribution_lambda_loss: 133542744.0000 61/122 [==============>...............] - ETA: 0s - loss: 133282592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0970 - distribution_lambda_loss: 133282592.0000 66/122 [===============>..............] - ETA: 0s - loss: 133097736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0210 - distribution_lambda_loss: 133097736.0000 71/122 [================>.............] - ETA: 0s - loss: 134011200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4101 - distribution_lambda_loss: 134011200.0000 76/122 [=================>............] - ETA: 0s - loss: 133660696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2832 - distribution_lambda_loss: 133660696.0000 81/122 [==================>...........] - ETA: 0s - loss: 133883880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3670 - distribution_lambda_loss: 133883880.0000 86/122 [====================>.........] - ETA: 0s - loss: 133774792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3935 - distribution_lambda_loss: 133774792.0000 91/122 [=====================>........] - ETA: 0s - loss: 133811400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4100 - distribution_lambda_loss: 133811400.0000 96/122 [======================>.......] - ETA: 0s - loss: 133988064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5215 - distribution_lambda_loss: 133988064.0000101/122 [=======================>......] - ETA: 0s - loss: 134132056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5215 - distribution_lambda_loss: 134132056.0000106/122 [=========================>....] - ETA: 0s - loss: 134080096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4910 - distribution_lambda_loss: 134080096.0000111/122 [==========================>...] - ETA: 0s - loss: 134218736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5517 - distribution_lambda_loss: 134218736.0000116/122 [===========================>..] - ETA: 0s - loss: 134355248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5967 - distribution_lambda_loss: 134355248.0000121/122 [============================>.] - ETA: 0s - loss: 134470256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6494 - distribution_lambda_loss: 134470256.0000122/122 [==============================] - 1s 11ms/step - loss: 134437696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6420 - distribution_lambda_loss: 134437696.0000 - val_loss: 140303392.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.3051 - val_distribution_lambda_loss: 140303392.0000 - lr: 1.2500e-04
Epoch 45/50
  1/122 [..............................] - ETA: 1s - loss: 138487776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9930 - distribution_lambda_loss: 138487776.0000  6/122 [>.............................] - ETA: 1s - loss: 135615984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6393 - distribution_lambda_loss: 135615984.0000 11/122 [=>............................] - ETA: 1s - loss: 135149024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7252 - distribution_lambda_loss: 135149024.0000 16/122 [==>...........................] - ETA: 1s - loss: 132821608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.7375 - distribution_lambda_loss: 132821608.0000 21/122 [====>.........................] - ETA: 1s - loss: 134846752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5722 - distribution_lambda_loss: 134846752.0000 26/122 [=====>........................] - ETA: 0s - loss: 133885960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2004 - distribution_lambda_loss: 133885960.0000 31/122 [======>.......................] - ETA: 0s - loss: 134192080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5140 - distribution_lambda_loss: 134192080.0000 36/122 [=======>......................] - ETA: 0s - loss: 133682976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3547 - distribution_lambda_loss: 133682976.0000 41/122 [=========>....................] - ETA: 0s - loss: 133700768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4354 - distribution_lambda_loss: 133700768.0000 46/122 [==========>...................] - ETA: 0s - loss: 132695776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0064 - distribution_lambda_loss: 132695776.0000 51/122 [===========>..................] - ETA: 0s - loss: 133201080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2064 - distribution_lambda_loss: 133201080.0000 56/122 [============>.................] - ETA: 0s - loss: 132881872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0657 - distribution_lambda_loss: 132881872.0000 61/122 [==============>...............] - ETA: 0s - loss: 133002008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1644 - distribution_lambda_loss: 133002008.0000 66/122 [===============>..............] - ETA: 0s - loss: 133262864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2106 - distribution_lambda_loss: 133262864.0000 71/122 [================>.............] - ETA: 0s - loss: 133502168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2963 - distribution_lambda_loss: 133502168.0000 76/122 [=================>............] - ETA: 0s - loss: 134175592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5302 - distribution_lambda_loss: 134175592.0000 81/122 [==================>...........] - ETA: 0s - loss: 134852544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7470 - distribution_lambda_loss: 134852544.0000 86/122 [====================>.........] - ETA: 0s - loss: 134895936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7739 - distribution_lambda_loss: 134895936.0000 91/122 [=====================>........] - ETA: 0s - loss: 134613840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7188 - distribution_lambda_loss: 134613840.0000 96/122 [======================>.......] - ETA: 0s - loss: 134672560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7068 - distribution_lambda_loss: 134672560.0000101/122 [=======================>......] - ETA: 0s - loss: 134697952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7357 - distribution_lambda_loss: 134697952.0000106/122 [=========================>....] - ETA: 0s - loss: 134299264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5679 - distribution_lambda_loss: 134299264.0000111/122 [==========================>...] - ETA: 0s - loss: 133950224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4452 - distribution_lambda_loss: 133950224.0000116/122 [===========================>..] - ETA: 0s - loss: 134446016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6240 - distribution_lambda_loss: 134446016.0000121/122 [============================>.] - ETA: 0s - loss: 134474880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6446 - distribution_lambda_loss: 134474880.0000122/122 [==============================] - 1s 11ms/step - loss: 134484656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6512 - distribution_lambda_loss: 134484656.0000 - val_loss: 140188304.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.0350 - val_distribution_lambda_loss: 140188304.0000 - lr: 1.2500e-04
Epoch 46/50
  1/122 [..............................] - ETA: 1s - loss: 123191904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.4016 - distribution_lambda_loss: 123191904.0000  6/122 [>.............................] - ETA: 1s - loss: 128418136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.6596 - distribution_lambda_loss: 128418136.0000 11/122 [=>............................] - ETA: 1s - loss: 128311600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.3514 - distribution_lambda_loss: 128311600.0000 16/122 [==>...........................] - ETA: 1s - loss: 127322064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.9900 - distribution_lambda_loss: 127322064.0000 21/122 [====>.........................] - ETA: 1s - loss: 125922624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.3787 - distribution_lambda_loss: 125922624.0000 26/122 [=====>........................] - ETA: 0s - loss: 127514656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.9648 - distribution_lambda_loss: 127514656.0000 31/122 [======>.......................] - ETA: 0s - loss: 129364504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.6004 - distribution_lambda_loss: 129364504.0000 36/122 [=======>......................] - ETA: 0s - loss: 129552824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.6814 - distribution_lambda_loss: 129552824.0000 41/122 [=========>....................] - ETA: 0s - loss: 130976256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.2308 - distribution_lambda_loss: 130976256.0000 46/122 [==========>...................] - ETA: 0s - loss: 132029304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.7118 - distribution_lambda_loss: 132029304.0000 51/122 [===========>..................] - ETA: 0s - loss: 133147520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1451 - distribution_lambda_loss: 133147520.0000 56/122 [============>.................] - ETA: 0s - loss: 132813952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0344 - distribution_lambda_loss: 132813952.0000 61/122 [==============>...............] - ETA: 0s - loss: 132560224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9062 - distribution_lambda_loss: 132560224.0000 66/122 [===============>..............] - ETA: 0s - loss: 132104064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.7331 - distribution_lambda_loss: 132104064.0000 71/122 [================>.............] - ETA: 0s - loss: 131997712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.7237 - distribution_lambda_loss: 131997712.0000 76/122 [=================>............] - ETA: 0s - loss: 132266392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8386 - distribution_lambda_loss: 132266392.0000 81/122 [==================>...........] - ETA: 0s - loss: 132472400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9359 - distribution_lambda_loss: 132472400.0000 86/122 [====================>.........] - ETA: 0s - loss: 132464344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9214 - distribution_lambda_loss: 132464344.0000 91/122 [=====================>........] - ETA: 0s - loss: 132548888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9449 - distribution_lambda_loss: 132548888.0000 96/122 [======================>.......] - ETA: 0s - loss: 132686848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9948 - distribution_lambda_loss: 132686848.0000101/122 [=======================>......] - ETA: 0s - loss: 132842904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0637 - distribution_lambda_loss: 132842904.0000106/122 [=========================>....] - ETA: 0s - loss: 133157624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1917 - distribution_lambda_loss: 133157624.0000111/122 [==========================>...] - ETA: 0s - loss: 133569616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3563 - distribution_lambda_loss: 133569616.0000116/122 [===========================>..] - ETA: 0s - loss: 133782000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4247 - distribution_lambda_loss: 133782000.0000121/122 [============================>.] - ETA: 0s - loss: 134107472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5481 - distribution_lambda_loss: 134107472.0000122/122 [==============================] - 1s 11ms/step - loss: 134170312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5593 - distribution_lambda_loss: 134170312.0000 - val_loss: 140182992.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.1874 - val_distribution_lambda_loss: 140182992.0000 - lr: 1.2500e-04
Epoch 47/50
  1/122 [..............................] - ETA: 1s - loss: 133625376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.7246 - distribution_lambda_loss: 133625376.0000  6/122 [>.............................] - ETA: 1s - loss: 128343688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.8652 - distribution_lambda_loss: 128343688.0000 11/122 [=>............................] - ETA: 1s - loss: 130608280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.2207 - distribution_lambda_loss: 130608280.0000 16/122 [==>...........................] - ETA: 1s - loss: 132231128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.5595 - distribution_lambda_loss: 132231128.0000 21/122 [====>.........................] - ETA: 1s - loss: 133315368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9998 - distribution_lambda_loss: 133315368.0000 26/122 [=====>........................] - ETA: 0s - loss: 133387040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9843 - distribution_lambda_loss: 133387040.0000 31/122 [======>.......................] - ETA: 0s - loss: 133077928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0088 - distribution_lambda_loss: 133077928.0000 36/122 [=======>......................] - ETA: 0s - loss: 132825272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9409 - distribution_lambda_loss: 132825272.0000 41/122 [=========>....................] - ETA: 0s - loss: 133083400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1408 - distribution_lambda_loss: 133083400.0000 46/122 [==========>...................] - ETA: 0s - loss: 133430520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2213 - distribution_lambda_loss: 133430520.0000 51/122 [===========>..................] - ETA: 0s - loss: 132616104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9674 - distribution_lambda_loss: 132616104.0000 56/122 [============>.................] - ETA: 0s - loss: 132945336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1402 - distribution_lambda_loss: 132945336.0000 61/122 [==============>...............] - ETA: 0s - loss: 133815536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5165 - distribution_lambda_loss: 133815536.0000 66/122 [===============>..............] - ETA: 0s - loss: 133847768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5520 - distribution_lambda_loss: 133847768.0000 71/122 [================>.............] - ETA: 0s - loss: 134057880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6099 - distribution_lambda_loss: 134057880.0000 76/122 [=================>............] - ETA: 0s - loss: 134044912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5899 - distribution_lambda_loss: 134044912.0000 81/122 [==================>...........] - ETA: 0s - loss: 134392576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7165 - distribution_lambda_loss: 134392576.0000 86/122 [====================>.........] - ETA: 0s - loss: 134062768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6016 - distribution_lambda_loss: 134062768.0000 91/122 [=====================>........] - ETA: 0s - loss: 134533168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7646 - distribution_lambda_loss: 134533168.0000 96/122 [======================>.......] - ETA: 0s - loss: 134410912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6742 - distribution_lambda_loss: 134410912.0000101/122 [=======================>......] - ETA: 0s - loss: 134203232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6046 - distribution_lambda_loss: 134203232.0000106/122 [=========================>....] - ETA: 0s - loss: 134182400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5867 - distribution_lambda_loss: 134182400.0000111/122 [==========================>...] - ETA: 0s - loss: 134381264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6277 - distribution_lambda_loss: 134381264.0000116/122 [===========================>..] - ETA: 0s - loss: 134570672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6708 - distribution_lambda_loss: 134570672.0000121/122 [============================>.] - ETA: 0s - loss: 134140848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5409 - distribution_lambda_loss: 134140848.0000122/122 [==============================] - 1s 11ms/step - loss: 134104432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5241 - distribution_lambda_loss: 134104432.0000 - val_loss: 140057600.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.1306 - val_distribution_lambda_loss: 140057600.0000 - lr: 1.2500e-04
Epoch 48/50
  1/122 [..............................] - ETA: 1s - loss: 116280960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 93.0330 - distribution_lambda_loss: 116280960.0000  6/122 [>.............................] - ETA: 1s - loss: 121672184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 93.9059 - distribution_lambda_loss: 121672184.0000 11/122 [=>............................] - ETA: 1s - loss: 132083128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.6374 - distribution_lambda_loss: 132083128.0000 16/122 [==>...........................] - ETA: 1s - loss: 132247312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8751 - distribution_lambda_loss: 132247312.0000 21/122 [====>.........................] - ETA: 1s - loss: 133578800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3409 - distribution_lambda_loss: 133578800.0000 26/122 [=====>........................] - ETA: 0s - loss: 133521536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3786 - distribution_lambda_loss: 133521536.0000 31/122 [======>.......................] - ETA: 0s - loss: 133182008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0511 - distribution_lambda_loss: 133182008.0000 36/122 [=======>......................] - ETA: 0s - loss: 132455880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8059 - distribution_lambda_loss: 132455880.0000 41/122 [=========>....................] - ETA: 0s - loss: 132453376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8276 - distribution_lambda_loss: 132453376.0000 46/122 [==========>...................] - ETA: 0s - loss: 132085672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.7319 - distribution_lambda_loss: 132085672.0000 51/122 [===========>..................] - ETA: 0s - loss: 132969920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0145 - distribution_lambda_loss: 132969920.0000 56/122 [============>.................] - ETA: 0s - loss: 132749040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0224 - distribution_lambda_loss: 132749040.0000 61/122 [==============>...............] - ETA: 0s - loss: 132591440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9380 - distribution_lambda_loss: 132591440.0000 66/122 [===============>..............] - ETA: 0s - loss: 132759552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9911 - distribution_lambda_loss: 132759552.0000 71/122 [================>.............] - ETA: 0s - loss: 132871776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0368 - distribution_lambda_loss: 132871776.0000 76/122 [=================>............] - ETA: 0s - loss: 133241400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2075 - distribution_lambda_loss: 133241400.0000 81/122 [==================>...........] - ETA: 0s - loss: 133136312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1675 - distribution_lambda_loss: 133136312.0000 86/122 [====================>.........] - ETA: 0s - loss: 133393488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2030 - distribution_lambda_loss: 133393488.0000 91/122 [=====================>........] - ETA: 0s - loss: 132976224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0627 - distribution_lambda_loss: 132976224.0000 96/122 [======================>.......] - ETA: 0s - loss: 133361056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2276 - distribution_lambda_loss: 133361056.0000101/122 [=======================>......] - ETA: 0s - loss: 133700104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3524 - distribution_lambda_loss: 133700104.0000106/122 [=========================>....] - ETA: 0s - loss: 133867392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4059 - distribution_lambda_loss: 133867392.0000111/122 [==========================>...] - ETA: 0s - loss: 133939752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4708 - distribution_lambda_loss: 133939752.0000116/122 [===========================>..] - ETA: 0s - loss: 133902952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4385 - distribution_lambda_loss: 133902952.0000121/122 [============================>.] - ETA: 0s - loss: 134071280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5184 - distribution_lambda_loss: 134071280.0000122/122 [==============================] - 1s 11ms/step - loss: 133971816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4929 - distribution_lambda_loss: 133971816.0000 - val_loss: 140077616.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 99.4124 - val_distribution_lambda_loss: 140077616.0000 - lr: 1.2500e-04
Epoch 49/50
  1/122 [..............................] - ETA: 1s - loss: 141010432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.9880 - distribution_lambda_loss: 141010432.0000  6/122 [>.............................] - ETA: 1s - loss: 136258288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 99.1879 - distribution_lambda_loss: 136258288.0000 11/122 [=>............................] - ETA: 1s - loss: 132815384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1135 - distribution_lambda_loss: 132815384.0000 16/122 [==>...........................] - ETA: 1s - loss: 134536160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5819 - distribution_lambda_loss: 134536160.0000 21/122 [====>.........................] - ETA: 1s - loss: 133519168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.2691 - distribution_lambda_loss: 133519168.0000 26/122 [=====>........................] - ETA: 1s - loss: 134250816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5894 - distribution_lambda_loss: 134250816.0000 31/122 [======>.......................] - ETA: 0s - loss: 133977280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4872 - distribution_lambda_loss: 133977280.0000 36/122 [=======>......................] - ETA: 0s - loss: 134998400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7520 - distribution_lambda_loss: 134998400.0000 41/122 [=========>....................] - ETA: 0s - loss: 135029504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8476 - distribution_lambda_loss: 135029504.0000 46/122 [==========>...................] - ETA: 0s - loss: 134615472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6657 - distribution_lambda_loss: 134615472.0000 51/122 [===========>..................] - ETA: 0s - loss: 134890096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8340 - distribution_lambda_loss: 134890096.0000 56/122 [============>.................] - ETA: 0s - loss: 134586384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6525 - distribution_lambda_loss: 134586384.0000 61/122 [==============>...............] - ETA: 0s - loss: 134574496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6740 - distribution_lambda_loss: 134574496.0000 66/122 [===============>..............] - ETA: 0s - loss: 134907440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.7683 - distribution_lambda_loss: 134907440.0000 71/122 [================>.............] - ETA: 0s - loss: 134336000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6422 - distribution_lambda_loss: 134336000.0000 76/122 [=================>............] - ETA: 0s - loss: 134989456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9217 - distribution_lambda_loss: 134989456.0000 81/122 [==================>...........] - ETA: 0s - loss: 135169168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9815 - distribution_lambda_loss: 135169168.0000 86/122 [====================>.........] - ETA: 0s - loss: 135055664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.9030 - distribution_lambda_loss: 135055664.0000 91/122 [=====================>........] - ETA: 0s - loss: 134982144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8652 - distribution_lambda_loss: 134982144.0000 96/122 [======================>.......] - ETA: 0s - loss: 134869648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.8737 - distribution_lambda_loss: 134869648.0000101/122 [=======================>......] - ETA: 0s - loss: 134471920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6876 - distribution_lambda_loss: 134471920.0000106/122 [=========================>....] - ETA: 0s - loss: 133765696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4194 - distribution_lambda_loss: 133765696.0000111/122 [==========================>...] - ETA: 0s - loss: 133801672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4044 - distribution_lambda_loss: 133801672.0000116/122 [===========================>..] - ETA: 0s - loss: 134356720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.6065 - distribution_lambda_loss: 134356720.0000121/122 [============================>.] - ETA: 0s - loss: 134120152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5426 - distribution_lambda_loss: 134120152.0000
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001.
122/122 [==============================] - 1s 11ms/step - loss: 134031808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5087 - distribution_lambda_loss: 134031808.0000 - val_loss: 140190608.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 99.0818 - val_distribution_lambda_loss: 140190608.0000 - lr: 1.2500e-04
Epoch 50/50
  1/122 [..............................] - ETA: 1s - loss: 134951168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.7700 - distribution_lambda_loss: 134951168.0000  6/122 [>.............................] - ETA: 1s - loss: 130108408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 96.6972 - distribution_lambda_loss: 130108408.0000 11/122 [=>............................] - ETA: 1s - loss: 127916384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 95.8351 - distribution_lambda_loss: 127916384.0000 16/122 [==>...........................] - ETA: 1s - loss: 134117704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9870 - distribution_lambda_loss: 134117704.0000 21/122 [====>.........................] - ETA: 1s - loss: 133981528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1538 - distribution_lambda_loss: 133981528.0000 26/122 [=====>........................] - ETA: 0s - loss: 134755552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.5456 - distribution_lambda_loss: 134755552.0000 31/122 [======>.......................] - ETA: 0s - loss: 134158784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3226 - distribution_lambda_loss: 134158784.0000 36/122 [=======>......................] - ETA: 0s - loss: 132070400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.6331 - distribution_lambda_loss: 132070400.0000 41/122 [=========>....................] - ETA: 0s - loss: 131849656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.6239 - distribution_lambda_loss: 131849656.0000 46/122 [==========>...................] - ETA: 0s - loss: 132385272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8105 - distribution_lambda_loss: 132385272.0000 51/122 [===========>..................] - ETA: 0s - loss: 132595864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.9562 - distribution_lambda_loss: 132595864.0000 56/122 [============>.................] - ETA: 0s - loss: 132508656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0035 - distribution_lambda_loss: 132508656.0000 61/122 [==============>...............] - ETA: 0s - loss: 132959096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.1546 - distribution_lambda_loss: 132959096.0000 66/122 [===============>..............] - ETA: 0s - loss: 132689144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0516 - distribution_lambda_loss: 132689144.0000 71/122 [================>.............] - ETA: 0s - loss: 132039864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 97.8351 - distribution_lambda_loss: 132039864.0000 76/122 [=================>............] - ETA: 0s - loss: 132647600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0421 - distribution_lambda_loss: 132647600.0000 81/122 [==================>...........] - ETA: 0s - loss: 132748488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.0838 - distribution_lambda_loss: 132748488.0000 86/122 [====================>.........] - ETA: 0s - loss: 133464600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3515 - distribution_lambda_loss: 133464600.0000 91/122 [=====================>........] - ETA: 0s - loss: 133362000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3577 - distribution_lambda_loss: 133362000.0000 96/122 [======================>.......] - ETA: 0s - loss: 133505224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3988 - distribution_lambda_loss: 133505224.0000101/122 [=======================>......] - ETA: 0s - loss: 133832936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4660 - distribution_lambda_loss: 133832936.0000106/122 [=========================>....] - ETA: 0s - loss: 133599368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3857 - distribution_lambda_loss: 133599368.0000111/122 [==========================>...] - ETA: 0s - loss: 133647800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3993 - distribution_lambda_loss: 133647800.0000116/122 [===========================>..] - ETA: 0s - loss: 133509360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3230 - distribution_lambda_loss: 133509360.0000121/122 [============================>.] - ETA: 0s - loss: 133625528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.3869 - distribution_lambda_loss: 133625528.0000122/122 [==============================] - 1s 11ms/step - loss: 133693416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 98.4081 - distribution_lambda_loss: 133693416.0000 - val_loss: 139588912.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 100.3061 - val_distribution_lambda_loss: 139588912.0000 - lr: 1.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:32  5/322 [..............................] - ETA: 4s    9/322 [..............................] - ETA: 4s 13/322 [>.............................] - ETA: 4s 17/322 [>.............................] - ETA: 4s 21/322 [>.............................] - ETA: 4s 25/322 [=>............................] - ETA: 4s 28/322 [=>............................] - ETA: 4s 32/322 [=>............................] - ETA: 4s 36/322 [==>...........................] - ETA: 4s 40/322 [==>...........................] - ETA: 4s 44/322 [===>..........................] - ETA: 4s 48/322 [===>..........................] - ETA: 4s 52/322 [===>..........................] - ETA: 4s 55/322 [====>.........................] - ETA: 4s 59/322 [====>.........................] - ETA: 4s 63/322 [====>.........................] - ETA: 4s 67/322 [=====>........................] - ETA: 4s 71/322 [=====>........................] - ETA: 3s 75/322 [=====>........................] - ETA: 3s 79/322 [======>.......................] - ETA: 3s 83/322 [======>.......................] - ETA: 3s 87/322 [=======>......................] - ETA: 3s 91/322 [=======>......................] - ETA: 3s 95/322 [=======>......................] - ETA: 3s 98/322 [========>.....................] - ETA: 3s102/322 [========>.....................] - ETA: 3s106/322 [========>.....................] - ETA: 3s109/322 [=========>....................] - ETA: 3s113/322 [=========>....................] - ETA: 3s117/322 [=========>....................] - ETA: 3s121/322 [==========>...................] - ETA: 3s125/322 [==========>...................] - ETA: 3s129/322 [===========>..................] - ETA: 3s133/322 [===========>..................] - ETA: 2s136/322 [===========>..................] - ETA: 2s139/322 [===========>..................] - ETA: 2s143/322 [============>.................] - ETA: 2s147/322 [============>.................] - ETA: 2s150/322 [============>.................] - ETA: 2s154/322 [=============>................] - ETA: 2s158/322 [=============>................] - ETA: 2s162/322 [==============>...............] - ETA: 2s166/322 [==============>...............] - ETA: 2s170/322 [==============>...............] - ETA: 2s174/322 [===============>..............] - ETA: 2s178/322 [===============>..............] - ETA: 2s181/322 [===============>..............] - ETA: 2s185/322 [================>.............] - ETA: 2s188/322 [================>.............] - ETA: 2s192/322 [================>.............] - ETA: 2s196/322 [=================>............] - ETA: 1s200/322 [=================>............] - ETA: 1s204/322 [==================>...........] - ETA: 1s207/322 [==================>...........] - ETA: 1s210/322 [==================>...........] - ETA: 1s213/322 [==================>...........] - ETA: 1s217/322 [===================>..........] - ETA: 1s220/322 [===================>..........] - ETA: 1s223/322 [===================>..........] - ETA: 1s227/322 [====================>.........] - ETA: 1s230/322 [====================>.........] - ETA: 1s234/322 [====================>.........] - ETA: 1s238/322 [=====================>........] - ETA: 1s242/322 [=====================>........] - ETA: 1s246/322 [=====================>........] - ETA: 1s250/322 [======================>.......] - ETA: 1s254/322 [======================>.......] - ETA: 1s258/322 [=======================>......] - ETA: 1s262/322 [=======================>......] - ETA: 0s266/322 [=======================>......] - ETA: 0s270/322 [========================>.....] - ETA: 0s273/322 [========================>.....] - ETA: 0s277/322 [========================>.....] - ETA: 0s281/322 [=========================>....] - ETA: 0s285/322 [=========================>....] - ETA: 0s288/322 [=========================>....] - ETA: 0s292/322 [==========================>...] - ETA: 0s296/322 [==========================>...] - ETA: 0s299/322 [==========================>...] - ETA: 0s303/322 [===========================>..] - ETA: 0s307/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s315/322 [============================>.] - ETA: 0s319/322 [============================>.] - ETA: 0s322/322 [==============================] - 7s 16ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:22:03,595 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:22:06,662 - INFO - Assets written to: /tmp/tmp5zzff6p3/autoencoder/assets
2025-07-27 21:22:06,710 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:22:08,348 - INFO - Assets written to: /tmp/tmp5zzff6p3/diffraction_to_obj/assets
2025-07-27 21:22:09,434 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run
[2025-07-27 21:22:10] SUCCESS: PtychoPINN training (n_images=2048, trial=2)
[2025-07-27 21:22:10] EXECUTING: Baseline training (n_images=2048, trial=2)
[2025-07-27 21:22:10] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run' \
            --nepochs 50
2025-07-27 21:22:10.793856: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:22:10.793889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:22:10.794720: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:22:10.798822: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:22:11.260648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:22:12.055411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.090848: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.093165: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:22:12.350008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.352270: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.354272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.468121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.469440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.470557: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:22:12.470706: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:22:12.471853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:22:12,747 - INFO - Configuration setup complete
2025-07-27 21:22:12,747 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run'))
2025-07-27 21:22:12,747 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:22:12,748 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:22:12,748 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1/
2025-07-27 21:22:12,748 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:22:12,761 - INFO - 
[2/6] Loading data...
2025-07-27 21:22:12,761 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:22:12,761 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:22:12,794 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
2025-07-27 21:22:12,794 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:22:12,868 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:22:33,416 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-07-27 21:22:33,416 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:22:33,418 - INFO - Final training input shape: (2048, 64, 64, 1)
2025-07-27 21:22:33,418 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:22:33,418 - INFO - Training with 2048 images
DEBUG: Setting timestamp to 07/27/2025, 21:22:12 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:22:12
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:22:34.822260: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:22:35.625099: I external/local_xla/xla/service/service.cc:168] XLA service 0x70ad1dc9f880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:22:35.625130: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:22:35.628741: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676555.691888 3727962 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 9:01 - loss: 3.5889 - conv2d_12_loss: 1.2317 - conv2d_19_loss: 2.3572  6/122 [>.............................] - ETA: 1s - loss: 12.1730 - conv2d_12_loss: 2.5724 - conv2d_19_loss: 9.6006  11/122 [=>............................] - ETA: 1s - loss: 8.2332 - conv2d_12_loss: 1.9453 - conv2d_19_loss: 6.2879  16/122 [==>...........................] - ETA: 1s - loss: 6.7234 - conv2d_12_loss: 1.6895 - conv2d_19_loss: 5.0340 21/122 [====>.........................] - ETA: 1s - loss: 5.8049 - conv2d_12_loss: 1.4598 - conv2d_19_loss: 4.3451 26/122 [=====>........................] - ETA: 1s - loss: 5.0125 - conv2d_12_loss: 1.2499 - conv2d_19_loss: 3.7626 31/122 [======>.......................] - ETA: 0s - loss: 4.3826 - conv2d_12_loss: 1.0889 - conv2d_19_loss: 3.2937 36/122 [=======>......................] - ETA: 0s - loss: 3.8986 - conv2d_12_loss: 0.9679 - conv2d_19_loss: 2.9307 41/122 [=========>....................] - ETA: 0s - loss: 3.5190 - conv2d_12_loss: 0.8730 - conv2d_19_loss: 2.6460 46/122 [==========>...................] - ETA: 0s - loss: 3.2139 - conv2d_12_loss: 0.7966 - conv2d_19_loss: 2.4173 51/122 [===========>..................] - ETA: 0s - loss: 2.9626 - conv2d_12_loss: 0.7332 - conv2d_19_loss: 2.2294 56/122 [============>.................] - ETA: 0s - loss: 2.7521 - conv2d_12_loss: 0.6799 - conv2d_19_loss: 2.0722 61/122 [==============>...............] - ETA: 0s - loss: 2.5720 - conv2d_12_loss: 0.6347 - conv2d_19_loss: 1.9373 66/122 [===============>..............] - ETA: 0s - loss: 2.4154 - conv2d_12_loss: 0.5956 - conv2d_19_loss: 1.8198 71/122 [================>.............] - ETA: 0s - loss: 2.2777 - conv2d_12_loss: 0.5617 - conv2d_19_loss: 1.7160 76/122 [=================>............] - ETA: 0s - loss: 2.1556 - conv2d_12_loss: 0.5318 - conv2d_19_loss: 1.6238 81/122 [==================>...........] - ETA: 0s - loss: 2.0473 - conv2d_12_loss: 0.5053 - conv2d_19_loss: 1.5420 86/122 [====================>.........] - ETA: 0s - loss: 1.9507 - conv2d_12_loss: 0.4816 - conv2d_19_loss: 1.4691 91/122 [=====================>........] - ETA: 0s - loss: 1.8640 - conv2d_12_loss: 0.4603 - conv2d_19_loss: 1.4036 96/122 [======================>.......] - ETA: 0s - loss: 1.7859 - conv2d_12_loss: 0.4412 - conv2d_19_loss: 1.3447101/122 [=======================>......] - ETA: 0s - loss: 1.7152 - conv2d_12_loss: 0.4238 - conv2d_19_loss: 1.2914106/122 [=========================>....] - ETA: 0s - loss: 1.6507 - conv2d_12_loss: 0.4080 - conv2d_19_loss: 1.2427111/122 [==========================>...] - ETA: 0s - loss: 1.5916 - conv2d_12_loss: 0.3935 - conv2d_19_loss: 1.1981116/122 [===========================>..] - ETA: 0s - loss: 1.5374 - conv2d_12_loss: 0.3803 - conv2d_19_loss: 1.1571121/122 [============================>.] - ETA: 0s - loss: 1.4874 - conv2d_12_loss: 0.3681 - conv2d_19_loss: 1.1193122/122 [==============================] - ETA: 0s - loss: 1.4819 - conv2d_12_loss: 0.3668 - conv2d_19_loss: 1.1151122/122 [==============================] - 8s 27ms/step - loss: 1.4819 - conv2d_12_loss: 0.3668 - conv2d_19_loss: 1.1151 - val_loss: 0.3230 - val_conv2d_12_loss: 0.0854 - val_conv2d_19_loss: 0.2376 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 0.3257 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2392  6/122 [>.............................] - ETA: 1s - loss: 0.3273 - conv2d_12_loss: 0.0870 - conv2d_19_loss: 0.2402 11/122 [=>............................] - ETA: 1s - loss: 0.3216 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2353 16/122 [==>...........................] - ETA: 1s - loss: 0.3180 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2324 21/122 [====>.........................] - ETA: 1s - loss: 0.3163 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2308 26/122 [=====>........................] - ETA: 1s - loss: 0.3169 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2312 31/122 [======>.......................] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2305 36/122 [=======>......................] - ETA: 0s - loss: 0.3172 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2313 41/122 [=========>....................] - ETA: 0s - loss: 0.3175 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2314 46/122 [==========>...................] - ETA: 0s - loss: 0.3172 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2309 51/122 [===========>..................] - ETA: 0s - loss: 0.3169 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2307 56/122 [============>.................] - ETA: 0s - loss: 0.3161 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2300 61/122 [==============>...............] - ETA: 0s - loss: 0.3162 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2301 66/122 [===============>..............] - ETA: 0s - loss: 0.3166 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2305 71/122 [================>.............] - ETA: 0s - loss: 0.3163 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2303 76/122 [=================>............] - ETA: 0s - loss: 0.3165 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2305 81/122 [==================>...........] - ETA: 0s - loss: 0.3166 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2305 86/122 [====================>.........] - ETA: 0s - loss: 0.3167 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2305 91/122 [=====================>........] - ETA: 0s - loss: 0.3168 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2306 96/122 [======================>.......] - ETA: 0s - loss: 0.3167 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2306101/122 [=======================>......] - ETA: 0s - loss: 0.3162 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2302106/122 [=========================>....] - ETA: 0s - loss: 0.3160 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2301111/122 [==========================>...] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2301116/122 [===========================>..] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2301121/122 [============================>.] - ETA: 0s - loss: 0.3157 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2299122/122 [==============================] - 1s 11ms/step - loss: 0.3157 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2299 - val_loss: 0.3121 - val_conv2d_12_loss: 0.0843 - val_conv2d_19_loss: 0.2278 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 0.3019 - conv2d_12_loss: 0.0831 - conv2d_19_loss: 0.2188  6/122 [>.............................] - ETA: 1s - loss: 0.3141 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2285 11/122 [=>............................] - ETA: 1s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 16/122 [==>...........................] - ETA: 1s - loss: 0.3122 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2270 21/122 [====>.........................] - ETA: 1s - loss: 0.3118 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2267 26/122 [=====>........................] - ETA: 1s - loss: 0.3115 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2263 31/122 [======>.......................] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2258 36/122 [=======>......................] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2263 41/122 [=========>....................] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2267 46/122 [==========>...................] - ETA: 0s - loss: 0.3127 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2271 51/122 [===========>..................] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2270 56/122 [============>.................] - ETA: 0s - loss: 0.3127 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2271 61/122 [==============>...............] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2268 66/122 [===============>..............] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2267 71/122 [================>.............] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2261 76/122 [=================>............] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2261 81/122 [==================>...........] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2260 86/122 [====================>.........] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2256 91/122 [=====================>........] - ETA: 0s - loss: 0.3111 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2259 96/122 [======================>.......] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2260101/122 [=======================>......] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2261106/122 [=========================>....] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2262111/122 [==========================>...] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2262116/122 [===========================>..] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2262121/122 [============================>.] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2263122/122 [==============================] - 1s 11ms/step - loss: 0.3115 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2263 - val_loss: 0.3103 - val_conv2d_12_loss: 0.0841 - val_conv2d_19_loss: 0.2262 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 0.3015 - conv2d_12_loss: 0.0827 - conv2d_19_loss: 0.2188  6/122 [>.............................] - ETA: 1s - loss: 0.3151 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2290 11/122 [=>............................] - ETA: 1s - loss: 0.3148 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2289 16/122 [==>...........................] - ETA: 1s - loss: 0.3126 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2273 21/122 [====>.........................] - ETA: 1s - loss: 0.3116 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2266 26/122 [=====>........................] - ETA: 1s - loss: 0.3112 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2263 31/122 [======>.......................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254 36/122 [=======>......................] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258 41/122 [=========>....................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2259 46/122 [==========>...................] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2256 51/122 [===========>..................] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2250 56/122 [============>.................] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2251 61/122 [==============>...............] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2254 66/122 [===============>..............] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2253 71/122 [================>.............] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2253 76/122 [=================>............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2251 81/122 [==================>...........] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2252 86/122 [====================>.........] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2249 91/122 [=====================>........] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2251 96/122 [======================>.......] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2254101/122 [=======================>......] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2254106/122 [=========================>....] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2256111/122 [==========================>...] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2261116/122 [===========================>..] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2265121/122 [============================>.] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2266122/122 [==============================] - 1s 11ms/step - loss: 0.3122 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2266 - val_loss: 0.3118 - val_conv2d_12_loss: 0.0834 - val_conv2d_19_loss: 0.2283 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 0.2971 - conv2d_12_loss: 0.0802 - conv2d_19_loss: 0.2170  6/122 [>.............................] - ETA: 1s - loss: 0.3152 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2301 11/122 [=>............................] - ETA: 1s - loss: 0.3137 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2285 16/122 [==>...........................] - ETA: 1s - loss: 0.3144 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2293 21/122 [====>.........................] - ETA: 1s - loss: 0.3152 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2299 26/122 [=====>........................] - ETA: 1s - loss: 0.3146 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2294 31/122 [======>.......................] - ETA: 0s - loss: 0.3143 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2292 36/122 [=======>......................] - ETA: 0s - loss: 0.3131 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2282 41/122 [=========>....................] - ETA: 0s - loss: 0.3127 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2278 46/122 [==========>...................] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2275 51/122 [===========>..................] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2269 56/122 [============>.................] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2273 61/122 [==============>...............] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2272 66/122 [===============>..............] - ETA: 0s - loss: 0.3129 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2282 71/122 [================>.............] - ETA: 0s - loss: 0.3133 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2286 76/122 [=================>............] - ETA: 0s - loss: 0.3130 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2284 81/122 [==================>...........] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2279 86/122 [====================>.........] - ETA: 0s - loss: 0.3124 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2278 91/122 [=====================>........] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2275 96/122 [======================>.......] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2271101/122 [=======================>......] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2269106/122 [=========================>....] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2270111/122 [==========================>...] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2271116/122 [===========================>..] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2271121/122 [============================>.] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2269122/122 [==============================] - 1s 11ms/step - loss: 0.3116 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2269 - val_loss: 0.3085 - val_conv2d_12_loss: 0.0836 - val_conv2d_19_loss: 0.2249 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 0.3119 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2276  6/122 [>.............................] - ETA: 1s - loss: 0.3047 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2204 11/122 [=>............................] - ETA: 1s - loss: 0.3076 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2233 16/122 [==>...........................] - ETA: 1s - loss: 0.3083 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2239 21/122 [====>.........................] - ETA: 1s - loss: 0.3080 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2237 26/122 [=====>........................] - ETA: 0s - loss: 0.3077 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2237 31/122 [======>.......................] - ETA: 0s - loss: 0.3078 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2237 36/122 [=======>......................] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2242 41/122 [=========>....................] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2242 46/122 [==========>...................] - ETA: 0s - loss: 0.3087 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2242 51/122 [===========>..................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 56/122 [============>.................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2255 61/122 [==============>...............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2252 66/122 [===============>..............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2250 71/122 [================>.............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2249 76/122 [=================>............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2252 81/122 [==================>...........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251 86/122 [====================>.........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 91/122 [=====================>........] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2246 96/122 [======================>.......] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2243101/122 [=======================>......] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2240106/122 [=========================>....] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2243111/122 [==========================>...] - ETA: 0s - loss: 0.3082 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2243116/122 [===========================>..] - ETA: 0s - loss: 0.3079 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2242121/122 [============================>.] - ETA: 0s - loss: 0.3077 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2240122/122 [==============================] - 1s 11ms/step - loss: 0.3077 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2240 - val_loss: 0.3027 - val_conv2d_12_loss: 0.0805 - val_conv2d_19_loss: 0.2222 - lr: 0.0010
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 0.3042 - conv2d_12_loss: 0.0814 - conv2d_19_loss: 0.2228  6/122 [>.............................] - ETA: 1s - loss: 0.3006 - conv2d_12_loss: 0.0811 - conv2d_19_loss: 0.2195 11/122 [=>............................] - ETA: 1s - loss: 0.3005 - conv2d_12_loss: 0.0822 - conv2d_19_loss: 0.2183 16/122 [==>...........................] - ETA: 1s - loss: 0.3010 - conv2d_12_loss: 0.0830 - conv2d_19_loss: 0.2180 21/122 [====>.........................] - ETA: 1s - loss: 0.3001 - conv2d_12_loss: 0.0827 - conv2d_19_loss: 0.2174 26/122 [=====>........................] - ETA: 0s - loss: 0.2992 - conv2d_12_loss: 0.0825 - conv2d_19_loss: 0.2167 31/122 [======>.......................] - ETA: 0s - loss: 0.2972 - conv2d_12_loss: 0.0822 - conv2d_19_loss: 0.2149 36/122 [=======>......................] - ETA: 0s - loss: 0.2964 - conv2d_12_loss: 0.0819 - conv2d_19_loss: 0.2145 41/122 [=========>....................] - ETA: 0s - loss: 0.2962 - conv2d_12_loss: 0.0816 - conv2d_19_loss: 0.2145 46/122 [==========>...................] - ETA: 0s - loss: 0.2949 - conv2d_12_loss: 0.0813 - conv2d_19_loss: 0.2136 51/122 [===========>..................] - ETA: 0s - loss: 0.2944 - conv2d_12_loss: 0.0811 - conv2d_19_loss: 0.2133 56/122 [============>.................] - ETA: 0s - loss: 0.2942 - conv2d_12_loss: 0.0810 - conv2d_19_loss: 0.2133 61/122 [==============>...............] - ETA: 0s - loss: 0.2940 - conv2d_12_loss: 0.0808 - conv2d_19_loss: 0.2131 66/122 [===============>..............] - ETA: 0s - loss: 0.2932 - conv2d_12_loss: 0.0805 - conv2d_19_loss: 0.2127 71/122 [================>.............] - ETA: 0s - loss: 0.2927 - conv2d_12_loss: 0.0804 - conv2d_19_loss: 0.2123 76/122 [=================>............] - ETA: 0s - loss: 0.2920 - conv2d_12_loss: 0.0802 - conv2d_19_loss: 0.2118 81/122 [==================>...........] - ETA: 0s - loss: 0.2911 - conv2d_12_loss: 0.0800 - conv2d_19_loss: 0.2111 86/122 [====================>.........] - ETA: 0s - loss: 0.2903 - conv2d_12_loss: 0.0797 - conv2d_19_loss: 0.2106 91/122 [=====================>........] - ETA: 0s - loss: 0.2896 - conv2d_12_loss: 0.0795 - conv2d_19_loss: 0.2101 96/122 [======================>.......] - ETA: 0s - loss: 0.2893 - conv2d_12_loss: 0.0793 - conv2d_19_loss: 0.2100101/122 [=======================>......] - ETA: 0s - loss: 0.2888 - conv2d_12_loss: 0.0791 - conv2d_19_loss: 0.2097106/122 [=========================>....] - ETA: 0s - loss: 0.2883 - conv2d_12_loss: 0.0789 - conv2d_19_loss: 0.2094111/122 [==========================>...] - ETA: 0s - loss: 0.2872 - conv2d_12_loss: 0.0786 - conv2d_19_loss: 0.2086116/122 [===========================>..] - ETA: 0s - loss: 0.2864 - conv2d_12_loss: 0.0784 - conv2d_19_loss: 0.2080121/122 [============================>.] - ETA: 0s - loss: 0.2858 - conv2d_12_loss: 0.0783 - conv2d_19_loss: 0.2075122/122 [==============================] - 1s 11ms/step - loss: 0.2857 - conv2d_12_loss: 0.0783 - conv2d_19_loss: 0.2074 - val_loss: 0.2684 - val_conv2d_12_loss: 0.0738 - val_conv2d_19_loss: 0.1945 - lr: 0.0010
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 0.2822 - conv2d_12_loss: 0.0771 - conv2d_19_loss: 0.2050  6/122 [>.............................] - ETA: 1s - loss: 0.2734 - conv2d_12_loss: 0.0750 - conv2d_19_loss: 0.1984 11/122 [=>............................] - ETA: 1s - loss: 0.2711 - conv2d_12_loss: 0.0739 - conv2d_19_loss: 0.1971 16/122 [==>...........................] - ETA: 1s - loss: 0.2692 - conv2d_12_loss: 0.0739 - conv2d_19_loss: 0.1953 21/122 [====>.........................] - ETA: 1s - loss: 0.2671 - conv2d_12_loss: 0.0737 - conv2d_19_loss: 0.1934 26/122 [=====>........................] - ETA: 0s - loss: 0.2656 - conv2d_12_loss: 0.0732 - conv2d_19_loss: 0.1924 31/122 [======>.......................] - ETA: 0s - loss: 0.2651 - conv2d_12_loss: 0.0732 - conv2d_19_loss: 0.1919 36/122 [=======>......................] - ETA: 0s - loss: 0.2646 - conv2d_12_loss: 0.0729 - conv2d_19_loss: 0.1917 41/122 [=========>....................] - ETA: 0s - loss: 0.2632 - conv2d_12_loss: 0.0727 - conv2d_19_loss: 0.1905 46/122 [==========>...................] - ETA: 0s - loss: 0.2621 - conv2d_12_loss: 0.0725 - conv2d_19_loss: 0.1896 51/122 [===========>..................] - ETA: 0s - loss: 0.2621 - conv2d_12_loss: 0.0724 - conv2d_19_loss: 0.1897 56/122 [============>.................] - ETA: 0s - loss: 0.2611 - conv2d_12_loss: 0.0723 - conv2d_19_loss: 0.1889 61/122 [==============>...............] - ETA: 0s - loss: 0.2603 - conv2d_12_loss: 0.0722 - conv2d_19_loss: 0.1880 66/122 [===============>..............] - ETA: 0s - loss: 0.2592 - conv2d_12_loss: 0.0720 - conv2d_19_loss: 0.1872 71/122 [================>.............] - ETA: 0s - loss: 0.2584 - conv2d_12_loss: 0.0720 - conv2d_19_loss: 0.1865 76/122 [=================>............] - ETA: 0s - loss: 0.2573 - conv2d_12_loss: 0.0717 - conv2d_19_loss: 0.1856 81/122 [==================>...........] - ETA: 0s - loss: 0.2567 - conv2d_12_loss: 0.0715 - conv2d_19_loss: 0.1852 86/122 [====================>.........] - ETA: 0s - loss: 0.2562 - conv2d_12_loss: 0.0712 - conv2d_19_loss: 0.1849 91/122 [=====================>........] - ETA: 0s - loss: 0.2560 - conv2d_12_loss: 0.0712 - conv2d_19_loss: 0.1848 96/122 [======================>.......] - ETA: 0s - loss: 0.2559 - conv2d_12_loss: 0.0711 - conv2d_19_loss: 0.1848101/122 [=======================>......] - ETA: 0s - loss: 0.2554 - conv2d_12_loss: 0.0708 - conv2d_19_loss: 0.1846106/122 [=========================>....] - ETA: 0s - loss: 0.2549 - conv2d_12_loss: 0.0706 - conv2d_19_loss: 0.1843111/122 [==========================>...] - ETA: 0s - loss: 0.2542 - conv2d_12_loss: 0.0704 - conv2d_19_loss: 0.1839116/122 [===========================>..] - ETA: 0s - loss: 0.2537 - conv2d_12_loss: 0.0702 - conv2d_19_loss: 0.1835121/122 [============================>.] - ETA: 0s - loss: 0.2531 - conv2d_12_loss: 0.0700 - conv2d_19_loss: 0.1831122/122 [==============================] - 1s 11ms/step - loss: 0.2529 - conv2d_12_loss: 0.0699 - conv2d_19_loss: 0.1830 - val_loss: 0.2490 - val_conv2d_12_loss: 0.0657 - val_conv2d_19_loss: 0.1833 - lr: 0.0010
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 0.2363 - conv2d_12_loss: 0.0631 - conv2d_19_loss: 0.1732  6/122 [>.............................] - ETA: 1s - loss: 0.2433 - conv2d_12_loss: 0.0658 - conv2d_19_loss: 0.1775 11/122 [=>............................] - ETA: 1s - loss: 0.2412 - conv2d_12_loss: 0.0650 - conv2d_19_loss: 0.1762 16/122 [==>...........................] - ETA: 1s - loss: 0.2370 - conv2d_12_loss: 0.0643 - conv2d_19_loss: 0.1727 21/122 [====>.........................] - ETA: 1s - loss: 0.2341 - conv2d_12_loss: 0.0638 - conv2d_19_loss: 0.1703 26/122 [=====>........................] - ETA: 1s - loss: 0.2322 - conv2d_12_loss: 0.0635 - conv2d_19_loss: 0.1687 31/122 [======>.......................] - ETA: 0s - loss: 0.2318 - conv2d_12_loss: 0.0634 - conv2d_19_loss: 0.1684 36/122 [=======>......................] - ETA: 0s - loss: 0.2307 - conv2d_12_loss: 0.0630 - conv2d_19_loss: 0.1677 41/122 [=========>....................] - ETA: 0s - loss: 0.2305 - conv2d_12_loss: 0.0629 - conv2d_19_loss: 0.1676 46/122 [==========>...................] - ETA: 0s - loss: 0.2302 - conv2d_12_loss: 0.0630 - conv2d_19_loss: 0.1672 51/122 [===========>..................] - ETA: 0s - loss: 0.2299 - conv2d_12_loss: 0.0631 - conv2d_19_loss: 0.1668 56/122 [============>.................] - ETA: 0s - loss: 0.2295 - conv2d_12_loss: 0.0631 - conv2d_19_loss: 0.1664 61/122 [==============>...............] - ETA: 0s - loss: 0.2291 - conv2d_12_loss: 0.0632 - conv2d_19_loss: 0.1659 66/122 [===============>..............] - ETA: 0s - loss: 0.2289 - conv2d_12_loss: 0.0635 - conv2d_19_loss: 0.1654 71/122 [================>.............] - ETA: 0s - loss: 0.2286 - conv2d_12_loss: 0.0636 - conv2d_19_loss: 0.1651 76/122 [=================>............] - ETA: 0s - loss: 0.2280 - conv2d_12_loss: 0.0635 - conv2d_19_loss: 0.1646 81/122 [==================>...........] - ETA: 0s - loss: 0.2276 - conv2d_12_loss: 0.0633 - conv2d_19_loss: 0.1642 86/122 [====================>.........] - ETA: 0s - loss: 0.2268 - conv2d_12_loss: 0.0631 - conv2d_19_loss: 0.1636 91/122 [=====================>........] - ETA: 0s - loss: 0.2262 - conv2d_12_loss: 0.0630 - conv2d_19_loss: 0.1632 96/122 [======================>.......] - ETA: 0s - loss: 0.2255 - conv2d_12_loss: 0.0629 - conv2d_19_loss: 0.1626101/122 [=======================>......] - ETA: 0s - loss: 0.2250 - conv2d_12_loss: 0.0628 - conv2d_19_loss: 0.1622106/122 [=========================>....] - ETA: 0s - loss: 0.2246 - conv2d_12_loss: 0.0627 - conv2d_19_loss: 0.1619111/122 [==========================>...] - ETA: 0s - loss: 0.2242 - conv2d_12_loss: 0.0626 - conv2d_19_loss: 0.1617116/122 [===========================>..] - ETA: 0s - loss: 0.2238 - conv2d_12_loss: 0.0624 - conv2d_19_loss: 0.1614121/122 [============================>.] - ETA: 0s - loss: 0.2235 - conv2d_12_loss: 0.0623 - conv2d_19_loss: 0.1612122/122 [==============================] - 1s 11ms/step - loss: 0.2234 - conv2d_12_loss: 0.0623 - conv2d_19_loss: 0.1611 - val_loss: 0.2104 - val_conv2d_12_loss: 0.0604 - val_conv2d_19_loss: 0.1500 - lr: 0.0010
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 0.2032 - conv2d_12_loss: 0.0594 - conv2d_19_loss: 0.1438  6/122 [>.............................] - ETA: 1s - loss: 0.2104 - conv2d_12_loss: 0.0603 - conv2d_19_loss: 0.1500 11/122 [=>............................] - ETA: 1s - loss: 0.2076 - conv2d_12_loss: 0.0600 - conv2d_19_loss: 0.1476 16/122 [==>...........................] - ETA: 1s - loss: 0.2077 - conv2d_12_loss: 0.0600 - conv2d_19_loss: 0.1477 21/122 [====>.........................] - ETA: 1s - loss: 0.2058 - conv2d_12_loss: 0.0593 - conv2d_19_loss: 0.1465 26/122 [=====>........................] - ETA: 0s - loss: 0.2064 - conv2d_12_loss: 0.0593 - conv2d_19_loss: 0.1471 31/122 [======>.......................] - ETA: 0s - loss: 0.2059 - conv2d_12_loss: 0.0591 - conv2d_19_loss: 0.1467 36/122 [=======>......................] - ETA: 0s - loss: 0.2056 - conv2d_12_loss: 0.0588 - conv2d_19_loss: 0.1468 41/122 [=========>....................] - ETA: 0s - loss: 0.2053 - conv2d_12_loss: 0.0586 - conv2d_19_loss: 0.1467 46/122 [==========>...................] - ETA: 0s - loss: 0.2043 - conv2d_12_loss: 0.0582 - conv2d_19_loss: 0.1460 51/122 [===========>..................] - ETA: 0s - loss: 0.2034 - conv2d_12_loss: 0.0580 - conv2d_19_loss: 0.1454 56/122 [============>.................] - ETA: 0s - loss: 0.2031 - conv2d_12_loss: 0.0579 - conv2d_19_loss: 0.1452 61/122 [==============>...............] - ETA: 0s - loss: 0.2032 - conv2d_12_loss: 0.0578 - conv2d_19_loss: 0.1453 66/122 [===============>..............] - ETA: 0s - loss: 0.2025 - conv2d_12_loss: 0.0576 - conv2d_19_loss: 0.1449 71/122 [================>.............] - ETA: 0s - loss: 0.2027 - conv2d_12_loss: 0.0575 - conv2d_19_loss: 0.1452 76/122 [=================>............] - ETA: 0s - loss: 0.2030 - conv2d_12_loss: 0.0574 - conv2d_19_loss: 0.1456 81/122 [==================>...........] - ETA: 0s - loss: 0.2032 - conv2d_12_loss: 0.0574 - conv2d_19_loss: 0.1459 86/122 [====================>.........] - ETA: 0s - loss: 0.2035 - conv2d_12_loss: 0.0574 - conv2d_19_loss: 0.1461 91/122 [=====================>........] - ETA: 0s - loss: 0.2032 - conv2d_12_loss: 0.0572 - conv2d_19_loss: 0.1460 96/122 [======================>.......] - ETA: 0s - loss: 0.2030 - conv2d_12_loss: 0.0572 - conv2d_19_loss: 0.1458101/122 [=======================>......] - ETA: 0s - loss: 0.2027 - conv2d_12_loss: 0.0571 - conv2d_19_loss: 0.1456106/122 [=========================>....] - ETA: 0s - loss: 0.2021 - conv2d_12_loss: 0.0569 - conv2d_19_loss: 0.1451111/122 [==========================>...] - ETA: 0s - loss: 0.2014 - conv2d_12_loss: 0.0568 - conv2d_19_loss: 0.1446116/122 [===========================>..] - ETA: 0s - loss: 0.2008 - conv2d_12_loss: 0.0566 - conv2d_19_loss: 0.1442121/122 [============================>.] - ETA: 0s - loss: 0.2006 - conv2d_12_loss: 0.0566 - conv2d_19_loss: 0.1440122/122 [==============================] - 1s 11ms/step - loss: 0.2006 - conv2d_12_loss: 0.0566 - conv2d_19_loss: 0.1440 - val_loss: 0.1941 - val_conv2d_12_loss: 0.0546 - val_conv2d_19_loss: 0.1396 - lr: 0.0010
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 0.1829 - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.1306  6/122 [>.............................] - ETA: 1s - loss: 0.1835 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1304 11/122 [=>............................] - ETA: 1s - loss: 0.1865 - conv2d_12_loss: 0.0538 - conv2d_19_loss: 0.1327 16/122 [==>...........................] - ETA: 1s - loss: 0.1860 - conv2d_12_loss: 0.0534 - conv2d_19_loss: 0.1325 21/122 [====>.........................] - ETA: 1s - loss: 0.1865 - conv2d_12_loss: 0.0536 - conv2d_19_loss: 0.1329 26/122 [=====>........................] - ETA: 0s - loss: 0.1869 - conv2d_12_loss: 0.0536 - conv2d_19_loss: 0.1334 31/122 [======>.......................] - ETA: 0s - loss: 0.1876 - conv2d_12_loss: 0.0534 - conv2d_19_loss: 0.1342 36/122 [=======>......................] - ETA: 0s - loss: 0.1878 - conv2d_12_loss: 0.0537 - conv2d_19_loss: 0.1342 41/122 [=========>....................] - ETA: 0s - loss: 0.1868 - conv2d_12_loss: 0.0536 - conv2d_19_loss: 0.1332 46/122 [==========>...................] - ETA: 0s - loss: 0.1867 - conv2d_12_loss: 0.0535 - conv2d_19_loss: 0.1332 51/122 [===========>..................] - ETA: 0s - loss: 0.1863 - conv2d_12_loss: 0.0534 - conv2d_19_loss: 0.1329 56/122 [============>.................] - ETA: 0s - loss: 0.1856 - conv2d_12_loss: 0.0532 - conv2d_19_loss: 0.1324 61/122 [==============>...............] - ETA: 0s - loss: 0.1849 - conv2d_12_loss: 0.0530 - conv2d_19_loss: 0.1318 66/122 [===============>..............] - ETA: 0s - loss: 0.1854 - conv2d_12_loss: 0.0532 - conv2d_19_loss: 0.1322 71/122 [================>.............] - ETA: 0s - loss: 0.1851 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1320 76/122 [=================>............] - ETA: 0s - loss: 0.1849 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1318 81/122 [==================>...........] - ETA: 0s - loss: 0.1851 - conv2d_12_loss: 0.0532 - conv2d_19_loss: 0.1319 86/122 [====================>.........] - ETA: 0s - loss: 0.1850 - conv2d_12_loss: 0.0532 - conv2d_19_loss: 0.1318 91/122 [=====================>........] - ETA: 0s - loss: 0.1849 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1317 96/122 [======================>.......] - ETA: 0s - loss: 0.1847 - conv2d_12_loss: 0.0531 - conv2d_19_loss: 0.1316101/122 [=======================>......] - ETA: 0s - loss: 0.1843 - conv2d_12_loss: 0.0530 - conv2d_19_loss: 0.1313106/122 [=========================>....] - ETA: 0s - loss: 0.1840 - conv2d_12_loss: 0.0529 - conv2d_19_loss: 0.1311111/122 [==========================>...] - ETA: 0s - loss: 0.1840 - conv2d_12_loss: 0.0528 - conv2d_19_loss: 0.1312116/122 [===========================>..] - ETA: 0s - loss: 0.1839 - conv2d_12_loss: 0.0528 - conv2d_19_loss: 0.1311121/122 [============================>.] - ETA: 0s - loss: 0.1840 - conv2d_12_loss: 0.0528 - conv2d_19_loss: 0.1313122/122 [==============================] - 1s 11ms/step - loss: 0.1841 - conv2d_12_loss: 0.0528 - conv2d_19_loss: 0.1313 - val_loss: 0.1845 - val_conv2d_12_loss: 0.0520 - val_conv2d_19_loss: 0.1325 - lr: 0.0010
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 0.1730 - conv2d_12_loss: 0.0492 - conv2d_19_loss: 0.1238  6/122 [>.............................] - ETA: 1s - loss: 0.1762 - conv2d_12_loss: 0.0495 - conv2d_19_loss: 0.1267 11/122 [=>............................] - ETA: 1s - loss: 0.1786 - conv2d_12_loss: 0.0493 - conv2d_19_loss: 0.1293 16/122 [==>...........................] - ETA: 1s - loss: 0.1820 - conv2d_12_loss: 0.0503 - conv2d_19_loss: 0.1317 21/122 [====>.........................] - ETA: 1s - loss: 0.1829 - conv2d_12_loss: 0.0506 - conv2d_19_loss: 0.1322 26/122 [=====>........................] - ETA: 1s - loss: 0.1828 - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.1319 31/122 [======>.......................] - ETA: 0s - loss: 0.1818 - conv2d_12_loss: 0.0513 - conv2d_19_loss: 0.1306 36/122 [=======>......................] - ETA: 0s - loss: 0.1814 - conv2d_12_loss: 0.0514 - conv2d_19_loss: 0.1300 41/122 [=========>....................] - ETA: 0s - loss: 0.1814 - conv2d_12_loss: 0.0515 - conv2d_19_loss: 0.1299 46/122 [==========>...................] - ETA: 0s - loss: 0.1809 - conv2d_12_loss: 0.0514 - conv2d_19_loss: 0.1295 51/122 [===========>..................] - ETA: 0s - loss: 0.1803 - conv2d_12_loss: 0.0512 - conv2d_19_loss: 0.1291 56/122 [============>.................] - ETA: 0s - loss: 0.1795 - conv2d_12_loss: 0.0511 - conv2d_19_loss: 0.1284 61/122 [==============>...............] - ETA: 0s - loss: 0.1786 - conv2d_12_loss: 0.0510 - conv2d_19_loss: 0.1276 66/122 [===============>..............] - ETA: 0s - loss: 0.1780 - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.1271 71/122 [================>.............] - ETA: 0s - loss: 0.1775 - conv2d_12_loss: 0.0507 - conv2d_19_loss: 0.1268 76/122 [=================>............] - ETA: 0s - loss: 0.1769 - conv2d_12_loss: 0.0506 - conv2d_19_loss: 0.1264 81/122 [==================>...........] - ETA: 0s - loss: 0.1766 - conv2d_12_loss: 0.0504 - conv2d_19_loss: 0.1262 86/122 [====================>.........] - ETA: 0s - loss: 0.1761 - conv2d_12_loss: 0.0503 - conv2d_19_loss: 0.1258 91/122 [=====================>........] - ETA: 0s - loss: 0.1757 - conv2d_12_loss: 0.0502 - conv2d_19_loss: 0.1255 96/122 [======================>.......] - ETA: 0s - loss: 0.1749 - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.1249101/122 [=======================>......] - ETA: 0s - loss: 0.1745 - conv2d_12_loss: 0.0499 - conv2d_19_loss: 0.1246106/122 [=========================>....] - ETA: 0s - loss: 0.1738 - conv2d_12_loss: 0.0498 - conv2d_19_loss: 0.1241111/122 [==========================>...] - ETA: 0s - loss: 0.1735 - conv2d_12_loss: 0.0497 - conv2d_19_loss: 0.1238116/122 [===========================>..] - ETA: 0s - loss: 0.1734 - conv2d_12_loss: 0.0497 - conv2d_19_loss: 0.1237121/122 [============================>.] - ETA: 0s - loss: 0.1729 - conv2d_12_loss: 0.0496 - conv2d_19_loss: 0.1233122/122 [==============================] - 1s 11ms/step - loss: 0.1729 - conv2d_12_loss: 0.0496 - conv2d_19_loss: 0.1233 - val_loss: 0.1715 - val_conv2d_12_loss: 0.0498 - val_conv2d_19_loss: 0.1217 - lr: 0.0010
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 0.1638 - conv2d_12_loss: 0.0495 - conv2d_19_loss: 0.1143  6/122 [>.............................] - ETA: 1s - loss: 0.1641 - conv2d_12_loss: 0.0476 - conv2d_19_loss: 0.1166 11/122 [=>............................] - ETA: 1s - loss: 0.1648 - conv2d_12_loss: 0.0478 - conv2d_19_loss: 0.1170 16/122 [==>...........................] - ETA: 1s - loss: 0.1646 - conv2d_12_loss: 0.0478 - conv2d_19_loss: 0.1168 21/122 [====>.........................] - ETA: 1s - loss: 0.1642 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1165 26/122 [=====>........................] - ETA: 0s - loss: 0.1657 - conv2d_12_loss: 0.0480 - conv2d_19_loss: 0.1178 31/122 [======>.......................] - ETA: 0s - loss: 0.1659 - conv2d_12_loss: 0.0482 - conv2d_19_loss: 0.1177 36/122 [=======>......................] - ETA: 0s - loss: 0.1659 - conv2d_12_loss: 0.0482 - conv2d_19_loss: 0.1177 41/122 [=========>....................] - ETA: 0s - loss: 0.1646 - conv2d_12_loss: 0.0478 - conv2d_19_loss: 0.1167 46/122 [==========>...................] - ETA: 0s - loss: 0.1642 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1165 51/122 [===========>..................] - ETA: 0s - loss: 0.1639 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1162 56/122 [============>.................] - ETA: 0s - loss: 0.1647 - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.1168 61/122 [==============>...............] - ETA: 0s - loss: 0.1646 - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.1167 66/122 [===============>..............] - ETA: 0s - loss: 0.1645 - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.1166 71/122 [================>.............] - ETA: 0s - loss: 0.1651 - conv2d_12_loss: 0.0480 - conv2d_19_loss: 0.1171 76/122 [=================>............] - ETA: 0s - loss: 0.1650 - conv2d_12_loss: 0.0480 - conv2d_19_loss: 0.1170 81/122 [==================>...........] - ETA: 0s - loss: 0.1647 - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.1167 86/122 [====================>.........] - ETA: 0s - loss: 0.1646 - conv2d_12_loss: 0.0479 - conv2d_19_loss: 0.1167 91/122 [=====================>........] - ETA: 0s - loss: 0.1644 - conv2d_12_loss: 0.0478 - conv2d_19_loss: 0.1166 96/122 [======================>.......] - ETA: 0s - loss: 0.1640 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1163101/122 [=======================>......] - ETA: 0s - loss: 0.1640 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1163106/122 [=========================>....] - ETA: 0s - loss: 0.1639 - conv2d_12_loss: 0.0477 - conv2d_19_loss: 0.1162111/122 [==========================>...] - ETA: 0s - loss: 0.1638 - conv2d_12_loss: 0.0476 - conv2d_19_loss: 0.1163116/122 [===========================>..] - ETA: 0s - loss: 0.1634 - conv2d_12_loss: 0.0475 - conv2d_19_loss: 0.1159121/122 [============================>.] - ETA: 0s - loss: 0.1631 - conv2d_12_loss: 0.0474 - conv2d_19_loss: 0.1157122/122 [==============================] - 1s 11ms/step - loss: 0.1630 - conv2d_12_loss: 0.0474 - conv2d_19_loss: 0.1156 - val_loss: 0.1609 - val_conv2d_12_loss: 0.0478 - val_conv2d_19_loss: 0.1131 - lr: 0.0010
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 0.1668 - conv2d_12_loss: 0.0495 - conv2d_19_loss: 0.1173  6/122 [>.............................] - ETA: 1s - loss: 0.1561 - conv2d_12_loss: 0.0454 - conv2d_19_loss: 0.1107 11/122 [=>............................] - ETA: 1s - loss: 0.1576 - conv2d_12_loss: 0.0453 - conv2d_19_loss: 0.1122 16/122 [==>...........................] - ETA: 1s - loss: 0.1563 - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.1112 21/122 [====>.........................] - ETA: 1s - loss: 0.1562 - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.1112 26/122 [=====>........................] - ETA: 0s - loss: 0.1557 - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.1106 31/122 [======>.......................] - ETA: 0s - loss: 0.1551 - conv2d_12_loss: 0.0452 - conv2d_19_loss: 0.1099 36/122 [=======>......................] - ETA: 0s - loss: 0.1548 - conv2d_12_loss: 0.0453 - conv2d_19_loss: 0.1095 41/122 [=========>....................] - ETA: 0s - loss: 0.1558 - conv2d_12_loss: 0.0455 - conv2d_19_loss: 0.1103 46/122 [==========>...................] - ETA: 0s - loss: 0.1551 - conv2d_12_loss: 0.0453 - conv2d_19_loss: 0.1098 51/122 [===========>..................] - ETA: 0s - loss: 0.1546 - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.1095 56/122 [============>.................] - ETA: 0s - loss: 0.1547 - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.1096 61/122 [==============>...............] - ETA: 0s - loss: 0.1558 - conv2d_12_loss: 0.0452 - conv2d_19_loss: 0.1105 66/122 [===============>..............] - ETA: 0s - loss: 0.1568 - conv2d_12_loss: 0.0455 - conv2d_19_loss: 0.1113 71/122 [================>.............] - ETA: 0s - loss: 0.1573 - conv2d_12_loss: 0.0459 - conv2d_19_loss: 0.1114 76/122 [=================>............] - ETA: 0s - loss: 0.1575 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1115 81/122 [==================>...........] - ETA: 0s - loss: 0.1575 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1115 86/122 [====================>.........] - ETA: 0s - loss: 0.1574 - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.1114 91/122 [=====================>........] - ETA: 0s - loss: 0.1577 - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.1116 96/122 [======================>.......] - ETA: 0s - loss: 0.1580 - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.1118101/122 [=======================>......] - ETA: 0s - loss: 0.1583 - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.1119106/122 [=========================>....] - ETA: 0s - loss: 0.1580 - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.1117111/122 [==========================>...] - ETA: 0s - loss: 0.1578 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1114116/122 [===========================>..] - ETA: 0s - loss: 0.1579 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1115121/122 [============================>.] - ETA: 0s - loss: 0.1580 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1116122/122 [==============================] - 1s 11ms/step - loss: 0.1581 - conv2d_12_loss: 0.0463 - conv2d_19_loss: 0.1118 - val_loss: 0.1582 - val_conv2d_12_loss: 0.0463 - val_conv2d_19_loss: 0.1119 - lr: 0.0010
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 0.1498 - conv2d_12_loss: 0.0443 - conv2d_19_loss: 0.1055  6/122 [>.............................] - ETA: 1s - loss: 0.1525 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.1094 11/122 [=>............................] - ETA: 1s - loss: 0.1537 - conv2d_12_loss: 0.0437 - conv2d_19_loss: 0.1100 16/122 [==>...........................] - ETA: 1s - loss: 0.1533 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1094 21/122 [====>.........................] - ETA: 1s - loss: 0.1514 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1076 26/122 [=====>........................] - ETA: 1s - loss: 0.1503 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1065 31/122 [======>.......................] - ETA: 0s - loss: 0.1504 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1065 36/122 [=======>......................] - ETA: 0s - loss: 0.1503 - conv2d_12_loss: 0.0440 - conv2d_19_loss: 0.1062 41/122 [=========>....................] - ETA: 0s - loss: 0.1494 - conv2d_12_loss: 0.0440 - conv2d_19_loss: 0.1054 46/122 [==========>...................] - ETA: 0s - loss: 0.1497 - conv2d_12_loss: 0.0441 - conv2d_19_loss: 0.1055 51/122 [===========>..................] - ETA: 0s - loss: 0.1488 - conv2d_12_loss: 0.0440 - conv2d_19_loss: 0.1048 56/122 [============>.................] - ETA: 0s - loss: 0.1481 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1042 61/122 [==============>...............] - ETA: 0s - loss: 0.1480 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1041 66/122 [===============>..............] - ETA: 0s - loss: 0.1478 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1039 71/122 [================>.............] - ETA: 0s - loss: 0.1475 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1036 76/122 [=================>............] - ETA: 0s - loss: 0.1477 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1037 81/122 [==================>...........] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1034 86/122 [====================>.........] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1035 91/122 [=====================>........] - ETA: 0s - loss: 0.1470 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1032 96/122 [======================>.......] - ETA: 0s - loss: 0.1473 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1035101/122 [=======================>......] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1035106/122 [=========================>....] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1036111/122 [==========================>...] - ETA: 0s - loss: 0.1474 - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.1035116/122 [===========================>..] - ETA: 0s - loss: 0.1473 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1035121/122 [============================>.] - ETA: 0s - loss: 0.1471 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1033122/122 [==============================] - 1s 11ms/step - loss: 0.1471 - conv2d_12_loss: 0.0438 - conv2d_19_loss: 0.1033 - val_loss: 0.1472 - val_conv2d_12_loss: 0.0441 - val_conv2d_19_loss: 0.1031 - lr: 0.0010
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 0.1348 - conv2d_12_loss: 0.0410 - conv2d_19_loss: 0.0937  6/122 [>.............................] - ETA: 1s - loss: 0.1421 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.0994 11/122 [=>............................] - ETA: 1s - loss: 0.1433 - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.1007 16/122 [==>...........................] - ETA: 1s - loss: 0.1420 - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.0995 21/122 [====>.........................] - ETA: 1s - loss: 0.1429 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.0998 26/122 [=====>........................] - ETA: 1s - loss: 0.1414 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.0987 31/122 [======>.......................] - ETA: 0s - loss: 0.1419 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.0992 36/122 [=======>......................] - ETA: 0s - loss: 0.1430 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1001 41/122 [=========>....................] - ETA: 0s - loss: 0.1436 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1007 46/122 [==========>...................] - ETA: 0s - loss: 0.1445 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.1015 51/122 [===========>..................] - ETA: 0s - loss: 0.1446 - conv2d_12_loss: 0.0430 - conv2d_19_loss: 0.1016 56/122 [============>.................] - ETA: 0s - loss: 0.1439 - conv2d_12_loss: 0.0428 - conv2d_19_loss: 0.1011 61/122 [==============>...............] - ETA: 0s - loss: 0.1443 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1014 66/122 [===============>..............] - ETA: 0s - loss: 0.1448 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1019 71/122 [================>.............] - ETA: 0s - loss: 0.1449 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1020 76/122 [=================>............] - ETA: 0s - loss: 0.1445 - conv2d_12_loss: 0.0428 - conv2d_19_loss: 0.1017 81/122 [==================>...........] - ETA: 0s - loss: 0.1449 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1020 86/122 [====================>.........] - ETA: 0s - loss: 0.1452 - conv2d_12_loss: 0.0430 - conv2d_19_loss: 0.1021 91/122 [=====================>........] - ETA: 0s - loss: 0.1451 - conv2d_12_loss: 0.0430 - conv2d_19_loss: 0.1021 96/122 [======================>.......] - ETA: 0s - loss: 0.1448 - conv2d_12_loss: 0.0430 - conv2d_19_loss: 0.1018101/122 [=======================>......] - ETA: 0s - loss: 0.1444 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.1015106/122 [=========================>....] - ETA: 0s - loss: 0.1440 - conv2d_12_loss: 0.0428 - conv2d_19_loss: 0.1011111/122 [==========================>...] - ETA: 0s - loss: 0.1436 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.1009116/122 [===========================>..] - ETA: 0s - loss: 0.1432 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.1006121/122 [============================>.] - ETA: 0s - loss: 0.1433 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.1006122/122 [==============================] - 1s 11ms/step - loss: 0.1433 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.1006 - val_loss: 0.1443 - val_conv2d_12_loss: 0.0433 - val_conv2d_19_loss: 0.1011 - lr: 0.0010
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 0.1421 - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.0990  6/122 [>.............................] - ETA: 1s - loss: 0.1402 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0980 11/122 [=>............................] - ETA: 1s - loss: 0.1387 - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.0964 16/122 [==>...........................] - ETA: 1s - loss: 0.1376 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0956 21/122 [====>.........................] - ETA: 1s - loss: 0.1368 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0950 26/122 [=====>........................] - ETA: 0s - loss: 0.1361 - conv2d_12_loss: 0.0415 - conv2d_19_loss: 0.0946 31/122 [======>.......................] - ETA: 0s - loss: 0.1356 - conv2d_12_loss: 0.0413 - conv2d_19_loss: 0.0943 36/122 [=======>......................] - ETA: 0s - loss: 0.1349 - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.0937 41/122 [=========>....................] - ETA: 0s - loss: 0.1344 - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.0933 46/122 [==========>...................] - ETA: 0s - loss: 0.1346 - conv2d_12_loss: 0.0414 - conv2d_19_loss: 0.0932 51/122 [===========>..................] - ETA: 0s - loss: 0.1347 - conv2d_12_loss: 0.0415 - conv2d_19_loss: 0.0932 56/122 [============>.................] - ETA: 0s - loss: 0.1349 - conv2d_12_loss: 0.0416 - conv2d_19_loss: 0.0933 61/122 [==============>...............] - ETA: 0s - loss: 0.1349 - conv2d_12_loss: 0.0416 - conv2d_19_loss: 0.0932 66/122 [===============>..............] - ETA: 0s - loss: 0.1349 - conv2d_12_loss: 0.0416 - conv2d_19_loss: 0.0933 71/122 [================>.............] - ETA: 0s - loss: 0.1351 - conv2d_12_loss: 0.0417 - conv2d_19_loss: 0.0934 76/122 [=================>............] - ETA: 0s - loss: 0.1353 - conv2d_12_loss: 0.0417 - conv2d_19_loss: 0.0935 81/122 [==================>...........] - ETA: 0s - loss: 0.1357 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0938 86/122 [====================>.........] - ETA: 0s - loss: 0.1359 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0941 91/122 [=====================>........] - ETA: 0s - loss: 0.1362 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0944 96/122 [======================>.......] - ETA: 0s - loss: 0.1364 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0945101/122 [=======================>......] - ETA: 0s - loss: 0.1363 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0945106/122 [=========================>....] - ETA: 0s - loss: 0.1364 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0945111/122 [==========================>...] - ETA: 0s - loss: 0.1363 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0944116/122 [===========================>..] - ETA: 0s - loss: 0.1366 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0946121/122 [============================>.] - ETA: 0s - loss: 0.1365 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0945122/122 [==============================] - 1s 11ms/step - loss: 0.1364 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0945 - val_loss: 0.1410 - val_conv2d_12_loss: 0.0433 - val_conv2d_19_loss: 0.0977 - lr: 0.0010
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 0.1284 - conv2d_12_loss: 0.0417 - conv2d_19_loss: 0.0867  6/122 [>.............................] - ETA: 1s - loss: 0.1341 - conv2d_12_loss: 0.0429 - conv2d_19_loss: 0.0911 11/122 [=>............................] - ETA: 1s - loss: 0.1353 - conv2d_12_loss: 0.0427 - conv2d_19_loss: 0.0926 16/122 [==>...........................] - ETA: 1s - loss: 0.1343 - conv2d_12_loss: 0.0425 - conv2d_19_loss: 0.0918 21/122 [====>.........................] - ETA: 1s - loss: 0.1333 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0911 26/122 [=====>........................] - ETA: 0s - loss: 0.1336 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0915 31/122 [======>.......................] - ETA: 0s - loss: 0.1332 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0911 36/122 [=======>......................] - ETA: 0s - loss: 0.1319 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0901 41/122 [=========>....................] - ETA: 0s - loss: 0.1319 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0901 46/122 [==========>...................] - ETA: 0s - loss: 0.1321 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0901 51/122 [===========>..................] - ETA: 0s - loss: 0.1320 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0900 56/122 [============>.................] - ETA: 0s - loss: 0.1328 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0906 61/122 [==============>...............] - ETA: 0s - loss: 0.1330 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0908 66/122 [===============>..............] - ETA: 0s - loss: 0.1330 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0909 71/122 [================>.............] - ETA: 0s - loss: 0.1328 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0908 76/122 [=================>............] - ETA: 0s - loss: 0.1334 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0913 81/122 [==================>...........] - ETA: 0s - loss: 0.1336 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0915 86/122 [====================>.........] - ETA: 0s - loss: 0.1340 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0918 91/122 [=====================>........] - ETA: 0s - loss: 0.1339 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0918 96/122 [======================>.......] - ETA: 0s - loss: 0.1341 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0920101/122 [=======================>......] - ETA: 0s - loss: 0.1340 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0920106/122 [=========================>....] - ETA: 0s - loss: 0.1337 - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.0917111/122 [==========================>...] - ETA: 0s - loss: 0.1338 - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.0918116/122 [===========================>..] - ETA: 0s - loss: 0.1338 - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.0917121/122 [============================>.] - ETA: 0s - loss: 0.1337 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0916122/122 [==============================] - 1s 11ms/step - loss: 0.1337 - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.0915 - val_loss: 0.1448 - val_conv2d_12_loss: 0.0452 - val_conv2d_19_loss: 0.0996 - lr: 0.0010
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 0.1192 - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.0808  6/122 [>.............................] - ETA: 1s - loss: 0.1288 - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.0870 11/122 [=>............................] - ETA: 1s - loss: 0.1281 - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.0869 16/122 [==>...........................] - ETA: 1s - loss: 0.1268 - conv2d_12_loss: 0.0408 - conv2d_19_loss: 0.0861 21/122 [====>.........................] - ETA: 1s - loss: 0.1252 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0850 26/122 [=====>........................] - ETA: 1s - loss: 0.1250 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0851 31/122 [======>.......................] - ETA: 0s - loss: 0.1257 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0856 36/122 [=======>......................] - ETA: 0s - loss: 0.1255 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0856 41/122 [=========>....................] - ETA: 0s - loss: 0.1268 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0868 46/122 [==========>...................] - ETA: 0s - loss: 0.1275 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0876 51/122 [===========>..................] - ETA: 0s - loss: 0.1282 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0882 56/122 [============>.................] - ETA: 0s - loss: 0.1287 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0887 61/122 [==============>...............] - ETA: 0s - loss: 0.1291 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0890 66/122 [===============>..............] - ETA: 0s - loss: 0.1290 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0889 71/122 [================>.............] - ETA: 0s - loss: 0.1283 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0883 76/122 [=================>............] - ETA: 0s - loss: 0.1282 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0882 81/122 [==================>...........] - ETA: 0s - loss: 0.1280 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0880 86/122 [====================>.........] - ETA: 0s - loss: 0.1279 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0879 91/122 [=====================>........] - ETA: 0s - loss: 0.1281 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0881 96/122 [======================>.......] - ETA: 0s - loss: 0.1281 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0881101/122 [=======================>......] - ETA: 0s - loss: 0.1281 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0881106/122 [=========================>....] - ETA: 0s - loss: 0.1278 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0878111/122 [==========================>...] - ETA: 0s - loss: 0.1275 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0875116/122 [===========================>..] - ETA: 0s - loss: 0.1272 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0873121/122 [============================>.] - ETA: 0s - loss: 0.1273 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0874122/122 [==============================] - 1s 11ms/step - loss: 0.1274 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0875 - val_loss: 0.1380 - val_conv2d_12_loss: 0.0424 - val_conv2d_19_loss: 0.0956 - lr: 0.0010
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 0.1298 - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.0895  6/122 [>.............................] - ETA: 1s - loss: 0.1326 - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.0923 11/122 [=>............................] - ETA: 1s - loss: 0.1298 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0896 16/122 [==>...........................] - ETA: 1s - loss: 0.1290 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0889 21/122 [====>.........................] - ETA: 1s - loss: 0.1282 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0882 26/122 [=====>........................] - ETA: 0s - loss: 0.1280 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0877 31/122 [======>.......................] - ETA: 0s - loss: 0.1275 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0873 36/122 [=======>......................] - ETA: 0s - loss: 0.1271 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0869 41/122 [=========>....................] - ETA: 0s - loss: 0.1268 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0866 46/122 [==========>...................] - ETA: 0s - loss: 0.1267 - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.0864 51/122 [===========>..................] - ETA: 0s - loss: 0.1267 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0865 56/122 [============>.................] - ETA: 0s - loss: 0.1266 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0863 61/122 [==============>...............] - ETA: 0s - loss: 0.1257 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0857 66/122 [===============>..............] - ETA: 0s - loss: 0.1256 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0856 71/122 [================>.............] - ETA: 0s - loss: 0.1255 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0855 76/122 [=================>............] - ETA: 0s - loss: 0.1258 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0858 81/122 [==================>...........] - ETA: 0s - loss: 0.1259 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0859 86/122 [====================>.........] - ETA: 0s - loss: 0.1259 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0859 91/122 [=====================>........] - ETA: 0s - loss: 0.1260 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0860 96/122 [======================>.......] - ETA: 0s - loss: 0.1259 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0859101/122 [=======================>......] - ETA: 0s - loss: 0.1259 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0859106/122 [=========================>....] - ETA: 0s - loss: 0.1258 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0859111/122 [==========================>...] - ETA: 0s - loss: 0.1256 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0858116/122 [===========================>..] - ETA: 0s - loss: 0.1254 - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.0856121/122 [============================>.] - ETA: 0s - loss: 0.1254 - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.0856122/122 [==============================] - 1s 11ms/step - loss: 0.1254 - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.0856 - val_loss: 0.1375 - val_conv2d_12_loss: 0.0414 - val_conv2d_19_loss: 0.0961 - lr: 0.0010
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 0.1172 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0805  6/122 [>.............................] - ETA: 1s - loss: 0.1192 - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.0805 11/122 [=>............................] - ETA: 1s - loss: 0.1230 - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.0832 16/122 [==>...........................] - ETA: 1s - loss: 0.1245 - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.0840 21/122 [====>.........................] - ETA: 1s - loss: 0.1236 - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.0830 26/122 [=====>........................] - ETA: 0s - loss: 0.1231 - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.0825 31/122 [======>.......................] - ETA: 0s - loss: 0.1222 - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.0819 36/122 [=======>......................] - ETA: 0s - loss: 0.1219 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0817 41/122 [=========>....................] - ETA: 0s - loss: 0.1220 - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.0818 46/122 [==========>...................] - ETA: 0s - loss: 0.1216 - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.0815 51/122 [===========>..................] - ETA: 0s - loss: 0.1217 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0817 56/122 [============>.................] - ETA: 0s - loss: 0.1218 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0819 61/122 [==============>...............] - ETA: 0s - loss: 0.1216 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0818 66/122 [===============>..............] - ETA: 0s - loss: 0.1212 - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.0814 71/122 [================>.............] - ETA: 0s - loss: 0.1210 - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.0812 76/122 [=================>............] - ETA: 0s - loss: 0.1213 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0814 81/122 [==================>...........] - ETA: 0s - loss: 0.1216 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0816 86/122 [====================>.........] - ETA: 0s - loss: 0.1217 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0817 91/122 [=====================>........] - ETA: 0s - loss: 0.1219 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0819 96/122 [======================>.......] - ETA: 0s - loss: 0.1220 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0820101/122 [=======================>......] - ETA: 0s - loss: 0.1218 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0819106/122 [=========================>....] - ETA: 0s - loss: 0.1220 - conv2d_12_loss: 0.0400 - conv2d_19_loss: 0.0820111/122 [==========================>...] - ETA: 0s - loss: 0.1221 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0821116/122 [===========================>..] - ETA: 0s - loss: 0.1224 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0825121/122 [============================>.] - ETA: 0s - loss: 0.1224 - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.0826122/122 [==============================] - 1s 11ms/step - loss: 0.1224 - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.0825 - val_loss: 0.1394 - val_conv2d_12_loss: 0.0408 - val_conv2d_19_loss: 0.0987 - lr: 0.0010
Epoch 22/50
  1/122 [..............................] - ETA: 1s - loss: 0.1268 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0890  6/122 [>.............................] - ETA: 1s - loss: 0.1241 - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.0855 11/122 [=>............................] - ETA: 1s - loss: 0.1253 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0871 16/122 [==>...........................] - ETA: 1s - loss: 0.1250 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0870 21/122 [====>.........................] - ETA: 1s - loss: 0.1243 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0862 26/122 [=====>........................] - ETA: 0s - loss: 0.1229 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0850 31/122 [======>.......................] - ETA: 0s - loss: 0.1213 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0835 36/122 [=======>......................] - ETA: 0s - loss: 0.1205 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0827 41/122 [=========>....................] - ETA: 0s - loss: 0.1203 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0824 46/122 [==========>...................] - ETA: 0s - loss: 0.1206 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0825 51/122 [===========>..................] - ETA: 0s - loss: 0.1194 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0815 56/122 [============>.................] - ETA: 0s - loss: 0.1191 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0812 61/122 [==============>...............] - ETA: 0s - loss: 0.1189 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0810 66/122 [===============>..............] - ETA: 0s - loss: 0.1189 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0808 71/122 [================>.............] - ETA: 0s - loss: 0.1195 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0813 76/122 [=================>............] - ETA: 0s - loss: 0.1194 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0811 81/122 [==================>...........] - ETA: 0s - loss: 0.1193 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0811 86/122 [====================>.........] - ETA: 0s - loss: 0.1193 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0811 91/122 [=====================>........] - ETA: 0s - loss: 0.1193 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0812 96/122 [======================>.......] - ETA: 0s - loss: 0.1193 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0812101/122 [=======================>......] - ETA: 0s - loss: 0.1194 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0813106/122 [=========================>....] - ETA: 0s - loss: 0.1192 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0811111/122 [==========================>...] - ETA: 0s - loss: 0.1192 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0811116/122 [===========================>..] - ETA: 0s - loss: 0.1191 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0810121/122 [============================>.] - ETA: 0s - loss: 0.1190 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0809122/122 [==============================] - 1s 11ms/step - loss: 0.1190 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0809 - val_loss: 0.1284 - val_conv2d_12_loss: 0.0407 - val_conv2d_19_loss: 0.0878 - lr: 0.0010
Epoch 23/50
  1/122 [..............................] - ETA: 1s - loss: 0.1041 - conv2d_12_loss: 0.0348 - conv2d_19_loss: 0.0693  6/122 [>.............................] - ETA: 1s - loss: 0.1109 - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.0738 11/122 [=>............................] - ETA: 1s - loss: 0.1116 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0742 16/122 [==>...........................] - ETA: 1s - loss: 0.1111 - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.0738 21/122 [====>.........................] - ETA: 1s - loss: 0.1115 - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.0742 26/122 [=====>........................] - ETA: 1s - loss: 0.1126 - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.0749 31/122 [======>.......................] - ETA: 0s - loss: 0.1129 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0750 36/122 [=======>......................] - ETA: 0s - loss: 0.1134 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0754 41/122 [=========>....................] - ETA: 0s - loss: 0.1136 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0755 46/122 [==========>...................] - ETA: 0s - loss: 0.1138 - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.0756 51/122 [===========>..................] - ETA: 0s - loss: 0.1136 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0755 56/122 [============>.................] - ETA: 0s - loss: 0.1140 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0760 61/122 [==============>...............] - ETA: 0s - loss: 0.1146 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0766 66/122 [===============>..............] - ETA: 0s - loss: 0.1148 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0768 71/122 [================>.............] - ETA: 0s - loss: 0.1147 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0768 76/122 [=================>............] - ETA: 0s - loss: 0.1147 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0768 81/122 [==================>...........] - ETA: 0s - loss: 0.1146 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0767 86/122 [====================>.........] - ETA: 0s - loss: 0.1145 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0766 91/122 [=====================>........] - ETA: 0s - loss: 0.1145 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0766 96/122 [======================>.......] - ETA: 0s - loss: 0.1144 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0766101/122 [=======================>......] - ETA: 0s - loss: 0.1144 - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.0765106/122 [=========================>....] - ETA: 0s - loss: 0.1148 - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.0768111/122 [==========================>...] - ETA: 0s - loss: 0.1150 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0769116/122 [===========================>..] - ETA: 0s - loss: 0.1148 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0768121/122 [============================>.] - ETA: 0s - loss: 0.1146 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0766122/122 [==============================] - 1s 11ms/step - loss: 0.1147 - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.0766 - val_loss: 0.1262 - val_conv2d_12_loss: 0.0413 - val_conv2d_19_loss: 0.0849 - lr: 0.0010
Epoch 24/50
  1/122 [..............................] - ETA: 1s - loss: 0.1138 - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.0750  6/122 [>.............................] - ETA: 1s - loss: 0.1139 - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.0748 11/122 [=>............................] - ETA: 1s - loss: 0.1121 - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.0738 16/122 [==>...........................] - ETA: 1s - loss: 0.1113 - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.0734 21/122 [====>.........................] - ETA: 1s - loss: 0.1110 - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.0732 26/122 [=====>........................] - ETA: 1s - loss: 0.1113 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0737 31/122 [======>.......................] - ETA: 0s - loss: 0.1107 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0734 36/122 [=======>......................] - ETA: 0s - loss: 0.1117 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0742 41/122 [=========>....................] - ETA: 0s - loss: 0.1123 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0748 46/122 [==========>...................] - ETA: 0s - loss: 0.1121 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0745 51/122 [===========>..................] - ETA: 0s - loss: 0.1119 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0745 56/122 [============>.................] - ETA: 0s - loss: 0.1118 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0744 61/122 [==============>...............] - ETA: 0s - loss: 0.1121 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0746 66/122 [===============>..............] - ETA: 0s - loss: 0.1121 - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.0746 71/122 [================>.............] - ETA: 0s - loss: 0.1122 - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.0747 76/122 [=================>............] - ETA: 0s - loss: 0.1118 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0743 81/122 [==================>...........] - ETA: 0s - loss: 0.1117 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0743 86/122 [====================>.........] - ETA: 0s - loss: 0.1116 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0743 91/122 [=====================>........] - ETA: 0s - loss: 0.1116 - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.0742 96/122 [======================>.......] - ETA: 0s - loss: 0.1117 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0744101/122 [=======================>......] - ETA: 0s - loss: 0.1118 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0744106/122 [=========================>....] - ETA: 0s - loss: 0.1119 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0745111/122 [==========================>...] - ETA: 0s - loss: 0.1120 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0746116/122 [===========================>..] - ETA: 0s - loss: 0.1120 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0746121/122 [============================>.] - ETA: 0s - loss: 0.1119 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0745122/122 [==============================] - 1s 11ms/step - loss: 0.1119 - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.0745 - val_loss: 0.1237 - val_conv2d_12_loss: 0.0397 - val_conv2d_19_loss: 0.0840 - lr: 0.0010
Epoch 25/50
  1/122 [..............................] - ETA: 1s - loss: 0.1042 - conv2d_12_loss: 0.0347 - conv2d_19_loss: 0.0694  6/122 [>.............................] - ETA: 1s - loss: 0.1089 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0730 11/122 [=>............................] - ETA: 1s - loss: 0.1084 - conv2d_12_loss: 0.0357 - conv2d_19_loss: 0.0727 16/122 [==>...........................] - ETA: 1s - loss: 0.1094 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0734 21/122 [====>.........................] - ETA: 1s - loss: 0.1105 - conv2d_12_loss: 0.0365 - conv2d_19_loss: 0.0740 26/122 [=====>........................] - ETA: 1s - loss: 0.1106 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0740 31/122 [======>.......................] - ETA: 0s - loss: 0.1106 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0738 36/122 [=======>......................] - ETA: 0s - loss: 0.1111 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0743 41/122 [=========>....................] - ETA: 0s - loss: 0.1108 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0739 46/122 [==========>...................] - ETA: 0s - loss: 0.1108 - conv2d_12_loss: 0.0369 - conv2d_19_loss: 0.0739 51/122 [===========>..................] - ETA: 0s - loss: 0.1104 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0736 56/122 [============>.................] - ETA: 0s - loss: 0.1101 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0733 61/122 [==============>...............] - ETA: 0s - loss: 0.1100 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0732 66/122 [===============>..............] - ETA: 0s - loss: 0.1099 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0731 71/122 [================>.............] - ETA: 0s - loss: 0.1099 - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.0731 76/122 [=================>............] - ETA: 0s - loss: 0.1096 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0729 81/122 [==================>...........] - ETA: 0s - loss: 0.1099 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0732 86/122 [====================>.........] - ETA: 0s - loss: 0.1101 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0734 91/122 [=====================>........] - ETA: 0s - loss: 0.1101 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0734 96/122 [======================>.......] - ETA: 0s - loss: 0.1101 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0734101/122 [=======================>......] - ETA: 0s - loss: 0.1100 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0733106/122 [=========================>....] - ETA: 0s - loss: 0.1098 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0731111/122 [==========================>...] - ETA: 0s - loss: 0.1097 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0730116/122 [===========================>..] - ETA: 0s - loss: 0.1096 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0729121/122 [============================>.] - ETA: 0s - loss: 0.1094 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0728122/122 [==============================] - 1s 11ms/step - loss: 0.1094 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0727 - val_loss: 0.1198 - val_conv2d_12_loss: 0.0388 - val_conv2d_19_loss: 0.0810 - lr: 0.0010
Epoch 26/50
  1/122 [..............................] - ETA: 1s - loss: 0.1039 - conv2d_12_loss: 0.0350 - conv2d_19_loss: 0.0689  6/122 [>.............................] - ETA: 1s - loss: 0.1030 - conv2d_12_loss: 0.0355 - conv2d_19_loss: 0.0675 11/122 [=>............................] - ETA: 1s - loss: 0.1034 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0679 16/122 [==>...........................] - ETA: 1s - loss: 0.1040 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0683 21/122 [====>.........................] - ETA: 1s - loss: 0.1034 - conv2d_12_loss: 0.0355 - conv2d_19_loss: 0.0679 26/122 [=====>........................] - ETA: 0s - loss: 0.1037 - conv2d_12_loss: 0.0355 - conv2d_19_loss: 0.0682 31/122 [======>.......................] - ETA: 0s - loss: 0.1039 - conv2d_12_loss: 0.0354 - conv2d_19_loss: 0.0685 36/122 [=======>......................] - ETA: 0s - loss: 0.1048 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0692 41/122 [=========>....................] - ETA: 0s - loss: 0.1053 - conv2d_12_loss: 0.0357 - conv2d_19_loss: 0.0696 46/122 [==========>...................] - ETA: 0s - loss: 0.1057 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0699 51/122 [===========>..................] - ETA: 0s - loss: 0.1060 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0701 56/122 [============>.................] - ETA: 0s - loss: 0.1062 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0702 61/122 [==============>...............] - ETA: 0s - loss: 0.1064 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0703 66/122 [===============>..............] - ETA: 0s - loss: 0.1070 - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.0708 71/122 [================>.............] - ETA: 0s - loss: 0.1071 - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.0709 76/122 [=================>............] - ETA: 0s - loss: 0.1071 - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.0708 81/122 [==================>...........] - ETA: 0s - loss: 0.1080 - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.0716 86/122 [====================>.........] - ETA: 0s - loss: 0.1084 - conv2d_12_loss: 0.0365 - conv2d_19_loss: 0.0718 91/122 [=====================>........] - ETA: 0s - loss: 0.1083 - conv2d_12_loss: 0.0365 - conv2d_19_loss: 0.0718 96/122 [======================>.......] - ETA: 0s - loss: 0.1085 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0718101/122 [=======================>......] - ETA: 0s - loss: 0.1084 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0718106/122 [=========================>....] - ETA: 0s - loss: 0.1086 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0719111/122 [==========================>...] - ETA: 0s - loss: 0.1088 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0721116/122 [===========================>..] - ETA: 0s - loss: 0.1085 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0719121/122 [============================>.] - ETA: 0s - loss: 0.1086 - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.0719122/122 [==============================] - 1s 11ms/step - loss: 0.1086 - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.0719 - val_loss: 0.1233 - val_conv2d_12_loss: 0.0393 - val_conv2d_19_loss: 0.0840 - lr: 0.0010
Epoch 27/50
  1/122 [..............................] - ETA: 1s - loss: 0.1095 - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.0723  6/122 [>.............................] - ETA: 1s - loss: 0.1054 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0698 11/122 [=>............................] - ETA: 1s - loss: 0.1046 - conv2d_12_loss: 0.0357 - conv2d_19_loss: 0.0688 16/122 [==>...........................] - ETA: 1s - loss: 0.1055 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0698 21/122 [====>.........................] - ETA: 1s - loss: 0.1057 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0700 26/122 [=====>........................] - ETA: 0s - loss: 0.1050 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0694 31/122 [======>.......................] - ETA: 0s - loss: 0.1053 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0697 36/122 [=======>......................] - ETA: 0s - loss: 0.1048 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0693 41/122 [=========>....................] - ETA: 0s - loss: 0.1051 - conv2d_12_loss: 0.0356 - conv2d_19_loss: 0.0694 46/122 [==========>...................] - ETA: 0s - loss: 0.1052 - conv2d_12_loss: 0.0357 - conv2d_19_loss: 0.0695 51/122 [===========>..................] - ETA: 0s - loss: 0.1056 - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.0698 56/122 [============>.................] - ETA: 0s - loss: 0.1056 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0698 61/122 [==============>...............] - ETA: 0s - loss: 0.1056 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0697 66/122 [===============>..............] - ETA: 0s - loss: 0.1058 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0699 71/122 [================>.............] - ETA: 0s - loss: 0.1059 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0700 76/122 [=================>............] - ETA: 0s - loss: 0.1057 - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.0699 81/122 [==================>...........] - ETA: 0s - loss: 0.1062 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0702 86/122 [====================>.........] - ETA: 0s - loss: 0.1063 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0703 91/122 [=====================>........] - ETA: 0s - loss: 0.1066 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0705 96/122 [======================>.......] - ETA: 0s - loss: 0.1066 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0705101/122 [=======================>......] - ETA: 0s - loss: 0.1066 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0705106/122 [=========================>....] - ETA: 0s - loss: 0.1067 - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.0705111/122 [==========================>...] - ETA: 0s - loss: 0.1066 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0705116/122 [===========================>..] - ETA: 0s - loss: 0.1066 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0705121/122 [============================>.] - ETA: 0s - loss: 0.1065 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0704
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 0.1064 - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.0704 - val_loss: 0.1204 - val_conv2d_12_loss: 0.0389 - val_conv2d_19_loss: 0.0815 - lr: 0.0010
Epoch 28/50
  1/122 [..............................] - ETA: 1s - loss: 0.0962 - conv2d_12_loss: 0.0341 - conv2d_19_loss: 0.0621  6/122 [>.............................] - ETA: 1s - loss: 0.1002 - conv2d_12_loss: 0.0352 - conv2d_19_loss: 0.0651 11/122 [=>............................] - ETA: 1s - loss: 0.1004 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0655 16/122 [==>...........................] - ETA: 1s - loss: 0.1000 - conv2d_12_loss: 0.0348 - conv2d_19_loss: 0.0652 21/122 [====>.........................] - ETA: 1s - loss: 0.1000 - conv2d_12_loss: 0.0347 - conv2d_19_loss: 0.0653 26/122 [=====>........................] - ETA: 1s - loss: 0.0988 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0644 31/122 [======>.......................] - ETA: 0s - loss: 0.0992 - conv2d_12_loss: 0.0346 - conv2d_19_loss: 0.0646 36/122 [=======>......................] - ETA: 0s - loss: 0.0989 - conv2d_12_loss: 0.0346 - conv2d_19_loss: 0.0643 41/122 [=========>....................] - ETA: 0s - loss: 0.0980 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0636 46/122 [==========>...................] - ETA: 0s - loss: 0.0983 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0638 51/122 [===========>..................] - ETA: 0s - loss: 0.0984 - conv2d_12_loss: 0.0345 - conv2d_19_loss: 0.0638 56/122 [============>.................] - ETA: 0s - loss: 0.0979 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0635 61/122 [==============>...............] - ETA: 0s - loss: 0.0973 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0630 66/122 [===============>..............] - ETA: 0s - loss: 0.0972 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0629 71/122 [================>.............] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0626 76/122 [=================>............] - ETA: 0s - loss: 0.0975 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0631 81/122 [==================>...........] - ETA: 0s - loss: 0.0974 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0631 86/122 [====================>.........] - ETA: 0s - loss: 0.0976 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0632 91/122 [=====================>........] - ETA: 0s - loss: 0.0975 - conv2d_12_loss: 0.0344 - conv2d_19_loss: 0.0632 96/122 [======================>.......] - ETA: 0s - loss: 0.0974 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0630101/122 [=======================>......] - ETA: 0s - loss: 0.0972 - conv2d_12_loss: 0.0343 - conv2d_19_loss: 0.0629106/122 [=========================>....] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0627111/122 [==========================>...] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0627116/122 [===========================>..] - ETA: 0s - loss: 0.0969 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0627121/122 [============================>.] - ETA: 0s - loss: 0.0968 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0626122/122 [==============================] - 1s 11ms/step - loss: 0.0968 - conv2d_12_loss: 0.0342 - conv2d_19_loss: 0.0626 - val_loss: 0.1152 - val_conv2d_12_loss: 0.0378 - val_conv2d_19_loss: 0.0775 - lr: 5.0000e-04
Epoch 29/50
  1/122 [..............................] - ETA: 1s - loss: 0.1063 - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.0703  6/122 [>.............................] - ETA: 1s - loss: 0.1003 - conv2d_12_loss: 0.0349 - conv2d_19_loss: 0.0654 11/122 [=>............................] - ETA: 1s - loss: 0.0961 - conv2d_12_loss: 0.0338 - conv2d_19_loss: 0.0623 16/122 [==>...........................] - ETA: 1s - loss: 0.0956 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0619 21/122 [====>.........................] - ETA: 1s - loss: 0.0942 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0608 26/122 [=====>........................] - ETA: 0s - loss: 0.0946 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0610 31/122 [======>.......................] - ETA: 0s - loss: 0.0948 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0611 36/122 [=======>......................] - ETA: 0s - loss: 0.0941 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0605 41/122 [=========>....................] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0606 46/122 [==========>...................] - ETA: 0s - loss: 0.0943 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0605 51/122 [===========>..................] - ETA: 0s - loss: 0.0942 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0605 56/122 [============>.................] - ETA: 0s - loss: 0.0941 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0604 61/122 [==============>...............] - ETA: 0s - loss: 0.0939 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0603 66/122 [===============>..............] - ETA: 0s - loss: 0.0942 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0605 71/122 [================>.............] - ETA: 0s - loss: 0.0940 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0604 76/122 [=================>............] - ETA: 0s - loss: 0.0939 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0602 81/122 [==================>...........] - ETA: 0s - loss: 0.0935 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0600 86/122 [====================>.........] - ETA: 0s - loss: 0.0936 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0600 91/122 [=====================>........] - ETA: 0s - loss: 0.0938 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0602 96/122 [======================>.......] - ETA: 0s - loss: 0.0938 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0602101/122 [=======================>......] - ETA: 0s - loss: 0.0938 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0602106/122 [=========================>....] - ETA: 0s - loss: 0.0939 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0603111/122 [==========================>...] - ETA: 0s - loss: 0.0940 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0604116/122 [===========================>..] - ETA: 0s - loss: 0.0940 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0603121/122 [============================>.] - ETA: 0s - loss: 0.0940 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0604122/122 [==============================] - 1s 11ms/step - loss: 0.0941 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0604 - val_loss: 0.1133 - val_conv2d_12_loss: 0.0374 - val_conv2d_19_loss: 0.0759 - lr: 5.0000e-04
Epoch 30/50
  1/122 [..............................] - ETA: 1s - loss: 0.0833 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0511  6/122 [>.............................] - ETA: 1s - loss: 0.0887 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0559 11/122 [=>............................] - ETA: 1s - loss: 0.0910 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0577 16/122 [==>...........................] - ETA: 1s - loss: 0.0913 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0579 21/122 [====>.........................] - ETA: 1s - loss: 0.0902 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0572 26/122 [=====>........................] - ETA: 0s - loss: 0.0911 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0578 31/122 [======>.......................] - ETA: 0s - loss: 0.0922 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0588 36/122 [=======>......................] - ETA: 0s - loss: 0.0915 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0583 41/122 [=========>....................] - ETA: 0s - loss: 0.0920 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0587 46/122 [==========>...................] - ETA: 0s - loss: 0.0916 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0584 51/122 [===========>..................] - ETA: 0s - loss: 0.0915 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0583 56/122 [============>.................] - ETA: 0s - loss: 0.0917 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0584 61/122 [==============>...............] - ETA: 0s - loss: 0.0919 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0586 66/122 [===============>..............] - ETA: 0s - loss: 0.0919 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0586 71/122 [================>.............] - ETA: 0s - loss: 0.0920 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0587 76/122 [=================>............] - ETA: 0s - loss: 0.0922 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0588 81/122 [==================>...........] - ETA: 0s - loss: 0.0922 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0589 86/122 [====================>.........] - ETA: 0s - loss: 0.0925 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591 91/122 [=====================>........] - ETA: 0s - loss: 0.0924 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591 96/122 [======================>.......] - ETA: 0s - loss: 0.0923 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0590101/122 [=======================>......] - ETA: 0s - loss: 0.0924 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591106/122 [=========================>....] - ETA: 0s - loss: 0.0925 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591111/122 [==========================>...] - ETA: 0s - loss: 0.0925 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0591116/122 [===========================>..] - ETA: 0s - loss: 0.0924 - conv2d_12_loss: 0.0333 - conv2d_19_loss: 0.0591121/122 [============================>.] - ETA: 0s - loss: 0.0925 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591122/122 [==============================] - 1s 11ms/step - loss: 0.0925 - conv2d_12_loss: 0.0334 - conv2d_19_loss: 0.0591 - val_loss: 0.1127 - val_conv2d_12_loss: 0.0374 - val_conv2d_19_loss: 0.0753 - lr: 5.0000e-04
Epoch 31/50
  1/122 [..............................] - ETA: 1s - loss: 0.0933 - conv2d_12_loss: 0.0335 - conv2d_19_loss: 0.0598  6/122 [>.............................] - ETA: 1s - loss: 0.0894 - conv2d_12_loss: 0.0325 - conv2d_19_loss: 0.0569 11/122 [=>............................] - ETA: 1s - loss: 0.0897 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0568 16/122 [==>...........................] - ETA: 1s - loss: 0.0897 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0569 21/122 [====>.........................] - ETA: 1s - loss: 0.0901 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0573 26/122 [=====>........................] - ETA: 1s - loss: 0.0903 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0574 31/122 [======>.......................] - ETA: 0s - loss: 0.0904 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0574 36/122 [=======>......................] - ETA: 0s - loss: 0.0906 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0576 41/122 [=========>....................] - ETA: 0s - loss: 0.0906 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0577 46/122 [==========>...................] - ETA: 0s - loss: 0.0909 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0579 51/122 [===========>..................] - ETA: 0s - loss: 0.0906 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0577 56/122 [============>.................] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0576 61/122 [==============>...............] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0576 66/122 [===============>..............] - ETA: 0s - loss: 0.0901 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0573 71/122 [================>.............] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0574 76/122 [=================>............] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0576 81/122 [==================>...........] - ETA: 0s - loss: 0.0904 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0575 86/122 [====================>.........] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0576 91/122 [=====================>........] - ETA: 0s - loss: 0.0908 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0578 96/122 [======================>.......] - ETA: 0s - loss: 0.0907 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0578101/122 [=======================>......] - ETA: 0s - loss: 0.0909 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0579106/122 [=========================>....] - ETA: 0s - loss: 0.0910 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0580111/122 [==========================>...] - ETA: 0s - loss: 0.0912 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0581116/122 [===========================>..] - ETA: 0s - loss: 0.0914 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0583121/122 [============================>.] - ETA: 0s - loss: 0.0916 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0584122/122 [==============================] - 1s 11ms/step - loss: 0.0916 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0584 - val_loss: 0.1128 - val_conv2d_12_loss: 0.0373 - val_conv2d_19_loss: 0.0755 - lr: 5.0000e-04
Epoch 32/50
  1/122 [..............................] - ETA: 1s - loss: 0.0887 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0572  6/122 [>.............................] - ETA: 1s - loss: 0.0917 - conv2d_12_loss: 0.0336 - conv2d_19_loss: 0.0581 11/122 [=>............................] - ETA: 1s - loss: 0.0914 - conv2d_12_loss: 0.0332 - conv2d_19_loss: 0.0582 16/122 [==>...........................] - ETA: 1s - loss: 0.0910 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0579 21/122 [====>.........................] - ETA: 1s - loss: 0.0909 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0578 26/122 [=====>........................] - ETA: 0s - loss: 0.0907 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0576 31/122 [======>.......................] - ETA: 0s - loss: 0.0911 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0580 36/122 [=======>......................] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0575 41/122 [=========>....................] - ETA: 0s - loss: 0.0900 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0572 46/122 [==========>...................] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0575 51/122 [===========>..................] - ETA: 0s - loss: 0.0906 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0576 56/122 [============>.................] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0573 61/122 [==============>...............] - ETA: 0s - loss: 0.0901 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0572 66/122 [===============>..............] - ETA: 0s - loss: 0.0900 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0572 71/122 [================>.............] - ETA: 0s - loss: 0.0904 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0574 76/122 [=================>............] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0573 81/122 [==================>...........] - ETA: 0s - loss: 0.0901 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0573 86/122 [====================>.........] - ETA: 0s - loss: 0.0899 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0571 91/122 [=====================>........] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0573 96/122 [======================>.......] - ETA: 0s - loss: 0.0903 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0574101/122 [=======================>......] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0573106/122 [=========================>....] - ETA: 0s - loss: 0.0902 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0573111/122 [==========================>...] - ETA: 0s - loss: 0.0904 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0575116/122 [===========================>..] - ETA: 0s - loss: 0.0905 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0575121/122 [============================>.] - ETA: 0s - loss: 0.0907 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0577
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 0.0906 - conv2d_12_loss: 0.0330 - conv2d_19_loss: 0.0577 - val_loss: 0.1133 - val_conv2d_12_loss: 0.0376 - val_conv2d_19_loss: 0.0757 - lr: 5.0000e-04
Epoch 33/50
  1/122 [..............................] - ETA: 1s - loss: 0.0915 - conv2d_12_loss: 0.0327 - conv2d_19_loss: 0.0588  6/122 [>.............................] - ETA: 1s - loss: 0.0914 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0585 11/122 [=>............................] - ETA: 1s - loss: 0.0932 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0596 16/122 [==>...........................] - ETA: 1s - loss: 0.0909 - conv2d_12_loss: 0.0331 - conv2d_19_loss: 0.0577 21/122 [====>.........................] - ETA: 1s - loss: 0.0898 - conv2d_12_loss: 0.0329 - conv2d_19_loss: 0.0569 26/122 [=====>........................] - ETA: 0s - loss: 0.0888 - conv2d_12_loss: 0.0327 - conv2d_19_loss: 0.0561 31/122 [======>.......................] - ETA: 0s - loss: 0.0876 - conv2d_12_loss: 0.0324 - conv2d_19_loss: 0.0552 36/122 [=======>......................] - ETA: 0s - loss: 0.0869 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0547 41/122 [=========>....................] - ETA: 0s - loss: 0.0871 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0548 46/122 [==========>...................] - ETA: 0s - loss: 0.0868 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0546 51/122 [===========>..................] - ETA: 0s - loss: 0.0867 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0545 56/122 [============>.................] - ETA: 0s - loss: 0.0865 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0543 61/122 [==============>...............] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0543 66/122 [===============>..............] - ETA: 0s - loss: 0.0863 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0542 71/122 [================>.............] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543 76/122 [=================>............] - ETA: 0s - loss: 0.0865 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543 81/122 [==================>...........] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543 86/122 [====================>.........] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0542 91/122 [=====================>........] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543 96/122 [======================>.......] - ETA: 0s - loss: 0.0865 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543101/122 [=======================>......] - ETA: 0s - loss: 0.0864 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0542106/122 [=========================>....] - ETA: 0s - loss: 0.0866 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0544111/122 [==========================>...] - ETA: 0s - loss: 0.0865 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0543116/122 [===========================>..] - ETA: 0s - loss: 0.0867 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0545121/122 [============================>.] - ETA: 0s - loss: 0.0868 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0546122/122 [==============================] - 1s 11ms/step - loss: 0.0868 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0546 - val_loss: 0.1105 - val_conv2d_12_loss: 0.0370 - val_conv2d_19_loss: 0.0735 - lr: 2.5000e-04
Epoch 34/50
  1/122 [..............................] - ETA: 1s - loss: 0.0846 - conv2d_12_loss: 0.0324 - conv2d_19_loss: 0.0522  6/122 [>.............................] - ETA: 1s - loss: 0.0878 - conv2d_12_loss: 0.0326 - conv2d_19_loss: 0.0552 11/122 [=>............................] - ETA: 1s - loss: 0.0855 - conv2d_12_loss: 0.0322 - conv2d_19_loss: 0.0533 16/122 [==>...........................] - ETA: 1s - loss: 0.0855 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0534 21/122 [====>.........................] - ETA: 1s - loss: 0.0855 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0534 26/122 [=====>........................] - ETA: 0s - loss: 0.0859 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0538 31/122 [======>.......................] - ETA: 0s - loss: 0.0855 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535 36/122 [=======>......................] - ETA: 0s - loss: 0.0853 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0533 41/122 [=========>....................] - ETA: 0s - loss: 0.0851 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0532 46/122 [==========>...................] - ETA: 0s - loss: 0.0851 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0531 51/122 [===========>..................] - ETA: 0s - loss: 0.0851 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0531 56/122 [============>.................] - ETA: 0s - loss: 0.0851 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0531 61/122 [==============>...............] - ETA: 0s - loss: 0.0850 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0531 66/122 [===============>..............] - ETA: 0s - loss: 0.0849 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0530 71/122 [================>.............] - ETA: 0s - loss: 0.0854 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0533 76/122 [=================>............] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0535 81/122 [==================>...........] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535 86/122 [====================>.........] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0535 91/122 [=====================>........] - ETA: 0s - loss: 0.0857 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0536 96/122 [======================>.......] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0535101/122 [=======================>......] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0535106/122 [=========================>....] - ETA: 0s - loss: 0.0856 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535111/122 [==========================>...] - ETA: 0s - loss: 0.0855 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535116/122 [===========================>..] - ETA: 0s - loss: 0.0855 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535121/122 [============================>.] - ETA: 0s - loss: 0.0855 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0535122/122 [==============================] - 1s 11ms/step - loss: 0.0854 - conv2d_12_loss: 0.0320 - conv2d_19_loss: 0.0534 - val_loss: 0.1094 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.0728 - lr: 2.5000e-04
Epoch 35/50
  1/122 [..............................] - ETA: 1s - loss: 0.0841 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0523  6/122 [>.............................] - ETA: 1s - loss: 0.0850 - conv2d_12_loss: 0.0321 - conv2d_19_loss: 0.0530 11/122 [=>............................] - ETA: 1s - loss: 0.0831 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0514 16/122 [==>...........................] - ETA: 1s - loss: 0.0822 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0508 21/122 [====>.........................] - ETA: 1s - loss: 0.0835 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0518 26/122 [=====>........................] - ETA: 1s - loss: 0.0834 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0517 31/122 [======>.......................] - ETA: 0s - loss: 0.0841 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0522 36/122 [=======>......................] - ETA: 0s - loss: 0.0842 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0523 41/122 [=========>....................] - ETA: 0s - loss: 0.0841 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0523 46/122 [==========>...................] - ETA: 0s - loss: 0.0844 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0525 51/122 [===========>..................] - ETA: 0s - loss: 0.0843 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0525 56/122 [============>.................] - ETA: 0s - loss: 0.0845 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0526 61/122 [==============>...............] - ETA: 0s - loss: 0.0844 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0526 66/122 [===============>..............] - ETA: 0s - loss: 0.0845 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0526 71/122 [================>.............] - ETA: 0s - loss: 0.0845 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0526 76/122 [=================>............] - ETA: 0s - loss: 0.0844 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0525 81/122 [==================>...........] - ETA: 0s - loss: 0.0844 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0526 86/122 [====================>.........] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0527 91/122 [=====================>........] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0528 96/122 [======================>.......] - ETA: 0s - loss: 0.0847 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0528101/122 [=======================>......] - ETA: 0s - loss: 0.0849 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0530106/122 [=========================>....] - ETA: 0s - loss: 0.0849 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0530111/122 [==========================>...] - ETA: 0s - loss: 0.0850 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0531116/122 [===========================>..] - ETA: 0s - loss: 0.0850 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0531121/122 [============================>.] - ETA: 0s - loss: 0.0848 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0530122/122 [==============================] - 1s 11ms/step - loss: 0.0849 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0530 - val_loss: 0.1092 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.0726 - lr: 2.5000e-04
Epoch 36/50
  1/122 [..............................] - ETA: 1s - loss: 0.0811 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0504  6/122 [>.............................] - ETA: 1s - loss: 0.0838 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0527 11/122 [=>............................] - ETA: 1s - loss: 0.0845 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0531 16/122 [==>...........................] - ETA: 1s - loss: 0.0835 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0522 21/122 [====>.........................] - ETA: 1s - loss: 0.0846 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0530 26/122 [=====>........................] - ETA: 1s - loss: 0.0838 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0524 31/122 [======>.......................] - ETA: 0s - loss: 0.0845 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0529 36/122 [=======>......................] - ETA: 0s - loss: 0.0842 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0526 41/122 [=========>....................] - ETA: 0s - loss: 0.0839 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0524 46/122 [==========>...................] - ETA: 0s - loss: 0.0840 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0524 51/122 [===========>..................] - ETA: 0s - loss: 0.0839 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0523 56/122 [============>.................] - ETA: 0s - loss: 0.0842 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0526 61/122 [==============>...............] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0528 66/122 [===============>..............] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0528 71/122 [================>.............] - ETA: 0s - loss: 0.0847 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0529 76/122 [=================>............] - ETA: 0s - loss: 0.0846 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0528 81/122 [==================>...........] - ETA: 0s - loss: 0.0843 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0525 86/122 [====================>.........] - ETA: 0s - loss: 0.0843 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0526 91/122 [=====================>........] - ETA: 0s - loss: 0.0843 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0526 96/122 [======================>.......] - ETA: 0s - loss: 0.0843 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0526101/122 [=======================>......] - ETA: 0s - loss: 0.0841 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0525106/122 [=========================>....] - ETA: 0s - loss: 0.0841 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0524111/122 [==========================>...] - ETA: 0s - loss: 0.0839 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0523116/122 [===========================>..] - ETA: 0s - loss: 0.0841 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0524121/122 [============================>.] - ETA: 0s - loss: 0.0840 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0523122/122 [==============================] - 1s 11ms/step - loss: 0.0840 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0524 - val_loss: 0.1089 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.0724 - lr: 2.5000e-04
Epoch 37/50
  1/122 [..............................] - ETA: 1s - loss: 0.0701 - conv2d_12_loss: 0.0280 - conv2d_19_loss: 0.0421  6/122 [>.............................] - ETA: 1s - loss: 0.0769 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0469 11/122 [=>............................] - ETA: 1s - loss: 0.0794 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0489 16/122 [==>...........................] - ETA: 1s - loss: 0.0815 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0504 21/122 [====>.........................] - ETA: 1s - loss: 0.0812 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0501 26/122 [=====>........................] - ETA: 0s - loss: 0.0817 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0506 31/122 [======>.......................] - ETA: 0s - loss: 0.0816 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0505 36/122 [=======>......................] - ETA: 0s - loss: 0.0818 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0506 41/122 [=========>....................] - ETA: 0s - loss: 0.0825 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0511 46/122 [==========>...................] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0509 51/122 [===========>..................] - ETA: 0s - loss: 0.0823 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0509 56/122 [============>.................] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0514 61/122 [==============>...............] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0519 66/122 [===============>..............] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0518 71/122 [================>.............] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0517 76/122 [=================>............] - ETA: 0s - loss: 0.0832 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0516 81/122 [==================>...........] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0518 86/122 [====================>.........] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0518 91/122 [=====================>........] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0519 96/122 [======================>.......] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0520101/122 [=======================>......] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0519106/122 [=========================>....] - ETA: 0s - loss: 0.0837 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0520111/122 [==========================>...] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0520116/122 [===========================>..] - ETA: 0s - loss: 0.0837 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0521121/122 [============================>.] - ETA: 0s - loss: 0.0837 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0521122/122 [==============================] - 1s 11ms/step - loss: 0.0837 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0521 - val_loss: 0.1090 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.0725 - lr: 2.5000e-04
Epoch 38/50
  1/122 [..............................] - ETA: 1s - loss: 0.0744 - conv2d_12_loss: 0.0295 - conv2d_19_loss: 0.0448  6/122 [>.............................] - ETA: 1s - loss: 0.0886 - conv2d_12_loss: 0.0328 - conv2d_19_loss: 0.0558 11/122 [=>............................] - ETA: 1s - loss: 0.0842 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0526 16/122 [==>...........................] - ETA: 1s - loss: 0.0852 - conv2d_12_loss: 0.0319 - conv2d_19_loss: 0.0533 21/122 [====>.........................] - ETA: 1s - loss: 0.0839 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0523 26/122 [=====>........................] - ETA: 0s - loss: 0.0839 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0523 31/122 [======>.......................] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0520 36/122 [=======>......................] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0520 41/122 [=========>....................] - ETA: 0s - loss: 0.0830 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0516 46/122 [==========>...................] - ETA: 0s - loss: 0.0828 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0514 51/122 [===========>..................] - ETA: 0s - loss: 0.0824 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0511 56/122 [============>.................] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0510 61/122 [==============>...............] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0510 66/122 [===============>..............] - ETA: 0s - loss: 0.0821 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0509 71/122 [================>.............] - ETA: 0s - loss: 0.0821 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0509 76/122 [=================>............] - ETA: 0s - loss: 0.0824 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0511 81/122 [==================>...........] - ETA: 0s - loss: 0.0825 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0512 86/122 [====================>.........] - ETA: 0s - loss: 0.0826 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0512 91/122 [=====================>........] - ETA: 0s - loss: 0.0827 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0513 96/122 [======================>.......] - ETA: 0s - loss: 0.0827 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0513101/122 [=======================>......] - ETA: 0s - loss: 0.0827 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0513106/122 [=========================>....] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0514111/122 [==========================>...] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0515116/122 [===========================>..] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0514121/122 [============================>.] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0515122/122 [==============================] - 1s 11ms/step - loss: 0.0829 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0515 - val_loss: 0.1088 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.0723 - lr: 2.5000e-04
Epoch 39/50
  1/122 [..............................] - ETA: 1s - loss: 0.0858 - conv2d_12_loss: 0.0337 - conv2d_19_loss: 0.0521  6/122 [>.............................] - ETA: 1s - loss: 0.0829 - conv2d_12_loss: 0.0318 - conv2d_19_loss: 0.0511 11/122 [=>............................] - ETA: 1s - loss: 0.0813 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0500 16/122 [==>...........................] - ETA: 1s - loss: 0.0823 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0509 21/122 [====>.........................] - ETA: 1s - loss: 0.0829 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0513 26/122 [=====>........................] - ETA: 0s - loss: 0.0828 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0513 31/122 [======>.......................] - ETA: 0s - loss: 0.0830 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0514 36/122 [=======>......................] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0517 41/122 [=========>....................] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0516 46/122 [==========>...................] - ETA: 0s - loss: 0.0827 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0512 51/122 [===========>..................] - ETA: 0s - loss: 0.0833 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0516 56/122 [============>.................] - ETA: 0s - loss: 0.0834 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0517 61/122 [==============>...............] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0518 66/122 [===============>..............] - ETA: 0s - loss: 0.0836 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0519 71/122 [================>.............] - ETA: 0s - loss: 0.0835 - conv2d_12_loss: 0.0317 - conv2d_19_loss: 0.0518 76/122 [=================>............] - ETA: 0s - loss: 0.0832 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0516 81/122 [==================>...........] - ETA: 0s - loss: 0.0831 - conv2d_12_loss: 0.0316 - conv2d_19_loss: 0.0515 86/122 [====================>.........] - ETA: 0s - loss: 0.0829 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0513 91/122 [=====================>........] - ETA: 0s - loss: 0.0827 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0513 96/122 [======================>.......] - ETA: 0s - loss: 0.0826 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0512101/122 [=======================>......] - ETA: 0s - loss: 0.0825 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0511106/122 [=========================>....] - ETA: 0s - loss: 0.0825 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0511111/122 [==========================>...] - ETA: 0s - loss: 0.0823 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0510116/122 [===========================>..] - ETA: 0s - loss: 0.0824 - conv2d_12_loss: 0.0314 - conv2d_19_loss: 0.0510121/122 [============================>.] - ETA: 0s - loss: 0.0824 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0511122/122 [==============================] - 1s 11ms/step - loss: 0.0824 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0510 - val_loss: 0.1089 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.0724 - lr: 2.5000e-04
Epoch 40/50
  1/122 [..............................] - ETA: 1s - loss: 0.0826 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0527  6/122 [>.............................] - ETA: 1s - loss: 0.0769 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0470 11/122 [=>............................] - ETA: 1s - loss: 0.0796 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0489 16/122 [==>...........................] - ETA: 1s - loss: 0.0807 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0498 21/122 [====>.........................] - ETA: 1s - loss: 0.0808 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0499 26/122 [=====>........................] - ETA: 0s - loss: 0.0817 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0506 31/122 [======>.......................] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0508 36/122 [=======>......................] - ETA: 0s - loss: 0.0817 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0506 41/122 [=========>....................] - ETA: 0s - loss: 0.0818 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0506 46/122 [==========>...................] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0510 51/122 [===========>..................] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0509 56/122 [============>.................] - ETA: 0s - loss: 0.0818 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0507 61/122 [==============>...............] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0509 66/122 [===============>..............] - ETA: 0s - loss: 0.0823 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0510 71/122 [================>.............] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0510 76/122 [=================>............] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0510 81/122 [==================>...........] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0508 86/122 [====================>.........] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0508 91/122 [=====================>........] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0508 96/122 [======================>.......] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0508101/122 [=======================>......] - ETA: 0s - loss: 0.0822 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0509106/122 [=========================>....] - ETA: 0s - loss: 0.0821 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0508111/122 [==========================>...] - ETA: 0s - loss: 0.0819 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0507116/122 [===========================>..] - ETA: 0s - loss: 0.0818 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0506121/122 [============================>.] - ETA: 0s - loss: 0.0820 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0507
Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
122/122 [==============================] - 1s 11ms/step - loss: 0.0819 - conv2d_12_loss: 0.0312 - conv2d_19_loss: 0.0507 - val_loss: 0.1092 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.0726 - lr: 2.5000e-04
Epoch 41/50
  1/122 [..............................] - ETA: 1s - loss: 0.0763 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0464  6/122 [>.............................] - ETA: 1s - loss: 0.0822 - conv2d_12_loss: 0.0313 - conv2d_19_loss: 0.0509 11/122 [=>............................] - ETA: 1s - loss: 0.0812 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0500 16/122 [==>...........................] - ETA: 1s - loss: 0.0811 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0500 21/122 [====>.........................] - ETA: 1s - loss: 0.0797 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0490 26/122 [=====>........................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0494 31/122 [======>.......................] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0495 36/122 [=======>......................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0494 41/122 [=========>....................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493 46/122 [==========>...................] - ETA: 0s - loss: 0.0804 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0494 51/122 [===========>..................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493 56/122 [============>.................] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493 61/122 [==============>...............] - ETA: 0s - loss: 0.0806 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0496 66/122 [===============>..............] - ETA: 0s - loss: 0.0807 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0496 71/122 [================>.............] - ETA: 0s - loss: 0.0807 - conv2d_12_loss: 0.0311 - conv2d_19_loss: 0.0497 76/122 [=================>............] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0495 81/122 [==================>...........] - ETA: 0s - loss: 0.0805 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0495 86/122 [====================>.........] - ETA: 0s - loss: 0.0803 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0494 91/122 [=====================>........] - ETA: 0s - loss: 0.0802 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493 96/122 [======================>.......] - ETA: 0s - loss: 0.0802 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0492101/122 [=======================>......] - ETA: 0s - loss: 0.0799 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0491106/122 [=========================>....] - ETA: 0s - loss: 0.0801 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0492111/122 [==========================>...] - ETA: 0s - loss: 0.0800 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0491116/122 [===========================>..] - ETA: 0s - loss: 0.0800 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0492121/122 [============================>.] - ETA: 0s - loss: 0.0801 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493122/122 [==============================] - 1s 11ms/step - loss: 0.0802 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0493 - val_loss: 0.1078 - val_conv2d_12_loss: 0.0363 - val_conv2d_19_loss: 0.0715 - lr: 1.2500e-04
Epoch 42/50
  1/122 [..............................] - ETA: 1s - loss: 0.0805 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0496  6/122 [>.............................] - ETA: 1s - loss: 0.0808 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0503 11/122 [=>............................] - ETA: 1s - loss: 0.0801 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0495 16/122 [==>...........................] - ETA: 1s - loss: 0.0796 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0490 21/122 [====>.........................] - ETA: 1s - loss: 0.0791 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0485 26/122 [=====>........................] - ETA: 1s - loss: 0.0791 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0486 31/122 [======>.......................] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0488 36/122 [=======>......................] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0487 41/122 [=========>....................] - ETA: 0s - loss: 0.0797 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0490 46/122 [==========>...................] - ETA: 0s - loss: 0.0799 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0491 51/122 [===========>..................] - ETA: 0s - loss: 0.0796 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0489 56/122 [============>.................] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0487 61/122 [==============>...............] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0486 66/122 [===============>..............] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0486 71/122 [================>.............] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0484 76/122 [=================>............] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0486 81/122 [==================>...........] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0486 86/122 [====================>.........] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0487 91/122 [=====================>........] - ETA: 0s - loss: 0.0795 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0488 96/122 [======================>.......] - ETA: 0s - loss: 0.0796 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0488101/122 [=======================>......] - ETA: 0s - loss: 0.0797 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0489106/122 [=========================>....] - ETA: 0s - loss: 0.0797 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0489111/122 [==========================>...] - ETA: 0s - loss: 0.0797 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0489116/122 [===========================>..] - ETA: 0s - loss: 0.0797 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0489121/122 [============================>.] - ETA: 0s - loss: 0.0796 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0488122/122 [==============================] - 1s 11ms/step - loss: 0.0796 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0488 - val_loss: 0.1080 - val_conv2d_12_loss: 0.0363 - val_conv2d_19_loss: 0.0718 - lr: 1.2500e-04
Epoch 43/50
  1/122 [..............................] - ETA: 1s - loss: 0.0694 - conv2d_12_loss: 0.0292 - conv2d_19_loss: 0.0402  6/122 [>.............................] - ETA: 1s - loss: 0.0739 - conv2d_12_loss: 0.0296 - conv2d_19_loss: 0.0443 11/122 [=>............................] - ETA: 1s - loss: 0.0778 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0472 16/122 [==>...........................] - ETA: 1s - loss: 0.0787 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0478 21/122 [====>.........................] - ETA: 1s - loss: 0.0789 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0481 26/122 [=====>........................] - ETA: 1s - loss: 0.0794 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0486 31/122 [======>.......................] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0484 36/122 [=======>......................] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0483 41/122 [=========>....................] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0482 46/122 [==========>...................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0481 51/122 [===========>..................] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0481 56/122 [============>.................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0480 61/122 [==============>...............] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 66/122 [===============>..............] - ETA: 0s - loss: 0.0788 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0482 71/122 [================>.............] - ETA: 0s - loss: 0.0788 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0482 76/122 [=================>............] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0484 81/122 [==================>...........] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0484 86/122 [====================>.........] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485 91/122 [=====================>........] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0486 96/122 [======================>.......] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485101/122 [=======================>......] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0484106/122 [=========================>....] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0484111/122 [==========================>...] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485116/122 [===========================>..] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485121/122 [============================>.] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485122/122 [==============================] - 1s 11ms/step - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485 - val_loss: 0.1076 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0714 - lr: 1.2500e-04
Epoch 44/50
  1/122 [..............................] - ETA: 1s - loss: 0.0812 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0506  6/122 [>.............................] - ETA: 1s - loss: 0.0787 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0480 11/122 [=>............................] - ETA: 1s - loss: 0.0789 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0480 16/122 [==>...........................] - ETA: 1s - loss: 0.0786 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0478 21/122 [====>.........................] - ETA: 1s - loss: 0.0785 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0477 26/122 [=====>........................] - ETA: 1s - loss: 0.0791 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0482 31/122 [======>.......................] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0481 36/122 [=======>......................] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0483 41/122 [=========>....................] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0485 46/122 [==========>...................] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0485 51/122 [===========>..................] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0485 56/122 [============>.................] - ETA: 0s - loss: 0.0787 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0481 61/122 [==============>...............] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0483 66/122 [===============>..............] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0482 71/122 [================>.............] - ETA: 0s - loss: 0.0790 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0483 76/122 [=================>............] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0485 81/122 [==================>...........] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0486 86/122 [====================>.........] - ETA: 0s - loss: 0.0793 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0486 91/122 [=====================>........] - ETA: 0s - loss: 0.0795 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0488 96/122 [======================>.......] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0487101/122 [=======================>......] - ETA: 0s - loss: 0.0795 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0487106/122 [=========================>....] - ETA: 0s - loss: 0.0794 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0486111/122 [==========================>...] - ETA: 0s - loss: 0.0792 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485116/122 [===========================>..] - ETA: 0s - loss: 0.0791 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0485121/122 [============================>.] - ETA: 0s - loss: 0.0789 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0483122/122 [==============================] - 1s 11ms/step - loss: 0.0789 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0483 - val_loss: 0.1078 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0716 - lr: 1.2500e-04
Epoch 45/50
  1/122 [..............................] - ETA: 1s - loss: 0.0757 - conv2d_12_loss: 0.0297 - conv2d_19_loss: 0.0461  6/122 [>.............................] - ETA: 1s - loss: 0.0815 - conv2d_12_loss: 0.0315 - conv2d_19_loss: 0.0500 11/122 [=>............................] - ETA: 1s - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 16/122 [==>...........................] - ETA: 1s - loss: 0.0793 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0487 21/122 [====>.........................] - ETA: 1s - loss: 0.0785 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0481 26/122 [=====>........................] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0480 31/122 [======>.......................] - ETA: 0s - loss: 0.0783 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0479 36/122 [=======>......................] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0479 41/122 [=========>....................] - ETA: 0s - loss: 0.0783 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0480 46/122 [==========>...................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0481 51/122 [===========>..................] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0481 56/122 [============>.................] - ETA: 0s - loss: 0.0783 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0478 61/122 [==============>...............] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0477 66/122 [===============>..............] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480 71/122 [================>.............] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 76/122 [=================>............] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 81/122 [==================>...........] - ETA: 0s - loss: 0.0781 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0477 86/122 [====================>.........] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 91/122 [=====================>........] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480 96/122 [======================>.......] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479101/122 [=======================>......] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480106/122 [=========================>....] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0481111/122 [==========================>...] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480116/122 [===========================>..] - ETA: 0s - loss: 0.0785 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480121/122 [============================>.] - ETA: 0s - loss: 0.0786 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0480122/122 [==============================] - 1s 11ms/step - loss: 0.0787 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0481 - val_loss: 0.1073 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0712 - lr: 1.2500e-04
Epoch 46/50
  1/122 [..............................] - ETA: 1s - loss: 0.0760 - conv2d_12_loss: 0.0308 - conv2d_19_loss: 0.0453  6/122 [>.............................] - ETA: 1s - loss: 0.0749 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0451 11/122 [=>............................] - ETA: 1s - loss: 0.0793 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0482 16/122 [==>...........................] - ETA: 1s - loss: 0.0785 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0478 21/122 [====>.........................] - ETA: 1s - loss: 0.0783 - conv2d_12_loss: 0.0307 - conv2d_19_loss: 0.0476 26/122 [=====>........................] - ETA: 1s - loss: 0.0781 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0475 31/122 [======>.......................] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0470 36/122 [=======>......................] - ETA: 0s - loss: 0.0776 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0471 41/122 [=========>....................] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0470 46/122 [==========>...................] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0470 51/122 [===========>..................] - ETA: 0s - loss: 0.0776 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0472 56/122 [============>.................] - ETA: 0s - loss: 0.0778 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0474 61/122 [==============>...............] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0475 66/122 [===============>..............] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0474 71/122 [================>.............] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0474 76/122 [=================>............] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0475 81/122 [==================>...........] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0475 86/122 [====================>.........] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0475 91/122 [=====================>........] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475 96/122 [======================>.......] - ETA: 0s - loss: 0.0781 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0477101/122 [=======================>......] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0477106/122 [=========================>....] - ETA: 0s - loss: 0.0783 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0478111/122 [==========================>...] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0478116/122 [===========================>..] - ETA: 0s - loss: 0.0782 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0478121/122 [============================>.] - ETA: 0s - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479122/122 [==============================] - 1s 11ms/step - loss: 0.0784 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0479 - val_loss: 0.1074 - val_conv2d_12_loss: 0.0361 - val_conv2d_19_loss: 0.0713 - lr: 1.2500e-04
Epoch 47/50
  1/122 [..............................] - ETA: 1s - loss: 0.0725 - conv2d_12_loss: 0.0288 - conv2d_19_loss: 0.0437  6/122 [>.............................] - ETA: 1s - loss: 0.0765 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0467 11/122 [=>............................] - ETA: 1s - loss: 0.0766 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0467 16/122 [==>...........................] - ETA: 1s - loss: 0.0766 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0467 21/122 [====>.........................] - ETA: 1s - loss: 0.0768 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0468 26/122 [=====>........................] - ETA: 0s - loss: 0.0768 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0468 31/122 [======>.......................] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0469 36/122 [=======>......................] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469 41/122 [=========>....................] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0473 46/122 [==========>...................] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0470 51/122 [===========>..................] - ETA: 0s - loss: 0.0777 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0474 56/122 [============>.................] - ETA: 0s - loss: 0.0776 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0473 61/122 [==============>...............] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475 66/122 [===============>..............] - ETA: 0s - loss: 0.0778 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0474 71/122 [================>.............] - ETA: 0s - loss: 0.0778 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475 76/122 [=================>............] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475 81/122 [==================>...........] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0476 86/122 [====================>.........] - ETA: 0s - loss: 0.0778 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0474 91/122 [=====================>........] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475 96/122 [======================>.......] - ETA: 0s - loss: 0.0781 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0477101/122 [=======================>......] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475106/122 [=========================>....] - ETA: 0s - loss: 0.0778 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475111/122 [==========================>...] - ETA: 0s - loss: 0.0779 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0475116/122 [===========================>..] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0476121/122 [============================>.] - ETA: 0s - loss: 0.0780 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0476
Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001.
122/122 [==============================] - 1s 11ms/step - loss: 0.0780 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0476 - val_loss: 0.1073 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0711 - lr: 1.2500e-04
Epoch 48/50
  1/122 [..............................] - ETA: 1s - loss: 0.0788 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0478  6/122 [>.............................] - ETA: 1s - loss: 0.0787 - conv2d_12_loss: 0.0310 - conv2d_19_loss: 0.0476 11/122 [=>............................] - ETA: 1s - loss: 0.0791 - conv2d_12_loss: 0.0309 - conv2d_19_loss: 0.0482 16/122 [==>...........................] - ETA: 1s - loss: 0.0773 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0469 21/122 [====>.........................] - ETA: 1s - loss: 0.0777 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0473 26/122 [=====>........................] - ETA: 0s - loss: 0.0781 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0475 31/122 [======>.......................] - ETA: 0s - loss: 0.0777 - conv2d_12_loss: 0.0305 - conv2d_19_loss: 0.0472 36/122 [=======>......................] - ETA: 0s - loss: 0.0768 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0466 41/122 [=========>....................] - ETA: 0s - loss: 0.0767 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0465 46/122 [==========>...................] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0470 51/122 [===========>..................] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 56/122 [============>.................] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 61/122 [==============>...............] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0468 66/122 [===============>..............] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0468 71/122 [================>.............] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470 76/122 [=================>............] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 81/122 [==================>...........] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 86/122 [====================>.........] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 91/122 [=====================>........] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 96/122 [======================>.......] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0471101/122 [=======================>......] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0470106/122 [=========================>....] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0470111/122 [==========================>...] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0471116/122 [===========================>..] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0472121/122 [============================>.] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0471122/122 [==============================] - 1s 11ms/step - loss: 0.0775 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0472 - val_loss: 0.1066 - val_conv2d_12_loss: 0.0360 - val_conv2d_19_loss: 0.0706 - lr: 1.0000e-04
Epoch 49/50
  1/122 [..............................] - ETA: 1s - loss: 0.0728 - conv2d_12_loss: 0.0290 - conv2d_19_loss: 0.0438  6/122 [>.............................] - ETA: 1s - loss: 0.0773 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0472 11/122 [=>............................] - ETA: 1s - loss: 0.0760 - conv2d_12_loss: 0.0298 - conv2d_19_loss: 0.0462 16/122 [==>...........................] - ETA: 1s - loss: 0.0760 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0461 21/122 [====>.........................] - ETA: 1s - loss: 0.0766 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0465 26/122 [=====>........................] - ETA: 0s - loss: 0.0768 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0466 31/122 [======>.......................] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0472 36/122 [=======>......................] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0472 41/122 [=========>....................] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0471 46/122 [==========>...................] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470 51/122 [===========>..................] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470 56/122 [============>.................] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 61/122 [==============>...............] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 66/122 [===============>..............] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 71/122 [================>.............] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 76/122 [=================>............] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469 81/122 [==================>...........] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 86/122 [====================>.........] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0467 91/122 [=====================>........] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 96/122 [======================>.......] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468101/122 [=======================>......] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470106/122 [=========================>....] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470111/122 [==========================>...] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0470116/122 [===========================>..] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469121/122 [============================>.] - ETA: 0s - loss: 0.0771 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469122/122 [==============================] - 1s 11ms/step - loss: 0.0771 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469 - val_loss: 0.1075 - val_conv2d_12_loss: 0.0362 - val_conv2d_19_loss: 0.0713 - lr: 1.0000e-04
Epoch 50/50
  1/122 [..............................] - ETA: 1s - loss: 0.0708 - conv2d_12_loss: 0.0285 - conv2d_19_loss: 0.0423  6/122 [>.............................] - ETA: 1s - loss: 0.0771 - conv2d_12_loss: 0.0306 - conv2d_19_loss: 0.0465 11/122 [=>............................] - ETA: 1s - loss: 0.0756 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0457 16/122 [==>...........................] - ETA: 1s - loss: 0.0762 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0462 21/122 [====>.........................] - ETA: 1s - loss: 0.0760 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0460 26/122 [=====>........................] - ETA: 0s - loss: 0.0754 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0456 31/122 [======>.......................] - ETA: 0s - loss: 0.0756 - conv2d_12_loss: 0.0299 - conv2d_19_loss: 0.0457 36/122 [=======>......................] - ETA: 0s - loss: 0.0759 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0459 41/122 [=========>....................] - ETA: 0s - loss: 0.0761 - conv2d_12_loss: 0.0300 - conv2d_19_loss: 0.0461 46/122 [==========>...................] - ETA: 0s - loss: 0.0764 - conv2d_12_loss: 0.0301 - conv2d_19_loss: 0.0463 51/122 [===========>..................] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467 56/122 [============>.................] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 61/122 [==============>...............] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 66/122 [===============>..............] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0469 71/122 [================>.............] - ETA: 0s - loss: 0.0775 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0472 76/122 [=================>............] - ETA: 0s - loss: 0.0774 - conv2d_12_loss: 0.0304 - conv2d_19_loss: 0.0470 81/122 [==================>...........] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0469 86/122 [====================>.........] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 91/122 [=====================>........] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0469 96/122 [======================>.......] - ETA: 0s - loss: 0.0773 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0470101/122 [=======================>......] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0469106/122 [=========================>....] - ETA: 0s - loss: 0.0772 - conv2d_12_loss: 0.0303 - conv2d_19_loss: 0.0469111/122 [==========================>...] - ETA: 0s - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468116/122 [===========================>..] - ETA: 0s - loss: 0.0768 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0466121/122 [============================>.] - ETA: 0s - loss: 0.0769 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0467122/122 [==============================] - 1s 11ms/step - loss: 0.0770 - conv2d_12_loss: 0.0302 - conv2d_19_loss: 0.0468 - val_loss: 0.1068 - val_conv2d_12_loss: 0.0360 - val_conv2d_19_loss: 0.0708 - lr: 1.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:23:45,739 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1/baseline_model.h5
2025-07-27 21:23:45,740 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:38 11/322 [>.............................] - ETA: 1s   21/322 [>.............................] - ETA: 1s 31/322 [=>............................] - ETA: 1s 41/322 [==>...........................] - ETA: 1s 51/322 [===>..........................] - ETA: 1s 61/322 [====>.........................] - ETA: 1s 71/322 [=====>........................] - ETA: 1s 81/322 [======>.......................] - ETA: 1s 91/322 [=======>......................] - ETA: 1s101/322 [========>.....................] - ETA: 1s111/322 [=========>....................] - ETA: 1s121/322 [==========>...................] - ETA: 1s131/322 [===========>..................] - ETA: 0s141/322 [============>.................] - ETA: 0s151/322 [=============>................] - ETA: 0s161/322 [==============>...............] - ETA: 0s171/322 [==============>...............] - ETA: 0s181/322 [===============>..............] - ETA: 0s191/322 [================>.............] - ETA: 0s201/322 [=================>............] - ETA: 0s211/322 [==================>...........] - ETA: 0s221/322 [===================>..........] - ETA: 0s231/322 [====================>.........] - ETA: 0s241/322 [=====================>........] - ETA: 0s251/322 [======================>.......] - ETA: 0s261/322 [=======================>......] - ETA: 0s271/322 [========================>.....] - ETA: 0s281/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s301/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s321/322 [============================>.] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:23:49,192 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:23:49,192 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:23:49,192 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:23:49,192 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:23:49,192 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:23:49,192 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:23:49,192 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:23:49,192 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:23:49,192 - INFO - --- Alignment complete ---
2025-07-27 21:23:49,192 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:23:49,284 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:23:49,284 - INFO -   MAE:  (0.037498154, 0.09478639676148592)
2025-07-27 21:23:49,284 - INFO -   PSNR: (74.3058662886382, 65.89809258157186)
2025-07-27 21:23:49,397 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:23:49,397 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.005112
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.226346, std=0.084539, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.250894, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.005112
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.226346, std=0.084539, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.250894, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:23:50] SUCCESS: Baseline training (n_images=2048, trial=2)
[2025-07-27 21:23:50] EXECUTING: Tike reconstruction (n_images=4096, trial=2)
[2025-07-27 21:23:50] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_2048/trial_2/tike_run' \
                --n-images 4096 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:27:15] SUCCESS: Tike reconstruction (n_images=4096, trial=2)
[2025-07-27 21:27:15] Completed training for train_size=2048 (Trial 2/3)
[2025-07-27 21:27:15] Training models for train_size=2048, test_size=4096 (Trial 3/3)
[2025-07-27 21:27:15] EXECUTING: PtychoPINN training (n_images=2048, trial=3)
[2025-07-27 21:27:15] COMMAND: python scripts/training/train.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data_file 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run' \
            --nepochs 50
2025-07-27 21:27:16.036379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:27:16.036411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:27:16.037244: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:27:16.041371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:27:16.511703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:27:17.555030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.588412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.590610: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:27:17.750905: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.753167: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.755308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.870489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.871698: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.872810: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:27:17.872950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:27:17.874088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:27:17,902 - INFO - Configuration setup complete
2025-07-27 21:27:17,902 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run'))
2025-07-27 21:27:17,902 - INFO - Parameter interpretation: --n-images=2048 refers to individual images (gridsize=1)
2025-07-27 21:27:17,902 - INFO - Starting training with n_images=2048, stitching=disabled
2025-07-27 21:27:17,902 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:27:17,936 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
2025-07-27 21:27:17,937 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:27:18,016 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
2025-07-27 21:27:18,016 - INFO - Loaded test data from datasets/fly64/fly64_shuffled.npz
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
input shape (None, 64, 64, 1)
2025-07-27 21:27:38,827 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
 a)                                                                                               
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
 g2D)                                                                                             
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
 mbda)                                                                                            
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
 Lambda)                                                                                          
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
 g2D)                                                                                             
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
 ing2D)                                                                                           
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
 da)                                                                                              
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
 mbda)                                                                                            
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
 da)                                                                 'tf.math.subtract[0][0]']    
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
 D)                                                                                               
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
 mbda)                                                               'tf.math.subtract_1[0][0]']  
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
 Lambda)                                                             'tf.math.multiply[0][0]']    
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
                                                                    ']                            
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
 r)                                                                                               
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
                                                                     'input_positions[0][0]']     
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
 Lambda)                                                             'input_positions[0][0]']     
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
                              (None, 64, 64, 1))                                                  
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
 )                                                                                                
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
 mbda)                                                                                            
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
 ibutionLambda)               (None, 64, 64, 1))                                                  
                                                                                                  
==================================================================================================
Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:27:38.943779: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:27:38.943792: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:27:38.943814: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:27:38.960663: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:27:38.960805: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.000-0.005j
  std: 0.654
  min: -1.772+0.357j
  max: 1.781+0.163j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
2025-07-27 21:27:38,962 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
Epoch 1/50
input shape (None, 64, 64, 1)
2025-07-27 21:27:39,629 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:27:39,635 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-07-27 21:27:40,613 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:27:40,619 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-07-27 21:27:41.280936: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:27:41.309574: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x215cfc30
2025-07-27 21:27:42.479507: I external/local_xla/xla/service/service.cc:168] XLA service 0x7a5123223580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:27:42.479537: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:27:42.482679: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676862.551176 3731881 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 13:08 - loss: 706971584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 159.2198 - distribution_lambda_loss: 706971584.0000  6/122 [>.............................] - ETA: 1s - loss: 99141410816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1856.5341 - distribution_lambda_loss: 99141410816.0000 11/122 [=>............................] - ETA: 1s - loss: 54509895680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 1105.6593 - distribution_lambda_loss: 54509895680.0000 16/122 [==>...........................] - ETA: 1s - loss: 37637328896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 824.4252 - distribution_lambda_loss: 37637328896.0000  21/122 [====>.........................] - ETA: 1s - loss: 28764768256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 668.6024 - distribution_lambda_loss: 28764768256.0000 26/122 [=====>........................] - ETA: 1s - loss: 23294609408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 568.2601 - distribution_lambda_loss: 23294609408.0000 31/122 [======>.......................] - ETA: 0s - loss: 19582474240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 501.5509 - distribution_lambda_loss: 19582474240.0000 36/122 [=======>......................] - ETA: 0s - loss: 16896318464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 449.7142 - distribution_lambda_loss: 16896318464.0000 41/122 [=========>....................] - ETA: 0s - loss: 14861280256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 410.1782 - distribution_lambda_loss: 14861280256.0000 46/122 [==========>...................] - ETA: 0s - loss: 13267129344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 378.9919 - distribution_lambda_loss: 13267129344.0000 51/122 [===========>..................] - ETA: 0s - loss: 11983817728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 353.1370 - distribution_lambda_loss: 11983817728.0000 56/122 [============>.................] - ETA: 0s - loss: 10928700416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 331.6657 - distribution_lambda_loss: 10928700416.0000 61/122 [==============>...............] - ETA: 0s - loss: 10046057472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 313.4768 - distribution_lambda_loss: 10046057472.0000 66/122 [===============>..............] - ETA: 0s - loss: 9296618496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 297.9458 - distribution_lambda_loss: 9296618496.0000   71/122 [================>.............] - ETA: 0s - loss: 8651832320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 284.2052 - distribution_lambda_loss: 8651832320.0000 76/122 [=================>............] - ETA: 0s - loss: 8091564544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 272.2078 - distribution_lambda_loss: 8091564544.0000 81/122 [==================>...........] - ETA: 0s - loss: 7600301568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 261.4993 - distribution_lambda_loss: 7600301568.0000 86/122 [====================>.........] - ETA: 0s - loss: 7166191104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 252.2006 - distribution_lambda_loss: 7166191104.0000 91/122 [=====================>........] - ETA: 0s - loss: 6779685376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 243.7479 - distribution_lambda_loss: 6779685376.0000 96/122 [======================>.......] - ETA: 0s - loss: 6433112576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 236.1199 - distribution_lambda_loss: 6433112576.0000101/122 [=======================>......] - ETA: 0s - loss: 6120729600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 229.1388 - distribution_lambda_loss: 6120729600.0000106/122 [=========================>....] - ETA: 0s - loss: 5837681664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 222.8105 - distribution_lambda_loss: 5837681664.0000111/122 [==========================>...] - ETA: 0s - loss: 5580110336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 217.0212 - distribution_lambda_loss: 5580110336.0000116/122 [===========================>..] - ETA: 0s - loss: 5344571392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 211.6796 - distribution_lambda_loss: 5344571392.0000121/122 [============================>.] - ETA: 0s - loss: 5128343040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 206.7272 - distribution_lambda_loss: 5128343040.0000122/122 [==============================] - ETA: 0s - loss: 5105090048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 206.1720 - distribution_lambda_loss: 5105090048.0000input shape (None, 64, 64, 1)
122/122 [==============================] - 10s 27ms/step - loss: 5105090048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 206.1720 - distribution_lambda_loss: 5105090048.0000 - val_loss: 114962968.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 89.7054 - val_distribution_lambda_loss: 114962968.0000 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 114503184.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.7057 - distribution_lambda_loss: 114503184.0000  6/122 [>.............................] - ETA: 1s - loss: 109400968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.7042 - distribution_lambda_loss: 109400968.0000 11/122 [=>............................] - ETA: 1s - loss: 110662024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 90.4398 - distribution_lambda_loss: 110662024.0000 16/122 [==>...........................] - ETA: 1s - loss: 108605280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.6381 - distribution_lambda_loss: 108605280.0000 21/122 [====>.........................] - ETA: 1s - loss: 107739064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 89.2993 - distribution_lambda_loss: 107739064.0000 26/122 [=====>........................] - ETA: 0s - loss: 106619280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.8177 - distribution_lambda_loss: 106619280.0000 31/122 [======>.......................] - ETA: 0s - loss: 106800392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.9499 - distribution_lambda_loss: 106800392.0000 36/122 [=======>......................] - ETA: 0s - loss: 106537944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.7657 - distribution_lambda_loss: 106537944.0000 41/122 [=========>....................] - ETA: 0s - loss: 106284616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.6850 - distribution_lambda_loss: 106284616.0000 46/122 [==========>...................] - ETA: 0s - loss: 105479768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 88.2525 - distribution_lambda_loss: 105479768.0000 51/122 [===========>..................] - ETA: 0s - loss: 104918488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.9634 - distribution_lambda_loss: 104918488.0000 56/122 [============>.................] - ETA: 0s - loss: 104436480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.7400 - distribution_lambda_loss: 104436480.0000 61/122 [==============>...............] - ETA: 0s - loss: 104043176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.5460 - distribution_lambda_loss: 104043176.0000 67/122 [===============>..............] - ETA: 0s - loss: 103584144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.4247 - distribution_lambda_loss: 103584144.0000 72/122 [================>.............] - ETA: 0s - loss: 103055336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 87.1419 - distribution_lambda_loss: 103055336.0000 77/122 [=================>............] - ETA: 0s - loss: 102507416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.8611 - distribution_lambda_loss: 102507416.0000 82/122 [===================>..........] - ETA: 0s - loss: 102058856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.6615 - distribution_lambda_loss: 102058856.0000 87/122 [====================>.........] - ETA: 0s - loss: 101427528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.4010 - distribution_lambda_loss: 101427528.0000 92/122 [=====================>........] - ETA: 0s - loss: 100739272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 86.0891 - distribution_lambda_loss: 100739272.0000 97/122 [======================>.......] - ETA: 0s - loss: 100234096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.8272 - distribution_lambda_loss: 100234096.0000102/122 [========================>.....] - ETA: 0s - loss: 99710304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.5787 - distribution_lambda_loss: 99710304.0000  107/122 [=========================>....] - ETA: 0s - loss: 99217816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.3343 - distribution_lambda_loss: 99217816.0000112/122 [==========================>...] - ETA: 0s - loss: 98707688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 85.0965 - distribution_lambda_loss: 98707688.0000117/122 [===========================>..] - ETA: 0s - loss: 98422704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.9089 - distribution_lambda_loss: 98422704.0000122/122 [==============================] - 1s 11ms/step - loss: 98081736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 84.7484 - distribution_lambda_loss: 98081736.0000 - val_loss: 90864152.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 80.1951 - val_distribution_lambda_loss: 90864152.0000 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 92474344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.5622 - distribution_lambda_loss: 92474344.0000  6/122 [>.............................] - ETA: 1s - loss: 88492632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.0295 - distribution_lambda_loss: 88492632.0000 11/122 [=>............................] - ETA: 1s - loss: 89694568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.4091 - distribution_lambda_loss: 89694568.0000 17/122 [===>..........................] - ETA: 1s - loss: 89416752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 80.2637 - distribution_lambda_loss: 89416752.0000 22/122 [====>.........................] - ETA: 1s - loss: 88528368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.7394 - distribution_lambda_loss: 88528368.0000 27/122 [=====>........................] - ETA: 0s - loss: 87871608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.3975 - distribution_lambda_loss: 87871608.0000 32/122 [======>.......................] - ETA: 0s - loss: 87383632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 79.0508 - distribution_lambda_loss: 87383632.0000 37/122 [========>.....................] - ETA: 0s - loss: 87266440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.9929 - distribution_lambda_loss: 87266440.0000 42/122 [=========>....................] - ETA: 0s - loss: 86452264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.4994 - distribution_lambda_loss: 86452264.0000 47/122 [==========>...................] - ETA: 0s - loss: 85888936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.2710 - distribution_lambda_loss: 85888936.0000 52/122 [===========>..................] - ETA: 0s - loss: 85600168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 78.1345 - distribution_lambda_loss: 85600168.0000 57/122 [=============>................] - ETA: 0s - loss: 85106024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.9193 - distribution_lambda_loss: 85106024.0000 62/122 [==============>...............] - ETA: 0s - loss: 84675384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.6926 - distribution_lambda_loss: 84675384.0000 67/122 [===============>..............] - ETA: 0s - loss: 84339936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.5109 - distribution_lambda_loss: 84339936.0000 72/122 [================>.............] - ETA: 0s - loss: 83943160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.3060 - distribution_lambda_loss: 83943160.0000 77/122 [=================>............] - ETA: 0s - loss: 83636824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.1526 - distribution_lambda_loss: 83636824.0000 82/122 [===================>..........] - ETA: 0s - loss: 83472776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 77.0483 - distribution_lambda_loss: 83472776.0000 87/122 [====================>.........] - ETA: 0s - loss: 83181176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.9010 - distribution_lambda_loss: 83181176.0000 92/122 [=====================>........] - ETA: 0s - loss: 82928120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.8163 - distribution_lambda_loss: 82928120.0000 97/122 [======================>.......] - ETA: 0s - loss: 82623792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.6777 - distribution_lambda_loss: 82623792.0000102/122 [========================>.....] - ETA: 0s - loss: 82387784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.5133 - distribution_lambda_loss: 82387784.0000107/122 [=========================>....] - ETA: 0s - loss: 82140960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.3996 - distribution_lambda_loss: 82140960.0000112/122 [==========================>...] - ETA: 0s - loss: 81790328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.2250 - distribution_lambda_loss: 81790328.0000117/122 [===========================>..] - ETA: 0s - loss: 81616704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.1429 - distribution_lambda_loss: 81616704.0000122/122 [==============================] - 1s 11ms/step - loss: 81507504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 76.0758 - distribution_lambda_loss: 81507504.0000 - val_loss: 78487168.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 73.2321 - val_distribution_lambda_loss: 78487168.0000 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 80009552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 74.1857 - distribution_lambda_loss: 80009552.0000  6/122 [>.............................] - ETA: 1s - loss: 76896608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.9773 - distribution_lambda_loss: 76896608.0000 11/122 [=>............................] - ETA: 1s - loss: 76805880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.7817 - distribution_lambda_loss: 76805880.0000 16/122 [==>...........................] - ETA: 1s - loss: 76388384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.5057 - distribution_lambda_loss: 76388384.0000 21/122 [====>.........................] - ETA: 1s - loss: 76780728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.5424 - distribution_lambda_loss: 76780728.0000 26/122 [=====>........................] - ETA: 0s - loss: 76152488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.3418 - distribution_lambda_loss: 76152488.0000 31/122 [======>.......................] - ETA: 0s - loss: 75712816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.1978 - distribution_lambda_loss: 75712816.0000 36/122 [=======>......................] - ETA: 0s - loss: 75523952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 73.0370 - distribution_lambda_loss: 75523952.0000 41/122 [=========>....................] - ETA: 0s - loss: 75365464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.9651 - distribution_lambda_loss: 75365464.0000 46/122 [==========>...................] - ETA: 0s - loss: 74909304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.7474 - distribution_lambda_loss: 74909304.0000 51/122 [===========>..................] - ETA: 0s - loss: 74783248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.7137 - distribution_lambda_loss: 74783248.0000 56/122 [============>.................] - ETA: 0s - loss: 74450312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.5687 - distribution_lambda_loss: 74450312.0000 61/122 [==============>...............] - ETA: 0s - loss: 74258352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.4751 - distribution_lambda_loss: 74258352.0000 66/122 [===============>..............] - ETA: 0s - loss: 74183728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.4263 - distribution_lambda_loss: 74183728.0000 71/122 [================>.............] - ETA: 0s - loss: 74041728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.3328 - distribution_lambda_loss: 74041728.0000 76/122 [=================>............] - ETA: 0s - loss: 73951072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.3090 - distribution_lambda_loss: 73951072.0000 81/122 [==================>...........] - ETA: 0s - loss: 73842856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2352 - distribution_lambda_loss: 73842856.0000 86/122 [====================>.........] - ETA: 0s - loss: 73850368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2446 - distribution_lambda_loss: 73850368.0000 91/122 [=====================>........] - ETA: 0s - loss: 73740392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.1702 - distribution_lambda_loss: 73740392.0000 96/122 [======================>.......] - ETA: 0s - loss: 73842136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2263 - distribution_lambda_loss: 73842136.0000101/122 [=======================>......] - ETA: 0s - loss: 73772536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2308 - distribution_lambda_loss: 73772536.0000106/122 [=========================>....] - ETA: 0s - loss: 73737048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.2085 - distribution_lambda_loss: 73737048.0000111/122 [==========================>...] - ETA: 0s - loss: 73721304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.1791 - distribution_lambda_loss: 73721304.0000116/122 [===========================>..] - ETA: 0s - loss: 73529504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.0839 - distribution_lambda_loss: 73529504.0000121/122 [============================>.] - ETA: 0s - loss: 73357000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.0014 - distribution_lambda_loss: 73357000.0000122/122 [==============================] - 1s 11ms/step - loss: 73334112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.9857 - distribution_lambda_loss: 73334112.0000 - val_loss: 73022280.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 71.8797 - val_distribution_lambda_loss: 73022280.0000 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 67955272.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.6243 - distribution_lambda_loss: 67955272.0000  6/122 [>.............................] - ETA: 1s - loss: 72322496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.6816 - distribution_lambda_loss: 72322496.0000 11/122 [=>............................] - ETA: 1s - loss: 72883384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.7657 - distribution_lambda_loss: 72883384.0000 16/122 [==>...........................] - ETA: 1s - loss: 73329432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 72.0407 - distribution_lambda_loss: 73329432.0000 21/122 [====>.........................] - ETA: 1s - loss: 72705856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.7136 - distribution_lambda_loss: 72705856.0000 26/122 [=====>........................] - ETA: 0s - loss: 72119408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.4610 - distribution_lambda_loss: 72119408.0000 31/122 [======>.......................] - ETA: 0s - loss: 71671552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.2260 - distribution_lambda_loss: 71671552.0000 36/122 [=======>......................] - ETA: 0s - loss: 71436232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0630 - distribution_lambda_loss: 71436232.0000 41/122 [=========>....................] - ETA: 0s - loss: 71560232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0715 - distribution_lambda_loss: 71560232.0000 46/122 [==========>...................] - ETA: 0s - loss: 71572424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 71.0045 - distribution_lambda_loss: 71572424.0000 51/122 [===========>..................] - ETA: 0s - loss: 71574264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.9628 - distribution_lambda_loss: 71574264.0000 56/122 [============>.................] - ETA: 0s - loss: 71547960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.9791 - distribution_lambda_loss: 71547960.0000 61/122 [==============>...............] - ETA: 0s - loss: 71456448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.9452 - distribution_lambda_loss: 71456448.0000 66/122 [===============>..............] - ETA: 0s - loss: 71144016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.8102 - distribution_lambda_loss: 71144016.0000 71/122 [================>.............] - ETA: 0s - loss: 71105048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.7881 - distribution_lambda_loss: 71105048.0000 76/122 [=================>............] - ETA: 0s - loss: 70902632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.6953 - distribution_lambda_loss: 70902632.0000 81/122 [==================>...........] - ETA: 0s - loss: 70663936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.5850 - distribution_lambda_loss: 70663936.0000 86/122 [====================>.........] - ETA: 0s - loss: 70518072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.5164 - distribution_lambda_loss: 70518072.0000 91/122 [=====================>........] - ETA: 0s - loss: 70253888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3660 - distribution_lambda_loss: 70253888.0000 96/122 [======================>.......] - ETA: 0s - loss: 70093752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.3092 - distribution_lambda_loss: 70093752.0000101/122 [=======================>......] - ETA: 0s - loss: 69782984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.1808 - distribution_lambda_loss: 69782984.0000106/122 [=========================>....] - ETA: 0s - loss: 69613296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.1029 - distribution_lambda_loss: 69613296.0000111/122 [==========================>...] - ETA: 0s - loss: 69464104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 70.0326 - distribution_lambda_loss: 69464104.0000116/122 [===========================>..] - ETA: 0s - loss: 69355976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9819 - distribution_lambda_loss: 69355976.0000121/122 [============================>.] - ETA: 0s - loss: 69312872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9335 - distribution_lambda_loss: 69312872.0000122/122 [==============================] - 1s 11ms/step - loss: 69298824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 69.9178 - distribution_lambda_loss: 69298824.0000 - val_loss: 68322224.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 70.0182 - val_distribution_lambda_loss: 68322224.0000 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 63973480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.1701 - distribution_lambda_loss: 63973480.0000  6/122 [>.............................] - ETA: 1s - loss: 67280288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.9832 - distribution_lambda_loss: 67280288.0000 11/122 [=>............................] - ETA: 1s - loss: 66125040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.5953 - distribution_lambda_loss: 66125040.0000 16/122 [==>...........................] - ETA: 1s - loss: 65975832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.3627 - distribution_lambda_loss: 65975832.0000 21/122 [====>.........................] - ETA: 1s - loss: 65908396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.2561 - distribution_lambda_loss: 65908396.0000 26/122 [=====>........................] - ETA: 0s - loss: 65611504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 68.0724 - distribution_lambda_loss: 65611504.0000 31/122 [======>.......................] - ETA: 0s - loss: 65409116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9909 - distribution_lambda_loss: 65409116.0000 36/122 [=======>......................] - ETA: 0s - loss: 65294364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.9931 - distribution_lambda_loss: 65294364.0000 41/122 [=========>....................] - ETA: 0s - loss: 64825424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7720 - distribution_lambda_loss: 64825424.0000 46/122 [==========>...................] - ETA: 0s - loss: 64821124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7290 - distribution_lambda_loss: 64821124.0000 51/122 [===========>..................] - ETA: 0s - loss: 64647504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6924 - distribution_lambda_loss: 64647504.0000 56/122 [============>.................] - ETA: 0s - loss: 64771192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7341 - distribution_lambda_loss: 64771192.0000 61/122 [==============>...............] - ETA: 0s - loss: 64709600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.7132 - distribution_lambda_loss: 64709600.0000 66/122 [===============>..............] - ETA: 0s - loss: 64687808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6731 - distribution_lambda_loss: 64687808.0000 71/122 [================>.............] - ETA: 0s - loss: 64559428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.6208 - distribution_lambda_loss: 64559428.0000 76/122 [=================>............] - ETA: 0s - loss: 64440928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5514 - distribution_lambda_loss: 64440928.0000 81/122 [==================>...........] - ETA: 0s - loss: 64425480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5527 - distribution_lambda_loss: 64425480.0000 86/122 [====================>.........] - ETA: 0s - loss: 64475564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.5384 - distribution_lambda_loss: 64475564.0000 91/122 [=====================>........] - ETA: 0s - loss: 64378492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4938 - distribution_lambda_loss: 64378492.0000 96/122 [======================>.......] - ETA: 0s - loss: 64308788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4725 - distribution_lambda_loss: 64308788.0000101/122 [=======================>......] - ETA: 0s - loss: 64279036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4514 - distribution_lambda_loss: 64279036.0000106/122 [=========================>....] - ETA: 0s - loss: 64364400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4687 - distribution_lambda_loss: 64364400.0000111/122 [==========================>...] - ETA: 0s - loss: 64327128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4458 - distribution_lambda_loss: 64327128.0000116/122 [===========================>..] - ETA: 0s - loss: 64223532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.3912 - distribution_lambda_loss: 64223532.0000121/122 [============================>.] - ETA: 0s - loss: 64133860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.3828 - distribution_lambda_loss: 64133860.0000122/122 [==============================] - 1s 11ms/step - loss: 64158740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.3930 - distribution_lambda_loss: 64158740.0000 - val_loss: 66443156.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 66.4991 - val_distribution_lambda_loss: 66443156.0000 - lr: 0.0010
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 60878912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.1862 - distribution_lambda_loss: 60878912.0000  6/122 [>.............................] - ETA: 1s - loss: 64850028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0690 - distribution_lambda_loss: 64850028.0000 11/122 [=>............................] - ETA: 1s - loss: 64672064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2752 - distribution_lambda_loss: 64672064.0000 16/122 [==>...........................] - ETA: 1s - loss: 65060028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2904 - distribution_lambda_loss: 65060028.0000 21/122 [====>.........................] - ETA: 1s - loss: 64859032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.4144 - distribution_lambda_loss: 64859032.0000 27/122 [=====>........................] - ETA: 0s - loss: 64553604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1643 - distribution_lambda_loss: 64553604.0000 32/122 [======>.......................] - ETA: 0s - loss: 64322460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.1432 - distribution_lambda_loss: 64322460.0000 37/122 [========>.....................] - ETA: 0s - loss: 64480000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.2389 - distribution_lambda_loss: 64480000.0000 42/122 [=========>....................] - ETA: 0s - loss: 64097620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 67.0782 - distribution_lambda_loss: 64097620.0000 47/122 [==========>...................] - ETA: 0s - loss: 63804472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.9317 - distribution_lambda_loss: 63804472.0000 52/122 [===========>..................] - ETA: 0s - loss: 63542096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.8103 - distribution_lambda_loss: 63542096.0000 57/122 [=============>................] - ETA: 0s - loss: 63371968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7496 - distribution_lambda_loss: 63371968.0000 62/122 [==============>...............] - ETA: 0s - loss: 63061340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6497 - distribution_lambda_loss: 63061340.0000 67/122 [===============>..............] - ETA: 0s - loss: 63181140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.7178 - distribution_lambda_loss: 63181140.0000 72/122 [================>.............] - ETA: 0s - loss: 63119060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6819 - distribution_lambda_loss: 63119060.0000 77/122 [=================>............] - ETA: 0s - loss: 63026876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.6538 - distribution_lambda_loss: 63026876.0000 82/122 [===================>..........] - ETA: 0s - loss: 62896016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5967 - distribution_lambda_loss: 62896016.0000 87/122 [====================>.........] - ETA: 0s - loss: 62708736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.5253 - distribution_lambda_loss: 62708736.0000 92/122 [=====================>........] - ETA: 0s - loss: 62571772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4635 - distribution_lambda_loss: 62571772.0000 97/122 [======================>.......] - ETA: 0s - loss: 62527312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.4098 - distribution_lambda_loss: 62527312.0000102/122 [========================>.....] - ETA: 0s - loss: 62481572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3646 - distribution_lambda_loss: 62481572.0000107/122 [=========================>....] - ETA: 0s - loss: 62341016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.3196 - distribution_lambda_loss: 62341016.0000112/122 [==========================>...] - ETA: 0s - loss: 62141828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.2410 - distribution_lambda_loss: 62141828.0000117/122 [===========================>..] - ETA: 0s - loss: 62055396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1793 - distribution_lambda_loss: 62055396.0000122/122 [==============================] - ETA: 0s - loss: 61968396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1256 - distribution_lambda_loss: 61968396.0000122/122 [==============================] - 1s 11ms/step - loss: 61968396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 66.1256 - distribution_lambda_loss: 61968396.0000 - val_loss: 63143388.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 67.2757 - val_distribution_lambda_loss: 63143388.0000 - lr: 0.0010
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 51900592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6098 - distribution_lambda_loss: 51900592.0000  6/122 [>.............................] - ETA: 1s - loss: 57382404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.2560 - distribution_lambda_loss: 57382404.0000 11/122 [=>............................] - ETA: 1s - loss: 58649980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.6012 - distribution_lambda_loss: 58649980.0000 16/122 [==>...........................] - ETA: 1s - loss: 58726640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.6515 - distribution_lambda_loss: 58726640.0000 21/122 [====>.........................] - ETA: 1s - loss: 58928696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7729 - distribution_lambda_loss: 58928696.0000 26/122 [=====>........................] - ETA: 0s - loss: 59064316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7447 - distribution_lambda_loss: 59064316.0000 31/122 [======>.......................] - ETA: 0s - loss: 59501092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8993 - distribution_lambda_loss: 59501092.0000 36/122 [=======>......................] - ETA: 0s - loss: 59931632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0715 - distribution_lambda_loss: 59931632.0000 41/122 [=========>....................] - ETA: 0s - loss: 60300892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2411 - distribution_lambda_loss: 60300892.0000 46/122 [==========>...................] - ETA: 0s - loss: 60305652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.2006 - distribution_lambda_loss: 60305652.0000 51/122 [===========>..................] - ETA: 0s - loss: 60180572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.1871 - distribution_lambda_loss: 60180572.0000 56/122 [============>.................] - ETA: 0s - loss: 59972196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0556 - distribution_lambda_loss: 59972196.0000 61/122 [==============>...............] - ETA: 0s - loss: 59778448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9832 - distribution_lambda_loss: 59778448.0000 66/122 [===============>..............] - ETA: 0s - loss: 59864976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0135 - distribution_lambda_loss: 59864976.0000 71/122 [================>.............] - ETA: 0s - loss: 59887536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.0269 - distribution_lambda_loss: 59887536.0000 76/122 [=================>............] - ETA: 0s - loss: 59740596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9206 - distribution_lambda_loss: 59740596.0000 81/122 [==================>...........] - ETA: 0s - loss: 59686564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8934 - distribution_lambda_loss: 59686564.0000 86/122 [====================>.........] - ETA: 0s - loss: 59803516.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9374 - distribution_lambda_loss: 59803516.0000 91/122 [=====================>........] - ETA: 0s - loss: 59818164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9470 - distribution_lambda_loss: 59818164.0000 96/122 [======================>.......] - ETA: 0s - loss: 59815572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9280 - distribution_lambda_loss: 59815572.0000101/122 [=======================>......] - ETA: 0s - loss: 59803104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9411 - distribution_lambda_loss: 59803104.0000106/122 [=========================>....] - ETA: 0s - loss: 59860348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9518 - distribution_lambda_loss: 59860348.0000112/122 [==========================>...] - ETA: 0s - loss: 59673888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8763 - distribution_lambda_loss: 59673888.0000117/122 [===========================>..] - ETA: 0s - loss: 59556708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.8195 - distribution_lambda_loss: 59556708.0000122/122 [==============================] - 1s 11ms/step - loss: 59346620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7257 - distribution_lambda_loss: 59346620.0000 - val_loss: 61046604.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 65.9761 - val_distribution_lambda_loss: 61046604.0000 - lr: 0.0010
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 58447080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.7099 - distribution_lambda_loss: 58447080.0000  6/122 [>.............................] - ETA: 1s - loss: 58364924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.2592 - distribution_lambda_loss: 58364924.0000 11/122 [=>............................] - ETA: 1s - loss: 57709308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.7996 - distribution_lambda_loss: 57709308.0000 16/122 [==>...........................] - ETA: 1s - loss: 57042088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.6222 - distribution_lambda_loss: 57042088.0000 21/122 [====>.........................] - ETA: 1s - loss: 56675084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.3898 - distribution_lambda_loss: 56675084.0000 26/122 [=====>........................] - ETA: 0s - loss: 56194248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.1542 - distribution_lambda_loss: 56194248.0000 31/122 [======>.......................] - ETA: 0s - loss: 56436568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.3261 - distribution_lambda_loss: 56436568.0000 36/122 [=======>......................] - ETA: 0s - loss: 57031224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5698 - distribution_lambda_loss: 57031224.0000 41/122 [=========>....................] - ETA: 0s - loss: 57447144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.6548 - distribution_lambda_loss: 57447144.0000 46/122 [==========>...................] - ETA: 0s - loss: 57374852.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.6059 - distribution_lambda_loss: 57374852.0000 51/122 [===========>..................] - ETA: 0s - loss: 57421588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.6295 - distribution_lambda_loss: 57421588.0000 56/122 [============>.................] - ETA: 0s - loss: 57270392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5538 - distribution_lambda_loss: 57270392.0000 61/122 [==============>...............] - ETA: 0s - loss: 57270508.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5254 - distribution_lambda_loss: 57270508.0000 66/122 [===============>..............] - ETA: 0s - loss: 57216996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5149 - distribution_lambda_loss: 57216996.0000 71/122 [================>.............] - ETA: 0s - loss: 57309512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5662 - distribution_lambda_loss: 57309512.0000 76/122 [=================>............] - ETA: 0s - loss: 57275648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5495 - distribution_lambda_loss: 57275648.0000 81/122 [==================>...........] - ETA: 0s - loss: 57127248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.4883 - distribution_lambda_loss: 57127248.0000 86/122 [====================>.........] - ETA: 0s - loss: 56954868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.3888 - distribution_lambda_loss: 56954868.0000 91/122 [=====================>........] - ETA: 0s - loss: 56832500.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.3330 - distribution_lambda_loss: 56832500.0000 96/122 [======================>.......] - ETA: 0s - loss: 56820848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.3019 - distribution_lambda_loss: 56820848.0000101/122 [=======================>......] - ETA: 0s - loss: 56714804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.2349 - distribution_lambda_loss: 56714804.0000106/122 [=========================>....] - ETA: 0s - loss: 56626588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.2069 - distribution_lambda_loss: 56626588.0000111/122 [==========================>...] - ETA: 0s - loss: 56581952.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.1773 - distribution_lambda_loss: 56581952.0000116/122 [===========================>..] - ETA: 0s - loss: 56600784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.2004 - distribution_lambda_loss: 56600784.0000121/122 [============================>.] - ETA: 0s - loss: 56494096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.1507 - distribution_lambda_loss: 56494096.0000122/122 [==============================] - 1s 11ms/step - loss: 56483628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.1416 - distribution_lambda_loss: 56483628.0000 - val_loss: 59535796.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 65.5955 - val_distribution_lambda_loss: 59535796.0000 - lr: 0.0010
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 58232092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.9276 - distribution_lambda_loss: 58232092.0000  6/122 [>.............................] - ETA: 1s - loss: 60321852.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 65.4348 - distribution_lambda_loss: 60321852.0000 11/122 [=>............................] - ETA: 1s - loss: 59331444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 64.4614 - distribution_lambda_loss: 59331444.0000 16/122 [==>...........................] - ETA: 1s - loss: 58396976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.8416 - distribution_lambda_loss: 58396976.0000 21/122 [====>.........................] - ETA: 1s - loss: 57778492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.5500 - distribution_lambda_loss: 57778492.0000 26/122 [=====>........................] - ETA: 0s - loss: 56945872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.2155 - distribution_lambda_loss: 56945872.0000 31/122 [======>.......................] - ETA: 0s - loss: 56383392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.9345 - distribution_lambda_loss: 56383392.0000 36/122 [=======>......................] - ETA: 0s - loss: 55944968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7773 - distribution_lambda_loss: 55944968.0000 41/122 [=========>....................] - ETA: 0s - loss: 55680476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6824 - distribution_lambda_loss: 55680476.0000 46/122 [==========>...................] - ETA: 0s - loss: 55500316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5763 - distribution_lambda_loss: 55500316.0000 51/122 [===========>..................] - ETA: 0s - loss: 55657596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6737 - distribution_lambda_loss: 55657596.0000 56/122 [============>.................] - ETA: 0s - loss: 55714696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7738 - distribution_lambda_loss: 55714696.0000 61/122 [==============>...............] - ETA: 0s - loss: 55704992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7629 - distribution_lambda_loss: 55704992.0000 66/122 [===============>..............] - ETA: 0s - loss: 55815988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7606 - distribution_lambda_loss: 55815988.0000 71/122 [================>.............] - ETA: 0s - loss: 55689396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7051 - distribution_lambda_loss: 55689396.0000 76/122 [=================>............] - ETA: 0s - loss: 55669428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6888 - distribution_lambda_loss: 55669428.0000 81/122 [==================>...........] - ETA: 0s - loss: 55723800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7219 - distribution_lambda_loss: 55723800.0000 86/122 [====================>.........] - ETA: 0s - loss: 55855848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7593 - distribution_lambda_loss: 55855848.0000 91/122 [=====================>........] - ETA: 0s - loss: 55736112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7079 - distribution_lambda_loss: 55736112.0000 96/122 [======================>.......] - ETA: 0s - loss: 55608676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6652 - distribution_lambda_loss: 55608676.0000101/122 [=======================>......] - ETA: 0s - loss: 55561504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6017 - distribution_lambda_loss: 55561504.0000106/122 [=========================>....] - ETA: 0s - loss: 55632028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6253 - distribution_lambda_loss: 55632028.0000111/122 [==========================>...] - ETA: 0s - loss: 55568016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.6079 - distribution_lambda_loss: 55568016.0000116/122 [===========================>..] - ETA: 0s - loss: 55530324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5732 - distribution_lambda_loss: 55530324.0000121/122 [============================>.] - ETA: 0s - loss: 55497976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5462 - distribution_lambda_loss: 55497976.0000122/122 [==============================] - 1s 11ms/step - loss: 55497084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5439 - distribution_lambda_loss: 55497084.0000 - val_loss: 58406400.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 63.5422 - val_distribution_lambda_loss: 58406400.0000 - lr: 0.0010
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 56190864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.7995 - distribution_lambda_loss: 56190864.0000  6/122 [>.............................] - ETA: 1s - loss: 55425772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.5404 - distribution_lambda_loss: 55425772.0000 11/122 [=>............................] - ETA: 1s - loss: 55306980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4883 - distribution_lambda_loss: 55306980.0000 16/122 [==>...........................] - ETA: 1s - loss: 55270164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4394 - distribution_lambda_loss: 55270164.0000 21/122 [====>.........................] - ETA: 1s - loss: 55224900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.4139 - distribution_lambda_loss: 55224900.0000 26/122 [=====>........................] - ETA: 1s - loss: 55017848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.2415 - distribution_lambda_loss: 55017848.0000 31/122 [======>.......................] - ETA: 0s - loss: 54707140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.0223 - distribution_lambda_loss: 54707140.0000 36/122 [=======>......................] - ETA: 0s - loss: 54564220.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.0298 - distribution_lambda_loss: 54564220.0000 41/122 [=========>....................] - ETA: 0s - loss: 54432720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.0016 - distribution_lambda_loss: 54432720.0000 46/122 [==========>...................] - ETA: 0s - loss: 54718412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.0575 - distribution_lambda_loss: 54718412.0000 51/122 [===========>..................] - ETA: 0s - loss: 54411296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.9488 - distribution_lambda_loss: 54411296.0000 56/122 [============>.................] - ETA: 0s - loss: 54232644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8544 - distribution_lambda_loss: 54232644.0000 61/122 [==============>...............] - ETA: 0s - loss: 54319944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8634 - distribution_lambda_loss: 54319944.0000 66/122 [===============>..............] - ETA: 0s - loss: 54278352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7986 - distribution_lambda_loss: 54278352.0000 71/122 [================>.............] - ETA: 0s - loss: 54264588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.8123 - distribution_lambda_loss: 54264588.0000 76/122 [=================>............] - ETA: 0s - loss: 54197568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.7777 - distribution_lambda_loss: 54197568.0000 81/122 [==================>...........] - ETA: 0s - loss: 54055044.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6915 - distribution_lambda_loss: 54055044.0000 86/122 [====================>.........] - ETA: 0s - loss: 53997860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6698 - distribution_lambda_loss: 53997860.0000 91/122 [=====================>........] - ETA: 0s - loss: 53904800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6197 - distribution_lambda_loss: 53904800.0000 96/122 [======================>.......] - ETA: 0s - loss: 53931652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6084 - distribution_lambda_loss: 53931652.0000101/122 [=======================>......] - ETA: 0s - loss: 53880668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.6117 - distribution_lambda_loss: 53880668.0000106/122 [=========================>....] - ETA: 0s - loss: 53727328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.5335 - distribution_lambda_loss: 53727328.0000111/122 [==========================>...] - ETA: 0s - loss: 53661716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.4925 - distribution_lambda_loss: 53661716.0000116/122 [===========================>..] - ETA: 0s - loss: 53560564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.4462 - distribution_lambda_loss: 53560564.0000121/122 [============================>.] - ETA: 0s - loss: 53532228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.4242 - distribution_lambda_loss: 53532228.0000122/122 [==============================] - 1s 11ms/step - loss: 53534016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.4287 - distribution_lambda_loss: 53534016.0000 - val_loss: 54925228.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 62.0623 - val_distribution_lambda_loss: 54925228.0000 - lr: 0.0010
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 53997388.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 62.2831 - distribution_lambda_loss: 53997388.0000  6/122 [>.............................] - ETA: 1s - loss: 51851552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1403 - distribution_lambda_loss: 51851552.0000 11/122 [=>............................] - ETA: 1s - loss: 51823268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.4519 - distribution_lambda_loss: 51823268.0000 16/122 [==>...........................] - ETA: 1s - loss: 52155172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.8068 - distribution_lambda_loss: 52155172.0000 21/122 [====>.........................] - ETA: 1s - loss: 52047392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.6658 - distribution_lambda_loss: 52047392.0000 26/122 [=====>........................] - ETA: 0s - loss: 52665640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.8938 - distribution_lambda_loss: 52665640.0000 31/122 [======>.......................] - ETA: 0s - loss: 52756136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.9892 - distribution_lambda_loss: 52756136.0000 36/122 [=======>......................] - ETA: 0s - loss: 52689028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.9461 - distribution_lambda_loss: 52689028.0000 41/122 [=========>....................] - ETA: 0s - loss: 52830552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.9681 - distribution_lambda_loss: 52830552.0000 46/122 [==========>...................] - ETA: 0s - loss: 52818308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.9953 - distribution_lambda_loss: 52818308.0000 51/122 [===========>..................] - ETA: 0s - loss: 53242856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1894 - distribution_lambda_loss: 53242856.0000 56/122 [============>.................] - ETA: 0s - loss: 53386312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2842 - distribution_lambda_loss: 53386312.0000 61/122 [==============>...............] - ETA: 0s - loss: 53411676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.3122 - distribution_lambda_loss: 53411676.0000 66/122 [===============>..............] - ETA: 0s - loss: 53362608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.3019 - distribution_lambda_loss: 53362608.0000 71/122 [================>.............] - ETA: 0s - loss: 53278884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2524 - distribution_lambda_loss: 53278884.0000 76/122 [=================>............] - ETA: 0s - loss: 53262008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2689 - distribution_lambda_loss: 53262008.0000 81/122 [==================>...........] - ETA: 0s - loss: 53254832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2499 - distribution_lambda_loss: 53254832.0000 87/122 [====================>.........] - ETA: 0s - loss: 53163524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1964 - distribution_lambda_loss: 53163524.0000 92/122 [=====================>........] - ETA: 0s - loss: 53167472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1879 - distribution_lambda_loss: 53167472.0000 97/122 [======================>.......] - ETA: 0s - loss: 53205488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2099 - distribution_lambda_loss: 53205488.0000102/122 [========================>.....] - ETA: 0s - loss: 53199836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.2124 - distribution_lambda_loss: 53199836.0000107/122 [=========================>....] - ETA: 0s - loss: 53147492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1994 - distribution_lambda_loss: 53147492.0000112/122 [==========================>...] - ETA: 0s - loss: 53092572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1557 - distribution_lambda_loss: 53092572.0000117/122 [===========================>..] - ETA: 0s - loss: 53111688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1355 - distribution_lambda_loss: 53111688.0000122/122 [==============================] - 1s 11ms/step - loss: 53160360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.1814 - distribution_lambda_loss: 53160360.0000 - val_loss: 55947204.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 62.8559 - val_distribution_lambda_loss: 55947204.0000 - lr: 0.0010
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 55582028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 63.1033 - distribution_lambda_loss: 55582028.0000  6/122 [>.............................] - ETA: 1s - loss: 52660544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.6458 - distribution_lambda_loss: 52660544.0000 11/122 [=>............................] - ETA: 1s - loss: 51272668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0633 - distribution_lambda_loss: 51272668.0000 16/122 [==>...........................] - ETA: 1s - loss: 51216216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1806 - distribution_lambda_loss: 51216216.0000 21/122 [====>.........................] - ETA: 1s - loss: 50938348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0606 - distribution_lambda_loss: 50938348.0000 26/122 [=====>........................] - ETA: 0s - loss: 51198872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0527 - distribution_lambda_loss: 51198872.0000 31/122 [======>.......................] - ETA: 0s - loss: 51276008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0543 - distribution_lambda_loss: 51276008.0000 36/122 [=======>......................] - ETA: 0s - loss: 51020776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0014 - distribution_lambda_loss: 51020776.0000 41/122 [=========>....................] - ETA: 0s - loss: 50849896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9205 - distribution_lambda_loss: 50849896.0000 46/122 [==========>...................] - ETA: 0s - loss: 50702972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8310 - distribution_lambda_loss: 50702972.0000 51/122 [===========>..................] - ETA: 0s - loss: 50751012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8598 - distribution_lambda_loss: 50751012.0000 56/122 [============>.................] - ETA: 0s - loss: 50865768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8862 - distribution_lambda_loss: 50865768.0000 61/122 [==============>...............] - ETA: 0s - loss: 50955468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9807 - distribution_lambda_loss: 50955468.0000 66/122 [===============>..............] - ETA: 0s - loss: 50830024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8971 - distribution_lambda_loss: 50830024.0000 71/122 [================>.............] - ETA: 0s - loss: 50930980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9132 - distribution_lambda_loss: 50930980.0000 76/122 [=================>............] - ETA: 0s - loss: 50916996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9322 - distribution_lambda_loss: 50916996.0000 81/122 [==================>...........] - ETA: 0s - loss: 50821980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8896 - distribution_lambda_loss: 50821980.0000 86/122 [====================>.........] - ETA: 0s - loss: 50861704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8883 - distribution_lambda_loss: 50861704.0000 91/122 [=====================>........] - ETA: 0s - loss: 50786776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8543 - distribution_lambda_loss: 50786776.0000 96/122 [======================>.......] - ETA: 0s - loss: 50822724.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9105 - distribution_lambda_loss: 50822724.0000101/122 [=======================>......] - ETA: 0s - loss: 50784528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8768 - distribution_lambda_loss: 50784528.0000106/122 [=========================>....] - ETA: 0s - loss: 50844212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9087 - distribution_lambda_loss: 50844212.0000111/122 [==========================>...] - ETA: 0s - loss: 50845880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9336 - distribution_lambda_loss: 50845880.0000116/122 [===========================>..] - ETA: 0s - loss: 50857984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9252 - distribution_lambda_loss: 50857984.0000121/122 [============================>.] - ETA: 0s - loss: 50848476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9429 - distribution_lambda_loss: 50848476.0000122/122 [==============================] - 1s 11ms/step - loss: 50826220.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9300 - distribution_lambda_loss: 50826220.0000 - val_loss: 52890284.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 59.6175 - val_distribution_lambda_loss: 52890284.0000 - lr: 0.0010
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 53981680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.8784 - distribution_lambda_loss: 53981680.0000  6/122 [>.............................] - ETA: 1s - loss: 50200196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4880 - distribution_lambda_loss: 50200196.0000 11/122 [=>............................] - ETA: 1s - loss: 49979956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4308 - distribution_lambda_loss: 49979956.0000 16/122 [==>...........................] - ETA: 1s - loss: 50202140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5150 - distribution_lambda_loss: 50202140.0000 21/122 [====>.........................] - ETA: 1s - loss: 50237576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5168 - distribution_lambda_loss: 50237576.0000 26/122 [=====>........................] - ETA: 0s - loss: 50054672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.3991 - distribution_lambda_loss: 50054672.0000 31/122 [======>.......................] - ETA: 0s - loss: 50335800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6506 - distribution_lambda_loss: 50335800.0000 36/122 [=======>......................] - ETA: 0s - loss: 50418568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6889 - distribution_lambda_loss: 50418568.0000 41/122 [=========>....................] - ETA: 0s - loss: 50176664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.6090 - distribution_lambda_loss: 50176664.0000 46/122 [==========>...................] - ETA: 0s - loss: 50052320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5542 - distribution_lambda_loss: 50052320.0000 51/122 [===========>..................] - ETA: 0s - loss: 49994732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4845 - distribution_lambda_loss: 49994732.0000 56/122 [============>.................] - ETA: 0s - loss: 50079956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5538 - distribution_lambda_loss: 50079956.0000 61/122 [==============>...............] - ETA: 0s - loss: 49961816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5186 - distribution_lambda_loss: 49961816.0000 66/122 [===============>..............] - ETA: 0s - loss: 49921348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.4863 - distribution_lambda_loss: 49921348.0000 71/122 [================>.............] - ETA: 0s - loss: 50006224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5458 - distribution_lambda_loss: 50006224.0000 76/122 [=================>............] - ETA: 0s - loss: 49941584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5043 - distribution_lambda_loss: 49941584.0000 81/122 [==================>...........] - ETA: 0s - loss: 49934704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.5107 - distribution_lambda_loss: 49934704.0000 86/122 [====================>.........] - ETA: 0s - loss: 50288832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.7016 - distribution_lambda_loss: 50288832.0000 91/122 [=====================>........] - ETA: 0s - loss: 50745444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.9573 - distribution_lambda_loss: 50745444.0000 96/122 [======================>.......] - ETA: 0s - loss: 50908848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0638 - distribution_lambda_loss: 50908848.0000101/122 [=======================>......] - ETA: 0s - loss: 51047276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1333 - distribution_lambda_loss: 51047276.0000106/122 [=========================>....] - ETA: 0s - loss: 51002348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1252 - distribution_lambda_loss: 51002348.0000111/122 [==========================>...] - ETA: 0s - loss: 51089740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.1380 - distribution_lambda_loss: 51089740.0000116/122 [===========================>..] - ETA: 0s - loss: 51042868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0941 - distribution_lambda_loss: 51042868.0000121/122 [============================>.] - ETA: 0s - loss: 51008684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0641 - distribution_lambda_loss: 51008684.0000122/122 [==============================] - 1s 11ms/step - loss: 50983600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 60.0610 - distribution_lambda_loss: 50983600.0000 - val_loss: 52175148.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 58.2803 - val_distribution_lambda_loss: 52175148.0000 - lr: 0.0010
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 44561520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9965 - distribution_lambda_loss: 44561520.0000  6/122 [>.............................] - ETA: 1s - loss: 48646268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.5095 - distribution_lambda_loss: 48646268.0000 11/122 [=>............................] - ETA: 1s - loss: 48901616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7642 - distribution_lambda_loss: 48901616.0000 16/122 [==>...........................] - ETA: 1s - loss: 49130780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9566 - distribution_lambda_loss: 49130780.0000 21/122 [====>.........................] - ETA: 1s - loss: 49146496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9462 - distribution_lambda_loss: 49146496.0000 26/122 [=====>........................] - ETA: 0s - loss: 49046248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9526 - distribution_lambda_loss: 49046248.0000 31/122 [======>.......................] - ETA: 0s - loss: 48870520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8782 - distribution_lambda_loss: 48870520.0000 36/122 [=======>......................] - ETA: 0s - loss: 48978392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8897 - distribution_lambda_loss: 48978392.0000 41/122 [=========>....................] - ETA: 0s - loss: 48787884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7978 - distribution_lambda_loss: 48787884.0000 46/122 [==========>...................] - ETA: 0s - loss: 48912868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8607 - distribution_lambda_loss: 48912868.0000 51/122 [===========>..................] - ETA: 0s - loss: 48777648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8176 - distribution_lambda_loss: 48777648.0000 56/122 [============>.................] - ETA: 0s - loss: 48793240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7840 - distribution_lambda_loss: 48793240.0000 61/122 [==============>...............] - ETA: 0s - loss: 48706916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.7426 - distribution_lambda_loss: 48706916.0000 66/122 [===============>..............] - ETA: 0s - loss: 48834544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8059 - distribution_lambda_loss: 48834544.0000 71/122 [================>.............] - ETA: 0s - loss: 48859880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8130 - distribution_lambda_loss: 48859880.0000 76/122 [=================>............] - ETA: 0s - loss: 48968308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8687 - distribution_lambda_loss: 48968308.0000 81/122 [==================>...........] - ETA: 0s - loss: 49091708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9360 - distribution_lambda_loss: 49091708.0000 86/122 [====================>.........] - ETA: 0s - loss: 49059904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9328 - distribution_lambda_loss: 49059904.0000 91/122 [=====================>........] - ETA: 0s - loss: 49107636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9643 - distribution_lambda_loss: 49107636.0000 96/122 [======================>.......] - ETA: 0s - loss: 49113844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9742 - distribution_lambda_loss: 49113844.0000101/122 [=======================>......] - ETA: 0s - loss: 49102300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9690 - distribution_lambda_loss: 49102300.0000106/122 [=========================>....] - ETA: 0s - loss: 49136944.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9752 - distribution_lambda_loss: 49136944.0000111/122 [==========================>...] - ETA: 0s - loss: 49155476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9829 - distribution_lambda_loss: 49155476.0000116/122 [===========================>..] - ETA: 0s - loss: 49102380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9665 - distribution_lambda_loss: 49102380.0000121/122 [============================>.] - ETA: 0s - loss: 49061028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9409 - distribution_lambda_loss: 49061028.0000122/122 [==============================] - 1s 11ms/step - loss: 49048412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.9323 - distribution_lambda_loss: 49048412.0000 - val_loss: 49989452.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 58.5266 - val_distribution_lambda_loss: 49989452.0000 - lr: 0.0010
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 48883384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8861 - distribution_lambda_loss: 48883384.0000  6/122 [>.............................] - ETA: 1s - loss: 47445084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0910 - distribution_lambda_loss: 47445084.0000 11/122 [=>............................] - ETA: 1s - loss: 47340404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.9578 - distribution_lambda_loss: 47340404.0000 16/122 [==>...........................] - ETA: 1s - loss: 47471096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0879 - distribution_lambda_loss: 47471096.0000 21/122 [====>.........................] - ETA: 1s - loss: 47516836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0677 - distribution_lambda_loss: 47516836.0000 26/122 [=====>........................] - ETA: 0s - loss: 47610216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1758 - distribution_lambda_loss: 47610216.0000 31/122 [======>.......................] - ETA: 0s - loss: 47777804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2270 - distribution_lambda_loss: 47777804.0000 36/122 [=======>......................] - ETA: 0s - loss: 47866996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2266 - distribution_lambda_loss: 47866996.0000 41/122 [=========>....................] - ETA: 0s - loss: 47951156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2572 - distribution_lambda_loss: 47951156.0000 46/122 [==========>...................] - ETA: 0s - loss: 47907368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2558 - distribution_lambda_loss: 47907368.0000 51/122 [===========>..................] - ETA: 0s - loss: 47879540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2781 - distribution_lambda_loss: 47879540.0000 56/122 [============>.................] - ETA: 0s - loss: 47830660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2154 - distribution_lambda_loss: 47830660.0000 61/122 [==============>...............] - ETA: 0s - loss: 47751780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2148 - distribution_lambda_loss: 47751780.0000 66/122 [===============>..............] - ETA: 0s - loss: 47612824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0914 - distribution_lambda_loss: 47612824.0000 71/122 [================>.............] - ETA: 0s - loss: 47583016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0848 - distribution_lambda_loss: 47583016.0000 76/122 [=================>............] - ETA: 0s - loss: 47686644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1434 - distribution_lambda_loss: 47686644.0000 81/122 [==================>...........] - ETA: 0s - loss: 47721072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1853 - distribution_lambda_loss: 47721072.0000 86/122 [====================>.........] - ETA: 0s - loss: 47742720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1775 - distribution_lambda_loss: 47742720.0000 91/122 [=====================>........] - ETA: 0s - loss: 47733896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1810 - distribution_lambda_loss: 47733896.0000 96/122 [======================>.......] - ETA: 0s - loss: 47660528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1460 - distribution_lambda_loss: 47660528.0000101/122 [=======================>......] - ETA: 0s - loss: 47692788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1618 - distribution_lambda_loss: 47692788.0000106/122 [=========================>....] - ETA: 0s - loss: 47736208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1816 - distribution_lambda_loss: 47736208.0000111/122 [==========================>...] - ETA: 0s - loss: 47749080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2037 - distribution_lambda_loss: 47749080.0000116/122 [===========================>..] - ETA: 0s - loss: 47772632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2092 - distribution_lambda_loss: 47772632.0000121/122 [============================>.] - ETA: 0s - loss: 47835884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2277 - distribution_lambda_loss: 47835884.0000122/122 [==============================] - 1s 11ms/step - loss: 47841104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2375 - distribution_lambda_loss: 47841104.0000 - val_loss: 51144660.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 61.9000 - val_distribution_lambda_loss: 51144660.0000 - lr: 0.0010
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 48727208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 61.3301 - distribution_lambda_loss: 48727208.0000  6/122 [>.............................] - ETA: 1s - loss: 48604672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 59.0112 - distribution_lambda_loss: 48604672.0000 11/122 [=>............................] - ETA: 1s - loss: 48237400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.5704 - distribution_lambda_loss: 48237400.0000 16/122 [==>...........................] - ETA: 1s - loss: 47978120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2965 - distribution_lambda_loss: 47978120.0000 21/122 [====>.........................] - ETA: 1s - loss: 47729528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.2230 - distribution_lambda_loss: 47729528.0000 26/122 [=====>........................] - ETA: 0s - loss: 47367704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0130 - distribution_lambda_loss: 47367704.0000 31/122 [======>.......................] - ETA: 0s - loss: 47219656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.9236 - distribution_lambda_loss: 47219656.0000 36/122 [=======>......................] - ETA: 0s - loss: 46864176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6887 - distribution_lambda_loss: 46864176.0000 41/122 [=========>....................] - ETA: 0s - loss: 47110736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7743 - distribution_lambda_loss: 47110736.0000 46/122 [==========>...................] - ETA: 0s - loss: 46970484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7400 - distribution_lambda_loss: 46970484.0000 51/122 [===========>..................] - ETA: 0s - loss: 46896360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6963 - distribution_lambda_loss: 46896360.0000 56/122 [============>.................] - ETA: 0s - loss: 46928260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6896 - distribution_lambda_loss: 46928260.0000 61/122 [==============>...............] - ETA: 0s - loss: 46967660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.7286 - distribution_lambda_loss: 46967660.0000 66/122 [===============>..............] - ETA: 0s - loss: 46883300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6989 - distribution_lambda_loss: 46883300.0000 71/122 [================>.............] - ETA: 0s - loss: 46778144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6401 - distribution_lambda_loss: 46778144.0000 76/122 [=================>............] - ETA: 0s - loss: 46691628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5862 - distribution_lambda_loss: 46691628.0000 81/122 [==================>...........] - ETA: 0s - loss: 46659256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5410 - distribution_lambda_loss: 46659256.0000 86/122 [====================>.........] - ETA: 0s - loss: 46603872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5172 - distribution_lambda_loss: 46603872.0000 91/122 [=====================>........] - ETA: 0s - loss: 46609148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5225 - distribution_lambda_loss: 46609148.0000 96/122 [======================>.......] - ETA: 0s - loss: 46691716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5771 - distribution_lambda_loss: 46691716.0000101/122 [=======================>......] - ETA: 0s - loss: 46777028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6043 - distribution_lambda_loss: 46777028.0000106/122 [=========================>....] - ETA: 0s - loss: 46857940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6619 - distribution_lambda_loss: 46857940.0000111/122 [==========================>...] - ETA: 0s - loss: 46840888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6538 - distribution_lambda_loss: 46840888.0000116/122 [===========================>..] - ETA: 0s - loss: 46818696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6387 - distribution_lambda_loss: 46818696.0000121/122 [============================>.] - ETA: 0s - loss: 46813864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6247 - distribution_lambda_loss: 46813864.0000122/122 [==============================] - 1s 11ms/step - loss: 46809396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6223 - distribution_lambda_loss: 46809396.0000 - val_loss: 48333668.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 59.3807 - val_distribution_lambda_loss: 48333668.0000 - lr: 0.0010
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 44043360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4817 - distribution_lambda_loss: 44043360.0000  6/122 [>.............................] - ETA: 1s - loss: 47292032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.4186 - distribution_lambda_loss: 47292032.0000 11/122 [=>............................] - ETA: 1s - loss: 47087376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.0570 - distribution_lambda_loss: 47087376.0000 16/122 [==>...........................] - ETA: 1s - loss: 47156916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.9583 - distribution_lambda_loss: 47156916.0000 21/122 [====>.........................] - ETA: 1s - loss: 46664648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6432 - distribution_lambda_loss: 46664648.0000 26/122 [=====>........................] - ETA: 0s - loss: 46534872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6268 - distribution_lambda_loss: 46534872.0000 31/122 [======>.......................] - ETA: 0s - loss: 46502304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5881 - distribution_lambda_loss: 46502304.0000 36/122 [=======>......................] - ETA: 0s - loss: 46328424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4422 - distribution_lambda_loss: 46328424.0000 41/122 [=========>....................] - ETA: 0s - loss: 46128020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3118 - distribution_lambda_loss: 46128020.0000 46/122 [==========>...................] - ETA: 0s - loss: 46129752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3192 - distribution_lambda_loss: 46129752.0000 51/122 [===========>..................] - ETA: 0s - loss: 46239096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4003 - distribution_lambda_loss: 46239096.0000 56/122 [============>.................] - ETA: 0s - loss: 46591164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6044 - distribution_lambda_loss: 46591164.0000 61/122 [==============>...............] - ETA: 0s - loss: 46616304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6438 - distribution_lambda_loss: 46616304.0000 66/122 [===============>..............] - ETA: 0s - loss: 46804708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6999 - distribution_lambda_loss: 46804708.0000 71/122 [================>.............] - ETA: 0s - loss: 46699276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6420 - distribution_lambda_loss: 46699276.0000 76/122 [=================>............] - ETA: 0s - loss: 46685408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6387 - distribution_lambda_loss: 46685408.0000 81/122 [==================>...........] - ETA: 0s - loss: 46712284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.6385 - distribution_lambda_loss: 46712284.0000 86/122 [====================>.........] - ETA: 0s - loss: 46633360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5876 - distribution_lambda_loss: 46633360.0000 91/122 [=====================>........] - ETA: 0s - loss: 46607176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5617 - distribution_lambda_loss: 46607176.0000 96/122 [======================>.......] - ETA: 0s - loss: 46513156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4930 - distribution_lambda_loss: 46513156.0000101/122 [=======================>......] - ETA: 0s - loss: 46487140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4832 - distribution_lambda_loss: 46487140.0000106/122 [=========================>....] - ETA: 0s - loss: 46334488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4157 - distribution_lambda_loss: 46334488.0000111/122 [==========================>...] - ETA: 0s - loss: 46326224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4066 - distribution_lambda_loss: 46326224.0000116/122 [===========================>..] - ETA: 0s - loss: 46282292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3818 - distribution_lambda_loss: 46282292.0000121/122 [============================>.] - ETA: 0s - loss: 46252052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3520 - distribution_lambda_loss: 46252052.0000122/122 [==============================] - 1s 11ms/step - loss: 46240600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3531 - distribution_lambda_loss: 46240600.0000 - val_loss: 47137708.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 57.0817 - val_distribution_lambda_loss: 47137708.0000 - lr: 0.0010
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 50217416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.8842 - distribution_lambda_loss: 50217416.0000  6/122 [>.............................] - ETA: 1s - loss: 46578528.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1147 - distribution_lambda_loss: 46578528.0000 11/122 [=>............................] - ETA: 1s - loss: 46453480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.5029 - distribution_lambda_loss: 46453480.0000 16/122 [==>...........................] - ETA: 1s - loss: 46340624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3878 - distribution_lambda_loss: 46340624.0000 21/122 [====>.........................] - ETA: 1s - loss: 46487840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.4733 - distribution_lambda_loss: 46487840.0000 26/122 [=====>........................] - ETA: 0s - loss: 46270064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.2864 - distribution_lambda_loss: 46270064.0000 31/122 [======>.......................] - ETA: 0s - loss: 46069080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3035 - distribution_lambda_loss: 46069080.0000 36/122 [=======>......................] - ETA: 0s - loss: 46101008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.3089 - distribution_lambda_loss: 46101008.0000 41/122 [=========>....................] - ETA: 0s - loss: 45845480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1115 - distribution_lambda_loss: 45845480.0000 46/122 [==========>...................] - ETA: 0s - loss: 46027748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1929 - distribution_lambda_loss: 46027748.0000 51/122 [===========>..................] - ETA: 0s - loss: 45976740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1433 - distribution_lambda_loss: 45976740.0000 56/122 [============>.................] - ETA: 0s - loss: 45914836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1400 - distribution_lambda_loss: 45914836.0000 61/122 [==============>...............] - ETA: 0s - loss: 45726400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0299 - distribution_lambda_loss: 45726400.0000 66/122 [===============>..............] - ETA: 0s - loss: 45693088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0158 - distribution_lambda_loss: 45693088.0000 71/122 [================>.............] - ETA: 0s - loss: 45672356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9870 - distribution_lambda_loss: 45672356.0000 76/122 [=================>............] - ETA: 0s - loss: 45620660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9492 - distribution_lambda_loss: 45620660.0000 81/122 [==================>...........] - ETA: 0s - loss: 45605164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.9488 - distribution_lambda_loss: 45605164.0000 86/122 [====================>.........] - ETA: 0s - loss: 45710232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0328 - distribution_lambda_loss: 45710232.0000 91/122 [=====================>........] - ETA: 0s - loss: 45929544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1471 - distribution_lambda_loss: 45929544.0000 96/122 [======================>.......] - ETA: 0s - loss: 45873792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1091 - distribution_lambda_loss: 45873792.0000101/122 [=======================>......] - ETA: 0s - loss: 45897748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1266 - distribution_lambda_loss: 45897748.0000106/122 [=========================>....] - ETA: 0s - loss: 45840832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.1160 - distribution_lambda_loss: 45840832.0000111/122 [==========================>...] - ETA: 0s - loss: 45803308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0780 - distribution_lambda_loss: 45803308.0000116/122 [===========================>..] - ETA: 0s - loss: 45743652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0418 - distribution_lambda_loss: 45743652.0000121/122 [============================>.] - ETA: 0s - loss: 45759168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0483 - distribution_lambda_loss: 45759168.0000122/122 [==============================] - 1s 11ms/step - loss: 45739240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 57.0459 - distribution_lambda_loss: 45739240.0000 - val_loss: 46624580.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 58.5720 - val_distribution_lambda_loss: 46624580.0000 - lr: 0.0010
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 45556788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 58.1393 - distribution_lambda_loss: 45556788.0000  6/122 [>.............................] - ETA: 1s - loss: 43854380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0300 - distribution_lambda_loss: 43854380.0000 11/122 [=>............................] - ETA: 1s - loss: 43666276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.8833 - distribution_lambda_loss: 43666276.0000 16/122 [==>...........................] - ETA: 1s - loss: 43315648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5795 - distribution_lambda_loss: 43315648.0000 21/122 [====>.........................] - ETA: 1s - loss: 43863716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0007 - distribution_lambda_loss: 43863716.0000 26/122 [=====>........................] - ETA: 0s - loss: 43840212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0575 - distribution_lambda_loss: 43840212.0000 31/122 [======>.......................] - ETA: 0s - loss: 44142376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1497 - distribution_lambda_loss: 44142376.0000 36/122 [=======>......................] - ETA: 0s - loss: 44297136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1941 - distribution_lambda_loss: 44297136.0000 41/122 [=========>....................] - ETA: 0s - loss: 44335996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2191 - distribution_lambda_loss: 44335996.0000 46/122 [==========>...................] - ETA: 0s - loss: 44298336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1681 - distribution_lambda_loss: 44298336.0000 51/122 [===========>..................] - ETA: 0s - loss: 44290696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1607 - distribution_lambda_loss: 44290696.0000 56/122 [============>.................] - ETA: 0s - loss: 44397140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2286 - distribution_lambda_loss: 44397140.0000 61/122 [==============>...............] - ETA: 0s - loss: 44347020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2016 - distribution_lambda_loss: 44347020.0000 66/122 [===============>..............] - ETA: 0s - loss: 44213548.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1176 - distribution_lambda_loss: 44213548.0000 71/122 [================>.............] - ETA: 0s - loss: 44186116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1106 - distribution_lambda_loss: 44186116.0000 76/122 [=================>............] - ETA: 0s - loss: 44187552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1073 - distribution_lambda_loss: 44187552.0000 81/122 [==================>...........] - ETA: 0s - loss: 44133544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0710 - distribution_lambda_loss: 44133544.0000 86/122 [====================>.........] - ETA: 0s - loss: 44026996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0435 - distribution_lambda_loss: 44026996.0000 91/122 [=====================>........] - ETA: 0s - loss: 44103840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0805 - distribution_lambda_loss: 44103840.0000 96/122 [======================>.......] - ETA: 0s - loss: 44092348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0653 - distribution_lambda_loss: 44092348.0000101/122 [=======================>......] - ETA: 0s - loss: 44081132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0628 - distribution_lambda_loss: 44081132.0000106/122 [=========================>....] - ETA: 0s - loss: 44064796.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0557 - distribution_lambda_loss: 44064796.0000111/122 [==========================>...] - ETA: 0s - loss: 44052832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0567 - distribution_lambda_loss: 44052832.0000116/122 [===========================>..] - ETA: 0s - loss: 44029328.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0460 - distribution_lambda_loss: 44029328.0000121/122 [============================>.] - ETA: 0s - loss: 44066220.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0674 - distribution_lambda_loss: 44066220.0000122/122 [==============================] - 1s 11ms/step - loss: 44057664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0568 - distribution_lambda_loss: 44057664.0000 - val_loss: 45200468.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 56.8040 - val_distribution_lambda_loss: 45200468.0000 - lr: 0.0010
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 45202984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.7999 - distribution_lambda_loss: 45202984.0000  6/122 [>.............................] - ETA: 1s - loss: 43745188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1915 - distribution_lambda_loss: 43745188.0000 11/122 [=>............................] - ETA: 1s - loss: 43764596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.8946 - distribution_lambda_loss: 43764596.0000 16/122 [==>...........................] - ETA: 1s - loss: 44089776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1661 - distribution_lambda_loss: 44089776.0000 21/122 [====>.........................] - ETA: 1s - loss: 44342476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2522 - distribution_lambda_loss: 44342476.0000 26/122 [=====>........................] - ETA: 0s - loss: 44161408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1179 - distribution_lambda_loss: 44161408.0000 31/122 [======>.......................] - ETA: 0s - loss: 44016308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1034 - distribution_lambda_loss: 44016308.0000 36/122 [=======>......................] - ETA: 0s - loss: 44022572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1007 - distribution_lambda_loss: 44022572.0000 41/122 [=========>....................] - ETA: 0s - loss: 44106888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.1492 - distribution_lambda_loss: 44106888.0000 46/122 [==========>...................] - ETA: 0s - loss: 44291808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2216 - distribution_lambda_loss: 44291808.0000 51/122 [===========>..................] - ETA: 0s - loss: 44316672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2566 - distribution_lambda_loss: 44316672.0000 56/122 [============>.................] - ETA: 0s - loss: 44436540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.3454 - distribution_lambda_loss: 44436540.0000 61/122 [==============>...............] - ETA: 0s - loss: 44312864.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2579 - distribution_lambda_loss: 44312864.0000 66/122 [===============>..............] - ETA: 0s - loss: 44339212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2446 - distribution_lambda_loss: 44339212.0000 71/122 [================>.............] - ETA: 0s - loss: 44456684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.3053 - distribution_lambda_loss: 44456684.0000 76/122 [=================>............] - ETA: 0s - loss: 44550824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.3480 - distribution_lambda_loss: 44550824.0000 81/122 [==================>...........] - ETA: 0s - loss: 44541768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.3597 - distribution_lambda_loss: 44541768.0000 86/122 [====================>.........] - ETA: 0s - loss: 44494788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.3079 - distribution_lambda_loss: 44494788.0000 91/122 [=====================>........] - ETA: 0s - loss: 44392052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2451 - distribution_lambda_loss: 44392052.0000 96/122 [======================>.......] - ETA: 0s - loss: 44454244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2873 - distribution_lambda_loss: 44454244.0000101/122 [=======================>......] - ETA: 0s - loss: 44388356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2485 - distribution_lambda_loss: 44388356.0000106/122 [=========================>....] - ETA: 0s - loss: 44441476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2790 - distribution_lambda_loss: 44441476.0000111/122 [==========================>...] - ETA: 0s - loss: 44392292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2744 - distribution_lambda_loss: 44392292.0000116/122 [===========================>..] - ETA: 0s - loss: 44307872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2228 - distribution_lambda_loss: 44307872.0000121/122 [============================>.] - ETA: 0s - loss: 44307596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2201 - distribution_lambda_loss: 44307596.0000122/122 [==============================] - 1s 11ms/step - loss: 44310812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.2132 - distribution_lambda_loss: 44310812.0000 - val_loss: 45441476.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 57.7291 - val_distribution_lambda_loss: 45441476.0000 - lr: 0.0010
Epoch 22/50
  1/122 [..............................] - ETA: 1s - loss: 42894412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.5641 - distribution_lambda_loss: 42894412.0000  6/122 [>.............................] - ETA: 1s - loss: 43382800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0742 - distribution_lambda_loss: 43382800.0000 11/122 [=>............................] - ETA: 1s - loss: 43481564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 56.0118 - distribution_lambda_loss: 43481564.0000 16/122 [==>...........................] - ETA: 1s - loss: 43619060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.9716 - distribution_lambda_loss: 43619060.0000 21/122 [====>.........................] - ETA: 1s - loss: 43515108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.8385 - distribution_lambda_loss: 43515108.0000 26/122 [=====>........................] - ETA: 0s - loss: 43368576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.7548 - distribution_lambda_loss: 43368576.0000 31/122 [======>.......................] - ETA: 0s - loss: 43110812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5900 - distribution_lambda_loss: 43110812.0000 36/122 [=======>......................] - ETA: 0s - loss: 43145232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5697 - distribution_lambda_loss: 43145232.0000 41/122 [=========>....................] - ETA: 0s - loss: 43191480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.5673 - distribution_lambda_loss: 43191480.0000 46/122 [==========>...................] - ETA: 0s - loss: 43028380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4742 - distribution_lambda_loss: 43028380.0000 51/122 [===========>..................] - ETA: 0s - loss: 42977836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4378 - distribution_lambda_loss: 42977836.0000 56/122 [============>.................] - ETA: 0s - loss: 42986344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4062 - distribution_lambda_loss: 42986344.0000 61/122 [==============>...............] - ETA: 0s - loss: 42890164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3588 - distribution_lambda_loss: 42890164.0000 66/122 [===============>..............] - ETA: 0s - loss: 42829264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3153 - distribution_lambda_loss: 42829264.0000 71/122 [================>.............] - ETA: 0s - loss: 42837460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3147 - distribution_lambda_loss: 42837460.0000 76/122 [=================>............] - ETA: 0s - loss: 42783804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2926 - distribution_lambda_loss: 42783804.0000 81/122 [==================>...........] - ETA: 0s - loss: 42765956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2918 - distribution_lambda_loss: 42765956.0000 86/122 [====================>.........] - ETA: 0s - loss: 42825932.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2988 - distribution_lambda_loss: 42825932.0000 91/122 [=====================>........] - ETA: 0s - loss: 42801832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2984 - distribution_lambda_loss: 42801832.0000 96/122 [======================>.......] - ETA: 0s - loss: 42706608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2437 - distribution_lambda_loss: 42706608.0000101/122 [=======================>......] - ETA: 0s - loss: 42739924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2722 - distribution_lambda_loss: 42739924.0000106/122 [=========================>....] - ETA: 0s - loss: 42744108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2716 - distribution_lambda_loss: 42744108.0000111/122 [==========================>...] - ETA: 0s - loss: 42730612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2587 - distribution_lambda_loss: 42730612.0000116/122 [===========================>..] - ETA: 0s - loss: 42733796.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2576 - distribution_lambda_loss: 42733796.0000121/122 [============================>.] - ETA: 0s - loss: 42748564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2750 - distribution_lambda_loss: 42748564.0000122/122 [==============================] - 1s 11ms/step - loss: 42745496.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2781 - distribution_lambda_loss: 42745496.0000 - val_loss: 44662576.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.5768 - val_distribution_lambda_loss: 44662576.0000 - lr: 0.0010
Epoch 23/50
  1/122 [..............................] - ETA: 1s - loss: 41510140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2116 - distribution_lambda_loss: 41510140.0000  6/122 [>.............................] - ETA: 1s - loss: 43139348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1917 - distribution_lambda_loss: 43139348.0000 11/122 [=>............................] - ETA: 1s - loss: 43255896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.4705 - distribution_lambda_loss: 43255896.0000 16/122 [==>...........................] - ETA: 1s - loss: 42869336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3250 - distribution_lambda_loss: 42869336.0000 21/122 [====>.........................] - ETA: 1s - loss: 42998432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3422 - distribution_lambda_loss: 42998432.0000 26/122 [=====>........................] - ETA: 0s - loss: 43142008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3820 - distribution_lambda_loss: 43142008.0000 31/122 [======>.......................] - ETA: 0s - loss: 42964240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2998 - distribution_lambda_loss: 42964240.0000 36/122 [=======>......................] - ETA: 0s - loss: 42895376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3160 - distribution_lambda_loss: 42895376.0000 41/122 [=========>....................] - ETA: 0s - loss: 42811568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2462 - distribution_lambda_loss: 42811568.0000 46/122 [==========>...................] - ETA: 0s - loss: 42758936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2098 - distribution_lambda_loss: 42758936.0000 51/122 [===========>..................] - ETA: 0s - loss: 42738024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2115 - distribution_lambda_loss: 42738024.0000 56/122 [============>.................] - ETA: 0s - loss: 42747540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2261 - distribution_lambda_loss: 42747540.0000 61/122 [==============>...............] - ETA: 0s - loss: 42625216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1534 - distribution_lambda_loss: 42625216.0000 66/122 [===============>..............] - ETA: 0s - loss: 42559544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0906 - distribution_lambda_loss: 42559544.0000 71/122 [================>.............] - ETA: 0s - loss: 42458420.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0377 - distribution_lambda_loss: 42458420.0000 76/122 [=================>............] - ETA: 0s - loss: 42471992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0589 - distribution_lambda_loss: 42471992.0000 81/122 [==================>...........] - ETA: 0s - loss: 42453176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0469 - distribution_lambda_loss: 42453176.0000 86/122 [====================>.........] - ETA: 0s - loss: 42397432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0280 - distribution_lambda_loss: 42397432.0000 91/122 [=====================>........] - ETA: 0s - loss: 42351360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9860 - distribution_lambda_loss: 42351360.0000 96/122 [======================>.......] - ETA: 0s - loss: 42370356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0247 - distribution_lambda_loss: 42370356.0000101/122 [=======================>......] - ETA: 0s - loss: 42404744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0431 - distribution_lambda_loss: 42404744.0000106/122 [=========================>....] - ETA: 0s - loss: 42363368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0299 - distribution_lambda_loss: 42363368.0000111/122 [==========================>...] - ETA: 0s - loss: 42402916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.0386 - distribution_lambda_loss: 42402916.0000116/122 [===========================>..] - ETA: 0s - loss: 42520704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1169 - distribution_lambda_loss: 42520704.0000121/122 [============================>.] - ETA: 0s - loss: 42537284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1310 - distribution_lambda_loss: 42537284.0000122/122 [==============================] - 1s 11ms/step - loss: 42538028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1286 - distribution_lambda_loss: 42538028.0000 - val_loss: 45105976.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 56.2331 - val_distribution_lambda_loss: 45105976.0000 - lr: 0.0010
Epoch 24/50
  1/122 [..............................] - ETA: 1s - loss: 42279928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.3145 - distribution_lambda_loss: 42279928.0000  6/122 [>.............................] - ETA: 1s - loss: 42923108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1120 - distribution_lambda_loss: 42923108.0000 11/122 [=>............................] - ETA: 1s - loss: 42526624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2236 - distribution_lambda_loss: 42526624.0000 16/122 [==>...........................] - ETA: 1s - loss: 42476240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1731 - distribution_lambda_loss: 42476240.0000 21/122 [====>.........................] - ETA: 1s - loss: 42308452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9895 - distribution_lambda_loss: 42308452.0000 26/122 [=====>........................] - ETA: 0s - loss: 42023360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8468 - distribution_lambda_loss: 42023360.0000 31/122 [======>.......................] - ETA: 0s - loss: 42124700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9301 - distribution_lambda_loss: 42124700.0000 36/122 [=======>......................] - ETA: 0s - loss: 42057396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9265 - distribution_lambda_loss: 42057396.0000 41/122 [=========>....................] - ETA: 0s - loss: 42063136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9144 - distribution_lambda_loss: 42063136.0000 46/122 [==========>...................] - ETA: 0s - loss: 42144536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9303 - distribution_lambda_loss: 42144536.0000 51/122 [===========>..................] - ETA: 0s - loss: 42166356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9402 - distribution_lambda_loss: 42166356.0000 56/122 [============>.................] - ETA: 0s - loss: 42159164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9158 - distribution_lambda_loss: 42159164.0000 61/122 [==============>...............] - ETA: 0s - loss: 42092412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8748 - distribution_lambda_loss: 42092412.0000 66/122 [===============>..............] - ETA: 0s - loss: 42115588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8998 - distribution_lambda_loss: 42115588.0000 71/122 [================>.............] - ETA: 0s - loss: 42024596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8213 - distribution_lambda_loss: 42024596.0000 76/122 [=================>............] - ETA: 0s - loss: 41997720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8381 - distribution_lambda_loss: 41997720.0000 81/122 [==================>...........] - ETA: 0s - loss: 42099720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8999 - distribution_lambda_loss: 42099720.0000 86/122 [====================>.........] - ETA: 0s - loss: 42080600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8669 - distribution_lambda_loss: 42080600.0000 91/122 [=====================>........] - ETA: 0s - loss: 42068332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8713 - distribution_lambda_loss: 42068332.0000 96/122 [======================>.......] - ETA: 0s - loss: 41993364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8277 - distribution_lambda_loss: 41993364.0000101/122 [=======================>......] - ETA: 0s - loss: 41982144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.8129 - distribution_lambda_loss: 41982144.0000106/122 [=========================>....] - ETA: 0s - loss: 41949648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7989 - distribution_lambda_loss: 41949648.0000111/122 [==========================>...] - ETA: 0s - loss: 41947856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7808 - distribution_lambda_loss: 41947856.0000116/122 [===========================>..] - ETA: 0s - loss: 41953616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7903 - distribution_lambda_loss: 41953616.0000121/122 [============================>.] - ETA: 0s - loss: 41918584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7732 - distribution_lambda_loss: 41918584.0000122/122 [==============================] - 1s 11ms/step - loss: 41933564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.7783 - distribution_lambda_loss: 41933564.0000 - val_loss: 43328908.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 56.2169 - val_distribution_lambda_loss: 43328908.0000 - lr: 0.0010
Epoch 25/50
  1/122 [..............................] - ETA: 1s - loss: 40968976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.3035 - distribution_lambda_loss: 40968976.0000  6/122 [>.............................] - ETA: 1s - loss: 42885072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.6537 - distribution_lambda_loss: 42885072.0000 11/122 [=>............................] - ETA: 1s - loss: 42243648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.2124 - distribution_lambda_loss: 42243648.0000 16/122 [==>...........................] - ETA: 1s - loss: 41991732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.9118 - distribution_lambda_loss: 41991732.0000 21/122 [====>.........................] - ETA: 1s - loss: 41548544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6249 - distribution_lambda_loss: 41548544.0000 26/122 [=====>........................] - ETA: 0s - loss: 41509292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6454 - distribution_lambda_loss: 41509292.0000 31/122 [======>.......................] - ETA: 0s - loss: 41622960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6490 - distribution_lambda_loss: 41622960.0000 36/122 [=======>......................] - ETA: 0s - loss: 41634992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.6437 - distribution_lambda_loss: 41634992.0000 41/122 [=========>....................] - ETA: 0s - loss: 41435100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4825 - distribution_lambda_loss: 41435100.0000 46/122 [==========>...................] - ETA: 0s - loss: 41434476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4915 - distribution_lambda_loss: 41434476.0000 51/122 [===========>..................] - ETA: 0s - loss: 41378364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4198 - distribution_lambda_loss: 41378364.0000 56/122 [============>.................] - ETA: 0s - loss: 41404000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4096 - distribution_lambda_loss: 41404000.0000 61/122 [==============>...............] - ETA: 0s - loss: 41296448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.3509 - distribution_lambda_loss: 41296448.0000 66/122 [===============>..............] - ETA: 0s - loss: 41439544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4750 - distribution_lambda_loss: 41439544.0000 71/122 [================>.............] - ETA: 0s - loss: 41437552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4745 - distribution_lambda_loss: 41437552.0000 76/122 [=================>............] - ETA: 0s - loss: 41386684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4464 - distribution_lambda_loss: 41386684.0000 81/122 [==================>...........] - ETA: 0s - loss: 41448968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4675 - distribution_lambda_loss: 41448968.0000 86/122 [====================>.........] - ETA: 0s - loss: 41531172.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5286 - distribution_lambda_loss: 41531172.0000 91/122 [=====================>........] - ETA: 0s - loss: 41483096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5101 - distribution_lambda_loss: 41483096.0000 96/122 [======================>.......] - ETA: 0s - loss: 41466392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5010 - distribution_lambda_loss: 41466392.0000101/122 [=======================>......] - ETA: 0s - loss: 41478376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4936 - distribution_lambda_loss: 41478376.0000106/122 [=========================>....] - ETA: 0s - loss: 41460308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4918 - distribution_lambda_loss: 41460308.0000111/122 [==========================>...] - ETA: 0s - loss: 41427312.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4576 - distribution_lambda_loss: 41427312.0000116/122 [===========================>..] - ETA: 0s - loss: 41373304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4199 - distribution_lambda_loss: 41373304.0000121/122 [============================>.] - ETA: 0s - loss: 41361684.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4256 - distribution_lambda_loss: 41361684.0000122/122 [==============================] - 1s 11ms/step - loss: 41363600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4208 - distribution_lambda_loss: 41363600.0000 - val_loss: 42368760.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 54.8518 - val_distribution_lambda_loss: 42368760.0000 - lr: 0.0010
Epoch 26/50
  1/122 [..............................] - ETA: 1s - loss: 39087040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.0864 - distribution_lambda_loss: 39087040.0000  6/122 [>.............................] - ETA: 1s - loss: 40371632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9183 - distribution_lambda_loss: 40371632.0000 11/122 [=>............................] - ETA: 1s - loss: 40543204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8428 - distribution_lambda_loss: 40543204.0000 16/122 [==>...........................] - ETA: 1s - loss: 40868572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.0837 - distribution_lambda_loss: 40868572.0000 21/122 [====>.........................] - ETA: 1s - loss: 41230324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1999 - distribution_lambda_loss: 41230324.0000 26/122 [=====>........................] - ETA: 1s - loss: 40720520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9302 - distribution_lambda_loss: 40720520.0000 31/122 [======>.......................] - ETA: 0s - loss: 40882652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.0693 - distribution_lambda_loss: 40882652.0000 36/122 [=======>......................] - ETA: 0s - loss: 40990480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1296 - distribution_lambda_loss: 40990480.0000 41/122 [=========>....................] - ETA: 0s - loss: 41090756.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1817 - distribution_lambda_loss: 41090756.0000 46/122 [==========>...................] - ETA: 0s - loss: 41211208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2528 - distribution_lambda_loss: 41211208.0000 51/122 [===========>..................] - ETA: 0s - loss: 41041816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1724 - distribution_lambda_loss: 41041816.0000 56/122 [============>.................] - ETA: 0s - loss: 41055840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1864 - distribution_lambda_loss: 41055840.0000 61/122 [==============>...............] - ETA: 0s - loss: 41043896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1930 - distribution_lambda_loss: 41043896.0000 66/122 [===============>..............] - ETA: 0s - loss: 41019372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1848 - distribution_lambda_loss: 41019372.0000 71/122 [================>.............] - ETA: 0s - loss: 41036416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1820 - distribution_lambda_loss: 41036416.0000 76/122 [=================>............] - ETA: 0s - loss: 40963140.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1594 - distribution_lambda_loss: 40963140.0000 81/122 [==================>...........] - ETA: 0s - loss: 40919536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1470 - distribution_lambda_loss: 40919536.0000 86/122 [====================>.........] - ETA: 0s - loss: 41066812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2160 - distribution_lambda_loss: 41066812.0000 91/122 [=====================>........] - ETA: 0s - loss: 41056480.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2260 - distribution_lambda_loss: 41056480.0000 96/122 [======================>.......] - ETA: 0s - loss: 40984820.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1812 - distribution_lambda_loss: 40984820.0000101/122 [=======================>......] - ETA: 0s - loss: 40950676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1755 - distribution_lambda_loss: 40950676.0000106/122 [=========================>....] - ETA: 0s - loss: 40965664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1697 - distribution_lambda_loss: 40965664.0000111/122 [==========================>...] - ETA: 0s - loss: 40921264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1377 - distribution_lambda_loss: 40921264.0000116/122 [===========================>..] - ETA: 0s - loss: 40943128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1387 - distribution_lambda_loss: 40943128.0000121/122 [============================>.] - ETA: 0s - loss: 41010392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1909 - distribution_lambda_loss: 41010392.0000122/122 [==============================] - 1s 11ms/step - loss: 41012332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1909 - distribution_lambda_loss: 41012332.0000 - val_loss: 43491576.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 53.3888 - val_distribution_lambda_loss: 43491576.0000 - lr: 0.0010
Epoch 27/50
  1/122 [..............................] - ETA: 1s - loss: 43183880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4257 - distribution_lambda_loss: 43183880.0000  6/122 [>.............................] - ETA: 1s - loss: 42960044.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 55.1792 - distribution_lambda_loss: 42960044.0000 11/122 [=>............................] - ETA: 1s - loss: 41409816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.5019 - distribution_lambda_loss: 41409816.0000 16/122 [==>...........................] - ETA: 1s - loss: 41530188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.4879 - distribution_lambda_loss: 41530188.0000 21/122 [====>.........................] - ETA: 1s - loss: 41070076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2127 - distribution_lambda_loss: 41070076.0000 26/122 [=====>........................] - ETA: 0s - loss: 41087576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.2700 - distribution_lambda_loss: 41087576.0000 31/122 [======>.......................] - ETA: 0s - loss: 40974640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1496 - distribution_lambda_loss: 40974640.0000 36/122 [=======>......................] - ETA: 0s - loss: 41000252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.1844 - distribution_lambda_loss: 41000252.0000 41/122 [=========>....................] - ETA: 0s - loss: 40729308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 54.0090 - distribution_lambda_loss: 40729308.0000 46/122 [==========>...................] - ETA: 0s - loss: 40598092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.9254 - distribution_lambda_loss: 40598092.0000 51/122 [===========>..................] - ETA: 0s - loss: 40454980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.8425 - distribution_lambda_loss: 40454980.0000 56/122 [============>.................] - ETA: 0s - loss: 40362292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7610 - distribution_lambda_loss: 40362292.0000 61/122 [==============>...............] - ETA: 0s - loss: 40315084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7402 - distribution_lambda_loss: 40315084.0000 66/122 [===============>..............] - ETA: 0s - loss: 40319252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7372 - distribution_lambda_loss: 40319252.0000 71/122 [================>.............] - ETA: 0s - loss: 40217540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6746 - distribution_lambda_loss: 40217540.0000 76/122 [=================>............] - ETA: 0s - loss: 40169704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6364 - distribution_lambda_loss: 40169704.0000 81/122 [==================>...........] - ETA: 0s - loss: 40152360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6168 - distribution_lambda_loss: 40152360.0000 86/122 [====================>.........] - ETA: 0s - loss: 40170608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6283 - distribution_lambda_loss: 40170608.0000 91/122 [=====================>........] - ETA: 0s - loss: 40180848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6243 - distribution_lambda_loss: 40180848.0000 96/122 [======================>.......] - ETA: 0s - loss: 40176028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6302 - distribution_lambda_loss: 40176028.0000101/122 [=======================>......] - ETA: 0s - loss: 40174236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6401 - distribution_lambda_loss: 40174236.0000106/122 [=========================>....] - ETA: 0s - loss: 40212620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6420 - distribution_lambda_loss: 40212620.0000111/122 [==========================>...] - ETA: 0s - loss: 40180376.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6187 - distribution_lambda_loss: 40180376.0000116/122 [===========================>..] - ETA: 0s - loss: 40182880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6248 - distribution_lambda_loss: 40182880.0000121/122 [============================>.] - ETA: 0s - loss: 40171832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6182 - distribution_lambda_loss: 40171832.0000122/122 [==============================] - 1s 11ms/step - loss: 40201632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6292 - distribution_lambda_loss: 40201632.0000 - val_loss: 42256380.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.6273 - val_distribution_lambda_loss: 42256380.0000 - lr: 0.0010
Epoch 28/50
  1/122 [..............................] - ETA: 1s - loss: 38006784.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2589 - distribution_lambda_loss: 38006784.0000  6/122 [>.............................] - ETA: 1s - loss: 40028012.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6854 - distribution_lambda_loss: 40028012.0000 11/122 [=>............................] - ETA: 1s - loss: 40214084.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6567 - distribution_lambda_loss: 40214084.0000 16/122 [==>...........................] - ETA: 1s - loss: 40137860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5925 - distribution_lambda_loss: 40137860.0000 21/122 [====>.........................] - ETA: 1s - loss: 40358704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7029 - distribution_lambda_loss: 40358704.0000 26/122 [=====>........................] - ETA: 0s - loss: 40171812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6026 - distribution_lambda_loss: 40171812.0000 31/122 [======>.......................] - ETA: 0s - loss: 40173124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6083 - distribution_lambda_loss: 40173124.0000 36/122 [=======>......................] - ETA: 0s - loss: 40194196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6613 - distribution_lambda_loss: 40194196.0000 41/122 [=========>....................] - ETA: 0s - loss: 40222380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6776 - distribution_lambda_loss: 40222380.0000 46/122 [==========>...................] - ETA: 0s - loss: 40192636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6605 - distribution_lambda_loss: 40192636.0000 51/122 [===========>..................] - ETA: 0s - loss: 40104868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6159 - distribution_lambda_loss: 40104868.0000 56/122 [============>.................] - ETA: 0s - loss: 40089884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6208 - distribution_lambda_loss: 40089884.0000 61/122 [==============>...............] - ETA: 0s - loss: 39947232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5387 - distribution_lambda_loss: 39947232.0000 66/122 [===============>..............] - ETA: 0s - loss: 39936212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5321 - distribution_lambda_loss: 39936212.0000 71/122 [================>.............] - ETA: 0s - loss: 39882440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4890 - distribution_lambda_loss: 39882440.0000 76/122 [=================>............] - ETA: 0s - loss: 39899112.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4889 - distribution_lambda_loss: 39899112.0000 81/122 [==================>...........] - ETA: 0s - loss: 39893664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4870 - distribution_lambda_loss: 39893664.0000 86/122 [====================>.........] - ETA: 0s - loss: 39915392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5066 - distribution_lambda_loss: 39915392.0000 91/122 [=====================>........] - ETA: 0s - loss: 39922924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5009 - distribution_lambda_loss: 39922924.0000 96/122 [======================>.......] - ETA: 0s - loss: 39961300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5322 - distribution_lambda_loss: 39961300.0000101/122 [=======================>......] - ETA: 0s - loss: 39999520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5233 - distribution_lambda_loss: 39999520.0000106/122 [=========================>....] - ETA: 0s - loss: 40075412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5851 - distribution_lambda_loss: 40075412.0000111/122 [==========================>...] - ETA: 0s - loss: 40165876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6490 - distribution_lambda_loss: 40165876.0000116/122 [===========================>..] - ETA: 0s - loss: 40166404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6311 - distribution_lambda_loss: 40166404.0000121/122 [============================>.] - ETA: 0s - loss: 40181560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6477 - distribution_lambda_loss: 40181560.0000122/122 [==============================] - 1s 11ms/step - loss: 40189248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.6579 - distribution_lambda_loss: 40189248.0000 - val_loss: 42839796.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 53.0270 - val_distribution_lambda_loss: 42839796.0000 - lr: 0.0010
Epoch 29/50
  1/122 [..............................] - ETA: 1s - loss: 41500568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1562 - distribution_lambda_loss: 41500568.0000  6/122 [>.............................] - ETA: 1s - loss: 41116844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5964 - distribution_lambda_loss: 41116844.0000 11/122 [=>............................] - ETA: 1s - loss: 40738168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.7270 - distribution_lambda_loss: 40738168.0000 16/122 [==>...........................] - ETA: 1s - loss: 40350052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.5410 - distribution_lambda_loss: 40350052.0000 21/122 [====>.........................] - ETA: 1s - loss: 40044032.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.4346 - distribution_lambda_loss: 40044032.0000 26/122 [=====>........................] - ETA: 0s - loss: 39918236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3605 - distribution_lambda_loss: 39918236.0000 31/122 [======>.......................] - ETA: 0s - loss: 39735372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2689 - distribution_lambda_loss: 39735372.0000 36/122 [=======>......................] - ETA: 0s - loss: 39537512.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1143 - distribution_lambda_loss: 39537512.0000 41/122 [=========>....................] - ETA: 0s - loss: 39573152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1382 - distribution_lambda_loss: 39573152.0000 46/122 [==========>...................] - ETA: 0s - loss: 39603060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1700 - distribution_lambda_loss: 39603060.0000 51/122 [===========>..................] - ETA: 0s - loss: 39614972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1819 - distribution_lambda_loss: 39614972.0000 56/122 [============>.................] - ETA: 0s - loss: 39578668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1756 - distribution_lambda_loss: 39578668.0000 61/122 [==============>...............] - ETA: 0s - loss: 39633372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2273 - distribution_lambda_loss: 39633372.0000 66/122 [===============>..............] - ETA: 0s - loss: 39673856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2804 - distribution_lambda_loss: 39673856.0000 71/122 [================>.............] - ETA: 0s - loss: 39693208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2538 - distribution_lambda_loss: 39693208.0000 76/122 [=================>............] - ETA: 0s - loss: 39709620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2675 - distribution_lambda_loss: 39709620.0000 81/122 [==================>...........] - ETA: 0s - loss: 39773368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3345 - distribution_lambda_loss: 39773368.0000 86/122 [====================>.........] - ETA: 0s - loss: 39798604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3376 - distribution_lambda_loss: 39798604.0000 91/122 [=====================>........] - ETA: 0s - loss: 39779216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3205 - distribution_lambda_loss: 39779216.0000 96/122 [======================>.......] - ETA: 0s - loss: 39827620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3614 - distribution_lambda_loss: 39827620.0000101/122 [=======================>......] - ETA: 0s - loss: 39809568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3449 - distribution_lambda_loss: 39809568.0000106/122 [=========================>....] - ETA: 0s - loss: 39775284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3268 - distribution_lambda_loss: 39775284.0000111/122 [==========================>...] - ETA: 0s - loss: 39706620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2883 - distribution_lambda_loss: 39706620.0000116/122 [===========================>..] - ETA: 0s - loss: 39694680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2809 - distribution_lambda_loss: 39694680.0000121/122 [============================>.] - ETA: 0s - loss: 39724996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3088 - distribution_lambda_loss: 39724996.0000122/122 [==============================] - 1s 11ms/step - loss: 39719008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3009 - distribution_lambda_loss: 39719008.0000 - val_loss: 40753868.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 54.4977 - val_distribution_lambda_loss: 40753868.0000 - lr: 0.0010
Epoch 30/50
  1/122 [..............................] - ETA: 1s - loss: 36281584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1535 - distribution_lambda_loss: 36281584.0000  6/122 [>.............................] - ETA: 1s - loss: 37909832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.4750 - distribution_lambda_loss: 37909832.0000 11/122 [=>............................] - ETA: 1s - loss: 38472540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.6551 - distribution_lambda_loss: 38472540.0000 16/122 [==>...........................] - ETA: 1s - loss: 38527688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.6980 - distribution_lambda_loss: 38527688.0000 21/122 [====>.........................] - ETA: 1s - loss: 38419300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5472 - distribution_lambda_loss: 38419300.0000 26/122 [=====>........................] - ETA: 0s - loss: 38279592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.4421 - distribution_lambda_loss: 38279592.0000 31/122 [======>.......................] - ETA: 0s - loss: 38397816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5480 - distribution_lambda_loss: 38397816.0000 36/122 [=======>......................] - ETA: 0s - loss: 38301000.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.4603 - distribution_lambda_loss: 38301000.0000 41/122 [=========>....................] - ETA: 0s - loss: 38418560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5245 - distribution_lambda_loss: 38418560.0000 46/122 [==========>...................] - ETA: 0s - loss: 38522472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5907 - distribution_lambda_loss: 38522472.0000 51/122 [===========>..................] - ETA: 0s - loss: 38496064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.5754 - distribution_lambda_loss: 38496064.0000 56/122 [============>.................] - ETA: 0s - loss: 38586552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.6271 - distribution_lambda_loss: 38586552.0000 61/122 [==============>...............] - ETA: 0s - loss: 38625340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.6504 - distribution_lambda_loss: 38625340.0000 66/122 [===============>..............] - ETA: 0s - loss: 38799712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.7734 - distribution_lambda_loss: 38799712.0000 71/122 [================>.............] - ETA: 0s - loss: 38904956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8161 - distribution_lambda_loss: 38904956.0000 76/122 [=================>............] - ETA: 0s - loss: 38967708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8616 - distribution_lambda_loss: 38967708.0000 81/122 [==================>...........] - ETA: 0s - loss: 38957344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8634 - distribution_lambda_loss: 38957344.0000 86/122 [====================>.........] - ETA: 0s - loss: 38967352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8674 - distribution_lambda_loss: 38967352.0000 91/122 [=====================>........] - ETA: 0s - loss: 38980244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8663 - distribution_lambda_loss: 38980244.0000 96/122 [======================>.......] - ETA: 0s - loss: 39013988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8967 - distribution_lambda_loss: 39013988.0000101/122 [=======================>......] - ETA: 0s - loss: 39060720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9320 - distribution_lambda_loss: 39060720.0000106/122 [=========================>....] - ETA: 0s - loss: 39033616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8872 - distribution_lambda_loss: 39033616.0000111/122 [==========================>...] - ETA: 0s - loss: 39052540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9053 - distribution_lambda_loss: 39052540.0000116/122 [===========================>..] - ETA: 0s - loss: 39138100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9617 - distribution_lambda_loss: 39138100.0000121/122 [============================>.] - ETA: 0s - loss: 39242708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.0146 - distribution_lambda_loss: 39242708.0000122/122 [==============================] - 1s 11ms/step - loss: 39245816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.0112 - distribution_lambda_loss: 39245816.0000 - val_loss: 41472836.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 54.8462 - val_distribution_lambda_loss: 41472836.0000 - lr: 0.0010
Epoch 31/50
  1/122 [..............................] - ETA: 1s - loss: 38597304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8264 - distribution_lambda_loss: 38597304.0000  6/122 [>.............................] - ETA: 1s - loss: 39793308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.3580 - distribution_lambda_loss: 39793308.0000 11/122 [=>............................] - ETA: 1s - loss: 39567664.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.1548 - distribution_lambda_loss: 39567664.0000 16/122 [==>...........................] - ETA: 1s - loss: 39449768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.0981 - distribution_lambda_loss: 39449768.0000 21/122 [====>.........................] - ETA: 1s - loss: 39224980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9922 - distribution_lambda_loss: 39224980.0000 26/122 [=====>........................] - ETA: 0s - loss: 39041816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.7870 - distribution_lambda_loss: 39041816.0000 31/122 [======>.......................] - ETA: 0s - loss: 39122792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9141 - distribution_lambda_loss: 39122792.0000 36/122 [=======>......................] - ETA: 0s - loss: 39289740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.0015 - distribution_lambda_loss: 39289740.0000 41/122 [=========>....................] - ETA: 0s - loss: 39176596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9600 - distribution_lambda_loss: 39176596.0000 46/122 [==========>...................] - ETA: 0s - loss: 39156372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9497 - distribution_lambda_loss: 39156372.0000 51/122 [===========>..................] - ETA: 0s - loss: 39156356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9300 - distribution_lambda_loss: 39156356.0000 56/122 [============>.................] - ETA: 0s - loss: 39144424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9323 - distribution_lambda_loss: 39144424.0000 61/122 [==============>...............] - ETA: 0s - loss: 39075672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8975 - distribution_lambda_loss: 39075672.0000 66/122 [===============>..............] - ETA: 0s - loss: 39132468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9175 - distribution_lambda_loss: 39132468.0000 71/122 [================>.............] - ETA: 0s - loss: 39074800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8914 - distribution_lambda_loss: 39074800.0000 76/122 [=================>............] - ETA: 0s - loss: 39053984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8796 - distribution_lambda_loss: 39053984.0000 81/122 [==================>...........] - ETA: 0s - loss: 39066060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.8715 - distribution_lambda_loss: 39066060.0000 86/122 [====================>.........] - ETA: 0s - loss: 39100456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9351 - distribution_lambda_loss: 39100456.0000 91/122 [=====================>........] - ETA: 0s - loss: 39116900.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9233 - distribution_lambda_loss: 39116900.0000 96/122 [======================>.......] - ETA: 0s - loss: 39116476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9334 - distribution_lambda_loss: 39116476.0000101/122 [=======================>......] - ETA: 0s - loss: 39093388.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9163 - distribution_lambda_loss: 39093388.0000106/122 [=========================>....] - ETA: 0s - loss: 39107064.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9259 - distribution_lambda_loss: 39107064.0000111/122 [==========================>...] - ETA: 0s - loss: 39173456.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9655 - distribution_lambda_loss: 39173456.0000116/122 [===========================>..] - ETA: 0s - loss: 39154116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9611 - distribution_lambda_loss: 39154116.0000121/122 [============================>.] - ETA: 0s - loss: 39153072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9604 - distribution_lambda_loss: 39153072.0000
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 39149452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.9623 - distribution_lambda_loss: 39149452.0000 - val_loss: 41842256.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 55.1514 - val_distribution_lambda_loss: 41842256.0000 - lr: 0.0010
Epoch 32/50
  1/122 [..............................] - ETA: 1s - loss: 38673288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 53.2180 - distribution_lambda_loss: 38673288.0000  6/122 [>.............................] - ETA: 1s - loss: 37941884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.2169 - distribution_lambda_loss: 37941884.0000 11/122 [=>............................] - ETA: 1s - loss: 37937444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0635 - distribution_lambda_loss: 37937444.0000 16/122 [==>...........................] - ETA: 1s - loss: 38018300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1371 - distribution_lambda_loss: 38018300.0000 21/122 [====>.........................] - ETA: 1s - loss: 37901896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.1114 - distribution_lambda_loss: 37901896.0000 26/122 [=====>........................] - ETA: 0s - loss: 37576764.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.9308 - distribution_lambda_loss: 37576764.0000 31/122 [======>.......................] - ETA: 0s - loss: 37490332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8643 - distribution_lambda_loss: 37490332.0000 36/122 [=======>......................] - ETA: 0s - loss: 37432552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7939 - distribution_lambda_loss: 37432552.0000 41/122 [=========>....................] - ETA: 0s - loss: 37383672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7488 - distribution_lambda_loss: 37383672.0000 46/122 [==========>...................] - ETA: 0s - loss: 37381200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7431 - distribution_lambda_loss: 37381200.0000 51/122 [===========>..................] - ETA: 0s - loss: 37376136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7551 - distribution_lambda_loss: 37376136.0000 56/122 [============>.................] - ETA: 0s - loss: 37387576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7543 - distribution_lambda_loss: 37387576.0000 61/122 [==============>...............] - ETA: 0s - loss: 37312152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6888 - distribution_lambda_loss: 37312152.0000 66/122 [===============>..............] - ETA: 0s - loss: 37259780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6576 - distribution_lambda_loss: 37259780.0000 71/122 [================>.............] - ETA: 0s - loss: 37289124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6911 - distribution_lambda_loss: 37289124.0000 76/122 [=================>............] - ETA: 0s - loss: 37305164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.7064 - distribution_lambda_loss: 37305164.0000 81/122 [==================>...........] - ETA: 0s - loss: 37257332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6780 - distribution_lambda_loss: 37257332.0000 86/122 [====================>.........] - ETA: 0s - loss: 37159924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6071 - distribution_lambda_loss: 37159924.0000 91/122 [=====================>........] - ETA: 0s - loss: 37104568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5712 - distribution_lambda_loss: 37104568.0000 96/122 [======================>.......] - ETA: 0s - loss: 37112956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5729 - distribution_lambda_loss: 37112956.0000101/122 [=======================>......] - ETA: 0s - loss: 37132824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5921 - distribution_lambda_loss: 37132824.0000106/122 [=========================>....] - ETA: 0s - loss: 37136296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6033 - distribution_lambda_loss: 37136296.0000111/122 [==========================>...] - ETA: 0s - loss: 37088604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5755 - distribution_lambda_loss: 37088604.0000116/122 [===========================>..] - ETA: 0s - loss: 37105208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5937 - distribution_lambda_loss: 37105208.0000121/122 [============================>.] - ETA: 0s - loss: 37083472.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5842 - distribution_lambda_loss: 37083472.0000122/122 [==============================] - 1s 11ms/step - loss: 37095124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5861 - distribution_lambda_loss: 37095124.0000 - val_loss: 38764968.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.8560 - val_distribution_lambda_loss: 38764968.0000 - lr: 5.0000e-04
Epoch 33/50
  1/122 [..............................] - ETA: 1s - loss: 37152216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3313 - distribution_lambda_loss: 37152216.0000  6/122 [>.............................] - ETA: 1s - loss: 36687100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3876 - distribution_lambda_loss: 36687100.0000 11/122 [=>............................] - ETA: 1s - loss: 36421372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2285 - distribution_lambda_loss: 36421372.0000 16/122 [==>...........................] - ETA: 1s - loss: 36337008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2012 - distribution_lambda_loss: 36337008.0000 21/122 [====>.........................] - ETA: 1s - loss: 36490976.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2602 - distribution_lambda_loss: 36490976.0000 26/122 [=====>........................] - ETA: 0s - loss: 36620144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3240 - distribution_lambda_loss: 36620144.0000 31/122 [======>.......................] - ETA: 0s - loss: 36480300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2132 - distribution_lambda_loss: 36480300.0000 36/122 [=======>......................] - ETA: 0s - loss: 36479532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2077 - distribution_lambda_loss: 36479532.0000 41/122 [=========>....................] - ETA: 0s - loss: 36556252.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2858 - distribution_lambda_loss: 36556252.0000 46/122 [==========>...................] - ETA: 0s - loss: 36574568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2860 - distribution_lambda_loss: 36574568.0000 51/122 [===========>..................] - ETA: 0s - loss: 36531564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2403 - distribution_lambda_loss: 36531564.0000 56/122 [============>.................] - ETA: 0s - loss: 36477812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1813 - distribution_lambda_loss: 36477812.0000 61/122 [==============>...............] - ETA: 0s - loss: 36493564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1859 - distribution_lambda_loss: 36493564.0000 66/122 [===============>..............] - ETA: 0s - loss: 36471880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1746 - distribution_lambda_loss: 36471880.0000 71/122 [================>.............] - ETA: 0s - loss: 36513424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2008 - distribution_lambda_loss: 36513424.0000 76/122 [=================>............] - ETA: 0s - loss: 36498080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1816 - distribution_lambda_loss: 36498080.0000 81/122 [==================>...........] - ETA: 0s - loss: 36512248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2012 - distribution_lambda_loss: 36512248.0000 86/122 [====================>.........] - ETA: 0s - loss: 36603072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2689 - distribution_lambda_loss: 36603072.0000 91/122 [=====================>........] - ETA: 0s - loss: 36679752.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3223 - distribution_lambda_loss: 36679752.0000 96/122 [======================>.......] - ETA: 0s - loss: 36711836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3436 - distribution_lambda_loss: 36711836.0000101/122 [=======================>......] - ETA: 0s - loss: 36694364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3230 - distribution_lambda_loss: 36694364.0000106/122 [=========================>....] - ETA: 0s - loss: 36685212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3250 - distribution_lambda_loss: 36685212.0000111/122 [==========================>...] - ETA: 0s - loss: 36705540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3376 - distribution_lambda_loss: 36705540.0000116/122 [===========================>..] - ETA: 0s - loss: 36708740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3474 - distribution_lambda_loss: 36708740.0000121/122 [============================>.] - ETA: 0s - loss: 36687348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3275 - distribution_lambda_loss: 36687348.0000122/122 [==============================] - 1s 11ms/step - loss: 36695024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3338 - distribution_lambda_loss: 36695024.0000 - val_loss: 38639768.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.9962 - val_distribution_lambda_loss: 38639768.0000 - lr: 5.0000e-04
Epoch 34/50
  1/122 [..............................] - ETA: 1s - loss: 34273308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6678 - distribution_lambda_loss: 34273308.0000  6/122 [>.............................] - ETA: 1s - loss: 36651320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2359 - distribution_lambda_loss: 36651320.0000 11/122 [=>............................] - ETA: 1s - loss: 37134076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.5530 - distribution_lambda_loss: 37134076.0000 16/122 [==>...........................] - ETA: 1s - loss: 37096324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4885 - distribution_lambda_loss: 37096324.0000 21/122 [====>.........................] - ETA: 1s - loss: 36890016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3864 - distribution_lambda_loss: 36890016.0000 26/122 [=====>........................] - ETA: 0s - loss: 36713060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3244 - distribution_lambda_loss: 36713060.0000 31/122 [======>.......................] - ETA: 0s - loss: 36649968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3048 - distribution_lambda_loss: 36649968.0000 36/122 [=======>......................] - ETA: 0s - loss: 36668372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2938 - distribution_lambda_loss: 36668372.0000 41/122 [=========>....................] - ETA: 0s - loss: 36713020.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3360 - distribution_lambda_loss: 36713020.0000 46/122 [==========>...................] - ETA: 0s - loss: 36864920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4291 - distribution_lambda_loss: 36864920.0000 51/122 [===========>..................] - ETA: 0s - loss: 36782224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3620 - distribution_lambda_loss: 36782224.0000 56/122 [============>.................] - ETA: 0s - loss: 36826124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3891 - distribution_lambda_loss: 36826124.0000 61/122 [==============>...............] - ETA: 0s - loss: 36848812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4064 - distribution_lambda_loss: 36848812.0000 66/122 [===============>..............] - ETA: 0s - loss: 36793748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3689 - distribution_lambda_loss: 36793748.0000 71/122 [================>.............] - ETA: 0s - loss: 36794780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3772 - distribution_lambda_loss: 36794780.0000 76/122 [=================>............] - ETA: 0s - loss: 36803748.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3852 - distribution_lambda_loss: 36803748.0000 81/122 [==================>...........] - ETA: 0s - loss: 36758340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3508 - distribution_lambda_loss: 36758340.0000 86/122 [====================>.........] - ETA: 0s - loss: 36717360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3235 - distribution_lambda_loss: 36717360.0000 91/122 [=====================>........] - ETA: 0s - loss: 36653764.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2942 - distribution_lambda_loss: 36653764.0000 96/122 [======================>.......] - ETA: 0s - loss: 36629908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2842 - distribution_lambda_loss: 36629908.0000101/122 [=======================>......] - ETA: 0s - loss: 36635408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2947 - distribution_lambda_loss: 36635408.0000106/122 [=========================>....] - ETA: 0s - loss: 36566660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2475 - distribution_lambda_loss: 36566660.0000111/122 [==========================>...] - ETA: 0s - loss: 36571636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2387 - distribution_lambda_loss: 36571636.0000116/122 [===========================>..] - ETA: 0s - loss: 36516380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2103 - distribution_lambda_loss: 36516380.0000121/122 [============================>.] - ETA: 0s - loss: 36501736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1975 - distribution_lambda_loss: 36501736.0000122/122 [==============================] - 1s 11ms/step - loss: 36482780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1851 - distribution_lambda_loss: 36482780.0000 - val_loss: 38542504.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.8888 - val_distribution_lambda_loss: 38542504.0000 - lr: 5.0000e-04
Epoch 35/50
  1/122 [..............................] - ETA: 1s - loss: 35613276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5003 - distribution_lambda_loss: 35613276.0000  6/122 [>.............................] - ETA: 1s - loss: 35434844.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6240 - distribution_lambda_loss: 35434844.0000 11/122 [=>............................] - ETA: 1s - loss: 35955828.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9808 - distribution_lambda_loss: 35955828.0000 16/122 [==>...........................] - ETA: 1s - loss: 36443368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.1898 - distribution_lambda_loss: 36443368.0000 21/122 [====>.........................] - ETA: 1s - loss: 36493920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2385 - distribution_lambda_loss: 36493920.0000 26/122 [=====>........................] - ETA: 1s - loss: 36622904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3221 - distribution_lambda_loss: 36622904.0000 31/122 [======>.......................] - ETA: 0s - loss: 36559956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2977 - distribution_lambda_loss: 36559956.0000 36/122 [=======>......................] - ETA: 0s - loss: 36722972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3696 - distribution_lambda_loss: 36722972.0000 41/122 [=========>....................] - ETA: 0s - loss: 36734840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3956 - distribution_lambda_loss: 36734840.0000 46/122 [==========>...................] - ETA: 0s - loss: 36768240.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4103 - distribution_lambda_loss: 36768240.0000 51/122 [===========>..................] - ETA: 0s - loss: 36876100.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4574 - distribution_lambda_loss: 36876100.0000 56/122 [============>.................] - ETA: 0s - loss: 36876996.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4424 - distribution_lambda_loss: 36876996.0000 61/122 [==============>...............] - ETA: 0s - loss: 36947380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4872 - distribution_lambda_loss: 36947380.0000 66/122 [===============>..............] - ETA: 0s - loss: 36799572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3900 - distribution_lambda_loss: 36799572.0000 71/122 [================>.............] - ETA: 0s - loss: 36855912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4207 - distribution_lambda_loss: 36855912.0000 76/122 [=================>............] - ETA: 0s - loss: 36915788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4586 - distribution_lambda_loss: 36915788.0000 81/122 [==================>...........] - ETA: 0s - loss: 36859024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4224 - distribution_lambda_loss: 36859024.0000 86/122 [====================>.........] - ETA: 0s - loss: 36846552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.4253 - distribution_lambda_loss: 36846552.0000 91/122 [=====================>........] - ETA: 0s - loss: 36808956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3873 - distribution_lambda_loss: 36808956.0000 96/122 [======================>.......] - ETA: 0s - loss: 36796316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3832 - distribution_lambda_loss: 36796316.0000101/122 [=======================>......] - ETA: 0s - loss: 36761680.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3639 - distribution_lambda_loss: 36761680.0000106/122 [=========================>....] - ETA: 0s - loss: 36732644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3418 - distribution_lambda_loss: 36732644.0000111/122 [==========================>...] - ETA: 0s - loss: 36690092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.3121 - distribution_lambda_loss: 36690092.0000116/122 [===========================>..] - ETA: 0s - loss: 36622028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2680 - distribution_lambda_loss: 36622028.0000121/122 [============================>.] - ETA: 0s - loss: 36594924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2470 - distribution_lambda_loss: 36594924.0000122/122 [==============================] - 1s 11ms/step - loss: 36602892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.2481 - distribution_lambda_loss: 36602892.0000 - val_loss: 38751388.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.9677 - val_distribution_lambda_loss: 38751388.0000 - lr: 5.0000e-04
Epoch 36/50
  1/122 [..............................] - ETA: 1s - loss: 34440712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4912 - distribution_lambda_loss: 34440712.0000  6/122 [>.............................] - ETA: 1s - loss: 35397068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6047 - distribution_lambda_loss: 35397068.0000 11/122 [=>............................] - ETA: 1s - loss: 35620132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6208 - distribution_lambda_loss: 35620132.0000 16/122 [==>...........................] - ETA: 1s - loss: 35964640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8844 - distribution_lambda_loss: 35964640.0000 21/122 [====>.........................] - ETA: 1s - loss: 36081824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9360 - distribution_lambda_loss: 36081824.0000 26/122 [=====>........................] - ETA: 0s - loss: 36099876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9595 - distribution_lambda_loss: 36099876.0000 31/122 [======>.......................] - ETA: 0s - loss: 35869348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7619 - distribution_lambda_loss: 35869348.0000 36/122 [=======>......................] - ETA: 0s - loss: 35913232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8099 - distribution_lambda_loss: 35913232.0000 41/122 [=========>....................] - ETA: 0s - loss: 36060564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8952 - distribution_lambda_loss: 36060564.0000 46/122 [==========>...................] - ETA: 0s - loss: 36216416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9818 - distribution_lambda_loss: 36216416.0000 51/122 [===========>..................] - ETA: 0s - loss: 36279780.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0065 - distribution_lambda_loss: 36279780.0000 56/122 [============>.................] - ETA: 0s - loss: 36251336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0014 - distribution_lambda_loss: 36251336.0000 61/122 [==============>...............] - ETA: 0s - loss: 36187168.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9571 - distribution_lambda_loss: 36187168.0000 66/122 [===============>..............] - ETA: 0s - loss: 36114532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9238 - distribution_lambda_loss: 36114532.0000 71/122 [================>.............] - ETA: 0s - loss: 36143232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9456 - distribution_lambda_loss: 36143232.0000 76/122 [=================>............] - ETA: 0s - loss: 36242344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0087 - distribution_lambda_loss: 36242344.0000 81/122 [==================>...........] - ETA: 0s - loss: 36267576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0181 - distribution_lambda_loss: 36267576.0000 86/122 [====================>.........] - ETA: 0s - loss: 36242636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0023 - distribution_lambda_loss: 36242636.0000 91/122 [=====================>........] - ETA: 0s - loss: 36233380.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9995 - distribution_lambda_loss: 36233380.0000 96/122 [======================>.......] - ETA: 0s - loss: 36231476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0089 - distribution_lambda_loss: 36231476.0000101/122 [=======================>......] - ETA: 0s - loss: 36174856.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9677 - distribution_lambda_loss: 36174856.0000106/122 [=========================>....] - ETA: 0s - loss: 36233452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0001 - distribution_lambda_loss: 36233452.0000111/122 [==========================>...] - ETA: 0s - loss: 36220332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9986 - distribution_lambda_loss: 36220332.0000116/122 [===========================>..] - ETA: 0s - loss: 36230412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0004 - distribution_lambda_loss: 36230412.0000121/122 [============================>.] - ETA: 0s - loss: 36198336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9816 - distribution_lambda_loss: 36198336.0000122/122 [==============================] - 1s 11ms/step - loss: 36192344.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9812 - distribution_lambda_loss: 36192344.0000 - val_loss: 38250768.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.3334 - val_distribution_lambda_loss: 38250768.0000 - lr: 5.0000e-04
Epoch 37/50
  1/122 [..............................] - ETA: 1s - loss: 36856988.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.6269 - distribution_lambda_loss: 36856988.0000  6/122 [>.............................] - ETA: 1s - loss: 36140148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8874 - distribution_lambda_loss: 36140148.0000 11/122 [=>............................] - ETA: 1s - loss: 36095228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9828 - distribution_lambda_loss: 36095228.0000 16/122 [==>...........................] - ETA: 1s - loss: 35808884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7500 - distribution_lambda_loss: 35808884.0000 21/122 [====>.........................] - ETA: 1s - loss: 35953928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8401 - distribution_lambda_loss: 35953928.0000 26/122 [=====>........................] - ETA: 0s - loss: 36047324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9028 - distribution_lambda_loss: 36047324.0000 31/122 [======>.......................] - ETA: 0s - loss: 36118404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9558 - distribution_lambda_loss: 36118404.0000 36/122 [=======>......................] - ETA: 0s - loss: 36044612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8663 - distribution_lambda_loss: 36044612.0000 41/122 [=========>....................] - ETA: 0s - loss: 35912832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8046 - distribution_lambda_loss: 35912832.0000 46/122 [==========>...................] - ETA: 0s - loss: 35957880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8348 - distribution_lambda_loss: 35957880.0000 51/122 [===========>..................] - ETA: 0s - loss: 36041816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8956 - distribution_lambda_loss: 36041816.0000 56/122 [============>.................] - ETA: 0s - loss: 36004160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8673 - distribution_lambda_loss: 36004160.0000 61/122 [==============>...............] - ETA: 0s - loss: 36008800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8605 - distribution_lambda_loss: 36008800.0000 66/122 [===============>..............] - ETA: 0s - loss: 36031332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8851 - distribution_lambda_loss: 36031332.0000 71/122 [================>.............] - ETA: 0s - loss: 36068644.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9096 - distribution_lambda_loss: 36068644.0000 76/122 [=================>............] - ETA: 0s - loss: 36098840.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9214 - distribution_lambda_loss: 36098840.0000 81/122 [==================>...........] - ETA: 0s - loss: 36153244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9553 - distribution_lambda_loss: 36153244.0000 86/122 [====================>.........] - ETA: 0s - loss: 36185268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9700 - distribution_lambda_loss: 36185268.0000 91/122 [=====================>........] - ETA: 0s - loss: 36186068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9600 - distribution_lambda_loss: 36186068.0000 96/122 [======================>.......] - ETA: 0s - loss: 36174460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9549 - distribution_lambda_loss: 36174460.0000101/122 [=======================>......] - ETA: 0s - loss: 36130068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9369 - distribution_lambda_loss: 36130068.0000106/122 [=========================>....] - ETA: 0s - loss: 36052320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8896 - distribution_lambda_loss: 36052320.0000111/122 [==========================>...] - ETA: 0s - loss: 36038892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8847 - distribution_lambda_loss: 36038892.0000116/122 [===========================>..] - ETA: 0s - loss: 36058572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8888 - distribution_lambda_loss: 36058572.0000121/122 [============================>.] - ETA: 0s - loss: 36054964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8863 - distribution_lambda_loss: 36054964.0000122/122 [==============================] - 1s 11ms/step - loss: 36054024.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8849 - distribution_lambda_loss: 36054024.0000 - val_loss: 38646100.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 53.2423 - val_distribution_lambda_loss: 38646100.0000 - lr: 5.0000e-04
Epoch 38/50
  1/122 [..............................] - ETA: 1s - loss: 36394556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 52.0130 - distribution_lambda_loss: 36394556.0000  6/122 [>.............................] - ETA: 1s - loss: 35735816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8092 - distribution_lambda_loss: 35735816.0000 11/122 [=>............................] - ETA: 1s - loss: 36174564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0091 - distribution_lambda_loss: 36174564.0000 16/122 [==>...........................] - ETA: 1s - loss: 36245624.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0347 - distribution_lambda_loss: 36245624.0000 21/122 [====>.........................] - ETA: 1s - loss: 36096712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.9385 - distribution_lambda_loss: 36096712.0000 26/122 [=====>........................] - ETA: 0s - loss: 35915824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7952 - distribution_lambda_loss: 35915824.0000 31/122 [======>.......................] - ETA: 0s - loss: 35899600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7920 - distribution_lambda_loss: 35899600.0000 36/122 [=======>......................] - ETA: 0s - loss: 36040476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8792 - distribution_lambda_loss: 36040476.0000 41/122 [=========>....................] - ETA: 0s - loss: 35986628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8467 - distribution_lambda_loss: 35986628.0000 46/122 [==========>...................] - ETA: 0s - loss: 35997460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8466 - distribution_lambda_loss: 35997460.0000 51/122 [===========>..................] - ETA: 0s - loss: 35929740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8192 - distribution_lambda_loss: 35929740.0000 56/122 [============>.................] - ETA: 0s - loss: 35849096.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7624 - distribution_lambda_loss: 35849096.0000 61/122 [==============>...............] - ETA: 0s - loss: 35780040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7061 - distribution_lambda_loss: 35780040.0000 66/122 [===============>..............] - ETA: 0s - loss: 35759876.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6881 - distribution_lambda_loss: 35759876.0000 71/122 [================>.............] - ETA: 0s - loss: 35758004.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6870 - distribution_lambda_loss: 35758004.0000 76/122 [=================>............] - ETA: 0s - loss: 35788532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7130 - distribution_lambda_loss: 35788532.0000 81/122 [==================>...........] - ETA: 0s - loss: 35806464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7161 - distribution_lambda_loss: 35806464.0000 86/122 [====================>.........] - ETA: 0s - loss: 35833232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7317 - distribution_lambda_loss: 35833232.0000 91/122 [=====================>........] - ETA: 0s - loss: 35838564.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7328 - distribution_lambda_loss: 35838564.0000 96/122 [======================>.......] - ETA: 0s - loss: 35868712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7525 - distribution_lambda_loss: 35868712.0000101/122 [=======================>......] - ETA: 0s - loss: 35899368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7717 - distribution_lambda_loss: 35899368.0000106/122 [=========================>....] - ETA: 0s - loss: 35903232.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7805 - distribution_lambda_loss: 35903232.0000111/122 [==========================>...] - ETA: 0s - loss: 35932072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7944 - distribution_lambda_loss: 35932072.0000116/122 [===========================>..] - ETA: 0s - loss: 35915736.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7857 - distribution_lambda_loss: 35915736.0000121/122 [============================>.] - ETA: 0s - loss: 35893980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7771 - distribution_lambda_loss: 35893980.0000122/122 [==============================] - 1s 11ms/step - loss: 35906816.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7817 - distribution_lambda_loss: 35906816.0000 - val_loss: 37970988.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.6775 - val_distribution_lambda_loss: 37970988.0000 - lr: 5.0000e-04
Epoch 39/50
  1/122 [..............................] - ETA: 1s - loss: 33912872.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4898 - distribution_lambda_loss: 33912872.0000  6/122 [>.............................] - ETA: 1s - loss: 34951368.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.3124 - distribution_lambda_loss: 34951368.0000 11/122 [=>............................] - ETA: 1s - loss: 35259948.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5266 - distribution_lambda_loss: 35259948.0000 16/122 [==>...........................] - ETA: 1s - loss: 35757896.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7961 - distribution_lambda_loss: 35757896.0000 21/122 [====>.........................] - ETA: 1s - loss: 35681352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7180 - distribution_lambda_loss: 35681352.0000 26/122 [=====>........................] - ETA: 0s - loss: 35714824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7163 - distribution_lambda_loss: 35714824.0000 31/122 [======>.......................] - ETA: 0s - loss: 35725056.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7179 - distribution_lambda_loss: 35725056.0000 36/122 [=======>......................] - ETA: 0s - loss: 35719648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6925 - distribution_lambda_loss: 35719648.0000 41/122 [=========>....................] - ETA: 0s - loss: 35867008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7834 - distribution_lambda_loss: 35867008.0000 46/122 [==========>...................] - ETA: 0s - loss: 35939204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8221 - distribution_lambda_loss: 35939204.0000 51/122 [===========>..................] - ETA: 0s - loss: 35866544.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7670 - distribution_lambda_loss: 35866544.0000 56/122 [============>.................] - ETA: 0s - loss: 35830200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7490 - distribution_lambda_loss: 35830200.0000 61/122 [==============>...............] - ETA: 0s - loss: 35839720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7461 - distribution_lambda_loss: 35839720.0000 66/122 [===============>..............] - ETA: 0s - loss: 35878348.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7705 - distribution_lambda_loss: 35878348.0000 71/122 [================>.............] - ETA: 0s - loss: 35941732.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8090 - distribution_lambda_loss: 35941732.0000 76/122 [=================>............] - ETA: 0s - loss: 35908156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7875 - distribution_lambda_loss: 35908156.0000 81/122 [==================>...........] - ETA: 0s - loss: 35817708.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7242 - distribution_lambda_loss: 35817708.0000 86/122 [====================>.........] - ETA: 0s - loss: 35853992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7550 - distribution_lambda_loss: 35853992.0000 91/122 [=====================>........] - ETA: 0s - loss: 35860932.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7641 - distribution_lambda_loss: 35860932.0000 96/122 [======================>.......] - ETA: 0s - loss: 35870264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7699 - distribution_lambda_loss: 35870264.0000101/122 [=======================>......] - ETA: 0s - loss: 35846584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7504 - distribution_lambda_loss: 35846584.0000106/122 [=========================>....] - ETA: 0s - loss: 35805120.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7150 - distribution_lambda_loss: 35805120.0000111/122 [==========================>...] - ETA: 0s - loss: 35818940.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7221 - distribution_lambda_loss: 35818940.0000116/122 [===========================>..] - ETA: 0s - loss: 35806280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7138 - distribution_lambda_loss: 35806280.0000121/122 [============================>.] - ETA: 0s - loss: 35821060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7259 - distribution_lambda_loss: 35821060.0000122/122 [==============================] - 1s 11ms/step - loss: 35808408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.7127 - distribution_lambda_loss: 35808408.0000 - val_loss: 37628476.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.4794 - val_distribution_lambda_loss: 37628476.0000 - lr: 5.0000e-04
Epoch 40/50
  1/122 [..............................] - ETA: 1s - loss: 33335326.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0519 - distribution_lambda_loss: 33335326.0000  6/122 [>.............................] - ETA: 1s - loss: 34964092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1503 - distribution_lambda_loss: 34964092.0000 11/122 [=>............................] - ETA: 1s - loss: 35517772.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4917 - distribution_lambda_loss: 35517772.0000 16/122 [==>...........................] - ETA: 1s - loss: 35521072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5780 - distribution_lambda_loss: 35521072.0000 21/122 [====>.........................] - ETA: 1s - loss: 35586260.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5588 - distribution_lambda_loss: 35586260.0000 26/122 [=====>........................] - ETA: 1s - loss: 35700812.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6497 - distribution_lambda_loss: 35700812.0000 31/122 [======>.......................] - ETA: 0s - loss: 35557332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4932 - distribution_lambda_loss: 35557332.0000 36/122 [=======>......................] - ETA: 0s - loss: 35528648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4721 - distribution_lambda_loss: 35528648.0000 41/122 [=========>....................] - ETA: 0s - loss: 35525936.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4909 - distribution_lambda_loss: 35525936.0000 46/122 [==========>...................] - ETA: 0s - loss: 35585212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5479 - distribution_lambda_loss: 35585212.0000 51/122 [===========>..................] - ETA: 0s - loss: 35566820.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5334 - distribution_lambda_loss: 35566820.0000 56/122 [============>.................] - ETA: 0s - loss: 35578468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5498 - distribution_lambda_loss: 35578468.0000 61/122 [==============>...............] - ETA: 0s - loss: 35497584.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5088 - distribution_lambda_loss: 35497584.0000 66/122 [===============>..............] - ETA: 0s - loss: 35465104.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4841 - distribution_lambda_loss: 35465104.0000 71/122 [================>.............] - ETA: 0s - loss: 35460556.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4784 - distribution_lambda_loss: 35460556.0000 76/122 [=================>............] - ETA: 0s - loss: 35426500.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4486 - distribution_lambda_loss: 35426500.0000 81/122 [==================>...........] - ETA: 0s - loss: 35450696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4504 - distribution_lambda_loss: 35450696.0000 86/122 [====================>.........] - ETA: 0s - loss: 35413568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4054 - distribution_lambda_loss: 35413568.0000 91/122 [=====================>........] - ETA: 0s - loss: 35493492.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4691 - distribution_lambda_loss: 35493492.0000 96/122 [======================>.......] - ETA: 0s - loss: 35545980.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5020 - distribution_lambda_loss: 35545980.0000101/122 [=======================>......] - ETA: 0s - loss: 35544908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5137 - distribution_lambda_loss: 35544908.0000106/122 [=========================>....] - ETA: 0s - loss: 35587128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5478 - distribution_lambda_loss: 35587128.0000111/122 [==========================>...] - ETA: 0s - loss: 35582692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5476 - distribution_lambda_loss: 35582692.0000116/122 [===========================>..] - ETA: 0s - loss: 35623912.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5666 - distribution_lambda_loss: 35623912.0000121/122 [============================>.] - ETA: 0s - loss: 35651276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5812 - distribution_lambda_loss: 35651276.0000122/122 [==============================] - 1s 11ms/step - loss: 35656060.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5881 - distribution_lambda_loss: 35656060.0000 - val_loss: 38101848.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2059 - val_distribution_lambda_loss: 38101848.0000 - lr: 5.0000e-04
Epoch 41/50
  1/122 [..............................] - ETA: 1s - loss: 36206576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2542 - distribution_lambda_loss: 36206576.0000  6/122 [>.............................] - ETA: 1s - loss: 35398444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.2820 - distribution_lambda_loss: 35398444.0000 11/122 [=>............................] - ETA: 1s - loss: 36115612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6836 - distribution_lambda_loss: 36115612.0000 16/122 [==>...........................] - ETA: 1s - loss: 35996280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6918 - distribution_lambda_loss: 35996280.0000 21/122 [====>.........................] - ETA: 1s - loss: 35766984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5373 - distribution_lambda_loss: 35766984.0000 26/122 [=====>........................] - ETA: 0s - loss: 35836288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6114 - distribution_lambda_loss: 35836288.0000 31/122 [======>.......................] - ETA: 0s - loss: 35770236.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6150 - distribution_lambda_loss: 35770236.0000 36/122 [=======>......................] - ETA: 0s - loss: 35697156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5823 - distribution_lambda_loss: 35697156.0000 41/122 [=========>....................] - ETA: 0s - loss: 35734860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5791 - distribution_lambda_loss: 35734860.0000 46/122 [==========>...................] - ETA: 0s - loss: 35613600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5255 - distribution_lambda_loss: 35613600.0000 51/122 [===========>..................] - ETA: 0s - loss: 35555800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4822 - distribution_lambda_loss: 35555800.0000 56/122 [============>.................] - ETA: 0s - loss: 35599636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5163 - distribution_lambda_loss: 35599636.0000 61/122 [==============>...............] - ETA: 0s - loss: 35600288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5057 - distribution_lambda_loss: 35600288.0000 66/122 [===============>..............] - ETA: 0s - loss: 35580632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4835 - distribution_lambda_loss: 35580632.0000 71/122 [================>.............] - ETA: 0s - loss: 35665464.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5574 - distribution_lambda_loss: 35665464.0000 76/122 [=================>............] - ETA: 0s - loss: 35641424.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5509 - distribution_lambda_loss: 35641424.0000 81/122 [==================>...........] - ETA: 0s - loss: 35629960.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5559 - distribution_lambda_loss: 35629960.0000 86/122 [====================>.........] - ETA: 0s - loss: 35614372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5493 - distribution_lambda_loss: 35614372.0000 91/122 [=====================>........] - ETA: 0s - loss: 35642712.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5644 - distribution_lambda_loss: 35642712.0000 96/122 [======================>.......] - ETA: 0s - loss: 35628268.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5605 - distribution_lambda_loss: 35628268.0000101/122 [=======================>......] - ETA: 0s - loss: 35580800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5322 - distribution_lambda_loss: 35580800.0000106/122 [=========================>....] - ETA: 0s - loss: 35578440.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5185 - distribution_lambda_loss: 35578440.0000111/122 [==========================>...] - ETA: 0s - loss: 35539052.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.4964 - distribution_lambda_loss: 35539052.0000116/122 [===========================>..] - ETA: 0s - loss: 35573448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5202 - distribution_lambda_loss: 35573448.0000121/122 [============================>.] - ETA: 0s - loss: 35585700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5355 - distribution_lambda_loss: 35585700.0000
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 35581188.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.5314 - distribution_lambda_loss: 35581188.0000 - val_loss: 38584120.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.3329 - val_distribution_lambda_loss: 38584120.0000 - lr: 5.0000e-04
Epoch 42/50
  1/122 [..............................] - ETA: 1s - loss: 36401552.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7611 - distribution_lambda_loss: 36401552.0000  6/122 [>.............................] - ETA: 1s - loss: 35824964.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.6456 - distribution_lambda_loss: 35824964.0000 11/122 [=>............................] - ETA: 1s - loss: 35003444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0779 - distribution_lambda_loss: 35003444.0000 16/122 [==>...........................] - ETA: 1s - loss: 34983148.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0120 - distribution_lambda_loss: 34983148.0000 21/122 [====>.........................] - ETA: 1s - loss: 34887628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9337 - distribution_lambda_loss: 34887628.0000 26/122 [=====>........................] - ETA: 0s - loss: 34868504.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9954 - distribution_lambda_loss: 34868504.0000 31/122 [======>.......................] - ETA: 0s - loss: 34764568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9568 - distribution_lambda_loss: 34764568.0000 36/122 [=======>......................] - ETA: 0s - loss: 34793928.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9251 - distribution_lambda_loss: 34793928.0000 41/122 [=========>....................] - ETA: 0s - loss: 34805892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9675 - distribution_lambda_loss: 34805892.0000 46/122 [==========>...................] - ETA: 0s - loss: 34783884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9528 - distribution_lambda_loss: 34783884.0000 51/122 [===========>..................] - ETA: 0s - loss: 34821476.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9856 - distribution_lambda_loss: 34821476.0000 56/122 [============>.................] - ETA: 0s - loss: 34774292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9441 - distribution_lambda_loss: 34774292.0000 61/122 [==============>...............] - ETA: 0s - loss: 34745660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9344 - distribution_lambda_loss: 34745660.0000 66/122 [===============>..............] - ETA: 0s - loss: 34723280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9320 - distribution_lambda_loss: 34723280.0000 71/122 [================>.............] - ETA: 0s - loss: 34748160.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9565 - distribution_lambda_loss: 34748160.0000 76/122 [=================>............] - ETA: 0s - loss: 34740576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9275 - distribution_lambda_loss: 34740576.0000 81/122 [==================>...........] - ETA: 0s - loss: 34750396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9314 - distribution_lambda_loss: 34750396.0000 86/122 [====================>.........] - ETA: 0s - loss: 34725704.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9269 - distribution_lambda_loss: 34725704.0000 91/122 [=====================>........] - ETA: 0s - loss: 34728300.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9324 - distribution_lambda_loss: 34728300.0000 96/122 [======================>.......] - ETA: 0s - loss: 34716216.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9251 - distribution_lambda_loss: 34716216.0000101/122 [=======================>......] - ETA: 0s - loss: 34688428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9001 - distribution_lambda_loss: 34688428.0000106/122 [=========================>....] - ETA: 0s - loss: 34682860.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8928 - distribution_lambda_loss: 34682860.0000111/122 [==========================>...] - ETA: 0s - loss: 34641728.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8646 - distribution_lambda_loss: 34641728.0000116/122 [===========================>..] - ETA: 0s - loss: 34616604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8543 - distribution_lambda_loss: 34616604.0000121/122 [============================>.] - ETA: 0s - loss: 34655068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8788 - distribution_lambda_loss: 34655068.0000122/122 [==============================] - 1s 11ms/step - loss: 34665632.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8866 - distribution_lambda_loss: 34665632.0000 - val_loss: 36810104.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2493 - val_distribution_lambda_loss: 36810104.0000 - lr: 2.5000e-04
Epoch 43/50
  1/122 [..............................] - ETA: 1s - loss: 36424888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.0541 - distribution_lambda_loss: 36424888.0000  6/122 [>.............................] - ETA: 1s - loss: 34289668.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5485 - distribution_lambda_loss: 34289668.0000 11/122 [=>............................] - ETA: 1s - loss: 34318652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5812 - distribution_lambda_loss: 34318652.0000 16/122 [==>...........................] - ETA: 1s - loss: 34607808.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7866 - distribution_lambda_loss: 34607808.0000 21/122 [====>.........................] - ETA: 1s - loss: 34566176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8048 - distribution_lambda_loss: 34566176.0000 26/122 [=====>........................] - ETA: 1s - loss: 34770200.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9263 - distribution_lambda_loss: 34770200.0000 31/122 [======>.......................] - ETA: 0s - loss: 34762116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8958 - distribution_lambda_loss: 34762116.0000 36/122 [=======>......................] - ETA: 0s - loss: 34803468.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9720 - distribution_lambda_loss: 34803468.0000 41/122 [=========>....................] - ETA: 0s - loss: 34807304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.0001 - distribution_lambda_loss: 34807304.0000 46/122 [==========>...................] - ETA: 0s - loss: 34731304.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9155 - distribution_lambda_loss: 34731304.0000 51/122 [===========>..................] - ETA: 0s - loss: 34719040.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9066 - distribution_lambda_loss: 34719040.0000 56/122 [============>.................] - ETA: 0s - loss: 34685224.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8983 - distribution_lambda_loss: 34685224.0000 61/122 [==============>...............] - ETA: 0s - loss: 34676204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9086 - distribution_lambda_loss: 34676204.0000 66/122 [===============>..............] - ETA: 0s - loss: 34589248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8374 - distribution_lambda_loss: 34589248.0000 71/122 [================>.............] - ETA: 0s - loss: 34593124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8379 - distribution_lambda_loss: 34593124.0000 76/122 [=================>............] - ETA: 0s - loss: 34616092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8611 - distribution_lambda_loss: 34616092.0000 81/122 [==================>...........] - ETA: 0s - loss: 34683888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9138 - distribution_lambda_loss: 34683888.0000 86/122 [====================>.........] - ETA: 0s - loss: 34627868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8643 - distribution_lambda_loss: 34627868.0000 91/122 [=====================>........] - ETA: 0s - loss: 34640768.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8751 - distribution_lambda_loss: 34640768.0000 96/122 [======================>.......] - ETA: 0s - loss: 34649196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8876 - distribution_lambda_loss: 34649196.0000101/122 [=======================>......] - ETA: 0s - loss: 34645384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8776 - distribution_lambda_loss: 34645384.0000106/122 [=========================>....] - ETA: 0s - loss: 34676336.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8947 - distribution_lambda_loss: 34676336.0000111/122 [==========================>...] - ETA: 0s - loss: 34659316.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8828 - distribution_lambda_loss: 34659316.0000116/122 [===========================>..] - ETA: 0s - loss: 34638048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8726 - distribution_lambda_loss: 34638048.0000121/122 [============================>.] - ETA: 0s - loss: 34611412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8616 - distribution_lambda_loss: 34611412.0000122/122 [==============================] - 1s 11ms/step - loss: 34614080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8622 - distribution_lambda_loss: 34614080.0000 - val_loss: 36694112.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.8450 - val_distribution_lambda_loss: 36694112.0000 - lr: 2.5000e-04
Epoch 44/50
  1/122 [..............................] - ETA: 1s - loss: 35253432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.1400 - distribution_lambda_loss: 35253432.0000  6/122 [>.............................] - ETA: 1s - loss: 34202908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5269 - distribution_lambda_loss: 34202908.0000 11/122 [=>............................] - ETA: 1s - loss: 34533848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7356 - distribution_lambda_loss: 34533848.0000 16/122 [==>...........................] - ETA: 1s - loss: 34282920.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5452 - distribution_lambda_loss: 34282920.0000 21/122 [====>.........................] - ETA: 1s - loss: 34255852.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5760 - distribution_lambda_loss: 34255852.0000 26/122 [=====>........................] - ETA: 0s - loss: 34372836.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6896 - distribution_lambda_loss: 34372836.0000 31/122 [======>.......................] - ETA: 0s - loss: 34375412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6796 - distribution_lambda_loss: 34375412.0000 36/122 [=======>......................] - ETA: 0s - loss: 34354128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6723 - distribution_lambda_loss: 34354128.0000 41/122 [=========>....................] - ETA: 0s - loss: 34308656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6441 - distribution_lambda_loss: 34308656.0000 46/122 [==========>...................] - ETA: 0s - loss: 34295176.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6035 - distribution_lambda_loss: 34295176.0000 51/122 [===========>..................] - ETA: 0s - loss: 34259740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5947 - distribution_lambda_loss: 34259740.0000 56/122 [============>.................] - ETA: 0s - loss: 34267692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6130 - distribution_lambda_loss: 34267692.0000 61/122 [==============>...............] - ETA: 0s - loss: 34334612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6585 - distribution_lambda_loss: 34334612.0000 66/122 [===============>..............] - ETA: 0s - loss: 34358600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6624 - distribution_lambda_loss: 34358600.0000 71/122 [================>.............] - ETA: 0s - loss: 34303628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6337 - distribution_lambda_loss: 34303628.0000 76/122 [=================>............] - ETA: 0s - loss: 34305612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6384 - distribution_lambda_loss: 34305612.0000 81/122 [==================>...........] - ETA: 0s - loss: 34318824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6410 - distribution_lambda_loss: 34318824.0000 86/122 [====================>.........] - ETA: 0s - loss: 34320892.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6511 - distribution_lambda_loss: 34320892.0000 91/122 [=====================>........] - ETA: 0s - loss: 34311196.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6349 - distribution_lambda_loss: 34311196.0000 96/122 [======================>.......] - ETA: 0s - loss: 34379308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6927 - distribution_lambda_loss: 34379308.0000101/122 [=======================>......] - ETA: 0s - loss: 34416028.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7169 - distribution_lambda_loss: 34416028.0000106/122 [=========================>....] - ETA: 0s - loss: 34418284.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7121 - distribution_lambda_loss: 34418284.0000111/122 [==========================>...] - ETA: 0s - loss: 34408360.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7039 - distribution_lambda_loss: 34408360.0000116/122 [===========================>..] - ETA: 0s - loss: 34440792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7376 - distribution_lambda_loss: 34440792.0000121/122 [============================>.] - ETA: 0s - loss: 34427700.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7156 - distribution_lambda_loss: 34427700.0000122/122 [==============================] - 1s 11ms/step - loss: 34441408.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7282 - distribution_lambda_loss: 34441408.0000 - val_loss: 36712524.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2464 - val_distribution_lambda_loss: 36712524.0000 - lr: 2.5000e-04
Epoch 45/50
  1/122 [..............................] - ETA: 1s - loss: 35456136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 50.8011 - distribution_lambda_loss: 35456136.0000  6/122 [>.............................] - ETA: 1s - loss: 34455916.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8147 - distribution_lambda_loss: 34455916.0000 11/122 [=>............................] - ETA: 1s - loss: 34146448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4804 - distribution_lambda_loss: 34146448.0000 16/122 [==>...........................] - ETA: 1s - loss: 34059428.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4651 - distribution_lambda_loss: 34059428.0000 21/122 [====>.........................] - ETA: 1s - loss: 34026448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4599 - distribution_lambda_loss: 34026448.0000 26/122 [=====>........................] - ETA: 0s - loss: 34024532.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4481 - distribution_lambda_loss: 34024532.0000 31/122 [======>.......................] - ETA: 0s - loss: 34136652.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5319 - distribution_lambda_loss: 34136652.0000 36/122 [=======>......................] - ETA: 0s - loss: 34234072.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6102 - distribution_lambda_loss: 34234072.0000 41/122 [=========>....................] - ETA: 0s - loss: 34362128.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6856 - distribution_lambda_loss: 34362128.0000 46/122 [==========>...................] - ETA: 0s - loss: 34289720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6297 - distribution_lambda_loss: 34289720.0000 51/122 [===========>..................] - ETA: 0s - loss: 34206144.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5955 - distribution_lambda_loss: 34206144.0000 56/122 [============>.................] - ETA: 0s - loss: 34181264.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5661 - distribution_lambda_loss: 34181264.0000 61/122 [==============>...............] - ETA: 0s - loss: 34198068.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5677 - distribution_lambda_loss: 34198068.0000 66/122 [===============>..............] - ETA: 0s - loss: 34234688.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5811 - distribution_lambda_loss: 34234688.0000 71/122 [================>.............] - ETA: 0s - loss: 34256580.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5955 - distribution_lambda_loss: 34256580.0000 76/122 [=================>............] - ETA: 0s - loss: 34235048.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5882 - distribution_lambda_loss: 34235048.0000 81/122 [==================>...........] - ETA: 0s - loss: 34229116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5790 - distribution_lambda_loss: 34229116.0000 86/122 [====================>.........] - ETA: 0s - loss: 34264924.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5959 - distribution_lambda_loss: 34264924.0000 91/122 [=====================>........] - ETA: 0s - loss: 34337132.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6486 - distribution_lambda_loss: 34337132.0000 96/122 [======================>.......] - ETA: 0s - loss: 34352484.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6539 - distribution_lambda_loss: 34352484.0000101/122 [=======================>......] - ETA: 0s - loss: 34359488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6624 - distribution_lambda_loss: 34359488.0000106/122 [=========================>....] - ETA: 0s - loss: 34372164.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6799 - distribution_lambda_loss: 34372164.0000111/122 [==========================>...] - ETA: 0s - loss: 34376888.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6862 - distribution_lambda_loss: 34376888.0000116/122 [===========================>..] - ETA: 0s - loss: 34363656.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6742 - distribution_lambda_loss: 34363656.0000121/122 [============================>.] - ETA: 0s - loss: 34370460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6815 - distribution_lambda_loss: 34370460.0000122/122 [==============================] - 1s 11ms/step - loss: 34365324.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6828 - distribution_lambda_loss: 34365324.0000 - val_loss: 36686148.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2628 - val_distribution_lambda_loss: 36686148.0000 - lr: 2.5000e-04
Epoch 46/50
  1/122 [..............................] - ETA: 1s - loss: 32704716.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3496 - distribution_lambda_loss: 32704716.0000  6/122 [>.............................] - ETA: 1s - loss: 34653412.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8989 - distribution_lambda_loss: 34653412.0000 11/122 [=>............................] - ETA: 1s - loss: 34307536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5115 - distribution_lambda_loss: 34307536.0000 16/122 [==>...........................] - ETA: 1s - loss: 34280904.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5151 - distribution_lambda_loss: 34280904.0000 21/122 [====>.........................] - ETA: 1s - loss: 34423540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6642 - distribution_lambda_loss: 34423540.0000 26/122 [=====>........................] - ETA: 0s - loss: 34257372.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5819 - distribution_lambda_loss: 34257372.0000 31/122 [======>.......................] - ETA: 0s - loss: 34469396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7340 - distribution_lambda_loss: 34469396.0000 36/122 [=======>......................] - ETA: 0s - loss: 34425720.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6998 - distribution_lambda_loss: 34425720.0000 41/122 [=========>....................] - ETA: 0s - loss: 34394972.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6869 - distribution_lambda_loss: 34394972.0000 46/122 [==========>...................] - ETA: 0s - loss: 34488616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7389 - distribution_lambda_loss: 34488616.0000 51/122 [===========>..................] - ETA: 0s - loss: 34499744.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7557 - distribution_lambda_loss: 34499744.0000 56/122 [============>.................] - ETA: 0s - loss: 34608244.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8369 - distribution_lambda_loss: 34608244.0000 61/122 [==============>...............] - ETA: 0s - loss: 34644636.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8855 - distribution_lambda_loss: 34644636.0000 66/122 [===============>..............] - ETA: 0s - loss: 34701288.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9181 - distribution_lambda_loss: 34701288.0000 71/122 [================>.............] - ETA: 0s - loss: 34711092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9150 - distribution_lambda_loss: 34711092.0000 76/122 [=================>............] - ETA: 0s - loss: 34680608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9016 - distribution_lambda_loss: 34680608.0000 81/122 [==================>...........] - ETA: 0s - loss: 34637276.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8827 - distribution_lambda_loss: 34637276.0000 86/122 [====================>.........] - ETA: 0s - loss: 34578884.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8418 - distribution_lambda_loss: 34578884.0000 91/122 [=====================>........] - ETA: 0s - loss: 34492764.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7817 - distribution_lambda_loss: 34492764.0000 96/122 [======================>.......] - ETA: 0s - loss: 34485124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7780 - distribution_lambda_loss: 34485124.0000101/122 [=======================>......] - ETA: 0s - loss: 34486868.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7717 - distribution_lambda_loss: 34486868.0000106/122 [=========================>....] - ETA: 0s - loss: 34501092.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7831 - distribution_lambda_loss: 34501092.0000111/122 [==========================>...] - ETA: 0s - loss: 34450296.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7445 - distribution_lambda_loss: 34450296.0000116/122 [===========================>..] - ETA: 0s - loss: 34416116.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7145 - distribution_lambda_loss: 34416116.0000121/122 [============================>.] - ETA: 0s - loss: 34424620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7277 - distribution_lambda_loss: 34424620.0000122/122 [==============================] - 1s 11ms/step - loss: 34425696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7280 - distribution_lambda_loss: 34425696.0000 - val_loss: 36536936.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 51.2362 - val_distribution_lambda_loss: 36536936.0000 - lr: 2.5000e-04
Epoch 47/50
  1/122 [..............................] - ETA: 1s - loss: 33856520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3533 - distribution_lambda_loss: 33856520.0000  6/122 [>.............................] - ETA: 1s - loss: 34191588.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6979 - distribution_lambda_loss: 34191588.0000 11/122 [=>............................] - ETA: 1s - loss: 34548804.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9640 - distribution_lambda_loss: 34548804.0000 16/122 [==>...........................] - ETA: 1s - loss: 34502204.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9294 - distribution_lambda_loss: 34502204.0000 21/122 [====>.........................] - ETA: 1s - loss: 34301956.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7551 - distribution_lambda_loss: 34301956.0000 26/122 [=====>........................] - ETA: 1s - loss: 34435280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8248 - distribution_lambda_loss: 34435280.0000 31/122 [======>.......................] - ETA: 0s - loss: 34461076.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8149 - distribution_lambda_loss: 34461076.0000 36/122 [=======>......................] - ETA: 0s - loss: 34476948.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8382 - distribution_lambda_loss: 34476948.0000 41/122 [=========>....................] - ETA: 0s - loss: 34419384.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7618 - distribution_lambda_loss: 34419384.0000 46/122 [==========>...................] - ETA: 0s - loss: 34360180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7240 - distribution_lambda_loss: 34360180.0000 51/122 [===========>..................] - ETA: 0s - loss: 34365908.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7512 - distribution_lambda_loss: 34365908.0000 56/122 [============>.................] - ETA: 0s - loss: 34367640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7483 - distribution_lambda_loss: 34367640.0000 61/122 [==============>...............] - ETA: 0s - loss: 34343180.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7097 - distribution_lambda_loss: 34343180.0000 66/122 [===============>..............] - ETA: 0s - loss: 34235352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6228 - distribution_lambda_loss: 34235352.0000 71/122 [================>.............] - ETA: 0s - loss: 34243648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6243 - distribution_lambda_loss: 34243648.0000 76/122 [=================>............] - ETA: 0s - loss: 34270660.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6444 - distribution_lambda_loss: 34270660.0000 81/122 [==================>...........] - ETA: 0s - loss: 34307152.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6734 - distribution_lambda_loss: 34307152.0000 86/122 [====================>.........] - ETA: 0s - loss: 34272832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6430 - distribution_lambda_loss: 34272832.0000 91/122 [=====================>........] - ETA: 0s - loss: 34302968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6457 - distribution_lambda_loss: 34302968.0000 96/122 [======================>.......] - ETA: 0s - loss: 34246280.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6138 - distribution_lambda_loss: 34246280.0000101/122 [=======================>......] - ETA: 0s - loss: 34240392.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6082 - distribution_lambda_loss: 34240392.0000106/122 [=========================>....] - ETA: 0s - loss: 34211740.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5852 - distribution_lambda_loss: 34211740.0000111/122 [==========================>...] - ETA: 0s - loss: 34275800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6378 - distribution_lambda_loss: 34275800.0000116/122 [===========================>..] - ETA: 0s - loss: 34304800.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6547 - distribution_lambda_loss: 34304800.0000121/122 [============================>.] - ETA: 0s - loss: 34345560.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6757 - distribution_lambda_loss: 34345560.0000122/122 [==============================] - 1s 11ms/step - loss: 34355256.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6798 - distribution_lambda_loss: 34355256.0000 - val_loss: 37741308.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.9566 - val_distribution_lambda_loss: 37741308.0000 - lr: 2.5000e-04
Epoch 48/50
  1/122 [..............................] - ETA: 1s - loss: 35314208.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 51.8030 - distribution_lambda_loss: 35314208.0000  6/122 [>.............................] - ETA: 1s - loss: 34160452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5849 - distribution_lambda_loss: 34160452.0000 11/122 [=>............................] - ETA: 1s - loss: 34598620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.8381 - distribution_lambda_loss: 34598620.0000 16/122 [==>...........................] - ETA: 1s - loss: 34735568.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9940 - distribution_lambda_loss: 34735568.0000 21/122 [====>.........................] - ETA: 1s - loss: 34748596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9805 - distribution_lambda_loss: 34748596.0000 26/122 [=====>........................] - ETA: 0s - loss: 34701968.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.9734 - distribution_lambda_loss: 34701968.0000 31/122 [======>.......................] - ETA: 0s - loss: 34396404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7696 - distribution_lambda_loss: 34396404.0000 36/122 [=======>......................] - ETA: 0s - loss: 34356672.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.7051 - distribution_lambda_loss: 34356672.0000 41/122 [=========>....................] - ETA: 0s - loss: 34234332.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6170 - distribution_lambda_loss: 34234332.0000 46/122 [==========>...................] - ETA: 0s - loss: 34137608.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5606 - distribution_lambda_loss: 34137608.0000 51/122 [===========>..................] - ETA: 0s - loss: 34209620.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6105 - distribution_lambda_loss: 34209620.0000 56/122 [============>.................] - ETA: 0s - loss: 34263404.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6632 - distribution_lambda_loss: 34263404.0000 61/122 [==============>...............] - ETA: 0s - loss: 34249136.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6422 - distribution_lambda_loss: 34249136.0000 66/122 [===============>..............] - ETA: 0s - loss: 34220352.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6146 - distribution_lambda_loss: 34220352.0000 71/122 [================>.............] - ETA: 0s - loss: 34237008.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.6210 - distribution_lambda_loss: 34237008.0000 76/122 [=================>............] - ETA: 0s - loss: 34193460.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5861 - distribution_lambda_loss: 34193460.0000 81/122 [==================>...........] - ETA: 0s - loss: 34131628.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5408 - distribution_lambda_loss: 34131628.0000 86/122 [====================>.........] - ETA: 0s - loss: 34108016.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5185 - distribution_lambda_loss: 34108016.0000 91/122 [=====================>........] - ETA: 0s - loss: 34111396.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5135 - distribution_lambda_loss: 34111396.0000 96/122 [======================>.......] - ETA: 0s - loss: 34119600.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5253 - distribution_lambda_loss: 34119600.0000101/122 [=======================>......] - ETA: 0s - loss: 34117724.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5271 - distribution_lambda_loss: 34117724.0000106/122 [=========================>....] - ETA: 0s - loss: 34127320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5343 - distribution_lambda_loss: 34127320.0000111/122 [==========================>...] - ETA: 0s - loss: 34171400.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5611 - distribution_lambda_loss: 34171400.0000116/122 [===========================>..] - ETA: 0s - loss: 34169676.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5592 - distribution_lambda_loss: 34169676.0000121/122 [============================>.] - ETA: 0s - loss: 34191788.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5769 - distribution_lambda_loss: 34191788.0000122/122 [==============================] - 1s 11ms/step - loss: 34177604.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5666 - distribution_lambda_loss: 34177604.0000 - val_loss: 36400060.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.8877 - val_distribution_lambda_loss: 36400060.0000 - lr: 2.5000e-04
Epoch 49/50
  1/122 [..............................] - ETA: 1s - loss: 33777248.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2207 - distribution_lambda_loss: 33777248.0000  6/122 [>.............................] - ETA: 1s - loss: 33111202.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 48.8088 - distribution_lambda_loss: 33111202.0000 11/122 [=>............................] - ETA: 1s - loss: 33402778.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0339 - distribution_lambda_loss: 33402778.0000 16/122 [==>...........................] - ETA: 1s - loss: 33656616.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2162 - distribution_lambda_loss: 33656616.0000 21/122 [====>.........................] - ETA: 1s - loss: 33652192.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2232 - distribution_lambda_loss: 33652192.0000 26/122 [=====>........................] - ETA: 0s - loss: 33644596.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1883 - distribution_lambda_loss: 33644596.0000 31/122 [======>.......................] - ETA: 0s - loss: 33614308.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1658 - distribution_lambda_loss: 33614308.0000 36/122 [=======>......................] - ETA: 0s - loss: 33502030.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0961 - distribution_lambda_loss: 33502030.0000 41/122 [=========>....................] - ETA: 0s - loss: 33489432.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.0975 - distribution_lambda_loss: 33489432.0000 46/122 [==========>...................] - ETA: 0s - loss: 33645612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2147 - distribution_lambda_loss: 33645612.0000 51/122 [===========>..................] - ETA: 0s - loss: 33674088.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2242 - distribution_lambda_loss: 33674088.0000 56/122 [============>.................] - ETA: 0s - loss: 33762292.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2795 - distribution_lambda_loss: 33762292.0000 61/122 [==============>...............] - ETA: 0s - loss: 33787592.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2644 - distribution_lambda_loss: 33787592.0000 66/122 [===============>..............] - ETA: 0s - loss: 33891156.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3473 - distribution_lambda_loss: 33891156.0000 71/122 [================>.............] - ETA: 0s - loss: 33975692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3969 - distribution_lambda_loss: 33975692.0000 76/122 [=================>............] - ETA: 0s - loss: 34048340.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4663 - distribution_lambda_loss: 34048340.0000 81/122 [==================>...........] - ETA: 0s - loss: 34164448.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5338 - distribution_lambda_loss: 34164448.0000 86/122 [====================>.........] - ETA: 0s - loss: 34147124.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5178 - distribution_lambda_loss: 34147124.0000 91/122 [=====================>........] - ETA: 0s - loss: 34156540.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5273 - distribution_lambda_loss: 34156540.0000 96/122 [======================>.......] - ETA: 0s - loss: 34144320.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5141 - distribution_lambda_loss: 34144320.0000101/122 [=======================>......] - ETA: 0s - loss: 34084108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4718 - distribution_lambda_loss: 34084108.0000106/122 [=========================>....] - ETA: 0s - loss: 34096212.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4768 - distribution_lambda_loss: 34096212.0000111/122 [==========================>...] - ETA: 0s - loss: 34084848.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4746 - distribution_lambda_loss: 34084848.0000116/122 [===========================>..] - ETA: 0s - loss: 34083696.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4766 - distribution_lambda_loss: 34083696.0000121/122 [============================>.] - ETA: 0s - loss: 34117692.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5004 - distribution_lambda_loss: 34117692.0000122/122 [==============================] - 1s 11ms/step - loss: 34115572.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.5006 - distribution_lambda_loss: 34115572.0000 - val_loss: 36575392.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 50.2645 - val_distribution_lambda_loss: 36575392.0000 - lr: 2.5000e-04
Epoch 50/50
  1/122 [..............................] - ETA: 1s - loss: 32280902.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 47.8086 - distribution_lambda_loss: 32280902.0000  6/122 [>.............................] - ETA: 1s - loss: 33537050.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1058 - distribution_lambda_loss: 33537050.0000 11/122 [=>............................] - ETA: 1s - loss: 33641880.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1581 - distribution_lambda_loss: 33641880.0000 16/122 [==>...........................] - ETA: 1s - loss: 33642536.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1288 - distribution_lambda_loss: 33642536.0000 21/122 [====>.........................] - ETA: 1s - loss: 33831356.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2563 - distribution_lambda_loss: 33831356.0000 26/122 [=====>........................] - ETA: 0s - loss: 33681792.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1116 - distribution_lambda_loss: 33681792.0000 31/122 [======>.......................] - ETA: 0s - loss: 33805080.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2052 - distribution_lambda_loss: 33805080.0000 36/122 [=======>......................] - ETA: 0s - loss: 33866576.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2842 - distribution_lambda_loss: 33866576.0000 41/122 [=========>....................] - ETA: 0s - loss: 33876416.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2916 - distribution_lambda_loss: 33876416.0000 46/122 [==========>...................] - ETA: 0s - loss: 33715824.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1827 - distribution_lambda_loss: 33715824.0000 51/122 [===========>..................] - ETA: 0s - loss: 33664488.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1581 - distribution_lambda_loss: 33664488.0000 56/122 [============>.................] - ETA: 0s - loss: 33682364.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1888 - distribution_lambda_loss: 33682364.0000 61/122 [==============>...............] - ETA: 0s - loss: 33667648.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.1861 - distribution_lambda_loss: 33667648.0000 66/122 [===============>..............] - ETA: 0s - loss: 33748520.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2397 - distribution_lambda_loss: 33748520.0000 71/122 [================>.............] - ETA: 0s - loss: 33799444.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2658 - distribution_lambda_loss: 33799444.0000 76/122 [=================>............] - ETA: 0s - loss: 33833776.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.2894 - distribution_lambda_loss: 33833776.0000 81/122 [==================>...........] - ETA: 0s - loss: 33886228.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3215 - distribution_lambda_loss: 33886228.0000 86/122 [====================>.........] - ETA: 0s - loss: 33903992.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3303 - distribution_lambda_loss: 33903992.0000 91/122 [=====================>........] - ETA: 0s - loss: 33944640.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3560 - distribution_lambda_loss: 33944640.0000 96/122 [======================>.......] - ETA: 0s - loss: 33965108.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3761 - distribution_lambda_loss: 33965108.0000101/122 [=======================>......] - ETA: 0s - loss: 33997452.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.3941 - distribution_lambda_loss: 33997452.0000106/122 [=========================>....] - ETA: 0s - loss: 34038524.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4308 - distribution_lambda_loss: 34038524.0000111/122 [==========================>...] - ETA: 0s - loss: 34015832.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4197 - distribution_lambda_loss: 34015832.0000116/122 [===========================>..] - ETA: 0s - loss: 34027036.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4155 - distribution_lambda_loss: 34027036.0000121/122 [============================>.] - ETA: 0s - loss: 34031612.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4120 - distribution_lambda_loss: 34031612.0000
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
122/122 [==============================] - 1s 11ms/step - loss: 34040984.0000 - trimmed_obj_loss: 0.0000e+00 - tf.math.multiply_2_loss: 49.4179 - distribution_lambda_loss: 34040984.0000 - val_loss: 37256108.0000 - val_trimmed_obj_loss: 0.0000e+00 - val_tf.math.multiply_2_loss: 52.4545 - val_distribution_lambda_loss: 37256108.0000 - lr: 2.5000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.05078768+0.03908647j]
  [-0.00147524+0.02986646j]
  [-0.04124447-0.02018933j]
  ...
  [ 0.02548227+0.01806978j]
  [ 0.04268315+0.0188654j ]
  [ 0.04516761+0.01956229j]]

 [[ 0.0220891 -0.01188079j]
  [ 0.03835767+0.03358509j]
  [-0.00142893+0.02197503j]
  ...
  [-0.01391465-0.00432523j]
  [ 0.03996065+0.03697475j]
  [ 0.02918082+0.03941054j]]

 [[ 0.02744894-0.00778296j]
  [-0.02554526+0.00479967j]
  [-0.01781248-0.02643128j]
  ...
  [-0.03899888+0.05420399j]
  [-0.02644318+0.00979219j]
  [ 0.03697952-0.08437678j]]

 ...

 [[-0.03238868-0.01856977j]
  [ 0.04393906+0.0009207j ]
  [-0.0523303 +0.16835369j]
  ...
  [ 0.07663022+0.06388126j]
  [-0.10884623+0.05475416j]
  [-0.09921163-0.09906429j]]

 [[-0.00452902-0.01962221j]
  [-0.03836754+0.03825318j]
  [-0.0233613 +0.0739998j ]
  ...
  [ 0.0232537 +0.04757752j]
  [-0.06083298-0.04434002j]
  [-0.0041243 -0.0299162j ]]

 [[ 0.02184559+0.02220817j]
  [-0.04714252-0.0093401j ]
  [-0.01891536-0.00193338j]
  ...
  [-0.10183024-0.00715991j]
  [ 0.0541427 -0.08391279j]
  [ 0.03675748+0.03997286j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
  1/322 [..............................] - ETA: 9:31  5/322 [..............................] - ETA: 5s    8/322 [..............................] - ETA: 5s 12/322 [>.............................] - ETA: 5s 16/322 [>.............................] - ETA: 4s 19/322 [>.............................] - ETA: 4s 22/322 [=>............................] - ETA: 5s 26/322 [=>............................] - ETA: 4s 30/322 [=>............................] - ETA: 4s 34/322 [==>...........................] - ETA: 4s 38/322 [==>...........................] - ETA: 4s 42/322 [==>...........................] - ETA: 4s 46/322 [===>..........................] - ETA: 4s 49/322 [===>..........................] - ETA: 4s 52/322 [===>..........................] - ETA: 4s 56/322 [====>.........................] - ETA: 4s 59/322 [====>.........................] - ETA: 4s 63/322 [====>.........................] - ETA: 4s 67/322 [=====>........................] - ETA: 4s 70/322 [=====>........................] - ETA: 4s 74/322 [=====>........................] - ETA: 4s 77/322 [======>.......................] - ETA: 4s 81/322 [======>.......................] - ETA: 3s 84/322 [======>.......................] - ETA: 3s 88/322 [=======>......................] - ETA: 3s 91/322 [=======>......................] - ETA: 3s 94/322 [=======>......................] - ETA: 3s 98/322 [========>.....................] - ETA: 3s102/322 [========>.....................] - ETA: 3s105/322 [========>.....................] - ETA: 3s109/322 [=========>....................] - ETA: 3s113/322 [=========>....................] - ETA: 3s116/322 [=========>....................] - ETA: 3s119/322 [==========>...................] - ETA: 3s122/322 [==========>...................] - ETA: 3s126/322 [==========>...................] - ETA: 3s130/322 [===========>..................] - ETA: 3s133/322 [===========>..................] - ETA: 3s137/322 [===========>..................] - ETA: 3s140/322 [============>.................] - ETA: 3s144/322 [============>.................] - ETA: 2s148/322 [============>.................] - ETA: 2s152/322 [=============>................] - ETA: 2s156/322 [=============>................] - ETA: 2s160/322 [=============>................] - ETA: 2s164/322 [==============>...............] - ETA: 2s168/322 [==============>...............] - ETA: 2s172/322 [===============>..............] - ETA: 2s176/322 [===============>..............] - ETA: 2s179/322 [===============>..............] - ETA: 2s182/322 [===============>..............] - ETA: 2s186/322 [================>.............] - ETA: 2s190/322 [================>.............] - ETA: 2s193/322 [================>.............] - ETA: 2s196/322 [=================>............] - ETA: 2s200/322 [=================>............] - ETA: 2s204/322 [==================>...........] - ETA: 1s208/322 [==================>...........] - ETA: 1s212/322 [==================>...........] - ETA: 1s216/322 [===================>..........] - ETA: 1s220/322 [===================>..........] - ETA: 1s224/322 [===================>..........] - ETA: 1s228/322 [====================>.........] - ETA: 1s231/322 [====================>.........] - ETA: 1s235/322 [====================>.........] - ETA: 1s238/322 [=====================>........] - ETA: 1s242/322 [=====================>........] - ETA: 1s246/322 [=====================>........] - ETA: 1s250/322 [======================>.......] - ETA: 1s254/322 [======================>.......] - ETA: 1s258/322 [=======================>......] - ETA: 1s262/322 [=======================>......] - ETA: 0s266/322 [=======================>......] - ETA: 0s270/322 [========================>.....] - ETA: 0s274/322 [========================>.....] - ETA: 0s278/322 [========================>.....] - ETA: 0s282/322 [=========================>....] - ETA: 0s286/322 [=========================>....] - ETA: 0s290/322 [==========================>...] - ETA: 0s294/322 [==========================>...] - ETA: 0s297/322 [==========================>...] - ETA: 0s300/322 [==========================>...] - ETA: 0s303/322 [===========================>..] - ETA: 0s307/322 [===========================>..] - ETA: 0s310/322 [===========================>..] - ETA: 0s314/322 [============================>.] - ETA: 0s318/322 [============================>.] - ETA: 0s322/322 [==============================] - ETA: 0s322/322 [==============================] - 7s 16ms/step
Object stitching failed: cannot reshape array of size 42205184 into shape (58,58,64,64,1)
cannot reshape array of size 42205184 into shape (58,58,64,64,1)
2025-07-27 21:29:00,872 - INFO - Skipping image stitching (disabled or no test data available)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
input shape (None, 64, 64, 1)
2025-07-27 21:29:03,932 - INFO - Assets written to: /tmp/tmpzbetjh2e/autoencoder/assets
2025-07-27 21:29:03,980 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-07-27 21:29:05,620 - INFO - Assets written to: /tmp/tmpzbetjh2e/diffraction_to_obj/assets
2025-07-27 21:29:06,684 - INFO - Outputs saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run
[2025-07-27 21:29:07] SUCCESS: PtychoPINN training (n_images=2048, trial=3)
[2025-07-27 21:29:07] EXECUTING: Baseline training (n_images=2048, trial=3)
[2025-07-27 21:29:07] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'datasets/fly64/fly64_bottom_half_shuffled.npz' \
            --test_data 'datasets/fly64/fly64_shuffled.npz' \
            --n_images 2048 \
            --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run' \
            --nepochs 50
2025-07-27 21:29:08.054060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:29:08.054090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:29:08.054923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:29:08.059053: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:29:08.520033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:29:09.331041: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.364745: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.366963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:29:09.625672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.627973: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.630036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.747220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.748503: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.749682: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:29:09.749819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:29:09.751197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:29:10,028 - INFO - Configuration setup complete
2025-07-27 21:29:10,028 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly64/fly64_bottom_half_shuffled.npz'), test_data_file=PosixPath('datasets/fly64/fly64_shuffled.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=2048, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run'))
2025-07-27 21:29:10,028 - INFO -  Validated model_type = 'supervised' for baseline training
2025-07-27 21:29:10,028 - INFO - --- Starting Supervised Baseline Run ---
2025-07-27 21:29:10,028 - INFO - Results will be saved to: 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1/
2025-07-27 21:29:10,028 - INFO - 
[1/6] Initializing probe...
2025-07-27 21:29:10,042 - INFO - 
[2/6] Loading data...
2025-07-27 21:29:10,042 - INFO - Loading from .npz files: datasets/fly64/fly64_bottom_half_shuffled.npz
2025-07-27 21:29:10,042 - INFO - Loading data from datasets/fly64/fly64_bottom_half_shuffled.npz with n_images=2048
2025-07-27 21:29:10,075 - INFO - Using sequential slicing for gridsize=1: selecting first 2048 images
2025-07-27 21:29:10,075 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=None
2025-07-27 21:29:10,148 - INFO - Using sequential slicing for gridsize=1: selecting first 10304 images
2025-07-27 21:29:30,340 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-07-27 21:29:30,340 - INFO - 
[3/6] Shaping data for the baseline model...
2025-07-27 21:29:30,342 - INFO - Final training input shape: (2048, 64, 64, 1)
2025-07-27 21:29:30,342 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-07-27 21:29:30,342 - INFO - Training with 2048 images
DEBUG: Setting timestamp to 07/27/2025, 21:29:10 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 2048
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly64/fly64_shuffled.npz
timestamp: 07/27/2025, 21:29:10
train_data_file_path: datasets/fly64/fly64_bottom_half_shuffled.npz
tv_weight: 0.0
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (2048, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2048,)
objectGuess shape: (232, 232)
xcoords shape: (2048,)
ycoords shape: (2048,)
xcoords_start shape: (2048,)
ycoords_start shape: (2048,)
diff3d shape: (10304, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10304,)
objectGuess shape: (232, 232)
xcoords shape: (10304,)
ycoords shape: (10304,)
xcoords_start shape: (10304,)
ycoords_start shape: (10304,)
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (2048, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(2048, 64, 64, 1) Y_I=(2048, 64, 64, 1) Y_phi=(2048, 64, 64, 1) norm_Y_I=() coords_nominal=(2048, 1, 2, 1) coords_true=(2048, 1, 2, 1) nn_indices=(2048, 1) mean=1023.500 global_offsets=(2048, 1, 2, 1) mean=95.258 local_offsets=(2048, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: nsamples: 2048 (gridsize=1, using legacy sequential sampling)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10304, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 64, 64, 1)]          0         []                            
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['input_1[0][0]']             
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
 D)                                                                                               
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
 g2D)                                                                                             
                                                                                                  
 conv2d_6 (Conv2D)           (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_13 (Conv2D)          (None, 8, 8, 256)            590080    ['max_pooling2d_2[0][0]']     
                                                                                                  
 conv2d_7 (Conv2D)           (None, 8, 8, 256)            590080    ['conv2d_6[0][0]']            
                                                                                                  
 conv2d_14 (Conv2D)          (None, 8, 8, 256)            590080    ['conv2d_13[0][0]']           
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            
 D)                                                                                               
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 256)          0         ['conv2d_14[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_8 (Conv2D)           (None, 16, 16, 128)          295040    ['up_sampling2d[0][0]']       
                                                                                                  
 conv2d_15 (Conv2D)          (None, 16, 16, 128)          295040    ['up_sampling2d_3[0][0]']     
                                                                                                  
 conv2d_9 (Conv2D)           (None, 16, 16, 128)          147584    ['conv2d_8[0][0]']            
                                                                                                  
 conv2d_16 (Conv2D)          (None, 16, 16, 128)          147584    ['conv2d_15[0][0]']           
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_9[0][0]']            
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 128)          0         ['conv2d_16[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_10 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_1[0][0]']     
                                                                                                  
 conv2d_17 (Conv2D)          (None, 32, 32, 64)           73792     ['up_sampling2d_4[0][0]']     
                                                                                                  
 conv2d_11 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_10[0][0]']           
                                                                                                  
 conv2d_18 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_17[0][0]']           
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_11[0][0]']           
 g2D)                                                                                             
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_18[0][0]']           
 g2D)                                                                                             
                                                                                                  
 conv2d_12 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
                                                                                                  
 conv2d_19 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
                                                                                                  
==================================================================================================
Total params: 4612418 (17.59 MB)
Trainable params: 4612418 (17.59 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
None
Training with 50 epochs and batch size 16
Epoch 1/50
2025-07-27 21:29:31.745304: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
2025-07-27 21:29:32.532054: I external/local_xla/xla/service/service.cc:168] XLA service 0x70acac3864b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-07-27 21:29:32.532077: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-07-27 21:29:32.535724: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1753676972.599103 3735797 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
  1/122 [..............................] - ETA: 9:00 - loss: 3.5802 - conv2d_12_loss: 1.2299 - conv2d_19_loss: 2.3504  6/122 [>.............................] - ETA: 1s - loss: 5.1371 - conv2d_12_loss: 1.1480 - conv2d_19_loss: 3.9891   11/122 [=>............................] - ETA: 1s - loss: 4.3628 - conv2d_12_loss: 1.1433 - conv2d_19_loss: 3.2195 16/122 [==>...........................] - ETA: 1s - loss: 3.8900 - conv2d_12_loss: 0.9862 - conv2d_19_loss: 2.9038 21/122 [====>.........................] - ETA: 1s - loss: 3.4525 - conv2d_12_loss: 0.8288 - conv2d_19_loss: 2.6237 26/122 [=====>........................] - ETA: 1s - loss: 2.9918 - conv2d_12_loss: 0.7180 - conv2d_19_loss: 2.2738 31/122 [======>.......................] - ETA: 0s - loss: 2.6463 - conv2d_12_loss: 0.6375 - conv2d_19_loss: 2.0088 36/122 [=======>......................] - ETA: 0s - loss: 2.3802 - conv2d_12_loss: 0.5761 - conv2d_19_loss: 1.8041 41/122 [=========>....................] - ETA: 0s - loss: 2.1713 - conv2d_12_loss: 0.5278 - conv2d_19_loss: 1.6435 46/122 [==========>...................] - ETA: 0s - loss: 2.0027 - conv2d_12_loss: 0.4882 - conv2d_19_loss: 1.5145 51/122 [===========>..................] - ETA: 0s - loss: 1.8632 - conv2d_12_loss: 0.4552 - conv2d_19_loss: 1.4080 56/122 [============>.................] - ETA: 0s - loss: 1.7453 - conv2d_12_loss: 0.4271 - conv2d_19_loss: 1.3182 61/122 [==============>...............] - ETA: 0s - loss: 1.6431 - conv2d_12_loss: 0.4028 - conv2d_19_loss: 1.2403 66/122 [===============>..............] - ETA: 0s - loss: 1.5532 - conv2d_12_loss: 0.3816 - conv2d_19_loss: 1.1716 71/122 [================>.............] - ETA: 0s - loss: 1.4742 - conv2d_12_loss: 0.3630 - conv2d_19_loss: 1.1112 76/122 [=================>............] - ETA: 0s - loss: 1.4041 - conv2d_12_loss: 0.3466 - conv2d_19_loss: 1.0576 81/122 [==================>...........] - ETA: 0s - loss: 1.3422 - conv2d_12_loss: 0.3319 - conv2d_19_loss: 1.0102 86/122 [====================>.........] - ETA: 0s - loss: 1.2871 - conv2d_12_loss: 0.3188 - conv2d_19_loss: 0.9683 91/122 [=====================>........] - ETA: 0s - loss: 1.2374 - conv2d_12_loss: 0.3069 - conv2d_19_loss: 0.9306 96/122 [======================>.......] - ETA: 0s - loss: 1.1924 - conv2d_12_loss: 0.2960 - conv2d_19_loss: 0.8964101/122 [=======================>......] - ETA: 0s - loss: 1.1514 - conv2d_12_loss: 0.2861 - conv2d_19_loss: 0.8654106/122 [=========================>....] - ETA: 0s - loss: 1.1137 - conv2d_12_loss: 0.2768 - conv2d_19_loss: 0.8369111/122 [==========================>...] - ETA: 0s - loss: 1.0793 - conv2d_12_loss: 0.2684 - conv2d_19_loss: 0.8110116/122 [===========================>..] - ETA: 0s - loss: 1.0474 - conv2d_12_loss: 0.2605 - conv2d_19_loss: 0.7869121/122 [============================>.] - ETA: 0s - loss: 1.0180 - conv2d_12_loss: 0.2533 - conv2d_19_loss: 0.7646122/122 [==============================] - ETA: 0s - loss: 1.0148 - conv2d_12_loss: 0.2525 - conv2d_19_loss: 0.7622122/122 [==============================] - 8s 27ms/step - loss: 1.0148 - conv2d_12_loss: 0.2525 - conv2d_19_loss: 0.7622 - val_loss: 0.3355 - val_conv2d_12_loss: 0.0861 - val_conv2d_19_loss: 0.2494 - lr: 0.0010
Epoch 2/50
  1/122 [..............................] - ETA: 1s - loss: 0.3169 - conv2d_12_loss: 0.0824 - conv2d_19_loss: 0.2345  6/122 [>.............................] - ETA: 1s - loss: 0.3306 - conv2d_12_loss: 0.0870 - conv2d_19_loss: 0.2436 11/122 [=>............................] - ETA: 1s - loss: 0.3297 - conv2d_12_loss: 0.0880 - conv2d_19_loss: 0.2417 16/122 [==>...........................] - ETA: 1s - loss: 0.3305 - conv2d_12_loss: 0.0885 - conv2d_19_loss: 0.2420 21/122 [====>.........................] - ETA: 1s - loss: 0.3269 - conv2d_12_loss: 0.0878 - conv2d_19_loss: 0.2390 26/122 [=====>........................] - ETA: 0s - loss: 0.3248 - conv2d_12_loss: 0.0874 - conv2d_19_loss: 0.2374 31/122 [======>.......................] - ETA: 0s - loss: 0.3238 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.2363 36/122 [=======>......................] - ETA: 0s - loss: 0.3225 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2350 41/122 [=========>....................] - ETA: 0s - loss: 0.3223 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.2348 46/122 [==========>...................] - ETA: 0s - loss: 0.3222 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2346 51/122 [===========>..................] - ETA: 0s - loss: 0.3221 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2345 56/122 [============>.................] - ETA: 0s - loss: 0.3213 - conv2d_12_loss: 0.0874 - conv2d_19_loss: 0.2339 61/122 [==============>...............] - ETA: 0s - loss: 0.3214 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.2339 66/122 [===============>..............] - ETA: 0s - loss: 0.3204 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2332 71/122 [================>.............] - ETA: 0s - loss: 0.3199 - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2327 76/122 [=================>............] - ETA: 0s - loss: 0.3192 - conv2d_12_loss: 0.0870 - conv2d_19_loss: 0.2322 81/122 [==================>...........] - ETA: 0s - loss: 0.3189 - conv2d_12_loss: 0.0869 - conv2d_19_loss: 0.2320 86/122 [====================>.........] - ETA: 0s - loss: 0.3187 - conv2d_12_loss: 0.0869 - conv2d_19_loss: 0.2318 91/122 [=====================>........] - ETA: 0s - loss: 0.3182 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2315 96/122 [======================>.......] - ETA: 0s - loss: 0.3182 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2315101/122 [=======================>......] - ETA: 0s - loss: 0.3180 - conv2d_12_loss: 0.0867 - conv2d_19_loss: 0.2314106/122 [=========================>....] - ETA: 0s - loss: 0.3180 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2314111/122 [==========================>...] - ETA: 0s - loss: 0.3177 - conv2d_12_loss: 0.0866 - conv2d_19_loss: 0.2311116/122 [===========================>..] - ETA: 0s - loss: 0.3173 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2308121/122 [============================>.] - ETA: 0s - loss: 0.3170 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2305122/122 [==============================] - 1s 11ms/step - loss: 0.3169 - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2305 - val_loss: 0.3130 - val_conv2d_12_loss: 0.0856 - val_conv2d_19_loss: 0.2273 - lr: 0.0010
Epoch 3/50
  1/122 [..............................] - ETA: 1s - loss: 0.3181 - conv2d_12_loss: 0.0886 - conv2d_19_loss: 0.2295  6/122 [>.............................] - ETA: 1s - loss: 0.3100 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2246 11/122 [=>............................] - ETA: 1s - loss: 0.3091 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2241 16/122 [==>...........................] - ETA: 1s - loss: 0.3093 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2245 21/122 [====>.........................] - ETA: 1s - loss: 0.3099 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 26/122 [=====>........................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 31/122 [======>.......................] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2254 36/122 [=======>......................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2263 41/122 [=========>....................] - ETA: 0s - loss: 0.3109 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2258 46/122 [==========>...................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2264 51/122 [===========>..................] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2270 56/122 [============>.................] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2263 61/122 [==============>...............] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2262 66/122 [===============>..............] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2265 71/122 [================>.............] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2268 76/122 [=================>............] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2268 81/122 [==================>...........] - ETA: 0s - loss: 0.3124 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2270 86/122 [====================>.........] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2269 91/122 [=====================>........] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2268 96/122 [======================>.......] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2269101/122 [=======================>......] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2267106/122 [=========================>....] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2265111/122 [==========================>...] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2265116/122 [===========================>..] - ETA: 0s - loss: 0.3120 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2266121/122 [============================>.] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2265122/122 [==============================] - 1s 11ms/step - loss: 0.3117 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2265 - val_loss: 0.3103 - val_conv2d_12_loss: 0.0842 - val_conv2d_19_loss: 0.2261 - lr: 0.0010
Epoch 4/50
  1/122 [..............................] - ETA: 1s - loss: 0.3006 - conv2d_12_loss: 0.0817 - conv2d_19_loss: 0.2189  6/122 [>.............................] - ETA: 1s - loss: 0.3113 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2265 11/122 [=>............................] - ETA: 1s - loss: 0.3147 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2291 16/122 [==>...........................] - ETA: 1s - loss: 0.3160 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2301 21/122 [====>.........................] - ETA: 1s - loss: 0.3169 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2307 26/122 [=====>........................] - ETA: 0s - loss: 0.3159 - conv2d_12_loss: 0.0860 - conv2d_19_loss: 0.2298 31/122 [======>.......................] - ETA: 0s - loss: 0.3140 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2284 36/122 [=======>......................] - ETA: 0s - loss: 0.3138 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2282 41/122 [=========>....................] - ETA: 0s - loss: 0.3129 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2275 46/122 [==========>...................] - ETA: 0s - loss: 0.3129 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2275 51/122 [===========>..................] - ETA: 0s - loss: 0.3127 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2274 56/122 [============>.................] - ETA: 0s - loss: 0.3132 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2278 61/122 [==============>...............] - ETA: 0s - loss: 0.3123 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2270 66/122 [===============>..............] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2268 71/122 [================>.............] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2265 76/122 [=================>............] - ETA: 0s - loss: 0.3126 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2268 81/122 [==================>...........] - ETA: 0s - loss: 0.3131 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2268 86/122 [====================>.........] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2266 91/122 [=====================>........] - ETA: 0s - loss: 0.3142 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2267 96/122 [======================>.......] - ETA: 0s - loss: 0.3141 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2264101/122 [=======================>......] - ETA: 0s - loss: 0.3142 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2264106/122 [=========================>....] - ETA: 0s - loss: 0.3141 - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2264111/122 [==========================>...] - ETA: 0s - loss: 0.3139 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2263116/122 [===========================>..] - ETA: 0s - loss: 0.3137 - conv2d_12_loss: 0.0875 - conv2d_19_loss: 0.2262121/122 [============================>.] - ETA: 0s - loss: 0.3135 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2262122/122 [==============================] - 1s 11ms/step - loss: 0.3135 - conv2d_12_loss: 0.0873 - conv2d_19_loss: 0.2262 - val_loss: 0.3113 - val_conv2d_12_loss: 0.0847 - val_conv2d_19_loss: 0.2266 - lr: 0.0010
Epoch 5/50
  1/122 [..............................] - ETA: 1s - loss: 0.3158 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2304  6/122 [>.............................] - ETA: 1s - loss: 0.3063 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2222 11/122 [=>............................] - ETA: 1s - loss: 0.3079 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2234 16/122 [==>...........................] - ETA: 1s - loss: 0.3099 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2251 21/122 [====>.........................] - ETA: 1s - loss: 0.3093 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2246 26/122 [=====>........................] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2247 31/122 [======>.......................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2257 36/122 [=======>......................] - ETA: 0s - loss: 0.3108 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2258 41/122 [=========>....................] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2261 46/122 [==========>...................] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2267 51/122 [===========>..................] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2265 56/122 [============>.................] - ETA: 0s - loss: 0.3120 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2266 61/122 [==============>...............] - ETA: 0s - loss: 0.3123 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2269 66/122 [===============>..............] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2270 71/122 [================>.............] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2267 76/122 [=================>............] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2264 81/122 [==================>...........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2263 86/122 [====================>.........] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2262 91/122 [=====================>........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2262 96/122 [======================>.......] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2263101/122 [=======================>......] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2263106/122 [=========================>....] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2264111/122 [==========================>...] - ETA: 0s - loss: 0.3119 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2265116/122 [===========================>..] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2264121/122 [============================>.] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2262
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
122/122 [==============================] - 1s 11ms/step - loss: 0.3114 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2261 - val_loss: 0.3103 - val_conv2d_12_loss: 0.0841 - val_conv2d_19_loss: 0.2262 - lr: 0.0010
Epoch 6/50
  1/122 [..............................] - ETA: 1s - loss: 0.3062 - conv2d_12_loss: 0.0828 - conv2d_19_loss: 0.2234  6/122 [>.............................] - ETA: 1s - loss: 0.3164 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2311 11/122 [=>............................] - ETA: 1s - loss: 0.3127 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2282 16/122 [==>...........................] - ETA: 1s - loss: 0.3118 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2274 21/122 [====>.........................] - ETA: 1s - loss: 0.3122 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2274 26/122 [=====>........................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2261 31/122 [======>.......................] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2264 36/122 [=======>......................] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2266 41/122 [=========>....................] - ETA: 0s - loss: 0.3109 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2261 46/122 [==========>...................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2267 51/122 [===========>..................] - ETA: 0s - loss: 0.3111 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2263 56/122 [============>.................] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257 61/122 [==============>...............] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2256 66/122 [===============>..............] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251 71/122 [================>.............] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253 76/122 [=================>............] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 81/122 [==================>...........] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 86/122 [====================>.........] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258 91/122 [=====================>........] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257 96/122 [======================>.......] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255101/122 [=======================>......] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258106/122 [=========================>....] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2258111/122 [==========================>...] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257116/122 [===========================>..] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254121/122 [============================>.] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254122/122 [==============================] - 1s 11ms/step - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 - val_loss: 0.3098 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2259 - lr: 5.0000e-04
Epoch 7/50
  1/122 [..............................] - ETA: 1s - loss: 0.3133 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2280  6/122 [>.............................] - ETA: 1s - loss: 0.3122 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2265 11/122 [=>............................] - ETA: 1s - loss: 0.3067 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2229 16/122 [==>...........................] - ETA: 1s - loss: 0.3052 - conv2d_12_loss: 0.0836 - conv2d_19_loss: 0.2216 21/122 [====>.........................] - ETA: 1s - loss: 0.3079 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2236 26/122 [=====>........................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 31/122 [======>.......................] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251 36/122 [=======>......................] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 41/122 [=========>....................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249 46/122 [==========>...................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249 51/122 [===========>..................] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2252 56/122 [============>.................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 61/122 [==============>...............] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 66/122 [===============>..............] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 71/122 [================>.............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2249 76/122 [=================>............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 81/122 [==================>...........] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 86/122 [====================>.........] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2257 91/122 [=====================>........] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258 96/122 [======================>.......] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2259101/122 [=======================>......] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2259106/122 [=========================>....] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254111/122 [==========================>...] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253116/122 [===========================>..] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2256121/122 [============================>.] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255122/122 [==============================] - 1s 11ms/step - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 - val_loss: 0.3098 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2260 - lr: 5.0000e-04
Epoch 8/50
  1/122 [..............................] - ETA: 1s - loss: 0.3239 - conv2d_12_loss: 0.0876 - conv2d_19_loss: 0.2363  6/122 [>.............................] - ETA: 1s - loss: 0.3166 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2307 11/122 [=>............................] - ETA: 1s - loss: 0.3172 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2311 16/122 [==>...........................] - ETA: 1s - loss: 0.3150 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2295 21/122 [====>.........................] - ETA: 1s - loss: 0.3163 - conv2d_12_loss: 0.0858 - conv2d_19_loss: 0.2304 26/122 [=====>........................] - ETA: 0s - loss: 0.3156 - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2297 31/122 [======>.......................] - ETA: 0s - loss: 0.3151 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2295 36/122 [=======>......................] - ETA: 0s - loss: 0.3145 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2290 41/122 [=========>....................] - ETA: 0s - loss: 0.3138 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2285 46/122 [==========>...................] - ETA: 0s - loss: 0.3134 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2281 51/122 [===========>..................] - ETA: 0s - loss: 0.3132 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2280 56/122 [============>.................] - ETA: 0s - loss: 0.3130 - conv2d_12_loss: 0.0852 - conv2d_19_loss: 0.2278 61/122 [==============>...............] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2273 66/122 [===============>..............] - ETA: 0s - loss: 0.3124 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2273 71/122 [================>.............] - ETA: 0s - loss: 0.3125 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2274 76/122 [=================>............] - ETA: 0s - loss: 0.3122 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2272 81/122 [==================>...........] - ETA: 0s - loss: 0.3117 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2268 86/122 [====================>.........] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2265 91/122 [=====================>........] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2264 96/122 [======================>.......] - ETA: 0s - loss: 0.3108 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2261101/122 [=======================>......] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2259106/122 [=========================>....] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2257111/122 [==========================>...] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2257116/122 [===========================>..] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2257121/122 [============================>.] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
122/122 [==============================] - 1s 11ms/step - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 - val_loss: 0.3106 - val_conv2d_12_loss: 0.0843 - val_conv2d_19_loss: 0.2263 - lr: 5.0000e-04
Epoch 9/50
  1/122 [..............................] - ETA: 1s - loss: 0.3088 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2243  6/122 [>.............................] - ETA: 1s - loss: 0.3161 - conv2d_12_loss: 0.0863 - conv2d_19_loss: 0.2298 11/122 [=>............................] - ETA: 1s - loss: 0.3128 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2275 16/122 [==>...........................] - ETA: 1s - loss: 0.3095 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2249 21/122 [====>.........................] - ETA: 1s - loss: 0.3097 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2250 26/122 [=====>........................] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2257 31/122 [======>.......................] - ETA: 0s - loss: 0.3112 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2261 36/122 [=======>......................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2253 41/122 [=========>....................] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 46/122 [==========>...................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2247 51/122 [===========>..................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2251 56/122 [============>.................] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2253 61/122 [==============>...............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2247 66/122 [===============>..............] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 71/122 [================>.............] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2249 76/122 [=================>............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2247 81/122 [==================>...........] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 86/122 [====================>.........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2249 91/122 [=====================>........] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 96/122 [======================>.......] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254101/122 [=======================>......] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254106/122 [=========================>....] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253111/122 [==========================>...] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2252116/122 [===========================>..] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2252121/122 [============================>.] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251122/122 [==============================] - 1s 11ms/step - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 - val_loss: 0.3095 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2257 - lr: 2.5000e-04
Epoch 10/50
  1/122 [..............................] - ETA: 1s - loss: 0.3174 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2314  6/122 [>.............................] - ETA: 1s - loss: 0.3081 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2241 11/122 [=>............................] - ETA: 1s - loss: 0.3096 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2250 16/122 [==>...........................] - ETA: 1s - loss: 0.3094 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2247 21/122 [====>.........................] - ETA: 1s - loss: 0.3088 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2243 26/122 [=====>........................] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 31/122 [======>.......................] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2245 36/122 [=======>......................] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2248 41/122 [=========>....................] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258 46/122 [==========>...................] - ETA: 0s - loss: 0.3107 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2259 51/122 [===========>..................] - ETA: 0s - loss: 0.3114 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2265 56/122 [============>.................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2265 61/122 [==============>...............] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2263 66/122 [===============>..............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 71/122 [================>.............] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2255 76/122 [=================>............] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2258 81/122 [==================>...........] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258 86/122 [====================>.........] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 91/122 [=====================>........] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258 96/122 [======================>.......] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2259101/122 [=======================>......] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258106/122 [=========================>....] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2256111/122 [==========================>...] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253116/122 [===========================>..] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251121/122 [============================>.] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252122/122 [==============================] - 1s 11ms/step - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 - val_loss: 0.3094 - val_conv2d_12_loss: 0.0839 - val_conv2d_19_loss: 0.2255 - lr: 2.5000e-04
Epoch 11/50
  1/122 [..............................] - ETA: 1s - loss: 0.3229 - conv2d_12_loss: 0.0883 - conv2d_19_loss: 0.2346  6/122 [>.............................] - ETA: 1s - loss: 0.3141 - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2285 11/122 [=>............................] - ETA: 1s - loss: 0.3142 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2287 16/122 [==>...........................] - ETA: 1s - loss: 0.3131 - conv2d_12_loss: 0.0855 - conv2d_19_loss: 0.2276 21/122 [====>.........................] - ETA: 1s - loss: 0.3121 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2268 26/122 [=====>........................] - ETA: 0s - loss: 0.3129 - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2276 31/122 [======>.......................] - ETA: 0s - loss: 0.3118 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2267 36/122 [=======>......................] - ETA: 0s - loss: 0.3121 - conv2d_12_loss: 0.0851 - conv2d_19_loss: 0.2270 41/122 [=========>....................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2265 46/122 [==========>...................] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2266 51/122 [===========>..................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2266 56/122 [============>.................] - ETA: 0s - loss: 0.3116 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2266 61/122 [==============>...............] - ETA: 0s - loss: 0.3113 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2264 66/122 [===============>..............] - ETA: 0s - loss: 0.3110 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2261 71/122 [================>.............] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2258 76/122 [=================>............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 81/122 [==================>...........] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 86/122 [====================>.........] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 91/122 [=====================>........] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 96/122 [======================>.......] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253101/122 [=======================>......] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253106/122 [=========================>....] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2256111/122 [==========================>...] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253116/122 [===========================>..] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254121/122 [============================>.] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255122/122 [==============================] - 1s 11ms/step - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 - val_loss: 0.3102 - val_conv2d_12_loss: 0.0846 - val_conv2d_19_loss: 0.2255 - lr: 2.5000e-04
Epoch 12/50
  1/122 [..............................] - ETA: 1s - loss: 0.2888 - conv2d_12_loss: 0.0805 - conv2d_19_loss: 0.2083  6/122 [>.............................] - ETA: 1s - loss: 0.3050 - conv2d_12_loss: 0.0831 - conv2d_19_loss: 0.2219 11/122 [=>............................] - ETA: 1s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 16/122 [==>...........................] - ETA: 1s - loss: 0.3084 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2243 21/122 [====>.........................] - ETA: 1s - loss: 0.3087 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2246 26/122 [=====>........................] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 31/122 [======>.......................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 36/122 [=======>......................] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2258 41/122 [=========>....................] - ETA: 0s - loss: 0.3115 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2266 46/122 [==========>...................] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257 51/122 [===========>..................] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254 56/122 [============>.................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 61/122 [==============>...............] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249 66/122 [===============>..............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 71/122 [================>.............] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253 76/122 [=================>............] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2256 81/122 [==================>...........] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 86/122 [====================>.........] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257 91/122 [=====================>........] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2258 96/122 [======================>.......] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2256101/122 [=======================>......] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258106/122 [=========================>....] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2258111/122 [==========================>...] - ETA: 0s - loss: 0.3104 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257116/122 [===========================>..] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253121/122 [============================>.] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2252
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
122/122 [==============================] - 1s 11ms/step - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 - val_loss: 0.3097 - val_conv2d_12_loss: 0.0843 - val_conv2d_19_loss: 0.2255 - lr: 2.5000e-04
Epoch 13/50
  1/122 [..............................] - ETA: 1s - loss: 0.2961 - conv2d_12_loss: 0.0804 - conv2d_19_loss: 0.2158  6/122 [>.............................] - ETA: 1s - loss: 0.3082 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2240 11/122 [=>............................] - ETA: 1s - loss: 0.3093 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249 16/122 [==>...........................] - ETA: 1s - loss: 0.3093 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2252 21/122 [====>.........................] - ETA: 1s - loss: 0.3088 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2247 26/122 [=====>........................] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2242 31/122 [======>.......................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2248 36/122 [=======>......................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 41/122 [=========>....................] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2257 46/122 [==========>...................] - ETA: 0s - loss: 0.3105 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2259 51/122 [===========>..................] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 56/122 [============>.................] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251 61/122 [==============>...............] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 66/122 [===============>..............] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 71/122 [================>.............] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 76/122 [=================>............] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 81/122 [==================>...........] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2242 86/122 [====================>.........] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 91/122 [=====================>........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 96/122 [======================>.......] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245101/122 [=======================>......] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245106/122 [=========================>....] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2246111/122 [==========================>...] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2248116/122 [===========================>..] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251 - val_loss: 0.3092 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2254 - lr: 1.2500e-04
Epoch 14/50
  1/122 [..............................] - ETA: 1s - loss: 0.3071 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2234  6/122 [>.............................] - ETA: 1s - loss: 0.3116 - conv2d_12_loss: 0.0854 - conv2d_19_loss: 0.2262 11/122 [=>............................] - ETA: 1s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254 16/122 [==>...........................] - ETA: 1s - loss: 0.3101 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2254 21/122 [====>.........................] - ETA: 1s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2250 26/122 [=====>........................] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2247 31/122 [======>.......................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2248 36/122 [=======>......................] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253 41/122 [=========>....................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 46/122 [==========>...................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253 51/122 [===========>..................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2247 56/122 [============>.................] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2249 61/122 [==============>...............] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 66/122 [===============>..............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2250 71/122 [================>.............] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2256 76/122 [=================>............] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253 81/122 [==================>...........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2247 86/122 [====================>.........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245 91/122 [=====================>........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2247 96/122 [======================>.......] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2250101/122 [=======================>......] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2248106/122 [=========================>....] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251111/122 [==========================>...] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2249116/122 [===========================>..] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251121/122 [============================>.] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3091 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2253 - lr: 1.2500e-04
Epoch 15/50
  1/122 [..............................] - ETA: 1s - loss: 0.3017 - conv2d_12_loss: 0.0830 - conv2d_19_loss: 0.2187  6/122 [>.............................] - ETA: 1s - loss: 0.3150 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2290 11/122 [=>............................] - ETA: 1s - loss: 0.3096 - conv2d_12_loss: 0.0849 - conv2d_19_loss: 0.2247 16/122 [==>...........................] - ETA: 1s - loss: 0.3083 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2238 21/122 [====>.........................] - ETA: 1s - loss: 0.3090 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2245 26/122 [=====>........................] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2252 31/122 [======>.......................] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2253 36/122 [=======>......................] - ETA: 0s - loss: 0.3106 - conv2d_12_loss: 0.0848 - conv2d_19_loss: 0.2257 41/122 [=========>....................] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 46/122 [==========>...................] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 51/122 [===========>..................] - ETA: 0s - loss: 0.3103 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2256 56/122 [============>.................] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253 61/122 [==============>...............] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253 66/122 [===============>..............] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2252 71/122 [================>.............] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 76/122 [=================>............] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 81/122 [==================>...........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 86/122 [====================>.........] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 91/122 [=====================>........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 96/122 [======================>.......] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249101/122 [=======================>......] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249106/122 [=========================>....] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245111/122 [==========================>...] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245116/122 [===========================>..] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251 - val_loss: 0.3094 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2257 - lr: 1.2500e-04
Epoch 16/50
  1/122 [..............................] - ETA: 1s - loss: 0.3194 - conv2d_12_loss: 0.0857 - conv2d_19_loss: 0.2337  6/122 [>.............................] - ETA: 1s - loss: 0.3068 - conv2d_12_loss: 0.0832 - conv2d_19_loss: 0.2236 11/122 [=>............................] - ETA: 1s - loss: 0.3068 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2228 16/122 [==>...........................] - ETA: 1s - loss: 0.3063 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2225 21/122 [====>.........................] - ETA: 1s - loss: 0.3075 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2233 26/122 [=====>........................] - ETA: 0s - loss: 0.3063 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2225 31/122 [======>.......................] - ETA: 0s - loss: 0.3069 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2229 36/122 [=======>......................] - ETA: 0s - loss: 0.3075 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2235 41/122 [=========>....................] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2239 46/122 [==========>...................] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2239 51/122 [===========>..................] - ETA: 0s - loss: 0.3080 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2239 56/122 [============>.................] - ETA: 0s - loss: 0.3073 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2234 61/122 [==============>...............] - ETA: 0s - loss: 0.3078 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2237 66/122 [===============>..............] - ETA: 0s - loss: 0.3084 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2242 71/122 [================>.............] - ETA: 0s - loss: 0.3081 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2241 76/122 [=================>............] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2243 81/122 [==================>...........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2245 86/122 [====================>.........] - ETA: 0s - loss: 0.3087 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245 91/122 [=====================>........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245 96/122 [======================>.......] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247101/122 [=======================>......] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249106/122 [=========================>....] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250111/122 [==========================>...] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249116/122 [===========================>..] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001.
122/122 [==============================] - 1s 11ms/step - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3091 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2254 - lr: 1.2500e-04
Epoch 17/50
  1/122 [..............................] - ETA: 1s - loss: 0.2951 - conv2d_12_loss: 0.0804 - conv2d_19_loss: 0.2147  6/122 [>.............................] - ETA: 1s - loss: 0.3035 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2192 11/122 [=>............................] - ETA: 1s - loss: 0.3069 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2224 16/122 [==>...........................] - ETA: 1s - loss: 0.3078 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2233 21/122 [====>.........................] - ETA: 1s - loss: 0.3078 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2236 26/122 [=====>........................] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2243 31/122 [======>.......................] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 36/122 [=======>......................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249 41/122 [=========>....................] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2247 46/122 [==========>...................] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251 51/122 [===========>..................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249 56/122 [============>.................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249 61/122 [==============>...............] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253 66/122 [===============>..............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 71/122 [================>.............] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 76/122 [=================>............] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2254 81/122 [==================>...........] - ETA: 0s - loss: 0.3102 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2256 86/122 [====================>.........] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 91/122 [=====================>........] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2252 96/122 [======================>.......] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249101/122 [=======================>......] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2249106/122 [=========================>....] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251111/122 [==========================>...] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253116/122 [===========================>..] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3095 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2258 - lr: 1.0000e-04
Epoch 18/50
  1/122 [..............................] - ETA: 1s - loss: 0.3199 - conv2d_12_loss: 0.0861 - conv2d_19_loss: 0.2338  6/122 [>.............................] - ETA: 1s - loss: 0.3103 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2253 11/122 [=>............................] - ETA: 1s - loss: 0.3104 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2257 16/122 [==>...........................] - ETA: 1s - loss: 0.3075 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2235 21/122 [====>.........................] - ETA: 1s - loss: 0.3075 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2235 26/122 [=====>........................] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 31/122 [======>.......................] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2242 36/122 [=======>......................] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2244 41/122 [=========>....................] - ETA: 0s - loss: 0.3082 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2241 46/122 [==========>...................] - ETA: 0s - loss: 0.3081 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2239 51/122 [===========>..................] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2243 56/122 [============>.................] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 61/122 [==============>...............] - ETA: 0s - loss: 0.3087 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2245 66/122 [===============>..............] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 71/122 [================>.............] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 76/122 [=================>............] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 81/122 [==================>...........] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 86/122 [====================>.........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251 91/122 [=====================>........] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2252 96/122 [======================>.......] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250101/122 [=======================>......] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2250106/122 [=========================>....] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251111/122 [==========================>...] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2252116/122 [===========================>..] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251122/122 [==============================] - 1s 11ms/step - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3090 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2253 - lr: 1.0000e-04
Epoch 19/50
  1/122 [..............................] - ETA: 1s - loss: 0.3145 - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2283  6/122 [>.............................] - ETA: 1s - loss: 0.3123 - conv2d_12_loss: 0.0850 - conv2d_19_loss: 0.2273 11/122 [=>............................] - ETA: 1s - loss: 0.3104 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2259 16/122 [==>...........................] - ETA: 1s - loss: 0.3096 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2254 21/122 [====>.........................] - ETA: 1s - loss: 0.3100 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2255 26/122 [=====>........................] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2254 31/122 [======>.......................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 36/122 [=======>......................] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2244 41/122 [=========>....................] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2244 46/122 [==========>...................] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 51/122 [===========>..................] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2244 56/122 [============>.................] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2247 61/122 [==============>...............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249 66/122 [===============>..............] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249 71/122 [================>.............] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2250 76/122 [=================>............] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2252 81/122 [==================>...........] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2251 86/122 [====================>.........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2251 91/122 [=====================>........] - ETA: 0s - loss: 0.3096 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2253 96/122 [======================>.......] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2251101/122 [=======================>......] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249106/122 [=========================>....] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2250111/122 [==========================>...] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2251116/122 [===========================>..] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3090 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2253 - lr: 1.0000e-04
Epoch 20/50
  1/122 [..............................] - ETA: 1s - loss: 0.3004 - conv2d_12_loss: 0.0825 - conv2d_19_loss: 0.2179  6/122 [>.............................] - ETA: 1s - loss: 0.3014 - conv2d_12_loss: 0.0827 - conv2d_19_loss: 0.2187 11/122 [=>............................] - ETA: 1s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 16/122 [==>...........................] - ETA: 1s - loss: 0.3068 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2229 21/122 [====>.........................] - ETA: 1s - loss: 0.3070 - conv2d_12_loss: 0.0839 - conv2d_19_loss: 0.2231 26/122 [=====>........................] - ETA: 0s - loss: 0.3058 - conv2d_12_loss: 0.0836 - conv2d_19_loss: 0.2222 31/122 [======>.......................] - ETA: 0s - loss: 0.3065 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2227 36/122 [=======>......................] - ETA: 0s - loss: 0.3064 - conv2d_12_loss: 0.0837 - conv2d_19_loss: 0.2227 41/122 [=========>....................] - ETA: 0s - loss: 0.3067 - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2229 46/122 [==========>...................] - ETA: 0s - loss: 0.3076 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2236 51/122 [===========>..................] - ETA: 0s - loss: 0.3082 - conv2d_12_loss: 0.0841 - conv2d_19_loss: 0.2240 56/122 [============>.................] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2244 61/122 [==============>...............] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2244 66/122 [===============>..............] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2249 71/122 [================>.............] - ETA: 0s - loss: 0.3089 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2246 76/122 [=================>............] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 81/122 [==================>...........] - ETA: 0s - loss: 0.3086 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2244 86/122 [====================>.........] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2246 91/122 [=====================>........] - ETA: 0s - loss: 0.3085 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2243 96/122 [======================>.......] - ETA: 0s - loss: 0.3084 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2242101/122 [=======================>......] - ETA: 0s - loss: 0.3083 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2242106/122 [=========================>....] - ETA: 0s - loss: 0.3088 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2246111/122 [==========================>...] - ETA: 0s - loss: 0.3091 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248116/122 [===========================>..] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3091 - val_conv2d_12_loss: 0.0838 - val_conv2d_19_loss: 0.2253 - lr: 1.0000e-04
Epoch 21/50
  1/122 [..............................] - ETA: 1s - loss: 0.2937 - conv2d_12_loss: 0.0810 - conv2d_19_loss: 0.2127  6/122 [>.............................] - ETA: 1s - loss: 0.3067 - conv2d_12_loss: 0.0840 - conv2d_19_loss: 0.2227 11/122 [=>............................] - ETA: 1s - loss: 0.3084 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2242 16/122 [==>...........................] - ETA: 1s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 21/122 [====>.........................] - ETA: 1s - loss: 0.3113 - conv2d_12_loss: 0.0847 - conv2d_19_loss: 0.2265 26/122 [=====>........................] - ETA: 0s - loss: 0.3108 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2263 31/122 [======>.......................] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2255 36/122 [=======>......................] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2255 41/122 [=========>....................] - ETA: 0s - loss: 0.3093 - conv2d_12_loss: 0.0842 - conv2d_19_loss: 0.2251 46/122 [==========>...................] - ETA: 0s - loss: 0.3092 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2248 51/122 [===========>..................] - ETA: 0s - loss: 0.3090 - conv2d_12_loss: 0.0843 - conv2d_19_loss: 0.2247 56/122 [============>.................] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 61/122 [==============>...............] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2254 66/122 [===============>..............] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2253 71/122 [================>.............] - ETA: 0s - loss: 0.3101 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2255 76/122 [=================>............] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252 81/122 [==================>...........] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2249 86/122 [====================>.........] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2251 91/122 [=====================>........] - ETA: 0s - loss: 0.3100 - conv2d_12_loss: 0.0846 - conv2d_19_loss: 0.2254 96/122 [======================>.......] - ETA: 0s - loss: 0.3098 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2253101/122 [=======================>......] - ETA: 0s - loss: 0.3099 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2254106/122 [=========================>....] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252111/122 [==========================>...] - ETA: 0s - loss: 0.3097 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2252116/122 [===========================>..] - ETA: 0s - loss: 0.3095 - conv2d_12_loss: 0.0845 - conv2d_19_loss: 0.2251121/122 [============================>.] - ETA: 0s - loss: 0.3094 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250122/122 [==============================] - 1s 11ms/step - loss: 0.3095 - conv2d_12_loss: 0.0844 - conv2d_19_loss: 0.2250 - val_loss: 0.3092 - val_conv2d_12_loss: 0.0837 - val_conv2d_19_loss: 0.2255 - lr: 1.0000e-04
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
2025-07-27 21:30:04,266 - INFO - Trained model saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1/baseline_model.h5
2025-07-27 21:30:04,267 - INFO - 
[5/6] Performing inference and stitching...
  1/322 [..............................] - ETA: 1:39 11/322 [>.............................] - ETA: 1s   21/322 [>.............................] - ETA: 1s 31/322 [=>............................] - ETA: 1s 41/322 [==>...........................] - ETA: 1s 51/322 [===>..........................] - ETA: 1s 61/322 [====>.........................] - ETA: 1s 71/322 [=====>........................] - ETA: 1s 81/322 [======>.......................] - ETA: 1s 91/322 [=======>......................] - ETA: 1s101/322 [========>.....................] - ETA: 1s111/322 [=========>....................] - ETA: 1s121/322 [==========>...................] - ETA: 1s131/322 [===========>..................] - ETA: 0s141/322 [============>.................] - ETA: 0s151/322 [=============>................] - ETA: 0s161/322 [==============>...............] - ETA: 0s171/322 [==============>...............] - ETA: 0s181/322 [===============>..............] - ETA: 0s191/322 [================>.............] - ETA: 0s201/322 [=================>............] - ETA: 0s211/322 [==================>...........] - ETA: 0s221/322 [===================>..........] - ETA: 0s231/322 [====================>.........] - ETA: 0s241/322 [=====================>........] - ETA: 0s251/322 [======================>.......] - ETA: 0s261/322 [=======================>......] - ETA: 0s271/322 [========================>.....] - ETA: 0s281/322 [=========================>....] - ETA: 0s291/322 [==========================>...] - ETA: 0s301/322 [===========================>..] - ETA: 0s311/322 [===========================>..] - ETA: 0s321/322 [============================>.] - ETA: 0s322/322 [==============================] - 2s 5ms/step
2025-07-27 21:30:07,731 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-07-27 21:30:07,731 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-07-27 21:30:07,731 - INFO - Aligning ground truth to match reconstruction bounds...
2025-07-27 21:30:07,732 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:30:07,732 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:30:07,732 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:30:07,732 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:30:07,732 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:30:07,732 - INFO - --- Alignment complete ---
2025-07-27 21:30:07,732 - INFO - Final evaluation shapes: Reconstruction=(1, 185, 185, 1), Ground Truth=(185, 185, 1)
2025-07-27 21:30:07,822 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-07-27 21:30:07,822 - INFO -   MAE:  (0.085036166, 0.2513031408791028)
2025-07-27 21:30:07,822 - INFO -   PSNR: (68.30541915365217, 58.98024944025171)
2025-07-27 21:30:07,924 - INFO - Metrics and reconstruction images saved.
2025-07-27 21:30:07,924 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 0.981189
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=1.256246, std=0.000000, shape=(181, 181, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction []: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.981189
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=1.256246, std=0.000000, shape=(181, 181, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]
performed by index method
performed by index method
performed by index method
[2025-07-27 21:30:08] SUCCESS: Baseline training (n_images=2048, trial=3)
[2025-07-27 21:30:08] EXECUTING: Tike reconstruction (n_images=4096, trial=3)
[2025-07-27 21:30:08] COMMAND: python scripts/reconstruction/run_tike_reconstruction.py \
                'datasets/fly64/fly64_shuffled.npz' \
                '3way_bothhalves_full_2xtest/train_2048/trial_3/tike_run' \
                --n-images 4096 \
                --iterations 1000 \
                --quiet
[2025-07-27 21:33:33] SUCCESS: Tike reconstruction (n_images=4096, trial=3)
[2025-07-27 21:33:33] Completed training for train_size=2048 (Trial 3/3)
[2025-07-27 21:33:33] Completed all trials for train_size=2048
[2025-07-27 21:33:33] Model training phase completed
[2025-07-27 21:33:33] === STEP 3: Model Comparison ===
[2025-07-27 21:33:33] Running comparisons for train_size=256, test_size=512 (3 trials)
[2025-07-27 21:33:33] Using test subset size 512 (3-way comparison mode)
[2025-07-27 21:33:33] EXECUTING: Model comparison (train_size=256, trial=1)
[2025-07-27 21:33:33] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_256/trial_1' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_256/trial_1/tike_run/tike_reconstruction.npz' --n-test-images 512
2025-07-27 21:33:33.602727: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:33:33.602759: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:33:33.603591: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:33:33.607755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:33:34.113354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:33:34.966475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:34.998738: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.000994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:33:35.269429: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.271683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.273850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.393095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.394338: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.395448: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:33:35.395585: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:33:35.396729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:33:35,425 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:33:35,425 - INFO - Registration: disabled
2025-07-27 21:33:35,425 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:33:35,425 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:33:35,425 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=512
2025-07-27 21:33:35,499 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:33:35,499 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:33:35,499 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:33:35,499 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:33:35,499 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:33:35,499 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:33:35,499 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:33:35,499 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:33:35,499 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:33:35,499 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:33:35,499 - INFO - DEBUG:
 nsamples:2025-07-27 21:33:35,499 - INFO - nsamples:
 103042025-07-27 21:33:35,499 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:33:35,499 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:33:35,521 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

neighbor-sampled diffraction shape2025-07-27 21:33:51,982 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:33:51,982 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:33:52,208 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:33:52,569 - INFO - INFO:
 None2025-07-27 21:33:52,569 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:33:52,569 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:33:52,570 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_256/trial_1/pinn_run...
input shape2025-07-27 21:33:53,216 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:33:53,216 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:33:53,226 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:33:53,337 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:33:53,337 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:33:53,337 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:33:53,337 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:33:53,338 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:33:53,338 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:33:53,338 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:33:53,338 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:33:53,338 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:33:53,338 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:33:53,338 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:33:53,338 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:33:53,338 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:33:53,338 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,338 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:33:53,338 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:33:53,339 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:33:53,339 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,339 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:33:53,339 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:33:53,339 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:33:53,339 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:33:53,339 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:33:53,339 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:33:53,339 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:33:53,339 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,339 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:33:53,339 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:33:53,339 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:33:53,339 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:33:53,339 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:33:53,339 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,339 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:33:53,340 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,340 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:33:53,340 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:33:53,340 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:33:53,340 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:33:53,340 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:33:53,340 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:33:53,340 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:33:53,340 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:33:53,340 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:33:53,340 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:33:53,340 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:33:53,340 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,340 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:33:53,340 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,340 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:33:53,340 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:33:53,340 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:33:53,340 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:33:53,341 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:33:53,341 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:33:53,341 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:33:53,341 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:33:53,341 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:33:53,341 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:33:53,341 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:33:53,341 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:33:53,341 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:33:53,341 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:33:53,341 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:33:53,341 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:33:53,341 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:33:53,341 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:33:53,341 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:33:53,341 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:33:53,341 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:33:53,341 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:33:53,341 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:33:53,341 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:33:53,341 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:33:53,341 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:33:53,341 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:33:53,342 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:33:53,342 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:33:53,342 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:33:53,342 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:33:53,342 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:33:53,342 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:33:53,342 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:33:53,342 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:33:53,342 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:33:53,342 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:33:53,342 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:33:53,342 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:33:53,342 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:33:53,342 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:33:53,342 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:33:53,342 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:33:53,342 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:33:53,342 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:33:53,342 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:33:53,342 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:33:53,342 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:33:53,342 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:33:53,343 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:33:53,343 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:33:53,343 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:33:53,343 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:33:53,343 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:33:53,343 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:33:53,343 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:33:53,343 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:33:53,343 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:33:53,343 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:33:53,343 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:33:53,343 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:33:53,343 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:33:53,343 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:33:53,343 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:33:53,343 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:33:53,343 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:33:53,343 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:33:53,344 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:33:53,344 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:33:53,344 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:33:53,344 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:33:53,344 - INFO - None

2025-07-27 21:33:53.345239: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:33:53.345254: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:33:53.345276: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:33:53.362154: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:33:53.362230: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:33:53,745 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:33:53,745 - INFO - (None, 64, 64, 1)

2025-07-27 21:33:53.771511: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmph7fj5dgq/autoencoder: FAILED_PRECONDITION: /tmp/tmph7fj5dgq/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:33:54,062 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:33:54,063 - INFO - (None, 64, 64, 1)

2025-07-27 21:33:54.087883: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmph7fj5dgq/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmph7fj5dgq/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:33:54,121 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1...
2025-07-27 21:33:54,121 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_run/07-27-2025-21.07.37_baseline_gs1/baseline_model.h5
2025-07-27 21:33:54,388 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_256/trial_1/tike_run/tike_reconstruction.npz...
2025-07-27 21:33:54,390 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:33:54,390 - INFO - Loaded Tike reconstruction: (358, 358) (complex64)
2025-07-27 21:33:54,390 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:33:54,390 - INFO - Running inference with PtychoPINN...
2025-07-27 21:33:54.772918: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:122025-07-27 21:33:55,279 - INFO - 1/322 [..............................] - ETA: 4:12
 13/322 [>.............................] - ETA: 1s  2025-07-27 21:33:55,330 - INFO -  13/322 [>.............................] - ETA: 1s
 25/322 [=>............................] - ETA: 1s2025-07-27 21:33:55,381 - INFO -  25/322 [=>............................] - ETA: 1s
 37/322 [==>...........................] - ETA: 1s2025-07-27 21:33:55,432 - INFO -  37/322 [==>...........................] - ETA: 1s
 49/322 [===>..........................] - ETA: 1s2025-07-27 21:33:55,483 - INFO -  49/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:33:55,534 - INFO -  61/322 [====>.........................] - ETA: 1s
 73/322 [=====>........................] - ETA: 1s2025-07-27 21:33:55,585 - INFO -  73/322 [=====>........................] - ETA: 1s
 85/322 [======>.......................] - ETA: 1s2025-07-27 21:33:55,636 - INFO -  85/322 [======>.......................] - ETA: 1s
 97/322 [========>.....................] - ETA: 0s2025-07-27 21:33:55,686 - INFO -  97/322 [========>.....................] - ETA: 0s
109/322 [=========>....................] - ETA: 0s2025-07-27 21:33:55,737 - INFO - 109/322 [=========>....................] - ETA: 0s
121/322 [==========>...................] - ETA: 0s2025-07-27 21:33:55,788 - INFO - 121/322 [==========>...................] - ETA: 0s
133/322 [===========>..................] - ETA: 0s2025-07-27 21:33:55,839 - INFO - 133/322 [===========>..................] - ETA: 0s
145/322 [============>.................] - ETA: 0s2025-07-27 21:33:55,889 - INFO - 145/322 [============>.................] - ETA: 0s
157/322 [=============>................] - ETA: 0s2025-07-27 21:33:55,939 - INFO - 157/322 [=============>................] - ETA: 0s
169/322 [==============>...............] - ETA: 0s2025-07-27 21:33:55,989 - INFO - 169/322 [==============>...............] - ETA: 0s
181/322 [===============>..............] - ETA: 0s2025-07-27 21:33:56,039 - INFO - 181/322 [===============>..............] - ETA: 0s
194/322 [=================>............] - ETA: 0s2025-07-27 21:33:56,093 - INFO - 194/322 [=================>............] - ETA: 0s
207/322 [==================>...........] - ETA: 0s2025-07-27 21:33:56,147 - INFO - 207/322 [==================>...........] - ETA: 0s
220/322 [===================>..........] - ETA: 0s2025-07-27 21:33:56,201 - INFO - 220/322 [===================>..........] - ETA: 0s
233/322 [====================>.........] - ETA: 0s2025-07-27 21:33:56,254 - INFO - 233/322 [====================>.........] - ETA: 0s
245/322 [=====================>........] - ETA: 0s2025-07-27 21:33:56,304 - INFO - 245/322 [=====================>........] - ETA: 0s
258/322 [=======================>......] - ETA: 0s2025-07-27 21:33:56,359 - INFO - 258/322 [=======================>......] - ETA: 0s
271/322 [========================>.....] - ETA: 0s2025-07-27 21:33:56,412 - INFO - 271/322 [========================>.....] - ETA: 0s
284/322 [=========================>....] - ETA: 0s2025-07-27 21:33:56,466 - INFO - 284/322 [=========================>....] - ETA: 0s
297/322 [==========================>...] - ETA: 0s2025-07-27 21:33:56,520 - INFO - 297/322 [==========================>...] - ETA: 0s
310/322 [===========================>..] - ETA: 0s2025-07-27 21:33:56,574 - INFO - 310/322 [===========================>..] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:33:56,624 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:33:56,933 - INFO - PtychoPINN inference completed in 2.54s
2025-07-27 21:33:56,933 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:33:58,275 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 43s2025-07-27 21:33:58,511 - INFO - 1/322 [..............................] - ETA: 43s
 12/322 [>.............................] - ETA: 1s 2025-07-27 21:33:58,566 - INFO -  12/322 [>.............................] - ETA: 1s
 22/322 [=>............................] - ETA: 1s2025-07-27 21:33:58,618 - INFO -  22/322 [=>............................] - ETA: 1s
 32/322 [=>............................] - ETA: 1s2025-07-27 21:33:58,670 - INFO -  32/322 [=>............................] - ETA: 1s
 42/322 [==>...........................] - ETA: 1s2025-07-27 21:33:58,722 - INFO -  42/322 [==>...........................] - ETA: 1s
 52/322 [===>..........................] - ETA: 1s2025-07-27 21:33:58,774 - INFO -  52/322 [===>..........................] - ETA: 1s
 62/322 [====>.........................] - ETA: 1s2025-07-27 21:33:58,827 - INFO -  62/322 [====>.........................] - ETA: 1s
 72/322 [=====>........................] - ETA: 1s2025-07-27 21:33:58,878 - INFO -  72/322 [=====>........................] - ETA: 1s
 82/322 [======>.......................] - ETA: 1s2025-07-27 21:33:58,930 - INFO -  82/322 [======>.......................] - ETA: 1s
 92/322 [=======>......................] - ETA: 1s2025-07-27 21:33:58,982 - INFO -  92/322 [=======>......................] - ETA: 1s
102/322 [========>.....................] - ETA: 1s2025-07-27 21:33:59,034 - INFO - 102/322 [========>.....................] - ETA: 1s
112/322 [=========>....................] - ETA: 1s2025-07-27 21:33:59,086 - INFO - 112/322 [=========>....................] - ETA: 1s
122/322 [==========>...................] - ETA: 1s2025-07-27 21:33:59,138 - INFO - 122/322 [==========>...................] - ETA: 1s
132/322 [===========>..................] - ETA: 0s2025-07-27 21:33:59,189 - INFO - 132/322 [===========>..................] - ETA: 0s
142/322 [============>.................] - ETA: 0s2025-07-27 21:33:59,241 - INFO - 142/322 [============>.................] - ETA: 0s
152/322 [=============>................] - ETA: 0s2025-07-27 21:33:59,293 - INFO - 152/322 [=============>................] - ETA: 0s
162/322 [==============>...............] - ETA: 0s2025-07-27 21:33:59,345 - INFO - 162/322 [==============>...............] - ETA: 0s
172/322 [===============>..............] - ETA: 0s2025-07-27 21:33:59,397 - INFO - 172/322 [===============>..............] - ETA: 0s
182/322 [===============>..............] - ETA: 0s2025-07-27 21:33:59,449 - INFO - 182/322 [===============>..............] - ETA: 0s
192/322 [================>.............] - ETA: 0s2025-07-27 21:33:59,501 - INFO - 192/322 [================>.............] - ETA: 0s
202/322 [=================>............] - ETA: 0s2025-07-27 21:33:59,553 - INFO - 202/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:33:59,605 - INFO - 212/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:33:59,657 - INFO - 222/322 [===================>..........] - ETA: 0s
232/322 [====================>.........] - ETA: 0s2025-07-27 21:33:59,709 - INFO - 232/322 [====================>.........] - ETA: 0s
242/322 [=====================>........] - ETA: 0s2025-07-27 21:33:59,761 - INFO - 242/322 [=====================>........] - ETA: 0s
252/322 [======================>.......] - ETA: 0s2025-07-27 21:33:59,813 - INFO - 252/322 [======================>.......] - ETA: 0s
262/322 [=======================>......] - ETA: 0s2025-07-27 21:33:59,865 - INFO - 262/322 [=======================>......] - ETA: 0s
272/322 [========================>.....] - ETA: 0s2025-07-27 21:33:59,917 - INFO - 272/322 [========================>.....] - ETA: 0s
282/322 [=========================>....] - ETA: 0s2025-07-27 21:33:59,969 - INFO - 282/322 [=========================>....] - ETA: 0s
292/322 [==========================>...] - ETA: 0s2025-07-27 21:34:00,022 - INFO - 292/322 [==========================>...] - ETA: 0s
302/322 [===========================>..] - ETA: 0s2025-07-27 21:34:00,074 - INFO - 302/322 [===========================>..] - ETA: 0s
312/322 [============================>.] - ETA: 0s2025-07-27 21:34:00,126 - INFO - 312/322 [============================>.] - ETA: 0s
322/322 [==============================] - ETA: 0s2025-07-27 21:34:00,178 - INFO - 322/322 [==============================] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:34:00,178 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:34:00,523 - INFO - Baseline inference completed in 2.25s
2025-07-27 21:34:00,973 - INFO - Reassembling baseline patches...
2025-07-27 21:34:01,027 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:34:01,137 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_1/reconstructions.npz
2025-07-27 21:34:01,137 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_1/reconstructions_metadata.txt
2025-07-27 21:34:01,137 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:34:01,137 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:34:01,137 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:34:01,137 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:01,137 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:01,137 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:34:01,137 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:34:01,137 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:01,137 - INFO - --- Alignment complete ---
2025-07-27 21:34:01,137 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:01,137 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:01,137 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:34:01,137 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:34:01,137 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:01,138 - INFO - --- Alignment complete ---
2025-07-27 21:34:01,138 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:01,138 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:01,138 - INFO - Initial shapes: Recon=(358, 358), Cropped GT=(185, 185)
2025-07-27 21:34:01,138 - INFO - Center-cropping from (358, 358) to (185, 185)
2025-07-27 21:34:01,138 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:01,138 - INFO - --- Alignment complete ---
2025-07-27 21:34:01,138 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:34:01,138 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.6518062025-07-27 21:34:01,142 - INFO - Amplitude normalization scale factor: 1.651806

mean scale adjustment:2025-07-27 21:34:01,142 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,142 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,143 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,143 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:01,162 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.746223, std=0.222079, shape=(181, 181, 1)2025-07-27 21:34:01,162 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.746223, std=0.222079, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:01,162 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.000000, shape=(181, 181)2025-07-27 21:34:01,162 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.000000, shape=(181, 181)

performed by index method2025-07-27 21:34:01,166 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,176 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,186 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:01,195 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,195 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,196 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,196 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:01,196 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:01,204 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,214 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,224 - INFO - performed by index method

2025-07-27 21:34:01,233 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.379, phase=0.521, MS-SSIM: amp=0.446, phase=0.029
Amplitude normalization scale factor: 0.9783632025-07-27 21:34:01,236 - INFO - Amplitude normalization scale factor: 0.978363

mean scale adjustment:2025-07-27 21:34:01,236 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,236 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,237 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,237 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:01,238 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.259875, std=0.000001, shape=(181, 181, 1)2025-07-27 21:34:01,238 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.259875, std=0.000001, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:01,238 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000014, shape=(181, 181)2025-07-27 21:34:01,238 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000014, shape=(181, 181)

performed by index method2025-07-27 21:34:01,241 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,251 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,261 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:01,270 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,270 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,270 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,270 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:01,271 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:01,278 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,288 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,298 - INFO - performed by index method

2025-07-27 21:34:01,308 - INFO - Baseline evaluation complete. SSIM: amp=0.086, phase=0.521, MS-SSIM: amp=0.031, phase=0.029
Amplitude normalization scale factor: 1.7471312025-07-27 21:34:01,311 - INFO - Amplitude normalization scale factor: 1.747131

mean scale adjustment:2025-07-27 21:34:01,311 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,311 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,311 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,311 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:01,312 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705508, std=0.071738, shape=(181, 181, 1)2025-07-27 21:34:01,312 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705508, std=0.071738, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:01,312 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.173099, shape=(181, 181)2025-07-27 21:34:01,312 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.173099, shape=(181, 181)

performed by index method2025-07-27 21:34:01,315 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,325 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,335 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:01,344 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,344 - INFO - 1

mean scale adjustment:2025-07-27 21:34:01,345 - INFO - mean scale adjustment:
 12025-07-27 21:34:01,345 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:01,345 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:01,353 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,362 - INFO - performed by index method

performed by index method2025-07-27 21:34:01,372 - INFO - performed by index method

2025-07-27 21:34:01,381 - INFO - Tike evaluation complete. SSIM: amp=0.024, phase=0.418, MS-SSIM: amp=0.033, phase=0.025
2025-07-27 21:34:01,383 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_256/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:34:01,383 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.238679  0.251303      NaN
PtychoPINN                mse   0.087935  0.082235      NaN
PtychoPINN               psnr  58.689174 58.980249      NaN
PtychoPINN               ssim   0.378602  0.520955      NaN
PtychoPINN            ms_ssim   0.445922  0.028860      NaN
PtychoPINN              frc50   3.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082234      NaN
  Baseline               psnr  68.305420 58.980267      NaN
  Baseline               ssim   0.085875  0.520956      NaN
  Baseline            ms_ssim   0.031288  0.028863      NaN
  Baseline              frc50   2.000000  1.000000      NaN
      Tike                mae   0.126184  0.269813      NaN
      Tike                mse   0.025129  0.110333      NaN
      Tike               psnr  64.129091 57.703733      NaN
      Tike               ssim   0.023516  0.417554      NaN
      Tike            ms_ssim   0.033418  0.024569      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.542971
  Baseline computation_time_s        NaN       NaN 2.2477572025-07-27 21:34:01,384 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.238679  0.251303      NaN
PtychoPINN                mse   0.087935  0.082235      NaN
PtychoPINN               psnr  58.689174 58.980249      NaN
PtychoPINN               ssim   0.378602  0.520955      NaN
PtychoPINN            ms_ssim   0.445922  0.028860      NaN
PtychoPINN              frc50   3.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082234      NaN
  Baseline               psnr  68.305420 58.980267      NaN
  Baseline               ssim   0.085875  0.520956      NaN
  Baseline            ms_ssim   0.031288  0.028863      NaN
  Baseline              frc50   2.000000  1.000000      NaN
      Tike                mae   0.126184  0.269813      NaN
      Tike                mse   0.025129  0.110333      NaN
      Tike               psnr  64.129091 57.703733      NaN
      Tike               ssim   0.023516  0.417554      NaN
      Tike            ms_ssim   0.033418  0.024569      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.542971
  Baseline computation_time_s        NaN       NaN 2.247757

2025-07-27 21:34:01,385 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_1/pinn_frc_curves.csv
2025-07-27 21:34:01,386 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_1/baseline_frc_curves.csv
2025-07-27 21:34:01,386 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:34:01,443 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_1/reconstructions_aligned.npz
2025-07-27 21:34:01,444 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_1/reconstructions_aligned_metadata.txt
2025-07-27 21:34:01,444 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:34:01,486 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.365, 0.973) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,487 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.260, 1.260) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,487 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (3.142, 3.142) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,488 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.217, -2.217) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,489 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.609, 0.796) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,489 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.264, 0.191) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,500 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:01,500 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:02,181 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_256/trial_1/comparison_plot.png
2025-07-27 21:34:02,181 - INFO - 
Comparison complete!
2025-07-27 21:34:02,181 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_256/trial_1
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:34:02,531 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:34:02,531 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:34:02,532 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:34:02] SUCCESS: Model comparison (train_size=256, trial=1)
[2025-07-27 21:34:03] Using test subset size 512 (3-way comparison mode)
[2025-07-27 21:34:03] EXECUTING: Model comparison (train_size=256, trial=2)
[2025-07-27 21:34:03] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_256/trial_2' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_256/trial_2/tike_run/tike_reconstruction.npz' --n-test-images 512
2025-07-27 21:34:03.409903: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:34:03.409933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:34:03.410766: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:34:03.414843: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:34:03.905975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:34:04.751154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:04.782379: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:04.783792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:34:05.049072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.051324: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.053450: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.157966: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.159190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.160331: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:34:05.160470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:05.161598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:34:05,191 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:34:05,191 - INFO - Registration: disabled
2025-07-27 21:34:05,191 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:34:05,191 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:34:05,191 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=512
2025-07-27 21:34:05,264 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:34:05,264 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:34:05,264 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:34:05,264 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:34:05,264 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:34:05,264 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:34:05,264 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:34:05,264 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:34:05,264 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:34:05,264 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:34:05,264 - INFO - DEBUG:
 nsamples:2025-07-27 21:34:05,264 - INFO - nsamples:
 103042025-07-27 21:34:05,264 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:34:05,264 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:34:05,287 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

neighbor-sampled diffraction shape2025-07-27 21:34:21,512 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:34:21,512 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:34:21,737 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:34:22,106 - INFO - INFO:
 None2025-07-27 21:34:22,106 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:34:22,106 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:34:22,108 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_256/trial_2/pinn_run...
input shape2025-07-27 21:34:22,754 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:22,754 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:34:22,765 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:34:22,879 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:34:22,879 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:34:22,879 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:34:22,879 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:34:22,879 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:34:22,879 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:34:22,879 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:34:22,879 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:34:22,879 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:34:22,879 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:34:22,879 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:34:22,879 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:34:22,880 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:34:22,880 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,880 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:34:22,880 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:34:22,880 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:34:22,880 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,880 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:34:22,880 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:34:22,880 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:34:22,880 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:34:22,880 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:34:22,880 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:34:22,880 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:34:22,880 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,880 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:34:22,880 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:34:22,881 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:34:22,881 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:34:22,881 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:34:22,881 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,881 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:34:22,881 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,881 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:34:22,881 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:22,881 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:34:22,881 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:22,881 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:34:22,881 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:34:22,881 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:34:22,881 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:34:22,881 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:34:22,881 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:34:22,881 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:34:22,881 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,882 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:34:22,882 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,882 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:34:22,882 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:34:22,882 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:34:22,882 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:34:22,882 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:34:22,882 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:22,882 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:34:22,882 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:34:22,882 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:34:22,882 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:22,882 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:34:22,882 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:22,882 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:34:22,882 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:34:22,882 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:34:22,882 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:34:22,882 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:34:22,882 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:22,882 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:34:22,883 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:34:22,883 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:34:22,883 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:34:22,883 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:34:22,883 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:22,883 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:34:22,883 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:34:22,883 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:34:22,883 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:34:22,883 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:34:22,883 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:34:22,883 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:34:22,883 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:34:22,883 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:34:22,883 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:22,883 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:34:22,883 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:34:22,883 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:34:22,883 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:34:22,883 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:34:22,883 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:34:22,884 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:34:22,884 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:34:22,884 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:34:22,884 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:34:22,884 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:34:22,884 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:34:22,884 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:34:22,884 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:34:22,884 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:34:22,884 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:34:22,884 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:34:22,884 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:34:22,884 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:34:22,884 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:34:22,884 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:34:22,884 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:34:22,884 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:34:22,884 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:34:22,884 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:34:22,885 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:34:22,885 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:34:22,885 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:22,885 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:34:22,885 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:34:22,885 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:34:22,885 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:34:22,885 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:34:22,886 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:34:22,886 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:34:22,886 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:34:22,886 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:34:22,886 - INFO - None

2025-07-27 21:34:22.886695: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:34:22.886710: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:34:22.886731: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:34:22.903678: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:34:22.903756: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:34:23,291 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:23,291 - INFO - (None, 64, 64, 1)

2025-07-27 21:34:23.318441: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmpqm1473r_/autoencoder: FAILED_PRECONDITION: /tmp/tmpqm1473r_/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:34:23,613 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:23,613 - INFO - (None, 64, 64, 1)

2025-07-27 21:34:23.638934: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmpqm1473r_/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmpqm1473r_/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:34:23,672 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1...
2025-07-27 21:34:23,672 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_run/07-27-2025-21.09.49_baseline_gs1/baseline_model.h5
2025-07-27 21:34:23,939 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_256/trial_2/tike_run/tike_reconstruction.npz...
2025-07-27 21:34:23,941 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:34:23,941 - INFO - Loaded Tike reconstruction: (358, 358) (complex64)
2025-07-27 21:34:23,941 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:34:23,941 - INFO - Running inference with PtychoPINN...
2025-07-27 21:34:24.334324: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:122025-07-27 21:34:24,838 - INFO - 1/322 [..............................] - ETA: 4:12
 13/322 [>.............................] - ETA: 1s  2025-07-27 21:34:24,888 - INFO -  13/322 [>.............................] - ETA: 1s
 25/322 [=>............................] - ETA: 1s2025-07-27 21:34:24,939 - INFO -  25/322 [=>............................] - ETA: 1s
 37/322 [==>...........................] - ETA: 1s2025-07-27 21:34:24,990 - INFO -  37/322 [==>...........................] - ETA: 1s
 49/322 [===>..........................] - ETA: 1s2025-07-27 21:34:25,041 - INFO -  49/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:34:25,092 - INFO -  61/322 [====>.........................] - ETA: 1s
 73/322 [=====>........................] - ETA: 1s2025-07-27 21:34:25,143 - INFO -  73/322 [=====>........................] - ETA: 1s
 85/322 [======>.......................] - ETA: 1s2025-07-27 21:34:25,194 - INFO -  85/322 [======>.......................] - ETA: 1s
 97/322 [========>.....................] - ETA: 0s2025-07-27 21:34:25,245 - INFO -  97/322 [========>.....................] - ETA: 0s
109/322 [=========>....................] - ETA: 0s2025-07-27 21:34:25,295 - INFO - 109/322 [=========>....................] - ETA: 0s
121/322 [==========>...................] - ETA: 0s2025-07-27 21:34:25,346 - INFO - 121/322 [==========>...................] - ETA: 0s
133/322 [===========>..................] - ETA: 0s2025-07-27 21:34:25,397 - INFO - 133/322 [===========>..................] - ETA: 0s
145/322 [============>.................] - ETA: 0s2025-07-27 21:34:25,447 - INFO - 145/322 [============>.................] - ETA: 0s
158/322 [=============>................] - ETA: 0s2025-07-27 21:34:25,501 - INFO - 158/322 [=============>................] - ETA: 0s
171/322 [==============>...............] - ETA: 0s2025-07-27 21:34:25,555 - INFO - 171/322 [==============>...............] - ETA: 0s
183/322 [================>.............] - ETA: 0s2025-07-27 21:34:25,605 - INFO - 183/322 [================>.............] - ETA: 0s
196/322 [=================>............] - ETA: 0s2025-07-27 21:34:25,659 - INFO - 196/322 [=================>............] - ETA: 0s
209/322 [==================>...........] - ETA: 0s2025-07-27 21:34:25,712 - INFO - 209/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:34:25,765 - INFO - 222/322 [===================>..........] - ETA: 0s
235/322 [====================>.........] - ETA: 0s2025-07-27 21:34:25,819 - INFO - 235/322 [====================>.........] - ETA: 0s
248/322 [======================>.......] - ETA: 0s2025-07-27 21:34:25,872 - INFO - 248/322 [======================>.......] - ETA: 0s
261/322 [=======================>......] - ETA: 0s2025-07-27 21:34:25,926 - INFO - 261/322 [=======================>......] - ETA: 0s
274/322 [========================>.....] - ETA: 0s2025-07-27 21:34:25,980 - INFO - 274/322 [========================>.....] - ETA: 0s
287/322 [=========================>....] - ETA: 0s2025-07-27 21:34:26,033 - INFO - 287/322 [=========================>....] - ETA: 0s
300/322 [==========================>...] - ETA: 0s2025-07-27 21:34:26,087 - INFO - 300/322 [==========================>...] - ETA: 0s
313/322 [============================>.] - ETA: 0s2025-07-27 21:34:26,141 - INFO - 313/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:34:26,178 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:34:26,484 - INFO - PtychoPINN inference completed in 2.54s
2025-07-27 21:34:26,484 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:34:27,869 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 42s2025-07-27 21:34:28,104 - INFO - 1/322 [..............................] - ETA: 42s
 11/322 [>.............................] - ETA: 1s 2025-07-27 21:34:28,155 - INFO -  11/322 [>.............................] - ETA: 1s
 21/322 [>.............................] - ETA: 1s2025-07-27 21:34:28,207 - INFO -  21/322 [>.............................] - ETA: 1s
 31/322 [=>............................] - ETA: 1s2025-07-27 21:34:28,260 - INFO -  31/322 [=>............................] - ETA: 1s
 41/322 [==>...........................] - ETA: 1s2025-07-27 21:34:28,312 - INFO -  41/322 [==>...........................] - ETA: 1s
 51/322 [===>..........................] - ETA: 1s2025-07-27 21:34:28,364 - INFO -  51/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:34:28,417 - INFO -  61/322 [====>.........................] - ETA: 1s
 71/322 [=====>........................] - ETA: 1s2025-07-27 21:34:28,469 - INFO -  71/322 [=====>........................] - ETA: 1s
 81/322 [======>.......................] - ETA: 1s2025-07-27 21:34:28,521 - INFO -  81/322 [======>.......................] - ETA: 1s
 91/322 [=======>......................] - ETA: 1s2025-07-27 21:34:28,574 - INFO -  91/322 [=======>......................] - ETA: 1s
101/322 [========>.....................] - ETA: 1s2025-07-27 21:34:28,625 - INFO - 101/322 [========>.....................] - ETA: 1s
111/322 [=========>....................] - ETA: 1s2025-07-27 21:34:28,678 - INFO - 111/322 [=========>....................] - ETA: 1s
121/322 [==========>...................] - ETA: 1s2025-07-27 21:34:28,730 - INFO - 121/322 [==========>...................] - ETA: 1s
131/322 [===========>..................] - ETA: 0s2025-07-27 21:34:28,782 - INFO - 131/322 [===========>..................] - ETA: 0s
141/322 [============>.................] - ETA: 0s2025-07-27 21:34:28,834 - INFO - 141/322 [============>.................] - ETA: 0s
151/322 [=============>................] - ETA: 0s2025-07-27 21:34:28,886 - INFO - 151/322 [=============>................] - ETA: 0s
161/322 [==============>...............] - ETA: 0s2025-07-27 21:34:28,938 - INFO - 161/322 [==============>...............] - ETA: 0s
171/322 [==============>...............] - ETA: 0s2025-07-27 21:34:28,990 - INFO - 171/322 [==============>...............] - ETA: 0s
181/322 [===============>..............] - ETA: 0s2025-07-27 21:34:29,042 - INFO - 181/322 [===============>..............] - ETA: 0s
191/322 [================>.............] - ETA: 0s2025-07-27 21:34:29,094 - INFO - 191/322 [================>.............] - ETA: 0s
201/322 [=================>............] - ETA: 0s2025-07-27 21:34:29,146 - INFO - 201/322 [=================>............] - ETA: 0s
211/322 [==================>...........] - ETA: 0s2025-07-27 21:34:29,198 - INFO - 211/322 [==================>...........] - ETA: 0s
221/322 [===================>..........] - ETA: 0s2025-07-27 21:34:29,250 - INFO - 221/322 [===================>..........] - ETA: 0s
231/322 [====================>.........] - ETA: 0s2025-07-27 21:34:29,302 - INFO - 231/322 [====================>.........] - ETA: 0s
241/322 [=====================>........] - ETA: 0s2025-07-27 21:34:29,354 - INFO - 241/322 [=====================>........] - ETA: 0s
251/322 [======================>.......] - ETA: 0s2025-07-27 21:34:29,406 - INFO - 251/322 [======================>.......] - ETA: 0s
261/322 [=======================>......] - ETA: 0s2025-07-27 21:34:29,458 - INFO - 261/322 [=======================>......] - ETA: 0s
271/322 [========================>.....] - ETA: 0s2025-07-27 21:34:29,510 - INFO - 271/322 [========================>.....] - ETA: 0s
281/322 [=========================>....] - ETA: 0s2025-07-27 21:34:29,562 - INFO - 281/322 [=========================>....] - ETA: 0s
291/322 [==========================>...] - ETA: 0s2025-07-27 21:34:29,614 - INFO - 291/322 [==========================>...] - ETA: 0s
301/322 [===========================>..] - ETA: 0s2025-07-27 21:34:29,666 - INFO - 301/322 [===========================>..] - ETA: 0s
311/322 [===========================>..] - ETA: 0s2025-07-27 21:34:29,719 - INFO - 311/322 [===========================>..] - ETA: 0s
321/322 [============================>.] - ETA: 0s2025-07-27 21:34:29,771 - INFO - 321/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:34:29,776 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:34:30,126 - INFO - Baseline inference completed in 2.26s
2025-07-27 21:34:30,576 - INFO - Reassembling baseline patches...
2025-07-27 21:34:30,673 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:34:30,763 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_2/reconstructions.npz
2025-07-27 21:34:30,763 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_2/reconstructions_metadata.txt
2025-07-27 21:34:30,763 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:34:30,763 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:34:30,764 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:34:30,764 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:30,764 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:30,764 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:34:30,764 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:34:30,764 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:30,764 - INFO - --- Alignment complete ---
2025-07-27 21:34:30,764 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:30,764 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:30,764 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:34:30,764 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:34:30,764 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:30,764 - INFO - --- Alignment complete ---
2025-07-27 21:34:30,764 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:34:30,764 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:34:30,764 - INFO - Initial shapes: Recon=(358, 358), Cropped GT=(185, 185)
2025-07-27 21:34:30,764 - INFO - Center-cropping from (358, 358) to (185, 185)
2025-07-27 21:34:30,764 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:34:30,764 - INFO - --- Alignment complete ---
2025-07-27 21:34:30,764 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:34:30,764 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.5373402025-07-27 21:34:30,769 - INFO - Amplitude normalization scale factor: 1.537340

mean scale adjustment:2025-07-27 21:34:30,769 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,769 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,769 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,769 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:30,787 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.801784, std=0.089958, shape=(181, 181, 1)2025-07-27 21:34:30,787 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.801784, std=0.089958, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:30,787 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.399790, shape=(181, 181)2025-07-27 21:34:30,788 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.399790, shape=(181, 181)

performed by index method2025-07-27 21:34:30,791 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,801 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,811 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:30,820 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,820 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,821 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,821 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:30,821 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:30,829 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,839 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,848 - INFO - performed by index method

2025-07-27 21:34:30,858 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.466, phase=0.860, MS-SSIM: amp=0.585, phase=0.813
Amplitude normalization scale factor: 0.9808352025-07-27 21:34:30,861 - INFO - Amplitude normalization scale factor: 0.980835

mean scale adjustment:2025-07-27 21:34:30,861 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,861 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,861 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,861 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:30,863 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.256699, std=0.000593, shape=(181, 181, 1)2025-07-27 21:34:30,863 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.256699, std=0.000593, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:30,863 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000910, shape=(181, 181)2025-07-27 21:34:30,863 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000910, shape=(181, 181)

performed by index method2025-07-27 21:34:30,866 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,876 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,886 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:30,895 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,895 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,895 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,895 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:30,895 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:30,903 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,913 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,923 - INFO - performed by index method

2025-07-27 21:34:30,932 - INFO - Baseline evaluation complete. SSIM: amp=0.086, phase=0.521, MS-SSIM: amp=0.032, phase=0.030
Amplitude normalization scale factor: 1.7470792025-07-27 21:34:30,935 - INFO - Amplitude normalization scale factor: 1.747079

mean scale adjustment:2025-07-27 21:34:30,935 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,935 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,935 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,935 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:34:30,936 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705529, std=0.071777, shape=(181, 181, 1)2025-07-27 21:34:30,937 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705529, std=0.071777, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:34:30,937 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.174291, shape=(181, 181)2025-07-27 21:34:30,937 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.174291, shape=(181, 181)

performed by index method2025-07-27 21:34:30,940 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,950 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,959 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:34:30,969 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,969 - INFO - 1

mean scale adjustment:2025-07-27 21:34:30,969 - INFO - mean scale adjustment:
 12025-07-27 21:34:30,969 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:34:30,969 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:34:30,977 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,987 - INFO - performed by index method

performed by index method2025-07-27 21:34:30,996 - INFO - performed by index method

2025-07-27 21:34:31,006 - INFO - Tike evaluation complete. SSIM: amp=0.024, phase=0.417, MS-SSIM: amp=0.032, phase=0.025
2025-07-27 21:34:31,007 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_256/trial_2/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:34:31,007 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.082160  0.162306      NaN
PtychoPINN                mse   0.010248  0.038887      NaN
PtychoPINN               psnr  68.024556 62.232720      NaN
PtychoPINN               ssim   0.465850  0.859748      NaN
PtychoPINN            ms_ssim   0.584617  0.812954      NaN
PtychoPINN              frc50   1.000000 29.000000      NaN
  Baseline                mae   0.084970  0.251168      NaN
  Baseline                mse   0.009597  0.082188      NaN
  Baseline               psnr  68.309574 58.982742      NaN
  Baseline               ssim   0.085905  0.521124      NaN
  Baseline            ms_ssim   0.032314  0.029736      NaN
  Baseline              frc50   2.000000  1.000000      NaN
      Tike                mae   0.126272  0.269984      NaN
      Tike                mse   0.025144  0.110662      NaN
      Tike               psnr  64.126498 57.690838      NaN
      Tike               ssim   0.023752  0.416928      NaN
      Tike            ms_ssim   0.032426  0.025042      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.542758
  Baseline computation_time_s        NaN       NaN 2.2572132025-07-27 21:34:31,009 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.082160  0.162306      NaN
PtychoPINN                mse   0.010248  0.038887      NaN
PtychoPINN               psnr  68.024556 62.232720      NaN
PtychoPINN               ssim   0.465850  0.859748      NaN
PtychoPINN            ms_ssim   0.584617  0.812954      NaN
PtychoPINN              frc50   1.000000 29.000000      NaN
  Baseline                mae   0.084970  0.251168      NaN
  Baseline                mse   0.009597  0.082188      NaN
  Baseline               psnr  68.309574 58.982742      NaN
  Baseline               ssim   0.085905  0.521124      NaN
  Baseline            ms_ssim   0.032314  0.029736      NaN
  Baseline              frc50   2.000000  1.000000      NaN
      Tike                mae   0.126272  0.269984      NaN
      Tike                mse   0.025144  0.110662      NaN
      Tike               psnr  64.126498 57.690838      NaN
      Tike               ssim   0.023752  0.416928      NaN
      Tike            ms_ssim   0.032426  0.025042      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.542758
  Baseline computation_time_s        NaN       NaN 2.257213

2025-07-27 21:34:31,009 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_2/pinn_frc_curves.csv
2025-07-27 21:34:31,010 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_2/baseline_frc_curves.csv
2025-07-27 21:34:31,010 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:34:31,088 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_2/reconstructions_aligned.npz
2025-07-27 21:34:31,088 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_2/reconstructions_aligned_metadata.txt
2025-07-27 21:34:31,088 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:34:31,130 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.670, 0.920) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,130 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.256, 1.257) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,131 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (0.221, 1.309) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,132 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.214, -2.211) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,132 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.608, 0.796) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,133 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.266, 0.192) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,143 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:31,144 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:34:32,146 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_256/trial_2/comparison_plot.png
2025-07-27 21:34:32,146 - INFO - 
Comparison complete!
2025-07-27 21:34:32,146 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_256/trial_2
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:34:32,498 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:34:32,498 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:34:32,499 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:34:32] SUCCESS: Model comparison (train_size=256, trial=2)
[2025-07-27 21:34:32] Using test subset size 512 (3-way comparison mode)
[2025-07-27 21:34:32] EXECUTING: Model comparison (train_size=256, trial=3)
[2025-07-27 21:34:32] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_256/trial_3' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_256/trial_3/tike_run/tike_reconstruction.npz' --n-test-images 512
2025-07-27 21:34:33.378828: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:34:33.378857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:34:33.379685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:34:33.383824: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:34:33.880035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:34:34.731717: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:34.764720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:34.766695: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:34:35.034674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.036915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.039032: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.143753: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.144984: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.146216: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:34:35.146349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:34:35.147582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:34:35,176 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:34:35,176 - INFO - Registration: disabled
2025-07-27 21:34:35,176 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:34:35,176 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:34:35,176 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=512
2025-07-27 21:34:35,249 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:34:35,249 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:34:35,249 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:34:35,249 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:34:35,249 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:34:35,249 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:34:35,249 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:34:35,249 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:34:35,249 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:34:35,249 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:34:35,249 - INFO - DEBUG:
 nsamples:2025-07-27 21:34:35,249 - INFO - nsamples:
 103042025-07-27 21:34:35,249 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:34:35,250 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:34:35,272 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

neighbor-sampled diffraction shape2025-07-27 21:34:51,681 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:34:51,681 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:34:51,905 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:34:52,266 - INFO - INFO:
 None2025-07-27 21:34:52,266 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:34:52,267 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:34:52,268 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_256/trial_3/pinn_run...
input shape2025-07-27 21:34:52,916 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:52,916 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:34:52,927 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:34:53,040 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:34:53,040 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:34:53,040 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:34:53,040 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:34:53,040 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:34:53,040 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:34:53,040 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:34:53,040 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:34:53,040 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:34:53,041 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:34:53,041 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:34:53,041 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:34:53,041 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:34:53,041 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,041 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:34:53,041 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:34:53,041 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:34:53,041 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,041 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:34:53,041 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:34:53,041 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:34:53,041 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:34:53,041 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:34:53,041 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:34:53,041 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:34:53,042 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,042 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:34:53,042 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:34:53,042 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:34:53,042 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:34:53,042 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:34:53,042 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,042 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:34:53,042 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,042 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:34:53,042 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:53,042 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:34:53,042 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:53,042 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:34:53,042 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:34:53,042 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:34:53,042 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:34:53,042 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:34:53,043 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:34:53,043 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:34:53,043 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,043 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:34:53,043 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,043 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:34:53,043 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:34:53,043 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:34:53,043 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:34:53,043 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:34:53,043 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:53,043 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:34:53,043 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:34:53,043 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:34:53,043 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:53,043 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:34:53,043 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:53,043 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:34:53,043 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:34:53,043 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:34:53,044 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:34:53,044 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:34:53,044 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:34:53,044 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:34:53,044 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:34:53,044 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:34:53,044 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:34:53,044 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:34:53,044 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:34:53,044 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:34:53,044 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:34:53,044 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:34:53,044 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:34:53,044 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:34:53,044 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:34:53,044 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:34:53,044 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:34:53,044 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:34:53,044 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:53,044 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:34:53,044 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:34:53,045 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:34:53,045 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:34:53,045 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:34:53,045 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:34:53,045 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:34:53,045 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:34:53,045 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:34:53,045 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:34:53,045 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:34:53,045 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:34:53,045 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:34:53,045 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:34:53,045 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:34:53,045 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:34:53,045 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:34:53,045 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:34:53,045 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:34:53,045 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:34:53,045 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:34:53,045 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:34:53,045 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:34:53,046 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:34:53,046 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:34:53,046 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:34:53,046 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:34:53,046 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:34:53,046 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:34:53,046 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:34:53,046 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:34:53,046 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:34:53,046 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:34:53,047 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:34:53,047 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:34:53,047 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:34:53,047 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:34:53,047 - INFO - None

2025-07-27 21:34:53.047857: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:34:53.047871: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:34:53.047894: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:34:53.064597: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:34:53.064679: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:34:53,454 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:53,454 - INFO - (None, 64, 64, 1)

2025-07-27 21:34:53.480921: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp7mr12lg1/autoencoder: FAILED_PRECONDITION: /tmp/tmp7mr12lg1/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:34:53,775 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:34:53,775 - INFO - (None, 64, 64, 1)

2025-07-27 21:34:53.800433: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp7mr12lg1/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmp7mr12lg1/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:34:53,834 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1...
2025-07-27 21:34:53,834 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_run/07-27-2025-21.12.03_baseline_gs1/baseline_model.h5
2025-07-27 21:34:54,099 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_256/trial_3/tike_run/tike_reconstruction.npz...
2025-07-27 21:34:54,102 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:34:54,102 - INFO - Loaded Tike reconstruction: (358, 358) (complex64)
2025-07-27 21:34:54,102 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:34:54,102 - INFO - Running inference with PtychoPINN...
2025-07-27 21:34:54.490507: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:122025-07-27 21:34:54,995 - INFO - 1/322 [..............................] - ETA: 4:12
 14/322 [>.............................] - ETA: 1s  2025-07-27 21:34:55,049 - INFO -  14/322 [>.............................] - ETA: 1s
 26/322 [=>............................] - ETA: 1s2025-07-27 21:34:55,101 - INFO -  26/322 [=>............................] - ETA: 1s
 38/322 [==>...........................] - ETA: 1s2025-07-27 21:34:55,152 - INFO -  38/322 [==>...........................] - ETA: 1s
 50/322 [===>..........................] - ETA: 1s2025-07-27 21:34:55,204 - INFO -  50/322 [===>..........................] - ETA: 1s
 62/322 [====>.........................] - ETA: 1s2025-07-27 21:34:55,255 - INFO -  62/322 [====>.........................] - ETA: 1s
 74/322 [=====>........................] - ETA: 1s2025-07-27 21:34:55,306 - INFO -  74/322 [=====>........................] - ETA: 1s
 86/322 [=======>......................] - ETA: 1s2025-07-27 21:34:55,356 - INFO -  86/322 [=======>......................] - ETA: 1s
 98/322 [========>.....................] - ETA: 0s2025-07-27 21:34:55,407 - INFO -  98/322 [========>.....................] - ETA: 0s
110/322 [=========>....................] - ETA: 0s2025-07-27 21:34:55,457 - INFO - 110/322 [=========>....................] - ETA: 0s
123/322 [==========>...................] - ETA: 0s2025-07-27 21:34:55,511 - INFO - 123/322 [==========>...................] - ETA: 0s
135/322 [===========>..................] - ETA: 0s2025-07-27 21:34:55,561 - INFO - 135/322 [===========>..................] - ETA: 0s
147/322 [============>.................] - ETA: 0s2025-07-27 21:34:55,611 - INFO - 147/322 [============>.................] - ETA: 0s
160/322 [=============>................] - ETA: 0s2025-07-27 21:34:55,665 - INFO - 160/322 [=============>................] - ETA: 0s
173/322 [===============>..............] - ETA: 0s2025-07-27 21:34:55,718 - INFO - 173/322 [===============>..............] - ETA: 0s
186/322 [================>.............] - ETA: 0s2025-07-27 21:34:55,772 - INFO - 186/322 [================>.............] - ETA: 0s
199/322 [=================>............] - ETA: 0s2025-07-27 21:34:55,826 - INFO - 199/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:34:55,880 - INFO - 212/322 [==================>...........] - ETA: 0s
225/322 [===================>..........] - ETA: 0s2025-07-27 21:34:55,933 - INFO - 225/322 [===================>..........] - ETA: 0s
238/322 [=====================>........] - ETA: 0s2025-07-27 21:34:55,987 - INFO - 238/322 [=====================>........] - ETA: 0s
251/322 [======================>.......] - ETA: 0s2025-07-27 21:34:56,040 - INFO - 251/322 [======================>.......] - ETA: 0s
264/322 [=======================>......] - ETA: 0s2025-07-27 21:34:56,093 - INFO - 264/322 [=======================>......] - ETA: 0s
277/322 [========================>.....] - ETA: 0s2025-07-27 21:34:56,147 - INFO - 277/322 [========================>.....] - ETA: 0s
290/322 [==========================>...] - ETA: 0s2025-07-27 21:34:56,201 - INFO - 290/322 [==========================>...] - ETA: 0s
303/322 [===========================>..] - ETA: 0s2025-07-27 21:34:56,255 - INFO - 303/322 [===========================>..] - ETA: 0s
316/322 [============================>.] - ETA: 0s2025-07-27 21:34:56,308 - INFO - 316/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:34:56,333 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:34:56,641 - INFO - PtychoPINN inference completed in 2.54s
2025-07-27 21:34:56,641 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:34:58,023 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 44s2025-07-27 21:34:58,263 - INFO - 1/322 [..............................] - ETA: 44s
 12/322 [>.............................] - ETA: 1s 2025-07-27 21:34:58,318 - INFO -  12/322 [>.............................] - ETA: 1s
 22/322 [=>............................] - ETA: 1s2025-07-27 21:34:58,370 - INFO -  22/322 [=>............................] - ETA: 1s
 32/322 [=>............................] - ETA: 1s2025-07-27 21:34:58,422 - INFO -  32/322 [=>............................] - ETA: 1s
 42/322 [==>...........................] - ETA: 1s2025-07-27 21:34:58,474 - INFO -  42/322 [==>...........................] - ETA: 1s
 52/322 [===>..........................] - ETA: 1s2025-07-27 21:34:58,526 - INFO -  52/322 [===>..........................] - ETA: 1s
 62/322 [====>.........................] - ETA: 1s2025-07-27 21:34:58,578 - INFO -  62/322 [====>.........................] - ETA: 1s
 72/322 [=====>........................] - ETA: 1s2025-07-27 21:34:58,630 - INFO -  72/322 [=====>........................] - ETA: 1s
 82/322 [======>.......................] - ETA: 1s2025-07-27 21:34:58,682 - INFO -  82/322 [======>.......................] - ETA: 1s
 92/322 [=======>......................] - ETA: 1s2025-07-27 21:34:58,734 - INFO -  92/322 [=======>......................] - ETA: 1s
102/322 [========>.....................] - ETA: 1s2025-07-27 21:34:58,786 - INFO - 102/322 [========>.....................] - ETA: 1s
112/322 [=========>....................] - ETA: 1s2025-07-27 21:34:58,838 - INFO - 112/322 [=========>....................] - ETA: 1s
122/322 [==========>...................] - ETA: 1s2025-07-27 21:34:58,890 - INFO - 122/322 [==========>...................] - ETA: 1s
132/322 [===========>..................] - ETA: 0s2025-07-27 21:34:58,942 - INFO - 132/322 [===========>..................] - ETA: 0s
142/322 [============>.................] - ETA: 0s2025-07-27 21:34:58,994 - INFO - 142/322 [============>.................] - ETA: 0s
152/322 [=============>................] - ETA: 0s2025-07-27 21:34:59,046 - INFO - 152/322 [=============>................] - ETA: 0s
162/322 [==============>...............] - ETA: 0s2025-07-27 21:34:59,098 - INFO - 162/322 [==============>...............] - ETA: 0s
172/322 [===============>..............] - ETA: 0s2025-07-27 21:34:59,150 - INFO - 172/322 [===============>..............] - ETA: 0s
182/322 [===============>..............] - ETA: 0s2025-07-27 21:34:59,203 - INFO - 182/322 [===============>..............] - ETA: 0s
192/322 [================>.............] - ETA: 0s2025-07-27 21:34:59,255 - INFO - 192/322 [================>.............] - ETA: 0s
202/322 [=================>............] - ETA: 0s2025-07-27 21:34:59,307 - INFO - 202/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:34:59,360 - INFO - 212/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:34:59,412 - INFO - 222/322 [===================>..........] - ETA: 0s
232/322 [====================>.........] - ETA: 0s2025-07-27 21:34:59,464 - INFO - 232/322 [====================>.........] - ETA: 0s
242/322 [=====================>........] - ETA: 0s2025-07-27 21:34:59,516 - INFO - 242/322 [=====================>........] - ETA: 0s
252/322 [======================>.......] - ETA: 0s2025-07-27 21:34:59,568 - INFO - 252/322 [======================>.......] - ETA: 0s
262/322 [=======================>......] - ETA: 0s2025-07-27 21:34:59,620 - INFO - 262/322 [=======================>......] - ETA: 0s
272/322 [========================>.....] - ETA: 0s2025-07-27 21:34:59,672 - INFO - 272/322 [========================>.....] - ETA: 0s
282/322 [=========================>....] - ETA: 0s2025-07-27 21:34:59,723 - INFO - 282/322 [=========================>....] - ETA: 0s
292/322 [==========================>...] - ETA: 0s2025-07-27 21:34:59,775 - INFO - 292/322 [==========================>...] - ETA: 0s
302/322 [===========================>..] - ETA: 0s2025-07-27 21:34:59,829 - INFO - 302/322 [===========================>..] - ETA: 0s
312/322 [============================>.] - ETA: 0s2025-07-27 21:34:59,881 - INFO - 312/322 [============================>.] - ETA: 0s
322/322 [==============================] - ETA: 0s2025-07-27 21:34:59,934 - INFO - 322/322 [==============================] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:34:59,934 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:35:00,283 - INFO - Baseline inference completed in 2.26s
2025-07-27 21:35:00,738 - INFO - Reassembling baseline patches...
2025-07-27 21:35:00,835 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:35:00,894 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_3/reconstructions.npz
2025-07-27 21:35:00,894 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_3/reconstructions_metadata.txt
2025-07-27 21:35:00,894 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:35:00,894 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:35:00,894 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:35:00,894 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:00,895 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:00,895 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:35:00,895 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:35:00,895 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:00,895 - INFO - --- Alignment complete ---
2025-07-27 21:35:00,895 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:00,895 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:00,895 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:35:00,895 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:35:00,895 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:00,895 - INFO - --- Alignment complete ---
2025-07-27 21:35:00,895 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:00,895 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:00,895 - INFO - Initial shapes: Recon=(358, 358), Cropped GT=(185, 185)
2025-07-27 21:35:00,895 - INFO - Center-cropping from (358, 358) to (185, 185)
2025-07-27 21:35:00,895 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:00,895 - INFO - --- Alignment complete ---
2025-07-27 21:35:00,895 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:35:00,895 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.5218692025-07-27 21:35:00,900 - INFO - Amplitude normalization scale factor: 1.521869

mean scale adjustment:2025-07-27 21:35:00,900 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,900 - INFO - 1

mean scale adjustment:2025-07-27 21:35:00,900 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,900 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:00,918 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.809935, std=0.100141, shape=(181, 181, 1)2025-07-27 21:35:00,918 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.809935, std=0.100141, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:00,918 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.388270, shape=(181, 181)2025-07-27 21:35:00,918 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.388270, shape=(181, 181)

performed by index method2025-07-27 21:35:00,922 - INFO - performed by index method

performed by index method2025-07-27 21:35:00,932 - INFO - performed by index method

performed by index method2025-07-27 21:35:00,942 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:00,951 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,951 - INFO - 1

mean scale adjustment:2025-07-27 21:35:00,951 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,951 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:00,951 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:00,960 - INFO - performed by index method

performed by index method2025-07-27 21:35:00,969 - INFO - performed by index method

performed by index method2025-07-27 21:35:00,979 - INFO - performed by index method

2025-07-27 21:35:00,988 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.489, phase=0.868, MS-SSIM: amp=0.625, phase=0.824
Amplitude normalization scale factor: 0.9683852025-07-27 21:35:00,992 - INFO - Amplitude normalization scale factor: 0.968385

mean scale adjustment:2025-07-27 21:35:00,992 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,992 - INFO - 1

mean scale adjustment:2025-07-27 21:35:00,992 - INFO - mean scale adjustment:
 12025-07-27 21:35:00,992 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:00,993 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.272857, std=0.000000, shape=(181, 181, 1)2025-07-27 21:35:00,993 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.272857, std=0.000000, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:00,993 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)2025-07-27 21:35:00,993 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)

performed by index method2025-07-27 21:35:00,997 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,006 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,016 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:01,025 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,025 - INFO - 1

mean scale adjustment:2025-07-27 21:35:01,026 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,026 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:01,026 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:01,034 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,043 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,053 - INFO - performed by index method

2025-07-27 21:35:01,062 - INFO - Baseline evaluation complete. SSIM: amp=0.086, phase=0.521, MS-SSIM: amp=0.031, phase=0.029
Amplitude normalization scale factor: 1.7471792025-07-27 21:35:01,066 - INFO - Amplitude normalization scale factor: 1.747179

mean scale adjustment:2025-07-27 21:35:01,066 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,066 - INFO - 1

mean scale adjustment:2025-07-27 21:35:01,066 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,066 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:01,067 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705489, std=0.071758, shape=(181, 181, 1)2025-07-27 21:35:01,067 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.705489, std=0.071758, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:01,067 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.173333, shape=(181, 181)2025-07-27 21:35:01,067 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.173333, shape=(181, 181)

performed by index method2025-07-27 21:35:01,070 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,080 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,090 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:01,100 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,100 - INFO - 1

mean scale adjustment:2025-07-27 21:35:01,100 - INFO - mean scale adjustment:
 12025-07-27 21:35:01,100 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:01,100 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:01,108 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,118 - INFO - performed by index method

performed by index method2025-07-27 21:35:01,127 - INFO - performed by index method

2025-07-27 21:35:01,137 - INFO - Tike evaluation complete. SSIM: amp=0.024, phase=0.418, MS-SSIM: amp=0.033, phase=0.027
2025-07-27 21:35:01,138 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_256/trial_3/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:35:01,138 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.086091  0.149852      NaN
PtychoPINN                mse   0.011399  0.034076      NaN
PtychoPINN               psnr  67.562309 62.806301      NaN
PtychoPINN               ssim   0.489137  0.868452      NaN
PtychoPINN            ms_ssim   0.624975  0.824301      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082235      NaN
  Baseline               psnr  68.305418 58.980249      NaN
  Baseline               ssim   0.085873  0.520955      NaN
  Baseline            ms_ssim   0.031282  0.028860      NaN
  Baseline              frc50   2.000000  2.000000      NaN
      Tike                mae   0.126278  0.269732      NaN
      Tike                mse   0.025158  0.110304      NaN
      Tike               psnr  64.124114 57.704893      NaN
      Tike               ssim   0.024041  0.417885      NaN
      Tike            ms_ssim   0.032610  0.026534      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.539304
  Baseline computation_time_s        NaN       NaN 2.2598682025-07-27 21:35:01,140 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.086091  0.149852      NaN
PtychoPINN                mse   0.011399  0.034076      NaN
PtychoPINN               psnr  67.562309 62.806301      NaN
PtychoPINN               ssim   0.489137  0.868452      NaN
PtychoPINN            ms_ssim   0.624975  0.824301      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082235      NaN
  Baseline               psnr  68.305418 58.980249      NaN
  Baseline               ssim   0.085873  0.520955      NaN
  Baseline            ms_ssim   0.031282  0.028860      NaN
  Baseline              frc50   2.000000  2.000000      NaN
      Tike                mae   0.126278  0.269732      NaN
      Tike                mse   0.025158  0.110304      NaN
      Tike               psnr  64.124114 57.704893      NaN
      Tike               ssim   0.024041  0.417885      NaN
      Tike            ms_ssim   0.032610  0.026534      NaN
      Tike              frc50   1.000000  3.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.539304
  Baseline computation_time_s        NaN       NaN 2.259868

2025-07-27 21:35:01,141 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_3/pinn_frc_curves.csv
2025-07-27 21:35:01,142 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_256/trial_3/baseline_frc_curves.csv
2025-07-27 21:35:01,142 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:35:01,189 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_256/trial_3/reconstructions_aligned.npz
2025-07-27 21:35:01,189 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_256/trial_3/reconstructions_aligned_metadata.txt
2025-07-27 21:35:01,189 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:35:01,232 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.658, 0.936) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,232 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.273, 1.273) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,233 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (0.024, 1.078) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,234 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.233, -2.233) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,234 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.609, 0.796) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,235 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.264, 0.190) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,245 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,246 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:01,916 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_256/trial_3/comparison_plot.png
2025-07-27 21:35:01,916 - INFO - 
Comparison complete!
2025-07-27 21:35:01,916 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_256/trial_3
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:35:02,263 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:35:02,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:35:02,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:35:02] SUCCESS: Model comparison (train_size=256, trial=3)
[2025-07-27 21:35:02] Completed comparisons for train_size=256
[2025-07-27 21:35:02] Running comparisons for train_size=2048, test_size=4096 (3 trials)
[2025-07-27 21:35:02] Using test subset size 4096 (3-way comparison mode)
[2025-07-27 21:35:02] EXECUTING: Model comparison (train_size=2048, trial=1)
[2025-07-27 21:35:02] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_1' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_2048/trial_1/tike_run/tike_reconstruction.npz' --n-test-images 4096
2025-07-27 21:35:03.143897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:35:03.143930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:35:03.144767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:35:03.148888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:35:03.654826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:35:04.519786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.553132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.555096: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:35:04.822576: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.824822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.826919: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.930763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.931993: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.933102: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:35:04.933236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:04.934377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:35:04,963 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:35:04,963 - INFO - Registration: disabled
2025-07-27 21:35:04,963 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:35:04,963 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:35:04,963 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=4096
2025-07-27 21:35:05,036 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:35:05,036 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:35:05,036 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:35:05,036 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:35:05,036 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:35:05,036 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:35:05,036 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:35:05,036 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:35:05,036 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:35:05,036 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:35:05,036 - INFO - DEBUG:
 nsamples:2025-07-27 21:35:05,036 - INFO - nsamples:
 103042025-07-27 21:35:05,036 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:35:05,036 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:35:05,058 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

neighbor-sampled diffraction shape2025-07-27 21:35:21,729 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:35:21,729 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:35:21,952 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:35:22,316 - INFO - INFO:
 None2025-07-27 21:35:22,316 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:35:22,316 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:35:22,317 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_run...
input shape2025-07-27 21:35:22,957 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:22,957 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:35:22,968 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:35:23,081 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:35:23,081 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:35:23,081 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:35:23,081 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:35:23,081 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:35:23,081 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:35:23,081 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:35:23,081 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:35:23,081 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:35:23,081 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:35:23,081 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:35:23,081 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:35:23,081 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:35:23,082 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,082 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:35:23,082 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:35:23,082 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:35:23,082 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,082 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:35:23,082 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:35:23,082 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:35:23,082 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:35:23,082 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:35:23,082 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:35:23,082 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:35:23,082 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,082 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:35:23,082 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:35:23,082 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:35:23,083 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:35:23,083 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:35:23,083 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,083 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:35:23,083 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,083 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:35:23,083 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:23,083 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:35:23,083 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:23,083 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:35:23,083 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:35:23,083 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:35:23,083 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:35:23,083 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:35:23,083 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:35:23,084 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:35:23,084 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,084 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:35:23,084 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,084 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:35:23,084 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:35:23,084 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:35:23,084 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:35:23,084 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:35:23,084 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:23,084 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:35:23,084 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:35:23,084 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:35:23,084 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:23,084 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:35:23,084 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:23,084 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:35:23,084 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:35:23,084 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:35:23,084 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:35:23,084 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:35:23,085 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:23,085 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:35:23,085 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:35:23,085 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:35:23,085 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:35:23,085 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:35:23,085 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:23,085 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:35:23,085 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:35:23,085 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:35:23,085 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:35:23,085 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:35:23,085 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:35:23,085 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:35:23,085 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:35:23,085 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:35:23,085 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:23,085 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:35:23,085 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:35:23,086 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:35:23,086 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:35:23,086 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:35:23,086 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:35:23,086 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:35:23,086 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:35:23,086 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:35:23,086 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:35:23,086 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:35:23,086 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:35:23,086 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:35:23,086 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:35:23,086 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:35:23,086 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:35:23,086 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:35:23,086 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:35:23,086 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:35:23,086 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:35:23,086 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:35:23,086 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:35:23,087 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:35:23,087 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:35:23,087 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:35:23,087 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:35:23,087 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:35:23,087 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:23,087 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:35:23,087 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:35:23,087 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:35:23,087 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:35:23,087 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:35:23,088 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:35:23,088 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:35:23,088 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:35:23,088 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:35:23,088 - INFO - None

2025-07-27 21:35:23.088896: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:35:23.088911: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:35:23.088934: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:35:23.105839: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:35:23.105913: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:35:23,501 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:23,501 - INFO - (None, 64, 64, 1)

2025-07-27 21:35:23.528497: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp9pke35vr/autoencoder: FAILED_PRECONDITION: /tmp/tmp9pke35vr/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:35:23,827 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:23,827 - INFO - (None, 64, 64, 1)

2025-07-27 21:35:23.852569: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp9pke35vr/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmp9pke35vr/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:35:23,887 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1...
2025-07-27 21:35:23,887 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_run/07-27-2025-21.15.15_baseline_gs1/baseline_model.h5
2025-07-27 21:35:24,149 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_2048/trial_1/tike_run/tike_reconstruction.npz...
2025-07-27 21:35:24,151 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:35:24,151 - INFO - Loaded Tike reconstruction: (359, 359) (complex64)
2025-07-27 21:35:24,151 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:35:24,151 - INFO - Running inference with PtychoPINN...
2025-07-27 21:35:24.539235: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:112025-07-27 21:35:25,043 - INFO - 1/322 [..............................] - ETA: 4:11
 13/322 [>.............................] - ETA: 1s  2025-07-27 21:35:25,094 - INFO -  13/322 [>.............................] - ETA: 1s
 25/322 [=>............................] - ETA: 1s2025-07-27 21:35:25,145 - INFO -  25/322 [=>............................] - ETA: 1s
 37/322 [==>...........................] - ETA: 1s2025-07-27 21:35:25,196 - INFO -  37/322 [==>...........................] - ETA: 1s
 49/322 [===>..........................] - ETA: 1s2025-07-27 21:35:25,247 - INFO -  49/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:35:25,298 - INFO -  61/322 [====>.........................] - ETA: 1s
 73/322 [=====>........................] - ETA: 1s2025-07-27 21:35:25,348 - INFO -  73/322 [=====>........................] - ETA: 1s
 85/322 [======>.......................] - ETA: 1s2025-07-27 21:35:25,399 - INFO -  85/322 [======>.......................] - ETA: 1s
 97/322 [========>.....................] - ETA: 0s2025-07-27 21:35:25,450 - INFO -  97/322 [========>.....................] - ETA: 0s
109/322 [=========>....................] - ETA: 0s2025-07-27 21:35:25,500 - INFO - 109/322 [=========>....................] - ETA: 0s
121/322 [==========>...................] - ETA: 0s2025-07-27 21:35:25,550 - INFO - 121/322 [==========>...................] - ETA: 0s
133/322 [===========>..................] - ETA: 0s2025-07-27 21:35:25,600 - INFO - 133/322 [===========>..................] - ETA: 0s
146/322 [============>.................] - ETA: 0s2025-07-27 21:35:25,654 - INFO - 146/322 [============>.................] - ETA: 0s
158/322 [=============>................] - ETA: 0s2025-07-27 21:35:25,704 - INFO - 158/322 [=============>................] - ETA: 0s
170/322 [==============>...............] - ETA: 0s2025-07-27 21:35:25,754 - INFO - 170/322 [==============>...............] - ETA: 0s
183/322 [================>.............] - ETA: 0s2025-07-27 21:35:25,808 - INFO - 183/322 [================>.............] - ETA: 0s
196/322 [=================>............] - ETA: 0s2025-07-27 21:35:25,861 - INFO - 196/322 [=================>............] - ETA: 0s
209/322 [==================>...........] - ETA: 0s2025-07-27 21:35:25,914 - INFO - 209/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:35:25,968 - INFO - 222/322 [===================>..........] - ETA: 0s
235/322 [====================>.........] - ETA: 0s2025-07-27 21:35:26,021 - INFO - 235/322 [====================>.........] - ETA: 0s
248/322 [======================>.......] - ETA: 0s2025-07-27 21:35:26,075 - INFO - 248/322 [======================>.......] - ETA: 0s
261/322 [=======================>......] - ETA: 0s2025-07-27 21:35:26,128 - INFO - 261/322 [=======================>......] - ETA: 0s
274/322 [========================>.....] - ETA: 0s2025-07-27 21:35:26,181 - INFO - 274/322 [========================>.....] - ETA: 0s
287/322 [=========================>....] - ETA: 0s2025-07-27 21:35:26,235 - INFO - 287/322 [=========================>....] - ETA: 0s
300/322 [==========================>...] - ETA: 0s2025-07-27 21:35:26,288 - INFO - 300/322 [==========================>...] - ETA: 0s
313/322 [============================>.] - ETA: 0s2025-07-27 21:35:26,341 - INFO - 313/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:35:26,378 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:35:26,691 - INFO - PtychoPINN inference completed in 2.54s
2025-07-27 21:35:26,691 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:35:28,040 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 43s2025-07-27 21:35:28,276 - INFO - 1/322 [..............................] - ETA: 43s
 12/322 [>.............................] - ETA: 1s 2025-07-27 21:35:28,331 - INFO -  12/322 [>.............................] - ETA: 1s
 22/322 [=>............................] - ETA: 1s2025-07-27 21:35:28,383 - INFO -  22/322 [=>............................] - ETA: 1s
 32/322 [=>............................] - ETA: 1s2025-07-27 21:35:28,435 - INFO -  32/322 [=>............................] - ETA: 1s
 42/322 [==>...........................] - ETA: 1s2025-07-27 21:35:28,487 - INFO -  42/322 [==>...........................] - ETA: 1s
 52/322 [===>..........................] - ETA: 1s2025-07-27 21:35:28,539 - INFO -  52/322 [===>..........................] - ETA: 1s
 62/322 [====>.........................] - ETA: 1s2025-07-27 21:35:28,591 - INFO -  62/322 [====>.........................] - ETA: 1s
 72/322 [=====>........................] - ETA: 1s2025-07-27 21:35:28,642 - INFO -  72/322 [=====>........................] - ETA: 1s
 82/322 [======>.......................] - ETA: 1s2025-07-27 21:35:28,694 - INFO -  82/322 [======>.......................] - ETA: 1s
 92/322 [=======>......................] - ETA: 1s2025-07-27 21:35:28,746 - INFO -  92/322 [=======>......................] - ETA: 1s
102/322 [========>.....................] - ETA: 1s2025-07-27 21:35:28,798 - INFO - 102/322 [========>.....................] - ETA: 1s
112/322 [=========>....................] - ETA: 1s2025-07-27 21:35:28,852 - INFO - 112/322 [=========>....................] - ETA: 1s
122/322 [==========>...................] - ETA: 1s2025-07-27 21:35:28,906 - INFO - 122/322 [==========>...................] - ETA: 1s
132/322 [===========>..................] - ETA: 0s2025-07-27 21:35:28,960 - INFO - 132/322 [===========>..................] - ETA: 0s
142/322 [============>.................] - ETA: 0s2025-07-27 21:35:29,014 - INFO - 142/322 [============>.................] - ETA: 0s
152/322 [=============>................] - ETA: 0s2025-07-27 21:35:29,068 - INFO - 152/322 [=============>................] - ETA: 0s
162/322 [==============>...............] - ETA: 0s2025-07-27 21:35:29,121 - INFO - 162/322 [==============>...............] - ETA: 0s
172/322 [===============>..............] - ETA: 0s2025-07-27 21:35:29,173 - INFO - 172/322 [===============>..............] - ETA: 0s
182/322 [===============>..............] - ETA: 0s2025-07-27 21:35:29,225 - INFO - 182/322 [===============>..............] - ETA: 0s
192/322 [================>.............] - ETA: 0s2025-07-27 21:35:29,276 - INFO - 192/322 [================>.............] - ETA: 0s
202/322 [=================>............] - ETA: 0s2025-07-27 21:35:29,328 - INFO - 202/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:35:29,380 - INFO - 212/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:35:29,432 - INFO - 222/322 [===================>..........] - ETA: 0s
232/322 [====================>.........] - ETA: 0s2025-07-27 21:35:29,483 - INFO - 232/322 [====================>.........] - ETA: 0s
242/322 [=====================>........] - ETA: 0s2025-07-27 21:35:29,535 - INFO - 242/322 [=====================>........] - ETA: 0s
252/322 [======================>.......] - ETA: 0s2025-07-27 21:35:29,587 - INFO - 252/322 [======================>.......] - ETA: 0s
262/322 [=======================>......] - ETA: 0s2025-07-27 21:35:29,638 - INFO - 262/322 [=======================>......] - ETA: 0s
272/322 [========================>.....] - ETA: 0s2025-07-27 21:35:29,690 - INFO - 272/322 [========================>.....] - ETA: 0s
282/322 [=========================>....] - ETA: 0s2025-07-27 21:35:29,741 - INFO - 282/322 [=========================>....] - ETA: 0s
292/322 [==========================>...] - ETA: 0s2025-07-27 21:35:29,792 - INFO - 292/322 [==========================>...] - ETA: 0s
302/322 [===========================>..] - ETA: 0s2025-07-27 21:35:29,843 - INFO - 302/322 [===========================>..] - ETA: 0s
312/322 [============================>.] - ETA: 0s2025-07-27 21:35:29,894 - INFO - 312/322 [============================>.] - ETA: 0s
322/322 [==============================] - ETA: 0s2025-07-27 21:35:29,945 - INFO - 322/322 [==============================] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:35:29,945 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:35:30,293 - INFO - Baseline inference completed in 2.25s
2025-07-27 21:35:30,730 - INFO - Reassembling baseline patches...
2025-07-27 21:35:30,826 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:35:30,889 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/reconstructions.npz
2025-07-27 21:35:30,889 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/reconstructions_metadata.txt
2025-07-27 21:35:30,889 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:35:30,889 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:35:30,889 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:35:30,889 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:30,889 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:30,889 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:35:30,889 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:35:30,889 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:30,889 - INFO - --- Alignment complete ---
2025-07-27 21:35:30,889 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:30,889 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:30,889 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:35:30,889 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:35:30,889 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:30,889 - INFO - --- Alignment complete ---
2025-07-27 21:35:30,889 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:35:30,890 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:35:30,890 - INFO - Initial shapes: Recon=(359, 359), Cropped GT=(185, 185)
2025-07-27 21:35:30,890 - INFO - Center-cropping from (359, 359) to (185, 185)
2025-07-27 21:35:30,890 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:35:30,890 - INFO - --- Alignment complete ---
2025-07-27 21:35:30,890 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:35:30,890 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.5371522025-07-27 21:35:30,895 - INFO - Amplitude normalization scale factor: 1.537152

mean scale adjustment:2025-07-27 21:35:30,895 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,895 - INFO - 1

mean scale adjustment:2025-07-27 21:35:30,895 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,895 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:30,913 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.801882, std=0.091043, shape=(181, 181, 1)2025-07-27 21:35:30,914 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.801882, std=0.091043, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:30,914 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.416951, shape=(181, 181)2025-07-27 21:35:30,914 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.416951, shape=(181, 181)

performed by index method2025-07-27 21:35:30,918 - INFO - performed by index method

performed by index method2025-07-27 21:35:30,927 - INFO - performed by index method

performed by index method2025-07-27 21:35:30,937 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:30,946 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,946 - INFO - 1

mean scale adjustment:2025-07-27 21:35:30,947 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,947 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:30,947 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:30,955 - INFO - performed by index method

performed by index method2025-07-27 21:35:30,965 - INFO - performed by index method

performed by index method2025-07-27 21:35:30,974 - INFO - performed by index method

2025-07-27 21:35:30,984 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.538, phase=0.882, MS-SSIM: amp=0.701, phase=0.836
Amplitude normalization scale factor: 1.0053932025-07-27 21:35:30,987 - INFO - Amplitude normalization scale factor: 1.005393

mean scale adjustment:2025-07-27 21:35:30,987 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,987 - INFO - 1

mean scale adjustment:2025-07-27 21:35:30,987 - INFO - mean scale adjustment:
 12025-07-27 21:35:30,987 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:30,988 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.226004, std=0.085327, shape=(181, 181, 1)2025-07-27 21:35:30,988 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.226004, std=0.085327, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:30,988 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.256054, shape=(181, 181)2025-07-27 21:35:30,988 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.256054, shape=(181, 181)

performed by index method2025-07-27 21:35:30,992 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,001 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,011 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:31,021 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,021 - INFO - 1

mean scale adjustment:2025-07-27 21:35:31,021 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,021 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:31,021 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:31,029 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,038 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,048 - INFO - performed by index method

2025-07-27 21:35:31,058 - INFO - Baseline evaluation complete. SSIM: amp=0.697, phase=0.899, MS-SSIM: amp=0.853, phase=0.849
Amplitude normalization scale factor: 1.7514282025-07-27 21:35:31,061 - INFO - Amplitude normalization scale factor: 1.751428

mean scale adjustment:2025-07-27 21:35:31,061 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,061 - INFO - 1

mean scale adjustment:2025-07-27 21:35:31,061 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,061 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:35:31,062 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703777, std=0.059597, shape=(181, 181, 1)2025-07-27 21:35:31,062 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703777, std=0.059597, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:35:31,063 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.282622, shape=(181, 181)2025-07-27 21:35:31,063 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.282622, shape=(181, 181)

performed by index method2025-07-27 21:35:31,066 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,075 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,085 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:35:31,095 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,095 - INFO - 1

mean scale adjustment:2025-07-27 21:35:31,095 - INFO - mean scale adjustment:
 12025-07-27 21:35:31,095 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:35:31,095 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:35:31,103 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,113 - INFO - performed by index method

performed by index method2025-07-27 21:35:31,123 - INFO - performed by index method

2025-07-27 21:35:31,132 - INFO - Tike evaluation complete. SSIM: amp=0.680, phase=0.895, MS-SSIM: amp=0.857, phase=0.861
2025-07-27 21:35:31,133 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:35:31,133 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.074776  0.162615      NaN
PtychoPINN                mse   0.008677  0.039524      NaN
PtychoPINN               psnr  68.747314 62.162147      NaN
PtychoPINN               ssim   0.537850  0.881527      NaN
PtychoPINN            ms_ssim   0.700622  0.835515      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.037122  0.092450      NaN
  Baseline                mse   0.002361  0.015761      NaN
  Baseline               psnr  74.399825 66.155012      NaN
  Baseline               ssim   0.696682  0.898661      NaN
  Baseline            ms_ssim   0.853237  0.848620      NaN
  Baseline              frc50  24.000000 40.000000      NaN
      Tike                mae   0.047244  0.092270      NaN
      Tike                mse   0.003857  0.017427      NaN
      Tike               psnr  72.268158 65.718551      NaN
      Tike               ssim   0.679777  0.894626      NaN
      Tike            ms_ssim   0.856852  0.860953      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.539588
  Baseline computation_time_s        NaN       NaN 2.2525142025-07-27 21:35:31,135 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.074776  0.162615      NaN
PtychoPINN                mse   0.008677  0.039524      NaN
PtychoPINN               psnr  68.747314 62.162147      NaN
PtychoPINN               ssim   0.537850  0.881527      NaN
PtychoPINN            ms_ssim   0.700622  0.835515      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.037122  0.092450      NaN
  Baseline                mse   0.002361  0.015761      NaN
  Baseline               psnr  74.399825 66.155012      NaN
  Baseline               ssim   0.696682  0.898661      NaN
  Baseline            ms_ssim   0.853237  0.848620      NaN
  Baseline              frc50  24.000000 40.000000      NaN
      Tike                mae   0.047244  0.092270      NaN
      Tike                mse   0.003857  0.017427      NaN
      Tike               psnr  72.268158 65.718551      NaN
      Tike               ssim   0.679777  0.894626      NaN
      Tike            ms_ssim   0.856852  0.860953      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.539588
  Baseline computation_time_s        NaN       NaN 2.252514

2025-07-27 21:35:31,136 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/pinn_frc_curves.csv
2025-07-27 21:35:31,137 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/baseline_frc_curves.csv
2025-07-27 21:35:31,137 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:35:31,188 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/reconstructions_aligned.npz
2025-07-27 21:35:31,188 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/reconstructions_aligned_metadata.txt
2025-07-27 21:35:31,188 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:35:31,231 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.667, 0.916) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,231 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.112, 1.331) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,232 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (1.055, 2.147) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,233 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.792, -2.102) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,233 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.620, 0.774) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,234 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.479, 0.262) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,244 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,245 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:35:31,912 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_2048/trial_1/comparison_plot.png
2025-07-27 21:35:31,912 - INFO - 
Comparison complete!
2025-07-27 21:35:31,912 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_2048/trial_1
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:35:32,263 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:35:32,263 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:35:32,264 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:35:32,265 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:35:32] SUCCESS: Model comparison (train_size=2048, trial=1)
[2025-07-27 21:35:32] Using test subset size 4096 (3-way comparison mode)
[2025-07-27 21:35:32] EXECUTING: Model comparison (train_size=2048, trial=2)
[2025-07-27 21:35:32] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_2' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_2048/trial_2/tike_run/tike_reconstruction.npz' --n-test-images 4096
2025-07-27 21:35:33.146707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:35:33.146737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:35:33.147556: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:35:33.151681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:35:33.650756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:35:34.509821: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.542934: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.544904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:35:34.812674: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.815101: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.817207: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.922472: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.923708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.924835: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:35:34.924968: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:35:34.926098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:35:34,954 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:35:34,954 - INFO - Registration: disabled
2025-07-27 21:35:34,954 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:35:34,954 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:35:34,954 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=4096
2025-07-27 21:35:35,029 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:35:35,029 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:35:35,029 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:35:35,029 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:35:35,029 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:35:35,029 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:35:35,029 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:35:35,029 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:35:35,029 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:35:35,029 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:35:35,029 - INFO - DEBUG:
 nsamples:2025-07-27 21:35:35,029 - INFO - nsamples:
 103042025-07-27 21:35:35,029 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:35:35,029 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:35:35,053 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

2025-07-27 21:35:50.544469: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 337641472 exceeds 10% of free system memory.
neighbor-sampled diffraction shape2025-07-27 21:35:51,249 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:35:51,249 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:35:51,474 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:35:51,805 - INFO - INFO:
 None2025-07-27 21:35:51,805 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:35:51,805 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:35:51,807 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_run...
input shape2025-07-27 21:35:52,447 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:52,447 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:35:52,458 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:35:52,571 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:35:52,571 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:35:52,571 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:35:52,571 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:35:52,571 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:35:52,571 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:35:52,571 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:35:52,571 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:35:52,571 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:35:52,571 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:35:52,571 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:35:52,571 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:35:52,571 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:35:52,572 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,572 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:35:52,572 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:35:52,572 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:35:52,572 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,572 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:35:52,572 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:35:52,572 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:35:52,572 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:35:52,572 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:35:52,572 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:35:52,572 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:35:52,572 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,572 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:35:52,572 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:35:52,572 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:35:52,573 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:35:52,573 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:35:52,573 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,573 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:35:52,573 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,573 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:35:52,573 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:52,573 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:35:52,573 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:52,573 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:35:52,573 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:35:52,573 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:35:52,573 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:35:52,573 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:35:52,573 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:35:52,573 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:35:52,573 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,573 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:35:52,573 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,573 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:35:52,574 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:35:52,574 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:35:52,574 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:35:52,574 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:35:52,574 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:52,574 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:35:52,574 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:35:52,574 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:35:52,574 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:52,574 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:35:52,574 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:52,574 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:35:52,574 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:35:52,574 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:35:52,574 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:35:52,574 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:35:52,574 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:35:52,574 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:35:52,574 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:35:52,574 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:35:52,575 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:35:52,575 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:35:52,575 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:35:52,575 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:35:52,575 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:35:52,575 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:35:52,575 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:35:52,575 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:35:52,575 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:35:52,575 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:35:52,575 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:35:52,575 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:35:52,575 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:52,575 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:35:52,575 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:35:52,575 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:35:52,575 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:35:52,575 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:35:52,575 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:35:52,575 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:35:52,575 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:35:52,576 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:35:52,576 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:35:52,576 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:35:52,576 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:35:52,576 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:35:52,576 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:35:52,576 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:35:52,576 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:35:52,576 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:35:52,576 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:35:52,576 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:35:52,576 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:35:52,576 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:35:52,576 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:35:52,576 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:35:52,576 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:35:52,576 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:35:52,576 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:35:52,576 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:35:52,576 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:35:52,577 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:35:52,577 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:35:52,577 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:35:52,577 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:35:52,577 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:35:52,578 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:35:52,578 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:35:52,578 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:35:52,578 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:35:52,578 - INFO - None

2025-07-27 21:35:52.578553: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:35:52.578569: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:35:52.578592: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:35:52.595300: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:35:52.595375: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:35:52,983 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:52,983 - INFO - (None, 64, 64, 1)

2025-07-27 21:35:53.009958: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp3vmx6utn/autoencoder: FAILED_PRECONDITION: /tmp/tmp3vmx6utn/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:35:53,300 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:35:53,300 - INFO - (None, 64, 64, 1)

2025-07-27 21:35:53.325002: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmp3vmx6utn/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmp3vmx6utn/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:35:53,358 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1...
2025-07-27 21:35:53,358 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_run/07-27-2025-21.22.12_baseline_gs1/baseline_model.h5
2025-07-27 21:35:53,627 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_2048/trial_2/tike_run/tike_reconstruction.npz...
2025-07-27 21:35:53,629 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:35:53,629 - INFO - Loaded Tike reconstruction: (359, 359) (complex64)
2025-07-27 21:35:53,629 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:35:53,629 - INFO - Running inference with PtychoPINN...
2025-07-27 21:35:54.023811: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:142025-07-27 21:35:54,531 - INFO - 1/322 [..............................] - ETA: 4:14
 13/322 [>.............................] - ETA: 1s  2025-07-27 21:35:54,582 - INFO -  13/322 [>.............................] - ETA: 1s
 25/322 [=>............................] - ETA: 1s2025-07-27 21:35:54,633 - INFO -  25/322 [=>............................] - ETA: 1s
 37/322 [==>...........................] - ETA: 1s2025-07-27 21:35:54,684 - INFO -  37/322 [==>...........................] - ETA: 1s
 49/322 [===>..........................] - ETA: 1s2025-07-27 21:35:54,735 - INFO -  49/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:35:54,786 - INFO -  61/322 [====>.........................] - ETA: 1s
 73/322 [=====>........................] - ETA: 1s2025-07-27 21:35:54,837 - INFO -  73/322 [=====>........................] - ETA: 1s
 85/322 [======>.......................] - ETA: 1s2025-07-27 21:35:54,888 - INFO -  85/322 [======>.......................] - ETA: 1s
 97/322 [========>.....................] - ETA: 0s2025-07-27 21:35:54,938 - INFO -  97/322 [========>.....................] - ETA: 0s
109/322 [=========>....................] - ETA: 0s2025-07-27 21:35:54,989 - INFO - 109/322 [=========>....................] - ETA: 0s
122/322 [==========>...................] - ETA: 0s2025-07-27 21:35:55,043 - INFO - 122/322 [==========>...................] - ETA: 0s
134/322 [===========>..................] - ETA: 0s2025-07-27 21:35:55,093 - INFO - 134/322 [===========>..................] - ETA: 0s
147/322 [============>.................] - ETA: 0s2025-07-27 21:35:55,147 - INFO - 147/322 [============>.................] - ETA: 0s
160/322 [=============>................] - ETA: 0s2025-07-27 21:35:55,201 - INFO - 160/322 [=============>................] - ETA: 0s
173/322 [===============>..............] - ETA: 0s2025-07-27 21:35:55,254 - INFO - 173/322 [===============>..............] - ETA: 0s
186/322 [================>.............] - ETA: 0s2025-07-27 21:35:55,308 - INFO - 186/322 [================>.............] - ETA: 0s
199/322 [=================>............] - ETA: 0s2025-07-27 21:35:55,362 - INFO - 199/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:35:55,416 - INFO - 212/322 [==================>...........] - ETA: 0s
225/322 [===================>..........] - ETA: 0s2025-07-27 21:35:55,470 - INFO - 225/322 [===================>..........] - ETA: 0s
238/322 [=====================>........] - ETA: 0s2025-07-27 21:35:55,524 - INFO - 238/322 [=====================>........] - ETA: 0s
251/322 [======================>.......] - ETA: 0s2025-07-27 21:35:55,577 - INFO - 251/322 [======================>.......] - ETA: 0s
264/322 [=======================>......] - ETA: 0s2025-07-27 21:35:55,631 - INFO - 264/322 [=======================>......] - ETA: 0s
277/322 [========================>.....] - ETA: 0s2025-07-27 21:35:55,685 - INFO - 277/322 [========================>.....] - ETA: 0s
290/322 [==========================>...] - ETA: 0s2025-07-27 21:35:55,739 - INFO - 290/322 [==========================>...] - ETA: 0s
303/322 [===========================>..] - ETA: 0s2025-07-27 21:35:55,793 - INFO - 303/322 [===========================>..] - ETA: 0s
316/322 [============================>.] - ETA: 0s2025-07-27 21:35:55,847 - INFO - 316/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:35:55,872 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:35:55.955806: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 337641472 exceeds 10% of free system memory.
2025-07-27 21:35:56,189 - INFO - PtychoPINN inference completed in 2.56s
2025-07-27 21:35:56,189 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:35:56.234046: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 337641472 exceeds 10% of free system memory.
2025-07-27 21:35:56.965627: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 337641472 exceeds 10% of free system memory.
2025-07-27 21:35:57,556 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 44s2025-07-27 21:35:57,795 - INFO - 1/322 [..............................] - ETA: 44s
 11/322 [>.............................] - ETA: 1s 2025-07-27 21:35:57,845 - INFO -  11/322 [>.............................] - ETA: 1s
 21/322 [>.............................] - ETA: 1s2025-07-27 21:35:57,897 - INFO -  21/322 [>.............................] - ETA: 1s
 31/322 [=>............................] - ETA: 1s2025-07-27 21:35:57,949 - INFO -  31/322 [=>............................] - ETA: 1s
 41/322 [==>...........................] - ETA: 1s2025-07-27 21:35:58,001 - INFO -  41/322 [==>...........................] - ETA: 1s
 51/322 [===>..........................] - ETA: 1s2025-07-27 21:35:58,054 - INFO -  51/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:35:58,106 - INFO -  61/322 [====>.........................] - ETA: 1s
 71/322 [=====>........................] - ETA: 1s2025-07-27 21:35:58,158 - INFO -  71/322 [=====>........................] - ETA: 1s
 81/322 [======>.......................] - ETA: 1s2025-07-27 21:35:58,210 - INFO -  81/322 [======>.......................] - ETA: 1s
 91/322 [=======>......................] - ETA: 1s2025-07-27 21:35:58,262 - INFO -  91/322 [=======>......................] - ETA: 1s
101/322 [========>.....................] - ETA: 1s2025-07-27 21:35:58,314 - INFO - 101/322 [========>.....................] - ETA: 1s
111/322 [=========>....................] - ETA: 1s2025-07-27 21:35:58,366 - INFO - 111/322 [=========>....................] - ETA: 1s
121/322 [==========>...................] - ETA: 1s2025-07-27 21:35:58,418 - INFO - 121/322 [==========>...................] - ETA: 1s
131/322 [===========>..................] - ETA: 0s2025-07-27 21:35:58,470 - INFO - 131/322 [===========>..................] - ETA: 0s
141/322 [============>.................] - ETA: 0s2025-07-27 21:35:58,522 - INFO - 141/322 [============>.................] - ETA: 0s
151/322 [=============>................] - ETA: 0s2025-07-27 21:35:58,573 - INFO - 151/322 [=============>................] - ETA: 0s
161/322 [==============>...............] - ETA: 0s2025-07-27 21:35:58,625 - INFO - 161/322 [==============>...............] - ETA: 0s
171/322 [==============>...............] - ETA: 0s2025-07-27 21:35:58,677 - INFO - 171/322 [==============>...............] - ETA: 0s
181/322 [===============>..............] - ETA: 0s2025-07-27 21:35:58,729 - INFO - 181/322 [===============>..............] - ETA: 0s
191/322 [================>.............] - ETA: 0s2025-07-27 21:35:58,781 - INFO - 191/322 [================>.............] - ETA: 0s
201/322 [=================>............] - ETA: 0s2025-07-27 21:35:58,833 - INFO - 201/322 [=================>............] - ETA: 0s
211/322 [==================>...........] - ETA: 0s2025-07-27 21:35:58,885 - INFO - 211/322 [==================>...........] - ETA: 0s
221/322 [===================>..........] - ETA: 0s2025-07-27 21:35:58,937 - INFO - 221/322 [===================>..........] - ETA: 0s
231/322 [====================>.........] - ETA: 0s2025-07-27 21:35:58,989 - INFO - 231/322 [====================>.........] - ETA: 0s
241/322 [=====================>........] - ETA: 0s2025-07-27 21:35:59,041 - INFO - 241/322 [=====================>........] - ETA: 0s
251/322 [======================>.......] - ETA: 0s2025-07-27 21:35:59,093 - INFO - 251/322 [======================>.......] - ETA: 0s
261/322 [=======================>......] - ETA: 0s2025-07-27 21:35:59,145 - INFO - 261/322 [=======================>......] - ETA: 0s
271/322 [========================>.....] - ETA: 0s2025-07-27 21:35:59,197 - INFO - 271/322 [========================>.....] - ETA: 0s
281/322 [=========================>....] - ETA: 0s2025-07-27 21:35:59,249 - INFO - 281/322 [=========================>....] - ETA: 0s
291/322 [==========================>...] - ETA: 0s2025-07-27 21:35:59,301 - INFO - 291/322 [==========================>...] - ETA: 0s
301/322 [===========================>..] - ETA: 0s2025-07-27 21:35:59,353 - INFO - 301/322 [===========================>..] - ETA: 0s
311/322 [===========================>..] - ETA: 0s2025-07-27 21:35:59,405 - INFO - 311/322 [===========================>..] - ETA: 0s
321/322 [============================>.] - ETA: 0s2025-07-27 21:35:59,457 - INFO - 321/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:35:59,462 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:35:59,808 - INFO - Baseline inference completed in 2.25s
2025-07-27 21:36:00,250 - INFO - Reassembling baseline patches...
2025-07-27 21:36:00,347 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:36:00,405 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/reconstructions.npz
2025-07-27 21:36:00,405 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/reconstructions_metadata.txt
2025-07-27 21:36:00,405 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:36:00,406 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:36:00,406 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:36:00,406 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:00,406 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:00,406 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:36:00,406 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:36:00,406 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:00,406 - INFO - --- Alignment complete ---
2025-07-27 21:36:00,406 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:00,406 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:00,406 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:36:00,406 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:36:00,406 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:00,406 - INFO - --- Alignment complete ---
2025-07-27 21:36:00,406 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:00,406 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:00,406 - INFO - Initial shapes: Recon=(359, 359), Cropped GT=(185, 185)
2025-07-27 21:36:00,406 - INFO - Center-cropping from (359, 359) to (185, 185)
2025-07-27 21:36:00,406 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:00,406 - INFO - --- Alignment complete ---
2025-07-27 21:36:00,406 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:36:00,406 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.6920172025-07-27 21:36:00,411 - INFO - Amplitude normalization scale factor: 1.692017

mean scale adjustment:2025-07-27 21:36:00,411 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,411 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,411 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,411 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:00,429 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.728489, std=0.225724, shape=(181, 181, 1)2025-07-27 21:36:00,429 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.728489, std=0.225724, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:00,429 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.000000, shape=(181, 181)2025-07-27 21:36:00,430 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.000000, shape=(181, 181)

performed by index method2025-07-27 21:36:00,433 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,443 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,453 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:00,462 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,462 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,463 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,463 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:00,463 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:00,471 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,481 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,490 - INFO - performed by index method

2025-07-27 21:36:00,500 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.353, phase=0.521, MS-SSIM: amp=0.428, phase=0.029
Amplitude normalization scale factor: 1.0051122025-07-27 21:36:00,503 - INFO - Amplitude normalization scale factor: 1.005112

mean scale adjustment:2025-07-27 21:36:00,503 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,503 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,503 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,503 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:00,504 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.226346, std=0.084539, shape=(181, 181, 1)2025-07-27 21:36:00,504 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.226346, std=0.084539, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:00,505 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.250894, shape=(181, 181)2025-07-27 21:36:00,505 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.250894, shape=(181, 181)

performed by index method2025-07-27 21:36:00,508 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,518 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,527 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:00,537 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,537 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,537 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,537 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:00,537 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:00,545 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,555 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,565 - INFO - performed by index method

2025-07-27 21:36:00,574 - INFO - Baseline evaluation complete. SSIM: amp=0.689, phase=0.887, MS-SSIM: amp=0.847, phase=0.825
Amplitude normalization scale factor: 1.7514212025-07-27 21:36:00,578 - INFO - Amplitude normalization scale factor: 1.751421

mean scale adjustment:2025-07-27 21:36:00,578 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,578 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,578 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,578 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:00,579 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703780, std=0.059615, shape=(181, 181, 1)2025-07-27 21:36:00,579 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703780, std=0.059615, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:00,579 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=0.000000, std=0.282595, shape=(181, 181)2025-07-27 21:36:00,579 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=0.000000, std=0.282595, shape=(181, 181)

performed by index method2025-07-27 21:36:00,583 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,592 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,602 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:00,612 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,612 - INFO - 1

mean scale adjustment:2025-07-27 21:36:00,612 - INFO - mean scale adjustment:
 12025-07-27 21:36:00,612 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:00,612 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:00,620 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,629 - INFO - performed by index method

performed by index method2025-07-27 21:36:00,639 - INFO - performed by index method

2025-07-27 21:36:00,649 - INFO - Tike evaluation complete. SSIM: amp=0.680, phase=0.895, MS-SSIM: amp=0.857, phase=0.861
2025-07-27 21:36:00,650 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:36:00,650 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.252352  0.251303      NaN
PtychoPINN                mse   0.095802  0.082235      NaN
PtychoPINN               psnr  58.317065 58.980249      NaN
PtychoPINN               ssim   0.352976  0.520955      NaN
PtychoPINN            ms_ssim   0.427738  0.028860      NaN
PtychoPINN              frc50   3.000000  1.000000      NaN
  Baseline                mae   0.037498  0.094786      NaN
  Baseline                mse   0.002413  0.016721      NaN
  Baseline               psnr  74.305866 65.898093      NaN
  Baseline               ssim   0.688853  0.887002      NaN
  Baseline            ms_ssim   0.846877  0.825091      NaN
  Baseline              frc50  24.000000 33.000000      NaN
      Tike                mae   0.047284  0.092343      NaN
      Tike                mse   0.003859  0.017449      NaN
      Tike               psnr  72.265922 65.713184      NaN
      Tike               ssim   0.679582  0.894506      NaN
      Tike            ms_ssim   0.856820  0.860771      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.559043
  Baseline computation_time_s        NaN       NaN 2.2519512025-07-27 21:36:00,652 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.252352  0.251303      NaN
PtychoPINN                mse   0.095802  0.082235      NaN
PtychoPINN               psnr  58.317065 58.980249      NaN
PtychoPINN               ssim   0.352976  0.520955      NaN
PtychoPINN            ms_ssim   0.427738  0.028860      NaN
PtychoPINN              frc50   3.000000  1.000000      NaN
  Baseline                mae   0.037498  0.094786      NaN
  Baseline                mse   0.002413  0.016721      NaN
  Baseline               psnr  74.305866 65.898093      NaN
  Baseline               ssim   0.688853  0.887002      NaN
  Baseline            ms_ssim   0.846877  0.825091      NaN
  Baseline              frc50  24.000000 33.000000      NaN
      Tike                mae   0.047284  0.092343      NaN
      Tike                mse   0.003859  0.017449      NaN
      Tike               psnr  72.265922 65.713184      NaN
      Tike               ssim   0.679582  0.894506      NaN
      Tike            ms_ssim   0.856820  0.860771      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.559043
  Baseline computation_time_s        NaN       NaN 2.251951

2025-07-27 21:36:00,652 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/pinn_frc_curves.csv
2025-07-27 21:36:00,653 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/baseline_frc_curves.csv
2025-07-27 21:36:00,653 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:36:00,700 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/reconstructions_aligned.npz
2025-07-27 21:36:00,700 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/reconstructions_aligned_metadata.txt
2025-07-27 21:36:00,700 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:36:00,743 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.355, 0.969) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,743 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.111, 1.331) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,744 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (3.142, 3.142) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,745 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.782, -2.103) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,745 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.620, 0.774) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,746 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.479, 0.262) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,756 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:00,757 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:01,426 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_2048/trial_2/comparison_plot.png
2025-07-27 21:36:01,427 - INFO - 
Comparison complete!
2025-07-27 21:36:01,427 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_2048/trial_2
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:36:01,777 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:36:01,777 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:36:01,778 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:36:02] SUCCESS: Model comparison (train_size=2048, trial=2)
[2025-07-27 21:36:02] Using test subset size 4096 (3-way comparison mode)
[2025-07-27 21:36:02] EXECUTING: Model comparison (train_size=2048, trial=3)
[2025-07-27 21:36:02] COMMAND: python scripts/compare_models.py \
                --pinn_dir '3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run' \
                --baseline_dir '3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1' \
                --test_data 'datasets/fly64/fly64_shuffled.npz' \
                --output_dir '3way_bothhalves_full_2xtest/train_2048/trial_3' \
                --skip-registration \
                 --tike_recon_path '3way_bothhalves_full_2xtest/train_2048/trial_3/tike_run/tike_reconstruction.npz' --n-test-images 4096
2025-07-27 21:36:02.653494: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-07-27 21:36:02.653527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-07-27 21:36:02.654369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-27 21:36:02.658489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-27 21:36:03.162589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-27 21:36:04.019388: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.050292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.052235: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
/home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
2025-07-27 21:36:04.317789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.320077: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.322181: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.426985: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.428303: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.429431: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0
2025-07-27 21:36:04.429579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-07-27 21:36:04.430817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21917 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-07-27 21:36:04,460 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-07-27 21:36:04,460 - INFO - Registration: disabled
2025-07-27 21:36:04,460 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-07-27 21:36:04,460 - INFO - Loading test data from datasets/fly64/fly64_shuffled.npz...
2025-07-27 21:36:04,460 - INFO - Loading data from datasets/fly64/fly64_shuffled.npz with n_images=4096
2025-07-27 21:36:04,532 - INFO - Using grouping-aware subsampling for gridsize=2: passing full dataset for group-first sampling
diff3d shape: (10304, 64, 64)2025-07-27 21:36:04,533 - INFO - diff3d shape: (10304, 64, 64)

probeGuess shape: (64, 64)2025-07-27 21:36:04,533 - INFO - probeGuess shape: (64, 64)

scan_index shape: (10304,)2025-07-27 21:36:04,533 - INFO - scan_index shape: (10304,)

objectGuess shape: (232, 232)2025-07-27 21:36:04,533 - INFO - objectGuess shape: (232, 232)

xcoords shape: (10304,)2025-07-27 21:36:04,533 - INFO - xcoords shape: (10304,)

ycoords shape: (10304,)2025-07-27 21:36:04,533 - INFO - ycoords shape: (10304,)

xcoords_start shape: (10304,)2025-07-27 21:36:04,533 - INFO - xcoords_start shape: (10304,)

ycoords_start shape: (10304,)2025-07-27 21:36:04,533 - INFO - ycoords_start shape: (10304,)

2025-07-27 21:36:04,533 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-07-27 21:36:04,533 - INFO - DEBUG:
 nsamples:2025-07-27 21:36:04,533 - INFO - nsamples:
 103042025-07-27 21:36:04,533 - INFO - 10304
 (gridsize=1, using legacy sequential sampling)2025-07-27 21:36:04,533 - INFO - (gridsize=1, using legacy sequential sampling)

INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.2025-07-27 21:36:04,556 - INFO - INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.

neighbor-sampled diffraction shape2025-07-27 21:36:21,040 - INFO - neighbor-sampled diffraction shape
 (10304, 64, 64, 1)2025-07-27 21:36:21,040 - INFO - (10304, 64, 64, 1)

loader: using provided ground truth patches.2025-07-27 21:36:21,268 - INFO - loader: using provided ground truth patches.

INFO:2025-07-27 21:36:21,631 - INFO - INFO:
 None2025-07-27 21:36:21,631 - INFO - None

<PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>2025-07-27 21:36:21,631 - INFO - <PtychoDataContainer X=(10304, 64, 64, 1) Y_I=(10304, 64, 64, 1) Y_phi=(10304, 64, 64, 1) norm_Y_I=() coords_nominal=(10304, 1, 2, 1) coords_true=(10304, 1, 2, 1) nn_indices=(10304, 1) mean=5151.500 global_offsets=(10304, 1, 2, 1) mean=115.758 local_offsets=(10304, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.086>

2025-07-27 21:36:21,633 - INFO - Loading PtychoPINN model from 3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_run...
input shape2025-07-27 21:36:22,268 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:36:22,268 - INFO - (None, 64, 64, 1)

WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2025-07-27 21:36:22,278 - WARNING - From /home/ollie/miniconda3/envs/ptycho-tf/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
Model: "model"
2025-07-27 21:36:22,392 - INFO - Model: "model"
__________________________________________________________________________________________________
2025-07-27 21:36:22,392 - INFO - __________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
2025-07-27 21:36:22,392 - INFO - Layer (type)                Output Shape                 Param #   Connected to
==================================================================================================
2025-07-27 21:36:22,392 - INFO - ==================================================================================================
 input (InputLayer)          [(None, 64, 64, 1)]          0         []                            
2025-07-27 21:36:22,392 - INFO - input (InputLayer)          [(None, 64, 64, 1)]          0         []
                                                                                                  
 tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']               
2025-07-27 21:36:22,392 - INFO - tf.math.truediv (TFOpLambd  (None, 64, 64, 1)            0         ['input[0][0]']
 a)                                                                                               
2025-07-27 21:36:22,392 - INFO - a)
                                                                                                  
 conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']     
2025-07-27 21:36:22,393 - INFO - conv2d (Conv2D)             (None, 64, 64, 64)           640       ['tf.math.truediv[0][0]']
                                                                                                  
 conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']              
2025-07-27 21:36:22,393 - INFO - conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']
                                                                                                  
 max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']            
2025-07-27 21:36:22,393 - INFO - max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']
 D)                                                                                               
2025-07-27 21:36:22,393 - INFO - D)
                                                                                                  
 conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']       
2025-07-27 21:36:22,393 - INFO - conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']
                                                                                                  
 conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']            
2025-07-27 21:36:22,393 - INFO - conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']
                                                                                                  
 max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']            
2025-07-27 21:36:22,393 - INFO - max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,393 - INFO - g2D)
                                                                                                  
 conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']     
2025-07-27 21:36:22,393 - INFO - conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']
                                                                                                  
 conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']            
2025-07-27 21:36:22,393 - INFO - conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']
                                                                                                  
 max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']            
2025-07-27 21:36:22,393 - INFO - max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,393 - INFO - g2D)
                                                                                                  
 conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:36:22,393 - INFO - conv2d_8 (Conv2D)           (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']     
2025-07-27 21:36:22,393 - INFO - conv2d_16 (Conv2D)          (None, 8, 8, 128)            295040    ['max_pooling2d_2[0][0]']
                                                                                                  
 conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']            
2025-07-27 21:36:22,393 - INFO - conv2d_9 (Conv2D)           (None, 8, 8, 128)            147584    ['conv2d_8[0][0]']
                                                                                                  
 conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']           
2025-07-27 21:36:22,394 - INFO - conv2d_17 (Conv2D)          (None, 8, 8, 128)            147584    ['conv2d_16[0][0]']
                                                                                                  
 up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']            
2025-07-27 21:36:22,394 - INFO - up_sampling2d (UpSampling2  (None, 16, 16, 128)          0         ['conv2d_9[0][0]']
 D)                                                                                               
2025-07-27 21:36:22,394 - INFO - D)
                                                                                                  
 up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']           
2025-07-27 21:36:22,394 - INFO - up_sampling2d_3 (UpSamplin  (None, 16, 16, 128)          0         ['conv2d_17[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,394 - INFO - g2D)
                                                                                                  
 conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']       
2025-07-27 21:36:22,394 - INFO - conv2d_10 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d[0][0]']
                                                                                                  
 conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']     
2025-07-27 21:36:22,394 - INFO - conv2d_18 (Conv2D)          (None, 16, 16, 64)           73792     ['up_sampling2d_3[0][0]']
                                                                                                  
 conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']           
2025-07-27 21:36:22,394 - INFO - conv2d_11 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_10[0][0]']
                                                                                                  
 conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']           
2025-07-27 21:36:22,394 - INFO - conv2d_19 (Conv2D)          (None, 16, 16, 64)           36928     ['conv2d_18[0][0]']
                                                                                                  
 up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']           
2025-07-27 21:36:22,394 - INFO - up_sampling2d_1 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_11[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,394 - INFO - g2D)
                                                                                                  
 up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']           
2025-07-27 21:36:22,394 - INFO - up_sampling2d_4 (UpSamplin  (None, 32, 32, 64)           0         ['conv2d_19[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,394 - INFO - g2D)
                                                                                                  
 tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:36:22,394 - INFO - tf.__operators__.getitem_1  (None, 32, 32, 4)            0         ['up_sampling2d_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:36:22,394 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:36:22,394 - INFO - tf.__operators__.getitem_4  (None, 32, 32, 4)            0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:36:22,394 - INFO - (SlicingOpLambda)
                                                                                                  
 conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
2025-07-27 21:36:22,394 - INFO - conv2d_12 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_1[0
                                                                    ][0]']                        
2025-07-27 21:36:22,394 - INFO - ][0]']
                                                                                                  
 conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
2025-07-27 21:36:22,395 - INFO - conv2d_20 (Conv2D)          (None, 32, 32, 64)           2368      ['tf.__operators__.getitem_4[0
                                                                    ][0]']                        
2025-07-27 21:36:22,395 - INFO - ][0]']
                                                                                                  
 conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']           
2025-07-27 21:36:22,395 - INFO - conv2d_13 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_12[0][0]']
                                                                                                  
 conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']           
2025-07-27 21:36:22,395 - INFO - conv2d_21 (Conv2D)          (None, 32, 32, 64)           36928     ['conv2d_20[0][0]']
                                                                                                  
 up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']           
2025-07-27 21:36:22,395 - INFO - up_sampling2d_2 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_13[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,395 - INFO - g2D)
                                                                                                  
 up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']           
2025-07-27 21:36:22,395 - INFO - up_sampling2d_5 (UpSamplin  (None, 64, 64, 64)           0         ['conv2d_21[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,395 - INFO - g2D)
                                                                                                  
 conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']     
2025-07-27 21:36:22,395 - INFO - conv2d_7 (Conv2D)           (None, 64, 64, 1)            577       ['up_sampling2d_2[0][0]']
                                                                                                  
 conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']     
2025-07-27 21:36:22,395 - INFO - conv2d_15 (Conv2D)          (None, 64, 64, 1)            577       ['up_sampling2d_5[0][0]']
                                                                                                  
 tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']            
2025-07-27 21:36:22,395 - INFO - tf.nn.silu (TFOpLambda)     (None, 64, 64, 1)            0         ['conv2d_7[0][0]']
                                                                                                  
 tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']           
2025-07-27 21:36:22,395 - INFO - tf.nn.silu_1 (TFOpLambda)   (None, 64, 64, 1)            0         ['conv2d_15[0][0]']
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']          
2025-07-27 21:36:22,395 - INFO - tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.nn.silu[0][0]']
 mbda)                                                                                            
2025-07-27 21:36:22,395 - INFO - mbda)
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']        
2025-07-27 21:36:22,395 - INFO - tf.compat.v1.shape_1 (TFOp  (4,)                         0         ['tf.nn.silu_1[0][0]']
 Lambda)                                                                                          
2025-07-27 21:36:22,395 - INFO - Lambda)
                                                                                                  
 tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']  
2025-07-27 21:36:22,395 - INFO - tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:36:22,395 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
2025-07-27 21:36:22,396 - INFO - tf.__operators__.getitem_5  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:36:22,396 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']     
2025-07-27 21:36:22,396 - INFO - tf.__operators__.getitem (  (None, 32, 32, 60)           0         ['up_sampling2d_1[0][0]']
 SlicingOpLambda)                                                                                 
2025-07-27 21:36:22,396 - INFO - SlicingOpLambda)
                                                                                                  
 tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
2025-07-27 21:36:22,396 - INFO - tf.ones (TFOpLambda)        (None, 32, 32, 1)            0         ['tf.__operators__.getitem_2[0
                                                                    ][0]']                        
2025-07-27 21:36:22,396 - INFO - ][0]']
                                                                                                  
 tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']     
2025-07-27 21:36:22,396 - INFO - tf.__operators__.getitem_3  (None, 32, 32, 60)           0         ['up_sampling2d_4[0][0]']
  (SlicingOpLambda)                                                                               
2025-07-27 21:36:22,396 - INFO - (SlicingOpLambda)
                                                                                                  
 tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
2025-07-27 21:36:22,396 - INFO - tf.ones_1 (TFOpLambda)      (None, 32, 32, 1)            0         ['tf.__operators__.getitem_5[0
                                                                    ][0]']                        
2025-07-27 21:36:22,396 - INFO - ][0]']
                                                                                                  
 conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
2025-07-27 21:36:22,396 - INFO - conv2d_6 (Conv2D)           (None, 32, 32, 1)            541       ['tf.__operators__.getitem[0][
                                                                    0]']                          
2025-07-27 21:36:22,396 - INFO - 0]']
                                                                                                  
 zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']             
2025-07-27 21:36:22,396 - INFO - zero_padding2d (ZeroPaddin  (None, 64, 64, 1)            0         ['tf.ones[0][0]']
 g2D)                                                                                             
2025-07-27 21:36:22,396 - INFO - g2D)
                                                                                                  
 conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
2025-07-27 21:36:22,396 - INFO - conv2d_14 (Conv2D)          (None, 32, 32, 1)            541       ['tf.__operators__.getitem_3[0
                                                                    ][0]']                        
2025-07-27 21:36:22,396 - INFO - ][0]']
                                                                                                  
 zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']           
2025-07-27 21:36:22,396 - INFO - zero_padding2d_1 (ZeroPadd  (None, 64, 64, 1)            0         ['tf.ones_1[0][0]']
 ing2D)                                                                                           
2025-07-27 21:36:22,396 - INFO - ing2D)
                                                                                                  
 amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']            
2025-07-27 21:36:22,396 - INFO - amp (Lambda)                (None, 32, 32, 1)            0         ['conv2d_6[0][0]']
                                                                                                  
 tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']      
2025-07-27 21:36:22,396 - INFO - tf.math.subtract (TFOpLamb  (None, 64, 64, 1)            0         ['zero_padding2d[0][0]']
 da)                                                                                              
2025-07-27 21:36:22,396 - INFO - da)
                                                                                                  
 phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']           
2025-07-27 21:36:22,396 - INFO - phi (Lambda)                (None, 32, 32, 1)            0         ['conv2d_14[0][0]']
                                                                                                  
 tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']    
2025-07-27 21:36:22,397 - INFO - tf.math.subtract_1 (TFOpLa  (None, 64, 64, 1)            0         ['zero_padding2d_1[0][0]']
 mbda)                                                                                            
2025-07-27 21:36:22,397 - INFO - mbda)
                                                                                                  
 amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']                 
2025-07-27 21:36:22,397 - INFO - amp_padded (ZeroPadding2D)  (None, 64, 64, 1)            0         ['amp[0][0]']
                                                                                                  
 tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',          
2025-07-27 21:36:22,397 - INFO - tf.math.multiply (TFOpLamb  (None, 64, 64, 1)            0         ['tf.nn.silu[0][0]',
 da)                                                                 'tf.math.subtract[0][0]']    
2025-07-27 21:36:22,397 - INFO - da)                                                                 'tf.math.subtract[0][0]']
                                                                                                  
 phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']                 
2025-07-27 21:36:22,397 - INFO - phase_padded (ZeroPadding2  (None, 64, 64, 1)            0         ['phi[0][0]']
 D)                                                                                               
2025-07-27 21:36:22,397 - INFO - D)
                                                                                                  
 tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',        
2025-07-27 21:36:22,397 - INFO - tf.math.multiply_1 (TFOpLa  (None, 64, 64, 1)            0         ['tf.nn.silu_1[0][0]',
 mbda)                                                               'tf.math.subtract_1[0][0]']  
2025-07-27 21:36:22,397 - INFO - mbda)                                                               'tf.math.subtract_1[0][0]']
                                                                                                  
 tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',          
2025-07-27 21:36:22,397 - INFO - tf.__operators__.add (TFOp  (None, 64, 64, 1)            0         ['amp_padded[0][0]',
 Lambda)                                                             'tf.math.multiply[0][0]']    
2025-07-27 21:36:22,397 - INFO - Lambda)                                                             'tf.math.multiply[0][0]']
                                                                                                  
 tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',        
2025-07-27 21:36:22,397 - INFO - tf.__operators__.add_1 (TF  (None, 64, 64, 1)            0         ['phase_padded[0][0]',
 OpLambda)                                                           'tf.math.multiply_1[0][0]']  
2025-07-27 21:36:22,397 - INFO - OpLambda)                                                           'tf.math.multiply_1[0][0]']
                                                                                                  
 obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
2025-07-27 21:36:22,397 - INFO - obj (Lambda)                (None, 64, 64, 1)            0         ['tf.__operators__.add[0][0]',
                                                                     'tf.__operators__.add_1[0][0]
2025-07-27 21:36:22,397 - INFO - 'tf.__operators__.add_1[0][0]
                                                                    ']                            
2025-07-27 21:36:22,397 - INFO - ']
                                                                                                  
 input_positions (InputLaye  [(None, 1, 2, 1)]            0         []                            
2025-07-27 21:36:22,397 - INFO - input_positions (InputLaye  [(None, 1, 2, 1)]            0         []
 r)                                                                                               
2025-07-27 21:36:22,397 - INFO - r)
                                                                                                  
 padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',                 
2025-07-27 21:36:22,397 - INFO - padded_obj_2 (Lambda)       (None, 74, 74, 1)            0         ['obj[0][0]',
                                                                     'input_positions[0][0]']     
2025-07-27 21:36:22,397 - INFO - 'input_positions[0][0]']
                                                                                                  
 padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',        
2025-07-27 21:36:22,397 - INFO - padded_objs_with_offsets (  (None, None, None, 1)        0         ['padded_obj_2[0][0]',
 Lambda)                                                             'input_positions[0][0]']     
2025-07-27 21:36:22,397 - INFO - Lambda)                                                             'input_positions[0][0]']
                                                                                                  
 probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
2025-07-27 21:36:22,398 - INFO - probe_illumination (ProbeI  ((None, 64, 64, 1),          4096      ['padded_objs_with_offsets[0][
 llumination)                 (1, 1, 64, 64, 1))                    0]']                          
2025-07-27 21:36:22,398 - INFO - llumination)                 (1, 1, 64, 64, 1))                    0]']
                                                                                                  
 pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']  
2025-07-27 21:36:22,398 - INFO - pred_amplitude (Lambda)     ((None, 64, 64, 1),          0         ['probe_illumination[0][0]']
                              (None, 64, 64, 1))                                                  
2025-07-27 21:36:22,398 - INFO - (None, 64, 64, 1))
                                                                                                  
 pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']      
2025-07-27 21:36:22,398 - INFO - pred_diff_channels (Lambda  (None, 64, 64, 1)            0         ['pred_amplitude[0][1]']
 )                                                                                                
2025-07-27 21:36:22,398 - INFO - )
                                                                                                  
 tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']  
2025-07-27 21:36:22,398 - INFO - tf.math.multiply_2 (TFOpLa  (None, 64, 64, 1)            0         ['pred_diff_channels[0][0]']
 mbda)                                                                                            
2025-07-27 21:36:22,398 - INFO - mbda)
                                                                                                  
 trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']        
2025-07-27 21:36:22,398 - INFO - trimmed_obj (Lambda)        (None, 64, 64, 1)            0         ['padded_obj_2[0][0]']
                                                                                                  
 distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']  
2025-07-27 21:36:22,398 - INFO - distribution_lambda (Distr  ((None, 64, 64, 1),          0         ['tf.math.multiply_2[0][0]']
 ibutionLambda)               (None, 64, 64, 1))                                                  
2025-07-27 21:36:22,398 - INFO - ibutionLambda)               (None, 64, 64, 1))
                                                                                                  
==================================================================================================
2025-07-27 21:36:22,398 - INFO - ==================================================================================================
Total params: 2335868 (8.93 MB)
2025-07-27 21:36:22,399 - INFO - Total params: 2335868 (8.93 MB)
Trainable params: 2331772 (8.90 MB)
2025-07-27 21:36:22,399 - INFO - Trainable params: 2331772 (8.90 MB)
Non-trainable params: 4096 (32.00 KB)
2025-07-27 21:36:22,399 - INFO - Non-trainable params: 4096 (32.00 KB)
__________________________________________________________________________________________________
2025-07-27 21:36:22,399 - INFO - __________________________________________________________________________________________________
None2025-07-27 21:36:22,399 - INFO - None

2025-07-27 21:36:22.399996: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.
2025-07-27 21:36:22.400012: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.
2025-07-27 21:36:22.400034: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1883] Profiler found 1 GPUs
2025-07-27 21:36:22.417159: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.
2025-07-27 21:36:22.417235: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:2017] CUPTI activity buffer flushed
input shape2025-07-27 21:36:22,803 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:36:22,803 - INFO - (None, 64, 64, 1)

2025-07-27 21:36:22.830545: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmpw7_if6qp/autoencoder: FAILED_PRECONDITION: /tmp/tmpw7_if6qp/autoencoder; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
input shape2025-07-27 21:36:23,125 - INFO - input shape
 (None, 64, 64, 1)2025-07-27 21:36:23,125 - INFO - (None, 64, 64, 1)

2025-07-27 21:36:23.150569: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open /tmp/tmpw7_if6qp/diffraction_to_obj: FAILED_PRECONDITION: /tmp/tmpw7_if6qp/diffraction_to_obj; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2025-07-27 21:36:23,184 - INFO - Loading Baseline model from 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1...
2025-07-27 21:36:23,184 - INFO - Found baseline model at: 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_run/07-27-2025-21.29.10_baseline_gs1/baseline_model.h5
2025-07-27 21:36:23,453 - INFO - Loading Tike reconstruction from 3way_bothhalves_full_2xtest/train_2048/trial_3/tike_run/tike_reconstruction.npz...
2025-07-27 21:36:23,455 - WARNING - Could not extract computation time from metadata: Object arrays cannot be loaded when allow_pickle=False
2025-07-27 21:36:23,455 - INFO - Loaded Tike reconstruction: (359, 359) (complex64)
2025-07-27 21:36:23,455 - INFO - Tike reconstruction loaded for three-way comparison
2025-07-27 21:36:23,455 - INFO - Running inference with PtychoPINN...
2025-07-27 21:36:23.844498: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904
  1/322 [..............................] - ETA: 4:132025-07-27 21:36:24,351 - INFO - 1/322 [..............................] - ETA: 4:13
 13/322 [>.............................] - ETA: 1s  2025-07-27 21:36:24,402 - INFO -  13/322 [>.............................] - ETA: 1s
 25/322 [=>............................] - ETA: 1s2025-07-27 21:36:24,453 - INFO -  25/322 [=>............................] - ETA: 1s
 37/322 [==>...........................] - ETA: 1s2025-07-27 21:36:24,504 - INFO -  37/322 [==>...........................] - ETA: 1s
 49/322 [===>..........................] - ETA: 1s2025-07-27 21:36:24,555 - INFO -  49/322 [===>..........................] - ETA: 1s
 61/322 [====>.........................] - ETA: 1s2025-07-27 21:36:24,605 - INFO -  61/322 [====>.........................] - ETA: 1s
 73/322 [=====>........................] - ETA: 1s2025-07-27 21:36:24,656 - INFO -  73/322 [=====>........................] - ETA: 1s
 85/322 [======>.......................] - ETA: 1s2025-07-27 21:36:24,707 - INFO -  85/322 [======>.......................] - ETA: 1s
 97/322 [========>.....................] - ETA: 0s2025-07-27 21:36:24,757 - INFO -  97/322 [========>.....................] - ETA: 0s
109/322 [=========>....................] - ETA: 0s2025-07-27 21:36:24,807 - INFO - 109/322 [=========>....................] - ETA: 0s
122/322 [==========>...................] - ETA: 0s2025-07-27 21:36:24,861 - INFO - 122/322 [==========>...................] - ETA: 0s
134/322 [===========>..................] - ETA: 0s2025-07-27 21:36:24,912 - INFO - 134/322 [===========>..................] - ETA: 0s
147/322 [============>.................] - ETA: 0s2025-07-27 21:36:24,966 - INFO - 147/322 [============>.................] - ETA: 0s
160/322 [=============>................] - ETA: 0s2025-07-27 21:36:25,020 - INFO - 160/322 [=============>................] - ETA: 0s
173/322 [===============>..............] - ETA: 0s2025-07-27 21:36:25,073 - INFO - 173/322 [===============>..............] - ETA: 0s
186/322 [================>.............] - ETA: 0s2025-07-27 21:36:25,127 - INFO - 186/322 [================>.............] - ETA: 0s
199/322 [=================>............] - ETA: 0s2025-07-27 21:36:25,181 - INFO - 199/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:36:25,235 - INFO - 212/322 [==================>...........] - ETA: 0s
225/322 [===================>..........] - ETA: 0s2025-07-27 21:36:25,289 - INFO - 225/322 [===================>..........] - ETA: 0s
238/322 [=====================>........] - ETA: 0s2025-07-27 21:36:25,343 - INFO - 238/322 [=====================>........] - ETA: 0s
251/322 [======================>.......] - ETA: 0s2025-07-27 21:36:25,397 - INFO - 251/322 [======================>.......] - ETA: 0s
264/322 [=======================>......] - ETA: 0s2025-07-27 21:36:25,451 - INFO - 264/322 [=======================>......] - ETA: 0s
277/322 [========================>.....] - ETA: 0s2025-07-27 21:36:25,504 - INFO - 277/322 [========================>.....] - ETA: 0s
290/322 [==========================>...] - ETA: 0s2025-07-27 21:36:25,558 - INFO - 290/322 [==========================>...] - ETA: 0s
303/322 [===========================>..] - ETA: 0s2025-07-27 21:36:25,612 - INFO - 303/322 [===========================>..] - ETA: 0s
316/322 [============================>.] - ETA: 0s2025-07-27 21:36:25,666 - INFO - 316/322 [============================>.] - ETA: 0s
322/322 [==============================] - 2s 4ms/step
2025-07-27 21:36:25,691 - INFO - 322/322 [==============================] - 2s 4ms/step
2025-07-27 21:36:26,000 - INFO - PtychoPINN inference completed in 2.54s
2025-07-27 21:36:26,000 - INFO - Reassembling PtychoPINN patches...
2025-07-27 21:36:27,362 - INFO - Running inference with Baseline model...
  1/322 [..............................] - ETA: 44s2025-07-27 21:36:27,599 - INFO - 1/322 [..............................] - ETA: 44s
 12/322 [>.............................] - ETA: 1s 2025-07-27 21:36:27,654 - INFO -  12/322 [>.............................] - ETA: 1s
 22/322 [=>............................] - ETA: 1s2025-07-27 21:36:27,707 - INFO -  22/322 [=>............................] - ETA: 1s
 32/322 [=>............................] - ETA: 1s2025-07-27 21:36:27,759 - INFO -  32/322 [=>............................] - ETA: 1s
 42/322 [==>...........................] - ETA: 1s2025-07-27 21:36:27,811 - INFO -  42/322 [==>...........................] - ETA: 1s
 52/322 [===>..........................] - ETA: 1s2025-07-27 21:36:27,863 - INFO -  52/322 [===>..........................] - ETA: 1s
 62/322 [====>.........................] - ETA: 1s2025-07-27 21:36:27,916 - INFO -  62/322 [====>.........................] - ETA: 1s
 72/322 [=====>........................] - ETA: 1s2025-07-27 21:36:27,967 - INFO -  72/322 [=====>........................] - ETA: 1s
 82/322 [======>.......................] - ETA: 1s2025-07-27 21:36:28,019 - INFO -  82/322 [======>.......................] - ETA: 1s
 92/322 [=======>......................] - ETA: 1s2025-07-27 21:36:28,071 - INFO -  92/322 [=======>......................] - ETA: 1s
102/322 [========>.....................] - ETA: 1s2025-07-27 21:36:28,123 - INFO - 102/322 [========>.....................] - ETA: 1s
112/322 [=========>....................] - ETA: 1s2025-07-27 21:36:28,175 - INFO - 112/322 [=========>....................] - ETA: 1s
122/322 [==========>...................] - ETA: 1s2025-07-27 21:36:28,226 - INFO - 122/322 [==========>...................] - ETA: 1s
132/322 [===========>..................] - ETA: 0s2025-07-27 21:36:28,280 - INFO - 132/322 [===========>..................] - ETA: 0s
142/322 [============>.................] - ETA: 0s2025-07-27 21:36:28,334 - INFO - 142/322 [============>.................] - ETA: 0s
152/322 [=============>................] - ETA: 0s2025-07-27 21:36:28,387 - INFO - 152/322 [=============>................] - ETA: 0s
162/322 [==============>...............] - ETA: 0s2025-07-27 21:36:28,442 - INFO - 162/322 [==============>...............] - ETA: 0s
172/322 [===============>..............] - ETA: 0s2025-07-27 21:36:28,494 - INFO - 172/322 [===============>..............] - ETA: 0s
182/322 [===============>..............] - ETA: 0s2025-07-27 21:36:28,545 - INFO - 182/322 [===============>..............] - ETA: 0s
192/322 [================>.............] - ETA: 0s2025-07-27 21:36:28,597 - INFO - 192/322 [================>.............] - ETA: 0s
202/322 [=================>............] - ETA: 0s2025-07-27 21:36:28,649 - INFO - 202/322 [=================>............] - ETA: 0s
212/322 [==================>...........] - ETA: 0s2025-07-27 21:36:28,701 - INFO - 212/322 [==================>...........] - ETA: 0s
222/322 [===================>..........] - ETA: 0s2025-07-27 21:36:28,752 - INFO - 222/322 [===================>..........] - ETA: 0s
232/322 [====================>.........] - ETA: 0s2025-07-27 21:36:28,804 - INFO - 232/322 [====================>.........] - ETA: 0s
242/322 [=====================>........] - ETA: 0s2025-07-27 21:36:28,856 - INFO - 242/322 [=====================>........] - ETA: 0s
252/322 [======================>.......] - ETA: 0s2025-07-27 21:36:28,908 - INFO - 252/322 [======================>.......] - ETA: 0s
262/322 [=======================>......] - ETA: 0s2025-07-27 21:36:28,960 - INFO - 262/322 [=======================>......] - ETA: 0s
272/322 [========================>.....] - ETA: 0s2025-07-27 21:36:29,012 - INFO - 272/322 [========================>.....] - ETA: 0s
282/322 [=========================>....] - ETA: 0s2025-07-27 21:36:29,064 - INFO - 282/322 [=========================>....] - ETA: 0s
292/322 [==========================>...] - ETA: 0s2025-07-27 21:36:29,116 - INFO - 292/322 [==========================>...] - ETA: 0s
302/322 [===========================>..] - ETA: 0s2025-07-27 21:36:29,169 - INFO - 302/322 [===========================>..] - ETA: 0s
312/322 [============================>.] - ETA: 0s2025-07-27 21:36:29,220 - INFO - 312/322 [============================>.] - ETA: 0s
322/322 [==============================] - ETA: 0s2025-07-27 21:36:29,272 - INFO - 322/322 [==============================] - ETA: 0s
322/322 [==============================] - 2s 5ms/step
2025-07-27 21:36:29,272 - INFO - 322/322 [==============================] - 2s 5ms/step
2025-07-27 21:36:29,619 - INFO - Baseline inference completed in 2.26s
2025-07-27 21:36:30,074 - INFO - Reassembling baseline patches...
2025-07-27 21:36:30,171 - INFO - Saving NPZ files of raw reconstructions...
2025-07-27 21:36:30,232 - INFO - Unified reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/reconstructions.npz
2025-07-27 21:36:30,232 - INFO - Metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/reconstructions_metadata.txt
2025-07-27 21:36:30,232 - INFO - Unified NPZ reconstruction file saved successfully!
2025-07-27 21:36:30,232 - INFO - Performing coordinate-based alignment of ground truth...
2025-07-27 21:36:30,232 - INFO - Ground truth original shape: (232, 232)
2025-07-27 21:36:30,232 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:30,233 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:30,233 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:36:30,233 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:36:30,233 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:30,233 - INFO - --- Alignment complete ---
2025-07-27 21:36:30,233 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:30,233 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:30,233 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(185, 185)
2025-07-27 21:36:30,233 - INFO - Center-cropping from (188, 188) to (185, 185)
2025-07-27 21:36:30,233 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:30,233 - INFO - --- Alignment complete ---
2025-07-27 21:36:30,233 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-07-27 21:36:30,233 - INFO - Calculated ground truth crop region: rows [23:208], cols [23:208]
2025-07-27 21:36:30,233 - INFO - Initial shapes: Recon=(359, 359), Cropped GT=(185, 185)
2025-07-27 21:36:30,233 - INFO - Center-cropping from (359, 359) to (185, 185)
2025-07-27 21:36:30,233 - INFO - Final aligned shape: (185, 185)
2025-07-27 21:36:30,233 - INFO - --- Alignment complete ---
2025-07-27 21:36:30,233 - INFO - Skipping registration (--skip-registration specified)
2025-07-27 21:36:30,233 - INFO - Final evaluation shapes: PINN (185, 185), Baseline (185, 185), Tike (185, 185), GT (185, 185)
Amplitude normalization scale factor: 1.5274252025-07-27 21:36:30,238 - INFO - Amplitude normalization scale factor: 1.527425

mean scale adjustment:2025-07-27 21:36:30,238 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,238 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,238 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,238 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:30,257 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.806989, std=0.090508, shape=(181, 181, 1)2025-07-27 21:36:30,257 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.806989, std=0.090508, shape=(181, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:30,257 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.399718, shape=(181, 181)2025-07-27 21:36:30,257 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.399718, shape=(181, 181)

performed by index method2025-07-27 21:36:30,261 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,271 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,280 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:30,290 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,290 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,290 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,290 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:30,290 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:30,298 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,308 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,317 - INFO - performed by index method

2025-07-27 21:36:30,327 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.539, phase=0.887, MS-SSIM: amp=0.706, phase=0.842
Amplitude normalization scale factor: 0.9811892025-07-27 21:36:30,330 - INFO - Amplitude normalization scale factor: 0.981189

mean scale adjustment:2025-07-27 21:36:30,330 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,330 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,330 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,330 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:30,331 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.256246, std=0.000000, shape=(181, 181, 1)2025-07-27 21:36:30,331 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=1.256246, std=0.000000, shape=(181, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:30,331 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)2025-07-27 21:36:30,332 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.000000, shape=(181, 181)

performed by index method2025-07-27 21:36:30,335 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,344 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,354 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:30,364 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,364 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,364 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,364 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:30,364 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:30,372 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,382 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,391 - INFO - performed by index method

2025-07-27 21:36:30,401 - INFO - Baseline evaluation complete. SSIM: amp=0.086, phase=0.521, MS-SSIM: amp=0.031, phase=0.029
Amplitude normalization scale factor: 1.7514242025-07-27 21:36:30,404 - INFO - Amplitude normalization scale factor: 1.751424

mean scale adjustment:2025-07-27 21:36:30,404 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,404 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,404 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,404 - INFO - 1

DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)2025-07-27 21:36:30,405 - INFO - DEBUG eval_reconstruction [Tike]: amp_target stats: mean=1.232615, std=0.098010, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703779, std=0.059649, shape=(181, 181, 1)2025-07-27 21:36:30,405 - INFO - DEBUG eval_reconstruction [Tike]: amp_pred stats: mean=0.703779, std=0.059649, shape=(181, 181, 1)

DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)2025-07-27 21:36:30,405 - INFO - DEBUG eval_reconstruction [Tike]: phi_target stats: mean=0.000000, std=0.286766, shape=(181, 181)

DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.282549, shape=(181, 181)2025-07-27 21:36:30,406 - INFO - DEBUG eval_reconstruction [Tike]: phi_pred stats: mean=-0.000000, std=0.282549, shape=(181, 181)

performed by index method2025-07-27 21:36:30,409 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,418 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,428 - INFO - performed by index method

mean scale adjustment:2025-07-27 21:36:30,438 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,438 - INFO - 1

mean scale adjustment:2025-07-27 21:36:30,438 - INFO - mean scale adjustment:
 12025-07-27 21:36:30,438 - INFO - 1

Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]2025-07-27 21:36:30,438 - INFO - Phase preprocessing: plane-fitted range [-0.698, 0.510] -> scaled range [0.389, 0.581]

performed by index method2025-07-27 21:36:30,446 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,455 - INFO - performed by index method

performed by index method2025-07-27 21:36:30,465 - INFO - performed by index method

2025-07-27 21:36:30,475 - INFO - Tike evaluation complete. SSIM: amp=0.680, phase=0.895, MS-SSIM: amp=0.857, phase=0.861
2025-07-27 21:36:30,476 - INFO - Metrics saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/comparison_metrics.csv

--- Comparison Metrics ---2025-07-27 21:36:30,476 - INFO - --- Comparison Metrics ---

     model             metric  amplitude     phase    value
PtychoPINN                mae   0.074187  0.151476      NaN
PtychoPINN                mse   0.008547  0.035849      NaN
PtychoPINN               psnr  68.812850 62.586071      NaN
PtychoPINN               ssim   0.539242  0.887492      NaN
PtychoPINN            ms_ssim   0.705819  0.842234      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082235      NaN
  Baseline               psnr  68.305419 58.980249      NaN
  Baseline               ssim   0.085874  0.520955      NaN
  Baseline            ms_ssim   0.031289  0.028860      NaN
  Baseline              frc50   1.000000  2.000000      NaN
      Tike                mae   0.047288  0.092258      NaN
      Tike                mse   0.003864  0.017409      NaN
      Tike               psnr  72.260932 65.723010      NaN
      Tike               ssim   0.679634  0.894751      NaN
      Tike            ms_ssim   0.856514  0.860794      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.544765
  Baseline computation_time_s        NaN       NaN 2.2575912025-07-27 21:36:30,478 - INFO - model             metric  amplitude     phase    value
PtychoPINN                mae   0.074187  0.151476      NaN
PtychoPINN                mse   0.008547  0.035849      NaN
PtychoPINN               psnr  68.812850 62.586071      NaN
PtychoPINN               ssim   0.539242  0.887492      NaN
PtychoPINN            ms_ssim   0.705819  0.842234      NaN
PtychoPINN              frc50   1.000000  1.000000      NaN
  Baseline                mae   0.085036  0.251303      NaN
  Baseline                mse   0.009606  0.082235      NaN
  Baseline               psnr  68.305419 58.980249      NaN
  Baseline               ssim   0.085874  0.520955      NaN
  Baseline            ms_ssim   0.031289  0.028860      NaN
  Baseline              frc50   1.000000  2.000000      NaN
      Tike                mae   0.047288  0.092258      NaN
      Tike                mse   0.003864  0.017409      NaN
      Tike               psnr  72.260932 65.723010      NaN
      Tike               ssim   0.679634  0.894751      NaN
      Tike            ms_ssim   0.856514  0.860794      NaN
      Tike              frc50  25.000000 43.000000      NaN
PtychoPINN computation_time_s        NaN       NaN 2.544765
  Baseline computation_time_s        NaN       NaN 2.257591

2025-07-27 21:36:30,478 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/pinn_frc_curves.csv
2025-07-27 21:36:30,479 - INFO - FRC curves saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/baseline_frc_curves.csv
2025-07-27 21:36:30,479 - INFO - Saving NPZ files of aligned reconstructions...
2025-07-27 21:36:30,529 - INFO - Unified aligned reconstructions saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/reconstructions_aligned.npz
2025-07-27 21:36:30,529 - INFO - Aligned metadata saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/reconstructions_aligned_metadata.txt
2025-07-27 21:36:30,529 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-07-27 21:36:30,572 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.672, 0.919) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,573 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (1.256, 1.256) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,573 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (1.564, 2.601) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,574 - INFO - Baseline phase color scale (vmin, vmax) set to: (-2.225, -2.225) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,575 - INFO - Tike amplitude color scale (vmin, vmax) set to: (0.620, 0.774) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,575 - INFO - Tike phase color scale (vmin, vmax) set to: (-0.479, 0.262) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,586 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (1.097, 1.351) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:30,587 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-2.804, -2.034) using 10.0/90.0 percentiles [per-panel].
2025-07-27 21:36:31,252 - INFO - Visual comparison saved to 3way_bothhalves_full_2xtest/train_2048/trial_3/comparison_plot.png
2025-07-27 21:36:31,252 - INFO - 
Comparison complete!
2025-07-27 21:36:31,252 - INFO - Results saved to: 3way_bothhalves_full_2xtest/train_2048/trial_3
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2025-07-27 21:36:31,598 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
2025-07-27 21:36:31,598 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._iterations
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
2025-07-27 21:36:31,598 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.25
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.26
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.27
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.28
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.29
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.30
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.31
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.32
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.33
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.34
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.35
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.36
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.37
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.38
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.39
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.40
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.41
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.42
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.43
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.44
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.45
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.46
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.47
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.48
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.49
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.50
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.51
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.52
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.53
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.54
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.55
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.56
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.57
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.58
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.59
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.60
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.61
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.62
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.63
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
2025-07-27 21:36:31,599 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.64
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.65
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.66
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.67
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.68
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.69
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.70
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.71
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.72
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.73
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.74
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.75
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.76
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.77
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.78
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.79
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.80
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.81
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.82
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.83
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.84
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.85
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.86
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.87
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).optimizer._variables.88
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.2.count
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.total
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
2025-07-27 21:36:31,600 - WARNING - Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.3.count
[2025-07-27 21:36:32] SUCCESS: Model comparison (train_size=2048, trial=3)
[2025-07-27 21:36:32] Completed comparisons for train_size=2048
[2025-07-27 21:36:32] Model comparison phase completed
[2025-07-27 21:36:32] === STEP 4: Results Aggregation ===
[2025-07-27 21:36:32] EXECUTING: PSNR phase generalization plot
[2025-07-27 21:36:32] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
21:36:32 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:32 - INFO - Analyzing psnr_phase
21:36:32 - INFO - Discovered 6 comparison files
21:36:32 - INFO - Found multi-trial data for some training sizes
21:36:32 - INFO - Multi-trial data detected - using statistical aggregation
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Loaded 18 trial records
21:36:32 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:32 - INFO - Filtering details by configuration:
21:36:32 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:32 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:32 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:32 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:32 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:32 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:32 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:32 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:32 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:32 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:32 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:32 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:32 - INFO - NaN exclusion summary:
21:36:32 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:32 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:32 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:32 - INFO - Total trial records: 18
21:36:32 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:32 - INFO -   passed: 9 (50.0%)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:32 - INFO - Loaded 18 trial records
21:36:32 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:32 - INFO - Filtering details by configuration:
21:36:32 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:32 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:32 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:32 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:32 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:32 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:32 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:32 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:32 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:32 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:32 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:32 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:32 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:32 - INFO - NaN exclusion summary:
21:36:32 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:32 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:32 - INFO - Extracted 4 data points for psnr_phase (using mean)
21:36:32 - WARNING - Model tike missing data for training sizes: [256]
21:36:32 - WARNING - Model baseline missing data for training sizes: [256]
21:36:32 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/psnr_phase_generalization.png
21:36:32 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:32 - INFO - Exported 4 rows with 14 metrics
21:36:32 - INFO - Processing complete!
21:36:32 - INFO - Outputs:
21:36:32 - INFO -   - Plot: 3way_bothhalves_full_2xtest/psnr_phase_generalization.png
21:36:32 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:32 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:32 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:32 - INFO - Training sizes: [256, 2048]
21:36:32 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:32 - INFO -   Train size 256: 2-2 trials per model
21:36:32 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:32] SUCCESS: PSNR phase generalization plot
[2025-07-27 21:36:32] EXECUTING: FRC amplitude generalization plot
[2025-07-27 21:36:32] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
21:36:33 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:33 - INFO - Analyzing frc50_amp
21:36:33 - INFO - Discovered 6 comparison files
21:36:33 - INFO - Found multi-trial data for some training sizes
21:36:33 - INFO - Multi-trial data detected - using statistical aggregation
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Loaded 18 trial records
21:36:33 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:33 - INFO - Filtering details by configuration:
21:36:33 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:33 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:33 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:33 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:33 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:33 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:33 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:33 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:33 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:33 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:33 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:33 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:33 - INFO - NaN exclusion summary:
21:36:33 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:33 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:33 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:33 - INFO - Total trial records: 18
21:36:33 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:33 - INFO -   passed: 9 (50.0%)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:33 - INFO - Loaded 18 trial records
21:36:33 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:33 - INFO - Filtering details by configuration:
21:36:33 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:33 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:33 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:33 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:33 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:33 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:33 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:33 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:33 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:33 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:33 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:33 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:33 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:33 - INFO - NaN exclusion summary:
21:36:33 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:33 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:33 - INFO - Extracted 4 data points for frc50_amp (using mean)
21:36:33 - WARNING - Model baseline missing data for training sizes: [256]
21:36:33 - WARNING - Model tike missing data for training sizes: [256]
21:36:33 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/frc50_amp_generalization.png
21:36:33 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:33 - INFO - Exported 4 rows with 14 metrics
21:36:33 - INFO - Processing complete!
21:36:33 - INFO - Outputs:
21:36:33 - INFO -   - Plot: 3way_bothhalves_full_2xtest/frc50_amp_generalization.png
21:36:33 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:33 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:33 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:33 - INFO - Training sizes: [256, 2048]
21:36:33 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:33 - INFO -   Train size 256: 2-2 trials per model
21:36:33 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:33] SUCCESS: FRC amplitude generalization plot
[2025-07-27 21:36:33] EXECUTING: MAE amplitude generalization plot
[2025-07-27 21:36:33] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
21:36:34 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:34 - INFO - Analyzing mae_amp
21:36:34 - INFO - Discovered 6 comparison files
21:36:34 - INFO - Found multi-trial data for some training sizes
21:36:34 - INFO - Multi-trial data detected - using statistical aggregation
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Loaded 18 trial records
21:36:34 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:34 - INFO - Filtering details by configuration:
21:36:34 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:34 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:34 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:34 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:34 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:34 - INFO - NaN exclusion summary:
21:36:34 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:34 - INFO - Total trial records: 18
21:36:34 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:34 - INFO -   passed: 9 (50.0%)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Loaded 18 trial records
21:36:34 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:34 - INFO - Filtering details by configuration:
21:36:34 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:34 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:34 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:34 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:34 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:34 - INFO - NaN exclusion summary:
21:36:34 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO - Extracted 4 data points for mae_amp (using mean)
21:36:34 - WARNING - Model baseline missing data for training sizes: [256]
21:36:34 - WARNING - Model tike missing data for training sizes: [256]
21:36:34 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/mae_amp_generalization.png
21:36:34 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:34 - INFO - Exported 4 rows with 14 metrics
21:36:34 - INFO - Processing complete!
21:36:34 - INFO - Outputs:
21:36:34 - INFO -   - Plot: 3way_bothhalves_full_2xtest/mae_amp_generalization.png
21:36:34 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:34 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:34 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:34 - INFO - Training sizes: [256, 2048]
21:36:34 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:34 - INFO -   Train size 256: 2-2 trials per model
21:36:34 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:34] SUCCESS: MAE amplitude generalization plot
[2025-07-27 21:36:34] EXECUTING: SSIM amplitude generalization plot
[2025-07-27 21:36:34] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
21:36:34 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:34 - INFO - Analyzing ssim_amp
21:36:34 - INFO - Discovered 6 comparison files
21:36:34 - INFO - Found multi-trial data for some training sizes
21:36:34 - INFO - Multi-trial data detected - using statistical aggregation
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Loaded 18 trial records
21:36:34 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:34 - INFO - Filtering details by configuration:
21:36:34 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:34 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:34 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:34 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:34 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:34 - INFO - NaN exclusion summary:
21:36:34 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:34 - INFO - Total trial records: 18
21:36:34 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:34 - INFO -   passed: 9 (50.0%)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:34 - INFO - Loaded 18 trial records
21:36:34 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:34 - INFO - Filtering details by configuration:
21:36:34 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:34 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:34 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:34 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:34 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:34 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:34 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:34 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:34 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:34 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:34 - INFO - NaN exclusion summary:
21:36:34 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:34 - INFO - Extracted 4 data points for ssim_amp (using mean)
21:36:34 - WARNING - Model baseline missing data for training sizes: [256]
21:36:34 - WARNING - Model tike missing data for training sizes: [256]
21:36:35 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/ssim_amp_generalization.png
21:36:35 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:35 - INFO - Exported 4 rows with 14 metrics
21:36:35 - INFO - Processing complete!
21:36:35 - INFO - Outputs:
21:36:35 - INFO -   - Plot: 3way_bothhalves_full_2xtest/ssim_amp_generalization.png
21:36:35 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:35 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:35 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:35 - INFO - Training sizes: [256, 2048]
21:36:35 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:35 - INFO -   Train size 256: 2-2 trials per model
21:36:35 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:35] SUCCESS: SSIM amplitude generalization plot
[2025-07-27 21:36:35] EXECUTING: SSIM phase generalization plot
[2025-07-27 21:36:35] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
21:36:35 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:35 - INFO - Analyzing ssim_phase
21:36:35 - INFO - Discovered 6 comparison files
21:36:35 - INFO - Found multi-trial data for some training sizes
21:36:35 - INFO - Multi-trial data detected - using statistical aggregation
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Loaded 18 trial records
21:36:35 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:35 - INFO - Filtering details by configuration:
21:36:35 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:35 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:35 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:35 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:35 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:35 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:35 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:35 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:35 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:35 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:35 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:35 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:35 - INFO - NaN exclusion summary:
21:36:35 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:35 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:35 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:35 - INFO - Total trial records: 18
21:36:35 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:35 - INFO -   passed: 9 (50.0%)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:35 - INFO - Loaded 18 trial records
21:36:35 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:35 - INFO - Filtering details by configuration:
21:36:35 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:35 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:35 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:35 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:35 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:35 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:35 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:35 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:35 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:35 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:35 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:35 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:35 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:35 - INFO - NaN exclusion summary:
21:36:35 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:35 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:35 - INFO - Extracted 4 data points for ssim_phase (using mean)
21:36:35 - WARNING - Model tike missing data for training sizes: [256]
21:36:35 - WARNING - Model baseline missing data for training sizes: [256]
21:36:35 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/ssim_phase_generalization.png
21:36:35 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:35 - INFO - Exported 4 rows with 14 metrics
21:36:35 - INFO - Processing complete!
21:36:35 - INFO - Outputs:
21:36:35 - INFO -   - Plot: 3way_bothhalves_full_2xtest/ssim_phase_generalization.png
21:36:35 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:35 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:35 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:35 - INFO - Training sizes: [256, 2048]
21:36:35 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:35 - INFO -   Train size 256: 2-2 trials per model
21:36:35 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:35] SUCCESS: SSIM phase generalization plot
[2025-07-27 21:36:35] EXECUTING: MS-SSIM amplitude generalization plot
[2025-07-27 21:36:35] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
21:36:36 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:36 - INFO - Analyzing ms_ssim_amp
21:36:36 - INFO - Discovered 6 comparison files
21:36:36 - INFO - Found multi-trial data for some training sizes
21:36:36 - INFO - Multi-trial data detected - using statistical aggregation
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Loaded 18 trial records
21:36:36 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:36 - INFO - Filtering details by configuration:
21:36:36 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:36 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:36 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:36 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:36 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:36 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:36 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:36 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:36 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:36 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:36 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:36 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:36 - INFO - NaN exclusion summary:
21:36:36 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:36 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:36 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:36 - INFO - Total trial records: 18
21:36:36 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:36 - INFO -   passed: 9 (50.0%)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:36 - INFO - Loaded 18 trial records
21:36:36 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:36 - INFO - Filtering details by configuration:
21:36:36 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:36 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:36 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:36 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:36 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:36 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:36 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:36 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:36 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:36 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:36 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:36 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:36 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:36 - INFO - NaN exclusion summary:
21:36:36 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:36 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:36 - INFO - Extracted 4 data points for ms_ssim_amp (using mean)
21:36:36 - WARNING - Model tike missing data for training sizes: [256]
21:36:36 - WARNING - Model baseline missing data for training sizes: [256]
21:36:36 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/ms_ssim_amp_generalization.png
21:36:36 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:36 - INFO - Exported 4 rows with 14 metrics
21:36:36 - INFO - Processing complete!
21:36:36 - INFO - Outputs:
21:36:36 - INFO -   - Plot: 3way_bothhalves_full_2xtest/ms_ssim_amp_generalization.png
21:36:36 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:36 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:36 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:36 - INFO - Training sizes: [256, 2048]
21:36:36 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:36 - INFO -   Train size 256: 2-2 trials per model
21:36:36 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:36] SUCCESS: MS-SSIM amplitude generalization plot
[2025-07-27 21:36:36] EXECUTING: MS-SSIM phase generalization plot
[2025-07-27 21:36:36] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_bothhalves_full_2xtest' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
21:36:37 - INFO - Processing study directory: 3way_bothhalves_full_2xtest
21:36:37 - INFO - Analyzing ms_ssim_phase
21:36:37 - INFO - Discovered 6 comparison files
21:36:37 - INFO - Found multi-trial data for some training sizes
21:36:37 - INFO - Multi-trial data detected - using statistical aggregation
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Loaded 18 trial records
21:36:37 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:37 - INFO - Filtering details by configuration:
21:36:37 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:37 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:37 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:37 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:37 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:37 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:37 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:37 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:37 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:37 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:37 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:37 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:37 - INFO - NaN exclusion summary:
21:36:37 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:37 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:37 - INFO - All trials results exported to: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:37 - INFO - Total trial records: 18
21:36:37 - INFO -   filtered_low_msssim: 9 (50.0%)
21:36:37 - INFO -   passed: 9 (50.0%)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
21:36:37 - INFO - Loaded 18 trial records
21:36:37 - INFO - Filtered out 9 trial records with MS-SSIM (phase) < 0.3
21:36:37 - INFO - Filtering details by configuration:
21:36:37 - INFO -   train_size=256, model=pinn: 1 filtered, 2 remaining
21:36:37 - INFO -   train_size=2048, model=baseline: 1 filtered, 2 remaining
21:36:37 - INFO -   train_size=2048, model=pinn: 1 filtered, 2 remaining
21:36:37 - INFO - Proceeding to aggregation with 9 trial records (after any filtering applied)
21:36:37 - WARNING - Only 2 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
21:36:37 - WARNING - Only 2 trials for train_size=2048, model=baseline. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=baseline)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=baseline)
21:36:37 - WARNING - Only 2 trials for train_size=2048, model=pinn. Percentile calculations may be unreliable.
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_amp (train_size=2048, model=pinn)
21:36:37 - WARNING - All 2 trials have NaN for computation_time_s_phase (train_size=2048, model=pinn)
21:36:37 - WARNING - All 3 trials have NaN for computation_time_s_amp (train_size=2048, model=tike)
21:36:37 - WARNING - All 3 trials have NaN for computation_time_s_phase (train_size=2048, model=tike)
21:36:37 - INFO - Computed statistics for 4 (train_size, model_type) combinations
21:36:37 - INFO - Train size 256: 2.0-2.0 trials (avg: 2.0)
21:36:37 - INFO - Train size 2048: 2.0-3.0 trials (avg: 2.3)
21:36:37 - INFO - NaN exclusion summary:
21:36:37 - INFO -   computation_time_s_amp: 9 NaN values excluded (100.0% of 9 total trials)
21:36:37 - INFO -   computation_time_s_phase: 9 NaN values excluded (100.0% of 9 total trials)
21:36:37 - INFO - Extracted 4 data points for ms_ssim_phase (using mean)
21:36:37 - WARNING - Model baseline missing data for training sizes: [256]
21:36:37 - WARNING - Model tike missing data for training sizes: [256]
21:36:37 - INFO - Plot saved to: 3way_bothhalves_full_2xtest/ms_ssim_phase_generalization.png
21:36:37 - INFO - Statistical results exported to: 3way_bothhalves_full_2xtest/results.csv
21:36:37 - INFO - Exported 4 rows with 14 metrics
21:36:37 - INFO - Processing complete!
21:36:37 - INFO - Outputs:
21:36:37 - INFO -   - Plot: 3way_bothhalves_full_2xtest/ms_ssim_phase_generalization.png
21:36:37 - INFO -   - Data: 3way_bothhalves_full_2xtest/results.csv
21:36:37 - INFO -   - All trials: 3way_bothhalves_full_2xtest/results_all_trials.csv
21:36:37 - INFO - Summary: 3 models, 2 training sizes, 9 total trials
21:36:37 - INFO - Training sizes: [256, 2048]
21:36:37 - INFO - Model types: ['baseline', 'pinn', 'tike']
21:36:37 - INFO -   Train size 256: 2-2 trials per model
21:36:37 - INFO -   Train size 2048: 2-3 trials per model
[2025-07-27 21:36:37] SUCCESS: MS-SSIM phase generalization plot
[2025-07-27 21:36:37] Results aggregation completed
[2025-07-27 21:36:37] === Generating Summary Report ===
[2025-07-27 21:36:37] Summary report generated: 3way_bothhalves_full_2xtest/STUDY_SUMMARY.md
[2025-07-27 21:36:37] === Study Completed Successfully ===
[2025-07-27 21:36:37] Training sizes tested: 2
[2025-07-27 21:36:37] Trials per size: 3
[2025-07-27 21:36:37] Total trials completed: 6
[2025-07-27 21:36:37] Total runtime: 00:29:55
[2025-07-27 21:36:37] Results directory: 3way_bothhalves_full_2xtest
[2025-07-27 21:36:37] Summary report: 3way_bothhalves_full_2xtest/STUDY_SUMMARY.md
