2026-01-27 13:11:25.474982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769548285.486817  822987 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769548285.490514  822987 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769548285.500710  822987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548285.500720  822987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548285.500722  822987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548285.500723  822987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-27 13:11:25.503531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769548288.140900  822987 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769548288.142134  822987 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING:tensorflow:From /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
Instructions for updating:
Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
2026-01-27 13:11:32.427689: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769548328.009654  822987 service.cc:152] XLA service 0x20022bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769548328.009673  822987 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-27 13:12:08.025497: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769548328.042943  822987 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769548328.256091  822987 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[grid_lines_workflow] Starting N=128, gridsize=1
[1/7] Loading and scaling probe...
Interpolating array from (64, 64) with zoom factor 2.0...
  New shape: (128, 128)
Applying Gaussian filter to complex array of shape (128, 128) (sigma=0.5)...
- Amplitude and unwrapped phase smoothed.
[2/7] Running grid simulation...
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Loading result from disk cache.
No cached result found. Calculating and caching the result.
simulating gaussian position jitter, scale 0.0
Sampling on regular grid
input shape (None, 128, 128, 1)
DEBUG: generating grid-mode ground truth image
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
[3/7] Saving datasets...
[4/7] Training PINN model...
DEBUG: Setting intensity_scale to 494.10587 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878603-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250924-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.02388911-0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.01775611-0.01380389j]
  [ 0.02431883-0.01161062j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.03569121+0.0154982j ]
  ...
  [ 0.01803495+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 128
amp_activation: sigmoid
architecture: cnn
backend: tensorflow
batch_size: 16
bigN: 128
big_gridsize: 10
data_source: lines
debug: True
default_probe_scale: 0.7
enable_oversampling: False
fno_blocks: 4
fno_cnn_blocks: 2
fno_input_transform: none
fno_modes: 12
fno_width: 32
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 494.1058654785156
intensity_scale.trainable: True
label: 
mae_weight: 1.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 512
neighbor_count: 4
nepochs: 1
nimgs_test: 1
nimgs_train: 1
nll_weight: 0.0
nphotons: 1000000000.0
npseed: 42
object.big: False
offset: 4
outer_offset_test: 20
outer_offset_train: 8
output_prefix: training_outputs
pad_object: True
positions.provided: True
probe:
  shape: (128, 128, 1)
  mean: -0.017-0.002j
  std: 0.672
  min: -3.810-1.052j
  max: 2.870-0.504j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: True
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 1
DEBUG _flat_to_channel: N from global params: 128
DEBUG _flat_to_channel: input shape=(4489, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m29:53[0m 7s/step - intensity_scaler_inv_loss: 25.2709 - loss: 25.2709 - pred_intensity_loss: -531455.0625 - trimmed_obj_loss: 0.0000e+00[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.1750 - loss: 27.1750 - pred_intensity_loss: -544031.0625 - trimmed_obj_loss: 0.0000e+00 [1m  6/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 29.8767 - loss: 29.8767 - pred_intensity_loss: -547250.0625 - trimmed_obj_loss: 0.0000e+00[1m  8/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 29.8012 - loss: 29.8012 - pred_intensity_loss: -546993.3750 - trimmed_obj_loss: 0.0000e+00[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 29.3572 - loss: 29.3572 - pred_intensity_loss: -546348.5625 - trimmed_obj_loss: 0.0000e+00[1m 14/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 28.7583 - loss: 28.7583 - pred_intensity_loss: -543716.6875 - trimmed_obj_loss: 0.0000e+00[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 28.2165 - loss: 28.2165 - pred_intensity_loss: -541833.0000 - trimmed_obj_loss: 0.0000e+00[1m 20/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.7327 - loss: 27.7327 - pred_intensity_loss: -540167.2500 - trimmed_obj_loss: 0.0000e+00[1m 22/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.4438 - loss: 27.4438 - pred_intensity_loss: -539112.9375 - trimmed_obj_loss: 0.0000e+00[1m 24/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.1921 - loss: 27.1921 - pred_intensity_loss: -538397.3750 - trimmed_obj_loss: 0.0000e+00[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 26.8411 - loss: 26.8411 - pred_intensity_loss: -537342.7500 - trimmed_obj_loss: 0.0000e+00[1m 30/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 26.5277 - loss: 26.5277 - pred_intensity_loss: -536433.9375 - trimmed_obj_loss: 0.0000e+00[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.2411 - loss: 26.2411 - pred_intensity_loss: -535662.2500 - trimmed_obj_loss: 0.0000e+00[1m 36/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.9863 - loss: 25.9863 - pred_intensity_loss: -534976.2500 - trimmed_obj_loss: 0.0000e+00[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.7565 - loss: 25.7565 - pred_intensity_loss: -534250.5000 - trimmed_obj_loss: 0.0000e+00[1m 42/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.5508 - loss: 25.5508 - pred_intensity_loss: -533599.5000 - trimmed_obj_loss: 0.0000e+00[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.3608 - loss: 25.3608 - pred_intensity_loss: -533056.6250 - trimmed_obj_loss: 0.0000e+00[1m 48/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.1810 - loss: 25.1810 - pred_intensity_loss: -532624.7500 - trimmed_obj_loss: 0.0000e+00[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.0082 - loss: 25.0082 - pred_intensity_loss: -532200.5000 - trimmed_obj_loss: 0.0000e+00[1m 54/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.8455 - loss: 24.8455 - pred_intensity_loss: -531795.0000 - trimmed_obj_loss: 0.0000e+00[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.6899 - loss: 24.6899 - pred_intensity_loss: -531404.6875 - trimmed_obj_loss: 0.0000e+00[1m 60/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.5408 - loss: 24.5408 - pred_intensity_loss: -531089.6250 - trimmed_obj_loss: 0.0000e+00[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.4030 - loss: 24.4030 - pred_intensity_loss: -530856.0000 - trimmed_obj_loss: 0.0000e+00[1m 66/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.2741 - loss: 24.2741 - pred_intensity_loss: -530580.1875 - trimmed_obj_loss: 0.0000e+00[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.1525 - loss: 24.1525 - pred_intensity_loss: -530265.3750 - trimmed_obj_loss: 0.0000e+00[1m 72/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.0384 - loss: 24.0384 - pred_intensity_loss: -530011.2500 - trimmed_obj_loss: 0.0000e+00[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.9291 - loss: 23.9291 - pred_intensity_loss: -529833.4375 - trimmed_obj_loss: 0.0000e+00[1m 78/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.8231 - loss: 23.8231 - pred_intensity_loss: -529694.9375 - trimmed_obj_loss: 0.0000e+00[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.7200 - loss: 23.7200 - pred_intensity_loss: -529587.6250 - trimmed_obj_loss: 0.0000e+00[1m 84/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.6203 - loss: 23.6203 - pred_intensity_loss: -529494.8125 - trimmed_obj_loss: 0.0000e+00[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.5231 - loss: 23.5231 - pred_intensity_loss: -529359.3125 - trimmed_obj_loss: 0.0000e+00[1m 90/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.4284 - loss: 23.4284 - pred_intensity_loss: -529245.5000 - trimmed_obj_loss: 0.0000e+00[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.3356 - loss: 23.3356 - pred_intensity_loss: -529089.5000 - trimmed_obj_loss: 0.0000e+00[1m 96/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.2446 - loss: 23.2446 - pred_intensity_loss: -528939.9375 - trimmed_obj_loss: 0.0000e+00[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.1555 - loss: 23.1555 - pred_intensity_loss: -528811.3750 - trimmed_obj_loss: 0.0000e+00[1m102/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.0676 - loss: 23.0676 - pred_intensity_loss: -528671.8750 - trimmed_obj_loss: 0.0000e+00[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.9816 - loss: 22.9816 - pred_intensity_loss: -528563.6875 - trimmed_obj_loss: 0.0000e+00[1m108/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.8975 - loss: 22.8975 - pred_intensity_loss: -528471.5625 - trimmed_obj_loss: 0.0000e+00[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.8156 - loss: 22.8156 - pred_intensity_loss: -528400.7500 - trimmed_obj_loss: 0.0000e+00[1m114/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.7355 - loss: 22.7355 - pred_intensity_loss: -528353.2500 - trimmed_obj_loss: 0.0000e+00[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.6566 - loss: 22.6566 - pred_intensity_loss: -528295.6250 - trimmed_obj_loss: 0.0000e+00[1m120/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.5788 - loss: 22.5788 - pred_intensity_loss: -528230.4375 - trimmed_obj_loss: 0.0000e+00[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.5021 - loss: 22.5021 - pred_intensity_loss: -528137.6250 - trimmed_obj_loss: 0.0000e+00[1m126/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.4266 - loss: 22.4266 - pred_intensity_loss: -528039.3125 - trimmed_obj_loss: 0.0000e+00[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.3524 - loss: 22.3524 - pred_intensity_loss: -527947.8750 - trimmed_obj_loss: 0.0000e+00[1m132/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.2793 - loss: 22.2793 - pred_intensity_loss: -527861.0625 - trimmed_obj_loss: 0.0000e+00[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.2070 - loss: 22.2070 - pred_intensity_loss: -527786.1250 - trimmed_obj_loss: 0.0000e+00[1m138/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.1357 - loss: 22.1357 - pred_intensity_loss: -527720.6875 - trimmed_obj_loss: 0.0000e+00[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.0654 - loss: 22.0654 - pred_intensity_loss: -527672.2500 - trimmed_obj_loss: 0.0000e+00[1m144/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9957 - loss: 21.9957 - pred_intensity_loss: -527619.6875 - trimmed_obj_loss: 0.0000e+00[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9269 - loss: 21.9269 - pred_intensity_loss: -527556.8125 - trimmed_obj_loss: 0.0000e+00[1m150/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.8587 - loss: 21.8587 - pred_intensity_loss: -527483.7500 - trimmed_obj_loss: 0.0000e+00[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.7912 - loss: 21.7912 - pred_intensity_loss: -527408.5000 - trimmed_obj_loss: 0.0000e+00[1m156/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.7244 - loss: 21.7244 - pred_intensity_loss: -527332.6875 - trimmed_obj_loss: 0.0000e+00[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.6582 - loss: 21.6582 - pred_intensity_loss: -527257.8125 - trimmed_obj_loss: 0.0000e+00[1m162/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.5925 - loss: 21.5925 - pred_intensity_loss: -527193.2500 - trimmed_obj_loss: 0.0000e+00[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.5272 - loss: 21.5272 - pred_intensity_loss: -527133.4375 - trimmed_obj_loss: 0.0000e+00[1m168/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.4625 - loss: 21.4625 - pred_intensity_loss: -527085.1250 - trimmed_obj_loss: 0.0000e+00[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.3986 - loss: 21.3986 - pred_intensity_loss: -527043.3125 - trimmed_obj_loss: 0.0000e+00[1m174/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.3356 - loss: 21.3356 - pred_intensity_loss: -527009.8750 - trimmed_obj_loss: 0.0000e+00[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.2734 - loss: 21.2734 - pred_intensity_loss: -526981.1250 - trimmed_obj_loss: 0.0000e+00[1m180/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.2120 - loss: 21.2120 - pred_intensity_loss: -526954.3750 - trimmed_obj_loss: 0.0000e+00[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.1514 - loss: 21.1514 - pred_intensity_loss: -526925.6250 - trimmed_obj_loss: 0.0000e+00[1m186/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.0913 - loss: 21.0913 - pred_intensity_loss: -526894.6875 - trimmed_obj_loss: 0.0000e+00[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.0317 - loss: 21.0317 - pred_intensity_loss: -526871.8125 - trimmed_obj_loss: 0.0000e+00[1m192/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.9726 - loss: 20.9726 - pred_intensity_loss: -526852.2500 - trimmed_obj_loss: 0.0000e+00[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.9141 - loss: 20.9141 - pred_intensity_loss: -526838.0000 - trimmed_obj_loss: 0.0000e+00[1m198/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.8560 - loss: 20.8560 - pred_intensity_loss: -526835.3125 - trimmed_obj_loss: 0.0000e+00[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.7984 - loss: 20.7984 - pred_intensity_loss: -526836.5000 - trimmed_obj_loss: 0.0000e+00[1m204/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.7411 - loss: 20.7411 - pred_intensity_loss: -526848.1250 - trimmed_obj_loss: 0.0000e+00[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.6842 - loss: 20.6842 - pred_intensity_loss: -526881.5000 - trimmed_obj_loss: 0.0000e+00[1m210/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.6277 - loss: 20.6277 - pred_intensity_loss: -526919.5000 - trimmed_obj_loss: 0.0000e+00[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.5715 - loss: 20.5715 - pred_intensity_loss: -526955.9375 - trimmed_obj_loss: 0.0000e+00[1m216/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.5157 - loss: 20.5157 - pred_intensity_loss: -526992.8125 - trimmed_obj_loss: 0.0000e+00[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.4603 - loss: 20.4603 - pred_intensity_loss: -527022.6250 - trimmed_obj_loss: 0.0000e+00[1m222/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.4054 - loss: 20.4054 - pred_intensity_loss: -527053.8750 - trimmed_obj_loss: 0.0000e+00[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 20.3510 - loss: 20.3510 - pred_intensity_loss: -527080.6875 - trimmed_obj_loss: 0.0000e+00[1m228/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.2970 - loss: 20.2970 - pred_intensity_loss: -527108.4375 - trimmed_obj_loss: 0.0000e+00[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.2435 - loss: 20.2435 - pred_intensity_loss: -527132.8125 - trimmed_obj_loss: 0.0000e+00[1m234/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.1903 - loss: 20.1903 - pred_intensity_loss: -527154.3125 - trimmed_obj_loss: 0.0000e+00[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.1376 - loss: 20.1376 - pred_intensity_loss: -527174.7500 - trimmed_obj_loss: 0.0000e+00[1m240/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.0854 - loss: 20.0854 - pred_intensity_loss: -527197.9375 - trimmed_obj_loss: 0.0000e+00[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.0336 - loss: 20.0336 - pred_intensity_loss: -527219.6250 - trimmed_obj_loss: 0.0000e+00[1m246/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.9822 - loss: 19.9822 - pred_intensity_loss: -527243.6875 - trimmed_obj_loss: 0.0000e+00[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.9313 - loss: 19.9313 - pred_intensity_loss: -527268.0625 - trimmed_obj_loss: 0.0000e+00[1m252/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.8809 - loss: 19.8809 - pred_intensity_loss: -527293.4375 - trimmed_obj_loss: 0.0000e+00[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.8307 - loss: 19.8307 - pred_intensity_loss: -527322.0625 - trimmed_obj_loss: 0.0000e+00[1m258/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.7810 - loss: 19.7810 - pred_intensity_loss: -527355.1250 - trimmed_obj_loss: 0.0000e+00[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.7315 - loss: 19.7315 - pred_intensity_loss: -527387.8125 - trimmed_obj_loss: 0.0000e+00[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.6988 - loss: 19.6988 - pred_intensity_loss: -527411.1250 - trimmed_obj_loss: 0.0000e+00[1m266/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 19.6500 - loss: 19.6500 - pred_intensity_loss: -527449.0625 - trimmed_obj_loss: 0.0000e+00[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step - intensity_scaler_inv_loss: 19.6338 - loss: 19.6339 - pred_intensity_loss: -527461.1875 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 34ms/step - intensity_scaler_inv_loss: 15.3300 - loss: 15.3419 - pred_intensity_loss: -530680.7500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 9.9675 - val_loss: 9.9454 - val_pred_intensity_loss: -527129.8750 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
[4/7] Training Baseline model...
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 128, 128,  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 128, 128,  â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 128, 128,  â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 64, 64,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 64, 64,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 1 epochs and batch size 16
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m31:49[0m 7s/step - conv2d_12_loss: 0.1949 - conv2d_19_loss: 0.2691 - loss: 0.4640[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - conv2d_12_loss: 0.1719 - conv2d_19_loss: 0.2729 - loss: 0.4449 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1667 - conv2d_19_loss: 0.2690 - loss: 0.4357[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1647 - conv2d_19_loss: 0.2658 - loss: 0.4305[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1646 - conv2d_19_loss: 0.2629 - loss: 0.4275[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1650 - conv2d_19_loss: 0.2604 - loss: 0.4254[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1653 - conv2d_19_loss: 0.2582 - loss: 0.4235[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1655 - conv2d_19_loss: 0.2561 - loss: 0.4216[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1656 - conv2d_19_loss: 0.2543 - loss: 0.4199[1m 19/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1657 - conv2d_19_loss: 0.2526 - loss: 0.4183[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1658 - conv2d_19_loss: 0.2511 - loss: 0.4169[1m 23/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1659 - conv2d_19_loss: 0.2498 - loss: 0.4157[1m 25/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1659 - conv2d_19_loss: 0.2486 - loss: 0.4145[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2475 - loss: 0.4135[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2465 - loss: 0.4125[1m 31/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2456 - loss: 0.4116[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2448 - loss: 0.4107[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2440 - loss: 0.4099[1m 37/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1659 - conv2d_19_loss: 0.2432 - loss: 0.4092[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1659 - conv2d_19_loss: 0.2425 - loss: 0.4084[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1659 - conv2d_19_loss: 0.2419 - loss: 0.4078[1m 43/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1658 - conv2d_19_loss: 0.2413 - loss: 0.4071[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1657 - conv2d_19_loss: 0.2407 - loss: 0.4065[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1656 - conv2d_19_loss: 0.2402 - loss: 0.4058[1m 49/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1655 - conv2d_19_loss: 0.2397 - loss: 0.4052[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1654 - conv2d_19_loss: 0.2393 - loss: 0.4046[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1653 - conv2d_19_loss: 0.2388 - loss: 0.4041[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1652 - conv2d_19_loss: 0.2384 - loss: 0.4035[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1651 - conv2d_19_loss: 0.2380 - loss: 0.4030[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1650 - conv2d_19_loss: 0.2376 - loss: 0.4025[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1648 - conv2d_19_loss: 0.2372 - loss: 0.4020[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1647 - conv2d_19_loss: 0.2368 - loss: 0.4015[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1645 - conv2d_19_loss: 0.2365 - loss: 0.4010[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1643 - conv2d_19_loss: 0.2362 - loss: 0.4004[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1640 - conv2d_19_loss: 0.2359 - loss: 0.3999[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1637 - conv2d_19_loss: 0.2356 - loss: 0.3993[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1633 - conv2d_19_loss: 0.2353 - loss: 0.3986[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1629 - conv2d_19_loss: 0.2350 - loss: 0.3980[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1625 - conv2d_19_loss: 0.2348 - loss: 0.3973[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1620 - conv2d_19_loss: 0.2345 - loss: 0.3966[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1615 - conv2d_19_loss: 0.2343 - loss: 0.3958[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1610 - conv2d_19_loss: 0.2341 - loss: 0.3951[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1605 - conv2d_19_loss: 0.2339 - loss: 0.3943[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1599 - conv2d_19_loss: 0.2337 - loss: 0.3935[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1593 - conv2d_19_loss: 0.2335 - loss: 0.3927[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1587 - conv2d_19_loss: 0.2333 - loss: 0.3919[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1580 - conv2d_19_loss: 0.2331 - loss: 0.3911[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1574 - conv2d_19_loss: 0.2329 - loss: 0.3903[1m 97/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1567 - conv2d_19_loss: 0.2327 - loss: 0.3894[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1560 - conv2d_19_loss: 0.2325 - loss: 0.3886[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1554 - conv2d_19_loss: 0.2324 - loss: 0.3877[1m103/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1547 - conv2d_19_loss: 0.2322 - loss: 0.3869[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1540 - conv2d_19_loss: 0.2320 - loss: 0.3860[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1533 - conv2d_19_loss: 0.2319 - loss: 0.3852[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1526 - conv2d_19_loss: 0.2317 - loss: 0.3843[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1519 - conv2d_19_loss: 0.2316 - loss: 0.3835[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1512 - conv2d_19_loss: 0.2314 - loss: 0.3826[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1505 - conv2d_19_loss: 0.2313 - loss: 0.3818[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1498 - conv2d_19_loss: 0.2312 - loss: 0.3809[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1491 - conv2d_19_loss: 0.2310 - loss: 0.3801[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1484 - conv2d_19_loss: 0.2309 - loss: 0.3793[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1477 - conv2d_19_loss: 0.2308 - loss: 0.3785[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1470 - conv2d_19_loss: 0.2307 - loss: 0.3776[1m127/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1463 - conv2d_19_loss: 0.2305 - loss: 0.3768[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1456 - conv2d_19_loss: 0.2304 - loss: 0.3760[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1449 - conv2d_19_loss: 0.2303 - loss: 0.3752[1m133/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1443 - conv2d_19_loss: 0.2302 - loss: 0.3745[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1436 - conv2d_19_loss: 0.2301 - loss: 0.3737[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1429 - conv2d_19_loss: 0.2300 - loss: 0.3729[1m139/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1422 - conv2d_19_loss: 0.2299 - loss: 0.3721[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1416 - conv2d_19_loss: 0.2298 - loss: 0.3713[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1409 - conv2d_19_loss: 0.2297 - loss: 0.3706[1m145/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1403 - conv2d_19_loss: 0.2296 - loss: 0.3698[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1396 - conv2d_19_loss: 0.2295 - loss: 0.3691[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1390 - conv2d_19_loss: 0.2293 - loss: 0.3683[1m151/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1384 - conv2d_19_loss: 0.2292 - loss: 0.3676[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1377 - conv2d_19_loss: 0.2291 - loss: 0.3669[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1371 - conv2d_19_loss: 0.2290 - loss: 0.3661[1m157/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1365 - conv2d_19_loss: 0.2289 - loss: 0.3654[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1359 - conv2d_19_loss: 0.2289 - loss: 0.3647[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1353 - conv2d_19_loss: 0.2288 - loss: 0.3640[1m163/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1347 - conv2d_19_loss: 0.2287 - loss: 0.3633[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1341 - conv2d_19_loss: 0.2286 - loss: 0.3626[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1335 - conv2d_19_loss: 0.2285 - loss: 0.3619[1m169/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1329 - conv2d_19_loss: 0.2284 - loss: 0.3613[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1323 - conv2d_19_loss: 0.2283 - loss: 0.3606[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1317 - conv2d_19_loss: 0.2282 - loss: 0.3599[1m175/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1312 - conv2d_19_loss: 0.2281 - loss: 0.3593[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1306 - conv2d_19_loss: 0.2280 - loss: 0.3586[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1300 - conv2d_19_loss: 0.2279 - loss: 0.3579[1m181/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1295 - conv2d_19_loss: 0.2278 - loss: 0.3573[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1289 - conv2d_19_loss: 0.2277 - loss: 0.3567[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1284 - conv2d_19_loss: 0.2276 - loss: 0.3560[1m187/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1279 - conv2d_19_loss: 0.2275 - loss: 0.3554[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1273 - conv2d_19_loss: 0.2274 - loss: 0.3548[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1268 - conv2d_19_loss: 0.2273 - loss: 0.3542[1m193/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1263 - conv2d_19_loss: 0.2273 - loss: 0.3536[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1258 - conv2d_19_loss: 0.2272 - loss: 0.3530[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1253 - conv2d_19_loss: 0.2271 - loss: 0.3524[1m199/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1248 - conv2d_19_loss: 0.2270 - loss: 0.3518[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1243 - conv2d_19_loss: 0.2269 - loss: 0.3512[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1238 - conv2d_19_loss: 0.2268 - loss: 0.3506[1m205/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1233 - conv2d_19_loss: 0.2267 - loss: 0.3500[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1228 - conv2d_19_loss: 0.2266 - loss: 0.3495[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1224 - conv2d_19_loss: 0.2265 - loss: 0.3489[1m211/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1219 - conv2d_19_loss: 0.2264 - loss: 0.3483[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1214 - conv2d_19_loss: 0.2264 - loss: 0.3478[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1210 - conv2d_19_loss: 0.2263 - loss: 0.3472[1m217/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1205 - conv2d_19_loss: 0.2262 - loss: 0.3467[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1201 - conv2d_19_loss: 0.2261 - loss: 0.3461[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1196 - conv2d_19_loss: 0.2260 - loss: 0.3456[1m223/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1192 - conv2d_19_loss: 0.2259 - loss: 0.3451[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1187 - conv2d_19_loss: 0.2258 - loss: 0.3445[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1183 - conv2d_19_loss: 0.2257 - loss: 0.3440[1m229/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1178 - conv2d_19_loss: 0.2256 - loss: 0.3435[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1174 - conv2d_19_loss: 0.2255 - loss: 0.3430[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1170 - conv2d_19_loss: 0.2254 - loss: 0.3424[1m235/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1166 - conv2d_19_loss: 0.2254 - loss: 0.3419[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1162 - conv2d_19_loss: 0.2253 - loss: 0.3414[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1157 - conv2d_19_loss: 0.2252 - loss: 0.3409[1m241/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1153 - conv2d_19_loss: 0.2251 - loss: 0.3404[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1149 - conv2d_19_loss: 0.2250 - loss: 0.3399[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1145 - conv2d_19_loss: 0.2249 - loss: 0.3394[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1141 - conv2d_19_loss: 0.2248 - loss: 0.3389[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1137 - conv2d_19_loss: 0.2247 - loss: 0.3385[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1133 - conv2d_19_loss: 0.2246 - loss: 0.3380[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1130 - conv2d_19_loss: 0.2245 - loss: 0.3375[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1126 - conv2d_19_loss: 0.2244 - loss: 0.3370[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1122 - conv2d_19_loss: 0.2244 - loss: 0.3366[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1118 - conv2d_19_loss: 0.2243 - loss: 0.3361[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1115 - conv2d_19_loss: 0.2242 - loss: 0.3356[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1111 - conv2d_19_loss: 0.2241 - loss: 0.3352[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1107 - conv2d_19_loss: 0.2240 - loss: 0.3347[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step - conv2d_12_loss: 0.1104 - conv2d_19_loss: 0.2239 - loss: 0.3342[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m21s[0m 50ms/step - conv2d_12_loss: 0.0622 - conv2d_19_loss: 0.2117 - loss: 0.2740 - val_conv2d_12_loss: 0.0237 - val_conv2d_19_loss: 0.1810 - val_loss: 0.2085 - learning_rate: 0.0010
[5/7] Running inference...
input shape (32, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(32, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 914ms/step[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step   [1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/stepinput shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 49ms/step
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m30s[0m 1s/step[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 70ms/step
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:259: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
  tf_training_config = to_training_config(
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:618: UserWarning: params.cfg already populated. Set force=True to overwrite existing values.
  warnings.warn(
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/ollie/Documents/tmp/PtychoPINN/training_outputs/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 656 K  | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
656 K     Trainable params
0         Non-trainable params
656 K     Total params
2.624     Total estimated model params size (MB)
43        Modules in train mode
0         Modules in eval mode
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 17.2 M | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
17.2 M    Trainable params
0         Non-trainable params
17.2 M    Total params
68.810    Total estimated model params size (MB)
60        Modules in train mode
0         Modules in eval mode
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.
/home/ollie/Documents/tmp/PtychoPINN/ptycho/workflows/grid_lines_workflow.py:548: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
[6/7] Stitching and computing metrics...
Amplitude normalization scale factor: 0.947783
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: amp_pred stats: mean=3.140823, std=0.603815, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn]: phi_pred stats: mean=-0.000000, std=1.068200, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.385499
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: amp_pred stats: mean=7.721994, std=1.581222, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [baseline]: phi_pred stats: mean=0.000000, std=0.897244, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
[7/7] Saving outputs...
[grid_lines_workflow] Complete. Outputs in outputs/grid_lines_gs1_n128_tf1_torch20_neuralop
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 16.303831
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_fno]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_fno]: amp_pred stats: mean=0.182584, std=0.036401, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_fno]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_fno]: phi_pred stats: mean=0.000000, std=0.212767, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 13.839366
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_hybrid]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: amp_pred stats: mean=0.215098, std=0.031482, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_hybrid]: phi_pred stats: mean=-0.000000, std=0.315580, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
