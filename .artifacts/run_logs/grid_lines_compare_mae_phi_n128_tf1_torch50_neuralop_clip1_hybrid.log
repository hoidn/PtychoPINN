2026-01-27 13:45:12.667005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769550312.678686  853024 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769550312.682595  853024 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769550312.692806  853024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769550312.692816  853024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769550312.692818  853024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769550312.692819  853024 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-27 13:45:12.695630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769550315.310238  853024 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769550315.311465  853024 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769550351.509675  853024 service.cc:152] XLA service 0x4874b2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769550351.509695  853024 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-27 13:45:51.525365: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769550351.542018  853024 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769550351.760237  853024 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[grid_lines_workflow] Starting N=128, gridsize=1
[1/7] Loading and scaling probe...
Interpolating array from (64, 64) with zoom factor 2.0...
  New shape: (128, 128)
Applying Gaussian filter to complex array of shape (128, 128) (sigma=0.5)...
- Amplitude and unwrapped phase smoothed.
[2/7] Running grid simulation...
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Loading result from disk cache.
Loading result from disk cache.
DEBUG: generating grid-mode ground truth image
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
[3/7] Saving datasets...
[4/7] Training PINN model...
DEBUG: Setting intensity_scale to 494.10587 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878603-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250924-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.02388911-0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.01775611-0.01380389j]
  [ 0.02431883-0.01161062j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.03569121+0.0154982j ]
  ...
  [ 0.01803495+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 128
amp_activation: sigmoid
architecture: cnn
backend: tensorflow
batch_size: 16
bigN: 128
big_gridsize: 10
data_source: lines
debug: True
default_probe_scale: 0.7
enable_oversampling: False
fno_blocks: 4
fno_cnn_blocks: 2
fno_input_transform: none
fno_modes: 12
fno_width: 32
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 494.1058654785156
intensity_scale.trainable: True
label: 
mae_weight: 1.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 512
neighbor_count: 4
nepochs: 1
nimgs_test: 1
nimgs_train: 1
nll_weight: 0.0
nphotons: 1000000000.0
npseed: 42
object.big: False
offset: 4
outer_offset_test: 20
outer_offset_train: 8
output_prefix: training_outputs
pad_object: True
positions.provided: True
probe:
  shape: (128, 128, 1)
  mean: -0.017-0.002j
  std: 0.672
  min: -3.810-1.052j
  max: 2.870-0.504j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: True
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 1
DEBUG _flat_to_channel: N from global params: 128
DEBUG _flat_to_channel: input shape=(4489, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m29:46[0m 7s/step - intensity_scaler_inv_loss: 24.1343 - loss: 24.1343 - pred_intensity_loss: -505583.4688 - trimmed_obj_loss: 0.0000e+00[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.1864 - loss: 27.1864 - pred_intensity_loss: -518422.4062 - trimmed_obj_loss: 0.0000e+00 [1m  6/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 32.4259 - loss: 32.4259 - pred_intensity_loss: -516590.8750 - trimmed_obj_loss: 0.0000e+00[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 32.5544 - loss: 32.5544 - pred_intensity_loss: -514853.6562 - trimmed_obj_loss: 0.0000e+00[1m 12/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 32.0893 - loss: 32.0893 - pred_intensity_loss: -517338.9375 - trimmed_obj_loss: 0.0000e+00[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 31.5052 - loss: 31.5052 - pred_intensity_loss: -519565.9375 - trimmed_obj_loss: 0.0000e+00[1m 18/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 30.8898 - loss: 30.8898 - pred_intensity_loss: -520517.5000 - trimmed_obj_loss: 0.0000e+00[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 30.3102 - loss: 30.3102 - pred_intensity_loss: -520928.4062 - trimmed_obj_loss: 0.0000e+00[1m 24/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 29.7598 - loss: 29.7598 - pred_intensity_loss: -521024.5625 - trimmed_obj_loss: 0.0000e+00[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 29.2552 - loss: 29.2552 - pred_intensity_loss: -521130.2188 - trimmed_obj_loss: 0.0000e+00[1m 30/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 28.8076 - loss: 28.8076 - pred_intensity_loss: -521371.8750 - trimmed_obj_loss: 0.0000e+00[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 28.4044 - loss: 28.4044 - pred_intensity_loss: -521543.8750 - trimmed_obj_loss: 0.0000e+00[1m 36/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 28.0360 - loss: 28.0360 - pred_intensity_loss: -521614.4688 - trimmed_obj_loss: 0.0000e+00[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 27.7076 - loss: 27.7076 - pred_intensity_loss: -521775.6562 - trimmed_obj_loss: 0.0000e+00[1m 42/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 27.4135 - loss: 27.4135 - pred_intensity_loss: -522172.8438 - trimmed_obj_loss: 0.0000e+00[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 27.1466 - loss: 27.1466 - pred_intensity_loss: -522379.8750 - trimmed_obj_loss: 0.0000e+00[1m 48/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.9002 - loss: 26.9002 - pred_intensity_loss: -522633.6562 - trimmed_obj_loss: 0.0000e+00[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.6729 - loss: 26.6729 - pred_intensity_loss: -522775.1250 - trimmed_obj_loss: 0.0000e+00[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.5318 - loss: 26.5318 - pred_intensity_loss: -522857.3750 - trimmed_obj_loss: 0.0000e+00[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.3972 - loss: 26.3972 - pred_intensity_loss: -522925.0312 - trimmed_obj_loss: 0.0000e+00[1m 58/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 26.2058 - loss: 26.2058 - pred_intensity_loss: -522937.9062 - trimmed_obj_loss: 0.0000e+00[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 26.0246 - loss: 26.0246 - pred_intensity_loss: -522922.3750 - trimmed_obj_loss: 0.0000e+00[1m 64/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.8503 - loss: 25.8503 - pred_intensity_loss: -522967.8125 - trimmed_obj_loss: 0.0000e+00[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.6824 - loss: 25.6824 - pred_intensity_loss: -523061.4688 - trimmed_obj_loss: 0.0000e+00[1m 70/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.5240 - loss: 25.5240 - pred_intensity_loss: -523213.9688 - trimmed_obj_loss: 0.0000e+00[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.3750 - loss: 25.3750 - pred_intensity_loss: -523418.1875 - trimmed_obj_loss: 0.0000e+00[1m 76/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.2323 - loss: 25.2323 - pred_intensity_loss: -523518.8125 - trimmed_obj_loss: 0.0000e+00[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 25.0971 - loss: 25.0971 - pred_intensity_loss: -523573.3438 - trimmed_obj_loss: 0.0000e+00[1m 82/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.9680 - loss: 24.9680 - pred_intensity_loss: -523602.8750 - trimmed_obj_loss: 0.0000e+00[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.8443 - loss: 24.8443 - pred_intensity_loss: -523569.6562 - trimmed_obj_loss: 0.0000e+00[1m 88/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.7264 - loss: 24.7264 - pred_intensity_loss: -523542.5938 - trimmed_obj_loss: 0.0000e+00[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.6131 - loss: 24.6131 - pred_intensity_loss: -523547.7500 - trimmed_obj_loss: 0.0000e+00[1m 94/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.5034 - loss: 24.5034 - pred_intensity_loss: -523561.9062 - trimmed_obj_loss: 0.0000e+00[1m 96/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.4324 - loss: 24.4324 - pred_intensity_loss: -523584.0938 - trimmed_obj_loss: 0.0000e+00[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 24.3286 - loss: 24.3286 - pred_intensity_loss: -523594.0000 - trimmed_obj_loss: 0.0000e+00[1m102/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 24.2275 - loss: 24.2275 - pred_intensity_loss: -523574.3750 - trimmed_obj_loss: 0.0000e+00[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 24.1283 - loss: 24.1283 - pred_intensity_loss: -523549.5312 - trimmed_obj_loss: 0.0000e+00[1m108/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 24.0317 - loss: 24.0317 - pred_intensity_loss: -523533.4375 - trimmed_obj_loss: 0.0000e+00[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.9393 - loss: 23.9393 - pred_intensity_loss: -523562.7188 - trimmed_obj_loss: 0.0000e+00[1m114/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.8501 - loss: 23.8501 - pred_intensity_loss: -523616.7188 - trimmed_obj_loss: 0.0000e+00[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.7636 - loss: 23.7636 - pred_intensity_loss: -523654.5000 - trimmed_obj_loss: 0.0000e+00[1m120/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.6794 - loss: 23.6794 - pred_intensity_loss: -523681.8750 - trimmed_obj_loss: 0.0000e+00[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.5973 - loss: 23.5973 - pred_intensity_loss: -523699.8750 - trimmed_obj_loss: 0.0000e+00[1m126/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.5170 - loss: 23.5170 - pred_intensity_loss: -523700.7500 - trimmed_obj_loss: 0.0000e+00[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.4387 - loss: 23.4387 - pred_intensity_loss: -523704.3438 - trimmed_obj_loss: 0.0000e+00[1m132/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.3617 - loss: 23.3617 - pred_intensity_loss: -523707.5312 - trimmed_obj_loss: 0.0000e+00[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.2858 - loss: 23.2858 - pred_intensity_loss: -523718.1875 - trimmed_obj_loss: 0.0000e+00[1m138/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.2115 - loss: 23.2115 - pred_intensity_loss: -523737.1875 - trimmed_obj_loss: 0.0000e+00[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 23.1387 - loss: 23.1387 - pred_intensity_loss: -523759.2812 - trimmed_obj_loss: 0.0000e+00[1m144/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 23.0673 - loss: 23.0673 - pred_intensity_loss: -523795.5000 - trimmed_obj_loss: 0.0000e+00[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.9970 - loss: 22.9970 - pred_intensity_loss: -523836.9375 - trimmed_obj_loss: 0.0000e+00[1m150/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.9280 - loss: 22.9280 - pred_intensity_loss: -523879.8125 - trimmed_obj_loss: 0.0000e+00[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.8602 - loss: 22.8602 - pred_intensity_loss: -523923.8750 - trimmed_obj_loss: 0.0000e+00[1m156/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.7940 - loss: 22.7940 - pred_intensity_loss: -523974.1562 - trimmed_obj_loss: 0.0000e+00[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.7290 - loss: 22.7290 - pred_intensity_loss: -524032.0625 - trimmed_obj_loss: 0.0000e+00[1m162/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.6650 - loss: 22.6650 - pred_intensity_loss: -524110.1250 - trimmed_obj_loss: 0.0000e+00[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.6019 - loss: 22.6019 - pred_intensity_loss: -524182.3125 - trimmed_obj_loss: 0.0000e+00[1m168/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.5398 - loss: 22.5398 - pred_intensity_loss: -524257.9688 - trimmed_obj_loss: 0.0000e+00[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.4786 - loss: 22.4786 - pred_intensity_loss: -524332.1250 - trimmed_obj_loss: 0.0000e+00[1m174/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.4181 - loss: 22.4181 - pred_intensity_loss: -524400.9375 - trimmed_obj_loss: 0.0000e+00[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.3584 - loss: 22.3584 - pred_intensity_loss: -524478.6250 - trimmed_obj_loss: 0.0000e+00[1m180/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.2994 - loss: 22.2994 - pred_intensity_loss: -524561.9375 - trimmed_obj_loss: 0.0000e+00[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.2410 - loss: 22.2410 - pred_intensity_loss: -524651.8125 - trimmed_obj_loss: 0.0000e+00[1m186/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 22.1832 - loss: 22.1832 - pred_intensity_loss: -524734.8125 - trimmed_obj_loss: 0.0000e+00[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 22.1261 - loss: 22.1261 - pred_intensity_loss: -524812.5000 - trimmed_obj_loss: 0.0000e+00[1m192/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 22.0698 - loss: 22.0698 - pred_intensity_loss: -524891.6875 - trimmed_obj_loss: 0.0000e+00[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 22.0139 - loss: 22.0139 - pred_intensity_loss: -524959.9375 - trimmed_obj_loss: 0.0000e+00[1m198/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.9585 - loss: 21.9585 - pred_intensity_loss: -525027.2500 - trimmed_obj_loss: 0.0000e+00[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.9036 - loss: 21.9036 - pred_intensity_loss: -525086.1250 - trimmed_obj_loss: 0.0000e+00[1m204/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.8490 - loss: 21.8490 - pred_intensity_loss: -525137.3125 - trimmed_obj_loss: 0.0000e+00[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7950 - loss: 21.7950 - pred_intensity_loss: -525186.1875 - trimmed_obj_loss: 0.0000e+00[1m210/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7413 - loss: 21.7413 - pred_intensity_loss: -525235.8125 - trimmed_obj_loss: 0.0000e+00[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6882 - loss: 21.6882 - pred_intensity_loss: -525284.8750 - trimmed_obj_loss: 0.0000e+00[1m216/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6356 - loss: 21.6356 - pred_intensity_loss: -525335.0000 - trimmed_obj_loss: 0.0000e+00[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.5835 - loss: 21.5835 - pred_intensity_loss: -525383.2500 - trimmed_obj_loss: 0.0000e+00[1m222/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.5318 - loss: 21.5318 - pred_intensity_loss: -525429.8750 - trimmed_obj_loss: 0.0000e+00[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.4804 - loss: 21.4804 - pred_intensity_loss: -525474.8125 - trimmed_obj_loss: 0.0000e+00[1m228/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4292 - loss: 21.4292 - pred_intensity_loss: -525518.9375 - trimmed_obj_loss: 0.0000e+00[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.3784 - loss: 21.3784 - pred_intensity_loss: -525567.0000 - trimmed_obj_loss: 0.0000e+00[1m234/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.3278 - loss: 21.3278 - pred_intensity_loss: -525616.0625 - trimmed_obj_loss: 0.0000e+00[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.2774 - loss: 21.2774 - pred_intensity_loss: -525665.4375 - trimmed_obj_loss: 0.0000e+00[1m240/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.2274 - loss: 21.2274 - pred_intensity_loss: -525715.9375 - trimmed_obj_loss: 0.0000e+00[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.1777 - loss: 21.1777 - pred_intensity_loss: -525769.4375 - trimmed_obj_loss: 0.0000e+00[1m246/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.1283 - loss: 21.1283 - pred_intensity_loss: -525824.9375 - trimmed_obj_loss: 0.0000e+00[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.0793 - loss: 21.0793 - pred_intensity_loss: -525876.0625 - trimmed_obj_loss: 0.0000e+00[1m252/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.0305 - loss: 21.0305 - pred_intensity_loss: -525921.5625 - trimmed_obj_loss: 0.0000e+00[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.9820 - loss: 20.9820 - pred_intensity_loss: -525970.0625 - trimmed_obj_loss: 0.0000e+00[1m258/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.9337 - loss: 20.9337 - pred_intensity_loss: -526019.6250 - trimmed_obj_loss: 0.0000e+00[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.8857 - loss: 20.8857 - pred_intensity_loss: -526070.6875 - trimmed_obj_loss: 0.0000e+00[1m264/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 20.8378 - loss: 20.8378 - pred_intensity_loss: -526118.5000 - trimmed_obj_loss: 0.0000e+00[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step - intensity_scaler_inv_loss: 20.7902 - loss: 20.7903 - pred_intensity_loss: -526164.0000 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 34ms/step - intensity_scaler_inv_loss: 16.5745 - loss: 16.5875 - pred_intensity_loss: -530101.3125 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 10.0062 - val_loss: 9.9999 - val_pred_intensity_loss: -527047.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
[4/7] Training Baseline model...
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 128, 128,  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 128, 128,  â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 128, 128,  â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 64, 64,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 64, 64,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 1 epochs and batch size 16
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m31:45[0m 7s/step - conv2d_12_loss: 0.1791 - conv2d_19_loss: 0.2547 - loss: 0.4338[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - conv2d_12_loss: 0.1782 - conv2d_19_loss: 0.2708 - loss: 0.4491 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1763 - conv2d_19_loss: 0.2675 - loss: 0.4438[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1744 - conv2d_19_loss: 0.2622 - loss: 0.4367[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1715 - conv2d_19_loss: 0.2579 - loss: 0.4295[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1678 - conv2d_19_loss: 0.2547 - loss: 0.4226[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.1651 - conv2d_19_loss: 0.2520 - loss: 0.4171[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1635 - conv2d_19_loss: 0.2496 - loss: 0.4131[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1623 - conv2d_19_loss: 0.2477 - loss: 0.4100[1m 19/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1613 - conv2d_19_loss: 0.2460 - loss: 0.4074[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1606 - conv2d_19_loss: 0.2446 - loss: 0.4052[1m 23/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1600 - conv2d_19_loss: 0.2434 - loss: 0.4034[1m 25/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1593 - conv2d_19_loss: 0.2423 - loss: 0.4016[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1587 - conv2d_19_loss: 0.2413 - loss: 0.4001[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1581 - conv2d_19_loss: 0.2404 - loss: 0.3985[1m 31/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1574 - conv2d_19_loss: 0.2396 - loss: 0.3971[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1569 - conv2d_19_loss: 0.2389 - loss: 0.3958[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1564 - conv2d_19_loss: 0.2382 - loss: 0.3947[1m 37/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1560 - conv2d_19_loss: 0.2376 - loss: 0.3936[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1555 - conv2d_19_loss: 0.2371 - loss: 0.3926[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1549 - conv2d_19_loss: 0.2366 - loss: 0.3915[1m 43/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1543 - conv2d_19_loss: 0.2361 - loss: 0.3904[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1536 - conv2d_19_loss: 0.2357 - loss: 0.3892[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1528 - conv2d_19_loss: 0.2353 - loss: 0.3881[1m 49/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.1520 - conv2d_19_loss: 0.2349 - loss: 0.3869[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1511 - conv2d_19_loss: 0.2346 - loss: 0.3857[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1502 - conv2d_19_loss: 0.2342 - loss: 0.3844[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1492 - conv2d_19_loss: 0.2339 - loss: 0.3832[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1483 - conv2d_19_loss: 0.2336 - loss: 0.3819[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1473 - conv2d_19_loss: 0.2334 - loss: 0.3807[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1463 - conv2d_19_loss: 0.2331 - loss: 0.3794[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1453 - conv2d_19_loss: 0.2329 - loss: 0.3781[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1443 - conv2d_19_loss: 0.2326 - loss: 0.3769[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1432 - conv2d_19_loss: 0.2324 - loss: 0.3756[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1422 - conv2d_19_loss: 0.2322 - loss: 0.3744[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1412 - conv2d_19_loss: 0.2320 - loss: 0.3732[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1402 - conv2d_19_loss: 0.2318 - loss: 0.3719[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1392 - conv2d_19_loss: 0.2316 - loss: 0.3707[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1382 - conv2d_19_loss: 0.2314 - loss: 0.3696[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1372 - conv2d_19_loss: 0.2312 - loss: 0.3684[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1362 - conv2d_19_loss: 0.2310 - loss: 0.3672[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1352 - conv2d_19_loss: 0.2309 - loss: 0.3661[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1343 - conv2d_19_loss: 0.2307 - loss: 0.3650[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1333 - conv2d_19_loss: 0.2306 - loss: 0.3639[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1324 - conv2d_19_loss: 0.2304 - loss: 0.3628[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1314 - conv2d_19_loss: 0.2303 - loss: 0.3617[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1305 - conv2d_19_loss: 0.2301 - loss: 0.3607[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1296 - conv2d_19_loss: 0.2300 - loss: 0.3596[1m 97/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1287 - conv2d_19_loss: 0.2299 - loss: 0.3586[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1279 - conv2d_19_loss: 0.2297 - loss: 0.3576[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1270 - conv2d_19_loss: 0.2296 - loss: 0.3566[1m103/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1261 - conv2d_19_loss: 0.2295 - loss: 0.3556[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1253 - conv2d_19_loss: 0.2294 - loss: 0.3547[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1245 - conv2d_19_loss: 0.2293 - loss: 0.3537[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1237 - conv2d_19_loss: 0.2291 - loss: 0.3528[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1229 - conv2d_19_loss: 0.2290 - loss: 0.3519[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1221 - conv2d_19_loss: 0.2289 - loss: 0.3510[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1213 - conv2d_19_loss: 0.2288 - loss: 0.3501[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1205 - conv2d_19_loss: 0.2287 - loss: 0.3492[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1198 - conv2d_19_loss: 0.2286 - loss: 0.3483[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1190 - conv2d_19_loss: 0.2285 - loss: 0.3475[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1183 - conv2d_19_loss: 0.2284 - loss: 0.3467[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1176 - conv2d_19_loss: 0.2283 - loss: 0.3458[1m127/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1168 - conv2d_19_loss: 0.2282 - loss: 0.3450[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1161 - conv2d_19_loss: 0.2281 - loss: 0.3442[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1155 - conv2d_19_loss: 0.2280 - loss: 0.3435[1m133/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1148 - conv2d_19_loss: 0.2279 - loss: 0.3427[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1141 - conv2d_19_loss: 0.2278 - loss: 0.3419[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1135 - conv2d_19_loss: 0.2277 - loss: 0.3412[1m139/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1128 - conv2d_19_loss: 0.2276 - loss: 0.3404[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1122 - conv2d_19_loss: 0.2275 - loss: 0.3397[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1115 - conv2d_19_loss: 0.2275 - loss: 0.3390[1m145/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1109 - conv2d_19_loss: 0.2274 - loss: 0.3383[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1103 - conv2d_19_loss: 0.2273 - loss: 0.3376[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1097 - conv2d_19_loss: 0.2272 - loss: 0.3369[1m151/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1091 - conv2d_19_loss: 0.2271 - loss: 0.3362[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1085 - conv2d_19_loss: 0.2270 - loss: 0.3356[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1080 - conv2d_19_loss: 0.2270 - loss: 0.3349[1m157/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1074 - conv2d_19_loss: 0.2269 - loss: 0.3343[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1069 - conv2d_19_loss: 0.2268 - loss: 0.3337[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1063 - conv2d_19_loss: 0.2267 - loss: 0.3330[1m163/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1058 - conv2d_19_loss: 0.2266 - loss: 0.3324[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1052 - conv2d_19_loss: 0.2266 - loss: 0.3318[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1047 - conv2d_19_loss: 0.2265 - loss: 0.3312[1m169/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1042 - conv2d_19_loss: 0.2264 - loss: 0.3306[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1037 - conv2d_19_loss: 0.2264 - loss: 0.3300[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1032 - conv2d_19_loss: 0.2263 - loss: 0.3294[1m175/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1027 - conv2d_19_loss: 0.2262 - loss: 0.3289[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1022 - conv2d_19_loss: 0.2261 - loss: 0.3283[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1017 - conv2d_19_loss: 0.2261 - loss: 0.3278[1m181/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1012 - conv2d_19_loss: 0.2260 - loss: 0.3272[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1008 - conv2d_19_loss: 0.2259 - loss: 0.3267[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1003 - conv2d_19_loss: 0.2258 - loss: 0.3261[1m187/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.0998 - conv2d_19_loss: 0.2258 - loss: 0.3256[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.0994 - conv2d_19_loss: 0.2257 - loss: 0.3251[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.0989 - conv2d_19_loss: 0.2256 - loss: 0.3246[1m193/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.0985 - conv2d_19_loss: 0.2255 - loss: 0.3241[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0981 - conv2d_19_loss: 0.2255 - loss: 0.3236[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0977 - conv2d_19_loss: 0.2254 - loss: 0.3231[1m199/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0972 - conv2d_19_loss: 0.2253 - loss: 0.3226[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0968 - conv2d_19_loss: 0.2253 - loss: 0.3221[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0964 - conv2d_19_loss: 0.2252 - loss: 0.3216[1m205/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0960 - conv2d_19_loss: 0.2251 - loss: 0.3211[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0956 - conv2d_19_loss: 0.2250 - loss: 0.3207[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0952 - conv2d_19_loss: 0.2250 - loss: 0.3202[1m211/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0949 - conv2d_19_loss: 0.2249 - loss: 0.3197[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0945 - conv2d_19_loss: 0.2248 - loss: 0.3193[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0941 - conv2d_19_loss: 0.2247 - loss: 0.3188[1m217/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0937 - conv2d_19_loss: 0.2247 - loss: 0.3184[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0934 - conv2d_19_loss: 0.2246 - loss: 0.3179[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0930 - conv2d_19_loss: 0.2245 - loss: 0.3175[1m223/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0926 - conv2d_19_loss: 0.2244 - loss: 0.3171[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0923 - conv2d_19_loss: 0.2244 - loss: 0.3166[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0919 - conv2d_19_loss: 0.2243 - loss: 0.3162[1m229/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.0916 - conv2d_19_loss: 0.2242 - loss: 0.3158[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0912 - conv2d_19_loss: 0.2241 - loss: 0.3154[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0909 - conv2d_19_loss: 0.2240 - loss: 0.3149[1m235/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0906 - conv2d_19_loss: 0.2240 - loss: 0.3145[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0902 - conv2d_19_loss: 0.2239 - loss: 0.3141[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0899 - conv2d_19_loss: 0.2238 - loss: 0.3137[1m241/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0896 - conv2d_19_loss: 0.2237 - loss: 0.3133[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0892 - conv2d_19_loss: 0.2237 - loss: 0.3129[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0889 - conv2d_19_loss: 0.2236 - loss: 0.3125[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0886 - conv2d_19_loss: 0.2235 - loss: 0.3121[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0883 - conv2d_19_loss: 0.2234 - loss: 0.3117[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0880 - conv2d_19_loss: 0.2233 - loss: 0.3113[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0877 - conv2d_19_loss: 0.2233 - loss: 0.3110[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0874 - conv2d_19_loss: 0.2232 - loss: 0.3106[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0871 - conv2d_19_loss: 0.2231 - loss: 0.3102[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0868 - conv2d_19_loss: 0.2230 - loss: 0.3098[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0865 - conv2d_19_loss: 0.2229 - loss: 0.3094[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2229 - loss: 0.3091[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0859 - conv2d_19_loss: 0.2228 - loss: 0.3087[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2227 - loss: 0.3083[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m21s[0m 50ms/step - conv2d_12_loss: 0.0480 - conv2d_19_loss: 0.2121 - loss: 0.2603 - val_conv2d_12_loss: 0.0269 - val_conv2d_19_loss: 0.1916 - val_loss: 0.2223 - learning_rate: 0.0010
[5/7] Running inference...
input shape (32, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(32, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 912ms/step[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step   [1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/stepinput shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 49ms/step
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m30s[0m 1s/step[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 70ms/step
/home/ollie/Documents/tmp/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0338) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:259: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
  tf_training_config = to_training_config(
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:618: UserWarning: params.cfg already populated. Set force=True to overwrite existing values.
  warnings.warn(
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/ollie/Documents/tmp/PtychoPINN/training_outputs/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 17.2 M | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
17.2 M    Trainable params
0         Non-trainable params
17.2 M    Total params
68.810    Total estimated model params size (MB)
60        Modules in train mode
0         Modules in eval mode
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.
/home/ollie/Documents/tmp/PtychoPINN/ptycho/workflows/grid_lines_workflow.py:548: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
[6/7] Stitching and computing metrics...
Amplitude normalization scale factor: 1.000281
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: amp_pred stats: mean=2.975980, std=0.579577, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn]: phi_pred stats: mean=-0.000000, std=1.743217, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.454660
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: amp_pred stats: mean=6.547343, std=1.378250, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [baseline]: phi_pred stats: mean=0.000000, std=0.769993, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
[7/7] Saving outputs...
[grid_lines_workflow] Complete. Outputs in outputs/grid_lines_gs1_n128_tf1_torch50_neuralop_clip1_hybrid
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 16.093866
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_hybrid]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: amp_pred stats: mean=0.184966, std=0.034666, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_hybrid]: phi_pred stats: mean=0.000000, std=0.169626, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
