2026-01-27 14:20:20.560852: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769552420.572412  882769 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769552420.576299  882769 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769552420.586406  882769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769552420.586415  882769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769552420.586417  882769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769552420.586418  882769 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-27 14:20:20.589221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769552423.256845  882769 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769552423.258098  882769 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769552458.872890  882769 service.cc:152] XLA service 0x32145ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769552458.872910  882769 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-27 14:20:58.888552: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769552458.905553  882769 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769552459.124435  882769 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[grid_lines_workflow] Starting N=128, gridsize=1
[1/7] Loading and scaling probe...
Interpolating array from (64, 64) with zoom factor 2.0...
  New shape: (128, 128)
Applying Gaussian filter to complex array of shape (128, 128) (sigma=0.5)...
- Amplitude and unwrapped phase smoothed.
[2/7] Running grid simulation...
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Loading result from disk cache.
Loading result from disk cache.
DEBUG: generating grid-mode ground truth image
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
[3/7] Saving datasets...
[4/7] Training PINN model...
DEBUG: Setting intensity_scale to 494.10587 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878603-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250924-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.02388911-0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.01775611-0.01380389j]
  [ 0.02431883-0.01161062j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.03569121+0.0154982j ]
  ...
  [ 0.01803495+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 128
amp_activation: sigmoid
architecture: cnn
backend: tensorflow
batch_size: 16
bigN: 128
big_gridsize: 10
data_source: lines
debug: True
default_probe_scale: 0.7
enable_oversampling: False
fno_blocks: 4
fno_cnn_blocks: 2
fno_input_transform: none
fno_modes: 12
fno_width: 32
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 494.1058654785156
intensity_scale.trainable: True
label: 
mae_weight: 1.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 512
neighbor_count: 4
nepochs: 1
nimgs_test: 1
nimgs_train: 1
nll_weight: 0.0
nphotons: 1000000000.0
npseed: 42
object.big: False
offset: 4
outer_offset_test: 20
outer_offset_train: 8
output_prefix: training_outputs
pad_object: True
positions.provided: True
probe:
  shape: (128, 128, 1)
  mean: -0.017-0.002j
  std: 0.672
  min: -3.810-1.052j
  max: 2.870-0.504j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: True
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 1
DEBUG _flat_to_channel: N from global params: 128
DEBUG _flat_to_channel: input shape=(4489, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m29:16[0m 7s/step - intensity_scaler_inv_loss: 25.4333 - loss: 25.4333 - pred_intensity_loss: -525998.5000 - trimmed_obj_loss: 0.0000e+00[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 26ms/step - intensity_scaler_inv_loss: 26.8432 - loss: 26.8432 - pred_intensity_loss: -521883.8125 - trimmed_obj_loss: 0.0000e+00 [1m  6/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.7441 - loss: 27.7441 - pred_intensity_loss: -517030.2188 - trimmed_obj_loss: 0.0000e+00[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 27.2378 - loss: 27.2378 - pred_intensity_loss: -516307.8750 - trimmed_obj_loss: 0.0000e+00[1m 12/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 26.9727 - loss: 26.9727 - pred_intensity_loss: -515686.2812 - trimmed_obj_loss: 0.0000e+00[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 26.6496 - loss: 26.6496 - pred_intensity_loss: -514750.7188 - trimmed_obj_loss: 0.0000e+00[1m 18/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 26.3446 - loss: 26.3446 - pred_intensity_loss: -513515.5938 - trimmed_obj_loss: 0.0000e+00[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 26.0676 - loss: 26.0676 - pred_intensity_loss: -512973.7812 - trimmed_obj_loss: 0.0000e+00[1m 24/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.8110 - loss: 25.8110 - pred_intensity_loss: -512704.5312 - trimmed_obj_loss: 0.0000e+00[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.5783 - loss: 25.5783 - pred_intensity_loss: -512752.5938 - trimmed_obj_loss: 0.0000e+00[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 25.4253 - loss: 25.4253 - pred_intensity_loss: -512734.0000 - trimmed_obj_loss: 0.0000e+00[1m 32/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.2116 - loss: 25.2116 - pred_intensity_loss: -512801.2188 - trimmed_obj_loss: 0.0000e+00[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 25.0104 - loss: 25.0104 - pred_intensity_loss: -512701.5625 - trimmed_obj_loss: 0.0000e+00[1m 38/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.8295 - loss: 24.8295 - pred_intensity_loss: -512907.7812 - trimmed_obj_loss: 0.0000e+00[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.6632 - loss: 24.6632 - pred_intensity_loss: -513173.3438 - trimmed_obj_loss: 0.0000e+00[1m 44/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.5098 - loss: 24.5098 - pred_intensity_loss: -513382.8750 - trimmed_obj_loss: 0.0000e+00[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.3711 - loss: 24.3711 - pred_intensity_loss: -513580.5938 - trimmed_obj_loss: 0.0000e+00[1m 50/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.2463 - loss: 24.2463 - pred_intensity_loss: -513932.1562 - trimmed_obj_loss: 0.0000e+00[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.1309 - loss: 24.1309 - pred_intensity_loss: -514164.9062 - trimmed_obj_loss: 0.0000e+00[1m 56/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 24.0198 - loss: 24.0198 - pred_intensity_loss: -514338.6875 - trimmed_obj_loss: 0.0000e+00[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 23.9180 - loss: 23.9180 - pred_intensity_loss: -514617.7812 - trimmed_obj_loss: 0.0000e+00[1m 62/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.8208 - loss: 23.8208 - pred_intensity_loss: -514816.3438 - trimmed_obj_loss: 0.0000e+00[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.7276 - loss: 23.7276 - pred_intensity_loss: -514987.2812 - trimmed_obj_loss: 0.0000e+00[1m 68/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.6395 - loss: 23.6395 - pred_intensity_loss: -515176.2812 - trimmed_obj_loss: 0.0000e+00[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.5554 - loss: 23.5554 - pred_intensity_loss: -515329.0625 - trimmed_obj_loss: 0.0000e+00[1m 74/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.4743 - loss: 23.4743 - pred_intensity_loss: -515466.6875 - trimmed_obj_loss: 0.0000e+00[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.3971 - loss: 23.3971 - pred_intensity_loss: -515564.2500 - trimmed_obj_loss: 0.0000e+00[1m 80/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.3234 - loss: 23.3234 - pred_intensity_loss: -515638.2500 - trimmed_obj_loss: 0.0000e+00[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.2524 - loss: 23.2524 - pred_intensity_loss: -515691.2812 - trimmed_obj_loss: 0.0000e+00[1m 86/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.1840 - loss: 23.1840 - pred_intensity_loss: -515773.3125 - trimmed_obj_loss: 0.0000e+00[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.1174 - loss: 23.1174 - pred_intensity_loss: -515851.5000 - trimmed_obj_loss: 0.0000e+00[1m 92/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 23.0524 - loss: 23.0524 - pred_intensity_loss: -515919.1250 - trimmed_obj_loss: 0.0000e+00[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 22.9907 - loss: 22.9907 - pred_intensity_loss: -516046.7188 - trimmed_obj_loss: 0.0000e+00[1m 98/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 22.9328 - loss: 22.9328 - pred_intensity_loss: -516202.3750 - trimmed_obj_loss: 0.0000e+00[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.8774 - loss: 22.8774 - pred_intensity_loss: -516362.7812 - trimmed_obj_loss: 0.0000e+00[1m104/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.8240 - loss: 22.8240 - pred_intensity_loss: -516520.5312 - trimmed_obj_loss: 0.0000e+00[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.7728 - loss: 22.7728 - pred_intensity_loss: -516661.0000 - trimmed_obj_loss: 0.0000e+00[1m110/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.7243 - loss: 22.7243 - pred_intensity_loss: -516835.0312 - trimmed_obj_loss: 0.0000e+00[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.6779 - loss: 22.6779 - pred_intensity_loss: -517018.2188 - trimmed_obj_loss: 0.0000e+00[1m116/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.6330 - loss: 22.6330 - pred_intensity_loss: -517194.5312 - trimmed_obj_loss: 0.0000e+00[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.5898 - loss: 22.5898 - pred_intensity_loss: -517374.4062 - trimmed_obj_loss: 0.0000e+00[1m122/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.5482 - loss: 22.5482 - pred_intensity_loss: -517535.4688 - trimmed_obj_loss: 0.0000e+00[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.5076 - loss: 22.5076 - pred_intensity_loss: -517690.8438 - trimmed_obj_loss: 0.0000e+00[1m128/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.4684 - loss: 22.4684 - pred_intensity_loss: -517844.6250 - trimmed_obj_loss: 0.0000e+00[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.4306 - loss: 22.4306 - pred_intensity_loss: -517978.5938 - trimmed_obj_loss: 0.0000e+00[1m134/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.3938 - loss: 22.3938 - pred_intensity_loss: -518094.7812 - trimmed_obj_loss: 0.0000e+00[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.3576 - loss: 22.3576 - pred_intensity_loss: -518184.9375 - trimmed_obj_loss: 0.0000e+00[1m140/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 22.3226 - loss: 22.3226 - pred_intensity_loss: -518283.6250 - trimmed_obj_loss: 0.0000e+00[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.2891 - loss: 22.2891 - pred_intensity_loss: -518383.5625 - trimmed_obj_loss: 0.0000e+00[1m146/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.2565 - loss: 22.2565 - pred_intensity_loss: -518482.0938 - trimmed_obj_loss: 0.0000e+00[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.2248 - loss: 22.2248 - pred_intensity_loss: -518580.5000 - trimmed_obj_loss: 0.0000e+00[1m152/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.1940 - loss: 22.1940 - pred_intensity_loss: -518674.0000 - trimmed_obj_loss: 0.0000e+00[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.1639 - loss: 22.1639 - pred_intensity_loss: -518762.2500 - trimmed_obj_loss: 0.0000e+00[1m158/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.1346 - loss: 22.1346 - pred_intensity_loss: -518852.6875 - trimmed_obj_loss: 0.0000e+00[1m160/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.1153 - loss: 22.1153 - pred_intensity_loss: -518907.6562 - trimmed_obj_loss: 0.0000e+00[1m162/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.0965 - loss: 22.0965 - pred_intensity_loss: -518959.5000 - trimmed_obj_loss: 0.0000e+00[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.0689 - loss: 22.0689 - pred_intensity_loss: -519036.0000 - trimmed_obj_loss: 0.0000e+00[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.0507 - loss: 22.0507 - pred_intensity_loss: -519079.8125 - trimmed_obj_loss: 0.0000e+00[1m170/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 22.0239 - loss: 22.0239 - pred_intensity_loss: -519139.3750 - trimmed_obj_loss: 0.0000e+00[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9979 - loss: 21.9979 - pred_intensity_loss: -519202.3750 - trimmed_obj_loss: 0.0000e+00[1m176/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9728 - loss: 21.9728 - pred_intensity_loss: -519282.1250 - trimmed_obj_loss: 0.0000e+00[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9482 - loss: 21.9482 - pred_intensity_loss: -519375.9062 - trimmed_obj_loss: 0.0000e+00[1m182/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 21.9242 - loss: 21.9242 - pred_intensity_loss: -519472.0312 - trimmed_obj_loss: 0.0000e+00[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.9010 - loss: 21.9010 - pred_intensity_loss: -519579.5312 - trimmed_obj_loss: 0.0000e+00[1m188/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.8784 - loss: 21.8784 - pred_intensity_loss: -519683.2188 - trimmed_obj_loss: 0.0000e+00[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.8564 - loss: 21.8564 - pred_intensity_loss: -519780.1562 - trimmed_obj_loss: 0.0000e+00[1m194/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.8349 - loss: 21.8349 - pred_intensity_loss: -519867.9062 - trimmed_obj_loss: 0.0000e+00[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.8137 - loss: 21.8137 - pred_intensity_loss: -519955.6562 - trimmed_obj_loss: 0.0000e+00[1m200/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7928 - loss: 21.7928 - pred_intensity_loss: -520038.5625 - trimmed_obj_loss: 0.0000e+00[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7722 - loss: 21.7722 - pred_intensity_loss: -520122.9375 - trimmed_obj_loss: 0.0000e+00[1m206/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7521 - loss: 21.7521 - pred_intensity_loss: -520207.7812 - trimmed_obj_loss: 0.0000e+00[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7325 - loss: 21.7325 - pred_intensity_loss: -520292.9062 - trimmed_obj_loss: 0.0000e+00[1m212/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.7132 - loss: 21.7132 - pred_intensity_loss: -520372.8438 - trimmed_obj_loss: 0.0000e+00[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6944 - loss: 21.6944 - pred_intensity_loss: -520446.9062 - trimmed_obj_loss: 0.0000e+00[1m218/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6760 - loss: 21.6760 - pred_intensity_loss: -520523.0000 - trimmed_obj_loss: 0.0000e+00[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6581 - loss: 21.6581 - pred_intensity_loss: -520610.2500 - trimmed_obj_loss: 0.0000e+00[1m224/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 21.6404 - loss: 21.6404 - pred_intensity_loss: -520689.9062 - trimmed_obj_loss: 0.0000e+00[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.6229 - loss: 21.6229 - pred_intensity_loss: -520765.9062 - trimmed_obj_loss: 0.0000e+00[1m230/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.6058 - loss: 21.6058 - pred_intensity_loss: -520840.8750 - trimmed_obj_loss: 0.0000e+00[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5889 - loss: 21.5889 - pred_intensity_loss: -520909.3125 - trimmed_obj_loss: 0.0000e+00[1m236/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5724 - loss: 21.5724 - pred_intensity_loss: -520978.1250 - trimmed_obj_loss: 0.0000e+00[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5562 - loss: 21.5562 - pred_intensity_loss: -521042.9375 - trimmed_obj_loss: 0.0000e+00[1m242/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5405 - loss: 21.5405 - pred_intensity_loss: -521114.5000 - trimmed_obj_loss: 0.0000e+00[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5252 - loss: 21.5252 - pred_intensity_loss: -521186.5000 - trimmed_obj_loss: 0.0000e+00[1m248/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.5101 - loss: 21.5101 - pred_intensity_loss: -521256.4375 - trimmed_obj_loss: 0.0000e+00[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4952 - loss: 21.4952 - pred_intensity_loss: -521325.4375 - trimmed_obj_loss: 0.0000e+00[1m254/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4807 - loss: 21.4807 - pred_intensity_loss: -521391.1250 - trimmed_obj_loss: 0.0000e+00[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4663 - loss: 21.4663 - pred_intensity_loss: -521453.2812 - trimmed_obj_loss: 0.0000e+00[1m260/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4521 - loss: 21.4521 - pred_intensity_loss: -521510.6562 - trimmed_obj_loss: 0.0000e+00[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4382 - loss: 21.4382 - pred_intensity_loss: -521573.4688 - trimmed_obj_loss: 0.0000e+00[1m266/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 21.4246 - loss: 21.4246 - pred_intensity_loss: -521641.6250 - trimmed_obj_loss: 0.0000e+00[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step - intensity_scaler_inv_loss: 21.4202 - loss: 21.4202 - pred_intensity_loss: -521665.1250 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 34ms/step - intensity_scaler_inv_loss: 20.2274 - loss: 20.2296 - pred_intensity_loss: -527910.9375 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 19.2669 - val_loss: 19.3377 - val_pred_intensity_loss: -522646.3438 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
[4/7] Training Baseline model...
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 128, 128,  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 128, 128,  â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 128, 128,  â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 64, 64,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 64, 64,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 1 epochs and batch size 16
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m31:39[0m 7s/step - conv2d_12_loss: 0.1952 - conv2d_19_loss: 0.2807 - loss: 0.4759[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - conv2d_12_loss: 0.2147 - conv2d_19_loss: 0.2882 - loss: 0.5030 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2240 - conv2d_19_loss: 0.2915 - loss: 0.5154[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2222 - conv2d_19_loss: 0.2890 - loss: 0.5113[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2187 - conv2d_19_loss: 0.2853 - loss: 0.5040[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2150 - conv2d_19_loss: 0.2813 - loss: 0.4963[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2116 - conv2d_19_loss: 0.2777 - loss: 0.4893[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2086 - conv2d_19_loss: 0.2743 - loss: 0.4829[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2059 - conv2d_19_loss: 0.2713 - loss: 0.4772[1m 19/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2035 - conv2d_19_loss: 0.2686 - loss: 0.4721[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2013 - conv2d_19_loss: 0.2663 - loss: 0.4676[1m 23/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1994 - conv2d_19_loss: 0.2642 - loss: 0.4636[1m 25/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1977 - conv2d_19_loss: 0.2624 - loss: 0.4601[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1962 - conv2d_19_loss: 0.2607 - loss: 0.4569[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1948 - conv2d_19_loss: 0.2592 - loss: 0.4540[1m 31/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1935 - conv2d_19_loss: 0.2578 - loss: 0.4513[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1921 - conv2d_19_loss: 0.2565 - loss: 0.4486[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1907 - conv2d_19_loss: 0.2553 - loss: 0.4460[1m 37/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1895 - conv2d_19_loss: 0.2542 - loss: 0.4437[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1883 - conv2d_19_loss: 0.2531 - loss: 0.4414[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1870 - conv2d_19_loss: 0.2522 - loss: 0.4391[1m 43/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1857 - conv2d_19_loss: 0.2512 - loss: 0.4369[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1844 - conv2d_19_loss: 0.2504 - loss: 0.4348[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.1830 - conv2d_19_loss: 0.2496 - loss: 0.4326[1m 49/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1817 - conv2d_19_loss: 0.2488 - loss: 0.4305[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1803 - conv2d_19_loss: 0.2481 - loss: 0.4284[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1789 - conv2d_19_loss: 0.2474 - loss: 0.4264[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1775 - conv2d_19_loss: 0.2468 - loss: 0.4243[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1761 - conv2d_19_loss: 0.2462 - loss: 0.4223[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1747 - conv2d_19_loss: 0.2456 - loss: 0.4203[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1732 - conv2d_19_loss: 0.2451 - loss: 0.4183[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1718 - conv2d_19_loss: 0.2445 - loss: 0.4163[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1703 - conv2d_19_loss: 0.2440 - loss: 0.4144[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1689 - conv2d_19_loss: 0.2436 - loss: 0.4124[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1674 - conv2d_19_loss: 0.2431 - loss: 0.4106[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2427 - loss: 0.4087[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1646 - conv2d_19_loss: 0.2423 - loss: 0.4069[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1632 - conv2d_19_loss: 0.2419 - loss: 0.4051[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1619 - conv2d_19_loss: 0.2415 - loss: 0.4034[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1605 - conv2d_19_loss: 0.2412 - loss: 0.4017[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1592 - conv2d_19_loss: 0.2408 - loss: 0.4000[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1579 - conv2d_19_loss: 0.2405 - loss: 0.3983[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1566 - conv2d_19_loss: 0.2401 - loss: 0.3967[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1553 - conv2d_19_loss: 0.2398 - loss: 0.3951[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1541 - conv2d_19_loss: 0.2395 - loss: 0.3936[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1528 - conv2d_19_loss: 0.2392 - loss: 0.3920[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1516 - conv2d_19_loss: 0.2389 - loss: 0.3905[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1505 - conv2d_19_loss: 0.2386 - loss: 0.3891[1m 97/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1493 - conv2d_19_loss: 0.2383 - loss: 0.3876[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1482 - conv2d_19_loss: 0.2380 - loss: 0.3862[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1470 - conv2d_19_loss: 0.2378 - loss: 0.3848[1m103/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1459 - conv2d_19_loss: 0.2375 - loss: 0.3834[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1449 - conv2d_19_loss: 0.2373 - loss: 0.3821[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1438 - conv2d_19_loss: 0.2370 - loss: 0.3808[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1427 - conv2d_19_loss: 0.2367 - loss: 0.3795[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1417 - conv2d_19_loss: 0.2365 - loss: 0.3782[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1407 - conv2d_19_loss: 0.2363 - loss: 0.3770[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1397 - conv2d_19_loss: 0.2360 - loss: 0.3757[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1387 - conv2d_19_loss: 0.2358 - loss: 0.3745[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1378 - conv2d_19_loss: 0.2356 - loss: 0.3733[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1368 - conv2d_19_loss: 0.2353 - loss: 0.3722[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1359 - conv2d_19_loss: 0.2351 - loss: 0.3710[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1350 - conv2d_19_loss: 0.2349 - loss: 0.3699[1m127/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1341 - conv2d_19_loss: 0.2347 - loss: 0.3688[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1332 - conv2d_19_loss: 0.2345 - loss: 0.3677[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1324 - conv2d_19_loss: 0.2343 - loss: 0.3666[1m133/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1315 - conv2d_19_loss: 0.2340 - loss: 0.3655[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1307 - conv2d_19_loss: 0.2338 - loss: 0.3645[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1298 - conv2d_19_loss: 0.2336 - loss: 0.3635[1m139/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1290 - conv2d_19_loss: 0.2334 - loss: 0.3625[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1282 - conv2d_19_loss: 0.2333 - loss: 0.3615[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1275 - conv2d_19_loss: 0.2331 - loss: 0.3605[1m145/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1267 - conv2d_19_loss: 0.2329 - loss: 0.3596[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1260 - conv2d_19_loss: 0.2327 - loss: 0.3587[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1252 - conv2d_19_loss: 0.2325 - loss: 0.3577[1m151/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1245 - conv2d_19_loss: 0.2323 - loss: 0.3568[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1238 - conv2d_19_loss: 0.2322 - loss: 0.3559[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1231 - conv2d_19_loss: 0.2320 - loss: 0.3551[1m157/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1224 - conv2d_19_loss: 0.2318 - loss: 0.3542[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1217 - conv2d_19_loss: 0.2317 - loss: 0.3534[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1210 - conv2d_19_loss: 0.2315 - loss: 0.3525[1m163/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1204 - conv2d_19_loss: 0.2313 - loss: 0.3517[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1197 - conv2d_19_loss: 0.2312 - loss: 0.3509[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1191 - conv2d_19_loss: 0.2310 - loss: 0.3501[1m169/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1185 - conv2d_19_loss: 0.2308 - loss: 0.3493[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1178 - conv2d_19_loss: 0.2307 - loss: 0.3485[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1172 - conv2d_19_loss: 0.2305 - loss: 0.3478[1m175/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1166 - conv2d_19_loss: 0.2304 - loss: 0.3470[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1160 - conv2d_19_loss: 0.2302 - loss: 0.3463[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1155 - conv2d_19_loss: 0.2301 - loss: 0.3455[1m181/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1149 - conv2d_19_loss: 0.2299 - loss: 0.3448[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1143 - conv2d_19_loss: 0.2298 - loss: 0.3441[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1137 - conv2d_19_loss: 0.2297 - loss: 0.3434[1m187/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1132 - conv2d_19_loss: 0.2295 - loss: 0.3427[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1126 - conv2d_19_loss: 0.2294 - loss: 0.3420[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1121 - conv2d_19_loss: 0.2292 - loss: 0.3413[1m193/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1116 - conv2d_19_loss: 0.2291 - loss: 0.3407[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1111 - conv2d_19_loss: 0.2289 - loss: 0.3400[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1105 - conv2d_19_loss: 0.2288 - loss: 0.3393[1m199/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1100 - conv2d_19_loss: 0.2287 - loss: 0.3387[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1095 - conv2d_19_loss: 0.2285 - loss: 0.3380[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1090 - conv2d_19_loss: 0.2284 - loss: 0.3374[1m205/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1085 - conv2d_19_loss: 0.2283 - loss: 0.3368[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1080 - conv2d_19_loss: 0.2281 - loss: 0.3362[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1076 - conv2d_19_loss: 0.2280 - loss: 0.3356[1m211/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1071 - conv2d_19_loss: 0.2279 - loss: 0.3349[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1066 - conv2d_19_loss: 0.2277 - loss: 0.3343[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1062 - conv2d_19_loss: 0.2276 - loss: 0.3338[1m217/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1057 - conv2d_19_loss: 0.2275 - loss: 0.3332[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1053 - conv2d_19_loss: 0.2273 - loss: 0.3326[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1048 - conv2d_19_loss: 0.2272 - loss: 0.3320[1m223/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1044 - conv2d_19_loss: 0.2271 - loss: 0.3314[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1039 - conv2d_19_loss: 0.2269 - loss: 0.3309[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1035 - conv2d_19_loss: 0.2268 - loss: 0.3303[1m229/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1031 - conv2d_19_loss: 0.2267 - loss: 0.3298[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1027 - conv2d_19_loss: 0.2266 - loss: 0.3292[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1022 - conv2d_19_loss: 0.2264 - loss: 0.3287[1m235/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1018 - conv2d_19_loss: 0.2263 - loss: 0.3282[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1014 - conv2d_19_loss: 0.2262 - loss: 0.3276[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1010 - conv2d_19_loss: 0.2261 - loss: 0.3271[1m241/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1006 - conv2d_19_loss: 0.2260 - loss: 0.3266[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1002 - conv2d_19_loss: 0.2258 - loss: 0.3261[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0999 - conv2d_19_loss: 0.2257 - loss: 0.3256[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0995 - conv2d_19_loss: 0.2256 - loss: 0.3251[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0991 - conv2d_19_loss: 0.2255 - loss: 0.3246[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0987 - conv2d_19_loss: 0.2254 - loss: 0.3241[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0983 - conv2d_19_loss: 0.2252 - loss: 0.3236[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0980 - conv2d_19_loss: 0.2251 - loss: 0.3231[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0976 - conv2d_19_loss: 0.2250 - loss: 0.3226[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0972 - conv2d_19_loss: 0.2249 - loss: 0.3221[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0969 - conv2d_19_loss: 0.2248 - loss: 0.3217[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0965 - conv2d_19_loss: 0.2247 - loss: 0.3212[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0962 - conv2d_19_loss: 0.2246 - loss: 0.3207[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step - conv2d_12_loss: 0.0958 - conv2d_19_loss: 0.2244 - loss: 0.3203[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m20s[0m 50ms/step - conv2d_12_loss: 0.0501 - conv2d_19_loss: 0.2093 - loss: 0.2594 - val_conv2d_12_loss: 0.0207 - val_conv2d_19_loss: 0.1952 - val_loss: 0.2191 - learning_rate: 0.0010
[5/7] Running inference...
input shape (32, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(32, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m19s[0m 904ms/step[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step   [1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/stepinput shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 49ms/step
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m30s[0m 1s/step[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 70ms/step
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:259: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
  tf_training_config = to_training_config(
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:618: UserWarning: params.cfg already populated. Set force=True to overwrite existing values.
  warnings.warn(
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/ollie/Documents/tmp/PtychoPINN/training_outputs/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 17.2 M | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
17.2 M    Trainable params
0         Non-trainable params
17.2 M    Total params
68.810    Total estimated model params size (MB)
60        Modules in train mode
0         Modules in eval mode
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.
/home/ollie/Documents/tmp/PtychoPINN/ptycho/workflows/grid_lines_workflow.py:548: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
[6/7] Stitching and computing metrics...
Amplitude normalization scale factor: 1.011396
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: amp_pred stats: mean=2.943277, std=0.000000, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn]: phi_pred stats: mean=-0.000000, std=0.001905, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.399095
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: amp_pred stats: mean=7.458918, std=1.622903, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [baseline]: phi_pred stats: mean=0.000000, std=0.939608, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
[7/7] Saving outputs...
[grid_lines_workflow] Complete. Outputs in outputs/grid_lines_gs1_n128_tf1_torch50_neuralop_clip0_hybrid_log1p
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 15.230211
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_hybrid]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: amp_pred stats: mean=0.195455, std=0.036003, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_hybrid]: phi_pred stats: mean=-0.000000, std=0.137788, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
