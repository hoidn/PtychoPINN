2026-01-27 13:59:08.712098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769551148.723740  864912 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769551148.727407  864912 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769551148.737516  864912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769551148.737526  864912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769551148.737528  864912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769551148.737529  864912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-27 13:59:08.740332: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769551151.388222  864912 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769551151.389463  864912 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769551187.414316  864912 service.cc:152] XLA service 0x314c1c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769551187.414335  864912 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-27 13:59:47.430609: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769551187.447424  864912 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769551187.661502  864912 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[grid_lines_workflow] Starting N=128, gridsize=1
[1/7] Loading and scaling probe...
Interpolating array from (64, 64) with zoom factor 2.0...
  New shape: (128, 128)
Applying Gaussian filter to complex array of shape (128, 128) (sigma=0.5)...
- Amplitude and unwrapped phase smoothed.
[2/7] Running grid simulation...
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Loading result from disk cache.
Loading result from disk cache.
DEBUG: generating grid-mode ground truth image
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
[3/7] Saving datasets...
[4/7] Training PINN model...
DEBUG: Setting intensity_scale to 494.10587 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878603-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250924-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.02388911-0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.01775611-0.01380389j]
  [ 0.02431883-0.01161062j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.03569121+0.0154982j ]
  ...
  [ 0.01803495+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 128
amp_activation: sigmoid
architecture: cnn
backend: tensorflow
batch_size: 16
bigN: 128
big_gridsize: 10
data_source: lines
debug: True
default_probe_scale: 0.7
enable_oversampling: False
fno_blocks: 4
fno_cnn_blocks: 2
fno_input_transform: none
fno_modes: 12
fno_width: 32
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 494.1058654785156
intensity_scale.trainable: True
label: 
mae_weight: 1.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 512
neighbor_count: 4
nepochs: 1
nimgs_test: 1
nimgs_train: 1
nll_weight: 0.0
nphotons: 1000000000.0
npseed: 42
object.big: False
offset: 4
outer_offset_test: 20
outer_offset_train: 8
output_prefix: training_outputs
pad_object: True
positions.provided: True
probe:
  shape: (128, 128, 1)
  mean: -0.017-0.002j
  std: 0.672
  min: -3.810-1.052j
  max: 2.870-0.504j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: True
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 1
DEBUG _flat_to_channel: N from global params: 128
DEBUG _flat_to_channel: input shape=(4489, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m29:50[0m 7s/step - intensity_scaler_inv_loss: 22.8706 - loss: 22.8706 - pred_intensity_loss: -491324.2500 - trimmed_obj_loss: 0.0000e+00[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 25ms/step - intensity_scaler_inv_loss: 26.5878 - loss: 26.5878 - pred_intensity_loss: -507315.5938 - trimmed_obj_loss: 0.0000e+00 [1m  6/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 36.5274 - loss: 36.5274 - pred_intensity_loss: -510696.4688 - trimmed_obj_loss: 0.0000e+00[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 37.7311 - loss: 37.7311 - pred_intensity_loss: -514212.3438 - trimmed_obj_loss: 0.0000e+00[1m 12/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 24ms/step - intensity_scaler_inv_loss: 37.1787 - loss: 37.1787 - pred_intensity_loss: -515150.8125 - trimmed_obj_loss: 0.0000e+00[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 36.3178 - loss: 36.3178 - pred_intensity_loss: -515726.4062 - trimmed_obj_loss: 0.0000e+00[1m 18/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 35.4518 - loss: 35.4518 - pred_intensity_loss: -516219.0000 - trimmed_obj_loss: 0.0000e+00[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 34.6470 - loss: 34.6470 - pred_intensity_loss: -516795.7188 - trimmed_obj_loss: 0.0000e+00[1m 24/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 33.9032 - loss: 33.9032 - pred_intensity_loss: -517577.6875 - trimmed_obj_loss: 0.0000e+00[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 33.2265 - loss: 33.2265 - pred_intensity_loss: -518768.1250 - trimmed_obj_loss: 0.0000e+00[1m 30/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 32.6117 - loss: 32.6117 - pred_intensity_loss: -519852.5312 - trimmed_obj_loss: 0.0000e+00[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 32.0591 - loss: 32.0591 - pred_intensity_loss: -521012.0000 - trimmed_obj_loss: 0.0000e+00[1m 36/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 31.5587 - loss: 31.5587 - pred_intensity_loss: -521972.9688 - trimmed_obj_loss: 0.0000e+00[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 31.1008 - loss: 31.1008 - pred_intensity_loss: -522584.2812 - trimmed_obj_loss: 0.0000e+00[1m 42/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 30.6756 - loss: 30.6756 - pred_intensity_loss: -522839.4375 - trimmed_obj_loss: 0.0000e+00[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 30.2836 - loss: 30.2836 - pred_intensity_loss: -523005.3438 - trimmed_obj_loss: 0.0000e+00[1m 48/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 29.9242 - loss: 29.9242 - pred_intensity_loss: -522998.9375 - trimmed_obj_loss: 0.0000e+00[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 29.5970 - loss: 29.5970 - pred_intensity_loss: -522963.0000 - trimmed_obj_loss: 0.0000e+00[1m 54/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 24ms/step - intensity_scaler_inv_loss: 29.2963 - loss: 29.2963 - pred_intensity_loss: -523087.4688 - trimmed_obj_loss: 0.0000e+00[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 29.0151 - loss: 29.0151 - pred_intensity_loss: -523183.1250 - trimmed_obj_loss: 0.0000e+00[1m 60/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 28.7515 - loss: 28.7515 - pred_intensity_loss: -523326.6562 - trimmed_obj_loss: 0.0000e+00[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 28.5044 - loss: 28.5044 - pred_intensity_loss: -523519.3125 - trimmed_obj_loss: 0.0000e+00[1m 66/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 28.2711 - loss: 28.2711 - pred_intensity_loss: -523659.0312 - trimmed_obj_loss: 0.0000e+00[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 28.0527 - loss: 28.0527 - pred_intensity_loss: -523746.8750 - trimmed_obj_loss: 0.0000e+00[1m 72/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 27.8480 - loss: 27.8480 - pred_intensity_loss: -523832.7188 - trimmed_obj_loss: 0.0000e+00[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 27.6547 - loss: 27.6547 - pred_intensity_loss: -523890.7812 - trimmed_obj_loss: 0.0000e+00[1m 78/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 27.4721 - loss: 27.4721 - pred_intensity_loss: -523926.6250 - trimmed_obj_loss: 0.0000e+00[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 27.2989 - loss: 27.2989 - pred_intensity_loss: -523982.7188 - trimmed_obj_loss: 0.0000e+00[1m 84/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 27.1344 - loss: 27.1344 - pred_intensity_loss: -524030.1875 - trimmed_obj_loss: 0.0000e+00[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 26.9784 - loss: 26.9784 - pred_intensity_loss: -524086.6250 - trimmed_obj_loss: 0.0000e+00[1m 90/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 26.8307 - loss: 26.8307 - pred_intensity_loss: -524126.9375 - trimmed_obj_loss: 0.0000e+00[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 26.6896 - loss: 26.6896 - pred_intensity_loss: -524148.1875 - trimmed_obj_loss: 0.0000e+00[1m 96/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 26.5562 - loss: 26.5562 - pred_intensity_loss: -524228.2188 - trimmed_obj_loss: 0.0000e+00[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 26.4293 - loss: 26.4293 - pred_intensity_loss: -524351.3750 - trimmed_obj_loss: 0.0000e+00[1m102/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 26.3074 - loss: 26.3074 - pred_intensity_loss: -524486.3125 - trimmed_obj_loss: 0.0000e+00[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 26.1908 - loss: 26.1908 - pred_intensity_loss: -524641.1875 - trimmed_obj_loss: 0.0000e+00[1m108/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 26.0787 - loss: 26.0787 - pred_intensity_loss: -524778.3750 - trimmed_obj_loss: 0.0000e+00[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.9710 - loss: 25.9710 - pred_intensity_loss: -524909.7500 - trimmed_obj_loss: 0.0000e+00[1m114/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.8681 - loss: 25.8681 - pred_intensity_loss: -525028.4375 - trimmed_obj_loss: 0.0000e+00[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.7696 - loss: 25.7696 - pred_intensity_loss: -525124.8750 - trimmed_obj_loss: 0.0000e+00[1m120/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.6748 - loss: 25.6748 - pred_intensity_loss: -525214.6875 - trimmed_obj_loss: 0.0000e+00[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.5830 - loss: 25.5830 - pred_intensity_loss: -525307.9375 - trimmed_obj_loss: 0.0000e+00[1m126/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.4942 - loss: 25.4942 - pred_intensity_loss: -525406.1875 - trimmed_obj_loss: 0.0000e+00[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.4089 - loss: 25.4089 - pred_intensity_loss: -525512.5625 - trimmed_obj_loss: 0.0000e+00[1m132/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.3264 - loss: 25.3264 - pred_intensity_loss: -525596.6875 - trimmed_obj_loss: 0.0000e+00[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.2468 - loss: 25.2468 - pred_intensity_loss: -525656.5625 - trimmed_obj_loss: 0.0000e+00[1m138/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 25.1701 - loss: 25.1701 - pred_intensity_loss: -525722.5625 - trimmed_obj_loss: 0.0000e+00[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 25.0953 - loss: 25.0953 - pred_intensity_loss: -525768.5000 - trimmed_obj_loss: 0.0000e+00[1m144/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 25.0230 - loss: 25.0230 - pred_intensity_loss: -525802.9375 - trimmed_obj_loss: 0.0000e+00[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.9528 - loss: 24.9528 - pred_intensity_loss: -525838.0625 - trimmed_obj_loss: 0.0000e+00[1m150/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.8851 - loss: 24.8851 - pred_intensity_loss: -525873.3125 - trimmed_obj_loss: 0.0000e+00[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.8200 - loss: 24.8200 - pred_intensity_loss: -525909.9375 - trimmed_obj_loss: 0.0000e+00[1m156/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.7568 - loss: 24.7568 - pred_intensity_loss: -525938.8750 - trimmed_obj_loss: 0.0000e+00[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.6953 - loss: 24.6953 - pred_intensity_loss: -525966.8125 - trimmed_obj_loss: 0.0000e+00[1m162/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.6351 - loss: 24.6351 - pred_intensity_loss: -525989.9375 - trimmed_obj_loss: 0.0000e+00[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.5765 - loss: 24.5765 - pred_intensity_loss: -526010.1875 - trimmed_obj_loss: 0.0000e+00[1m168/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.5196 - loss: 24.5196 - pred_intensity_loss: -526026.2500 - trimmed_obj_loss: 0.0000e+00[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.4644 - loss: 24.4644 - pred_intensity_loss: -526038.0000 - trimmed_obj_loss: 0.0000e+00[1m174/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.4107 - loss: 24.4107 - pred_intensity_loss: -526041.3125 - trimmed_obj_loss: 0.0000e+00[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.3583 - loss: 24.3583 - pred_intensity_loss: -526037.8750 - trimmed_obj_loss: 0.0000e+00[1m180/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 24.3072 - loss: 24.3072 - pred_intensity_loss: -526025.6250 - trimmed_obj_loss: 0.0000e+00[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.2574 - loss: 24.2574 - pred_intensity_loss: -526015.1250 - trimmed_obj_loss: 0.0000e+00[1m186/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.2093 - loss: 24.2093 - pred_intensity_loss: -526007.5625 - trimmed_obj_loss: 0.0000e+00[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.1625 - loss: 24.1625 - pred_intensity_loss: -525993.0625 - trimmed_obj_loss: 0.0000e+00[1m192/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.1168 - loss: 24.1168 - pred_intensity_loss: -525978.6250 - trimmed_obj_loss: 0.0000e+00[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.0722 - loss: 24.0722 - pred_intensity_loss: -525968.1250 - trimmed_obj_loss: 0.0000e+00[1m198/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 24.0289 - loss: 24.0289 - pred_intensity_loss: -525964.0625 - trimmed_obj_loss: 0.0000e+00[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.9866 - loss: 23.9866 - pred_intensity_loss: -525963.5000 - trimmed_obj_loss: 0.0000e+00[1m204/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.9451 - loss: 23.9451 - pred_intensity_loss: -525959.5625 - trimmed_obj_loss: 0.0000e+00[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.9048 - loss: 23.9048 - pred_intensity_loss: -525957.6875 - trimmed_obj_loss: 0.0000e+00[1m210/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.8654 - loss: 23.8654 - pred_intensity_loss: -525961.2500 - trimmed_obj_loss: 0.0000e+00[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.8268 - loss: 23.8268 - pred_intensity_loss: -525961.7500 - trimmed_obj_loss: 0.0000e+00[1m216/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.7891 - loss: 23.7891 - pred_intensity_loss: -525955.8750 - trimmed_obj_loss: 0.0000e+00[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.7523 - loss: 23.7523 - pred_intensity_loss: -525948.6875 - trimmed_obj_loss: 0.0000e+00[1m222/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 23.7165 - loss: 23.7165 - pred_intensity_loss: -525951.6875 - trimmed_obj_loss: 0.0000e+00[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.6814 - loss: 23.6814 - pred_intensity_loss: -525958.6875 - trimmed_obj_loss: 0.0000e+00[1m228/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.6472 - loss: 23.6472 - pred_intensity_loss: -525970.0000 - trimmed_obj_loss: 0.0000e+00[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.6137 - loss: 23.6137 - pred_intensity_loss: -525976.3125 - trimmed_obj_loss: 0.0000e+00[1m234/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.5809 - loss: 23.5809 - pred_intensity_loss: -525985.1250 - trimmed_obj_loss: 0.0000e+00[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.5488 - loss: 23.5488 - pred_intensity_loss: -525996.0000 - trimmed_obj_loss: 0.0000e+00[1m240/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.5174 - loss: 23.5174 - pred_intensity_loss: -526010.6250 - trimmed_obj_loss: 0.0000e+00[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.4865 - loss: 23.4865 - pred_intensity_loss: -526029.8125 - trimmed_obj_loss: 0.0000e+00[1m246/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.4562 - loss: 23.4562 - pred_intensity_loss: -526047.4375 - trimmed_obj_loss: 0.0000e+00[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.4265 - loss: 23.4265 - pred_intensity_loss: -526063.4375 - trimmed_obj_loss: 0.0000e+00[1m252/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.3971 - loss: 23.3971 - pred_intensity_loss: -526079.4375 - trimmed_obj_loss: 0.0000e+00[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.3685 - loss: 23.3685 - pred_intensity_loss: -526096.5000 - trimmed_obj_loss: 0.0000e+00[1m258/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.3404 - loss: 23.3404 - pred_intensity_loss: -526112.6875 - trimmed_obj_loss: 0.0000e+00[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.3129 - loss: 23.3129 - pred_intensity_loss: -526127.1250 - trimmed_obj_loss: 0.0000e+00[1m264/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.2859 - loss: 23.2859 - pred_intensity_loss: -526143.1250 - trimmed_obj_loss: 0.0000e+00[1m266/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 23.2681 - loss: 23.2681 - pred_intensity_loss: -526153.8125 - trimmed_obj_loss: 0.0000e+00[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 28ms/step - intensity_scaler_inv_loss: 23.2592 - loss: 23.2593 - pred_intensity_loss: -526159.2500 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 34ms/step - intensity_scaler_inv_loss: 20.9017 - loss: 20.9103 - pred_intensity_loss: -527601.6875 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 19.7156 - val_loss: 19.7769 - val_pred_intensity_loss: -522538.7188 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
[4/7] Training Baseline model...
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 128, 128,  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 128, 128,  â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 128, 128,  â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 64, 64,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 64, 64,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 1 epochs and batch size 16
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m31:44[0m 7s/step - conv2d_12_loss: 0.1874 - conv2d_19_loss: 0.2751 - loss: 0.4625[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - conv2d_12_loss: 0.2873 - conv2d_19_loss: 0.3356 - loss: 0.6229 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3284 - conv2d_19_loss: 0.3605 - loss: 0.6888[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3260 - conv2d_19_loss: 0.3575 - loss: 0.6834[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3165 - conv2d_19_loss: 0.3502 - loss: 0.6668[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3064 - conv2d_19_loss: 0.3422 - loss: 0.6486[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2971 - conv2d_19_loss: 0.3347 - loss: 0.6317[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2888 - conv2d_19_loss: 0.3282 - loss: 0.6170[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2816 - conv2d_19_loss: 0.3223 - loss: 0.6039[1m 19/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2751 - conv2d_19_loss: 0.3172 - loss: 0.5923[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2694 - conv2d_19_loss: 0.3125 - loss: 0.5819[1m 23/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2643 - conv2d_19_loss: 0.3084 - loss: 0.5726[1m 25/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2597 - conv2d_19_loss: 0.3046 - loss: 0.5643[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2554 - conv2d_19_loss: 0.3012 - loss: 0.5566[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2512 - conv2d_19_loss: 0.2981 - loss: 0.5493[1m 31/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2473 - conv2d_19_loss: 0.2952 - loss: 0.5425[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2436 - conv2d_19_loss: 0.2925 - loss: 0.5361[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2400 - conv2d_19_loss: 0.2900 - loss: 0.5301[1m 37/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2365 - conv2d_19_loss: 0.2878 - loss: 0.5243[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2332 - conv2d_19_loss: 0.2856 - loss: 0.5188[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2299 - conv2d_19_loss: 0.2837 - loss: 0.5136[1m 43/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2267 - conv2d_19_loss: 0.2818 - loss: 0.5085[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2236 - conv2d_19_loss: 0.2801 - loss: 0.5037[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - conv2d_12_loss: 0.2205 - conv2d_19_loss: 0.2785 - loss: 0.4990[1m 49/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2175 - conv2d_19_loss: 0.2770 - loss: 0.4945[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2147 - conv2d_19_loss: 0.2756 - loss: 0.4902[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2118 - conv2d_19_loss: 0.2742 - loss: 0.4861[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2091 - conv2d_19_loss: 0.2730 - loss: 0.4821[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2064 - conv2d_19_loss: 0.2718 - loss: 0.4782[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2039 - conv2d_19_loss: 0.2707 - loss: 0.4745[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.2014 - conv2d_19_loss: 0.2696 - loss: 0.4710[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1989 - conv2d_19_loss: 0.2686 - loss: 0.4675[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1965 - conv2d_19_loss: 0.2676 - loss: 0.4641[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1942 - conv2d_19_loss: 0.2667 - loss: 0.4609[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1920 - conv2d_19_loss: 0.2658 - loss: 0.4578[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1898 - conv2d_19_loss: 0.2649 - loss: 0.4547[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1877 - conv2d_19_loss: 0.2641 - loss: 0.4518[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1856 - conv2d_19_loss: 0.2633 - loss: 0.4489[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1836 - conv2d_19_loss: 0.2626 - loss: 0.4461[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1816 - conv2d_19_loss: 0.2618 - loss: 0.4434[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1797 - conv2d_19_loss: 0.2611 - loss: 0.4408[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1778 - conv2d_19_loss: 0.2604 - loss: 0.4382[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step - conv2d_12_loss: 0.1760 - conv2d_19_loss: 0.2598 - loss: 0.4358[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1742 - conv2d_19_loss: 0.2591 - loss: 0.4333[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1725 - conv2d_19_loss: 0.2585 - loss: 0.4310[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1708 - conv2d_19_loss: 0.2579 - loss: 0.4287[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1691 - conv2d_19_loss: 0.2574 - loss: 0.4265[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1675 - conv2d_19_loss: 0.2568 - loss: 0.4244[1m 97/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1660 - conv2d_19_loss: 0.2563 - loss: 0.4223[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1644 - conv2d_19_loss: 0.2558 - loss: 0.4202[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1630 - conv2d_19_loss: 0.2553 - loss: 0.4182[1m103/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1615 - conv2d_19_loss: 0.2548 - loss: 0.4163[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1601 - conv2d_19_loss: 0.2543 - loss: 0.4144[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1587 - conv2d_19_loss: 0.2539 - loss: 0.4126[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1573 - conv2d_19_loss: 0.2534 - loss: 0.4108[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1560 - conv2d_19_loss: 0.2530 - loss: 0.4090[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1547 - conv2d_19_loss: 0.2526 - loss: 0.4073[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1534 - conv2d_19_loss: 0.2522 - loss: 0.4056[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1522 - conv2d_19_loss: 0.2518 - loss: 0.4040[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1510 - conv2d_19_loss: 0.2514 - loss: 0.4023[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 27ms/step - conv2d_12_loss: 0.1498 - conv2d_19_loss: 0.2510 - loss: 0.4008[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1486 - conv2d_19_loss: 0.2506 - loss: 0.3992[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1475 - conv2d_19_loss: 0.2503 - loss: 0.3977[1m127/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1463 - conv2d_19_loss: 0.2499 - loss: 0.3962[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1452 - conv2d_19_loss: 0.2496 - loss: 0.3948[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1442 - conv2d_19_loss: 0.2492 - loss: 0.3934[1m133/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1431 - conv2d_19_loss: 0.2489 - loss: 0.3920[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1421 - conv2d_19_loss: 0.2486 - loss: 0.3906[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1411 - conv2d_19_loss: 0.2483 - loss: 0.3893[1m139/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1401 - conv2d_19_loss: 0.2479 - loss: 0.3880[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1391 - conv2d_19_loss: 0.2476 - loss: 0.3867[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1381 - conv2d_19_loss: 0.2473 - loss: 0.3855[1m145/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1372 - conv2d_19_loss: 0.2471 - loss: 0.3842[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1363 - conv2d_19_loss: 0.2468 - loss: 0.3830[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1354 - conv2d_19_loss: 0.2465 - loss: 0.3819[1m151/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1345 - conv2d_19_loss: 0.2462 - loss: 0.3807[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1336 - conv2d_19_loss: 0.2460 - loss: 0.3795[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1327 - conv2d_19_loss: 0.2457 - loss: 0.3784[1m157/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 27ms/step - conv2d_12_loss: 0.1319 - conv2d_19_loss: 0.2454 - loss: 0.3773[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1311 - conv2d_19_loss: 0.2452 - loss: 0.3762[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1302 - conv2d_19_loss: 0.2449 - loss: 0.3752[1m163/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1294 - conv2d_19_loss: 0.2447 - loss: 0.3741[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1287 - conv2d_19_loss: 0.2445 - loss: 0.3731[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1279 - conv2d_19_loss: 0.2442 - loss: 0.3721[1m169/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1271 - conv2d_19_loss: 0.2440 - loss: 0.3711[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1264 - conv2d_19_loss: 0.2437 - loss: 0.3701[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1256 - conv2d_19_loss: 0.2435 - loss: 0.3691[1m175/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1249 - conv2d_19_loss: 0.2433 - loss: 0.3682[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1242 - conv2d_19_loss: 0.2431 - loss: 0.3672[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1235 - conv2d_19_loss: 0.2428 - loss: 0.3663[1m181/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1228 - conv2d_19_loss: 0.2426 - loss: 0.3654[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1221 - conv2d_19_loss: 0.2424 - loss: 0.3645[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1214 - conv2d_19_loss: 0.2422 - loss: 0.3636[1m187/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1208 - conv2d_19_loss: 0.2420 - loss: 0.3628[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1201 - conv2d_19_loss: 0.2418 - loss: 0.3619[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1195 - conv2d_19_loss: 0.2416 - loss: 0.3610[1m193/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 27ms/step - conv2d_12_loss: 0.1188 - conv2d_19_loss: 0.2414 - loss: 0.3602[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1182 - conv2d_19_loss: 0.2412 - loss: 0.3594[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1176 - conv2d_19_loss: 0.2410 - loss: 0.3586[1m199/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1170 - conv2d_19_loss: 0.2408 - loss: 0.3578[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1164 - conv2d_19_loss: 0.2406 - loss: 0.3570[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1158 - conv2d_19_loss: 0.2404 - loss: 0.3562[1m205/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1152 - conv2d_19_loss: 0.2402 - loss: 0.3554[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1147 - conv2d_19_loss: 0.2400 - loss: 0.3547[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1141 - conv2d_19_loss: 0.2398 - loss: 0.3539[1m211/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1136 - conv2d_19_loss: 0.2396 - loss: 0.3532[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1130 - conv2d_19_loss: 0.2394 - loss: 0.3525[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1125 - conv2d_19_loss: 0.2393 - loss: 0.3517[1m217/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1120 - conv2d_19_loss: 0.2391 - loss: 0.3510[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1114 - conv2d_19_loss: 0.2389 - loss: 0.3503[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1109 - conv2d_19_loss: 0.2387 - loss: 0.3497[1m223/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1104 - conv2d_19_loss: 0.2386 - loss: 0.3490[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1099 - conv2d_19_loss: 0.2384 - loss: 0.3483[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1094 - conv2d_19_loss: 0.2382 - loss: 0.3476[1m229/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 27ms/step - conv2d_12_loss: 0.1089 - conv2d_19_loss: 0.2380 - loss: 0.3470[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1085 - conv2d_19_loss: 0.2379 - loss: 0.3463[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1080 - conv2d_19_loss: 0.2377 - loss: 0.3457[1m235/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1075 - conv2d_19_loss: 0.2375 - loss: 0.3451[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1071 - conv2d_19_loss: 0.2374 - loss: 0.3444[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1066 - conv2d_19_loss: 0.2372 - loss: 0.3438[1m241/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1061 - conv2d_19_loss: 0.2371 - loss: 0.3432[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1057 - conv2d_19_loss: 0.2369 - loss: 0.3426[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1053 - conv2d_19_loss: 0.2367 - loss: 0.3420[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1048 - conv2d_19_loss: 0.2366 - loss: 0.3414[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1044 - conv2d_19_loss: 0.2364 - loss: 0.3408[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1040 - conv2d_19_loss: 0.2363 - loss: 0.3402[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1035 - conv2d_19_loss: 0.2361 - loss: 0.3397[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1031 - conv2d_19_loss: 0.2360 - loss: 0.3391[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1027 - conv2d_19_loss: 0.2358 - loss: 0.3385[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1023 - conv2d_19_loss: 0.2357 - loss: 0.3380[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1019 - conv2d_19_loss: 0.2355 - loss: 0.3374[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1015 - conv2d_19_loss: 0.2354 - loss: 0.3369[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1011 - conv2d_19_loss: 0.2352 - loss: 0.3363[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step - conv2d_12_loss: 0.1007 - conv2d_19_loss: 0.2351 - loss: 0.3358[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m20s[0m 50ms/step - conv2d_12_loss: 0.0494 - conv2d_19_loss: 0.2154 - loss: 0.2648 - val_conv2d_12_loss: 0.0222 - val_conv2d_19_loss: 0.1842 - val_loss: 0.2099 - learning_rate: 0.0010
[5/7] Running inference...
input shape (32, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(32, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 917ms/step[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step   [1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/stepinput shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 49ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 49ms/step
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m30s[0m 1s/step[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 69ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 69ms/step
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:259: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
  tf_training_config = to_training_config(
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:618: UserWarning: params.cfg already populated. Set force=True to overwrite existing values.
  warnings.warn(
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/ollie/Documents/tmp/PtychoPINN/training_outputs/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 17.2 M | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
17.2 M    Trainable params
0         Non-trainable params
17.2 M    Total params
68.810    Total estimated model params size (MB)
60        Modules in train mode
0         Modules in eval mode
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.
/home/ollie/Documents/tmp/PtychoPINN/ptycho/workflows/grid_lines_workflow.py:548: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
[6/7] Stitching and computing metrics...
Amplitude normalization scale factor: 1.021422
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: amp_pred stats: mean=2.914385, std=0.000000, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn]: phi_pred stats: mean=0.000000, std=0.000000, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.426660
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: amp_pred stats: mean=6.977019, std=1.476979, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [baseline]: phi_pred stats: mean=0.000000, std=0.908805, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
[7/7] Saving outputs...
[grid_lines_workflow] Complete. Outputs in outputs/grid_lines_gs1_n128_tf1_torch50_neuralop_clip2_hybrid
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 16.346701
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_hybrid]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: amp_pred stats: mean=0.182105, std=0.036915, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_hybrid]: phi_pred stats: mean=0.000000, std=0.176108, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
