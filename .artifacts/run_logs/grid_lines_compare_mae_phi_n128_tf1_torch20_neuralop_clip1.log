2026-01-27 13:22:19.647818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769548939.659227  833452 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769548939.663111  833452 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769548939.672957  833452 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548939.672970  833452 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548939.672971  833452 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769548939.672972  833452 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-27 13:22:19.676003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769548942.326167  833452 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769548942.327495  833452 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769548978.138560  833452 service.cc:152] XLA service 0x4b9d2410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769548978.138579  833452 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-27 13:22:58.153937: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769548978.170912  833452 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769548978.387699  833452 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[grid_lines_workflow] Starting N=128, gridsize=1
[1/7] Loading and scaling probe...
Interpolating array from (64, 64) with zoom factor 2.0...
  New shape: (128, 128)
Applying Gaussian filter to complex array of shape (128, 128) (sigma=0.5)...
- Amplitude and unwrapped phase smoothed.
[2/7] Running grid simulation...
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Loading result from disk cache.
Loading result from disk cache.
DEBUG: generating grid-mode ground truth image
DEBUG: Setting set_phi to True in params
DEBUG: Setting data_source to lines in params
DEBUG: Setting size to 392 in params
DEBUG: Setting offset to 4 in params
DEBUG: Setting outer_offset_train to 8 in params
DEBUG: Setting outer_offset_test to 20 in params
DEBUG: Setting nimgs_train to 1 in params
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting nphotons to 1000000000.0 in params
DEBUG: Setting sim_jitter_scale to 0.0 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878602-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250923-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.0238891 -0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.0177561 -0.01380389j]
  [ 0.02431883-0.01161061j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.0356912 +0.0154982j ]
  ...
  [ 0.01803494+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
[3/7] Saving datasets...
[4/7] Training PINN model...
DEBUG: Setting intensity_scale to 494.10587 in params
DEBUG: Setting probe to tf.Tensor(
[[[-0.00281417+0.00957439j]
  [ 0.00331743+0.01025555j]
  [ 0.01147824+0.00401044j]
  ...
  [ 0.00495815+0.02322712j]
  [-0.00977774+0.01104522j]
  [-0.01878603-0.00455442j]]

 [[ 0.00268082+0.00909749j]
  [ 0.00728524+0.00475555j]
  [ 0.00846692-0.00404805j]
  ...
  [ 0.00939881+0.01355992j]
  [-0.00178548+0.00791903j]
  [-0.01220136-0.00049783j]]

 [[ 0.00976495+0.00415384j]
  [ 0.00923867-0.00528766j]
  [ 0.00359875-0.01371592j]
  ...
  [ 0.01361457-0.00591458j]
  [ 0.01250924-0.00197433j]
  [ 0.01142095+0.00119001j]]

 ...

 [[-0.02388911-0.00012609j]
  [-0.01030042-0.00678665j]
  [ 0.0050651 -0.01159466j]
  ...
  [ 0.00455302-0.01465488j]
  [ 0.01775611-0.01380389j]
  [ 0.02431883-0.01161062j]]

 [[-0.0109976 -0.01387846j]
  [ 0.00961646-0.00897927j]
  [ 0.02716208+0.00652508j]
  ...
  [ 0.01472731-0.00267653j]
  [ 0.0192056 +0.00208824j]
  [ 0.01936014+0.00459269j]]

 [[ 0.00103496-0.01461066j]
  [ 0.02086722-0.00362996j]
  [ 0.03569121+0.0154982j ]
  ...
  [ 0.01803495+0.00841902j]
  [ 0.01742416+0.01160111j]
  [ 0.01445885+0.01217751j]]], shape=(128, 128, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 128
amp_activation: sigmoid
architecture: cnn
backend: tensorflow
batch_size: 16
bigN: 128
big_gridsize: 10
data_source: lines
debug: True
default_probe_scale: 0.7
enable_oversampling: False
fno_blocks: 4
fno_cnn_blocks: 2
fno_input_transform: none
fno_modes: 12
fno_width: 32
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 494.1058654785156
intensity_scale.trainable: True
label: 
mae_weight: 1.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 512
neighbor_count: 4
nepochs: 1
nimgs_test: 1
nimgs_train: 1
nll_weight: 0.0
nphotons: 1000000000.0
npseed: 42
object.big: False
offset: 4
outer_offset_test: 20
outer_offset_train: 8
output_prefix: training_outputs
pad_object: True
positions.provided: True
probe:
  shape: (128, 128, 1)
  mean: -0.017-0.002j
  std: 0.672
  min: -3.810-1.052j
  max: 2.870-0.504j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: True
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 1
DEBUG _flat_to_channel: N from global params: 128
DEBUG _flat_to_channel: input shape=(4489, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m31:49[0m 7s/step - intensity_scaler_inv_loss: 24.6252 - loss: 24.6252 - pred_intensity_loss: -498617.8125 - trimmed_obj_loss: 0.0000e+00[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m8s[0m 32ms/step - intensity_scaler_inv_loss: 23.7936 - loss: 23.7936 - pred_intensity_loss: -498925.7812 - trimmed_obj_loss: 0.0000e+00 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 30ms/step - intensity_scaler_inv_loss: 23.5419 - loss: 23.5419 - pred_intensity_loss: -498208.7500 - trimmed_obj_loss: 0.0000e+00[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - intensity_scaler_inv_loss: 23.5146 - loss: 23.5146 - pred_intensity_loss: -499410.1562 - trimmed_obj_loss: 0.0000e+00[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - intensity_scaler_inv_loss: 23.4291 - loss: 23.4291 - pred_intensity_loss: -501662.5625 - trimmed_obj_loss: 0.0000e+00[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - intensity_scaler_inv_loss: 23.3050 - loss: 23.3050 - pred_intensity_loss: -503419.9062 - trimmed_obj_loss: 0.0000e+00[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - intensity_scaler_inv_loss: 23.1830 - loss: 23.1830 - pred_intensity_loss: -505477.6875 - trimmed_obj_loss: 0.0000e+00[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - intensity_scaler_inv_loss: 23.0374 - loss: 23.0374 - pred_intensity_loss: -506683.6562 - trimmed_obj_loss: 0.0000e+00[1m 18/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - intensity_scaler_inv_loss: 22.8310 - loss: 22.8310 - pred_intensity_loss: -507597.4062 - trimmed_obj_loss: 0.0000e+00[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 27ms/step - intensity_scaler_inv_loss: 22.6672 - loss: 22.6672 - pred_intensity_loss: -508487.2500 - trimmed_obj_loss: 0.0000e+00[1m 24/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 26ms/step - intensity_scaler_inv_loss: 22.5214 - loss: 22.5214 - pred_intensity_loss: -509594.8438 - trimmed_obj_loss: 0.0000e+00[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 26ms/step - intensity_scaler_inv_loss: 22.3876 - loss: 22.3876 - pred_intensity_loss: -511259.3750 - trimmed_obj_loss: 0.0000e+00[1m 30/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 26ms/step - intensity_scaler_inv_loss: 22.2742 - loss: 22.2742 - pred_intensity_loss: -512693.9375 - trimmed_obj_loss: 0.0000e+00[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 26ms/step - intensity_scaler_inv_loss: 22.1761 - loss: 22.1761 - pred_intensity_loss: -513750.5938 - trimmed_obj_loss: 0.0000e+00[1m 36/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 22.0805 - loss: 22.0805 - pred_intensity_loss: -514542.0312 - trimmed_obj_loss: 0.0000e+00[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.9861 - loss: 21.9861 - pred_intensity_loss: -515461.0938 - trimmed_obj_loss: 0.0000e+00[1m 42/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.8971 - loss: 21.8971 - pred_intensity_loss: -516226.7812 - trimmed_obj_loss: 0.0000e+00[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.8136 - loss: 21.8136 - pred_intensity_loss: -516808.2500 - trimmed_obj_loss: 0.0000e+00[1m 48/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.7332 - loss: 21.7332 - pred_intensity_loss: -517253.3438 - trimmed_obj_loss: 0.0000e+00[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.6536 - loss: 21.6536 - pred_intensity_loss: -517657.0625 - trimmed_obj_loss: 0.0000e+00[1m 54/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.5734 - loss: 21.5734 - pred_intensity_loss: -517964.5000 - trimmed_obj_loss: 0.0000e+00[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.4926 - loss: 21.4926 - pred_intensity_loss: -518228.6562 - trimmed_obj_loss: 0.0000e+00[1m 60/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.4122 - loss: 21.4122 - pred_intensity_loss: -518442.1250 - trimmed_obj_loss: 0.0000e+00[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 25ms/step - intensity_scaler_inv_loss: 21.3321 - loss: 21.3321 - pred_intensity_loss: -518585.0312 - trimmed_obj_loss: 0.0000e+00[1m 66/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 21.2545 - loss: 21.2545 - pred_intensity_loss: -518791.9062 - trimmed_obj_loss: 0.0000e+00[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 21.1782 - loss: 21.1782 - pred_intensity_loss: -518994.9688 - trimmed_obj_loss: 0.0000e+00[1m 72/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 21.1034 - loss: 21.1034 - pred_intensity_loss: -519241.0312 - trimmed_obj_loss: 0.0000e+00[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 21.0288 - loss: 21.0288 - pred_intensity_loss: -519428.4375 - trimmed_obj_loss: 0.0000e+00[1m 78/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 20.9546 - loss: 20.9546 - pred_intensity_loss: -519588.3125 - trimmed_obj_loss: 0.0000e+00[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 20.8806 - loss: 20.8806 - pred_intensity_loss: -519765.8438 - trimmed_obj_loss: 0.0000e+00[1m 84/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 25ms/step - intensity_scaler_inv_loss: 20.8070 - loss: 20.8070 - pred_intensity_loss: -519912.8438 - trimmed_obj_loss: 0.0000e+00[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.7349 - loss: 20.7349 - pred_intensity_loss: -520052.4062 - trimmed_obj_loss: 0.0000e+00[1m 90/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.6642 - loss: 20.6642 - pred_intensity_loss: -520180.5000 - trimmed_obj_loss: 0.0000e+00[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.5955 - loss: 20.5955 - pred_intensity_loss: -520307.7812 - trimmed_obj_loss: 0.0000e+00[1m 96/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.5278 - loss: 20.5278 - pred_intensity_loss: -520442.5625 - trimmed_obj_loss: 0.0000e+00[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.4606 - loss: 20.4606 - pred_intensity_loss: -520576.4062 - trimmed_obj_loss: 0.0000e+00[1m102/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 24ms/step - intensity_scaler_inv_loss: 20.3934 - loss: 20.3934 - pred_intensity_loss: -520687.0938 - trimmed_obj_loss: 0.0000e+00[1m104/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.3492 - loss: 20.3492 - pred_intensity_loss: -520758.4688 - trimmed_obj_loss: 0.0000e+00[1m106/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.3053 - loss: 20.3053 - pred_intensity_loss: -520829.7500 - trimmed_obj_loss: 0.0000e+00[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.2402 - loss: 20.2402 - pred_intensity_loss: -520939.4688 - trimmed_obj_loss: 0.0000e+00[1m112/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.1757 - loss: 20.1757 - pred_intensity_loss: -521048.0938 - trimmed_obj_loss: 0.0000e+00[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.1117 - loss: 20.1117 - pred_intensity_loss: -521186.1875 - trimmed_obj_loss: 0.0000e+00[1m118/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 20.0480 - loss: 20.0480 - pred_intensity_loss: -521354.4688 - trimmed_obj_loss: 0.0000e+00[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.9845 - loss: 19.9845 - pred_intensity_loss: -521528.0938 - trimmed_obj_loss: 0.0000e+00[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.9423 - loss: 19.9423 - pred_intensity_loss: -521650.5625 - trimmed_obj_loss: 0.0000e+00[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.9002 - loss: 19.9002 - pred_intensity_loss: -521776.2500 - trimmed_obj_loss: 0.0000e+00[1m128/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.8373 - loss: 19.8373 - pred_intensity_loss: -521943.1250 - trimmed_obj_loss: 0.0000e+00[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.7754 - loss: 19.7754 - pred_intensity_loss: -522105.4375 - trimmed_obj_loss: 0.0000e+00[1m134/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.7140 - loss: 19.7140 - pred_intensity_loss: -522269.2500 - trimmed_obj_loss: 0.0000e+00[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.6529 - loss: 19.6529 - pred_intensity_loss: -522440.3438 - trimmed_obj_loss: 0.0000e+00[1m140/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.5922 - loss: 19.5922 - pred_intensity_loss: -522613.9062 - trimmed_obj_loss: 0.0000e+00[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 24ms/step - intensity_scaler_inv_loss: 19.5320 - loss: 19.5320 - pred_intensity_loss: -522794.3125 - trimmed_obj_loss: 0.0000e+00[1m146/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.4723 - loss: 19.4723 - pred_intensity_loss: -522969.5625 - trimmed_obj_loss: 0.0000e+00[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.4130 - loss: 19.4130 - pred_intensity_loss: -523141.5938 - trimmed_obj_loss: 0.0000e+00[1m152/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.3542 - loss: 19.3542 - pred_intensity_loss: -523301.8750 - trimmed_obj_loss: 0.0000e+00[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.2957 - loss: 19.2957 - pred_intensity_loss: -523452.5312 - trimmed_obj_loss: 0.0000e+00[1m158/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.2376 - loss: 19.2376 - pred_intensity_loss: -523589.5625 - trimmed_obj_loss: 0.0000e+00[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.1799 - loss: 19.1799 - pred_intensity_loss: -523718.3750 - trimmed_obj_loss: 0.0000e+00[1m164/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.1225 - loss: 19.1225 - pred_intensity_loss: -523831.8438 - trimmed_obj_loss: 0.0000e+00[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.0656 - loss: 19.0656 - pred_intensity_loss: -523934.9375 - trimmed_obj_loss: 0.0000e+00[1m170/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 19.0092 - loss: 19.0092 - pred_intensity_loss: -524042.0625 - trimmed_obj_loss: 0.0000e+00[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 18.9532 - loss: 18.9532 - pred_intensity_loss: -524149.2812 - trimmed_obj_loss: 0.0000e+00[1m176/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 18.8978 - loss: 18.8978 - pred_intensity_loss: -524257.8125 - trimmed_obj_loss: 0.0000e+00[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 18.8429 - loss: 18.8429 - pred_intensity_loss: -524356.1875 - trimmed_obj_loss: 0.0000e+00[1m182/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 24ms/step - intensity_scaler_inv_loss: 18.7885 - loss: 18.7885 - pred_intensity_loss: -524441.4375 - trimmed_obj_loss: 0.0000e+00[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.7348 - loss: 18.7348 - pred_intensity_loss: -524530.1875 - trimmed_obj_loss: 0.0000e+00[1m188/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.6817 - loss: 18.6817 - pred_intensity_loss: -524617.8750 - trimmed_obj_loss: 0.0000e+00[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.6291 - loss: 18.6291 - pred_intensity_loss: -524708.4375 - trimmed_obj_loss: 0.0000e+00[1m194/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.5770 - loss: 18.5770 - pred_intensity_loss: -524797.1875 - trimmed_obj_loss: 0.0000e+00[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.5253 - loss: 18.5253 - pred_intensity_loss: -524881.5625 - trimmed_obj_loss: 0.0000e+00[1m200/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.4742 - loss: 18.4742 - pred_intensity_loss: -524969.8750 - trimmed_obj_loss: 0.0000e+00[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.4235 - loss: 18.4235 - pred_intensity_loss: -525058.3750 - trimmed_obj_loss: 0.0000e+00[1m206/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.3734 - loss: 18.3734 - pred_intensity_loss: -525150.5000 - trimmed_obj_loss: 0.0000e+00[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.3238 - loss: 18.3238 - pred_intensity_loss: -525249.5000 - trimmed_obj_loss: 0.0000e+00[1m212/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.2748 - loss: 18.2748 - pred_intensity_loss: -525349.4375 - trimmed_obj_loss: 0.0000e+00[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.2263 - loss: 18.2263 - pred_intensity_loss: -525447.0000 - trimmed_obj_loss: 0.0000e+00[1m218/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.1782 - loss: 18.1782 - pred_intensity_loss: -525542.3750 - trimmed_obj_loss: 0.0000e+00[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.1306 - loss: 18.1306 - pred_intensity_loss: -525638.6250 - trimmed_obj_loss: 0.0000e+00[1m224/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 24ms/step - intensity_scaler_inv_loss: 18.0834 - loss: 18.0834 - pred_intensity_loss: -525731.1875 - trimmed_obj_loss: 0.0000e+00[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 18.0365 - loss: 18.0365 - pred_intensity_loss: -525818.7500 - trimmed_obj_loss: 0.0000e+00[1m230/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.9900 - loss: 17.9900 - pred_intensity_loss: -525903.3125 - trimmed_obj_loss: 0.0000e+00[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.9439 - loss: 17.9439 - pred_intensity_loss: -525988.1250 - trimmed_obj_loss: 0.0000e+00[1m236/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.8982 - loss: 17.8982 - pred_intensity_loss: -526070.2500 - trimmed_obj_loss: 0.0000e+00[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.8529 - loss: 17.8529 - pred_intensity_loss: -526154.1250 - trimmed_obj_loss: 0.0000e+00[1m242/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.8079 - loss: 17.8079 - pred_intensity_loss: -526231.7500 - trimmed_obj_loss: 0.0000e+00[1m244/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.7782 - loss: 17.7782 - pred_intensity_loss: -526280.9375 - trimmed_obj_loss: 0.0000e+00[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.7339 - loss: 17.7339 - pred_intensity_loss: -526347.0625 - trimmed_obj_loss: 0.0000e+00[1m250/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.6901 - loss: 17.6901 - pred_intensity_loss: -526409.4375 - trimmed_obj_loss: 0.0000e+00[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.6467 - loss: 17.6467 - pred_intensity_loss: -526465.3125 - trimmed_obj_loss: 0.0000e+00[1m256/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.6037 - loss: 17.6037 - pred_intensity_loss: -526520.3125 - trimmed_obj_loss: 0.0000e+00[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.5611 - loss: 17.5611 - pred_intensity_loss: -526575.0625 - trimmed_obj_loss: 0.0000e+00[1m262/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.5190 - loss: 17.5190 - pred_intensity_loss: -526632.6250 - trimmed_obj_loss: 0.0000e+00[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 17.4772 - loss: 17.4772 - pred_intensity_loss: -526692.2500 - trimmed_obj_loss: 0.0000e+00[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 29ms/step - intensity_scaler_inv_loss: 17.4496 - loss: 17.4496 - pred_intensity_loss: -526728.5625 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m16s[0m 35ms/step - intensity_scaler_inv_loss: 13.7775 - loss: 13.7872 - pred_intensity_loss: -531414.3125 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 10.1767 - val_loss: 10.1620 - val_pred_intensity_loss: -527012.6250 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
[4/7] Training Baseline model...
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 128, 128,  â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 128, 128,  â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 128, 128,  â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 64, 64,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 64, 64,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 32, 32,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 64, 64,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 128, 128,  â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 128, 128,  â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”‚                     â”‚ 1)                â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 1 epochs and batch size 16
[1m  1/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m32:25[0m 7s/step - conv2d_12_loss: 0.1784 - conv2d_19_loss: 0.2701 - loss: 0.4486[1m  3/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 29ms/step - conv2d_12_loss: 0.3751 - conv2d_19_loss: 0.2574 - loss: 0.6325 [1m  5/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3579 - conv2d_19_loss: 0.2511 - loss: 0.6091[1m  7/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3356 - conv2d_19_loss: 0.2506 - loss: 0.5863[1m  9/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3173 - conv2d_19_loss: 0.2491 - loss: 0.5664[1m 11/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.3023 - conv2d_19_loss: 0.2475 - loss: 0.5499[1m 13/267[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2900 - conv2d_19_loss: 0.2462 - loss: 0.5362[1m 15/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 28ms/step - conv2d_12_loss: 0.2793 - conv2d_19_loss: 0.2450 - loss: 0.5243[1m 17/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2704 - conv2d_19_loss: 0.2439 - loss: 0.5142[1m 19/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2624 - conv2d_19_loss: 0.2428 - loss: 0.5052[1m 21/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2556 - conv2d_19_loss: 0.2419 - loss: 0.4975[1m 23/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2498 - conv2d_19_loss: 0.2410 - loss: 0.4907[1m 25/267[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2447 - conv2d_19_loss: 0.2401 - loss: 0.4848[1m 27/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2402 - conv2d_19_loss: 0.2394 - loss: 0.4796[1m 29/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2362 - conv2d_19_loss: 0.2386 - loss: 0.4748[1m 31/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2326 - conv2d_19_loss: 0.2379 - loss: 0.4706[1m 33/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2293 - conv2d_19_loss: 0.2373 - loss: 0.4666[1m 35/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2261 - conv2d_19_loss: 0.2367 - loss: 0.4628[1m 37/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2230 - conv2d_19_loss: 0.2362 - loss: 0.4592[1m 39/267[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2200 - conv2d_19_loss: 0.2357 - loss: 0.4558[1m 41/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2171 - conv2d_19_loss: 0.2353 - loss: 0.4524[1m 43/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2143 - conv2d_19_loss: 0.2349 - loss: 0.4491[1m 45/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2115 - conv2d_19_loss: 0.2345 - loss: 0.4459[1m 47/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2087 - conv2d_19_loss: 0.2341 - loss: 0.4428[1m 49/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 28ms/step - conv2d_12_loss: 0.2061 - conv2d_19_loss: 0.2338 - loss: 0.4398[1m 51/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.2034 - conv2d_19_loss: 0.2334 - loss: 0.4369[1m 53/267[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.2009 - conv2d_19_loss: 0.2331 - loss: 0.4340[1m 55/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1983 - conv2d_19_loss: 0.2328 - loss: 0.4311[1m 57/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1959 - conv2d_19_loss: 0.2325 - loss: 0.4284[1m 59/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1935 - conv2d_19_loss: 0.2322 - loss: 0.4257[1m 61/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1912 - conv2d_19_loss: 0.2319 - loss: 0.4231[1m 63/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1890 - conv2d_19_loss: 0.2317 - loss: 0.4206[1m 65/267[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1868 - conv2d_19_loss: 0.2314 - loss: 0.4182[1m 67/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1847 - conv2d_19_loss: 0.2312 - loss: 0.4158[1m 69/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1826 - conv2d_19_loss: 0.2309 - loss: 0.4135[1m 71/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1806 - conv2d_19_loss: 0.2307 - loss: 0.4113[1m 73/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1786 - conv2d_19_loss: 0.2305 - loss: 0.4091[1m 75/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1767 - conv2d_19_loss: 0.2303 - loss: 0.4069[1m 77/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1748 - conv2d_19_loss: 0.2301 - loss: 0.4049[1m 79/267[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1730 - conv2d_19_loss: 0.2299 - loss: 0.4028[1m 81/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1712 - conv2d_19_loss: 0.2297 - loss: 0.4008[1m 83/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1695 - conv2d_19_loss: 0.2295 - loss: 0.3989[1m 85/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 28ms/step - conv2d_12_loss: 0.1678 - conv2d_19_loss: 0.2293 - loss: 0.3970[1m 87/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1661 - conv2d_19_loss: 0.2291 - loss: 0.3952[1m 89/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1645 - conv2d_19_loss: 0.2289 - loss: 0.3934[1m 91/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1629 - conv2d_19_loss: 0.2287 - loss: 0.3917[1m 93/267[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1614 - conv2d_19_loss: 0.2286 - loss: 0.3900[1m 95/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1599 - conv2d_19_loss: 0.2284 - loss: 0.3883[1m 97/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1584 - conv2d_19_loss: 0.2282 - loss: 0.3867[1m 99/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1570 - conv2d_19_loss: 0.2281 - loss: 0.3851[1m101/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1556 - conv2d_19_loss: 0.2279 - loss: 0.3835[1m103/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1543 - conv2d_19_loss: 0.2278 - loss: 0.3820[1m105/267[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1529 - conv2d_19_loss: 0.2276 - loss: 0.3805[1m107/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1516 - conv2d_19_loss: 0.2274 - loss: 0.3791[1m109/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1503 - conv2d_19_loss: 0.2273 - loss: 0.3776[1m111/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1491 - conv2d_19_loss: 0.2271 - loss: 0.3762[1m113/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1479 - conv2d_19_loss: 0.2270 - loss: 0.3748[1m115/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1467 - conv2d_19_loss: 0.2268 - loss: 0.3735[1m117/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1455 - conv2d_19_loss: 0.2267 - loss: 0.3722[1m119/267[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1444 - conv2d_19_loss: 0.2265 - loss: 0.3709[1m121/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m4s[0m 28ms/step - conv2d_12_loss: 0.1432 - conv2d_19_loss: 0.2264 - loss: 0.3696[1m123/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1422 - conv2d_19_loss: 0.2263 - loss: 0.3684[1m125/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1411 - conv2d_19_loss: 0.2261 - loss: 0.3672[1m127/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1400 - conv2d_19_loss: 0.2260 - loss: 0.3660[1m129/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1390 - conv2d_19_loss: 0.2259 - loss: 0.3649[1m131/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1380 - conv2d_19_loss: 0.2257 - loss: 0.3637[1m133/267[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1370 - conv2d_19_loss: 0.2256 - loss: 0.3626[1m135/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1360 - conv2d_19_loss: 0.2255 - loss: 0.3615[1m137/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1351 - conv2d_19_loss: 0.2253 - loss: 0.3604[1m139/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1341 - conv2d_19_loss: 0.2252 - loss: 0.3594[1m141/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1332 - conv2d_19_loss: 0.2251 - loss: 0.3583[1m143/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1323 - conv2d_19_loss: 0.2250 - loss: 0.3573[1m145/267[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1315 - conv2d_19_loss: 0.2249 - loss: 0.3563[1m147/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1306 - conv2d_19_loss: 0.2247 - loss: 0.3553[1m149/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1297 - conv2d_19_loss: 0.2246 - loss: 0.3544[1m151/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1289 - conv2d_19_loss: 0.2245 - loss: 0.3534[1m153/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1281 - conv2d_19_loss: 0.2244 - loss: 0.3525[1m155/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1273 - conv2d_19_loss: 0.2243 - loss: 0.3515[1m157/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m3s[0m 28ms/step - conv2d_12_loss: 0.1265 - conv2d_19_loss: 0.2241 - loss: 0.3506[1m159/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1257 - conv2d_19_loss: 0.2240 - loss: 0.3497[1m161/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1249 - conv2d_19_loss: 0.2239 - loss: 0.3489[1m163/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1242 - conv2d_19_loss: 0.2238 - loss: 0.3480[1m165/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1235 - conv2d_19_loss: 0.2237 - loss: 0.3471[1m167/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1227 - conv2d_19_loss: 0.2236 - loss: 0.3463[1m169/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1220 - conv2d_19_loss: 0.2234 - loss: 0.3455[1m171/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1213 - conv2d_19_loss: 0.2233 - loss: 0.3446[1m173/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1206 - conv2d_19_loss: 0.2232 - loss: 0.3438[1m175/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1199 - conv2d_19_loss: 0.2231 - loss: 0.3430[1m177/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1193 - conv2d_19_loss: 0.2230 - loss: 0.3423[1m179/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1186 - conv2d_19_loss: 0.2229 - loss: 0.3415[1m181/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1179 - conv2d_19_loss: 0.2228 - loss: 0.3407[1m183/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1173 - conv2d_19_loss: 0.2227 - loss: 0.3400[1m185/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1167 - conv2d_19_loss: 0.2225 - loss: 0.3392[1m187/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1161 - conv2d_19_loss: 0.2224 - loss: 0.3385[1m189/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1154 - conv2d_19_loss: 0.2223 - loss: 0.3378[1m191/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1148 - conv2d_19_loss: 0.2222 - loss: 0.3371[1m193/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m2s[0m 28ms/step - conv2d_12_loss: 0.1142 - conv2d_19_loss: 0.2221 - loss: 0.3364[1m195/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1137 - conv2d_19_loss: 0.2220 - loss: 0.3357[1m197/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1131 - conv2d_19_loss: 0.2219 - loss: 0.3350[1m199/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1125 - conv2d_19_loss: 0.2218 - loss: 0.3343[1m201/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1119 - conv2d_19_loss: 0.2217 - loss: 0.3336[1m203/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1114 - conv2d_19_loss: 0.2216 - loss: 0.3330[1m205/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1108 - conv2d_19_loss: 0.2215 - loss: 0.3323[1m207/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1103 - conv2d_19_loss: 0.2214 - loss: 0.3317[1m209/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1098 - conv2d_19_loss: 0.2213 - loss: 0.3310[1m211/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1093 - conv2d_19_loss: 0.2212 - loss: 0.3304[1m213/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1087 - conv2d_19_loss: 0.2211 - loss: 0.3298[1m215/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1082 - conv2d_19_loss: 0.2210 - loss: 0.3292[1m217/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1077 - conv2d_19_loss: 0.2209 - loss: 0.3286[1m219/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1072 - conv2d_19_loss: 0.2207 - loss: 0.3280[1m221/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1067 - conv2d_19_loss: 0.2206 - loss: 0.3274[1m223/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1063 - conv2d_19_loss: 0.2205 - loss: 0.3268[1m225/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1058 - conv2d_19_loss: 0.2204 - loss: 0.3262[1m227/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1053 - conv2d_19_loss: 0.2203 - loss: 0.3256[1m229/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m1s[0m 28ms/step - conv2d_12_loss: 0.1048 - conv2d_19_loss: 0.2202 - loss: 0.3251[1m231/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1044 - conv2d_19_loss: 0.2201 - loss: 0.3245[1m233/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1039 - conv2d_19_loss: 0.2200 - loss: 0.3239[1m235/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1035 - conv2d_19_loss: 0.2199 - loss: 0.3234[1m237/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1030 - conv2d_19_loss: 0.2198 - loss: 0.3228[1m239/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1026 - conv2d_19_loss: 0.2197 - loss: 0.3223[1m241/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1022 - conv2d_19_loss: 0.2196 - loss: 0.3218[1m243/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1017 - conv2d_19_loss: 0.2195 - loss: 0.3213[1m245/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1013 - conv2d_19_loss: 0.2194 - loss: 0.3207[1m247/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1009 - conv2d_19_loss: 0.2193 - loss: 0.3202[1m249/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1005 - conv2d_19_loss: 0.2192 - loss: 0.3197[1m251/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.1001 - conv2d_19_loss: 0.2191 - loss: 0.3192[1m253/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0997 - conv2d_19_loss: 0.2190 - loss: 0.3187[1m255/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0993 - conv2d_19_loss: 0.2189 - loss: 0.3182[1m257/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0989 - conv2d_19_loss: 0.2188 - loss: 0.3178[1m259/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0986 - conv2d_19_loss: 0.2187 - loss: 0.3173[1m261/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0982 - conv2d_19_loss: 0.2186 - loss: 0.3168[1m263/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0978 - conv2d_19_loss: 0.2185 - loss: 0.3163[1m265/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0974 - conv2d_19_loss: 0.2184 - loss: 0.3159[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 43ms/step - conv2d_12_loss: 0.0971 - conv2d_19_loss: 0.2183 - loss: 0.3154[1m267/267[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m21s[0m 51ms/step - conv2d_12_loss: 0.0486 - conv2d_19_loss: 0.2060 - loss: 0.2547 - val_conv2d_12_loss: 0.0266 - val_conv2d_19_loss: 0.1935 - val_loss: 0.2227 - learning_rate: 0.0010
[5/7] Running inference...
input shape (32, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(32, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m20s[0m 933ms/step[1m 7/23[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step   [1m13/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 9ms/step[1m19/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 9ms/stepinput shape (None, 128, 128, 1)
DEBUG _flat_to_channel: gridsize from parameter: 1
DEBUG _flat_to_channel: N from parameter: 128
DEBUG _flat_to_channel: input shape=(None, 128, 128, 1), reshaping to (-1, 1, 128, 128)
[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 52ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 52ms/step
[1m 1/23[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m30s[0m 1s/step[1m 6/23[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step[1m10/23[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m14/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step[1m18/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 13ms/step[1m22/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 13ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 72ms/step[1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 73ms/step
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:259: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
  tf_training_config = to_training_config(
/home/ollie/Documents/tmp/PtychoPINN/ptycho_torch/config_factory.py:618: UserWarning: params.cfg already populated. Set force=True to overwrite existing values.
  warnings.warn(
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
INFO:pytorch_lightning.utilities.rank_zero:You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/ollie/Documents/tmp/PtychoPINN/training_outputs/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 656 K  | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
656 K     Trainable params
0         Non-trainable params
656 K     Total params
2.624     Total estimated model params size (MB)
43        Modules in train mode
0         Modules in eval mode
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.
Seed set to 42
INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params | Mode 
---------------------------------------------
0 | model | PtychoPINN | 17.2 M | train
1 | Loss  | MAELoss    | 0      | train
---------------------------------------------
17.2 M    Trainable params
0         Non-trainable params
17.2 M    Total params
68.810    Total estimated model params size (MB)
60        Modules in train mode
0         Modules in eval mode
INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=20` reached.
/home/ollie/Documents/tmp/PtychoPINN/ptycho/workflows/grid_lines_workflow.py:548: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.tight_layout()
[6/7] Stitching and computing metrics...
Amplitude normalization scale factor: 1.041112
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: amp_pred stats: mean=2.859268, std=0.529231, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn]: phi_pred stats: mean=-0.000000, std=1.094950, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 0.365600
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: amp_pred stats: mean=8.142278, std=1.803646, shape=(266, 266, 1)
DEBUG eval_reconstruction [baseline]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [baseline]: phi_pred stats: mean=0.000000, std=1.397596, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
[7/7] Saving outputs...
[grid_lines_workflow] Complete. Outputs in outputs/grid_lines_gs1_n128_tf1_torch20_neuralop_clip1
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 16.529749
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_fno]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_fno]: amp_pred stats: mean=0.180089, std=0.037707, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_fno]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_fno]: phi_pred stats: mean=0.000000, std=0.180869, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
DEBUG: Setting nimgs_test to 1 in params
DEBUG: Setting outer_offset_test to 20 in params
Amplitude normalization scale factor: 16.319408
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [pinn_hybrid]: amp_target stats: mean=2.976817, std=0.648537, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: amp_pred stats: mean=0.182410, std=0.035491, shape=(266, 266, 1)
DEBUG eval_reconstruction [pinn_hybrid]: phi_target stats: mean=0.000000, std=0.241847, shape=(266, 266)
DEBUG eval_reconstruction [pinn_hybrid]: phi_pred stats: mean=0.000000, std=0.187532, shape=(266, 266)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.647, 0.710] -> scaled range [0.397, 0.613]
performed by index method
performed by index method
performed by index method
