# Fix Plan Archive

This file stores dated snapshots of `docs/fix_plan.md` for historical reference.
Each snapshot is appended and never modified after creation.

---



---

# Snapshot 2026-01-06 Fix Plan Ledger

# PtychoPINN Fix Plan Ledger (Condensed)

**Last Updated:** 2025-11-20 (ARRP Phase 4 artifact alignment; Tier-2 dwell context preserved)
**Active Focus:** FIX-TF-C1D-SCALED-RERUN-001 ‚Äî Guard + scaled TF rerun evidence capture (Phase‚ÄØC1d)

---

## [STUDY-SYNTH-FLY64-DOSE-OVERLAP-001] Synthetic fly64 dose/overlap study
- Depends on: Phase‚ÄØC/E/F artifacts already staged under `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/data/`; FEAT-LAZY-LOADING-001 to eliminate the dense-test OOM wall called out by PINN-CHUNKED-001.
- Priority: High
- Status: blocked_escalation ‚Äî Tier‚ÄØ3 dwell triggered on 2025-11-16; full dense-test Phase‚ÄØG remains blocked on GPU/TF resource limits. See `analysis/dwell_escalation_report.md` plus hub `red/` blockers for the detailed error signatures and prior attempts.
- Owner/Date: Ralph/2025-11-11
- Working Plan: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md`
- Summary: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/summary.md`
- Reports Hub: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/`
- Goals:
  - <strong>G‚Äëfull (blocked):</strong> Phase‚ÄØG dense verification on the full dense train+test configurations (current 5216‚Äëgroup test split) with non‚Äëzero Baseline rows, SSIM grid, metrics summary/deltas/preview, verification_report.json=10/10, and artifact_inventory.txt. Concrete commands and flags are defined in the hub plan (`.../phase_g_dense_full_run_verifier/plan/plan.md`) and associated CLI logs.
  - <strong>G‚Äëscaled (next execution target):</strong> Phase‚ÄØG dense verification on a <em>scaled</em> configuration that uses the same CLI/code paths but reduces size/time knobs (e.g., constrained `--n-test-groups` / chunk sizes) so that chunked compare_models, Phase‚ÄØD guards, counted `run_phase_g_dense.py`, metrics helpers, and `--post-verify-only` can complete without OOM/timeout while producing non‚Äëzero Baseline rows and a self‚Äëconsistent verification bundle. The exact scaled configuration and commands are documented in the Working Plan and hub plan; results must be labeled as scaled in the hub summary.
- Return Conditions:
  - <strong>For G‚Äëscaled:</strong> A scaled Phase‚ÄØG rerun has completed end‚Äëto‚Äëend via the existing Phase‚ÄØG plan/CLI (see hub `plan/plan.md`), and `{analysis}` under the Reports Hub contains: (a) populated Baseline rows for the scaled train/test splits, (b) SSIM grid and metrics summary/deltas/preview for the scaled configuration, (c) verification_report.json updated to reflect the scaled run, and (d) artifact_inventory.txt covering all Phase‚ÄØG artifacts. Any remaining resource or correctness issues at scaled configuration must be documented under `$HUB/red/blocked_<timestamp>.md`.
  - <strong>For G‚Äëfull:</strong> After at least one successful scaled configuration, either: (a) a follow‚Äëup initiative is opened to address the GPU/TF/container limitations that prevent full dense-test compare_models and counted Phase‚ÄØG at full scale (referencing this row and the hub blockers); or (b) a decision is recorded in the Working Plan and `docs/findings.md` that G‚Äëfull will remain blocked, with the current error signatures cited and the scaled configuration accepted as the practical endpoint for this study.
- Latest Attempt (2025-11-16T110500Z): planning ‚Äî Tier‚ÄØ3 enforcement logged under `analysis/dwell_escalation_report.md` and initiative summary updated to reflect the G‚Äëfull/G‚Äëscaled split; no further planning until Ralph lands a scaled‚Äëconfiguration rerun that satisfies the G‚Äëscaled Return Condition or records a new scaled‚Äëconfig blocker.

## [FIX-PYTORCH-FORWARD-PARITY-001] Stabilize Torch Forward Patch Parity
- Depends on: INTEGRATE-PYTORCH-PARITY-001 (PyTorch backend API parity reactivation), FIX-COMPARE-MODELS-TRANSLATION-001 (translation batching guardrails)
- Priority: High
- Status: blocked ‚Äî Phase‚ÄØA/B complete (intensity_scale=9.882118), but Tier-2 dwell enforcement triggered because the guard selector + scaled TF rerun have not executed since Ralph‚Äôs commit `a4e980e4`; awaiting completion of the dedicated blocker focus FIX-TF-C1D-SCALED-RERUN-001.
- Owner/Date: Ralph/2025-11-14
- Working Plan: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/implementation.md`
- Reports Hub: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/reports/2025-11-13T000000Z/forward_parity/`
- Notes: Phase‚ÄØA rerun v3 (2025-11-14T0547Z) confirmed TrainingPayload threading and healthy variance; B1 object_big defaults already enforced (`ptycho_torch/config_factory.py:205-234`). Commit 9a09ece2 threads the learned/fallback `intensity_scale` through `_train_with_lightning ‚Üí save_torch_bundle ‚Üí load_inference_bundle_torch` with docs/tests updated (`docs/workflows/pytorch.md:150-189`, `tests/torch/test_model_manager.py:1-200`). Scaling evidence now lives under `scaling_alignment/phase_b3/analysis/forward_parity_debug_scaling/stats.json` showing the persisted scalar is loaded at inference time (phase_b3 log line‚ÄØ29).
- Do Now (next): BLOCKED ‚Äî actionable work is tracked under FIX-TF-C1D-SCALED-RERUN-001; reopen this parent focus once that blocker delivers guard + scaled TF evidence or records a new failure per Return Condition.
- Return Condition: Resume work here when FIX-TF-C1D-SCALED-RERUN-001 produces both (a) `$HUB/green/pytest_tf_translation_guard.log` from `pytest tests/tf_helper/test_translation_shape_guard.py::test_non_xla_translation_guard -vv | tee "$HUB/green/pytest_tf_translation_guard.log"` and (b) `$HUB/tf_baseline/phase_c1_scaled/analysis/forward_parity_debug_tf/{stats.json,offsets.json,pngs}` + a non-empty `$HUB/tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log` (or an updated `$HUB/tf_baseline/phase_c1_scaled/red/blocked_<timestamp>_tf_translation_guard.md` citing the selector + CLI logs).

- Latest Attempt (2025-11-19T190500Z): planning ‚Äî Dwell hit Tier‚ÄØ2 with no new Ralph execution since commit `a4e980e4`; `git log --oneline --grep '^RALPH' -n1` still reports that SHA and the Do‚ÄØNow commands from `input.md` (`pytest tests/tf_helper/test_translation_shape_guard.py::test_non_xla_translation_guard -vv | tee "$HUB/green/pytest_tf_translation_guard.log"` and `python scripts/training/train.py --backend tensorflow --train_data_file ... --gridsize 2 --neighbor_count 7 |& tee "$HUB/tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log"`) have not produced any artifacts (`tf_baseline/phase_c1_scaled/analysis/` empty, `tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log` still 0‚ÄØbytes per `ls -l`). Focus marked BLOCKED and blocker focus FIX-TF-C1D-SCALED-RERUN-001 minted with the same selector/CLI plus blocker policy so dwell resets there.
- Latest Attempt (2025-11-19T160500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / TF-NON-XLA-SHAPE-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; docs/workflows/pytorch.md; specs/spec-ptycho-workflow.md; specs/spec-ptycho-core.md; specs/spec-ptycho-interfaces.md; specs/spec-ptycho-runtime.md; specs/spec-ptycho-tracing.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; prompts/callchain.md; docs/fix_plan.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; and the Reports Hub (`$HUB/analysis`, `summary.md`, `tf_baseline/phase_c1_scaled/{cli,analysis,red}`). Reality: `tf_baseline/phase_c1_scaled/analysis/` remains empty, `cli/train_tf_phase_c1_scaled.log` is still 0‚ÄØbytes, and the guard regression tests already cover the fixed non-XLA path, so no new TF artifacts have landed since the last loop. Do‚ÄØNow stays focused on re-running the guard selector + scaled TF CLI with the recorded env vars, then updating `analysis/artifact_inventory.txt` (or logging a fresh blocker) as soon as the run completes.
- Latest Attempt (2025-11-19T123500Z): planning ‚Äî Verified that the non-XLA guard + regression tests already exist (commit `801780b6`, `ptycho/tf_helper.py:702-790`, `tests/tf_helper/test_translation_shape_guard.py:1-156`) and that `$HUB/tf_baseline/phase_c1_scaled/analysis/` is still empty with `cli/train_tf_phase_c1_scaled.log` at 0‚ÄØbytes, so the missing evidence is the scaled TF rerun rather than new code edits. Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / TF-NON-XLA-SHAPE-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/workflows/pytorch.md; docs/architecture.md; specs/spec-ptycho-workflow.md; specs/spec-ptycho-core.md; specs/spec-ptycho-interfaces.md; specs/spec-ptycho-runtime.md; specs/spec-ptycho-tracing.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; Reports Hub `$HUB/tf_baseline/phase_c1_scaled/{cli,analysis,red}`. Updated the working plan checklist (split C1d into guard vs rerun), refreshed the initiative summary + Do‚ÄØNow, and rewrote input.md so Ralph‚Äôs next turn runs the guard pytest selector followed by the scaled TF CLI with the specified env captures, then updates `analysis/artifact_inventory.txt` or files a new blocker if `_translate_images_simple` still reshapes incorrectly. Status: ready_for_implementation.

- Latest Attempt (2025-11-19T093000Z): planning ‚Äî Confirmed the inference CLI guard already landed in commit `f85a9150` by reviewing the new assertions in `tests/torch/test_cli_train_torch.py` and `$HUB/green/pytest_patch_variance_guard.log` (1/1 PASSED, 7.21s). Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/spec-ptycho-workflow.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; and the TF blocker files under `$HUB/tf_baseline/phase_c1/red/`. Updated the implementation plan checklist (C3c/C3d checked off), added the C1d subtask authorizing a `ptycho/tf_helper.py` edit + regression test, rewrote this Do‚ÄØNow, and refreshed the initiative summary so Ralph can implement the non-XLA translation guard before rerunning the scaled TF baseline. Status: ready_for_implementation.

- Latest Attempt (2025-11-19T060500Z): planning ‚Äî Verified Ralph‚Äôs Phase‚ÄØC3 training guard commit (`392a44ea`) refreshed `tests/torch/test_cli_train_torch.py`, `$HUB/green/pytest_patch_variance_guard.log`, and the Phase‚ÄØC3 section in `analysis/artifact_inventory.txt`, but confirmed there is still no inference guard coverage. Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / ANTIPATTERN-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/spec-ptycho-workflow.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}`; Reports Hub `analysis/artifact_inventory.txt`, `summary.md`, and `green/pytest_patch_variance_guard.log`. Updated the implementation plan checklist (C3c/C3d), initiative summary, and this Do‚ÄØNow so Ralph extends the selector to run the inference CLI, enforces the same variance/global-mean thresholds on `torch_patch_stats_inference.json`, and refreshes hub summaries/logs or logs a blocker if inference collapses. Status: ready_for_implementation.

## [FIX-IMPORT-SIDE-EFFECTS-001] Remove Global State Side-Effects in ptycho/model.py
- Depends on: `spec-ptycho-config-bridge.md` Compliance & Prohibitions; `docs/debugging/QUICK_REFERENCE_PARAMS.md` initialization-order guardrails.
- Priority: High
- Status: pending ‚Äî planning artifacts created 2025-11-20; awaiting execution of Phase‚ÄØA regression tests.
- Owner/Date: Ralph/2025-11-20
- Working Plan: `plans/active/FIX-IMPORT-SIDE-EFFECTS-001/implementation.md`
- Summary: `plans/active/FIX-IMPORT-SIDE-EFFECTS-001/summary.md`
- Reports Hub: `plans/active/FIX-IMPORT-SIDE-EFFECTS-001/reports/`
- Goals:
  - Remove module-scope `params.get()` calls so importing `ptycho/model.py` never pre-reads legacy config.
  - Ensure `autoencoder`/`diffraction_to_obj` are instantiated through factories after `update_legacy_dict`.
  - Add regression tests proving `import ptycho.model` performs no `ptycho.params` access.
- Return Condition: Regression test passes and the plan summary documents factory-only config access with evidence stored in the Reports Hub.

## [FEAT-LAZY-LOADING-001] Implement Lazy Tensor Allocation in loader.py
- Depends on: `spec-ptycho-workflow.md` Resource Constraints; finding `PINN-CHUNKED-001` (dense-test OOM blocker).
- Priority: High
- Status: pending ‚Äî planning artifacts created 2025-11-20; awaiting Phase‚ÄØA reproduction script.
- Owner/Date: Ralph/2025-11-20
- Working Plan: `plans/active/FEAT-LAZY-LOADING-001/implementation.md`
- Summary: `plans/active/FEAT-LAZY-LOADING-001/summary.md`
- Reports Hub: `plans/active/FEAT-LAZY-LOADING-001/reports/`
- Goals:
  - Refactor `PtychoDataContainer` so datasets stay in NumPy/mmap form until batches are requested.
  - Provide streaming/batching APIs (`.as_dataset()` or equivalent) so training/inference loops avoid full VRAM allocation.
  - Update dependent scripts (train_pinn, compare_models) to use the lazy interfaces.
- Return Condition: Lazy container merged with tests reproducing and fixing the OOM scenario, and STUDY-SYNTH-FLY64 marked unblocked with scaled/full runs reinstated.

- Latest Attempt (2025-11-19T014500Z): evidence_only ‚Äî Executed Phase C1c GS1 consolidation: ran Python snippet to generate stats-delta artifact (sha1: 50ac27fa99bd12a332fdbb44cec98da92d3dac74) showing phase_b3.patch.var_zero_mean=8.97e9 vs phase_c1_gs1=0.0, mirrored into both tf_baseline/phase_c1_gs1/ and scaling_alignment/phase_c1_gs1/. Updated hub `analysis/artifact_inventory.txt` with comprehensive Phase C1 GS1 section documenting PyTorch-only completion (bundle c3124f2d, intensity_scale persisted correctly) plus three TensorFlow blocker files. Prepended `$HUB/summary.md` and initiative `summary.md` with dataset note (same fly001_reconstructed, no divergence), stats-delta paths, and PyTorch-only decision per POLICY-001. All GS1 evidence now reviewer-visible; ready for Phase C2.
- Latest Attempt (2025-11-19T024500Z): planning ‚Äî Verified Ralph‚Äôs GS1 consolidation landed (stats delta + hub inventory/summary). Updated the implementation plan with a detailed Phase‚ÄØC2 PyTorch-only comparison workflow (Tier‚Äë2 script, CLI recipe, metrics/sha1 destinations, blocker handling). Refreshed the initiative summary so the next Do‚ÄØNow instructs Ralph to create `bin/phase_c2_compare_stats.py`, run it on Phase‚ÄØB3 vs GS1 stats, and publish `$HUB/analysis/phase_c2_pytorch_only_metrics.txt` plus log/sha1 updates or emit a missing-stats blocker.
- Latest Attempt (2025-11-19T032500Z): planning ‚Äî Confirmed Phase‚ÄØC2 artifacts landed (`bin/phase_c2_compare_stats.py`, metrics file, hub inventory/summary updates) and that TensorFlow remains blocked, so the next critical gap is a regression guard ensuring PyTorch patch variance never collapses at gridsize‚ÄØ2. Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / ANTIPATTERN-001 / XLA-DYN-DOT-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/spec-ptycho-workflow.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; hub artifacts (`analysis/phase_c2_pytorch_only_metrics.txt`, `analysis/artifact_inventory.txt`, `cli/phase_c2_compare_stats.log`). Updated the implementation plan with a Phase‚ÄØC3 action plan (seeded CLI fixture, `var_zero_mean > 1e-6` assertion, pytest logging requirements), refreshed the initiative summary, and rewrote input.md so Ralph edits the existing selector, captures `pytest ...test_patch_stats_dump` to `$HUB/green/pytest_patch_variance_guard.log`, and files a blocker if the stats JSON is missing. Status: ready_for_implementation.
- Latest Attempt (2025-11-19T011500Z) [superseded by 2025-11-19T014500Z]: planning ‚Äî Confirmed GS1 PyTorch artifacts already live under `scaling_alignment/phase_c1_gs1/` (train/infer logs, stats JSON, debug dump) while TensorFlow remains blocked via `tf_baseline/phase_c1_gs1/red/blocked_*`. The hub inventory/summary still stop at Phase‚ÄØB3, so parity reviewers cannot see the GS1 fallback or the blocker details. Re-scoped the Do‚ÄØNow to (a) generate a stats-delta text file comparing `forward_parity_debug_scaling/stats.json` vs `forward_parity_debug_gs1/stats.json`, (b) append a ‚ÄúPhase‚ÄØC1 ‚Äî GS1 fallback‚Äù section to `$HUB/analysis/artifact_inventory.txt`, and (c) prepend the initiative summary/hub summary with the dataset note, stats delta path, and TF blocker citations so Phase‚ÄØC2 can proceed PyTorch-only. Artifacts reviewed: docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / ANTIPATTERN-001 / XLA-DYN-DOT-001); docs/DEVELOPER_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/spec-ptycho-workflow.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; Reports Hub `analysis/artifact_inventory.txt`, `scaling_alignment/phase_b3/analysis/forward_parity_debug_scaling/stats.json`, `scaling_alignment/phase_c1_gs1/analysis/forward_parity_debug_gs1/stats.json`, `scaling_alignment/phase_c1_gs1/analysis/torch_patch_stats_gs1.json`, `tf_baseline/phase_c1_gs1/{cli/train_tf_phase_c1_gs1.log,green/pytest_tf_integration_gs1.log,red/blocked_*}`; input.md; galph_memory.md.

- Priority: High (unblocks the guarded baseline integration test, Phase‚ÄØG dense orchestrator suite, and PyTorch workflow regressions)
- Status: pending ‚Äî implementation plan drafted; awaiting first Do Now loop
- Owner/Date: Ralph/2025-11-14
- Working Plan: `plans/active/FIX-PYTEST-SUITE-REALIGN-001/implementation.md`
- Notes: Fixes the Literal CLI parsing regression in `parse_arguments`, updates Phase‚ÄØG orchestrator tests for the programmatic Phase‚ÄØD path, and refreshes PyTorch CLI/workflow tests so they match the new execution-config plumbing (CONFIG-001 / POLICY-001 / DEVICE-MISMATCH-001). Avoid modifying `ptycho/model.py`, `ptycho/diffsim.py`, or `ptycho/tf_helper.py` without explicit scope.
- Latest Attempt (2025-11-14T000000Z): planning ‚Äî Created the implementation plan and Reports Hub skeleton per prompts/plan_generation.md.

---

Housekeeping: This ledger is intentionally brief. Detailed ‚ÄúAttempts History‚Äù entries were moved to archives to keep decision‚Äëmaking crisp.

- Current archive snapshot: `docs/archive/2025-11-06_fix_plan_archive.md`
- Earlier snapshots: `docs/archive/2025-10-17_fix_plan_archive.md`, `docs/archive/2025-10-20_fix_plan_archive.md`
- Artifact/plan policy (2025-11-12): Each focus keeps a single evolving plan file (see ‚ÄúWorking Plan‚Äù below). Reuse the same reports hub until you capture a new milestone; append new evidence and summaries into the existing directory instead of creating a fresh timestamp every loop.

Use the ‚ÄúWorking Plan‚Äù and the per‚Äëinitiative `summary.md` for day‚Äëto‚Äëday artifacts. Link to any bulky evidence stored externally or under `.artifacts/`.

---

## [FIX-TF-C1D-SCALED-RERUN-001] Phase‚ÄØC1d TensorFlow scaled rerun execution
- Depends on: FIX-PYTORCH-FORWARD-PARITY-001 (Phase‚ÄØC guard + regression tests merged)
- Priority: Critical
- Status: in_progress ‚Äî guard/regression code already landed (`ptycho/tf_helper.py`, `tests/tf_helper/test_translation_shape_guard.py`); executing scaled TF rerun + inventory updates now.
- Owner/Date: Ralph/2025-11-19
- Working Plan: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/implementation.md` (Phase‚ÄØC1d checklist)
- Summary: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/summary.md`
- Reports Hub: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/reports/2025-11-13T000000Z/forward_parity/`
- Do Now (next): Execute the scaled TF rerun documented in input.md ‚Äî (1) export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, `HUB=$PWD/plans/active/FIX-PYTORCH-FORWARD-PARITY-001/reports/2025-11-13T000000Z/forward_parity`, `TF_BASE="$HUB/tf_baseline/phase_c1_scaled"`, `TF_XLA_FLAGS="--tf_xla_auto_jit=0"`, and `USE_XLA_TRANSLATE=0`; run `pytest tests/tf_helper/test_translation_shape_guard.py::test_non_xla_translation_guard -vv | tee "$HUB/green/pytest_tf_translation_guard.log"` to prove the guard is still GREEN. (2) Create `$TF_BASE/{cli,analysis,green,red}` as needed and run the scaled TF training CLI with the documented dataset paths and knobs (`python scripts/training/train.py --backend tensorflow --train_data_file datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_train.npz --test_data_file ..._test.npz --output_dir "$TF_BASE/run_scaled" --n_images 64 --n_groups 32 --batch_size 4 --gridsize 2 --neighbor_count 7 --max_epochs 1 --do_stitching --quiet |& tee "$TF_BASE/cli/train_tf_phase_c1_scaled.log"`). (3) On success, copy the resulting `analysis/forward_parity_debug_tf/{stats.json,offsets.json,pngs}`, record the `stats.json` sha1, and append a ‚ÄúPhase‚ÄØC1 ‚Äî TF scaled baseline‚Äù section to `$HUB/analysis/artifact_inventory.txt` plus notes in `$HUB/summary.md`; on failure, capture a blocker under `$TF_BASE/red/blocked_<timestamp>_tf_translation_guard.md` referencing both the guard log and CLI log so reviewers have the minimal error signature.
- Return Conditions:
  - Guard selector log exists under `$HUB/green/pytest_tf_translation_guard.log` and shows the selector GREEN on the current codebase.
  - `$TF_BASE/analysis/forward_parity_debug_tf/` contains `stats.json`, `offsets.json`, and normalized PNG grids (or a new blocker exists with the failure stack trace, env capture, and guard log link).
  - `$TF_BASE/cli/train_tf_phase_c1_scaled.log` is non-empty and captures the CLI stdout/stderr (or the blocker references it explicitly if the run failed early).
  - `$HUB/analysis/artifact_inventory.txt` and `$HUB/summary.md` document the outcome (artifacts or blocker) plus env captures.
- Latest Attempt (2025-11-20T002500Z): planning ‚Äî Third-loop retrospective confirmed `git log --grep '^RALPH ' -n1` still reports commit `11fd5fc4` (2025-11-14) and no scaled TF evidence has landed since (`stat green/pytest_tf_translation_guard.log` and `stat tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log` both show Nov‚ÄØ14 timestamps; `$TF_BASE/analysis/forward_parity_debug_tf/` remains empty). Re-read docs/index.md, docs/findings.md (POLICY-001, CONFIG-001, TF-NON-XLA-SHAPE-001), docs/DEVELOPER_GUIDE.md, docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, specs/spec-ptycho-workflow.md, specs/spec-ptycho-runtime.md, and the Phase‚ÄØC1d checklist. Input.md refreshed so Ralph must re-export the env vars, rerun `pytest tests/tf_helper/test_translation_shape_guard.py::test_non_xla_translation_guard -vv | tee "$HUB/green/pytest_tf_translation_guard.log"`, then execute the scaled TensorFlow CLI with the documented dataset + scaling knobs and either publish `forward_parity_debug_tf/{stats.json,offsets.json,PNGs}` with inventory/summary updates or log `$TF_BASE/red/blocked_<ts>_tf_translation_guard.md` referencing both logs if the eval reshape bug persists. Dwell remains at Tier‚ÄØ1; no further planning allowed until implementation evidence (guard log + CLI artifacts or blocker) lands.
- Latest Attempt (2025-11-19T214500Z): planning ‚Äî Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / TF-NON-XLA-SHAPE-001), docs/DEVELOPER_GUIDE.md, docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, specs/spec-ptycho-workflow.md, specs/spec-ptycho-runtime.md, specs/data_contracts.md, specs/ptychodus_api_spec.md, the Phase‚ÄØC1d checklist in `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/implementation.md`, and the hub summary/inventory. Confirmed via `ls -l` that `$HUB/tf_baseline/phase_c1_scaled/analysis/` is still empty, `tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log` hasn‚Äôt changed since the 2025-11-14 failure (55‚ÄØKB), and `green/pytest_tf_translation_guard.log` also predates the blocker focus, so no TensorFlow evidence landed after the new Do‚ÄØNow. Updated docs/fix_plan.md, the initiative summary, and input.md so Ralph‚Äôs marching orders remain: rerun the guard selector + scaled TF CLI with the documented env exports, then either publish `forward_parity_debug_tf/{stats.json,offsets.json,pngs}` with inventory/summary updates or log `$TF_BASE/red/blocked_<timestamp>_tf_translation_guard.md` citing both logs if the reshape error persists.
- Latest Attempt (2025-11-14T155500Z): execution ‚Äî Guard selector PASSED GREEN (1/1 in 5.00s), confirming training-time non-XLA translation fallback working correctly. Scaled TF CLI training completed epoch 1 successfully (8/8 batches, loss=-2,700,843.25) but failed during eval/inference phase with identical reshape error in _translate_images_simple:199 (0-element tensor, requested shape 4). Fourth consecutive failure with same error signature. Created blocker tf_baseline/phase_c1_scaled/red/blocked_20251114T155500Z_tf_translation_guard.md documenting that guard covers training path only and does NOT exercise eval/inference batching logic where failure occurs. Updated artifact_inventory.txt Phase C1d section (Fourth Attempt) noting guard GREEN + CLI logs captured + env capture documented, but TensorFlow forward parity debug artifacts NOT generated. Refreshed summary.md with turn summary and blocker outcome. Root cause confirmed: Guard test exercises training forward path with controlled batch dimensions, but eval/inference uses different batching (test dataset 7597 images vs 32 training groups) that produces 0-element tensors during stitching. Artifacts: green/pytest_tf_translation_guard.log (GREEN, 1 passed in 5.00s), tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log (705 lines, FAILED during eval), tf_baseline/phase_c1_scaled/cli/env_capture_scaled.txt, tf_baseline/phase_c1_scaled/red/blocked_20251114T155500Z_tf_translation_guard.md, analysis/artifact_inventory.txt. Next Actions: Either (1) extend guard test to cover eval/inference path, (2) investigate eval batch shapes via instrumentation at tf_helper.py:789, or (3) defer TensorFlow parity and proceed PyTorch-only per POLICY-001 (supervisor decision after fifth consecutive failure).
- Attempt (2025-11-19T190500Z): planning ‚Äî Tier-2 dwell enforcement forced a focus split because `tf_baseline/phase_c1_scaled/analysis/` is still empty and `tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log` remains a 0-byte file even though the Do‚ÄØNow requires `pytest tests/tf_helper/test_translation_shape_guard.py::test_non_xla_translation_guard -vv | tee "$HUB/green/pytest_tf_translation_guard.log"` and the scaled TF CLI. Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / TF-NON-XLA-SHAPE-001); docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; specs/spec-ptycho-workflow.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; plans/active/FIX-PYTORCH-FORWARD-PARITY-001/{implementation.md,summary.md}; and the Reports Hub to confirm no new evidence. Minted this blocker focus so Ralph‚Äôs next turn must execute the guard selector + scaled TF CLI or emit a new blocker before we can resume the parent initiative.
- Attempt (2025-11-14T153800Z): execution ‚Äî Guard selector PASSED GREEN (1/1 in 5.03s), confirming training-time translation guard working correctly. Scaled TF CLI training completed epoch 1 successfully but failed during eval/inference phase with reshape error in _translate_images_simple:199 (0-element tensor, requested shape 4). Created blocker tf_baseline/phase_c1_scaled/red/blocked_20251114T153747_tf_translation_guard.md documenting this is the third consecutive failure with identical error signature. Updated artifact_inventory.txt Phase C1d section noting guard covers training but NOT eval path, and refreshed summary.md with blocker outcome. Root cause: Guard test exercises training forward path but eval/inference uses different batching that produces 0-element tensors. Artifacts: green/pytest_tf_translation_guard.log, tf_baseline/phase_c1_scaled/cli/train_tf_phase_c1_scaled.log (55KB), tf_baseline/phase_c1_scaled/red/blocked_20251114T153747_tf_translation_guard.md, analysis/artifact_inventory.txt, summary.md. Next Actions: Investigate eval-time batch shape mismatch or extend guard test to cover eval code path.
## [INDEPENDENT-SAMPLING-CONTROL-PHASE6] Independent sampling control ‚Äî Phase 6 guardrails
- Depends on: Phases 1‚Äì5 (subsampling plumbing + docs) already complete per `plans/active/independent-sampling-control/implementation.md`
- Priority: High (unblocks users from explicitly managing oversampling + provides hard evidence before reattempting Phase G)
- Status: done ‚Äî Phase 6A guardrails landed (explicit `enable_oversampling`/`neighbor_pool_size` plumbing, RawData gating per OVERSAMPLING-001, extended pytest coverage, and refreshed docs).
- Owner/Date: Ralph/2025-11-12 (handoff prepared by Galph)
- Working Plan: `plans/active/independent-sampling-control/implementation.md`
- Historical reports hub (Phase 6 hardening): `plans/active/independent-sampling-control/reports/2025-11-12T005637Z/phase6_hardening/` (do not create new hubs)
- Test Strategy: `plans/active/independent-sampling-control/test_tracking.md`
- Constraints: Maintain CONFIG-001 (update_legacy_dict before legacy code), OVERSAMPLING-001 (require gridsize>1 and K‚â•C), and do not regress existing sampling modes (legacy `n_images`, independent `n_subsample`+`n_groups`); avoid touching `ptycho/model.py`, `ptycho/diffsim.py`, `ptycho/tf_helper.py`.
- Notes: `RawData.generate_grouped_data` currently auto-enters oversampling when `nsamples > n_points`; Phase 6A must require an explicit opt-in flag plus pool sizing, emit actionable logs, and capture doc/examples per `docs/initiatives/independent_sampling_control/phase6_plan.md` and `docs/SAMPLING_USER_GUIDE.md`.

- Latest Attempt (2025-11-12T011535Z): review_or_housekeeping ‚Äî Re-read docs/index.md; docs/findings.md (OVERSAMPLING-001, CONFIG-001, DATA-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/TESTING_GUIDE.md (oversampling coverage); docs/COMMANDS_REFERENCE.md; docs/SAMPLING_USER_GUIDE.md; docs/fix_plan.md; input.md; `plans/active/independent-sampling-control/implementation.md`; `test_tracking.md`; and the Phase 6 hub (`summary.md`, `green/pytest_enable_flag.log`, `green/pytest_neighbor_pool_size_guard.log`). Verified commit `7e99cebc` adds the enable_oversampling/neighbor_pool_size config fields, RawData gating, CLI plumbing, extended pytest suite, and doc updates. Marked the checklist complete in the plan, prepended the hub summary with the Turn Summary, and freed this focus so the active Do Now can return to the Phase G dense rerun blocker. No further actions required unless Phase 6B scope appears.

---

## [STUDY-SYNTH-FLY64-DOSE-OVERLAP-001] Synthetic fly64 dose/overlap study
- Depends on: FIX-COMPARE-MODELS-TRANSLATION-001 (‚úÖ complete), Baseline inference center/diagnostics (‚úÖ via `BASELINE-OFFSET-001`), counted dense rerun (üöß)
- Priority: High
- Status: superseded ‚Äî see the blocked_escalation entry at the top of this ledger for the current status; the details below are retained for archival context about the earlier ready_for_implementation state.
- Latest Attempt (2025-11-16T153500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / BASELINE-OFFSET-001 / BASELINE-CHUNKED-001 / BASELINE-CHUNKED-002 / TEST-CLI-001 / PREVIEW-PHASE-001 / METRICS-NAMING-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; docs/GRIDSIZE_N_GROUPS_GUIDE.md; specs/data_contracts.md; specs/overlap_metrics.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/{summary.md,analysis/metrics_summary.json,analysis/dose_1000/dense/test/comparison_metrics.csv,analysis/verification_report.json,analysis/dose_1000/dense/test_debug_v2/logs/logs/debug.log,cli/aggregate_report_cli.log,cli/run_phase_g_dense_post_verify_only.log}; verified the Phase‚ÄØC/E/F assets via `ls -lh` (patched_{train,test}.npz, dense/gs2 and baseline/gs1 wts.h5.zip, phase_f/dense/test/ptychi_reconstruction.npz). Reality: `analysis/verification_report.json:1-80` still reports `n_valid=0/10`, dense-test Baseline rows remain blank (`analysis/metrics_summary.json:48-70`, `analysis/dose_1000/dense/test/comparison_metrics.csv:2-13`), the metrics reporter fails with ‚ÄúRequired models missing: Baseline‚Äù (`cli/aggregate_report_cli.log:6-10`), the post-verify helper still aborts under PREVIEW-PHASE-001 because `analysis/metrics_delta_highlights_preview.txt` never existed (`cli/run_phase_g_dense_post_verify_only.log:1-22`), and the chunked debug log never progressed beyond chunk‚ÄØ21/33 (`analysis/dose_1000/dense/test_debug_v2/logs/logs/debug.log:1299`), so no new evidence landed after the chunked refactor. Keeping the Phase‚ÄØC/E/F assets confirmed means the Do‚ÄØNow stays ready_for_implementation: guard the hub with those checks, rerun the translation selector, rerun the chunked debug + full compare_models commands with the new chunk/batch flags, then immediately run the Phase‚ÄØD selectors, clobbered `run_phase_g_dense.py`, metrics helpers, and fully parameterized `--post-verify-only`, logging `$HUB/red/blocked_<timestamp>.md` whenever Baseline stats or PREVIEW artifacts are still missing.
- Latest Attempt (2025-11-16T123500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / BASELINE-OFFSET-001 / BASELINE-CHUNKED-001 / BASELINE-CHUNKED-002 / TEST-CLI-001 / PREVIEW-PHASE-001 / METRICS-NAMING-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub artifacts (`green/pytest_compare_models_translation_fix_v18.log`, `red/blocked_20251113T235013Z_missing_hub_data.md`, `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/dose_1000/dense/test_debug_v2/logs/logs/debug.log`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, `cli/run_phase_g_dense_post_verify_only.log`) plus the hub data tree (`data/phase_c/dose_1000/patched_{train,test}.npz`, `data/phase_e/dose_1000/{dense/gs2,baseline/gs1}/wts.h5.zip`, `data/phase_f/dose_1000/dense/test/ptychi_reconstruction.npz`). Reality: those files exist, so the red blocker was a false alarm and Baseline metrics are still blank. Updated the plan/summary/input/galph_memory so Step‚ÄØ1 now exports HUB/AUTHORITATIVE_CMDS_DOC and runs `ls -lh` against those paths before the translation pytest ‚Üí chunked compare_models ‚Üí Phase‚ÄØD selectors ‚Üí counted pipeline ‚Üí metrics/post-verify sequence, with `$HUB/red/blocked_<timestamp>.md` still required if Baseline rows or PREVIEW artifacts remain missing.
- Latest Attempt (2025-11-16T103500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / BASELINE-OFFSET-001 / BASELINE-CHUNKED-001 / BASELINE-CHUNKED-002 / TEST-CLI-001 / PREVIEW-PHASE-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub artifacts (`green/pytest_compare_models_translation_fix_v17.log`, `analysis/dose_1000/dense/test_debug_v2/logs/logs/debug.log`, `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, `cli/run_phase_g_dense_post_verify_only.log`). Reality: commit `451fdd82` prevents the pre-chunked OOM but the new chunked debug run never finished (log stops at chunk 21/33) and the canonical dense-test CSV/summary remain blank for Baseline, so the aggregate metrics helper and post-verify sweep still fail immediately and verification is 0/10. Updated this ledger, the plan, summary, galph_memory.md, and input.md so Ralph now executes the chunked debug + full train/test commands with the documented chunk sizes, then immediately resumes the Phase‚ÄØD selectors ‚Üí counted `run_phase_g_dense.py --clobber` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only`, filing `$HUB/red/blocked_<timestamp>.md` if Baseline stats regress or the SSIM/preview bundle is still missing.
- Latest Attempt (2025-11-16T073500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary plus `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/dose_1000/dense/train/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, `cli/run_phase_g_dense_post_verify_only.log`, and `analysis/dose_1000/dense/test_debug/logs/logs/debug.log`. Reality: the chunked debug runs remain healthy (non-zero DIAGNOSTIC stats) and dense-train CSVs have Baseline rows, but the canonical dense-test CSV/metrics summary are still blank so aggregate_report/post-verify stay red and verification is 0/10. Updated this ledger, the plan, summary, and input.md so Ralph reruns the translation selector ‚Üí chunked debug/full compare_models (stop + `$HUB/red/` if Baseline stats regress) ‚Üí Phase‚ÄØD selectors ‚Üí clobbered `run_phase_g_dense.py` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only` until `{analysis}` contains the SSIM/verification/highlights/preview/inventory bundle or a blocker documents the failing command/signature.
- Latest Attempt (2025-11-16T050500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary plus `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, and `cli/run_phase_g_dense_post_verify_only.log`. Reality: only the debug-limited chunked runs landed‚Äîdense-train metrics now include Baseline rows, but dense-test CSV/metrics summary remain blank so the aggregate metrics helper and `--post-verify-only` chain still fail and verification stays 0/10. Updated this ledger, the plan, summary, and input.md so Ralph now reruns the translation guard ‚Üí chunked debug/full compare_models (with the documented chunk/batch sizes, stopping to file `$HUB/red/` blockers if Baseline stats regress) ‚Üí Phase‚ÄØD selectors ‚Üí clobbered `run_phase_g_dense.py` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only` until `{analysis}` holds the SSIM/verification/highlights/preview/inventory bundle or a blocker is logged with the exact command/error.
- Latest Attempt (2025-11-16T010000Z): implementation ‚Äî Added chunked Baseline inference (`scripts/compare_models.py` commit `26c26402`) with `--baseline-chunk-size`/`--baseline-predict-batch-size`, per-chunk DIAGNOSTIC logging, and automatic fallback (`docs/findings.md:BASELINE-CHUNKED-001`). Translation regression selectors stayed green (`plans/active/.../green/pytest_compare_models_translation_fix_v15.log`). However, the new chunked path has not been executed from this repo yet, so `analysis/dose_1000/dense/test/comparison_metrics.csv` and `analysis/metrics_summary.json` are still missing Baseline rows and the Phase‚ÄØG bundle remains absent.
- Latest Attempt (2025-11-16T031500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary + blocker file. Reality: commits landed chunked inference but the hub still reflects the pre-chunked compare_models runs (Baseline rows blank, verification 0/10). Updated this ledger, the plan, and `input.md` so Ralph now focuses on (1) rerunning the translation guard and debug/full compare_models commands with `--baseline-chunk-size 256 --baseline-predict-batch-size 16`, (2) verifying the Baseline metrics + DIAGNOSTIC lines exist for both splits before touching Phase‚ÄØD, and (3) running the dense acceptance selectors, counted `run_phase_g_dense.py --clobber`, metrics reporters, and fully parameterized `--post-verify-only` until `{analysis}` holds the SSIM/verification/highlights/preview/inventory bundle with `verification_report.json` at 10/10; blockers go under `$HUB/red/`.
- Latest Attempt (2025-11-15T200500Z): planning ‚Äî Dense-test compare_models still halts with `DIAGNOSTIC baseline_output stats: mean=0.000000 ... nonzero_count=0/341835776` while dense-train records non-zero outputs (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/{test,train}/logs/logs/debug.log:534-550`), so `analysis/metrics_summary.json` and `analysis/dose_1000/dense/test/comparison_metrics.csv` remain Baseline-empty, `report_phase_g_dense_metrics.py` keeps failing (`.../cli/aggregate_report_cli.log:1-11`), and the post-verify helper immediately aborts because `analysis/metrics_delta_highlights_preview.txt` never existed (`.../cli/run_phase_g_dense_post_verify_only.log:1-23`). A targeted `n_images=64` container probe showed flattened `baseline_offsets` for dense-test shifted to ‚âà273‚ÄØ¬±‚ÄØ86‚ÄØpx versus ‚âà185‚ÄØ¬±‚ÄØ72‚ÄØpx for dense-train (`.../data/phase_c/dose_1000/patched_{train,test}.npz`), so the refreshed Do‚ÄØNow forces offset-centering + debug flags in `scripts/compare_models.py`, reruns dense-train/dense-test compare_models until canonical Baseline rows appear in CSV/JSON, then repeats the Phase‚ÄØD guard, counted `run_phase_g_dense.py --clobber`, metrics helpers, and fully parameterized `--post-verify-only` before updating the ledger. Blockers must be captured under `$HUB/red/blocked_<timestamp>.md` with the command/error signature if Baseline stats regress or preview/verifier artifacts remain missing.
- Latest Attempt (2025-11-13T200447Z): implementation ‚Äî Instrumented scripts/compare_models.py (commit e830a5be) with RuntimeError assertion that halts when Baseline outputs are zero, plus canonical model ID mapping (`PtyChi` not `"Pty-chi (algorithm)"`). Translation guard GREEN (2/2 passed, 6.21s). Train split succeeds: Baseline input mean=0.112964 ‚Üí output mean=0.003092 (1.4M nonzero), CSV contains `Baseline` and `PtyChi` canonical IDs with valid metrics. Test split fails: Baseline input mean=0.112671 (17.8M nonzero) ‚Üí output mean=0.0 (0 nonzero), triggering RuntimeError with diagnostic stats. Blocker filed (`red/blocked_20251113T200447Z_baseline_test_zero_instrumented.md`) confirming TensorFlow/model runtime issue beyond compare_models.py scope. Status: **blocked** pending decision on Baseline model investigation vs proceeding with PINN vs PtyChi only.
- Latest Attempt (2025-11-15T123000Z): planning ‚Äî Dense-train compare_models logs confirm Baseline outputs are non-zero (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/train/logs/logs/debug.log:425-537`) while dense-test still returns zero-valued predictions despite healthy inputs (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/test/logs/logs/debug.log:426-540`), so `analysis/metrics_summary.json` and `analysis/dose_1000/dense/test/comparison_metrics.csv` remain Baseline-empty and the metrics helper + preview keep failing (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/aggregate_report_cli.log:1-9`, `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/run_phase_g_dense_post_verify_only.log:1-19`). Updated the plan/summary/docs/input so Ralph must add a fast Baseline-debug loop (instrument `scripts/compare_models.py`, optionally add `--baseline-debug-limit`, log the first patch amplitude/phase), stop with `$HUB/red/blocked_<timestamp>.md` if `DIAGNOSTIC baseline_output` stays zero, and only proceed to the Phase‚ÄØD/Phase‚ÄØG rerun once `analysis/dose_1000/dense/{split}/comparison_metrics.csv` and `analysis/metrics_summary.json` contain canonical Baseline/PtyChi rows.
- Latest Attempt (2025-11-15T041500Z): planning ‚Äî Dense-test compare_models logs still report non-zero inputs but zero outputs (mean=0.112671 in, mean=0.0 out at `analysis/dose_1000/dense/test/logs/logs/debug.log:421-535`), so `analysis/metrics_summary.json` keeps blank Baseline rows, `analysis/dose_1000/dense/test/comparison_metrics.csv` lists empty Baseline metrics, `cli/aggregate_report_cli.log:1-11` fails with ‚ÄúRequired models missing for delta computation: Baseline‚Äù, and `cli/run_phase_g_dense_post_verify_only.log:4-23` continues to abort because the preview file is missing. Updated the plan/summary/input so Ralph must instrument `scripts/compare_models.py` with tf.debugging asserts + canonical IDs, stop immediately with `$HUB/red/blocked_<timestamp>.md` if Baseline remains zero, verify the CSV/JSON Baseline metrics before rerunning `report_phase_g_dense_metrics.py`, and only invoke the SSIM/verification helper after `analysis/metrics_delta_highlights_preview.txt` exists.
- Latest Attempt (2025-11-15T010500Z): planning ‚Äî Audited `analysis/verification_report.json:1-80` (still `n_valid=0/10`), `analysis/dose_1000/dense/test/logs/logs/debug.log:312-535` (Baseline inputs non-zero but outputs mean/max/nonzero=0), `analysis/metrics_summary.json` (Baseline rows empty and `Pty-chi (pty-chi)` alias), `cli/aggregate_report_cli.log:1-9` (metrics reporter fails) and `cli/run_phase_g_dense_post_verify_only.log:1-15` (preview missing). Updated plan/summary/docs/input so the Do‚ÄØNow now enforces the translation guard ‚Üí compare_models diagnostics with stop-on-zero Baseline outputs ‚Üí Phase‚ÄØD acceptance selectors ‚Üí counted `run_phase_g_dense.py --clobber` ‚Üí metrics reporters with canonical-ID verification ‚Üí `run_phase_g_dense.py --post-verify-only`, with blockers logged under `$HUB/red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-13T193000Z): verification ‚Äî Translation regression tests remain GREEN (green/pytest_compare_models_translation_fix_v8.log: 2/2 PASSED, 6.22s). Confirmed diagnostic logging from previous loop successfully captures the issue: Baseline **inputs** are valid for both splits (mean~0.112, nonzero>17M), train split produces valid **outputs** (mean=0.003092, nonzero=1.4M), but test split outputs **all zeros** (mean=0.0, nonzero=0). Updated blocker doc confirming this is a TensorFlow/model runtime issue beyond compare_models.py instrumentation scope. No code changes made this loop (diagnostic-only verification). Status remains **blocked** pending baseline model numerical stability investigation.
- Latest Attempt (2025-11-14T235900Z): planning ‚Äî Baseline dense-test reconstructions remain all zeros (`analysis/dose_1000/dense/test/reconstructions_aligned.npz` + `analysis/dose_1000/dense/test/reconstructions.npz`), so `analysis/metrics_summary.json` never records `Baseline` rows and `report_phase_g_dense_metrics.py` still fails with ‚ÄúRequired models missing‚Äù (`cli/aggregate_report_cli.log`). `run_phase_g_dense.py --post-verify-only` also dies immediately because `analysis/metrics_delta_highlights_preview.txt` was never emitted (`cli/run_phase_g_dense_post_verify_only.log` ‚Üî `cli/ssim_grid_cli.log`), keeping `analysis/verification_report.json` stuck at 0/10. Added plan_update‚ÄØv1.7 plus summary/input updates so Ralph must instrument/fix `scripts/compare_models.py` (log + guard Baseline stats) before rerunning both compare_models splits; after that he still has to rerun the Phase‚ÄØD guards, execute `run_phase_g_dense.py --clobber`, regenerate the metrics/digest/preview bundle, and only then rerun the fully parameterized `--post-verify-only` until SSIM/verification/highlights/metrics/preview/artifact-inventory artifacts exist and `verification_report.json` reports 10/10 (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md`).
- Latest Attempt (2025-11-14T021842Z): planning ‚Äî Hub audit shows the counted rerun is still incomplete: `analysis/verification_report.json` reports `n_valid=0/10` and still lists `metrics_summary.*` as missing (lines 1‚Äë19), the actual `analysis/metrics_summary.json` contains only PtychoPINN rows plus a `‚ÄúPty-chi (pty-chi)‚Äù` alias while every Baseline metric field is empty (lines 48‚Äë105), `analysis/dose_1000/dense/test/logs/logs/debug.log` proves the dense **test** Baseline recon is all zeros (lines 600‚Äë609) so `analysis/dose_1000/dense/test/comparison_metrics.csv` keeps blank Baseline rows (lines 8‚Äë18), `report_phase_g_dense_metrics.py` therefore fails with ‚ÄúRequired models missing for delta computation: Baseline, PtyChi‚Äù (cli/aggregate_report_cli.log lines 1‚Äë11), and `run_phase_g_dense_post_verify_only.log` still dies under PREVIEW-PHASE-001 because `analysis/metrics_delta_highlights_preview.txt` never materialized (lines 12‚Äë23). Updated the plan/summary/input so Ralph must guard `/home/ollie/Documents/PtychoPINN`, rerun the translation pytest selector, regenerate both the train and test compare_models bundles with canonical model IDs per METRICS-NAMING-001 (filing `$HUB/red/blocked_<timestamp>.md` if Baseline amplitudes remain zero), rerun the Phase‚ÄØD acceptance pytest guards, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately replay `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py` so the metrics summary/digest/preview/artifact inventory exist, and only then run the fully parameterized `--post-verify-only` so `{analysis}` can finally collect the SSIM grid, verification logs, highlights, metrics, preview, and artifact inventory bundle required for `verification_report.json` to reach 10/10.
- Latest Attempt (2025-11-14T173500Z): planning ‚Äî Verified the translation evidence (`green/pytest_compare_models_translation_fix_v2.log`, `cli/phase_g_dense_translation_fix_{train,test}_v2.log`, `analysis/verification_report_translation_fix.json`) and audited the Phase‚ÄØG hub (`analysis/verification_report.json` still 0/10; `analysis/blocker.log` records `report_phase_g_dense_metrics.py` failing because Baseline/PtyChi deltas are missing). Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}`, this ledger, and input.md so Ralph now (1) reruns `run_phase_g_dense.py --clobber --dose 1000 --view dense --splits train test`, (2) immediately executes the fully parameterized `--post-verify-only`, (3) replays `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py`, and (4) only stops once `{analysis}` contains the SSIM grid/verification/highlights/metrics/preview/inventory bundle with 10/10 validity (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md`).
- Latest Attempt (2025-11-14T223000Z): planning ‚Äî Rechecked `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/verification_report.json` (still `n_valid=0/10`), saw `analysis/metrics_summary.json` only contains new PtychoPINN vs PtyChi rows while all Baseline metric entries are empty, and `analysis/blocker.log` plus `cli/ssim_grid_cli.log` prove `bin/ssim_grid.py` dies immediately because `analysis/metrics_delta_highlights_preview.txt` never existed (PREVIEW-PHASE-001). Do‚ÄØNow remains ready_for_implementation: guard `/home/ollie/Documents/PtychoPINN`, rerun the guarded pytest selector, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately run the fully parameterized `--post-verify-only`, rerun `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py` so SSIM/verification/highlights/metrics/preview/inventory artifacts exist, and drop `$HUB/red/blocked_<timestamp>.md` with command/error signatures if anything still fails before `verification_report.json` reaches 10/10.
- Latest Attempt (2025-11-14T150800Z): planning ‚Äî Dwell hit Tier 2 and no new Ralph commit appeared, so we audited the hub, confirmed the `Translation` ValueError is still the blocking failure mode, and spun out FIX-COMPARE-MODELS-TRANSLATION-001 to own the implementation work. Return condition: once that focus delivers batched `ReassemblePatchesLayer` + GREEN regression/tests + successful `scripts/compare_models.py` executions for train/test, flip this item back to `ready_for_implementation` and resume the counted rerun (`run_phase_g_dense.py --clobber`, `--post-verify-only`, metrics/helpers per ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001).
- Latest Attempt (2025-11-14T152000Z): housekeeping ‚Äî Verified FIX-COMPARE-MODELS-TRANSLATION-001 is complete with all exit criteria met: commits a80d4d2b + bf3f1b07 in repo, pytest selector GREEN (plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/green/pytest_compare_models_translation_fix_v2.log shows 2/2 PASSED), train/test compare_models exit 0 with refreshed metrics (verification_report_translation_fix.json shows 10/10), blocker_resolved.log documents resolution. Updated STUDY-SYNTH status from blocked to ready_for_implementation. Next: execute counted Phase G rerun per return condition above.



---

## [FIX-COMPARE-MODELS-TRANSLATION-001] Dense Phase G translation guard
- Depends on: STUDY-SYNTH-FLY64-DOSE-OVERLAP-001 (unblocked)
- Priority: Critical (Tier 2 mitigation)
- Status: done ‚Äî All exit criteria met. Batched reassembly (a80d4d2b) + XLA streaming (bf3f1b07) verified. Regression tests GREEN (2/2 in 6.12s), train/test compare_models exit 0 with refreshed metrics. Verification report 10/10 valid. STUDY-SYNTH unblocked for counted Phase G rerun.
- Owner/Date: Ralph / 2025-11-13 (completed)
- Working Plan: `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/implementation.md`
- Summary: `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/summary.md`
- Reports Hub: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/`
- Exit criteria (‚úÖ ALL MET): (a) both regression tests GREEN (pytest_compare_models_translation_fix_v2.log: 2/2 PASSED in 6.12s); (b) train/test `scripts/compare_models.py` exit 0 with refreshed metrics (train: MS-SSIM phase=0.054 MAE=0.234; test: MS-SSIM phase=0.048 MAE=0.242); (c) `analysis/blocker_resolved.log` documents resolution and `verification_report_translation_fix.json` shows 10/10; (d) padded-size/batching instrumentation logged in ptycho/tf_helper.py:955-965 with tf.debugging assertions; (e) STUDY-SYNTH focus updated to ready_for_implementation.
- Latest Attempt (2025-11-14T173500Z): review_or_housekeeping ‚Äî Re-read `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md}`, `green/pytest_compare_models_translation_fix_v2.log`, `cli/phase_g_dense_translation_fix_{train,test}_v2.log`, and `analysis/verification_report_translation_fix.json`, confirmed all exit criteria remain satisfied, and refreshed this ledger so STUDY-SYNTH is the active focus for the counted Phase‚ÄØG rerun.
- Latest Attempt (2025-11-13T170500Z): implementation (COMPLETE) ‚Äî Verified the two fixes (a80d4d2b batched reassembly, bf3f1b07 XLA streaming) with fresh evidence: pytest selector GREEN (2/2 passed, 6.12s), train split compare_models exit 0 (MS-SSIM phase=0.054, MAE phase=0.234), test split compare_models exit 0 (MS-SSIM phase=0.048, MAE phase=0.242). Created `analysis/verification_report_translation_fix.json` (10/10) and `analysis/blocker_resolved.log`. Exit criteria met: regression tests GREEN, both CLI runs successful with refreshed metrics, blocker cleared. Prepended Turn Summary to initiative summary. Status: done.
- Latest Attempt (2025-11-14T005300Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001 / TYPE-PATH-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/GRIDSIZE_N_GROUPS_GUIDE.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md,reports/pytest_translation_fix.log}; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/verification_report.json,analysis/blocker.log,cli/phase_g_dense_translation_fix_train.log}; input.md; galph_memory.md. Reality check: no new Ralph evidence since Nov‚ÄØ13 ‚Äî the pytest log still dies at `ptycho/tf_helper.py:959`, `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log` have not been rerun, and `analysis/verification_report.json` remains `n_valid=0`. Updated the plan (plan_update v1.5), ledger, and input so Ralph must add a patch-count gate + tf.print diagnostics in `ReassemblePatchesLayer` and `_reassemble_position_batched` before repeating the CLI/tests, keeping all evidence in the existing hub. Status: ready_for_implementation (dwell=4; next loop must drive production work or escalate per Tier‚ÄØ2).
- Latest Attempt (2025-11-14T153500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/GRIDSIZE_N_GROUPS_GUIDE.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md,reports/pytest_translation_fix.log}; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{summary.md,implementation.md}; hub artifacts (`analysis/verification_report.json`, `analysis/blocker.log`, `cli/phase_g_dense_translation_fix_{train,test}.log`). Reality: pytest still dies at `_reassemble_position_batched`, and the train/test compare_models logs never progressed past argument parsing because the command used the unsupported `--split` flag, so no new evidence was captured. Updated the plan + Do Now to remove `--split`, reiterate the batching instrumentation (single `tf.image.resize_with_crop_or_pad`, padded_size logging, `tf.debugging.assert_equal` guards), and restated the required pytest selector + CLI reruns with blocker logging expectations. Status: ready_for_implementation (dwell=3, next loop must be implementation).
- Latest Attempt (2025-11-14T123500Z): planning ‚Äî Re-read docs/index.md, docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/DEVELOPER_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/overlap_metrics.md, specs/data_contracts.md, the initiative plan/summary, `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/reports/pytest_translation_fix.log`, and the hub evidence (`analysis/verification_report.json`, `analysis/dose_1000/dense/train/logs/logs/debug.log`, `cli/phase_g_dense_translation_fix_train.log`). Reality check: pytest still dies at `ptycho/tf_helper.py:959` ("{{__wrapped__AddV2}} required broadcastable shapes"), `{analysis}` still lacks SSIM/metrics bundles (`n_valid=0`), and no new CLI logs were produced since 2025-11-13. Updated the plan + Do Now so Ralph instruments `_reassemble_position_batched` (log padded_size, assert `tf.shape(canvas)==tf.shape(batch_result)`/dtype), replaces the per-element `tf.image.resize_with_crop_or_pad` with a batched call, and captures those diagnostics in the pytest log plus renewed train/test CLI runs. Status: ready_for_implementation.
- Latest Attempt (2025-11-14T150800Z): planning ‚Äî Tier 2 dwell enforcement created this focus. Drafted the Do Now: reproduce the failure via direct `scripts/compare_models.py` runs for train/test, update `ptycho/custom_layers.ReassemblePatchesLayer` (and helpers in `ptycho/tf_helper.py` as needed) to call the batched reassembly path, add a regression test that feeds a synthetic ‚â•5 k-patch tensor through the layer, and rerun the targeted CLI commands plus the guarded pytest selectors with logs under `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log` and `$HUB/green/pytest_compare_models_translation_fix.log`.
- Latest Attempt (2025-11-13T174400Z): planning ‚Äî Re-read docs/index.md, docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, docs/DEVELOPER_GUIDE.md, docs/architecture.md, docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001), docs/GRIDSIZE_N_GROUPS_GUIDE.md, specs/data_contracts.md, specs/ptychodus_api_spec.md, specs/overlap_metrics.md, and the initiative plan/summary. Reviewed `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/reports/pytest_translation_fix.log`, which shows `tests/study/test_dose_overlap_comparison.py::test_pinn_reconstruction_reassembles_full_train_split` still failing with `InvalidArgumentError: required broadcastable shapes` inside `_reassemble_position_batched` (B=159, N=138, C=4) while `test_pinn_reconstruction_reassembles_batched_predictions` remains GREEN. Updated the plan checklist (regression test already exists), refreshed input.md, and logged the blocker so Ralph can focus on hardening `ReassemblePatchesLayer`/`tf_helper`, re-running the guarded pytest selector, and capturing the train/test CLI evidence under `$HUB/cli/phase_g_dense_translation_fix_{split}.log`. Status: ready_for_implementation.
- Latest Attempt (2025-11-13T180500Z): maintenance ‚Äî Reverted commits `da91e466` / `087a9238` to undo the unintended `_reassemble_position_batched` semantics that broke TF integration. Updated the plan + guardrails so future batching work must call the existing helper (no modifications to `reassemble_patches` / `_flat_to_channel`), log crop events, and re-establish regression evidence (pytest selector + compare_models train/test logs) before reconnecting to STUDY-SYNTH. Status: ready_for_implementation (Do‚ÄØNow reset).
- Do Now:
  1. `export AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB="$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier"`
  2. Reproduce the failure with `PYTHONPATH="$PWD" python scripts/compare_models.py --pinn_dir "$HUB"/data/phase_e/dose_1000/dense/gs2 --baseline_dir "$HUB"/data/phase_e/dose_1000/baseline/gs1 --test_data "$HUB"/data/phase_c/dose_1000/patched_train.npz --output_dir "$HUB"/analysis/dose_1000/dense/train --ms-ssim-sigma 1.0 --tike_recon_path "$HUB"/data/phase_f/dose_1000/dense/train/ptychi_reconstruction.npz --register-ptychi-only --split train` (repeat for `--split test` and adjust `--output_dir`). Capture minimal error snippet in `$HUB/red/blocked_<timestamp>.md` if it still fails.
  3. Patch `ptycho/custom_layers.ReassemblePatchesLayer` so it calls `hh.mk_reassemble_position_batched_real` with a clearly documented batch-size guard (`total_patches > batch_size`). Do **not** touch `reassemble_patches`/`_flat_to_channel`; add an assertion/log so we know when the batched path engages.
  4. Enhance `_reassemble_position_batched` to derive `padded_size` from the kwarg or `params.get_padded_size()`, replace the per-element `tf.map_fn` resize with a single `tf.image.resize_with_crop_or_pad(batch_translated, padded_size, padded_size)` call, and emit shape/dtype diagnostics plus `tf.debugging.assert_equal(tf.shape(canvas), tf.shape(batch_result))` before `canvas + batch_result`. Log whenever a resize would crop translated data (counts + padded_size) so future runs are auditable.
  5. Extend `tests/study/test_dose_overlap_comparison.py` so the ‚â•5 k-patch regression asserts overlap/intensity conservation, then run `pytest tests/study/test_dose_overlap_comparison.py::{test_pinn_reconstruction_reassembles_batched_predictions,test_pinn_reconstruction_reassembles_full_train_split} -vv | tee "$HUB"/green/pytest_compare_models_translation_fix.log`.
  6. Re-run the train/test `scripts/compare_models.py` commands (same args as step‚ÄØ2, adjusting `--split`/`--output_dir`) and capture logs under `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log`. Success criteria: exit‚ÄØ0, refreshed `analysis/dose_1000/dense/{train,test}/comparison_metrics.csv`, and the new shape instrumentation in the logs.
  7. Update `analysis/blocker.log`, `{analysis}/verification_report.json`, docs/fix_plan.md, `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{summary.md,implementation.md}`, and galph_memory with MS-SSIM/MAE deltas + selector/command references before handing the hub back to STUDY-SYNTH.


- Latest Attempt (2025-11-12T004400Z): implementation (PARTIAL ‚Äî pipeline running) ‚Äî Confirmed `filter_dataset_by_mask` fix already in place (`studies/fly64_dose_overlap/overlap.py:225` checks `arr.ndim == 0` and broadcasts scalar metadata). Ran `test_filter_dataset_by_mask_handles_scalar_metadata` (PASSED 1.38s, saved to `$HUB/green/pytest_filter_dataset_by_mask.log`). Launched Phase C‚ÜíG dense pipeline with `PYTHONPATH=/home/ollie/Documents/PtychoPINN` to fix import path issue (background PID 5f48f9, started 2025-11-12T00:43:56Z). Pipeline archived stale Phase C outputs and is currently executing Phase C (Dataset Generation) with TensorFlow/CUDA initialized. Estimated completion: 30‚Äì120 minutes. Remaining steps: await pipeline completion, execute `--post-verify-only` chain, regenerate metrics helpers if needed, and verify `{analysis}` contains complete SSIM/verification/highlights/metrics/inventory bundle with MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas. Status: in_progress (long-running task). Artifacts: `$HUB/green/pytest_filter_dataset_by_mask.log` (‚úÖ), `$HUB/cli/run_phase_g_dense_stdout.log` (streaming), `$HUB/summary/summary.md` (‚úÖ).
- Attempt (2025-11-13T022400Z): planning ‚Äî `git status --porcelain` was clean, so I ran `timeout 30 git pull --rebase` (already up to date) and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/overlap_metrics.md, specs/data_contracts.md ¬ß12, docs/GRIDSIZE_N_GROUPS_GUIDE.md, the initiative plan, galph_memory.md, input.md, and the active Phase D/Phase G hub summaries + plans + `analysis/blocker.log` + `cli/phase_d_dense.log`. Reality check: the Phase D overlap metrics hub already contains gs1/gs2 CLI evidence (`summary/summary.md`, `analysis/artifact_inventory.txt`), so that checklist is complete, but the latest dense rerun fails immediately with `TypeError: len() of unsized object` at `studies/fly64_dose_overlap/overlap.py:194` because `filter_dataset_by_mask` applies a boolean mask to scalar metadata fields. Updated the implementation plan, hub plan/summaries, docs/fix_plan.md, and input.md so the ready_for_implementation Do Now now requires (1) hardening `filter_dataset_by_mask` to bypass scalars/zero-d arrays plus a regression in `tests/study/test_dose_overlap_overlap.py`, (2) rerunning the dense acceptance selector alongside the new regression, (3) executing `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `--post-verify-only`, and (4) rerunning the metrics helpers so `{analysis}` holds `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, `preview.txt`, and `analysis/artifact_inventory.txt` with MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas logged. Failures still belong under `$HUB/red/blocked_<timestamp>.md`.

<plan_update version="1.0">
  <trigger>Housekeeping: enforce interpreter discipline and reduce Phase C runtime</trigger>
  <focus_id>STUDY-SYNTH-FLY64-DOSE-OVERLAP-001</focus_id>
  <documents_read>docs/index.md, docs/DEVELOPER_GUIDE.md, CLAUDE.md, input.md, scripts/orchestration/README.md, plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md, plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py, studies/fly64_dose_overlap/generation.py</documents_read>
  <current_plan_path>plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md</current_plan_path>
  <proposed_changes>Adopt PYTHON-ENV-001 across orchestrators/wrappers/docs; add --dose/--doses to Phase C generator and pass dose from orchestrator; update Do Now accordingly</proposed_changes>
  <impacts>Eliminates ModuleNotFoundError via active interpreter; reduces Phase C time by filtering to a single dose; requires rerun of dense pipeline and light doc/test adjustments</impacts>
  <ledger_updates>Record commit 811f4264 as policy adoption; mark env blocker resolved; set Do Now to implement generator dose filter then execute single-dose run</ledger_updates>
  <status>approved</status>
</plan_update>

‚Ä¢ Spec Update (2025-11-12): Adopt overlap‚Äëdriven metrics and explicit sampling controls for Phase D; deprecate dense/sparse labels and spacing/packing gates.
  - New spec: specs/overlap_metrics.md (Metric 1 group‚Äëbased gs=2 only; Metric 2 image‚Äëbased global; Metric 3 group‚Üîgroup COM; disc overlap; probe_diameter_px; s_img/n_groups; neighbor_count default 6).
  - Docs updated: docs/index.md (Spec link), docs/GRIDSIZE_N_GROUPS_GUIDE.md (inter‚Äëgroup control via s_img/n_groups; dense/sparse deprecated).
  - Plan/test/constraints revised: plans/active/.../implementation.md Phase D section updated (SPEC ADOPTED); test_strategy now targets the three metrics; constraint_analysis reflects policy.
- Implementation is deferred to a future attempt; no code changed in this loop.
  - Do Now: Implement Phase D overlap metrics and tests per specs/overlap_metrics.md; remove spacing gates and dense/sparse labels; pause Phase G reruns until GREEN tests and metrics bundles exist.

- Latest Attempt (2025-11-12T000700Z): planning ‚Äî `git status -sb` was clean; `timeout 30 git pull --rebase` failed with ‚ÄúCannot rebase onto multiple branches,‚Äù so reran `timeout 30 git pull --rebase origin feature/torchapi-newprompt` (already up to date). Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / OVERSAMPLING-001 / ACCEPTANCE-001), specs/overlap_metrics.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, the Phase D hub plan/summary/artifact inventory, `studies/fly64_dose_overlap/overlap.py`, `tests/study/test_dose_overlap_overlap.py`, and `$HUB/green/pytest_phase_d_overlap.log`. Reality: commit `d94f24f7` already delivers Metric 1/2/3 + CLI support (18/18 tests pass), but the Phase D hub still has no CLI logs or metrics JSON (`cli/` and `metrics/` are empty). Updated `implementation.md` and the hub plan with new `<plan_update>` blocks, marked the API/CLI/test checklist items complete, and re-scoped the Do Now so Ralph must rerun the pytest selector, execute the overlap CLI twice (gs1 `s_img=1.0,n_groups=512`, gs2 `s_img=0.8,n_groups=512`) against `data/phase_c/dose_1000`, and archive `train_metrics.json`, `test_metrics.json`, `metrics_bundle.json`, and CLI stdout/err under `$HUB`. Rewrote `input.md` accordingly.
- Latest Attempt (2025-11-13T012900Z): planning ‚Äî `git status --porcelain` listed the deleted `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/data/phase_c/run_manifest.json`, so I stashed those evidence files, ran `timeout 30 git pull --rebase`, then popped the stash before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / OVERSAMPLING-001 / ACCEPTANCE-001), specs/overlap_metrics.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, specs/data_contracts.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, the initiative plan, test_strategy, constraint_analysis, input.md, galph_memory.md, `studies/fly64_dose_overlap/overlap.py`, and `tests/study/test_dose_overlap_overlap.py`. Reality: Phase D still enforces dense/sparse spacing gates, CLI lacks explicit sampling args, and tests only assert acceptance. Stood up the dedicated hub `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_d_overlap_metrics/`, drafted its plan/summary, and added a new `<plan_update>` so the implementation plan + ledger point at the overlap-metrics deliverable before any new Phase G rerun.
  - Ready_for_implementation Do Now:
    1. Overhaul `studies/fly64_dose_overlap/overlap.py` to implement disc-overlap helpers plus Metric 1 (gs=2 only), Metric 2, and Metric 3 per specs/overlap_metrics.md. Remove MIN_ACCEPTANCE_RATE / greedy fallback, plumb deterministic `s_img` subsampling + unified `n_groups` semantics (gs=1 = single-image groups; gs=2 = `n_groups √ó gridsize¬≤` samples with allowed duplication), and record `gridsize`, `s_img`, `n_groups`, `neighbor_count`, `probe_diameter_px`, RNG seeds, and metric averages in each metrics JSON + `_metadata`.
    2. Refresh the CLI so commands resemble `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB="$PWD/plans/active/.../phase_d_overlap_metrics" python -m studies.fly64_dose_overlap.overlap --phase-c-root data/phase_c/dose_1000 --output-root tmp/phase_d_overlap --artifact-root "$HUB" --gridsize 2 --s-img 0.8 --n-groups 512 --neighbor-count 6 --probe-diameter-px 38.4 --rng-seed-subsample 456`. Keep the Python API callable by future orchestrators.
    3. Rewrite `tests/study/test_dose_overlap_overlap.py` to cover the disc-overlap math, Metric 1/2/3 aggregation, gs=1 skipping Metric 1, and the new bundle schema. Add at least one CLI-focused selector that inspects `metrics_bundle.json`. Remove spacing-threshold assertions.
    4. Evidence expectations: run `pytest tests/study/test_dose_overlap_overlap.py -vv | tee "$HUB"/green/pytest_phase_d_overlap.log`, capture CLI stdout/err under `$HUB/cli/phase_d_overlap_metrics.log`, and drop `train_metrics.json`, `test_metrics.json`, and `metrics_bundle.json` (with Metric 1/2/3 + sampling parameters) into `$HUB` (record file list in `analysis/artifact_inventory.txt`). Blockers go to `$HUB/red/blocked_<timestamp>.md` with the failing command + exit code.

- Latest Attempt (2025-11-13T012200Z): planning ‚Äî `git status --porcelain` only showed the stale `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/phase_d_dense.log`, so per the reports-hub evidence rule I skipped `git pull --rebase` (logged `evidence_only_dirty=true`) and exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ß¬ßPhase G orchestrator + metrics helpers, docs/development/TEST_SUITE_INDEX.md (study row), specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub summaries, `analysis/blocker.log`, `cli/phase_d_dense.log`, and `cli/run_phase_g_dense_post_verify_only.log`. Hub reality: `{analysis}` is still only `blocker.log`, `{cli}` tops out at `phase_c_generation.log`, `phase_d_dense.log`, and the `run_phase_g_dense_stdout*.log` trio, and the post-verify CLI log is just the argparse usage banner because the helper again omitted `--dose/--view/--splits`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED goes to `$HUB/red/`); (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` and immediately follow with `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) if `analysis/metrics_summary.json` predates the rerun, run `plans/active/.../bin/report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` plus `plans/active/.../bin/analyze_dense_metrics.py --hub "$HUB"` so `{analysis}` gains `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, and `metrics_digest.md`; (5) do not stop until `{analysis}` also lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, and `artifact_inventory.txt`, then record MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas and selector/CLI references across `$HUB/summary/summary.md`, docs/fix_plan.md, and galph_memory (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md` with command + exit code).
- Latest Attempt (2025-11-12T235900Z): planning ‚Äî `git status -sb` was clean, so I still executed `timeout 30 git pull --rebase` (failed with ‚ÄúCannot rebase onto multiple branches‚Äù), ran `git pull --no-rebase` to confirm the branch is current, and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, `summary.md`, `summary/summary.md`, and the latest hub logs (`analysis/blocker.log`, `cli/phase_d_dense.log`, `cli/run_phase_g_dense_post_verify_only.log`). `docs/prompt_sources_map.json` is still absent, so docs/index.md remains authoritative. Audit finding: `cli/run_phase_g_dense_post_verify_only.log` is only the argparse usage banner because the command omitted `--dose/--view/--splits`, meaning no post-verify steps actually ran and `{analysis}` still contains only `blocker.log`‚Äîthere is still zero SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) refresh the GREEN record via `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED ‚Üí `$HUB/red/`); (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` and immediately follow with `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) if `analysis/metrics_summary.json` predates the run, rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` and `analyze_dense_metrics.py --hub "$HUB"` so preview/highlights/digest artifacts align; (5) do not stop until `{analysis}` lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, and `artifact_inventory.txt`, and document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus selector/CLI references across `$HUB/summary/summary.md`, this ledger, galph_memory, and hub blockers (`$HUB/red/blocked_<timestamp>.md`) if anything fails.
- Latest Attempt (2025-11-11T220602Z): planning ‚Äî Stashed the dirty plan files, ran `timeout 30 git pull --rebase` (already up to date), and popped the stash before exporting `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md (Phase G orchestrator + metrics helper sections), docs/development/TEST_SUITE_INDEX.md (study selectors), specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, both summaries, and the current hub artifacts (`analysis/blocker.log`, `cli/phase_d_dense.log`, `cli/run_phase_g_dense*.log`) plus `studies/fly64_dose_overlap/overlap.py` and `tests/study/test_dose_overlap_overlap.py`. Reality check: `{analysis}` still only contains `blocker.log`; there is no SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. The dense CLI logs prove the pipeline kept failing in Phase D, and code review shows the helper still emits `geometry_aware_floor` (50 % of the theoretical bound, floored at 1 %) instead of the required `geometry_acceptance_bound` capped at 10 %, so the JSON/metadata keys do not match ACCEPTANCE-001. Ready_for_implementation Do Now: (1) update `studies/fly64_dose_overlap/overlap.py` + `SpacingMetrics` to compute the per-split bounding-box acceptance bound `(area / (pi * (threshold / 2) ** 2)) / n_positions`, clamp it to ‚â§0.10 with a tiny epsilon lower guard, and log the values as `geometry_acceptance_bound` + `effective_min_acceptance` in both the metrics JSON and `_metadata`; (2) refresh `tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor` (and any shared fixtures) so it asserts the renamed JSON keys and the new clamp behavior, capturing the run via `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED output ‚Üí `$HUB/red/`); (3) from `/home/ollie/Documents/PtychoPINN` rerun `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`, then regenerate metrics via `report_phase_g_dense_metrics.py` and `analyze_dense_metrics.py` if `analysis/metrics_summary.json` predates the run. Stop only when `{analysis}` lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, preview verdict text, and `artifact_inventory.txt`, and document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas + selector/CLI references across `$HUB/summary/summary.md`, this ledger, and galph_memory. Blockers belong under `$HUB/red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-11T233550Z): implementation (PARTIAL ‚Äî pipeline running) ‚Äî Confirmed working directory guard PASS, executed `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv` (PASSED, 4.17s, GREEN log saved to `$HUB/green/pytest_dense_acceptance_floor.log`). Started Phase C‚ÜíG dense pipeline with `PYTHONPATH=/home/ollie/Documents/PtychoPINN:$PYTHONPATH /home/ollie/miniconda3/envs/ptycho311/bin/python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub ... --dose 1000 --view dense --splits train test --clobber` after discovering that script imports required explicit PYTHONPATH (when running script files directly, Python doesn't auto-add project root to sys.path). Pipeline launched successfully (PID 1357749, started 2025-11-11 15:35:43 UTC), currently in Phase C (TensorFlow/CUDA initialized, dataset generation in progress). Output streaming to `$HUB/cli/run_phase_g_dense_stdout.log`. Estimated completion: 30‚Äì120 minutes. Remaining steps: await pipeline completion, then run `--post-verify-only` chain and verify `{analysis}` artifacts (SSIM grid, verification report, highlights, metrics summaries). Status: in_progress (long-running task). Artifacts: `$HUB/green/pytest_dense_acceptance_floor.log` (‚úÖ), `$HUB/cli/run_phase_g_dense_stdout.log` (streaming), `$HUB/summary/summary.md` (‚úÖ).
- Latest Attempt (2025-11-11T222901Z): planning ‚Äî Ran `timeout 30 git pull --rebase` (already up to date), exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, both summaries, and the current hub artifacts (`analysis/blocker.log`, `cli/phase_d_dense.log`, `green/pytest_dense_acceptance_floor.log`) plus `studies/fly64_dose_overlap/overlap.py` and `tests/study/test_dose_overlap_overlap.py`. `docs/prompt_sources_map.json` is still absent so docs/index.md remains the canonical map. Audit: the geometry-aware acceptance bound implementation (`studies/fly64_dose_overlap/overlap.py:334-555`) and its pytest (`tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor`, GREEN log under `$HUB/green/pytest_dense_acceptance_floor.log`) are already in the repo, yet `{analysis}` still only contains `blocker.log` because the counted dense rerun + `--post-verify-only` sweep never executed with the new code ‚Äî `cli/phase_d_dense.log` still shows the pre-fix "minimum 10.0%" error and there is no SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED output ‚Üí `$HUB/red/`) so the log reflects the current branch; (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) rerun `plans/active/.../bin/report_phase_g_dense_metrics.py` and `plans/active/.../bin/analyze_dense_metrics.py` if `analysis/metrics_summary.json` predates the rerun so `{analysis}` captures `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, preview verdict text, and `artifact_inventory.txt`; (5) document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus the selector/CLI references inside `$HUB/summary/summary.md`, this ledger, and galph_memory, dropping any new blockers under `$HUB/red/blocked_<timestamp>.md`.

Attempts History (archived):
- See `docs/archive/2025-11-06_fix_plan_archive.md` for full attempt logs and evidence links.

Do Now (updated):
- Add a geometry-aware acceptance floor inside `studies/fly64_dose_overlap/overlap.py::generate_overlap_views` (or a focused helper): compute each split‚Äôs bounding-box area from `xcoords/ycoords`, derive the theoretical maximum acceptance for the requested spacing threshold, require only a conservative fraction of that bound, and persist both the bound and the actual acceptance in the emitted metrics JSON so downstream verifiers know the effective overlap.
- Extend `tests/study/test_dose_overlap_overlap.py` with `test_generate_overlap_views_dense_acceptance_floor` (or equivalent) to prove the new guard allows dense datasets whose acceptance matches the computed bound while still failing when even the bound is unattainable.
- After the guard + tests land, re-run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` followed immediately by `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`, then publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid summary/log, verification report/log, highlights log, metrics summary/digest, `metrics_delta_highlights_preview.txt`, and `artifact_inventory.txt` under `{analysis}` with selectors + CLI paths called out in `$HUB/summary/summary.md`, this ledger, and galph_memory.

- Attempt (2025-11-11T205022Z): Planning ‚Äî `git status -sb` showed `?? docs/fix_plan.md.bak` (whitelisted) plus `?? docs/iteration_scores_262-291.csv`, so I ran `timeout 30 git pull --rebase` (already up to date) before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G orchestrator, docs/development/TEST_SUITE_INDEX.md:62, `galph_memory.md`, the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, `analysis/blocker.log`, and `cli/phase_d_dense.log`. Hub reality check: `{analysis}` still only contains `blocker.log`, `{cli}` is capped at `phase_c_generation.log`, `phase_d_dense.log`, and the `run_phase_g_dense_stdout*` variants, and `data/phase_c/run_manifest.json` remains deleted (must be regenerated via `--clobber`, not restored manually). `cli/phase_d_dense.log` again ends with `ValueError: Object arrays cannot be loaded when allow_pickle=False` emitted **inside `/home/ollie/Documents/PtychoPINN`**, proving the overlap fix has never run here. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` plus `HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest --collect-only tests/study/test_phase_g_dense_orchestrator.py -k post_verify_only_executes_chain -vv | tee "$HUB"/collect/pytest_collect_post_verify_only.log` and `pytest tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain -vv | tee "$HUB"/green/pytest_post_verify_only.log`; (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` so Phase C manifests regenerate and the dense pipeline reruns under this repo; (4) immediately run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (5) rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` and `analyze_dense_metrics.py` if needed so `metrics_delta_highlights_preview.txt` (phase-only per PREVIEW-PHASE-001) and `metrics_digest.md` match the new evidence; (6) ensure `{analysis}` now contains `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, and `artifact_inventory.txt`; and (7) log MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, selectors, and CLI paths in `$HUB/summary/summary.md`, this ledger, and galph_memory. Any failure transcript belongs under `$HUB/red/blocked_$(date -u +%FT%H%M%SZ).md` with the command + exit status. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md}`.
- Attempt (2025-11-11T213824Z): Planning ‚Äî `git status -sb` again showed only report artifacts plus the stray `docs/iteration_scores_262-291.csv`, so I reran `timeout 30 git pull --rebase` (already up to date), exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G, docs/development/TEST_SUITE_INDEX.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, docs/fix_plan.md, galph_memory.md, input.md, the hub plan + summaries, `analysis/blocker.log`, `cli/run_phase_g_dense_stdout.log`, `cli/phase_d_dense.log`, and the regenerated Phase C artifacts. The counted dense run now executes locally (regenerates `data/phase_c/run_manifest.json` + patched splits) but **fails deterministically during Phase D** with `ValueError: Insufficient positions meet spacing threshold` because only 42/5088 train positions (0.8%) survive the 38.4 px guard even after the greedy fallback. Geometry probe (56 399 px¬≤ split area; ‚âà48.7 viable slots; ‚âà0.0096 acceptance ceiling) proves the current MIN_ACCEPTANCE_RATE=0.1 is mathematically impossible for dense view, so rerunning the CLI without changing the guard will never produce SSIM grid / verification / metrics / inventory evidence. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md` (new `<plan_update>` + audit), the hub plan + summaries, docs/fix_plan.md, input.md, and galph_memory.md so Ralph must first implement a geometry-aware acceptance floor in `studies/fly64_dose_overlap/overlap.py` (log derived bounds + actual acceptance in the metrics bundle) and add a dense acceptance-floor pytest, then rerun `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber` followed immediately by `--post-verify-only`, publishing MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus SSIM grid / verification / highlights / metrics / artifact inventory evidence across summaries + ledger. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md,analysis/blocker.log,cli/run_phase_g_dense_stdout.log,cli/phase_d_dense.log}`.
- Attempt (2025-11-11T202702Z): Planning ‚Äî Evidence-only dirty exemption re-applied (`git status -sb` shows only the deleted `plans/.../phase_g_dense_full_run_verifier/data/phase_c/run_manifest.json` plus `docs/fix_plan.md.bak`, so pull was skipped). Re-read docs/index.md, docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G commands, docs/development/TEST_SUITE_INDEX.md:62, specs/data_contracts.md, `input.md`, the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, and the `cli/phase_d_dense.log` + `cli/run_phase_g_dense_clobber.log` pair (docs/prompt_sources_map.json remains absent, so docs/index.md stays the authoritative map). Hub audit: `analysis/` still only holds `blocker.log`; `{cli}` contains `phase_c_generation.log`, `phase_d_dense.log`, `run_phase_g_dense_stdout(_retry,_v2).log`, and the partial `run_phase_g_dense_clobber.log`; `data/phase_c/run_manifest.json` is still deleted; and there are zero SSIM grid summaries/logs, verification/highlights outputs, preview text, metrics summary/digest, or artifact inventory files in this workspace. `cli/phase_d_dense.log` again shows the failure occurred **inside `/home/ollie/Documents/PtychoPINN`** and ends with the pre-fix `ValueError: Object arrays cannot be loaded when allow_pickle=False`, confirming the overlap.py fix has never been rerun locally. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md` (new `<plan_update>` + audit), the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, and `input.md` to keep the focus ready_for_implementation with the same Do Now: (1) guard `pwd -P` equals `/home/ollie/Documents/PtychoPINN`, export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` and `HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest --collect-only tests/study/test_phase_g_dense_orchestrator.py -k post_verify_only_executes_chain -vv | tee "$HUB"/collect/pytest_collect_post_verify_only.log` plus `pytest tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain -vv | tee "$HUB"/green/pytest_post_verify_only.log`; (3) execute the counted pipeline `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log`, regenerating Phase C manifests and populating `{analysis}` with `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt` (phase-only per PREVIEW-PHASE-001), `metrics_digest.md`, and `artifact_inventory.txt`; (4) immediately run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (5) rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` if the sanity table is stale; and (6) publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid references, verification/highlights links, pytest selectors, and CLI log paths inside `$HUB/summary/summary.md`, this ledger, and galph_memory. Any failure must land under `$HUB/red/blocked_<timestamp>.md` with the exact command + exit code before stopping. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md}`.
- Attempt (2025-11-11T192358Z): Planning ‚Äî Repeated the `git stash push --include-untracked` ‚Üí `timeout 30 git pull --rebase` ‚Üí `git stash pop` flow, exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, re-read docs/index.md plus docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001), and re-audited the 2025-11-12 hub. Nothing has landed since the last directive: `analysis/` still only holds `blocker.log`, `{cli}` remains capped at `phase_c_generation.log`, `phase_d_dense.log`, and `run_phase_g_dense_stdout*.log`, and `cli/phase_d_dense.log` still ends with the local `ValueError: Object arrays cannot be loaded when allow_pickle=False`. Added a new Phase G audit entry (with XML guard) to the implementation plan plus refreshed the hub plan + summaries, all reiterating the ready_for_implementation Do Now: rerun the mapped pytest collect-only selector + `tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain`, execute `plans/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber` from `/home/ollie/Documents/PtychoPINN`, immediately follow with `--post-verify-only`, then publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid summary/log, verification report/log, highlights log, metrics digest/summary, and artifact inventory evidence across the hub and ledger docs. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,summary.md,summary/summary.md,input.md}`.
- Attempt (2025-11-11T191109Z): Planning ‚Äî `timeout 30 git pull --rebase` returned up to date, so I re-read docs/index.md plus docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001) before auditing the active hub: `analysis/` still contains only `blocker.log`, `{cli}` remains capped at `phase_c_generation.log`, `phase_d_dense.log`, and the trio of `run_phase_g_dense_stdout*.log`, and `phase_d_dense.log` still ends with the local `ValueError: Object arrays cannot be loaded when allow_pickle=False` stack trace. No SSIM grid summaries, verification/highlights logs, preview text, metrics digests, or artifact-inventory files exist, so the counted dense rerun + immediate `--post-verify-only` sweep has **still never executed inside this workspace** even though the allow_pickle fix landed days ago. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md`, the hub plan, summary.md, summary/summary.md, and `input.md` with the ready_for_implementation Do Now: from `/home/ollie/Documents/PtychoPINN` rerun the mapped pytest collect/execution selector, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately follow with `--post-verify-only`, and publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus preview/verifier/highlights/SSIM grid references, CLI logs, and artifact inventory evidence inside the hub, docs/fix_plan.md, and galph_memory. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,summary.md,summary/summary.md,input.md}`.

## [FIX-PHASE-C-GENERATION-001] Fix Phase C coordinate type bug
- Depends on: ‚Äî
- Priority: High (blocks STUDY-SYNTH-FLY64-DOSE-OVERLAP-001 Phase G evidence)
- Status: done
- Owner/Date: Ralph/2025-11-07
- Error Signature: `TypeError: object of type 'float' has no len()` at `ptycho/raw_data.py:227`
- Root Cause: `studies/fly64_dose_overlap/generation.py:85-91` did not set `TrainingConfig.n_images`, leaving it None; legacy simulator `_generate_simulated_data_legacy_params` depends on `n_images` to size coordinate arrays
- Impact: Phase C dataset generation fails immediately, blocking all downstream phases (D/E/F/G)
- Repro: `python -m studies.fly64_dose_overlap.generation --base-npz <path> --output-root <path>`
- Scope: `studies/fly64_dose_overlap/generation.py` config construction; `tests/study/test_dose_overlap_generation.py` coverage
- Notes: Discovered during 2025-11-07T070500Z Phase G orchestrator execution; blocker logged at `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-07T070500Z/phase_g_execution_real_runs/analysis/blocker.log`

## [EXPORT-PTYCHODUS-PRODUCT-001] TF-side Ptychodus product exporter/importer + Run1084 conversion
- Depends on: ‚Äî
- Priority: Medium
- Status: done ‚Äî All deliverables complete. Exporter/importer code, CLI, tests (3/3 PASSED), Run1084 HDF5 evidence, and comprehensive documentation published to DATA_MANAGEMENT_GUIDE.md + index.md. Commit a679e6fb.
- Owner/Date: Codex Agent/2025-10-28
- Working Plan: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/implementation_plan.md`
- Test Strategy: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/test_strategy.md`
- Reports Hub: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/`
- Latest Attempt (2025-11-16T131500Z): verification ‚Äî Re-read `docs/DATA_MANAGEMENT_GUIDE.md:242-369`, `docs/index.md:125-133`, and hub artifacts (`analysis/data_guide_snippet.md`, `analysis/artifact_inventory.txt`, `summary/*.md`) to confirm the ‚ÄúPtychodus Product Export‚Äù section plus index cross-link already match the approved snippet. No repo edits required; focus stays `done` and evidence references remain valid.
- Latest Attempt (2025-11-14T010940Z): verification ‚Äî Verified commit a679e6fb (Nov 11) already integrated all deliverables: docs/DATA_MANAGEMENT_GUIDE.md lines 242-375 contain the full "Ptychodus Product Export" section with CLI examples, metadata parameters, raw-data toggles, storage policy, programmatic API, and verification code; docs/index.md lines 125-128 cross-reference the guide with ptychodus-export keyword; hub artifact_inventory.txt, summary.md, and summary/summary.md all document the integration. Tests (3/3 PASSED), CLI conversion, and HDF5 verification logs remain at the hub. Updated fix_plan status to `done`, cleared Active Focus, and prepared Turn Summary. Artifacts: plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/ (all evidence already committed).
- Do Now (superseded ‚Äî 2025-11-13T101500Z):
  1. Guard from `/home/ollie/Documents/PtychoPINN`, export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and set `HUB="$PWD/plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap"`.
  2. Integrate the drafted ‚ÄúPtychodus Product Export‚Äù subsection into `docs/DATA_MANAGEMENT_GUIDE.md` (after the NPZ/HDF5 sections). The new section must include the approved CLI example (with metadata flags), explain raw-data inclusion toggles, reiterate the storage policy (keep products under `outputs/ptychodus_products/`), and cite `specs/data_contracts.md` + `ptycho/io/ptychodus_product_io.py` for canonical behavior.
  3. If discoverability would benefit, add a short cross-link under the Data Management Guide entry in `docs/index.md` pointing at the new subsection.
  4. Update `analysis/artifact_inventory.txt`, `summary.md`, and `summary/summary.md` within the active hub so they reference the documentation edit (file path + section heading). No new pytest selector is required for this doc-only pass; blockers must drop a note in `red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-13T104500Z): planning ‚Äî Ran a verification preflight to generate a Phase G hub analysis deliverable: `python plans/active/.../bin/verify_dense_pipeline_artifacts.py --hub "$HUB" --report "$HUB"/analysis/verification_report.json --dose 1000 --view dense` (exit 1 as expected due to missing Phase G outputs; log at `$HUB/cli/verify_dense_pipeline_artifacts.log`). This establishes a concrete checklist of missing artifacts while landing a new `{analysis}` file. Updated input.md and hub summary to direct the counted rerun and post‚Äëverify sweep. Focus is now ready_for_implementation.
- Latest Attempt (2025-11-13T093000Z): implementation ‚Äî Ran `pytest tests/io/test_ptychodus_product_io.py -vv` (3 PASSED in 3.73s, logged to `$HUB/green/pytest_product_io.log`). Executed CLI conversion of Run1084 NPZ to HDF5 product (`outputs/ptychodus_products/run1084_product.h5`), capturing stdout to `$HUB/cli/convert_run1084.log` (exit 0). Verified HDF5 structure via h5py (all required datasets present, 1087 scan positions, probe 64√ó64 complex64, object 227√ó226 complex64, diffraction [1087,64,64] in canonical NHW order, empty loss arrays). Saved verification log to `$HUB/analysis/verify_product.log` and product summary JSON. Drafted DATA_MANAGEMENT_GUIDE snippet in `$HUB/analysis/data_guide_snippet.md` covering CLI usage, metadata parameters, raw data inclusion, storage policy, and programmatic access. Created artifact inventory and turn summary. All Do Now steps complete; focus ready for doc integration. Artifacts: plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/ (green/pytest_product_io.log, cli/convert_run1084.log, analysis/{verify_product.log,product_summary.json,data_guide_snippet.md,artifact_inventory.txt}, summary/summary.md).
- Latest Attempt (2025-11-13T112200Z): planning ‚Äî `git status --porcelain` showed local edits to `pyproject.toml` and `ptychopinn.egg-info/SOURCES.txt`, so I ran `git stash push -u`, `timeout 30 git pull --rebase origin feature/torchapi-newprompt`, then `git stash pop`, and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Reviewed docs/index.md, docs/findings.md (DATA-001), specs/data_contracts.md ¬ßProduct files, docs/DATA_MANAGEMENT_GUIDE.md, the initiative implementation plan, hub plan/summary files, and the drafted snippet at `$HUB/analysis/data_guide_snippet.md`. Reality: the guide still contains the older one-paragraph ‚ÄúExporting to Ptychodus HDF5 Product‚Äù note (from 6cfd2ada) with no metadata flag breakdown, raw-data toggle, storage policy reminder, or references to `ptycho/io/ptychodus_product_io.py`; docs/index.md still lacks any pointer to the Data Management Guide, and the hub summaries/artifact inventory cite only the exporter evidence. Reiterated the Do Now so Ralph must insert the full ‚ÄúPtychodus Product Export‚Äù subsection (CLI block + metadata parameters + raw-data inclusion toggle + storage policy + references), add or update the docs/index.md entry so it links directly to the new subsection, and refresh `$HUB/analysis/artifact_inventory.txt`, `summary.md`, and `summary/summary.md` with the doc path + section title (blockers go under `$HUB/red/`). Status: ready_for_implementation. Artifacts: plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/.
- Latest Attempt (2025-11-13T101500Z): planning ‚Äî Reviewed the Run1084 hub evidence (`green/pytest_product_io.log`, `cli/convert_run1084.log`, `analysis/{verify_product.log,product_summary.json,data_guide_snippet.md,artifact_inventory.txt}`) plus docs/index.md, docs/findings.md (DATA-001), specs/data_contracts.md, docs/DATA_MANAGEMENT_GUIDE.md, and the implementation plan. Confirmed exporter evidence is complete and the documentation snippet is ready for publication. Updated the working plan with a new `<plan_update>` + Do Now describing the doc insertion, hub summary refresh, and optional docs/index cross-link. Status stays planning until the doc diff lands.
- Latest Attempt (2025-11-16T110500Z): planning ‚Äî After enforcing Tier‚ÄØ3 on STUDY-SYNTH-FLY64-DOSE-OVERLAP-001, pivoted back to this initiative, re-read docs/index.md; docs/findings.md (DATA-001); docs/DATA_MANAGEMENT_GUIDE.md; docs/index.md; specs/data_contracts.md; the implementation plan; and the Run1084 snippet (`analysis/data_guide_snippet.md`). Confirmed exporter CLI/pytest evidence plus the drafted copy still live in the hub, refreshed input.md/plan/summary to demand the doc insertion + optional docs/index cross-link, and reiterated that `analysis/artifact_inventory.txt`, `summary.md`, and `summary/summary.md` must cite the new section after editing. Focus is ready_for_implementation.

## [INTEGRATE-PYTORCH-PARITY-001] PyTorch backend API parity reactivation
- Depends on: Phase F handoff of `INTEGRATE-PYTORCH-001` (config bridge + policy decisions already archived under `plans/active/INTEGRATE-PYTORCH-001/`)
- Priority: High
- Status: done ‚Äî Phase R CLI GPU-default handoff evidence complete with all requested artifacts archived under the active hub. Training/inference CLIs both succeeded without `--torch-*` flags and correctly logged POLICY-001 warnings plus auto-instantiated CUDA execution config. Execution_config regression test failures (2 FAILED due to stub fixture issue) documented under `red/blocked_20251113T224500Z_execution_config.md` with fix strategy.
- Owner/Date: Ralph/2025-11-13T220500Z
- Working Plan: `plans/ptychodus_pytorch_integration_plan.md`
- Summary: `plans/active/INTEGRATE-PYTORCH-001/summary.md`
- Reports Hub: `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/`
- GPU Baseline: All PyTorch backend work (including this focus and TEST-PYTORCH-001) must now run on a pinned CUDA device by default. CPU-only runs are considered fallback evidence; cite the GPU model/driver in summaries and follow the updated workflow guidance (`docs/workflows/pytorch.md` ¬ß¬ß11‚Äì12).
- Test Strategy: `plans/pytorch_integration_test_plan.md`
- Constraints: POLICY-001, CONFIG-001, CONFIG-LOGGER-001, plus "no edits to ptycho/model.py / diffsim.py / tf_helper.py" rule.

- Latest Attempt (2025-11-13T220500Z): implementation ‚Äî Executed all Do Now steps: (1) environment verified with `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` ‚úÖ and env vars set; (2) ran training CLI without `--torch-*` flags ‚Üí GREEN `cli/pytorch_cli_smoke_training/train_gpu_default_log.log` showing POLICY-001 warning and auto-instantiated CUDA config, training succeeded with bundle at `train_outputs/wts.h5.zip`; (3) ran inference CLI without `--torch-*` flags ‚Üí GREEN `cli/pytorch_cli_smoke_training/inference_gpu_default_log.log` showing same POLICY-001 + CUDA placement, inference succeeded with amplitude/phase PNGs; (4) captured execution_config regression RED log ‚Üí 2 FAILED (StubLightningModule lacks `automatic_optimization` attribute), summary at `red/blocked_20251113T224500Z_execution_config.md` with fix strategy (test fixture issue, not production bug); (5) updated `analysis/artifact_inventory.txt`, initiative summary, and hub summary with all new evidence links. GPU confirmed: NVIDIA GeForce RTX 3090. Status: done. Artifacts: cli/pytorch_cli_smoke_training/{train_gpu_default_log.log,inference_gpu_default_log.log}, red/{pytest_workflows_execution_config.log,blocked_20251113T224500Z_execution_config.md}, analysis/artifact_inventory.txt.
- Latest Attempt (2025-11-13T224000Z): implementation ‚Äî Commit `d3793315` added POLICY-001 GPU-default logging to both CLIs plus new pytest coverage in `tests/scripts/test_*backend_selector.py::test_pytorch_backend_defaults_auto_execution_config`; GREEN log captured at `green/pytest_backend_selector_cli.log` (2 PASSED). CLI smokes and execution_config regression evidence still pending.
- Latest Attempt (2025-11-13T220000Z): implementation ‚Äî Commit `83ae55af` extended `tests/torch/test_execution_config_defaults.py` with dispatcher-level GPU-default coverage (new CUDA + CPU tests), ensured backend_selector auto-instantiates `PyTorchExecutionConfig()` when callers omit `torch_execution_config`, and reran `pytest tests/torch/test_execution_config_defaults.py -vv` (8 items, log at `green/pytest_execution_config_defaults.log`). Hub inventory + summaries now cite the new tests and POLICY-001 enforcement notes.
- Latest Attempt (2025-11-13T210000Z): implementation ‚Äî Commit `3efa2dc3` changed `PyTorchExecutionConfig.accelerator` default to `'auto'`, added auto-resolution logic with POLICY-001 warnings, logged resolved accelerators inside `_build_inference_dataloader` and `_train_with_lightning`, and introduced `tests/torch/test_execution_config_defaults.py` (2 tests) with GREEN log `green/pytest_execution_config_defaults.log`. Artifact inventory updated with GPU/CPU detection notes.
- Latest Attempt (2025-11-13T203500Z): implementation ‚Äî Commit `85478a67` moved bundle-loaded models to the requested accelerator, added regression tests (`tests/scripts/test_inference_backend_selector.py::TestInferenceCliBackendDispatch::test_pytorch_backend_moves_model_to_execution_device`, `tests/torch/test_cli_inference_torch.py::TestInferenceCLI::test_accelerator_flag_roundtrip`), and reran the CUDA inference CLI with `CUDA_VISIBLE_DEVICES=0`. Evidence: `green/pytest_pytorch_inference_device.log`, `cli/pytorch_cli_smoke_training/inference_cuda.log`, and `inference_outputs_cuda/{reconstructed_amplitude.png,reconstructed_phase.png}`. DEVICE-MISMATCH-001 resolved.
- Latest Attempt (2025-11-13T205500Z): planning ‚Äî Verified commit `420e2f14` and the associated GREEN pytest + CLI evidence captured under `reports/2025-11-13T150000Z/parity_reactivation/{green/pytest_cuda_default_exec_config.log,cli/pytorch_cli_smoke_training/train_cuda_default.log,inference_cuda_default.log}`. Updated `plans/ptychodus_pytorch_integration_plan.md`, `summary.md`, and this ledger to mark the CUDA-default checklist complete, highlighted that defaulting `PyTorchExecutionConfig` to CPU keeps backend_selector callers on CPU, and drafted the new Do¬†Now (GPU-first dataclass defaults + regression tests). Input.md refreshed accordingly.

## [INTEGRATE-PYTORCH-PARITY-001B] CLI GPU-default evidence & execution-config regression capture
- Depends on: completion of INTEGRATE-PYTORCH-PARITY-001 (CUDA defaults + device placement already merged)
- Priority: High
- Status: done ‚Äî Training/inference CLI GPU-default evidence plus the RED execution_config regression log are archived under the parity hub; artifact inventory and summaries updated.
- Owner/Date: Ralph/2025-11-14T020000Z
- Working Plan: `plans/ptychodus_pytorch_integration_plan.md`
- Summary: `plans/active/INTEGRATE-PYTORCH-001/summary.md`
- Reports Hub: `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/`
- Do Now (2025-11-14T020000Z):
  1. From repo root, `export HUB="$PWD/plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation"`.
  2. Training CLI without any `--torch-*` flags:  
     `python scripts/training/train.py --config configs/gridsize2_minimal.yaml --train_data_file tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --test_data_file tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --backend pytorch --output_dir "$HUB"/cli/pytorch_cli_smoke_training/train_outputs --n_groups 4 --n_subsample 16 --neighbor_count 7 --batch_size 4 --nepochs 1 |& tee "$HUB"/cli/pytorch_cli_smoke_training/train_gpu_default_log.log` (verify POLICY-001 log + CUDA execution_config message near top).
  3. Inference CLI (reuse bundle from step¬†2, still no torch flags):  
     `python scripts/inference/inference.py --model_path "$HUB"/cli/pytorch_cli_smoke_training/train_outputs --test_data tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --backend pytorch --output_dir "$HUB"/cli/pytorch_cli_smoke_training/inference_outputs --n_images 4 --n_subsample 16 |& tee "$HUB"/cli/pytorch_cli_smoke_training/inference_gpu_default_log.log` (same GPU-default log, regenerated amplitude/phase PNGs).
  4. Execution-config regression suite (expected RED):  
     `pytest tests/torch/test_workflows_components.py -k execution_config -vv |& tee "$HUB"/red/pytest_workflows_execution_config.log` and append the first failure signature (StubLightningModule) to `$HUB/red/blocked_20251113T224500Z_execution_config.md`.
  5. Refresh `analysis/artifact_inventory.txt`, initiative summary, and hub summary with links to the new GREEN CLI logs + RED pytest log (blockers stay under `$HUB/red/`).
- Latest Attempt (2025-11-14T020000Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; initiative plan; hub summary + inventory. Reality: CUDA-default code is merged but the hub still lacks `train_gpu_default_log.log`, `inference_gpu_default_log.log`, and only contains the older RED execution-config log. Added this row to isolate the evidence tasks, updated the plan checklist, refreshed summaries, and rewrote `input.md` with the commands above. Focus remains ready_for_implementation.
- Latest Attempt (2025-11-13T225000Z): implementation ‚Äî Ran the training and inference CLIs without any `--torch-*` flags, capturing POLICY-001 GPU-default banners plus CUDA placement in `cli/pytorch_cli_smoke_training/{train_gpu_default_log.log,inference_gpu_default_log.log}`; reran `pytest tests/torch/test_workflows_components.py -k execution_config -vv` with the expected RED failure logged to `red/pytest_workflows_execution_config.log` and summarized in `red/blocked_20251113T224500Z_execution_config.md`; refreshed `analysis/artifact_inventory.txt`, the initiative summary, and hub summaries with links to the new logs. Status: done.

## [PARALLEL-API-INFERENCE] Programmatic TF/PyTorch API parity
- Depends on: INTEGRATE-PYTORCH-PARITY-001 (backend selector wiring complete; this focus builds a programmatic example)
- Priority: Medium
- Status: planning ‚Äî new initiative to expose the backend selector in a demo script + reusable helpers
- Owner/Date: Ralph/2025-11-14T030000Z
- Working Plan: `plans/active/PARALLEL-API-INFERENCE/plan.md`
- Reports Hub: TBD (will use `plans/active/PARALLEL-API-INFERENCE/reports/<timestamp>/`)
- Do Now (2025-11-14T030000Z):
  1. Extract a TensorFlow inference helper from `scripts/inference/inference.py` (data container prep + output saving) so programmatic callers can invoke it without the CLI.
  2. Build `scripts/pytorch_api_demo.py` that loads `RawData`, constructs `TrainingConfig`/`InferenceConfig`, and runs both backends via `run_cdi_example_with_backend` + the new TF helper / `_run_inference_and_reconstruct`.
  3. Add a smoke test under `tests/scripts/test_api_demo.py` that calls `run_backend('pytorch')` and `run_backend('tensorflow')` against the minimal dataset (skip CUDA path if GPU unavailable).
  4. Document the usage snippet referencing `specs/ptychodus_api_spec.md` (e.g., add a ‚ÄúProgrammatic API‚Äù section to `docs/workflows/pytorch.md`).
- Latest Attempt (2025-11-14T030000Z): planning ‚Äî Created plan file `plans/active/PARALLEL-API-INFERENCE/plan.md` outlining goals, scope, tasks, and risks. Logged outstanding gaps (TF inference tied to CLI internals, PyTorch helper already available) and set next steps for implementation + regression tests. Focus now ready_for_implementation.
- Latest Attempt (2025-11-13T202000Z): planning ‚Äî Reviewed docs/index.md; docs/workflows/pytorch.md (GPU default table); docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-LOGGER-001 / EXEC-ACCUM-001 / DATA-SUP-001 / DEVICE-MISMATCH-001); docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/COMMANDS_REFERENCE.md; plan + hub summaries; and `cli/pytorch_cli_smoke_training/train_clean.log`. Determined that CLI defaults still resolve to CPU despite GPU baseline, so drafted the CUDA-default Do¬†Now and updated plan/input artifacts.
- Latest Attempt (2025-11-13T033117Z): implementation ‚Äî Commit `dd0a5b0e` finished the config-default backfill, updated the PyTorch factories/bridge, and reran `pytest tests/torch/test_config_bridge.py::TestConfigBridgeParity -vv` (47 PASSED; GREEN log at `$HUB/green/pytest_config_bridge.log`). The PyTorch inference CLI executed against `$HUB/cli/pytorch_cli_smoke_training/train_outputs/wts.h5.zip`; CUDA path failed with `Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor)` because bundle-loaded Lightning modules remain on CPU, while the CPU accelerator succeeded and produced `inference_outputs/{reconstructed_amplitude.png,reconstructed_phase.png}` (24 KB/18 KB). Evidence captured via `$HUB/cli/pytorch_cli_smoke_training/{inference.log,inference_cpu.log}` and blocker log `$HUB/red/blocked_2025-11-13T033117Z_device_mismatch.md`. Phase R objectives are complete; fixing DEVICE-MISMATCH-001 is now the gating inference task.

- Latest Attempt (2025-11-13T190000Z): implementation ‚Äî Commit `9daa00b7` added the EXEC-ACCUM-001 guard (`_train_with_lightning` now raises before Lightning misconfiguration), the DATA-SUP-001 detector for unlabeled supervised datasets, doc updates in `docs/workflows/pytorch.md`, and regression coverage (`test_manual_accumulation_guard`). `pytest_backend_selector_cli.log` now shows 4 PASS, and the PINN-mode training CLI completes on the fly001 subset (`cli/pytorch_cli_smoke_training/train_clean.log`, bundle saved to `train_outputs/wts.h5.zip`). Supervised runs remain blocked (DATA-SUP-001); inference still needs to be rerun against the new bundle.
- Latest Attempt (2025-11-13T190500Z): planning ‚Äî Updated the plan, hub summary, and artifact inventory to capture the guard evidence, noted the outstanding inference rerun, and rewrote the Do¬†Now toward spec-default parity in `ptycho_torch/config_params.py` plus the parity test selector. Input.md now directs Ralph to the config-default work and the pending PyTorch inference CLI refresh.
- Latest Attempt (2025-11-13T182600Z): implementation ‚Äî Commit `04a016ad` exposed the PyTorch execution-config flags on `scripts/training/train.py`, threaded `torch_execution_config` through `ptycho.workflows.backend_selector.run_cdi_example_with_backend`, and added `test_pytorch_execution_config_flags` under `tests/scripts/test_training_backend_selector.py` (GREEN log at `$HUB/green/pytest_backend_selector_cli.log`). The training CLI smoke hit `AttributeError: 'PtychoPINN_Lightning' object has no attribute 'loss_name'`, recorded in `train_debug.log:30621-30623` and `$HUB/red/blocked_20251113T183500Z_loss_name.md`; no new bundles/PNGs were produced.
- Latest Attempt (2025-11-13T020801Z): implementation ‚Äî Commit `b218696a` added PyTorch execution-config flags to the inference CLI (`scripts/inference/inference.py:95-149, 508-546`), introduced `test_pytorch_execution_config_flags` in `tests/scripts/test_inference_backend_selector.py`, reran the targeted pytest selector (2 PASSED, log at `$HUB/green/pytest_backend_selector_cli.log`), and repeated the PyTorch CLI smoke with the new flags (`cli/pytorch_cli_smoke/{train.log,inference.log}` + refreshed PNGs). `analysis/artifact_inventory.txt` now documents the execution-config evidence and policy compliance.
- Latest Attempt (2025-11-13T200000Z): implementation ‚Äî Commit `12fa29dd` introduced the backend-aware PyTorch inference branch, added `test_pytorch_inference_execution_path`, reran the backend-dispatch selectors (3 PASSED), and executed the minimal PyTorch CLI smoke (logs + amplitude/phase PNGs under `cli/pytorch_cli_smoke/`).
- Latest Attempt (2025-11-13T020801Z): implementation ‚Äî Commit `b218696a` added the PyTorch execution-config flags to the inference CLI (`scripts/inference/inference.py:95-149` + `508-546`), introduced `test_pytorch_execution_config_flags` (`tests/scripts/test_inference_backend_selector.py:365-446`), reran the targeted pytest selector (2 PASSED, log at `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/green/pytest_backend_selector_cli.log`), and repeated the PyTorch CLI smoke with the new flags (`cli/pytorch_cli_smoke/{train.log,inference.log}` + refreshed PNGs). `analysis/artifact_inventory.txt` now documents the execution-config evidence and policy compliance. Focus shifts to training CLI parity.
- Latest Attempt (2025-11-13T200000Z): implementation ‚Äî Commit `12fa29dd` introduced the backend-aware PyTorch inference branch (scripts/inference/inference.py:493-542), added `test_pytorch_inference_execution_path`, reran the backend-dispatch selectors (`green/pytest_backend_selector_cli.log`, 3 PASSED), and executed the minimal PyTorch CLI smoke (logs + amplitude/phase PNGs under `cli/pytorch_cli_smoke/`). `analysis/artifact_inventory.txt` now documents the successful train/inference commands, metrics ranges, and policy compliance. Focus remains ready_for_implementation pending the execution-config flag exposure + new tests/logs.
- Latest Attempt (2025-11-13T184500Z): implementation ‚Äî Commit `c983bdc8` added the inference `--backend` CLI flag/defaults, extended `tests/scripts/test_inference_backend_selector.py` with the parsing checks (GREEN via `pytest ...::test_pytorch_backend_dispatch`, log at `$HUB/green/pytest_backend_selector_cli.log`), and ran the minimal PyTorch CLI smoke. Training command succeeded (`cli/pytorch_cli_smoke/train.log`, bundle at `train_outputs/wts.h5.zip`), but the inference CLI still failed with `Error during inference: 'probe'` because the code re-enters the TensorFlow `perform_inference()` path instead of invoking a PyTorch helper. Evidence (including stdout with the `'probe'` KeyError) captured in `$HUB/cli/pytorch_cli_smoke/inference.log` and summarized in `analysis/artifact_inventory.txt`. Focus remains ready_for_implementation pending the PyTorch inference execution branch + rerun.
- Latest Attempt (2025-11-13T173500Z): planning ‚Äî Verified that commit `a53f897b` wired `scripts/training/train.py` / `scripts/inference/inference.py` through `ptycho.workflows.backend_selector`, guarded the TensorFlow-only persistence helpers, and added the new backend dispatch unit tests (`green/pytest_training_backend_dispatch.log`, `green/pytest_inference_backend_dispatch.log`). Reviewed docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-002 / CONFIG-LOGGER-001 / TYPE-PATH-001), docs/workflows/pytorch.md, plans/ptychodus_pytorch_integration_plan.md, plans/pytorch_integration_test_plan.md, hub summary + artifact inventory, and galph_memory/input briefs. Updated the plan + ledger to mark the backend-selector checklist complete, drafted the PyTorch CLI smoke-test Do Now (inference backend flag + minimal fixture training/inference runs), and rewrote input.md so Ralph can jump straight into the implementation work with explicit commands + pytest selector. Focus remains ready_for_implementation pending the new CLI argument + smoke run evidence.
- Latest Attempt (2025-11-13T160500Z): planning ‚Äî Reviewed docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-002 / CONFIG-LOGGER-001 / TYPE-PATH-001), docs/workflows/pytorch.md, specs/spec-ptycho-config-bridge.md, docs/DEVELOPER_GUIDE.md, `plans/ptychodus_pytorch_integration_plan.md`, `plans/pytorch_integration_test_plan.md`, hub inventory (`analysis/artifact_inventory.txt`), `scripts/training/train.py`, `scripts/inference/inference.py`, and `ptycho/workflows/backend_selector.py`. Confirmed commit `ccff2f5c` + `green/pytest_config_bridge.log` satisfy the Phase R checklist (config bridge wiring + PyTorch persistence shim + parity pytest). Updated the plan and this ledger to pivot the Do¬†Now toward backend-selector adoption in the production CLIs so `--backend pytorch` becomes runnable from the canonical scripts. Input brief + plan now direct Ralph to modify the CLIs, add dispatch tests, and log the new pytest evidence under the active hub.
- Latest Attempt (2025-10-19T215800Z): planning ‚Äî Final Phase E3 docs handoff noted that config bridge invocation, PyTorch persistence, and regression harness remained undone; see `plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-19T215800Z/phase_e3_docs_handoff/summary.md` plus `PYTORCH_INVENTORY_SUMMARY.txt` for the outstanding gaps. No further work occurred until this reactivation.

## [INTEGRATE-PYTORCH-001-STUBS] Finish PyTorch workflow stubs deferred from Phase D2
- Status: archived 2025-10-20 ‚Äî see `docs/archive/2025-10-20_fix_plan_archive.md#integrate-pytorch-001-stubs-finish-pytorch-workflow-stubs-deferred-from-phase-d2`.

## [INTEGRATE-PYTORCH-001-DATALOADER] Restore PyTorch dataloader DATA-001 compliance
- Status: archived 2025-10-20 ‚Äî see `docs/archive/2025-10-20_fix_plan_archive.md#integrate-pytorch-001-dataloader-restore-pytorch-dataloader-data-001-compliance`.

---

Process references:
- Supervisor prompt: `prompts/supervisor.md`
- Engineer prompt: `prompts/main.md`
- Findings ledger: `docs/findings.md`
- Data contracts: `specs/data_contracts.md`

- Latest Attempt (2025-11-11T161300Z): implementation ‚Äî Reran `pytest tests/study/test_dose_overlap_overlap.py::test_overlap_metrics_bundle -vv` (PASSED 1.54s, green log saved). Executed Phase D overlap CLI twice: (1) gs1 `--gridsize 1 --s-img 1.0 --n-groups 512` producing `metrics/gs1_s100_n512/{train,test,metrics_bundle}.json` with Metric 2 train=0.8908/test=0.8917 and Metric 3 train=0.2662/test=0.2658 (Metric 1 N/A for gs=1); (2) gs2 `--gridsize 2 --s-img 0.8 --n-groups 512` producing `metrics/gs2_s080_n512/*.json` with Metric 1 train=0.8909/test=0.8942, Metric 2 train=0.8777/test=0.8794, Metric 3 train=0.2706/test=0.2673 (4070/5088 train images retained, 4173/5216 test, 512 groups each split). Archived CLI logs under `$HUB/cli/phase_d_overlap_gs{1,2}.log`, updated `analysis/artifact_inventory.txt` with commands + metric summaries, wrote turn summary to `$HUB/summary/summary.md`. Phase E/G now unblocked for training manifest alignment and dense pipeline reruns. Artifacts: plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_d_overlap_metrics/ (green/pytest_phase_d_overlap_bundle_rerun.log, cli logs, metrics JSONs, artifact_inventory.txt, summary/summary.md).

- Latest Attempt (2025-11-14T0849Z): implementation ‚Äî Executed Phase C3 variance regression guard: seeded `TestPatchStatsCLI.minimal_train_args` fixture with `np.random.seed(12345)` for deterministic non-zero variance, updated `test_patch_stats_dump` to assert `var_zero_mean > 1e-6` and `abs(global_mean) > 1e-9` (citing phase_c2_pytorch_only_metrics.txt rationale). Pytest selector GREEN (1/1 PASSED, 7.07s), confirming seeded fixture produces healthy variance (1.44e-05) and non-zero mean (2.18e-03). Updated HUB artifact_inventory.txt + summary.md with Phase C3 section, initiative summary prepended. Guard applies only to gridsize‚â•2 configurations (test uses gridsize=2). No doc/test-registry updates required (selector name unchanged).
