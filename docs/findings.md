# PtychoPINN Knowledge Base (NanoBragg Standard)

This ledger captures the most important lessons, conventions, and recurring issues discovered across the project. Before starting new workâ€”or especially when debuggingâ€”consult this table to avoid repeating known mistakes.

| Finding ID | Date | Keywords | Synopsis | Evidence Pointer | Status |
| REASSEMBLY-BATCH-001 | 2025-11-13 | batched-reassembly, translation-layer, shape-mismatch, dense-view | Batched patch reassembly failed with InvalidArgumentError "required broadcastable shapes" when processing large (5k+) dense datasets. Translation layer output can shrink by 1px (e.g., 147 vs 148) due to interpolation/rounding in translate_core, causing mismatch during canvas + batch_result in tf.while_loop. Fixed by using tf.image.resize_with_crop_or_pad to align batch_summed to canvas dimensions after reduce_sum. | [Link](ptycho/tf_helper.py:941-957) | Resolved |
| XLA-DYN-DOT-001 | 2025-11-13 | xla, einsum, dynamic-shape, projective-warp | TF XLA JIT failed during inference with DynamicPadder RET_CHECK on dot/einsum when applying homography to the sampling grid (dynamic HÃ—W). Replaced `tf.einsum("bij,bhwj->bhwi", M, grid)` with explicit broadcasted multiplies/adds to compute `(sx, sy, w)`; removes dynamic dot and unblocks XLA. Also removed a `tf.print` in Translation layer that emitted a PrintV2 op. | ptycho/projective_warp_xla.py:90, ptycho/tf_helper.py:824 | Resolved |
| :--- | :--- | :--- | :--- | :--- | :--- |
| CONVENTION-001 | 2025-10-16 | architecture, legacy, global-state | The codebase consists of a legacy grid-based system tied to `params.cfg` and a modern coordinate-based system; pick the right side before changing anything. | [Link](docs/DEVELOPER_GUIDE.md#1-the-core-concept-a-two-system-architecture) | Active |
| POLICY-001 | 2025-10-17 | policy, PyTorch, dependencies, mandatory | PyTorch (torch>=2.2) is now a mandatory dependency for PtychoPINN as of Phase F (INTEGRATE-PYTORCH-001). All code in `ptycho_torch/` and `tests/torch/` assumes PyTorch is installed. Torch-optional execution paths were removed; modules raise actionable RuntimeError if torch import fails. Tests in `tests/torch/` are automatically skipped in TensorFlow-only CI environments via directory-based pytest collection rules in `tests/conftest.py`, but will fail with actionable ImportError messages if PyTorch is missing in local development. Migration rationale and implementation evidence documented in governance decision and Phase F implementation logs. | [Link](plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-17T184624Z/governance_decision.md) | Active |
| ANTIPATTERN-001 | 2025-10-16 | imports, side-effects, debugging | Import-time side effects (e.g., loading data in module scope) caused hidden crashes; always push work into functions with explicit arguments. | [Link](docs/DEVELOPER_GUIDE.md#21-anti-pattern-side-effects-on-import) | Active |
| CONFIG-001 | 2025-10-16 | params.cfg, initialization-order | `update_legacy_dict(params.cfg, config)` must run before any legacy module executes; missing this broke gridsize sync and legacy interop. | [Link](docs/debugging/QUICK_REFERENCE_PARAMS.md#âš ï¸-the-golden-rule) | Active |
| CONFIG-002 | 2025-10-20 | execution-config, cli, params.cfg | PyTorch execution configuration (PyTorchExecutionConfig) controls runtime behavior only and MUST NOT populate params.cfg. Only canonical configs (TrainingConfig, InferenceConfig) bridge via CONFIG-001. CLI helpers auto-detect accelerator default='auto' and validate execution config fields via factory integration. Execution config applied at priority level 2 (between explicit overrides and dataclass defaults). | [Link](plans/active/ADR-003-BACKEND-API/reports/2025-10-20T150020Z/phase_e_governance_spec_redline/spec_redline.md) | Active |
| CONFIG-LOGGER-001 | 2025-10-24 | logger, execution-config, lightning, mlflow | PyTorch training uses CSVLogger by default (`PyTorchExecutionConfig.logger_backend='csv'`) to capture train/validation metrics from Lightning `self.log()` calls, replacing prior `logger=False` which discarded metrics. Allowed backends: `csv` (zero deps, CI-friendly), `tensorboard` (requires tensorboard from TF install), `mlflow` (requires mlflow package + server), `none` (disable). Legacy `--disable_mlflow` flag deprecated with DeprecationWarning mapping to `--logger none`. MLflow migration to Lightning MLFlowLogger tracked as Phase EB3.C4 backlog. Decision rationale and implementation evidence in governance decision approval record. | [Link](plans/active/ADR-003-BACKEND-API/reports/2025-10-20T153300Z/phase_e_execution_knobs/2025-10-23T110500Z/decision/approved.md) | Active |
| EXEC-ACCUM-001 | 2025-11-13 | pytorch, lightning, manual-optimization | Lightning manual optimization (PtychoPINN_Lightning sets `automatic_optimization=False`) is incompatible with `Trainer(accumulate_grad_batches>1)`. Passing `--torch-accumulate-grad-batches` > 1 causes `MisconfigurationException: Automatic gradient accumulation is not supported for manual optimization`. Treat the flag as unsupported for PyTorch backend until Lightning support lands: fail fast or clamp to 1 with a clear warning. | [Link](plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/red/blocked_20251113T184100Z_manual_optim_accum.md) | Active |
| DATA-SUP-001 | 2025-11-13 | supervised, labels, data-contract | Supervised PyTorch mode expects dataloader batches with `label_amp`/`label_phase`. Experimental fly001 NPZ datasets and the minimal CLI fixture omit those keys, leading to `KeyError: 'label_amp'` in `PtychoPINN_Lightning.training_step`. Either supply labeled synthetic NPZ (per DATA-001) or block supervised runs with an actionable error until labeled data is available. | [Link](plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/red/blocked_20251113T184300Z_supervised_data_contract.md) | Active |
| DEVICE-MISMATCH-001 | 2025-11-13 | pytorch, inference, accelerator | RESOLVED â€” Commit 85478a67 updates `scripts/inference/inference.py` and `ptycho_torch/inference.py` to call `model.to(device)`/`model.eval()` in both the CLI and helper, adds regression tests, and proves CUDA inference succeeds (`cli/pytorch_cli_smoke_training/inference_cuda.log`, `green/pytest_pytorch_inference_device.log`). | [Link](plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/analysis/artifact_inventory.txt) | Resolved |
| BUG-TF-001 | 2025-10-16 | shape-mismatch, gridsize, tests | Gridsize > 1 yields channel mismatches unless `params.cfg['gridsize']` is populated before `generate_grouped_data`; verify config vs params values. | [Link](docs/debugging/TROUBLESHOOTING.md#shape-mismatch-errors) | Active |
| DATA-001 | 2025-10-16 | data-contract, npz, io | All NPZ datasets must follow the canonical specification (keys, dtypes, normalization); deviations caused silent inference failures. | [Link](specs/data_contracts.md) | Active |
| NORMALIZATION-001 | 2025-10-16 | scaling, physics, preprocessing | Three independent normalization systems (physics, statistical, display) must never be mixed; applying scaling in the wrong stage created double-scaling bugs. | [Link](docs/DEVELOPER_GUIDE.md#35-normalization-architecture-three-distinct-systems) | Active |
| STUDY-001 | 2025-10-16 | fly64, baseline, generalization | On fly64 experiments the baseline model outperformed PtychoPINN by ~6â€“10 dB, contradicting expectations and motivating architecture review. | [Link](docs/FLY64_GENERALIZATION_STUDY_ANALYSIS.md#key-findings) | Active |
| ACCEPTANCE-001 | 2025-11-11 | phase-d, geometry, spacing, dense-view | Dense fly64 overlap runs cannot meet the legacy 10â€¯% minimum acceptanceâ€”bounding-box math caps the dense view at â‰ˆ0.96â€¯% (42/5088) for the 38.4â€¯px thresholdâ€”so `generate_overlap_views` must compute a geometry-aware acceptance floor (area Ã· packing discs) and log `geometry_acceptance_bound` + `effective_min_acceptance` in the metrics bundle before proceeding. | [Link](plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md) | Active |
| OVERSAMPLING-001 | 2025-10-16 | oversampling, gridsize, combinatorics | Oversampling only works when `gridsize > 1` and `K > C`; otherwise requested groups can never exceed raw images. | [Link](docs/debugging/TROUBLESHOOTING.md#oversampling-not-working) | Active |
| MIGRATION-001 | 2025-10-16 | params-removal, refactor, strategy | 66+ files still depend on `params.cfg`; migration plan is to eliminate new uses, document remaining ones, then remove the dependency. | [Link](docs/debugging/QUICK_REFERENCE_PARAMS.md#the-66-file-problem) | Active |
| PROCEDURE-001 | 2025-10-16 | review, defensive-coding | Flag hidden `params` reads and undocumented dependencies during code review; insist on explicit parameters or documented prerequisites. | [Link](docs/debugging/QUICK_REFERENCE_PARAMS.md#red-flags-in-code-review-ðŸš©) | Active |
| FORMAT-001 | 2025-10-17 | data-contract, npz, legacy-format, transpose | Some NPZ datasets use legacy (H,W,N) diffraction array format instead of DATA-001 compliant (N,H,W); caused IndexError in PyTorch dataloader when nn_indices referenced global positions beyond first dimension. Auto-transpose heuristic added to both `_get_diffraction_stack()` and `npz_headers()` to detect and fix at runtime. | [Link](plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-17T230724Z/callchain/summary.md) | Active |
| TYPE-PATH-001 | 2025-11-06 | pytorch, path, type-safety, config | PyTorch workflows failed with AttributeError/TypeError when string paths from TrainingConfig were passed to functions expecting Path objects. Root cause: ptycho_torch/workflows/components.py:650,682 called functions with raw string paths (config.train_data_file, config.output_dir) instead of wrapping with Path(). Symptom: 'str' object has no attribute 'exists' and unsupported operand type(s) for /. Fix: Wrap path parameters with Path() at call sites before invoking downstream helpers. Prevention: Normalize TrainingConfig/InferenceConfig path fields via Path() in constructors or apply runtime coercion at module boundaries. | [Link](plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-06T150500Z/phase_e_training_bundle_real_runs_exec/summary.md) | Active |
| PHASEC-METADATA-001 | 2025-11-06 | phase-c, metadata, validator, orchestration | `run_phase_g_dense.py` still expects Phase C outputs in legacy `dose_*_{train,test}/fly64_<split>_simulated.npz` directories; the refreshed generator now writes `data/phase_c/dose_<dose>/{patched,patched_train,patched_test}.npz` with `_metadata`. The guard falsely blocks dense relaunches until it scans the new layout and ensures `_metadata` on the patched splits. | [Link](plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-06T081826Z/phase_c_metadata_guard_blocker/cli/blocker_phase_c_metadata.log) | Active |
| TEST-CLI-001 | 2025-11-10 | tdd, cli-validation, orchestration, regression-guard | Orchestrator-level CLI validation requires explicit test fixtures for RED/GREEN cycles and must enforce complete log bundles (phase banners + SUCCESS sentinel + dose/view-specific filenames). When adding validation to artifact verifiers, create both RED (missing/wrong patterns) and GREEN (complete artifacts) test cases with realistic log content including all required markers. **Filename patterns MUST match orchestrator output**: phase_e_baseline_gs1_dose{dose}.log, phase_e_{view}_gs2_dose{dose}.log, phase_f_{view}_train.log, etc. (not generic phase_e_baseline.log). Helper logs (aggregate_report_cli.log, metrics_digest_cli.log) and completion sentinels ("complete" marker) are also required. Test isolation tip: GREEN tests should validate only the specific check under test, not entire bundle completeness (use focused assertions on check['valid'] field rather than exit_code==0). | [Link](plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/verify_dense_pipeline_artifacts.py:437-596) | Active |
| PREVIEW-PHASE-001 | 2025-11-11 | highlights, preview, validator, phase-only | The dense Phase G preview artifact (`analysis/metrics_delta_highlights_preview.txt`) must contain **only** the four phase deltas (MS-SSIM/MAE vs Baseline/PtyChi) with explicit Â± signs; any `amplitude` text or extra tokens indicates corruption and must fail validation. Existing verifier logic only checked for the presence of formatted numbers, so previews that regressed back to amplitude-inclusive lines could slip through. Harden `validate_metrics_delta_highlights` (and tests) to enforce phase-only content and surface actionable metadata in reports. | [Link](plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-11T005802Z/phase_g_dense_full_execution_real_run/plan/plan.md) | Active |


## DATA-002 - NPZ Metadata Pickle Requirement
**Category:** Data I/O  
**Impact:** Phase Câ†’Dâ†’E pipeline execution  
**Location:** studies/fly64_dose_overlap/{overlap.py:388, training.py:409,416}  
**Date:** 2025-11-11

### Issue
Phase C datasets include a `_metadata` field (dtype=object) containing JSON provenance strings. NumPy 1.16+ defaults to `allow_pickle=False` for security, causing `ValueError: Object arrays cannot be loaded when allow_pickle=False` when consuming these NPZ files downstream.

### Solution
Add `allow_pickle=True` parameter to all `np.load()` calls that read Phase C outputs:
```python
with np.load(path, allow_pickle=True) as data:
    data_dict = {k: data[k] for k in data.keys()}
```

### Context
- Phase C generation (studies/fly64_dose_overlap/generation.py) saves metadata as object array
- Phase D (overlap.py) and Phase E (training.py) validation consume these NPZs  
- Security: object arrays are trusted since they're generated internally, not user-supplied

### Related
- DATA-001 (data contract compliance)
- Commit: 5cd130d3
