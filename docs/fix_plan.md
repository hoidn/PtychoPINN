# PtychoPINN Fix Plan Ledger (Condensed)

**Last Updated:** 2025-11-16 (Galph s=279)
**Active Focus:** STUDY-SYNTH-FLY64-DOSE-OVERLAP-001 ‚Äî Synthetic fly64 dose/overlap study [ready_for_implementation] (Chunked Baseline inference is merged in `scripts/compare_models.py` (`--baseline-chunk-size`, `--baseline-predict-batch-size`, DIAGNOSTIC logging; `docs/findings.md:BASELINE-CHUNKED-001`) and the translation guard is still green, yet the canonical hub still reflects the pre-chunked dense-test evidence: `analysis/dose_1000/dense/test/comparison_metrics.csv` and `analysis/metrics_summary.json` have blank Baseline rows, `cli/aggregate_report_cli.log` fails with ‚ÄúRequired models missing: Baseline‚Äù, `cli/run_phase_g_dense_post_verify_only.log` trips PREVIEW-PHASE-001 because the preview never regenerated, and `analysis/verification_report.json` reports `n_valid=0/10`. Ralph must now (1) rerun the translation selector, (2) execute the debug-limited compare_models commands and then the full dense train/test runs with `--baseline-chunk-size 256 --baseline-predict-batch-size 16` to capture non-zero DIAGNOSTIC stats plus populated Baseline rows, and (3) immediately continue through the Phase‚ÄØD acceptance selectors ‚Üí counted `run_phase_g_dense.py --clobber` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only` sweep until `{analysis}` contains the SSIM grid/verification/highlights/preview/inventory bundle and `analysis/verification_report.json` reads 10/10. Every failure or missing artifact must land in `$HUB/red/blocked_<timestamp>.md` with the exact command + error signature (TEST-CLI-001 / PREVIEW-PHASE-001).

---

## [FIX-PYTORCH-FORWARD-PARITY-001] Stabilize Torch Forward Patch Parity
- Depends on: INTEGRATE-PYTORCH-PARITY-001 (PyTorch backend API parity reactivation), FIX-COMPARE-MODELS-TRANSLATION-001 (translation batching guardrails)
- Priority: High
- Status: pending ‚Äî instrumentation and scaling alignment plan prepared; awaiting implementation loops.
- Owner/Date: Ralph/2025-11-13
- Working Plan: `plans/active/FIX-PYTORCH-FORWARD-PARITY-001/implementation.md`
- Notes: PyTorch inference still emits impulse-like patches even after per-patch normalization; this focus adds structured instrumentation, fixes scaling/object_big defaults, and proves TF vs Torch parity before touching stitching (POLICY-001 / CONFIG-001 enforced).
- Latest Attempt (2025-11-13T000000Z): planning ‚Äî Created the implementation plan and Reports Hub skeleton; no code changes yet.

---

## [FIX-PYTEST-SUITE-REALIGN-001] Pytest Suite Realignment & CLI Guardrails
- Depends on: ‚Äî
- Priority: High (unblocks the guarded baseline integration test, Phase‚ÄØG dense orchestrator suite, and PyTorch workflow regressions)
- Status: pending ‚Äî implementation plan drafted; awaiting first Do Now loop
- Owner/Date: Ralph/2025-11-14
- Working Plan: `plans/active/FIX-PYTEST-SUITE-REALIGN-001/implementation.md`
- Notes: Fixes the Literal CLI parsing regression in `parse_arguments`, updates Phase‚ÄØG orchestrator tests for the programmatic Phase‚ÄØD path, and refreshes PyTorch CLI/workflow tests so they match the new execution-config plumbing (CONFIG-001 / POLICY-001 / DEVICE-MISMATCH-001). Avoid modifying `ptycho/model.py`, `ptycho/diffsim.py`, or `ptycho/tf_helper.py` without explicit scope.
- Latest Attempt (2025-11-14T000000Z): planning ‚Äî Created the implementation plan and Reports Hub skeleton per prompts/plan_generation.md.

---

Housekeeping: This ledger is intentionally brief. Detailed ‚ÄúAttempts History‚Äù entries were moved to archives to keep decision‚Äëmaking crisp.

- Current archive snapshot: `docs/archive/2025-11-06_fix_plan_archive.md`
- Earlier snapshots: `docs/archive/2025-10-17_fix_plan_archive.md`, `docs/archive/2025-10-20_fix_plan_archive.md`
- Artifact/plan policy (2025-11-12): Each focus keeps a single evolving plan file (see ‚ÄúWorking Plan‚Äù below). Reuse the same reports hub until you capture a new milestone; append new evidence and summaries into the existing directory instead of creating a fresh timestamp every loop.

Use the ‚ÄúWorking Plan‚Äù and the per‚Äëinitiative `summary.md` for day‚Äëto‚Äëday artifacts. Link to any bulky evidence stored externally or under `.artifacts/`.

---

## [INDEPENDENT-SAMPLING-CONTROL-PHASE6] Independent sampling control ‚Äî Phase 6 guardrails
- Depends on: Phases 1‚Äì5 (subsampling plumbing + docs) already complete per `plans/active/independent-sampling-control/implementation.md`
- Priority: High (unblocks users from explicitly managing oversampling + provides hard evidence before reattempting Phase G)
- Status: done ‚Äî Phase 6A guardrails landed (explicit `enable_oversampling`/`neighbor_pool_size` plumbing, RawData gating per OVERSAMPLING-001, extended pytest coverage, and refreshed docs).
- Owner/Date: Ralph/2025-11-12 (handoff prepared by Galph)
- Working Plan: `plans/active/independent-sampling-control/implementation.md`
- Historical reports hub (Phase 6 hardening): `plans/active/independent-sampling-control/reports/2025-11-12T005637Z/phase6_hardening/` (do not create new hubs)
- Test Strategy: `plans/active/independent-sampling-control/test_tracking.md`
- Constraints: Maintain CONFIG-001 (update_legacy_dict before legacy code), OVERSAMPLING-001 (require gridsize>1 and K‚â•C), and do not regress existing sampling modes (legacy `n_images`, independent `n_subsample`+`n_groups`); avoid touching `ptycho/model.py`, `ptycho/diffsim.py`, `ptycho/tf_helper.py`.
- Notes: `RawData.generate_grouped_data` currently auto-enters oversampling when `nsamples > n_points`; Phase 6A must require an explicit opt-in flag plus pool sizing, emit actionable logs, and capture doc/examples per `docs/initiatives/independent_sampling_control/phase6_plan.md` and `docs/SAMPLING_USER_GUIDE.md`.

- Latest Attempt (2025-11-12T011535Z): review_or_housekeeping ‚Äî Re-read docs/index.md; docs/findings.md (OVERSAMPLING-001, CONFIG-001, DATA-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/TESTING_GUIDE.md (oversampling coverage); docs/COMMANDS_REFERENCE.md; docs/SAMPLING_USER_GUIDE.md; docs/fix_plan.md; input.md; `plans/active/independent-sampling-control/implementation.md`; `test_tracking.md`; and the Phase 6 hub (`summary.md`, `green/pytest_enable_flag.log`, `green/pytest_neighbor_pool_size_guard.log`). Verified commit `7e99cebc` adds the enable_oversampling/neighbor_pool_size config fields, RawData gating, CLI plumbing, extended pytest suite, and doc updates. Marked the checklist complete in the plan, prepended the hub summary with the Turn Summary, and freed this focus so the active Do Now can return to the Phase G dense rerun blocker. No further actions required unless Phase 6B scope appears.

---

## [STUDY-SYNTH-FLY64-DOSE-OVERLAP-001] Synthetic fly64 dose/overlap study
- Depends on: FIX-COMPARE-MODELS-TRANSLATION-001 (‚úÖ complete), Baseline inference center/diagnostics (‚úÖ via `BASELINE-OFFSET-001`), counted dense rerun (üöß)
- Priority: High
- Status: **ready_for_implementation** ‚Äî Chunked Baseline inference is merged (`scripts/compare_models.py` commit `26c26402`, Finding `BASELINE-CHUNKED-001`) and the translation guard stayed green during the landing (`plans/active/.../green/pytest_compare_models_translation_fix_v15.log`). The debug-only probes also show healthy Baseline stats, yet the canonical dense train/test artifacts inside this repo still reflect the pre-chunked run: `analysis/dose_1000/dense/test/comparison_metrics.csv` has blank Baseline rows, `analysis/metrics_summary.json` lacks Baseline entries, and `analysis/verification_report.json` remains 0/10 because no counted Phase‚ÄØG rerun has been executed with the new flags. Ralph now needs to rerun the debug-limited compare_models commands plus the full train/test runs with `--baseline-chunk-size 256 --baseline-predict-batch-size 16`, confirm DIAGNOSTIC stats + CSV rows in `analysis/dose_1000/dense/{split}/logs/logs/debug.log` and `.../comparison_metrics.csv`, then immediately execute the Phase‚ÄØD acceptance selectors, counted `run_phase_g_dense.py --clobber`, metrics reporters, and `--post-verify-only` helper until `{analysis}` contains the SSIM grid / verification / highlights / preview / inventory bundle required by PREVIEW-PHASE-001 / TEST-CLI-001 / TYPE-PATH-001. Capture `$HUB/red/blocked_<timestamp>.md` with the failing command + log snippet if any step regresses.
- Latest Attempt (2025-11-16T073500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/ptychodus_api_spec.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary plus `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/dose_1000/dense/train/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, `cli/run_phase_g_dense_post_verify_only.log`, and `analysis/dose_1000/dense/test_debug/logs/logs/debug.log`. Reality: the chunked debug runs remain healthy (non-zero DIAGNOSTIC stats) and dense-train CSVs have Baseline rows, but the canonical dense-test CSV/metrics summary are still blank so aggregate_report/post-verify stay red and verification is 0/10. Updated this ledger, the plan, summary, and input.md so Ralph reruns the translation selector ‚Üí chunked debug/full compare_models (stop + `$HUB/red/` if Baseline stats regress) ‚Üí Phase‚ÄØD selectors ‚Üí clobbered `run_phase_g_dense.py` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only` until `{analysis}` contains the SSIM/verification/highlights/preview/inventory bundle or a blocker documents the failing command/signature.
- Latest Attempt (2025-11-16T050500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary plus `analysis/dose_1000/dense/test/comparison_metrics.csv`, `analysis/metrics_summary.json`, `analysis/verification_report.json`, `cli/aggregate_report_cli.log`, and `cli/run_phase_g_dense_post_verify_only.log`. Reality: only the debug-limited chunked runs landed‚Äîdense-train metrics now include Baseline rows, but dense-test CSV/metrics summary remain blank so the aggregate metrics helper and `--post-verify-only` chain still fail and verification stays 0/10. Updated this ledger, the plan, summary, and input.md so Ralph now reruns the translation guard ‚Üí chunked debug/full compare_models (with the documented chunk/batch sizes, stopping to file `$HUB/red/` blockers if Baseline stats regress) ‚Üí Phase‚ÄØD selectors ‚Üí clobbered `run_phase_g_dense.py` ‚Üí metrics helpers ‚Üí fully parameterized `--post-verify-only` until `{analysis}` holds the SSIM/verification/highlights/preview/inventory bundle or a blocker is logged with the exact command/error.
- Latest Attempt (2025-11-16T010000Z): implementation ‚Äî Added chunked Baseline inference (`scripts/compare_models.py` commit `26c26402`) with `--baseline-chunk-size`/`--baseline-predict-batch-size`, per-chunk DIAGNOSTIC logging, and automatic fallback (`docs/findings.md:BASELINE-CHUNKED-001`). Translation regression selectors stayed green (`plans/active/.../green/pytest_compare_models_translation_fix_v15.log`). However, the new chunked path has not been executed from this repo yet, so `analysis/dose_1000/dense/test/comparison_metrics.csv` and `analysis/metrics_summary.json` are still missing Baseline rows and the Phase‚ÄØG bundle remains absent.
- Latest Attempt (2025-11-16T031500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / BASELINE-CHUNKED-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}; hub summary + blocker file. Reality: commits landed chunked inference but the hub still reflects the pre-chunked compare_models runs (Baseline rows blank, verification 0/10). Updated this ledger, the plan, and `input.md` so Ralph now focuses on (1) rerunning the translation guard and debug/full compare_models commands with `--baseline-chunk-size 256 --baseline-predict-batch-size 16`, (2) verifying the Baseline metrics + DIAGNOSTIC lines exist for both splits before touching Phase‚ÄØD, and (3) running the dense acceptance selectors, counted `run_phase_g_dense.py --clobber`, metrics reporters, and fully parameterized `--post-verify-only` until `{analysis}` holds the SSIM/verification/highlights/preview/inventory bundle with `verification_report.json` at 10/10; blockers go under `$HUB/red/`.
- Latest Attempt (2025-11-15T200500Z): planning ‚Äî Dense-test compare_models still halts with `DIAGNOSTIC baseline_output stats: mean=0.000000 ... nonzero_count=0/341835776` while dense-train records non-zero outputs (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/{test,train}/logs/logs/debug.log:534-550`), so `analysis/metrics_summary.json` and `analysis/dose_1000/dense/test/comparison_metrics.csv` remain Baseline-empty, `report_phase_g_dense_metrics.py` keeps failing (`.../cli/aggregate_report_cli.log:1-11`), and the post-verify helper immediately aborts because `analysis/metrics_delta_highlights_preview.txt` never existed (`.../cli/run_phase_g_dense_post_verify_only.log:1-23`). A targeted `n_images=64` container probe showed flattened `baseline_offsets` for dense-test shifted to ‚âà273‚ÄØ¬±‚ÄØ86‚ÄØpx versus ‚âà185‚ÄØ¬±‚ÄØ72‚ÄØpx for dense-train (`.../data/phase_c/dose_1000/patched_{train,test}.npz`), so the refreshed Do‚ÄØNow forces offset-centering + debug flags in `scripts/compare_models.py`, reruns dense-train/dense-test compare_models until canonical Baseline rows appear in CSV/JSON, then repeats the Phase‚ÄØD guard, counted `run_phase_g_dense.py --clobber`, metrics helpers, and fully parameterized `--post-verify-only` before updating the ledger. Blockers must be captured under `$HUB/red/blocked_<timestamp>.md` with the command/error signature if Baseline stats regress or preview/verifier artifacts remain missing.
- Latest Attempt (2025-11-13T200447Z): implementation ‚Äî Instrumented scripts/compare_models.py (commit e830a5be) with RuntimeError assertion that halts when Baseline outputs are zero, plus canonical model ID mapping (`PtyChi` not `"Pty-chi (algorithm)"`). Translation guard GREEN (2/2 passed, 6.21s). Train split succeeds: Baseline input mean=0.112964 ‚Üí output mean=0.003092 (1.4M nonzero), CSV contains `Baseline` and `PtyChi` canonical IDs with valid metrics. Test split fails: Baseline input mean=0.112671 (17.8M nonzero) ‚Üí output mean=0.0 (0 nonzero), triggering RuntimeError with diagnostic stats. Blocker filed (`red/blocked_20251113T200447Z_baseline_test_zero_instrumented.md`) confirming TensorFlow/model runtime issue beyond compare_models.py scope. Status: **blocked** pending decision on Baseline model investigation vs proceeding with PINN vs PtyChi only.
- Latest Attempt (2025-11-15T123000Z): planning ‚Äî Dense-train compare_models logs confirm Baseline outputs are non-zero (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/train/logs/logs/debug.log:425-537`) while dense-test still returns zero-valued predictions despite healthy inputs (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/dose_1000/dense/test/logs/logs/debug.log:426-540`), so `analysis/metrics_summary.json` and `analysis/dose_1000/dense/test/comparison_metrics.csv` remain Baseline-empty and the metrics helper + preview keep failing (`plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/aggregate_report_cli.log:1-9`, `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/run_phase_g_dense_post_verify_only.log:1-19`). Updated the plan/summary/docs/input so Ralph must add a fast Baseline-debug loop (instrument `scripts/compare_models.py`, optionally add `--baseline-debug-limit`, log the first patch amplitude/phase), stop with `$HUB/red/blocked_<timestamp>.md` if `DIAGNOSTIC baseline_output` stays zero, and only proceed to the Phase‚ÄØD/Phase‚ÄØG rerun once `analysis/dose_1000/dense/{split}/comparison_metrics.csv` and `analysis/metrics_summary.json` contain canonical Baseline/PtyChi rows.
- Latest Attempt (2025-11-15T041500Z): planning ‚Äî Dense-test compare_models logs still report non-zero inputs but zero outputs (mean=0.112671 in, mean=0.0 out at `analysis/dose_1000/dense/test/logs/logs/debug.log:421-535`), so `analysis/metrics_summary.json` keeps blank Baseline rows, `analysis/dose_1000/dense/test/comparison_metrics.csv` lists empty Baseline metrics, `cli/aggregate_report_cli.log:1-11` fails with ‚ÄúRequired models missing for delta computation: Baseline‚Äù, and `cli/run_phase_g_dense_post_verify_only.log:4-23` continues to abort because the preview file is missing. Updated the plan/summary/input so Ralph must instrument `scripts/compare_models.py` with tf.debugging asserts + canonical IDs, stop immediately with `$HUB/red/blocked_<timestamp>.md` if Baseline remains zero, verify the CSV/JSON Baseline metrics before rerunning `report_phase_g_dense_metrics.py`, and only invoke the SSIM/verification helper after `analysis/metrics_delta_highlights_preview.txt` exists.
- Latest Attempt (2025-11-15T010500Z): planning ‚Äî Audited `analysis/verification_report.json:1-80` (still `n_valid=0/10`), `analysis/dose_1000/dense/test/logs/logs/debug.log:312-535` (Baseline inputs non-zero but outputs mean/max/nonzero=0), `analysis/metrics_summary.json` (Baseline rows empty and `Pty-chi (pty-chi)` alias), `cli/aggregate_report_cli.log:1-9` (metrics reporter fails) and `cli/run_phase_g_dense_post_verify_only.log:1-15` (preview missing). Updated plan/summary/docs/input so the Do‚ÄØNow now enforces the translation guard ‚Üí compare_models diagnostics with stop-on-zero Baseline outputs ‚Üí Phase‚ÄØD acceptance selectors ‚Üí counted `run_phase_g_dense.py --clobber` ‚Üí metrics reporters with canonical-ID verification ‚Üí `run_phase_g_dense.py --post-verify-only`, with blockers logged under `$HUB/red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-13T193000Z): verification ‚Äî Translation regression tests remain GREEN (green/pytest_compare_models_translation_fix_v8.log: 2/2 PASSED, 6.22s). Confirmed diagnostic logging from previous loop successfully captures the issue: Baseline **inputs** are valid for both splits (mean~0.112, nonzero>17M), train split produces valid **outputs** (mean=0.003092, nonzero=1.4M), but test split outputs **all zeros** (mean=0.0, nonzero=0). Updated blocker doc confirming this is a TensorFlow/model runtime issue beyond compare_models.py instrumentation scope. No code changes made this loop (diagnostic-only verification). Status remains **blocked** pending baseline model numerical stability investigation.
- Latest Attempt (2025-11-14T235900Z): planning ‚Äî Baseline dense-test reconstructions remain all zeros (`analysis/dose_1000/dense/test/reconstructions_aligned.npz` + `analysis/dose_1000/dense/test/reconstructions.npz`), so `analysis/metrics_summary.json` never records `Baseline` rows and `report_phase_g_dense_metrics.py` still fails with ‚ÄúRequired models missing‚Äù (`cli/aggregate_report_cli.log`). `run_phase_g_dense.py --post-verify-only` also dies immediately because `analysis/metrics_delta_highlights_preview.txt` was never emitted (`cli/run_phase_g_dense_post_verify_only.log` ‚Üî `cli/ssim_grid_cli.log`), keeping `analysis/verification_report.json` stuck at 0/10. Added plan_update‚ÄØv1.7 plus summary/input updates so Ralph must instrument/fix `scripts/compare_models.py` (log + guard Baseline stats) before rerunning both compare_models splits; after that he still has to rerun the Phase‚ÄØD guards, execute `run_phase_g_dense.py --clobber`, regenerate the metrics/digest/preview bundle, and only then rerun the fully parameterized `--post-verify-only` until SSIM/verification/highlights/metrics/preview/artifact-inventory artifacts exist and `verification_report.json` reports 10/10 (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md`).
- Latest Attempt (2025-11-14T021842Z): planning ‚Äî Hub audit shows the counted rerun is still incomplete: `analysis/verification_report.json` reports `n_valid=0/10` and still lists `metrics_summary.*` as missing (lines 1‚Äë19), the actual `analysis/metrics_summary.json` contains only PtychoPINN rows plus a `‚ÄúPty-chi (pty-chi)‚Äù` alias while every Baseline metric field is empty (lines 48‚Äë105), `analysis/dose_1000/dense/test/logs/logs/debug.log` proves the dense **test** Baseline recon is all zeros (lines 600‚Äë609) so `analysis/dose_1000/dense/test/comparison_metrics.csv` keeps blank Baseline rows (lines 8‚Äë18), `report_phase_g_dense_metrics.py` therefore fails with ‚ÄúRequired models missing for delta computation: Baseline, PtyChi‚Äù (cli/aggregate_report_cli.log lines 1‚Äë11), and `run_phase_g_dense_post_verify_only.log` still dies under PREVIEW-PHASE-001 because `analysis/metrics_delta_highlights_preview.txt` never materialized (lines 12‚Äë23). Updated the plan/summary/input so Ralph must guard `/home/ollie/Documents/PtychoPINN`, rerun the translation pytest selector, regenerate both the train and test compare_models bundles with canonical model IDs per METRICS-NAMING-001 (filing `$HUB/red/blocked_<timestamp>.md` if Baseline amplitudes remain zero), rerun the Phase‚ÄØD acceptance pytest guards, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately replay `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py` so the metrics summary/digest/preview/artifact inventory exist, and only then run the fully parameterized `--post-verify-only` so `{analysis}` can finally collect the SSIM grid, verification logs, highlights, metrics, preview, and artifact inventory bundle required for `verification_report.json` to reach 10/10.
- Latest Attempt (2025-11-14T173500Z): planning ‚Äî Verified the translation evidence (`green/pytest_compare_models_translation_fix_v2.log`, `cli/phase_g_dense_translation_fix_{train,test}_v2.log`, `analysis/verification_report_translation_fix.json`) and audited the Phase‚ÄØG hub (`analysis/verification_report.json` still 0/10; `analysis/blocker.log` records `report_phase_g_dense_metrics.py` failing because Baseline/PtyChi deltas are missing). Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md}`, this ledger, and input.md so Ralph now (1) reruns `run_phase_g_dense.py --clobber --dose 1000 --view dense --splits train test`, (2) immediately executes the fully parameterized `--post-verify-only`, (3) replays `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py`, and (4) only stops once `{analysis}` contains the SSIM grid/verification/highlights/metrics/preview/inventory bundle with 10/10 validity (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md`).
- Latest Attempt (2025-11-14T223000Z): planning ‚Äî Rechecked `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/verification_report.json` (still `n_valid=0/10`), saw `analysis/metrics_summary.json` only contains new PtychoPINN vs PtyChi rows while all Baseline metric entries are empty, and `analysis/blocker.log` plus `cli/ssim_grid_cli.log` prove `bin/ssim_grid.py` dies immediately because `analysis/metrics_delta_highlights_preview.txt` never existed (PREVIEW-PHASE-001). Do‚ÄØNow remains ready_for_implementation: guard `/home/ollie/Documents/PtychoPINN`, rerun the guarded pytest selector, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately run the fully parameterized `--post-verify-only`, rerun `report_phase_g_dense_metrics.py` + `analyze_dense_metrics.py` so SSIM/verification/highlights/metrics/preview/inventory artifacts exist, and drop `$HUB/red/blocked_<timestamp>.md` with command/error signatures if anything still fails before `verification_report.json` reaches 10/10.
- Latest Attempt (2025-11-14T150800Z): planning ‚Äî Dwell hit Tier 2 and no new Ralph commit appeared, so we audited the hub, confirmed the `Translation` ValueError is still the blocking failure mode, and spun out FIX-COMPARE-MODELS-TRANSLATION-001 to own the implementation work. Return condition: once that focus delivers batched `ReassemblePatchesLayer` + GREEN regression/tests + successful `scripts/compare_models.py` executions for train/test, flip this item back to `ready_for_implementation` and resume the counted rerun (`run_phase_g_dense.py --clobber`, `--post-verify-only`, metrics/helpers per ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001).
- Latest Attempt (2025-11-14T152000Z): housekeeping ‚Äî Verified FIX-COMPARE-MODELS-TRANSLATION-001 is complete with all exit criteria met: commits a80d4d2b + bf3f1b07 in repo, pytest selector GREEN (plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/green/pytest_compare_models_translation_fix_v2.log shows 2/2 PASSED), train/test compare_models exit 0 with refreshed metrics (verification_report_translation_fix.json shows 10/10), blocker_resolved.log documents resolution. Updated STUDY-SYNTH status from blocked to ready_for_implementation. Next: execute counted Phase G rerun per return condition above.



---

## [FIX-COMPARE-MODELS-TRANSLATION-001] Dense Phase G translation guard
- Depends on: STUDY-SYNTH-FLY64-DOSE-OVERLAP-001 (unblocked)
- Priority: Critical (Tier 2 mitigation)
- Status: done ‚Äî All exit criteria met. Batched reassembly (a80d4d2b) + XLA streaming (bf3f1b07) verified. Regression tests GREEN (2/2 in 6.12s), train/test compare_models exit 0 with refreshed metrics. Verification report 10/10 valid. STUDY-SYNTH unblocked for counted Phase G rerun.
- Owner/Date: Ralph / 2025-11-13 (completed)
- Working Plan: `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/implementation.md`
- Summary: `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/summary.md`
- Reports Hub: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/`
- Exit criteria (‚úÖ ALL MET): (a) both regression tests GREEN (pytest_compare_models_translation_fix_v2.log: 2/2 PASSED in 6.12s); (b) train/test `scripts/compare_models.py` exit 0 with refreshed metrics (train: MS-SSIM phase=0.054 MAE=0.234; test: MS-SSIM phase=0.048 MAE=0.242); (c) `analysis/blocker_resolved.log` documents resolution and `verification_report_translation_fix.json` shows 10/10; (d) padded-size/batching instrumentation logged in ptycho/tf_helper.py:955-965 with tf.debugging assertions; (e) STUDY-SYNTH focus updated to ready_for_implementation.
- Latest Attempt (2025-11-14T173500Z): review_or_housekeeping ‚Äî Re-read `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md}`, `green/pytest_compare_models_translation_fix_v2.log`, `cli/phase_g_dense_translation_fix_{train,test}_v2.log`, and `analysis/verification_report_translation_fix.json`, confirmed all exit criteria remain satisfied, and refreshed this ledger so STUDY-SYNTH is the active focus for the counted Phase‚ÄØG rerun.
- Latest Attempt (2025-11-13T170500Z): implementation (COMPLETE) ‚Äî Verified the two fixes (a80d4d2b batched reassembly, bf3f1b07 XLA streaming) with fresh evidence: pytest selector GREEN (2/2 passed, 6.12s), train split compare_models exit 0 (MS-SSIM phase=0.054, MAE phase=0.234), test split compare_models exit 0 (MS-SSIM phase=0.048, MAE phase=0.242). Created `analysis/verification_report_translation_fix.json` (10/10) and `analysis/blocker_resolved.log`. Exit criteria met: regression tests GREEN, both CLI runs successful with refreshed metrics, blocker cleared. Prepended Turn Summary to initiative summary. Status: done.
- Latest Attempt (2025-11-14T005300Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001 / TYPE-PATH-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/GRIDSIZE_N_GROUPS_GUIDE.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; docs/fix_plan.md; plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md,reports/pytest_translation_fix.log}; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/analysis/verification_report.json,analysis/blocker.log,cli/phase_g_dense_translation_fix_train.log}; input.md; galph_memory.md. Reality check: no new Ralph evidence since Nov‚ÄØ13 ‚Äî the pytest log still dies at `ptycho/tf_helper.py:959`, `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log` have not been rerun, and `analysis/verification_report.json` remains `n_valid=0`. Updated the plan (plan_update v1.5), ledger, and input so Ralph must add a patch-count gate + tf.print diagnostics in `ReassemblePatchesLayer` and `_reassemble_position_batched` before repeating the CLI/tests, keeping all evidence in the existing hub. Status: ready_for_implementation (dwell=4; next loop must drive production work or escalate per Tier‚ÄØ2).
- Latest Attempt (2025-11-14T153500Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/DEVELOPER_GUIDE.md; docs/COMMANDS_REFERENCE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/GRIDSIZE_N_GROUPS_GUIDE.md; docs/architecture.md; specs/data_contracts.md; specs/overlap_metrics.md; specs/ptychodus_api_spec.md; docs/fix_plan.md; plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{implementation.md,summary.md,reports/pytest_translation_fix.log}; plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{summary.md,implementation.md}; hub artifacts (`analysis/verification_report.json`, `analysis/blocker.log`, `cli/phase_g_dense_translation_fix_{train,test}.log`). Reality: pytest still dies at `_reassemble_position_batched`, and the train/test compare_models logs never progressed past argument parsing because the command used the unsupported `--split` flag, so no new evidence was captured. Updated the plan + Do Now to remove `--split`, reiterate the batching instrumentation (single `tf.image.resize_with_crop_or_pad`, padded_size logging, `tf.debugging.assert_equal` guards), and restated the required pytest selector + CLI reruns with blocker logging expectations. Status: ready_for_implementation (dwell=3, next loop must be implementation).
- Latest Attempt (2025-11-14T123500Z): planning ‚Äî Re-read docs/index.md, docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/DEVELOPER_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/overlap_metrics.md, specs/data_contracts.md, the initiative plan/summary, `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/reports/pytest_translation_fix.log`, and the hub evidence (`analysis/verification_report.json`, `analysis/dose_1000/dense/train/logs/logs/debug.log`, `cli/phase_g_dense_translation_fix_train.log`). Reality check: pytest still dies at `ptycho/tf_helper.py:959` ("{{__wrapped__AddV2}} required broadcastable shapes"), `{analysis}` still lacks SSIM/metrics bundles (`n_valid=0`), and no new CLI logs were produced since 2025-11-13. Updated the plan + Do Now so Ralph instruments `_reassemble_position_batched` (log padded_size, assert `tf.shape(canvas)==tf.shape(batch_result)`/dtype), replaces the per-element `tf.image.resize_with_crop_or_pad` with a batched call, and captures those diagnostics in the pytest log plus renewed train/test CLI runs. Status: ready_for_implementation.
- Latest Attempt (2025-11-14T150800Z): planning ‚Äî Tier 2 dwell enforcement created this focus. Drafted the Do Now: reproduce the failure via direct `scripts/compare_models.py` runs for train/test, update `ptycho/custom_layers.ReassemblePatchesLayer` (and helpers in `ptycho/tf_helper.py` as needed) to call the batched reassembly path, add a regression test that feeds a synthetic ‚â•5 k-patch tensor through the layer, and rerun the targeted CLI commands plus the guarded pytest selectors with logs under `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log` and `$HUB/green/pytest_compare_models_translation_fix.log`.
- Latest Attempt (2025-11-13T174400Z): planning ‚Äî Re-read docs/index.md, docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/COMMANDS_REFERENCE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, docs/DEVELOPER_GUIDE.md, docs/architecture.md, docs/findings.md (REASSEMBLY-BATCH-001 / ACCEPTANCE-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / DATA-001), docs/GRIDSIZE_N_GROUPS_GUIDE.md, specs/data_contracts.md, specs/ptychodus_api_spec.md, specs/overlap_metrics.md, and the initiative plan/summary. Reviewed `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/reports/pytest_translation_fix.log`, which shows `tests/study/test_dose_overlap_comparison.py::test_pinn_reconstruction_reassembles_full_train_split` still failing with `InvalidArgumentError: required broadcastable shapes` inside `_reassemble_position_batched` (B=159, N=138, C=4) while `test_pinn_reconstruction_reassembles_batched_predictions` remains GREEN. Updated the plan checklist (regression test already exists), refreshed input.md, and logged the blocker so Ralph can focus on hardening `ReassemblePatchesLayer`/`tf_helper`, re-running the guarded pytest selector, and capturing the train/test CLI evidence under `$HUB/cli/phase_g_dense_translation_fix_{split}.log`. Status: ready_for_implementation.
- Latest Attempt (2025-11-13T180500Z): maintenance ‚Äî Reverted commits `da91e466` / `087a9238` to undo the unintended `_reassemble_position_batched` semantics that broke TF integration. Updated the plan + guardrails so future batching work must call the existing helper (no modifications to `reassemble_patches` / `_flat_to_channel`), log crop events, and re-establish regression evidence (pytest selector + compare_models train/test logs) before reconnecting to STUDY-SYNTH. Status: ready_for_implementation (Do‚ÄØNow reset).
- Do Now:
  1. `export AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB="$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier"`
  2. Reproduce the failure with `PYTHONPATH="$PWD" python scripts/compare_models.py --pinn_dir "$HUB"/data/phase_e/dose_1000/dense/gs2 --baseline_dir "$HUB"/data/phase_e/dose_1000/baseline/gs1 --test_data "$HUB"/data/phase_c/dose_1000/patched_train.npz --output_dir "$HUB"/analysis/dose_1000/dense/train --ms-ssim-sigma 1.0 --tike_recon_path "$HUB"/data/phase_f/dose_1000/dense/train/ptychi_reconstruction.npz --register-ptychi-only --split train` (repeat for `--split test` and adjust `--output_dir`). Capture minimal error snippet in `$HUB/red/blocked_<timestamp>.md` if it still fails.
  3. Patch `ptycho/custom_layers.ReassemblePatchesLayer` so it calls `hh.mk_reassemble_position_batched_real` with a clearly documented batch-size guard (`total_patches > batch_size`). Do **not** touch `reassemble_patches`/`_flat_to_channel`; add an assertion/log so we know when the batched path engages.
  4. Enhance `_reassemble_position_batched` to derive `padded_size` from the kwarg or `params.get_padded_size()`, replace the per-element `tf.map_fn` resize with a single `tf.image.resize_with_crop_or_pad(batch_translated, padded_size, padded_size)` call, and emit shape/dtype diagnostics plus `tf.debugging.assert_equal(tf.shape(canvas), tf.shape(batch_result))` before `canvas + batch_result`. Log whenever a resize would crop translated data (counts + padded_size) so future runs are auditable.
  5. Extend `tests/study/test_dose_overlap_comparison.py` so the ‚â•5 k-patch regression asserts overlap/intensity conservation, then run `pytest tests/study/test_dose_overlap_comparison.py::{test_pinn_reconstruction_reassembles_batched_predictions,test_pinn_reconstruction_reassembles_full_train_split} -vv | tee "$HUB"/green/pytest_compare_models_translation_fix.log`.
  6. Re-run the train/test `scripts/compare_models.py` commands (same args as step‚ÄØ2, adjusting `--split`/`--output_dir`) and capture logs under `$HUB/cli/phase_g_dense_translation_fix_{train,test}.log`. Success criteria: exit‚ÄØ0, refreshed `analysis/dose_1000/dense/{train,test}/comparison_metrics.csv`, and the new shape instrumentation in the logs.
  7. Update `analysis/blocker.log`, `{analysis}/verification_report.json`, docs/fix_plan.md, `plans/active/FIX-COMPARE-MODELS-TRANSLATION-001/{summary.md,implementation.md}`, and galph_memory with MS-SSIM/MAE deltas + selector/command references before handing the hub back to STUDY-SYNTH.


- Latest Attempt (2025-11-12T004400Z): implementation (PARTIAL ‚Äî pipeline running) ‚Äî Confirmed `filter_dataset_by_mask` fix already in place (`studies/fly64_dose_overlap/overlap.py:225` checks `arr.ndim == 0` and broadcasts scalar metadata). Ran `test_filter_dataset_by_mask_handles_scalar_metadata` (PASSED 1.38s, saved to `$HUB/green/pytest_filter_dataset_by_mask.log`). Launched Phase C‚ÜíG dense pipeline with `PYTHONPATH=/home/ollie/Documents/PtychoPINN` to fix import path issue (background PID 5f48f9, started 2025-11-12T00:43:56Z). Pipeline archived stale Phase C outputs and is currently executing Phase C (Dataset Generation) with TensorFlow/CUDA initialized. Estimated completion: 30‚Äì120 minutes. Remaining steps: await pipeline completion, execute `--post-verify-only` chain, regenerate metrics helpers if needed, and verify `{analysis}` contains complete SSIM/verification/highlights/metrics/inventory bundle with MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas. Status: in_progress (long-running task). Artifacts: `$HUB/green/pytest_filter_dataset_by_mask.log` (‚úÖ), `$HUB/cli/run_phase_g_dense_stdout.log` (streaming), `$HUB/summary/summary.md` (‚úÖ).
- Attempt (2025-11-13T022400Z): planning ‚Äî `git status --porcelain` was clean, so I ran `timeout 30 git pull --rebase` (already up to date) and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/overlap_metrics.md, specs/data_contracts.md ¬ß12, docs/GRIDSIZE_N_GROUPS_GUIDE.md, the initiative plan, galph_memory.md, input.md, and the active Phase D/Phase G hub summaries + plans + `analysis/blocker.log` + `cli/phase_d_dense.log`. Reality check: the Phase D overlap metrics hub already contains gs1/gs2 CLI evidence (`summary/summary.md`, `analysis/artifact_inventory.txt`), so that checklist is complete, but the latest dense rerun fails immediately with `TypeError: len() of unsized object` at `studies/fly64_dose_overlap/overlap.py:194` because `filter_dataset_by_mask` applies a boolean mask to scalar metadata fields. Updated the implementation plan, hub plan/summaries, docs/fix_plan.md, and input.md so the ready_for_implementation Do Now now requires (1) hardening `filter_dataset_by_mask` to bypass scalars/zero-d arrays plus a regression in `tests/study/test_dose_overlap_overlap.py`, (2) rerunning the dense acceptance selector alongside the new regression, (3) executing `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `--post-verify-only`, and (4) rerunning the metrics helpers so `{analysis}` holds `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, `preview.txt`, and `analysis/artifact_inventory.txt` with MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas logged. Failures still belong under `$HUB/red/blocked_<timestamp>.md`.

<plan_update version="1.0">
  <trigger>Housekeeping: enforce interpreter discipline and reduce Phase C runtime</trigger>
  <focus_id>STUDY-SYNTH-FLY64-DOSE-OVERLAP-001</focus_id>
  <documents_read>docs/index.md, docs/DEVELOPER_GUIDE.md, CLAUDE.md, input.md, scripts/orchestration/README.md, plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md, plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py, studies/fly64_dose_overlap/generation.py</documents_read>
  <current_plan_path>plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md</current_plan_path>
  <proposed_changes>Adopt PYTHON-ENV-001 across orchestrators/wrappers/docs; add --dose/--doses to Phase C generator and pass dose from orchestrator; update Do Now accordingly</proposed_changes>
  <impacts>Eliminates ModuleNotFoundError via active interpreter; reduces Phase C time by filtering to a single dose; requires rerun of dense pipeline and light doc/test adjustments</impacts>
  <ledger_updates>Record commit 811f4264 as policy adoption; mark env blocker resolved; set Do Now to implement generator dose filter then execute single-dose run</ledger_updates>
  <status>approved</status>
</plan_update>

‚Ä¢ Spec Update (2025-11-12): Adopt overlap‚Äëdriven metrics and explicit sampling controls for Phase D; deprecate dense/sparse labels and spacing/packing gates.
  - New spec: specs/overlap_metrics.md (Metric 1 group‚Äëbased gs=2 only; Metric 2 image‚Äëbased global; Metric 3 group‚Üîgroup COM; disc overlap; probe_diameter_px; s_img/n_groups; neighbor_count default 6).
  - Docs updated: docs/index.md (Spec link), docs/GRIDSIZE_N_GROUPS_GUIDE.md (inter‚Äëgroup control via s_img/n_groups; dense/sparse deprecated).
  - Plan/test/constraints revised: plans/active/.../implementation.md Phase D section updated (SPEC ADOPTED); test_strategy now targets the three metrics; constraint_analysis reflects policy.
- Implementation is deferred to a future attempt; no code changed in this loop.
  - Do Now: Implement Phase D overlap metrics and tests per specs/overlap_metrics.md; remove spacing gates and dense/sparse labels; pause Phase G reruns until GREEN tests and metrics bundles exist.

- Latest Attempt (2025-11-12T000700Z): planning ‚Äî `git status -sb` was clean; `timeout 30 git pull --rebase` failed with ‚ÄúCannot rebase onto multiple branches,‚Äù so reran `timeout 30 git pull --rebase origin feature/torchapi-newprompt` (already up to date). Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / OVERSAMPLING-001 / ACCEPTANCE-001), specs/overlap_metrics.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, the Phase D hub plan/summary/artifact inventory, `studies/fly64_dose_overlap/overlap.py`, `tests/study/test_dose_overlap_overlap.py`, and `$HUB/green/pytest_phase_d_overlap.log`. Reality: commit `d94f24f7` already delivers Metric 1/2/3 + CLI support (18/18 tests pass), but the Phase D hub still has no CLI logs or metrics JSON (`cli/` and `metrics/` are empty). Updated `implementation.md` and the hub plan with new `<plan_update>` blocks, marked the API/CLI/test checklist items complete, and re-scoped the Do Now so Ralph must rerun the pytest selector, execute the overlap CLI twice (gs1 `s_img=1.0,n_groups=512`, gs2 `s_img=0.8,n_groups=512`) against `data/phase_c/dose_1000`, and archive `train_metrics.json`, `test_metrics.json`, `metrics_bundle.json`, and CLI stdout/err under `$HUB`. Rewrote `input.md` accordingly.
- Latest Attempt (2025-11-13T012900Z): planning ‚Äî `git status --porcelain` listed the deleted `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/data/phase_c/run_manifest.json`, so I stashed those evidence files, ran `timeout 30 git pull --rebase`, then popped the stash before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / OVERSAMPLING-001 / ACCEPTANCE-001), specs/overlap_metrics.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, specs/data_contracts.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, the initiative plan, test_strategy, constraint_analysis, input.md, galph_memory.md, `studies/fly64_dose_overlap/overlap.py`, and `tests/study/test_dose_overlap_overlap.py`. Reality: Phase D still enforces dense/sparse spacing gates, CLI lacks explicit sampling args, and tests only assert acceptance. Stood up the dedicated hub `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_d_overlap_metrics/`, drafted its plan/summary, and added a new `<plan_update>` so the implementation plan + ledger point at the overlap-metrics deliverable before any new Phase G rerun.
  - Ready_for_implementation Do Now:
    1. Overhaul `studies/fly64_dose_overlap/overlap.py` to implement disc-overlap helpers plus Metric 1 (gs=2 only), Metric 2, and Metric 3 per specs/overlap_metrics.md. Remove MIN_ACCEPTANCE_RATE / greedy fallback, plumb deterministic `s_img` subsampling + unified `n_groups` semantics (gs=1 = single-image groups; gs=2 = `n_groups √ó gridsize¬≤` samples with allowed duplication), and record `gridsize`, `s_img`, `n_groups`, `neighbor_count`, `probe_diameter_px`, RNG seeds, and metric averages in each metrics JSON + `_metadata`.
    2. Refresh the CLI so commands resemble `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB="$PWD/plans/active/.../phase_d_overlap_metrics" python -m studies.fly64_dose_overlap.overlap --phase-c-root data/phase_c/dose_1000 --output-root tmp/phase_d_overlap --artifact-root "$HUB" --gridsize 2 --s-img 0.8 --n-groups 512 --neighbor-count 6 --probe-diameter-px 38.4 --rng-seed-subsample 456`. Keep the Python API callable by future orchestrators.
    3. Rewrite `tests/study/test_dose_overlap_overlap.py` to cover the disc-overlap math, Metric 1/2/3 aggregation, gs=1 skipping Metric 1, and the new bundle schema. Add at least one CLI-focused selector that inspects `metrics_bundle.json`. Remove spacing-threshold assertions.
    4. Evidence expectations: run `pytest tests/study/test_dose_overlap_overlap.py -vv | tee "$HUB"/green/pytest_phase_d_overlap.log`, capture CLI stdout/err under `$HUB/cli/phase_d_overlap_metrics.log`, and drop `train_metrics.json`, `test_metrics.json`, and `metrics_bundle.json` (with Metric 1/2/3 + sampling parameters) into `$HUB` (record file list in `analysis/artifact_inventory.txt`). Blockers go to `$HUB/red/blocked_<timestamp>.md` with the failing command + exit code.

- Latest Attempt (2025-11-13T012200Z): planning ‚Äî `git status --porcelain` only showed the stale `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/cli/phase_d_dense.log`, so per the reports-hub evidence rule I skipped `git pull --rebase` (logged `evidence_only_dirty=true`) and exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ß¬ßPhase G orchestrator + metrics helpers, docs/development/TEST_SUITE_INDEX.md (study row), specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub summaries, `analysis/blocker.log`, `cli/phase_d_dense.log`, and `cli/run_phase_g_dense_post_verify_only.log`. Hub reality: `{analysis}` is still only `blocker.log`, `{cli}` tops out at `phase_c_generation.log`, `phase_d_dense.log`, and the `run_phase_g_dense_stdout*.log` trio, and the post-verify CLI log is just the argparse usage banner because the helper again omitted `--dose/--view/--splits`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED goes to `$HUB/red/`); (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` and immediately follow with `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) if `analysis/metrics_summary.json` predates the rerun, run `plans/active/.../bin/report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` plus `plans/active/.../bin/analyze_dense_metrics.py --hub "$HUB"` so `{analysis}` gains `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, and `metrics_digest.md`; (5) do not stop until `{analysis}` also lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, and `artifact_inventory.txt`, then record MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas and selector/CLI references across `$HUB/summary/summary.md`, docs/fix_plan.md, and galph_memory (blockers ‚Üí `$HUB/red/blocked_<timestamp>.md` with command + exit code).
- Latest Attempt (2025-11-12T235900Z): planning ‚Äî `git status -sb` was clean, so I still executed `timeout 30 git pull --rebase` (failed with ‚ÄúCannot rebase onto multiple branches‚Äù), ran `git pull --no-rebase` to confirm the branch is current, and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, `summary.md`, `summary/summary.md`, and the latest hub logs (`analysis/blocker.log`, `cli/phase_d_dense.log`, `cli/run_phase_g_dense_post_verify_only.log`). `docs/prompt_sources_map.json` is still absent, so docs/index.md remains authoritative. Audit finding: `cli/run_phase_g_dense_post_verify_only.log` is only the argparse usage banner because the command omitted `--dose/--view/--splits`, meaning no post-verify steps actually ran and `{analysis}` still contains only `blocker.log`‚Äîthere is still zero SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) refresh the GREEN record via `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED ‚Üí `$HUB/red/`); (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` and immediately follow with `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) if `analysis/metrics_summary.json` predates the run, rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` and `analyze_dense_metrics.py --hub "$HUB"` so preview/highlights/digest artifacts align; (5) do not stop until `{analysis}` lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, and `artifact_inventory.txt`, and document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus selector/CLI references across `$HUB/summary/summary.md`, this ledger, galph_memory, and hub blockers (`$HUB/red/blocked_<timestamp>.md`) if anything fails.
- Latest Attempt (2025-11-11T220602Z): planning ‚Äî Stashed the dirty plan files, ran `timeout 30 git pull --rebase` (already up to date), and popped the stash before exporting `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md (Phase G orchestrator + metrics helper sections), docs/development/TEST_SUITE_INDEX.md (study selectors), specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, both summaries, and the current hub artifacts (`analysis/blocker.log`, `cli/phase_d_dense.log`, `cli/run_phase_g_dense*.log`) plus `studies/fly64_dose_overlap/overlap.py` and `tests/study/test_dose_overlap_overlap.py`. Reality check: `{analysis}` still only contains `blocker.log`; there is no SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. The dense CLI logs prove the pipeline kept failing in Phase D, and code review shows the helper still emits `geometry_aware_floor` (50 % of the theoretical bound, floored at 1 %) instead of the required `geometry_acceptance_bound` capped at 10 %, so the JSON/metadata keys do not match ACCEPTANCE-001. Ready_for_implementation Do Now: (1) update `studies/fly64_dose_overlap/overlap.py` + `SpacingMetrics` to compute the per-split bounding-box acceptance bound `(area / (pi * (threshold / 2) ** 2)) / n_positions`, clamp it to ‚â§0.10 with a tiny epsilon lower guard, and log the values as `geometry_acceptance_bound` + `effective_min_acceptance` in both the metrics JSON and `_metadata`; (2) refresh `tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor` (and any shared fixtures) so it asserts the renamed JSON keys and the new clamp behavior, capturing the run via `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED output ‚Üí `$HUB/red/`); (3) from `/home/ollie/Documents/PtychoPINN` rerun `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`, then regenerate metrics via `report_phase_g_dense_metrics.py` and `analyze_dense_metrics.py` if `analysis/metrics_summary.json` predates the run. Stop only when `{analysis}` lists `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, preview verdict text, and `artifact_inventory.txt`, and document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas + selector/CLI references across `$HUB/summary/summary.md`, this ledger, and galph_memory. Blockers belong under `$HUB/red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-11T233550Z): implementation (PARTIAL ‚Äî pipeline running) ‚Äî Confirmed working directory guard PASS, executed `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv` (PASSED, 4.17s, GREEN log saved to `$HUB/green/pytest_dense_acceptance_floor.log`). Started Phase C‚ÜíG dense pipeline with `PYTHONPATH=/home/ollie/Documents/PtychoPINN:$PYTHONPATH /home/ollie/miniconda3/envs/ptycho311/bin/python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub ... --dose 1000 --view dense --splits train test --clobber` after discovering that script imports required explicit PYTHONPATH (when running script files directly, Python doesn't auto-add project root to sys.path). Pipeline launched successfully (PID 1357749, started 2025-11-11 15:35:43 UTC), currently in Phase C (TensorFlow/CUDA initialized, dataset generation in progress). Output streaming to `$HUB/cli/run_phase_g_dense_stdout.log`. Estimated completion: 30‚Äì120 minutes. Remaining steps: await pipeline completion, then run `--post-verify-only` chain and verify `{analysis}` artifacts (SSIM grid, verification report, highlights, metrics summaries). Status: in_progress (long-running task). Artifacts: `$HUB/green/pytest_dense_acceptance_floor.log` (‚úÖ), `$HUB/cli/run_phase_g_dense_stdout.log` (streaming), `$HUB/summary/summary.md` (‚úÖ).
- Latest Attempt (2025-11-11T222901Z): planning ‚Äî Ran `timeout 30 git pull --rebase` (already up to date), exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md, docs/development/TEST_SUITE_INDEX.md, specs/data_contracts.md ¬ß12, docs/fix_plan.md, galph_memory.md, input.md, the initiative plan, hub plan, both summaries, and the current hub artifacts (`analysis/blocker.log`, `cli/phase_d_dense.log`, `green/pytest_dense_acceptance_floor.log`) plus `studies/fly64_dose_overlap/overlap.py` and `tests/study/test_dose_overlap_overlap.py`. `docs/prompt_sources_map.json` is still absent so docs/index.md remains the canonical map. Audit: the geometry-aware acceptance bound implementation (`studies/fly64_dose_overlap/overlap.py:334-555`) and its pytest (`tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor`, GREEN log under `$HUB/green/pytest_dense_acceptance_floor.log`) are already in the repo, yet `{analysis}` still only contains `blocker.log` because the counted dense rerun + `--post-verify-only` sweep never executed with the new code ‚Äî `cli/phase_d_dense.log` still shows the pre-fix "minimum 10.0%" error and there is no SSIM grid summary/log, verification report/log, highlights log, preview verdict, metrics summary/delta/digest, or `artifact_inventory.txt`. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest tests/study/test_dose_overlap_overlap.py::test_generate_overlap_views_dense_acceptance_floor -vv | tee "$HUB"/green/pytest_dense_acceptance_floor.log` (RED output ‚Üí `$HUB/red/`) so the log reflects the current branch; (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` immediately followed by `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (4) rerun `plans/active/.../bin/report_phase_g_dense_metrics.py` and `plans/active/.../bin/analyze_dense_metrics.py` if `analysis/metrics_summary.json` predates the rerun so `{analysis}` captures `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, preview verdict text, and `artifact_inventory.txt`; (5) document MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus the selector/CLI references inside `$HUB/summary/summary.md`, this ledger, and galph_memory, dropping any new blockers under `$HUB/red/blocked_<timestamp>.md`.

Attempts History (archived):
- See `docs/archive/2025-11-06_fix_plan_archive.md` for full attempt logs and evidence links.

Do Now (updated):
- Add a geometry-aware acceptance floor inside `studies/fly64_dose_overlap/overlap.py::generate_overlap_views` (or a focused helper): compute each split‚Äôs bounding-box area from `xcoords/ycoords`, derive the theoretical maximum acceptance for the requested spacing threshold, require only a conservative fraction of that bound, and persist both the bound and the actual acceptance in the emitted metrics JSON so downstream verifiers know the effective overlap.
- Extend `tests/study/test_dose_overlap_overlap.py` with `test_generate_overlap_views_dense_acceptance_floor` (or equivalent) to prove the new guard allows dense datasets whose acceptance matches the computed bound while still failing when even the bound is unattainable.
- After the guard + tests land, re-run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` followed immediately by `python plans/active/.../bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`, then publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid summary/log, verification report/log, highlights log, metrics summary/digest, `metrics_delta_highlights_preview.txt`, and `artifact_inventory.txt` under `{analysis}` with selectors + CLI paths called out in `$HUB/summary/summary.md`, this ledger, and galph_memory.

- Attempt (2025-11-11T205022Z): Planning ‚Äî `git status -sb` showed `?? docs/fix_plan.md.bak` (whitelisted) plus `?? docs/iteration_scores_262-291.csv`, so I ran `timeout 30 git pull --rebase` (already up to date) before editing. Re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G orchestrator, docs/development/TEST_SUITE_INDEX.md:62, `galph_memory.md`, the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, `analysis/blocker.log`, and `cli/phase_d_dense.log`. Hub reality check: `{analysis}` still only contains `blocker.log`, `{cli}` is capped at `phase_c_generation.log`, `phase_d_dense.log`, and the `run_phase_g_dense_stdout*` variants, and `data/phase_c/run_manifest.json` remains deleted (must be regenerated via `--clobber`, not restored manually). `cli/phase_d_dense.log` again ends with `ValueError: Object arrays cannot be loaded when allow_pickle=False` emitted **inside `/home/ollie/Documents/PtychoPINN`**, proving the overlap fix has never run here. Ready_for_implementation Do Now: (1) guard `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` and export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` plus `HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest --collect-only tests/study/test_phase_g_dense_orchestrator.py -k post_verify_only_executes_chain -vv | tee "$HUB"/collect/pytest_collect_post_verify_only.log` and `pytest tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain -vv | tee "$HUB"/green/pytest_post_verify_only.log`; (3) execute `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log` so Phase C manifests regenerate and the dense pipeline reruns under this repo; (4) immediately run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (5) rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` and `analyze_dense_metrics.py` if needed so `metrics_delta_highlights_preview.txt` (phase-only per PREVIEW-PHASE-001) and `metrics_digest.md` match the new evidence; (6) ensure `{analysis}` now contains `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt`, `metrics_digest.md`, and `artifact_inventory.txt`; and (7) log MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, selectors, and CLI paths in `$HUB/summary/summary.md`, this ledger, and galph_memory. Any failure transcript belongs under `$HUB/red/blocked_$(date -u +%FT%H%M%SZ).md` with the command + exit status. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md}`.
- Attempt (2025-11-11T213824Z): Planning ‚Äî `git status -sb` again showed only report artifacts plus the stray `docs/iteration_scores_262-291.csv`, so I reran `timeout 30 git pull --rebase` (already up to date), exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and re-read docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G, docs/development/TEST_SUITE_INDEX.md, docs/GRIDSIZE_N_GROUPS_GUIDE.md, docs/fix_plan.md, galph_memory.md, input.md, the hub plan + summaries, `analysis/blocker.log`, `cli/run_phase_g_dense_stdout.log`, `cli/phase_d_dense.log`, and the regenerated Phase C artifacts. The counted dense run now executes locally (regenerates `data/phase_c/run_manifest.json` + patched splits) but **fails deterministically during Phase D** with `ValueError: Insufficient positions meet spacing threshold` because only 42/5088 train positions (0.8%) survive the 38.4 px guard even after the greedy fallback. Geometry probe (56 399 px¬≤ split area; ‚âà48.7 viable slots; ‚âà0.0096 acceptance ceiling) proves the current MIN_ACCEPTANCE_RATE=0.1 is mathematically impossible for dense view, so rerunning the CLI without changing the guard will never produce SSIM grid / verification / metrics / inventory evidence. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md` (new `<plan_update>` + audit), the hub plan + summaries, docs/fix_plan.md, input.md, and galph_memory.md so Ralph must first implement a geometry-aware acceptance floor in `studies/fly64_dose_overlap/overlap.py` (log derived bounds + actual acceptance in the metrics bundle) and add a dense acceptance-floor pytest, then rerun `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber` followed immediately by `--post-verify-only`, publishing MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus SSIM grid / verification / highlights / metrics / artifact inventory evidence across summaries + ledger. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md,analysis/blocker.log,cli/run_phase_g_dense_stdout.log,cli/phase_d_dense.log}`.
- Attempt (2025-11-11T202702Z): Planning ‚Äî Evidence-only dirty exemption re-applied (`git status -sb` shows only the deleted `plans/.../phase_g_dense_full_run_verifier/data/phase_c/run_manifest.json` plus `docs/fix_plan.md.bak`, so pull was skipped). Re-read docs/index.md, docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001), docs/INITIATIVE_WORKFLOW_GUIDE.md, docs/TESTING_GUIDE.md ¬ßPhase G commands, docs/development/TEST_SUITE_INDEX.md:62, specs/data_contracts.md, `input.md`, the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, and the `cli/phase_d_dense.log` + `cli/run_phase_g_dense_clobber.log` pair (docs/prompt_sources_map.json remains absent, so docs/index.md stays the authoritative map). Hub audit: `analysis/` still only holds `blocker.log`; `{cli}` contains `phase_c_generation.log`, `phase_d_dense.log`, `run_phase_g_dense_stdout(_retry,_v2).log`, and the partial `run_phase_g_dense_clobber.log`; `data/phase_c/run_manifest.json` is still deleted; and there are zero SSIM grid summaries/logs, verification/highlights outputs, preview text, metrics summary/digest, or artifact inventory files in this workspace. `cli/phase_d_dense.log` again shows the failure occurred **inside `/home/ollie/Documents/PtychoPINN`** and ends with the pre-fix `ValueError: Object arrays cannot be loaded when allow_pickle=False`, confirming the overlap.py fix has never been rerun locally. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md` (new `<plan_update>` + audit), the hub `plan/plan.md`, `summary.md`, `summary/summary.md`, and `input.md` to keep the focus ready_for_implementation with the same Do Now: (1) guard `pwd -P` equals `/home/ollie/Documents/PtychoPINN`, export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md` and `HUB=$PWD/plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier`; (2) rerun `pytest --collect-only tests/study/test_phase_g_dense_orchestrator.py -k post_verify_only_executes_chain -vv | tee "$HUB"/collect/pytest_collect_post_verify_only.log` plus `pytest tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain -vv | tee "$HUB"/green/pytest_post_verify_only.log`; (3) execute the counted pipeline `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber |& tee "$HUB"/cli/run_phase_g_dense_stdout.log`, regenerating Phase C manifests and populating `{analysis}` with `ssim_grid_summary.md`, `ssim_grid.log`, `verification_report.json`, `verify_dense_stdout.log`, `check_dense_highlights.log`, `metrics_summary.json`, `metrics_delta_highlights_preview.txt` (phase-only per PREVIEW-PHASE-001), `metrics_digest.md`, and `artifact_inventory.txt`; (4) immediately run `python plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/bin/run_phase_g_dense.py --hub "$HUB" --post-verify-only |& tee "$HUB"/cli/run_phase_g_dense_post_verify_only.log`; (5) rerun `report_phase_g_dense_metrics.py --hub "$HUB" --metrics "$HUB"/analysis/metrics_summary.json` if the sanity table is stale; and (6) publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid references, verification/highlights links, pytest selectors, and CLI log paths inside `$HUB/summary/summary.md`, this ledger, and galph_memory. Any failure must land under `$HUB/red/blocked_<timestamp>.md` with the exact command + exit code before stopping. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/summary/summary.md,input.md}`.
- Attempt (2025-11-11T192358Z): Planning ‚Äî Repeated the `git stash push --include-untracked` ‚Üí `timeout 30 git pull --rebase` ‚Üí `git stash pop` flow, exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, re-read docs/index.md plus docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001), and re-audited the 2025-11-12 hub. Nothing has landed since the last directive: `analysis/` still only holds `blocker.log`, `{cli}` remains capped at `phase_c_generation.log`, `phase_d_dense.log`, and `run_phase_g_dense_stdout*.log`, and `cli/phase_d_dense.log` still ends with the local `ValueError: Object arrays cannot be loaded when allow_pickle=False`. Added a new Phase G audit entry (with XML guard) to the implementation plan plus refreshed the hub plan + summaries, all reiterating the ready_for_implementation Do Now: rerun the mapped pytest collect-only selector + `tests/study/test_phase_g_dense_orchestrator.py::test_run_phase_g_dense_post_verify_only_executes_chain`, execute `plans/.../bin/run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber` from `/home/ollie/Documents/PtychoPINN`, immediately follow with `--post-verify-only`, then publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas, preview verdict, SSIM grid summary/log, verification report/log, highlights log, metrics digest/summary, and artifact inventory evidence across the hub and ledger docs. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,summary.md,summary/summary.md,input.md}`.
- Attempt (2025-11-11T191109Z): Planning ‚Äî `timeout 30 git pull --rebase` returned up to date, so I re-read docs/index.md plus docs/findings.md (POLICY-001, CONFIG-001, DATA-001, TYPE-PATH-001, STUDY-001, TEST-CLI-001, PREVIEW-PHASE-001, PHASEC-METADATA-001) before auditing the active hub: `analysis/` still contains only `blocker.log`, `{cli}` remains capped at `phase_c_generation.log`, `phase_d_dense.log`, and the trio of `run_phase_g_dense_stdout*.log`, and `phase_d_dense.log` still ends with the local `ValueError: Object arrays cannot be loaded when allow_pickle=False` stack trace. No SSIM grid summaries, verification/highlights logs, preview text, metrics digests, or artifact-inventory files exist, so the counted dense rerun + immediate `--post-verify-only` sweep has **still never executed inside this workspace** even though the allow_pickle fix landed days ago. Updated `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md`, the hub plan, summary.md, summary/summary.md, and `input.md` with the ready_for_implementation Do Now: from `/home/ollie/Documents/PtychoPINN` rerun the mapped pytest collect/execution selector, execute `run_phase_g_dense.py --hub "$HUB" --dose 1000 --view dense --splits train test --clobber`, immediately follow with `--post-verify-only`, and publish MS-SSIM ¬±0.000 / MAE ¬±0.000000 deltas plus preview/verifier/highlights/SSIM grid references, CLI logs, and artifact inventory evidence inside the hub, docs/fix_plan.md, and galph_memory. Status: ready_for_implementation. Artifacts: `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/{implementation.md,reports/2025-11-12T010500Z/phase_g_dense_full_run_verifier/plan/plan.md,summary.md,summary/summary.md,input.md}`.

## [FIX-PHASE-C-GENERATION-001] Fix Phase C coordinate type bug
- Depends on: ‚Äî
- Priority: High (blocks STUDY-SYNTH-FLY64-DOSE-OVERLAP-001 Phase G evidence)
- Status: done
- Owner/Date: Ralph/2025-11-07
- Error Signature: `TypeError: object of type 'float' has no len()` at `ptycho/raw_data.py:227`
- Root Cause: `studies/fly64_dose_overlap/generation.py:85-91` did not set `TrainingConfig.n_images`, leaving it None; legacy simulator `_generate_simulated_data_legacy_params` depends on `n_images` to size coordinate arrays
- Impact: Phase C dataset generation fails immediately, blocking all downstream phases (D/E/F/G)
- Repro: `python -m studies.fly64_dose_overlap.generation --base-npz <path> --output-root <path>`
- Scope: `studies/fly64_dose_overlap/generation.py` config construction; `tests/study/test_dose_overlap_generation.py` coverage
- Notes: Discovered during 2025-11-07T070500Z Phase G orchestrator execution; blocker logged at `plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-07T070500Z/phase_g_execution_real_runs/analysis/blocker.log`

## [EXPORT-PTYCHODUS-PRODUCT-001] TF-side Ptychodus product exporter/importer + Run1084 conversion
- Depends on: ‚Äî
- Priority: Medium
- Status: planning ‚Äî Run1084 exporter evidence is complete; documentation needs to be updated with the approved snippet plus ledger references before closing the initiative.
- Owner/Date: Codex Agent/2025-10-28
- Working Plan: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/implementation_plan.md`
- Test Strategy: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/test_strategy.md`
- Reports Hub: `plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/`
- Do Now (2025-11-13T101500Z):
  1. Guard from `/home/ollie/Documents/PtychoPINN`, export `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`, and set `HUB="$PWD/plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap"`.
  2. Integrate the drafted ‚ÄúPtychodus Product Export‚Äù subsection into `docs/DATA_MANAGEMENT_GUIDE.md` (after the NPZ/HDF5 sections). The new section must include the approved CLI example (with metadata flags), explain raw-data inclusion toggles, reiterate the storage policy (keep products under `outputs/ptychodus_products/`), and cite `specs/data_contracts.md` + `ptycho/io/ptychodus_product_io.py` for canonical behavior.
  3. If discoverability would benefit, add a short cross-link under the Data Management Guide entry in `docs/index.md` pointing at the new subsection.
  4. Update `analysis/artifact_inventory.txt`, `summary.md`, and `summary/summary.md` within the active hub so they reference the documentation edit (file path + section heading). No new pytest selector is required for this doc-only pass; blockers must drop a note in `red/blocked_<timestamp>.md`.
- Latest Attempt (2025-11-13T104500Z): planning ‚Äî Ran a verification preflight to generate a Phase G hub analysis deliverable: `python plans/active/.../bin/verify_dense_pipeline_artifacts.py --hub "$HUB" --report "$HUB"/analysis/verification_report.json --dose 1000 --view dense` (exit 1 as expected due to missing Phase G outputs; log at `$HUB/cli/verify_dense_pipeline_artifacts.log`). This establishes a concrete checklist of missing artifacts while landing a new `{analysis}` file. Updated input.md and hub summary to direct the counted rerun and post‚Äëverify sweep. Focus is now ready_for_implementation.
- Latest Attempt (2025-11-13T093000Z): implementation ‚Äî Ran `pytest tests/io/test_ptychodus_product_io.py -vv` (3 PASSED in 3.73s, logged to `$HUB/green/pytest_product_io.log`). Executed CLI conversion of Run1084 NPZ to HDF5 product (`outputs/ptychodus_products/run1084_product.h5`), capturing stdout to `$HUB/cli/convert_run1084.log` (exit 0). Verified HDF5 structure via h5py (all required datasets present, 1087 scan positions, probe 64√ó64 complex64, object 227√ó226 complex64, diffraction [1087,64,64] in canonical NHW order, empty loss arrays). Saved verification log to `$HUB/analysis/verify_product.log` and product summary JSON. Drafted DATA_MANAGEMENT_GUIDE snippet in `$HUB/analysis/data_guide_snippet.md` covering CLI usage, metadata parameters, raw data inclusion, storage policy, and programmatic access. Created artifact inventory and turn summary. All Do Now steps complete; focus ready for doc integration. Artifacts: plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/ (green/pytest_product_io.log, cli/convert_run1084.log, analysis/{verify_product.log,product_summary.json,data_guide_snippet.md,artifact_inventory.txt}, summary/summary.md).
- Latest Attempt (2025-11-13T112200Z): planning ‚Äî `git status --porcelain` showed local edits to `pyproject.toml` and `ptychopinn.egg-info/SOURCES.txt`, so I ran `git stash push -u`, `timeout 30 git pull --rebase origin feature/torchapi-newprompt`, then `git stash pop`, and re-exported `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md`. Reviewed docs/index.md, docs/findings.md (DATA-001), specs/data_contracts.md ¬ßProduct files, docs/DATA_MANAGEMENT_GUIDE.md, the initiative implementation plan, hub plan/summary files, and the drafted snippet at `$HUB/analysis/data_guide_snippet.md`. Reality: the guide still contains the older one-paragraph ‚ÄúExporting to Ptychodus HDF5 Product‚Äù note (from 6cfd2ada) with no metadata flag breakdown, raw-data toggle, storage policy reminder, or references to `ptycho/io/ptychodus_product_io.py`; docs/index.md still lacks any pointer to the Data Management Guide, and the hub summaries/artifact inventory cite only the exporter evidence. Reiterated the Do Now so Ralph must insert the full ‚ÄúPtychodus Product Export‚Äù subsection (CLI block + metadata parameters + raw-data inclusion toggle + storage policy + references), add or update the docs/index.md entry so it links directly to the new subsection, and refresh `$HUB/analysis/artifact_inventory.txt`, `summary.md`, and `summary/summary.md` with the doc path + section title (blockers go under `$HUB/red/`). Status: ready_for_implementation. Artifacts: plans/active/EXPORT-PTYCHODUS-PRODUCT-001/reports/2025-11-13T091500Z/hdf5_exporter_bootstrap/.
- Latest Attempt (2025-11-13T101500Z): planning ‚Äî Reviewed the Run1084 hub evidence (`green/pytest_product_io.log`, `cli/convert_run1084.log`, `analysis/{verify_product.log,product_summary.json,data_guide_snippet.md,artifact_inventory.txt}`) plus docs/index.md, docs/findings.md (DATA-001), specs/data_contracts.md, docs/DATA_MANAGEMENT_GUIDE.md, and the implementation plan. Confirmed exporter evidence is complete and the documentation snippet is ready for publication. Updated the working plan with a new `<plan_update>` + Do Now describing the doc insertion, hub summary refresh, and optional docs/index cross-link. Status stays planning until the doc diff lands.

## [INTEGRATE-PYTORCH-PARITY-001] PyTorch backend API parity reactivation
- Depends on: Phase F handoff of `INTEGRATE-PYTORCH-001` (config bridge + policy decisions already archived under `plans/active/INTEGRATE-PYTORCH-001/`)
- Priority: High
- Status: done ‚Äî Phase R CLI GPU-default handoff evidence complete with all requested artifacts archived under the active hub. Training/inference CLIs both succeeded without `--torch-*` flags and correctly logged POLICY-001 warnings plus auto-instantiated CUDA execution config. Execution_config regression test failures (2 FAILED due to stub fixture issue) documented under `red/blocked_20251113T224500Z_execution_config.md` with fix strategy.
- Owner/Date: Ralph/2025-11-13T220500Z
- Working Plan: `plans/ptychodus_pytorch_integration_plan.md`
- Summary: `plans/active/INTEGRATE-PYTORCH-001/summary.md`
- Reports Hub: `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/`
- GPU Baseline: All PyTorch backend work (including this focus and TEST-PYTORCH-001) must now run on a pinned CUDA device by default. CPU-only runs are considered fallback evidence; cite the GPU model/driver in summaries and follow the updated workflow guidance (`docs/workflows/pytorch.md` ¬ß¬ß11‚Äì12).
- Test Strategy: `plans/pytorch_integration_test_plan.md`
- Constraints: POLICY-001, CONFIG-001, CONFIG-LOGGER-001, plus "no edits to ptycho/model.py / diffsim.py / tf_helper.py" rule.

- Latest Attempt (2025-11-13T220500Z): implementation ‚Äî Executed all Do Now steps: (1) environment verified with `test "$(pwd -P)" = "/home/ollie/Documents/PtychoPINN"` ‚úÖ and env vars set; (2) ran training CLI without `--torch-*` flags ‚Üí GREEN `cli/pytorch_cli_smoke_training/train_gpu_default_log.log` showing POLICY-001 warning and auto-instantiated CUDA config, training succeeded with bundle at `train_outputs/wts.h5.zip`; (3) ran inference CLI without `--torch-*` flags ‚Üí GREEN `cli/pytorch_cli_smoke_training/inference_gpu_default_log.log` showing same POLICY-001 + CUDA placement, inference succeeded with amplitude/phase PNGs; (4) captured execution_config regression RED log ‚Üí 2 FAILED (StubLightningModule lacks `automatic_optimization` attribute), summary at `red/blocked_20251113T224500Z_execution_config.md` with fix strategy (test fixture issue, not production bug); (5) updated `analysis/artifact_inventory.txt`, initiative summary, and hub summary with all new evidence links. GPU confirmed: NVIDIA GeForce RTX 3090. Status: done. Artifacts: cli/pytorch_cli_smoke_training/{train_gpu_default_log.log,inference_gpu_default_log.log}, red/{pytest_workflows_execution_config.log,blocked_20251113T224500Z_execution_config.md}, analysis/artifact_inventory.txt.
- Latest Attempt (2025-11-13T224000Z): implementation ‚Äî Commit `d3793315` added POLICY-001 GPU-default logging to both CLIs plus new pytest coverage in `tests/scripts/test_*backend_selector.py::test_pytorch_backend_defaults_auto_execution_config`; GREEN log captured at `green/pytest_backend_selector_cli.log` (2 PASSED). CLI smokes and execution_config regression evidence still pending.
- Latest Attempt (2025-11-13T220000Z): implementation ‚Äî Commit `83ae55af` extended `tests/torch/test_execution_config_defaults.py` with dispatcher-level GPU-default coverage (new CUDA + CPU tests), ensured backend_selector auto-instantiates `PyTorchExecutionConfig()` when callers omit `torch_execution_config`, and reran `pytest tests/torch/test_execution_config_defaults.py -vv` (8 items, log at `green/pytest_execution_config_defaults.log`). Hub inventory + summaries now cite the new tests and POLICY-001 enforcement notes.
- Latest Attempt (2025-11-13T210000Z): implementation ‚Äî Commit `3efa2dc3` changed `PyTorchExecutionConfig.accelerator` default to `'auto'`, added auto-resolution logic with POLICY-001 warnings, logged resolved accelerators inside `_build_inference_dataloader` and `_train_with_lightning`, and introduced `tests/torch/test_execution_config_defaults.py` (2 tests) with GREEN log `green/pytest_execution_config_defaults.log`. Artifact inventory updated with GPU/CPU detection notes.
- Latest Attempt (2025-11-13T203500Z): implementation ‚Äî Commit `85478a67` moved bundle-loaded models to the requested accelerator, added regression tests (`tests/scripts/test_inference_backend_selector.py::TestInferenceCliBackendDispatch::test_pytorch_backend_moves_model_to_execution_device`, `tests/torch/test_cli_inference_torch.py::TestInferenceCLI::test_accelerator_flag_roundtrip`), and reran the CUDA inference CLI with `CUDA_VISIBLE_DEVICES=0`. Evidence: `green/pytest_pytorch_inference_device.log`, `cli/pytorch_cli_smoke_training/inference_cuda.log`, and `inference_outputs_cuda/{reconstructed_amplitude.png,reconstructed_phase.png}`. DEVICE-MISMATCH-001 resolved.
- Latest Attempt (2025-11-13T205500Z): planning ‚Äî Verified commit `420e2f14` and the associated GREEN pytest + CLI evidence captured under `reports/2025-11-13T150000Z/parity_reactivation/{green/pytest_cuda_default_exec_config.log,cli/pytorch_cli_smoke_training/train_cuda_default.log,inference_cuda_default.log}`. Updated `plans/ptychodus_pytorch_integration_plan.md`, `summary.md`, and this ledger to mark the CUDA-default checklist complete, highlighted that defaulting `PyTorchExecutionConfig` to CPU keeps backend_selector callers on CPU, and drafted the new Do¬†Now (GPU-first dataclass defaults + regression tests). Input.md refreshed accordingly.

## [INTEGRATE-PYTORCH-PARITY-001B] CLI GPU-default evidence & execution-config regression capture
- Depends on: completion of INTEGRATE-PYTORCH-PARITY-001 (CUDA defaults + device placement already merged)
- Priority: High
- Status: ready_for_implementation ‚Äî Implementation complete but required GREEN/RED evidence missing from the hub and checklist.
- Owner/Date: Ralph/2025-11-14T020000Z
- Working Plan: `plans/ptychodus_pytorch_integration_plan.md`
- Summary: `plans/active/INTEGRATE-PYTORCH-001/summary.md`
- Reports Hub: `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/`
- Do Now (2025-11-14T020000Z):
  1. From repo root, `export HUB="$PWD/plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation"`.
  2. Training CLI without any `--torch-*` flags:  
     `python scripts/training/train.py --config configs/gridsize2_minimal.yaml --train_data_file tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --test_data_file tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --backend pytorch --output_dir "$HUB"/cli/pytorch_cli_smoke_training/train_outputs --n_groups 4 --n_subsample 16 --neighbor_count 7 --batch_size 4 --nepochs 1 |& tee "$HUB"/cli/pytorch_cli_smoke_training/train_gpu_default_log.log` (verify POLICY-001 log + CUDA execution_config message near top).
  3. Inference CLI (reuse bundle from step¬†2, still no torch flags):  
     `python scripts/inference/inference.py --model_path "$HUB"/cli/pytorch_cli_smoke_training/train_outputs --test_data tests/fixtures/pytorch_integration/minimal_dataset_v1.npz --backend pytorch --output_dir "$HUB"/cli/pytorch_cli_smoke_training/inference_outputs --n_images 4 --n_subsample 16 |& tee "$HUB"/cli/pytorch_cli_smoke_training/inference_gpu_default_log.log` (same GPU-default log, regenerated amplitude/phase PNGs).
  4. Execution-config regression suite (expected RED):  
     `pytest tests/torch/test_workflows_components.py -k execution_config -vv |& tee "$HUB"/red/pytest_workflows_execution_config.log` and append the first failure signature (StubLightningModule) to `$HUB/red/blocked_20251113T224500Z_execution_config.md`.
  5. Refresh `analysis/artifact_inventory.txt`, initiative summary, and hub summary with links to the new GREEN CLI logs + RED pytest log (blockers stay under `$HUB/red/`).
- Latest Attempt (2025-11-14T020000Z): planning ‚Äî Re-read docs/index.md; docs/findings.md (POLICY-001 / CONFIG-001 / DATA-001 / TYPE-PATH-001 / STUDY-001 / TEST-CLI-001 / PREVIEW-PHASE-001 / PHASEC-METADATA-001 / ACCEPTANCE-001); docs/INITIATIVE_WORKFLOW_GUIDE.md; docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; specs/overlap_metrics.md; docs/fix_plan.md; galph_memory.md; input.md; initiative plan; hub summary + inventory. Reality: CUDA-default code is merged but the hub still lacks `train_gpu_default_log.log`, `inference_gpu_default_log.log`, and only contains the older RED execution-config log. Added this row to isolate the evidence tasks, updated the plan checklist, refreshed summaries, and rewrote `input.md` with the commands above. Focus remains ready_for_implementation.

## [PARALLEL-API-INFERENCE] Programmatic TF/PyTorch API parity
- Depends on: INTEGRATE-PYTORCH-PARITY-001 (backend selector wiring complete; this focus builds a programmatic example)
- Priority: Medium
- Status: planning ‚Äî new initiative to expose the backend selector in a demo script + reusable helpers
- Owner/Date: Ralph/2025-11-14T030000Z
- Working Plan: `plans/active/PARALLEL-API-INFERENCE/plan.md`
- Reports Hub: TBD (will use `plans/active/PARALLEL-API-INFERENCE/reports/<timestamp>/`)
- Do Now (2025-11-14T030000Z):
  1. Extract a TensorFlow inference helper from `scripts/inference/inference.py` (data container prep + output saving) so programmatic callers can invoke it without the CLI.
  2. Build `scripts/pytorch_api_demo.py` that loads `RawData`, constructs `TrainingConfig`/`InferenceConfig`, and runs both backends via `run_cdi_example_with_backend` + the new TF helper / `_run_inference_and_reconstruct`.
  3. Add a smoke test under `tests/scripts/test_api_demo.py` that calls `run_backend('pytorch')` and `run_backend('tensorflow')` against the minimal dataset (skip CUDA path if GPU unavailable).
  4. Document the usage snippet referencing `specs/ptychodus_api_spec.md` (e.g., add a ‚ÄúProgrammatic API‚Äù section to `docs/workflows/pytorch.md`).
- Latest Attempt (2025-11-14T030000Z): planning ‚Äî Created plan file `plans/active/PARALLEL-API-INFERENCE/plan.md` outlining goals, scope, tasks, and risks. Logged outstanding gaps (TF inference tied to CLI internals, PyTorch helper already available) and set next steps for implementation + regression tests. Focus now ready_for_implementation.
- Latest Attempt (2025-11-13T202000Z): planning ‚Äî Reviewed docs/index.md; docs/workflows/pytorch.md (GPU default table); docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-LOGGER-001 / EXEC-ACCUM-001 / DATA-SUP-001 / DEVICE-MISMATCH-001); docs/TESTING_GUIDE.md; docs/development/TEST_SUITE_INDEX.md; docs/COMMANDS_REFERENCE.md; plan + hub summaries; and `cli/pytorch_cli_smoke_training/train_clean.log`. Determined that CLI defaults still resolve to CPU despite GPU baseline, so drafted the CUDA-default Do¬†Now and updated plan/input artifacts.
- Latest Attempt (2025-11-13T033117Z): implementation ‚Äî Commit `dd0a5b0e` finished the config-default backfill, updated the PyTorch factories/bridge, and reran `pytest tests/torch/test_config_bridge.py::TestConfigBridgeParity -vv` (47 PASSED; GREEN log at `$HUB/green/pytest_config_bridge.log`). The PyTorch inference CLI executed against `$HUB/cli/pytorch_cli_smoke_training/train_outputs/wts.h5.zip`; CUDA path failed with `Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor)` because bundle-loaded Lightning modules remain on CPU, while the CPU accelerator succeeded and produced `inference_outputs/{reconstructed_amplitude.png,reconstructed_phase.png}` (24 KB/18 KB). Evidence captured via `$HUB/cli/pytorch_cli_smoke_training/{inference.log,inference_cpu.log}` and blocker log `$HUB/red/blocked_2025-11-13T033117Z_device_mismatch.md`. Phase R objectives are complete; fixing DEVICE-MISMATCH-001 is now the gating inference task.

- Latest Attempt (2025-11-13T190000Z): implementation ‚Äî Commit `9daa00b7` added the EXEC-ACCUM-001 guard (`_train_with_lightning` now raises before Lightning misconfiguration), the DATA-SUP-001 detector for unlabeled supervised datasets, doc updates in `docs/workflows/pytorch.md`, and regression coverage (`test_manual_accumulation_guard`). `pytest_backend_selector_cli.log` now shows 4 PASS, and the PINN-mode training CLI completes on the fly001 subset (`cli/pytorch_cli_smoke_training/train_clean.log`, bundle saved to `train_outputs/wts.h5.zip`). Supervised runs remain blocked (DATA-SUP-001); inference still needs to be rerun against the new bundle.
- Latest Attempt (2025-11-13T190500Z): planning ‚Äî Updated the plan, hub summary, and artifact inventory to capture the guard evidence, noted the outstanding inference rerun, and rewrote the Do¬†Now toward spec-default parity in `ptycho_torch/config_params.py` plus the parity test selector. Input.md now directs Ralph to the config-default work and the pending PyTorch inference CLI refresh.
- Latest Attempt (2025-11-13T182600Z): implementation ‚Äî Commit `04a016ad` exposed the PyTorch execution-config flags on `scripts/training/train.py`, threaded `torch_execution_config` through `ptycho.workflows.backend_selector.run_cdi_example_with_backend`, and added `test_pytorch_execution_config_flags` under `tests/scripts/test_training_backend_selector.py` (GREEN log at `$HUB/green/pytest_backend_selector_cli.log`). The training CLI smoke hit `AttributeError: 'PtychoPINN_Lightning' object has no attribute 'loss_name'`, recorded in `train_debug.log:30621-30623` and `$HUB/red/blocked_20251113T183500Z_loss_name.md`; no new bundles/PNGs were produced.
- Latest Attempt (2025-11-13T020801Z): implementation ‚Äî Commit `b218696a` added PyTorch execution-config flags to the inference CLI (`scripts/inference/inference.py:95-149, 508-546`), introduced `test_pytorch_execution_config_flags` in `tests/scripts/test_inference_backend_selector.py`, reran the targeted pytest selector (2 PASSED, log at `$HUB/green/pytest_backend_selector_cli.log`), and repeated the PyTorch CLI smoke with the new flags (`cli/pytorch_cli_smoke/{train.log,inference.log}` + refreshed PNGs). `analysis/artifact_inventory.txt` now documents the execution-config evidence and policy compliance.
- Latest Attempt (2025-11-13T200000Z): implementation ‚Äî Commit `12fa29dd` introduced the backend-aware PyTorch inference branch, added `test_pytorch_inference_execution_path`, reran the backend-dispatch selectors (3 PASSED), and executed the minimal PyTorch CLI smoke (logs + amplitude/phase PNGs under `cli/pytorch_cli_smoke/`).
- Latest Attempt (2025-11-13T020801Z): implementation ‚Äî Commit `b218696a` added the PyTorch execution-config flags to the inference CLI (`scripts/inference/inference.py:95-149` + `508-546`), introduced `test_pytorch_execution_config_flags` (`tests/scripts/test_inference_backend_selector.py:365-446`), reran the targeted pytest selector (2 PASSED, log at `plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/green/pytest_backend_selector_cli.log`), and repeated the PyTorch CLI smoke with the new flags (`cli/pytorch_cli_smoke/{train.log,inference.log}` + refreshed PNGs). `analysis/artifact_inventory.txt` now documents the execution-config evidence and policy compliance. Focus shifts to training CLI parity.
- Latest Attempt (2025-11-13T200000Z): implementation ‚Äî Commit `12fa29dd` introduced the backend-aware PyTorch inference branch (scripts/inference/inference.py:493-542), added `test_pytorch_inference_execution_path`, reran the backend-dispatch selectors (`green/pytest_backend_selector_cli.log`, 3 PASSED), and executed the minimal PyTorch CLI smoke (logs + amplitude/phase PNGs under `cli/pytorch_cli_smoke/`). `analysis/artifact_inventory.txt` now documents the successful train/inference commands, metrics ranges, and policy compliance. Focus remains ready_for_implementation pending the execution-config flag exposure + new tests/logs.
- Latest Attempt (2025-11-13T184500Z): implementation ‚Äî Commit `c983bdc8` added the inference `--backend` CLI flag/defaults, extended `tests/scripts/test_inference_backend_selector.py` with the parsing checks (GREEN via `pytest ...::test_pytorch_backend_dispatch`, log at `$HUB/green/pytest_backend_selector_cli.log`), and ran the minimal PyTorch CLI smoke. Training command succeeded (`cli/pytorch_cli_smoke/train.log`, bundle at `train_outputs/wts.h5.zip`), but the inference CLI still failed with `Error during inference: 'probe'` because the code re-enters the TensorFlow `perform_inference()` path instead of invoking a PyTorch helper. Evidence (including stdout with the `'probe'` KeyError) captured in `$HUB/cli/pytorch_cli_smoke/inference.log` and summarized in `analysis/artifact_inventory.txt`. Focus remains ready_for_implementation pending the PyTorch inference execution branch + rerun.
- Latest Attempt (2025-11-13T173500Z): planning ‚Äî Verified that commit `a53f897b` wired `scripts/training/train.py` / `scripts/inference/inference.py` through `ptycho.workflows.backend_selector`, guarded the TensorFlow-only persistence helpers, and added the new backend dispatch unit tests (`green/pytest_training_backend_dispatch.log`, `green/pytest_inference_backend_dispatch.log`). Reviewed docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-002 / CONFIG-LOGGER-001 / TYPE-PATH-001), docs/workflows/pytorch.md, plans/ptychodus_pytorch_integration_plan.md, plans/pytorch_integration_test_plan.md, hub summary + artifact inventory, and galph_memory/input briefs. Updated the plan + ledger to mark the backend-selector checklist complete, drafted the PyTorch CLI smoke-test Do Now (inference backend flag + minimal fixture training/inference runs), and rewrote input.md so Ralph can jump straight into the implementation work with explicit commands + pytest selector. Focus remains ready_for_implementation pending the new CLI argument + smoke run evidence.
- Latest Attempt (2025-11-13T160500Z): planning ‚Äî Reviewed docs/index.md, docs/findings.md (POLICY-001 / CONFIG-001 / CONFIG-002 / CONFIG-LOGGER-001 / TYPE-PATH-001), docs/workflows/pytorch.md, docs/specs/spec-ptycho-config-bridge.md, docs/DEVELOPER_GUIDE.md, `plans/ptychodus_pytorch_integration_plan.md`, `plans/pytorch_integration_test_plan.md`, hub inventory (`analysis/artifact_inventory.txt`), `scripts/training/train.py`, `scripts/inference/inference.py`, and `ptycho/workflows/backend_selector.py`. Confirmed commit `ccff2f5c` + `green/pytest_config_bridge.log` satisfy the Phase R checklist (config bridge wiring + PyTorch persistence shim + parity pytest). Updated the plan and this ledger to pivot the Do¬†Now toward backend-selector adoption in the production CLIs so `--backend pytorch` becomes runnable from the canonical scripts. Input brief + plan now direct Ralph to modify the CLIs, add dispatch tests, and log the new pytest evidence under the active hub.
- Latest Attempt (2025-10-19T215800Z): planning ‚Äî Final Phase E3 docs handoff noted that config bridge invocation, PyTorch persistence, and regression harness remained undone; see `plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-19T215800Z/phase_e3_docs_handoff/summary.md` plus `PYTORCH_INVENTORY_SUMMARY.txt` for the outstanding gaps. No further work occurred until this reactivation.

## [INTEGRATE-PYTORCH-001-STUBS] Finish PyTorch workflow stubs deferred from Phase D2
- Status: archived 2025-10-20 ‚Äî see `docs/archive/2025-10-20_fix_plan_archive.md#integrate-pytorch-001-stubs-finish-pytorch-workflow-stubs-deferred-from-phase-d2`.

## [INTEGRATE-PYTORCH-001-DATALOADER] Restore PyTorch dataloader DATA-001 compliance
- Status: archived 2025-10-20 ‚Äî see `docs/archive/2025-10-20_fix_plan_archive.md#integrate-pytorch-001-dataloader-restore-pytorch-dataloader-data-001-compliance`.

---

Process references:
- Supervisor prompt: `prompts/supervisor.md`
- Engineer prompt: `prompts/main.md`
- Findings ledger: `docs/findings.md`
- Data contracts: `specs/data_contracts.md`

- Latest Attempt (2025-11-11T161300Z): implementation ‚Äî Reran `pytest tests/study/test_dose_overlap_overlap.py::test_overlap_metrics_bundle -vv` (PASSED 1.54s, green log saved). Executed Phase D overlap CLI twice: (1) gs1 `--gridsize 1 --s-img 1.0 --n-groups 512` producing `metrics/gs1_s100_n512/{train,test,metrics_bundle}.json` with Metric 2 train=0.8908/test=0.8917 and Metric 3 train=0.2662/test=0.2658 (Metric 1 N/A for gs=1); (2) gs2 `--gridsize 2 --s-img 0.8 --n-groups 512` producing `metrics/gs2_s080_n512/*.json` with Metric 1 train=0.8909/test=0.8942, Metric 2 train=0.8777/test=0.8794, Metric 3 train=0.2706/test=0.2673 (4070/5088 train images retained, 4173/5216 test, 512 groups each split). Archived CLI logs under `$HUB/cli/phase_d_overlap_gs{1,2}.log`, updated `analysis/artifact_inventory.txt` with commands + metric summaries, wrote turn summary to `$HUB/summary/summary.md`. Phase E/G now unblocked for training manifest alignment and dense pipeline reruns. Artifacts: plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/reports/2025-11-12T010500Z/phase_d_overlap_metrics/ (green/pytest_phase_d_overlap_bundle_rerun.log, cli logs, metrics JSONs, artifact_inventory.txt, summary/summary.md).
