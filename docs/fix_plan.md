# PtychoPINN Fix Plan Ledger (Condensed)

**Last Updated:** 2026-01-20 (ORCH-ORCHESTRATOR reviewer user_input routing)
**Active Focus:** ORCH-ORCHESTRATOR-001 — route actionable reviewer findings to user_input.md

---

**Housekeeping Notes:**
- Full ledger snapshot archived at `docs/archive/2026-01-13_fix_plan_archive.md`
- Full Attempts History archived in `docs/fix_plan_archive.md` (snapshot 2026-01-06)
- Earlier snapshots: `docs/archive/2025-11-06_fix_plan_archive.md`, `docs/archive/2025-10-17_fix_plan_archive.md`, `docs/archive/2025-10-20_fix_plan_archive.md`
- Each initiative has a working plan at `plans/active/<ID>/implementation.md` and reports under `plans/active/<ID>/reports/`

---

## Active / Pending Initiatives

### [DEBUG-SIM-LINES-DOSE-001] Isolate sim_lines_4x vs dose_experiments discrepancy
- Depends on: None
- Priority: **Critical** (Highest Priority)
- Status: in_progress — Phase C diagnostics (C4 intensity normalization audit)
- Owner/Date: Codex/2026-01-13
- Working Plan: `plans/active/DEBUG-SIM-LINES-DOSE-001/implementation.md`
- Summary: `plans/active/DEBUG-SIM-LINES-DOSE-001/summary.md`
- Reports Hub: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/`
- Spec Owner: `specs/spec-ptycho-workflow.md`
- Test Strategy: `plans/active/DEBUG-SIM-LINES-DOSE-001/test_strategy.md`
- Goals:
  - Identify whether the sim_lines_4x failure stems from a core regression, nongrid pipeline differences, or a workflow/config mismatch.
  - Produce a minimal repro that isolates grid vs nongrid and probe normalization effects.
  - Apply a targeted fix and verify success via visual inspection if metrics are unavailable.
- Exit Criteria:
  - A/B results captured for grid vs nongrid, probe normalization, and grouping parameters.
  - Root-cause statement with evidence (logs + params snapshot + artifacts).
  - Targeted fix or workflow change applied, with recon success and no NaNs.
  - Visual inspection success gate satisfied if metrics are unavailable.
- Attempts History:
  - *2026-01-13T000000Z:* Drafted phased debugging plan, summary, and test strategy. Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/implementation.md`, `plans/active/DEBUG-SIM-LINES-DOSE-001/summary.md`, `plans/active/DEBUG-SIM-LINES-DOSE-001/test_strategy.md`.
  - *2026-01-15T235900Z:* Reactivated focus, set Phase A evidence capture Do Now, and opened new artifacts hub. Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-15T235900Z/`.
  - *2026-01-16T000353Z:* Reframed Phase A A0/A1/A3 handoff to build `collect_sim_lines_4x_params.py`, inventory `dose_experiments` defaults, and run the pipeline import smoke test. Artifacts hub: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T000353Z/`.
  - *2026-01-16T002700Z:* Implemented `scripts/tools/collect_sim_lines_4x_params.py` (metadata-only snapshot CLI), captured the JSON snapshot, recorded the legacy `dose_experiments` tree + parameter script, and reran the sim_lines pipeline import smoke test. Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v` (pass). Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T000353Z/{sim_lines_4x_params_snapshot.json,dose_experiments_tree.txt,dose_experiments_param_scan.md,pytest_sim_lines_pipeline_import.log}`. Next Actions: Compare sim_lines snapshot vs dose_experiments defaults (Phase A4) and plan the differential experiments.
  - *2026-01-16T003217Z:* Reviewed the captured artifacts, ticked A1/A3 in the plan, and authored the A4 comparison Do Now plus new artifacts hub (`plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T003217Z/`) so Ralph can implement the diff script with fresh pytest evidence.
  - *2026-01-16T013500Z:* Implemented `bin/compare_sim_lines_params.py`, generated the Markdown + JSON diff artifacts for all four scenarios, and reran the synthetic helpers CLI smoke test to guard imports.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v` (pass)
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T003217Z/{comparison_draft.md,comparison_diff.json,pytest_sim_lines_pipeline_import.log}`
    - Next Actions: Use the diff to scope the Phase B differential experiments (grid vs nongrid, probe normalization) or flag gaps if additional parameters need capture.
  - *2026-01-16T020000Z:* Reviewed the comparison diff, marked Phase A4 complete in the working plan, and scoped Phase B1 instrumentation to capture grouping stats for both the legacy (dose_experiments) and sim_lines parameter regimes. Created new artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T020000Z/` for the upcoming grouping summaries and refreshed the Do Now with the bin script plan plus pytest guard.
  - *2026-01-16T005400Z:* Added `bin/grouping_summary.py` under the initiative, captured grouping summaries for the SIM-LINES defaults and the legacy gridsize=2 dose constraints (including failure diagnostics), and reran the synthetic helpers CLI smoke guard.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T020000Z/{grouping_sim_lines_default.json,grouping_sim_lines_default.md,grouping_dose_experiments_legacy.json,grouping_dose_experiments_legacy.md,pytest_sim_lines_pipeline_import.log}`
    - Next Actions: Mine the grouping stats to plan the remainder of Phase B (probe normalization and grouping differentials) or flag if additional parameter overrides are required.
  - *2026-01-16T031700Z:* Implemented the plan-local `probe_normalization_report.py` CLI plus `plans/.../bin/__init__.py`, generated JSON/Markdown stats for gs1/gs2 × custom/ideal probes, captured the CLI log, and reran the synthetic helpers CLI smoke test.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T031500Z/{probe_stats_gs1_custom.json,probe_stats_gs1_custom.md,probe_stats_gs1_ideal.json,probe_stats_gs1_ideal.md,probe_stats_gs2_custom.json,probe_stats_gs2_custom.md,probe_stats_gs2_ideal.json,probe_stats_gs2_ideal.md,probe_normalization_cli.log,pytest_sim_lines_pipeline_import.log}`
    - Next Actions: Compare the legacy vs sim_lines probe stats to decide if normalization explains the reconstruction gap or if grouping/reassembly experiments must proceed (Phase B3/B4).
  - *2026-01-16T041700Z:* Supervisor review confirmed the probe stats are numerically identical (max delta ≈5e-7), so normalization is no longer a suspect. Scoped Phase B3 to extend `bin/grouping_summary.py` with per-axis offset stats + nn-index ranges and to capture three runs (gs1 default, gs2 default, gs2 neighbor-count=1) plus the CLI smoke guard under `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T041700Z/`.
  - *2026-01-16T043500Z:* Extended `bin/grouping_summary.py` with overall mean/std reporting plus per-axis coordinate stats (when the penultimate dimension is 2) and nn-index min/max telemetry, regenerated the gs1 default, gs2 default, and gs2 `neighbor-count=1` grouping summaries, and archived the combined CLI + pytest logs under the Phase B3 hub.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T041700Z/{grouping_gs1_custom_default.json,grouping_gs1_custom_default.md,grouping_gs2_custom_default.json,grouping_gs2_custom_default.md,grouping_gs2_custom_neighbor1.json,grouping_gs2_custom_neighbor1.md,grouping_cli.log,pytest_sim_lines_pipeline_import.log}`
    - Next Actions: Analyze the richer per-axis telemetry to decide whether B4 needs additional grouping probes or if we can pivot directly to the reassembly experiments.
  - *2026-01-16T050500Z:* Reviewed the B3 telemetry (coords offsets up to ~382 px on gs2) and compared it against the legacy padded-size math (`get_padded_size()` ≈ 78 px when `offset` remains 4 and `max_position_jitter` remains 10), confirming reassembly canvas under-allocation is the likely regression. Scoped Phase B4 around a `reassembly_limits_report.py` helper that contrasts observed offsets vs padded-size requirements and runs a sum-preservation probe via `reassemble_whole_object()`. Opened artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T050500Z/` for the next evidence batch and refreshed the Do Now accordingly.
  - *2026-01-16T053600Z:* Added `bin/reassembly_limits_report.py`, generated JSON/Markdown + CLI evidence for `gs1_custom` and `gs2_custom`, and proved that the observed max offsets (~382 px) demand canvases ≥828–831 px while the legacy padded size stays at 74/78 px (loss fractions ≥94%). Pytest guard reran clean.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v` (pass)
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T050500Z/{reassembly_cli.log,reassembly_gs1_custom.json,reassembly_gs1_custom.md,reassembly_gs2_custom.json,reassembly_gs2_custom.md,pytest_sim_lines_pipeline_import.log}`
    - Next Actions: Feed the reassembly deltas into Phase C to patch `get_padded_size()`/canvas sizing or open a dedicated backlog item if the fix crosses initiatives.
  - *2026-01-16T060156Z:* Supervisor planning loop to pivot into Phase C: mined the B4 telemetry, marked Phase B complete in the implementation plan, and scoped C1 around updating `create_ptycho_data_container()` (plus a targeted pytest) so grouped offsets automatically expand `max_position_jitter`/padded size before training/inference. Refreshed `plans/active/DEBUG-SIM-LINES-DOSE-001/{implementation.md,summary.md}` and `input.md` with the new Do Now, no new production artifacts yet. Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T060156Z/`.
  - *2026-01-20T011212Z:* Implemented `_update_max_position_jitter_from_offsets()` with padded-size parity handling, wired it into `create_ptycho_data_container`, and updated `reassembly_limits_report.py` to apply the helper while basing the required canvas on `coords_offsets`. Added the regression pytest, refreshed test docs, and confirmed SIM-LINES reassembly telemetry now reports `fits_canvas=True` with zero loss for gs1/gs2 custom runs.
    - Metrics: `ruff check ptycho/workflows/components.py plans/active/DEBUG-SIM-LINES-DOSE-001/bin/reassembly_limits_report.py tests/test_workflow_components.py`, `pytest --collect-only tests/test_workflow_components.py -q`, `pytest tests/test_workflow_components.py::TestCreatePtychoDataContainer::test_updates_max_position_jitter -v`, `pytest -v -m integration`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-16T060900Z/{git_diff.txt,ruff_check.log,pytest_collect_workflow_components.log,pytest_workflow_components.log,pytest_integration.log,reassembly_cli.log,reassembly_gs1_custom.json,reassembly_gs1_custom.md,reassembly_gs2_custom.json,reassembly_gs2_custom.md}`
    - Next Actions: Run the Phase C2 gs1/gs2 ideal telemetry (if required) or proceed to the inference smoke validation once the padded-size update is accepted.
  - *2026-01-20T041420Z:* Reviewed the C1 landing evidence, marked the checklist entries complete, and queued Phase C2 handoff to rerun the gs1_ideal + gs2_ideal scenarios with the jitter fix. Do Now captures end-to-end runs, NaN/canvas inspection, and manual visual checks with artifacts staged under `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T041420Z/`.
  - *2026-01-20T052730Z:* Prepared the Phase C2 supervisor loop (this turn) with a fresh artifacts hub, scoped a plan-local runner (`bin/run_phase_c2_scenario.py`) to capture amplitude/phase arrays + NaN stats, and refreshed `input.md` with commands for gs1_ideal + gs2_ideal runs plus reassembly telemetry.
  - *2026-01-20T052010Z:* Implemented the Phase C2 runner (`bin/run_phase_c2_scenario.py`) with CLI arg overrides, stats PNG generation, and run_metadata tracking, then executed the gs1_ideal (512 images/256 groups/`batch_size=8`) and gs2_ideal (256 base images/128 groups/`batch_size=4`) scenarios. Archived amplitude/phase `.npy`, PNGs, stats JSON, CLI logs, updated reassembly telemetry for both scenarios, and re-ran the synthetic helpers CLI smoke pytest selector.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T061530Z/{gs1_ideal_runner.log,gs2_ideal_runner.log,gs1_ideal/inference_outputs/*,gs2_ideal/inference_outputs/*,gs1_ideal_notes.md,gs2_ideal_notes.md,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs2_ideal.json,pytest_cli_smoke.log}`
    - Notes: gs1 needed reduced group_count to avoid NaNs; both reassembly JSONs report `fits_canvas=true` with jitter-expanded padded sizes.
  - *2026-01-20T062804Z:* Reviewed the Phase C2 evidence, confirmed the jitter-driven padded size passes (`fits_canvas=true`, 0 NaNs) on both ideal scenarios, and logged a follow-up checklist (C2b) to bake the reduced-load profile (gs1: 512/256/8, gs2: 256/128/4) into `run_phase_c2_scenario.py` so reruns no longer depend on manual CLI overrides. New hub and telemetry updates will accompany that rerun.
  - *2026-01-20T061530Z:* Current loop — revisited the C2 scope, updated the working plan/status to Phase C verification, opened artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T061530Z/`, and drafted the Do Now for implementing `bin/run_phase_c2_scenario.py`, running gs1_ideal + gs2_ideal with PNG/NaN evidence, rerunning the reassembly telemetry, and guarding the flow with the synthetic helpers CLI pytest selector.
  - *2026-01-20T063500Z:* Baked the `gs1_ideal`/`gs2_ideal` “stable profiles” directly into `run_phase_c2_scenario.py`, reran both scenarios under the new artifacts hub, refreshed the manual inspection notes + reassembly telemetry, and re-ran the synthetic helpers CLI smoke guard.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T063500Z/{gs1_ideal_runner.log,gs2_ideal_runner.log,gs*_ideal/inference_outputs/*,gs*_ideal_notes.md,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs2_ideal.json,pytest_cli_smoke.log}`
    - Notes: run_metadata now records the baked overrides (base_total_images/group_count/batch_size/neighbor_count) without CLI hacks; `gs2_ideal` stayed healthy with `fits_canvas=true`, while `gs1_ideal` still collapses to NaNs despite the reduced profile, so the NaN root cause remains open even though the workload knobs are fixed in-code.
  - *2026-01-20T071800Z:* Logged the gs1 vs gs2 divergence after the stable-profile reruns, marked C2b complete in the working plan, and scoped Phase C3 around instrumenting `run_phase_c2_scenario.py` to persist per-epoch training history and NaN detection. Reserved artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T071800Z/` for the telemetry reruns (gs1_ideal + gs2_ideal), refreshed `input.md`, and prepped the new Do Now with the pytest guard plus reassembly CLI instructions.
  - *2026-01-20T073600Z:* Extended the Phase C2 runner with JSON-safe history capture, NaN summarization, and Markdown narratives, then reran the baked `gs1_ideal`/`gs2_ideal` profiles plus the reassembly telemetry and CLI guard so the new evidence lands under the 2026-01-20T071800Z hub.
    - Metrics: `pytest --collect-only tests/scripts/test_synthetic_helpers_cli_smoke.py -q`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T071800Z/{gs1_ideal_runner.log,gs2_ideal_runner.log,gs1_ideal/train_outputs/history.json,gs1_ideal/train_outputs/history_summary.json,gs1_ideal/gs1_ideal_training_summary.md,gs2_ideal/train_outputs/history.json,gs2_ideal/train_outputs/history_summary.json,gs2_ideal/gs2_ideal_training_summary.md,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs1_ideal.md,reassembly_gs2_ideal.json,reassembly_gs2_ideal.md,pytest_collect_cli_smoke.log,pytest_cli_smoke.log}`
    - Notes: Both scenarios now emit structured history without NaNs/Infs (gs1 still collapses visually while gs2 remains healthy), `run_metadata.json` references the new telemetry, and `reassembly_limits_report.py` confirms the padded canvases stay at 828/826 px with `fits_canvas=true`.
  - *2026-01-20T075800Z:* Updated `run_phase_c2_scenario.py` so `run_metadata.json` exposes explicit `training_history_path`/`training_summary_path` entries and reran the gs1_ideal/gs2_ideal profiles with fresh history JSON/Markdown plus reassembly telemetry under the 2026-01-20T071800Z hub. Logged the new history summaries and run metadata alongside reiterated reassembly limits, then reran the synthetic helpers CLI smoke selector (collect + targeted test).
    - Metrics: `pytest --collect-only tests/scripts/test_synthetic_helpers_cli_smoke.py -q`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T071800Z/{gs1_ideal_runner.log,gs2_ideal_runner.log,gs*_ideal/train_outputs/history.json,gs*_ideal/train_outputs/history_summary.json,gs*_ideal_training_summary.md,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs1_ideal.md,reassembly_gs2_ideal.json,reassembly_gs2_ideal.md,pytest_collect_cli_smoke.log,pytest_cli_smoke.log}`
    - Notes: `run_metadata.json` now points directly to the history/summary artifacts (relative paths) and both scenarios continue to report `fits_canvas=true` with zero NaNs detected in the stored metrics.
  - *2026-01-20T083000Z:* Reviewed the C3 telemetry, confirmed both scenarios report finite metrics, and scoped Phase C3b around extending the Phase C2 runner with ground-truth comparison outputs (object amplitude/phase dumps, center-cropped diff metrics/PNGs, and run_metadata pointers) so we can quantify gs1 vs gs2 reconstruction error instead of relying on visual inspection. Reserved artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T083000Z/` and refreshed `input.md` with the new Do Now plus pytest/reassembly instructions.
  - *2026-01-20T085500Z:* Extended `run_phase_c2_scenario.py` with `save_ground_truth`, `center_crop`, and diff-artifact helpers so the runner now writes cropped amplitude/phase arrays, ground-truth PNGs/NPYs, amplitude+phase diff PNGs, comparison metrics JSON, and metadata pointers. Reran the baked `gs1_ideal`/`gs2_ideal` profiles under the new artifacts hub, regenerated the reassembly limits telemetry, and guarded the flow with the synthetic helpers CLI pytest selectors.
    - Metrics: `pytest --collect-only tests/scripts/test_synthetic_helpers_cli_smoke.py -q`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T083000Z/{gs1_ideal_runner.log,gs2_ideal_runner.log,gs1_ideal/comparison_metrics.json,gs2_ideal/comparison_metrics.json,gs1_ideal/ground_truth_amp.npy,gs1_ideal/amplitude_diff.png,gs2_ideal/amplitude_diff.png,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs2_ideal.json,pytest_collect_cli_smoke.log,pytest_cli_smoke.log}`
    - Notes: `run_metadata.json` for each scenario now records ground-truth artifact paths, comparison metrics (MAE/RMSE/max/pearson), diff PNGs, and crop metadata so downstream consumers can quantify gs1 vs gs2 divergence without replaying the runner. Both reassembly limit reports still show `fits_canvas=true` with jitter-updated padded sizes (828 px gs1, 826 px gs2).
  - *2026-01-20T090600Z:* Reviewed the C3b comparison metrics and computed direct amplitude stats showing both gs1_ideal and gs2_ideal undershoot the ground truth by ≈2.5 (mean/median bias) despite clean reassembly telemetry. Scoped Phase C3c around augmenting `run_phase_c2_scenario.py` with per-scenario prediction vs truth stats (mean/min/max/std plus bias percentiles) and Markdown summaries so we can prove whether the collapse is a shared intensity offset before touching core workflows. Opened artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T093000Z/` and refreshed `input.md` with the bias telemetry Do Now + pytest/reassembly commands.
  - *2026-01-20T093000Z:* Implemented the C3c instrumentation: `run_phase_c2_scenario.py` now records prediction vs truth stats, bias percentiles, and Markdown summaries per scenario (gs1_ideal + gs2_ideal) and persists the paths in run_metadata/comparison_metrics. Reran both scenarios under the new hub, refreshed reassembly limits, and reran the CLI pytest guard.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T093000Z/{gs*_ideal/*,reassembly_cli.log,reassembly_gs1_ideal.json,reassembly_gs2_ideal.json,pytest_cli_smoke.log}`
    - Notes: Both scenarios report amplitude bias mean ≈-2.47 (median ≈-2.53, P95 ≈-0.98) with prediction means ≈0.23–0.25 while ground truth mean stays 2.71. Phase bias shows the same zero-vs-offset behavior, confirming the remaining failure is a shared intensity offset rather than gs1-specific NaNs.
  - *2026-01-20T094500Z:* Scoped Phase C3d to dump the `IntensityScaler`/`IntensityScaler_inv` weights and `params.cfg['intensity_scale']` from the gs1_ideal/gs2_ideal checkpoints (plan-local inspector script) so we can trace the constant bias back to the intensity-scaling workflow before modifying shared modules. Will open artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T103000Z/` for the inspector outputs + pytest log.
  - *2026-01-20T103000Z:* Added `bin/inspect_intensity_scaler.py`, ran it for `gs1_ideal` and `gs2_ideal`, and recorded IntensityScaler/IntensityScaler_inv gains along with the archived `intensity_scale` under the new hub. Both scenarios load `exp(log_scale)=988.211666` (delta vs recorded scale `-3.9e-06`, ratio `0.999999996`), eliminating scaler weights as the source of the shared ≈2.47 amplitude bias.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T103000Z/{intensity_scaler_gs1_ideal.json,intensity_scaler_gs1_ideal.md,intensity_scaler_gs2_ideal.json,intensity_scaler_gs2_ideal.md,pytest_cli_smoke.log,summary.md}`
    - Next Actions: Pivot Phase C3d toward the upstream workflow math (intensity normalization + stats) since both checkpoints share the same scaler weights despite diverging outputs.
  - *2026-01-20T110000Z:* Scoped Phase C4 to add intensity-normalization telemetry inside `run_phase_c2_scenario.py` (raw/grouped/container stats + recorded `intensity_scale`) and to rerun the gs1_ideal / gs2_ideal scenarios under a fresh hub so the new JSON lives alongside the bias summaries. Updated the implementation plan (C3c/C3d complete, C4a–C4c added) and reserved `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/` for the reruns + pytest evidence.
  - *2026-01-20T113000Z:* Implemented the Phase C4 intensity telemetry by extending `run_phase_c2_scenario.py` to emit scalar-only stats for raw diffraction, grouped diffraction/X_full, and container tensors plus both the bundle-recorded and current `legacy_params['intensity_scale']`. Reran the baked `gs1_ideal`/`gs2_ideal` profiles under the new hub so each scenario now writes `intensity_stats.json/.md` alongside the existing bias artifacts, and confirmed run_metadata identifiers include the new JSON/Markdown paths.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/{gs1_ideal/*,gs2_ideal/*,gs1_ideal_runner.log,gs2_ideal_runner.log,pytest_cli_smoke.log}`
    - Notes: Both scenarios report identical bundle vs legacy intensity scales (`988.21167`, delta 0.0) and the telemetry confirms normalization drops raw amplitudes from ≈0.15 mean to ≈0.085 inside `X_full`/`container.X`. `gs1_ideal` still exhibits the ~2.5 amplitude bias, and this rerun surfaced that `gs2_ideal`’s training history now records NaNs from the first step even though inference completes—flagging Phase C4 follow-ups to correlate the new telemetry with the bias metrics.
    - Next Actions: Mine the new intensity summaries vs the comparison metrics to decide whether the shared amplitude drop matches the scaler value or if upstream workflow math needs fixes; investigate the newly observed gs2 training NaNs during the next loop.
  - *2026-01-20T121500Z:* Reviewed the Phase C4 telemetry and confirmed the amplitude bias remains ≈2.5 for both gs1/gs2 despite identical `bundle_intensity_scale` readings while gs2 now logs NaNs from the first optimizer step. Scoped the next increment to add a plan-local analyzer (`bin/analyze_intensity_bias.py`) that ingests existing scenario hubs, correlates amplitude bias vs probe/intensity stats, and summarizes the NaN metrics so we can distinguish physics-vs-normalization faults before touching shared workflows. Reserved artifacts hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T121500Z/` for the analyzer outputs + pytest guard and rewrote input.md with the new Do Now.
  - *2026-01-20T121800Z:* Implemented the analyzer CLI, generated `bias_summary.json/.md` for the gs1_ideal + gs2_ideal hubs, and re-ran the CLI smoke guard. The summary confirms both scenarios still undershoot amplitude by ≈2.5 despite identical intensity-scale readings and highlights that gs2’s training history now reports NaNs across every primary loss metric, reinforcing the workflow-level bias hypothesis.
    - Metrics: `python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/analyze_intensity_bias.py --scenario gs1_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs1_ideal --scenario gs2_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs2_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T121500Z > plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T121500Z/analyze_intensity_bias.log`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T121500Z/{bias_summary.json,bias_summary.md,analyze_intensity_bias.log,pytest_cli_smoke.log}`
    - Findings: Amplitude bias means remain -2.49 (gs1) vs -2.67 (gs2) with matching bundle/legacy intensity scales (Δ=0); gs2 training metrics now show immediate NaN contamination while normalization stats confirm loader scaling is stable (raw mean ≈0.146 → container mean ≈0.085).
  - *2026-01-20T130000Z:* Documentation hygiene per reviewer request — removed the duplicated *2026-01-20T121500Z* attempts entry, ensured plan/summary references now point to the single analyzer-planning record, and logged this maintenance action. (Docs-only; no tests required.)
  - *2026-01-20T132500Z:* Scoped the next Phase C4 increment around deriving stage-by-stage amplitude ratios (raw → grouped → normalized → reconstruction) from the existing telemetry. Updated `input.md` with instructions to extend `bin/analyze_intensity_bias.py` accordingly, rerun the analyzer for gs1_ideal/gs2_ideal, and archive outputs under `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T132500Z/` alongside the CLI pytest guard so we can pinpoint where the ≈2.5 drop enters the workflow.
  - *2026-01-20T132500Z:* Extended `bin/analyze_intensity_bias.py` with stage-mean telemetry, stage-to-stage ratios, and “largest drop” detection, then reran it for the gs1_ideal + gs2_ideal hubs and refreshed the CLI smoke guard so the Markdown/JSON summaries now highlight that the grouped→normalized stage slashes amplitude by ≈44 %.
    - Metrics: `python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/analyze_intensity_bias.py --scenario gs1_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs1_ideal --scenario gs2_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs2_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T132500Z`
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T132500Z/{bias_summary.json,bias_summary.md,analyze_intensity_bias.log,pytest_cli_smoke.log}`
    - Findings: Both scenarios now report per-stage amplitude tables plus ratio bullets; the largest drop occurs during grouped→normalized (ratio ≈0.56) with identical bundle/legacy intensity scales, confirming normalization as the current suspect.
    - Next Actions: Use the new ratio telemetry to trace the normalization drop inside `normalize_data`/loader before touching shared workflows or adjusting loss weights.
  - *2026-01-20T143000Z:* Analyzed the new ratio summaries and confirmed gs1_ideal loses ≈44 % of amplitude at `normalize_data` (grouped→normalized 0.56×) and another ≈12× before reaching ground-truth amplitude, while gs2_ideal collapses completely after prediction due to NaNs. Scoped the next increment (C4d) around extending `analyze_intensity_bias.py` to ingest the amplitude `.npy` files, compute best-fit prediction↔truth scaling factors, and report whether a single scalar explains the ≈12× gap before planning fixes.
    - Artifacts hub reserved for evidence: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z/`
    - Next Actions: Extend the analyzer with prediction↔truth scaling diagnostics, rerun it for gs1_ideal + gs2_ideal, and archive the CLI pytest guard log under the new hub.
  - *2026-01-20T143000Z:* Extended `bin/analyze_intensity_bias.py` with prediction↔truth scaling diagnostics that load `inference_outputs/amplitude.npy` + `ground_truth_amp.npy`, compute truth/pred ratio stats (mean/median/p05/p95), evaluate least-squares scalars, and report rescaled MAE/RMSE so we can prove whether a single scalar explains the ≈12× amplitude gap. Reran the analyzer for gs1_ideal + gs2_ideal under the new hub and kept the synthetic helpers CLI smoke selector green.
    - Metrics: `python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/analyze_intensity_bias.py --scenario gs1_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs1_ideal --scenario gs2_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs2_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z/{bias_summary.json,bias_summary.md,analyze_intensity_bias.log,pytest_cli_smoke.log}`
    - Findings: gs1_ideal’s best-fit least-squares scalar (≈1.88) still leaves MAE ≈2.37 vs baseline 2.49, proving a constant factor cannot fully recover the ≈12× prediction shortfall, while gs2_ideal ratios continue to diverge due to NaNs.
    - Next Actions: Use the new scaling section to determine whether loader normalization or downstream loss wiring needs correction before shipping the Phase C4 fix.
  - *2026-01-20T143500Z:* Refined the scaling analyzer output so `bias_summary.{json,md}` now expose explicit ratio-count tables plus baseline→scaled MAE/RMSE callouts, then regenerated the gs1_ideal/gs2_ideal summaries under the 2026-01-20T143000Z hub with the pytest CLI guard.
    - Metrics: `python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/analyze_intensity_bias.py --scenario gs1_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs1_ideal --scenario gs2_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T113000Z/gs2_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z > plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z/analyze_intensity_bias.log`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v | tee plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z/pytest_cli_smoke.log`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T143000Z/{bias_summary.json,bias_summary.md,analyze_intensity_bias.log,pytest_cli_smoke.log}`
    - Findings: Tables now spell out gs1_ideal’s truth/pred ratio spread (mean≈2.01, p05≈1.19, p95≈3.09) and baseline→scaled MAE deltas (2.49→2.37) while gs2_ideal reports zero usable ratios due to NaNs, reinforcing that normalization fixes alone cannot close the ≈12× gap.
    - Next Actions: Feed these quantified ratios back into Phase C4d planning to decide whether loader normalization or downstream loss wiring must change before touching shared workflow code.
  - *2026-01-20T150500Z:* Synced the plan + summary with existing evidence (checked off A0/A1b/A2 and C4d, documented the A1b waiver), scoped C4e to pilot an amplitude-rescale hook in the runner + sim_lines pipeline, and opened `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/` for the upcoming implementation evidence.
  - *2026-01-20T151900Z:* Implemented the C4e prediction-scale hook (shared helper in `scripts/studies/sim_lines_4x/pipeline.py`, runner flag/metadata updates, analyzer support) and reran `gs1_ideal`/`gs2_ideal` with `--prediction-scale-source least_squares` so the new bias/artifact outputs land under `.../reports/2026-01-20T150500Z/`. Captured the analyzer summary and CLI smoke selector alongside the runner logs.
    - Metrics: `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/run_phase_c2_scenario.py --scenario gs1_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/gs1_ideal --prediction-scale-source least_squares --group-limit 64 --nepochs 5`, same command for `gs2_ideal`, `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md python plans/active/DEBUG-SIM-LINES-DOSE-001/bin/analyze_intensity_bias.py --scenario gs1_ideal=plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/gs1_ideal --scenario gs2_ideal=.../gs2_ideal --output-dir plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z`, `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`.
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/{gs1_ideal/**,gs2_ideal/**,bias_summary.json,bias_summary.md,pytest_cli_smoke.log}`.
  - *2026-01-20T152400Z:* Wired the Phase C2 runner’s `save_stats()` helper to accept extra metadata so the selected prediction-scale mode/value land in `stats.json`, then reran the SIM-LINES CLI smoke selector to guard imports.
    - Metrics: `AUTHORITATIVE_CMDS_DOC=./docs/TESTING_GUIDE.md pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v`
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/pytest_cli_smoke.log`
  - *2026-01-20T092411Z:* Manual override for checklist A1b — attempted to rerun the legacy `dose_experiments` simulate→train→infer flow straight from `/home/ollie/Documents/PtychoPINN`. Built a non-production compatibility runner (`plans/active/DEBUG-SIM-LINES-DOSE-001/bin/run_dose_stage.py`) plus stub `tensorflow_addons`/`components` modules (`plans/active/DEBUG-SIM-LINES-DOSE-001/bin/tfa_stub/`) so the old scripts would import under the frozen environment, then drove the CLI repeatedly (logs under `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T092411Z/`). The shims fixed the missing `keras.src` and `update_params` errors, but the simulation stage still fails: the default `--nimages 2000` run OOMs the RTX 3090 even after chunking attempts (`simulation_attempt16.log`), and smoke runs with smaller image counts crash inside `RawData.from_simulation` because the hard-coded `neighbor_count=5` exceeds the number of scan positions (see `simulation_smoke.log`). Need a follow-up plan (environment repro or loader patches) before we can close A1b with a full ground-truth rerun.
  - *2026-01-20T014500Z:* Extended `run_dose_stage.py` with parameter clamping to fix the KD-tree IndexError: neighbor_count now clamped to `min(current, nimages - 1)`, nimages capped at 512 to avoid GPU OOM, and gridsize+N forced to 1/64 for simulation stage since `RawData.from_simulation` requires gridsize=1 and the NPZ probe is 64x64. Simulation stage now completes successfully, producing 512 diffraction patterns and visualization PNGs; training stage fails with Keras 3.x `KerasTensor` error (known legacy model incompatibility, outside current scope).
    - Metrics: Simulation complete (512 images), artifacts generated
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T092411Z/simulation_clamped4.log`, `.artifacts/DEBUG-SIM-LINES-DOSE-001/2026-01-20T092411Z/simulation/`
    - Notes: Original IndexError root cause = KD-tree querying K+1 neighbors with K=5 but only 4 scan positions; N vs probe shape mismatch = N=128 patches vs 64x64 probe.
    - Next Actions: Decide whether to provision legacy TF/Keras env for full training or document simulation-only capability for A1b ground-truth runs.
  - *2026-01-20T160000Z:* Reviewed the C4e evidence (bias_summary shows least-squares scalars ≈1.86–1.99 yet amplitude MAE/pearson_r unchanged) and concluded constant prediction scaling cannot close the gap; scoped C4f to enforce CONFIG-001 bridging before every training/inference call and rerun gs1_ideal/gs2_ideal under hub `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T160000Z/` with analyzer + pytest evidence after syncing params.cfg.
  - *2026-01-20T100500Z:* Implemented CONFIG-001 bridging in `scripts/studies/sim_lines_4x/pipeline.py` (run_scenario + run_inference) and `plans/active/DEBUG-SIM-LINES-DOSE-001/bin/run_phase_c2_scenario.py` (main + run_inference_and_reassemble). Reran gs1_ideal + gs2_ideal with `--prediction-scale-source least_squares` under the new hub and refreshed the analyzer outputs.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v` (pass)
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T160000Z/{gs1_ideal/*,gs2_ideal/*,bias_summary.json,bias_summary.md,gs1_ideal_runner.log,gs2_ideal_runner.log,pytest_cli_smoke.log,analyze_intensity_bias.log}`
    - Findings: Both scenarios now sync params.cfg before training/inference; gs2_ideal healthy (no training NaNs, fits_canvas=true, least_squares scalar=1.91), gs1_ideal still collapses to NaNs at epoch 3 despite CONFIG-001 bridging (normalized→prediction ratio=0, amplitude bias mean=-2.68). Amplitude undershoot persists (≈2.3–2.7) but bundle/legacy intensity_scale delta now confirms zero drift.
    - Next Actions: Investigate gs1_ideal's NaN instability (gridsize=1 numeric collapse hypothesis) or pivot to core workflow normalization audit if amplitude bias remains the primary blocker.
  - *2026-01-20T101800Z:* Reran C4f evidence collection (CONFIG-001 bridging already in place). Executed gs1_ideal + gs2_ideal with `--prediction-scale-source least_squares --group-limit 64`, refreshed analyzer bias summary, and captured pytest CLI smoke guard.
    - Metrics: `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py::test_sim_lines_pipeline_import_smoke -v` (pass)
    - Artifacts: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T160000Z/{gs1_ideal/*,gs2_ideal/*,bias_summary.json,bias_summary.md,gs1_ideal_runner.log,gs2_ideal_runner.log,pytest_cli_smoke.log,analyze_intensity_bias.log}`
    - Findings: **Both scenarios now complete without training NaNs** (all metrics `has_nan=false`), fits_canvas=true for both, bundle vs legacy intensity_scale delta=0. Amplitude bias remains ≈-2.29 (gs1) and ≈-2.30 (gs2) with least_squares scalars 1.71 and 2.06 respectively; pearson_r improved slightly (0.103 gs1, 0.138 gs2).
    - Next Actions: CONFIG-001 bridging verified and NaNs eliminated; remaining amplitude bias is workflow-level (normalization or loss weighting) and unrelated to param drift. Consider auditing the normalization math or loss weighting to close the ≈2.3 amplitude gap.

### [FIX-DEVICE-TOGGLE-001] Remove CPU/GPU toggle (GPU-only execution)
- Depends on: None
- Priority: High
- Status: pending
- Owner/Date: Codex/2026-01-20
- Working Plan: `plans/active/FIX-DEVICE-TOGGLE-001/implementation.md`
- Summary: `plans/active/FIX-DEVICE-TOGGLE-001/summary.md`
- Reports Hub: `plans/active/FIX-DEVICE-TOGGLE-001/reports/`
- Spec Owner: `specs/ptychodus_api_spec.md`
- Test Strategy: `plans/active/FIX-DEVICE-TOGGLE-001/test_strategy.md`
- Goals:
  - Remove GPU/CPU toggles from PyTorch CLI + execution config.
  - Enforce GPU-only runtime with actionable errors on missing CUDA.
  - Align specs/docs/tests with GPU-only contract.
- Exit Criteria:
  - CLI no longer exposes `--device`, `--accelerator`, `--torch-accelerator`.
  - Execution config defaults to GPU-only values; no CPU fallback.
  - Spec/doc updates merged; tests updated with passing pytest logs archived.
- Attempts History:
  - *2026-01-20:* Drafted implementation plan, test strategy, and summary. Artifacts: `plans/active/FIX-DEVICE-TOGGLE-001/{implementation.md,test_strategy.md,summary.md}`.

### [REFACTOR-MEMOIZE-CORE-001] Move RawData memoization decorator into core module
- Depends on: None
- Priority: Low
- Status: done — Phase C docs/tests landed; ready for archive after a short soak
- Owner/Date: TBD/2026-01-13
- Working Plan: `plans/active/REFACTOR-MEMOIZE-CORE-001/implementation.md`
- Summary: `plans/active/REFACTOR-MEMOIZE-CORE-001/summary.md`
- Reports Hub: `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/`
- Spec Owner: `docs/architecture.md`
- Test Strategy: Inline test annotations (refactor only; reuse existing tests)
- Goals:
  - Move `memoize_raw_data` from `scripts/simulation/cache_utils.py` into a core module under `ptycho/`.
  - Preserve cache hashing and default cache paths used by synthetic helpers.
  - Keep script imports working via direct update or a thin shim.
- Exit Criteria:
  - Core module provides `memoize_raw_data` with unchanged behavior.
  - Synthetic helpers use the core module; shim or removal completed without regressions.
  - Existing synthetic helper tests pass and logs archived.
- Attempts History:
  - *2026-01-13T202358Z:* Drafted implementation plan and initialized initiative summary. Artifacts: `plans/active/REFACTOR-MEMOIZE-CORE-001/implementation.md`, `plans/active/REFACTOR-MEMOIZE-CORE-001/summary.md`.
  - *2026-01-15T225850Z:* Phase A inventory + compatibility design completed; handed off Phase B move/shim work with pytest coverage instructions. Artifacts: `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/2026-01-15T225850Z/`
  - *2026-01-15T231710Z:* Added `ptycho/cache.py` with the memoize helpers, updated synthetic_helpers to import it, and converted `scripts/simulation/cache_utils.py` into a DeprecationWarning shim. Tests: `pytest tests/scripts/test_synthetic_helpers.py::test_simulate_nongrid_seeded -v`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py -v`. Artifacts: `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/2026-01-15T225850Z/`
  - *2026-01-15T232107Z:* Confirmed Phase B landed in commit `d29efc91` and staged Phase C cleanup: refresh docs (`docs/index.md`, `scripts/simulation/README.md`), rerun the two synthetic helper selectors, and archive logs under `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/2026-01-15T232107Z/`.
  - *2026-01-15T233050Z:* Documented the new `ptycho/cache.py` core helper in `docs/index.md`, refreshed `scripts/simulation/README.md` with cache-root/override guidance, and captured the required pytest evidence (`pytest --collect-only tests/scripts/test_synthetic_helpers.py -q`, `pytest tests/scripts/test_synthetic_helpers.py::test_simulate_nongrid_seeded -v`, `pytest tests/scripts/test_synthetic_helpers_cli_smoke.py -v`). Artifacts: `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/2026-01-15T232107Z/pytest_collect.log`, `.../pytest_synthetic_helpers.log`, `.../pytest_cli_smoke.log`.
  - *2026-01-15T233622Z:* Verified Phase C evidence (docs updated, selectors rerun), checked plan checkboxes, and logged completion so the initiative can be archived after the soak window. Artifacts: `plans/active/REFACTOR-MEMOIZE-CORE-001/reports/2026-01-15T232107Z/`, `plans/active/REFACTOR-MEMOIZE-CORE-001/implementation.md`

### [PARALLEL-API-INFERENCE] Programmatic TF/PyTorch API parity
- Depends on: None
- Priority: Medium
- Status: pending — paused while DEBUG-SIM-LINES-DOSE-001 is active
- Owner/Date: TBD/2026-01-09
- Working Plan: `plans/active/PARALLEL-API-INFERENCE/plan.md`
- Summary: `plans/active/PARALLEL-API-INFERENCE/summary.md`
- Reports Hub: `plans/active/PARALLEL-API-INFERENCE/reports/`
- Spec Owner: `specs/ptychodus_api_spec.md`
- Test Strategy: `tests/scripts/test_tf_inference_helper.py`, `tests/scripts/test_api_demo.py`
- Goals:
  - Provide a single programmatic entry point that can train + infer via TensorFlow or PyTorch without shell wrappers.
  - Extract reusable TensorFlow inference helper so `_run_tf_inference_and_reconstruct()` mirrors the PyTorch helper.
  - Update `scripts/pytorch_api_demo.py` to exercise both backends and add smoke tests.
- Exit Criteria:
  - `_run_tf_inference_and_reconstruct()` helper exposed (done) and consumed by new programmatic flows.
  - `scripts/pytorch_api_demo.py` drives both backends, uses core helpers (TF + PyTorch), and captures outputs under `tmp/api_demo/<backend>/`.
  - `tests/scripts/test_api_demo.py` exercises imports/signatures plus marked slow end-to-end runs for both backends; helper tests continue to pass.
- Attempts History:
  - *2026-01-09T010000Z:* Completed exploration + extraction design for TF helper. Artifacts: `plans/active/PARALLEL-API-INFERENCE/reports/2026-01-09T010000Z/extraction_design.md`.
  - *2026-01-09T020000Z:* Implemented `_run_tf_inference_and_reconstruct()` and `extract_ground_truth()`, deprecated `perform_inference`, and added 7 regression tests + integration workflow run (all green). Artifacts: `plans/active/PARALLEL-API-INFERENCE/reports/2026-01-09T020000Z/`.
  - *2026-01-09T030000Z:* Reviewed Task 1 results and scoped Task 2-3 (demo script + smoke test). Artifacts: `plans/active/PARALLEL-API-INFERENCE/reports/2026-01-09T030000Z/`.
  - *2026-01-15T225312Z:* Added initial smoke tests for `scripts/pytorch_api_demo.py` (import + signature) and reran TF helper regression suite; slow execution tests still deselected pending demo parity. Artifacts: `plans/active/PARALLEL-API-INFERENCE/reports/2026-01-15T225312Z/pytest_collect.log`, `pytest_tf_helper_regression.log`, `pytest_api_demo.log`.

### [ORCH-ROUTER-001] Router prompt + orchestration dispatch layer
- Depends on: None
- Priority: Medium
- Status: done — Phase C verification complete (ready for archive)
- Owner/Date: Codex/2026-01-20
- Working Plan: `plans/active/ORCH-ROUTER-001/implementation.md`
- Summary: `plans/active/ORCH-ROUTER-001/summary.md`
- Reports Hub: `.artifacts/orch-router-001/`
- Spec Owner: `scripts/orchestration/README.md`
- Test Strategy: `plans/active/ORCH-ROUTER-001/test_strategy.md`
- Goals:
  - Add a router loop with deterministic routing + optional prompt override.
  - Preserve sync semantics while enforcing allowlist and crash behavior.
- Exit Criteria:
  - Deterministic routing + router override verified.
  - Allowlist and failure behavior documented and tested.
  - Logging/state annotations captured as specified in the plan.
- Attempts History:
  - *2026-01-20T011707Z:* Drafted implementation plan, test strategy, and summary. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,test_strategy.md,summary.md}`.
  - *2026-01-20T012145Z:* Refined the plan to locate the routing function in `scripts/orchestration/router.py`, document YAML-as-parameters-only, and clarify review cadence/state.json decisions. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.
  - *2026-01-20T012303Z:* Clarified routing contract to use review cadence every N iterations with actor gating and router precedence, and constrained state.json persistence to the last selected prompt only. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.
  - *2026-01-20T012542Z:* Drafted the Phase A routing contract artifact and marked A0-A2 complete in the plan (routing contract + state.json field + test strategy linkage). Artifacts: `plans/active/ORCH-ROUTER-001/{routing_contract.md,implementation.md,summary.md}`.
  - *2026-01-20T012735Z:* Expanded plan documentation steps to include docs/index.md updates in Phase A/C. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.
  - *2026-01-20T012912Z:* Addressed plan conformance issues: added missing context priming fields, clarified router override source, and made state.json persistence/log archival requirements explicit. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.
  - *2026-01-20T013928Z:* Implemented deterministic router entrypoint + wrapper, added pytest coverage, and updated test registry docs.
    - Metrics: `ruff check scripts/orchestration/router.py tests/tools/test_orchestration_router.py`, `pytest --collect-only tests/tools/test_orchestration_router.py -v`, `pytest tests/tools/test_orchestration_router.py -v`
    - Artifacts: `.artifacts/orch-router-001/{ruff_check.log,pytest_collect_router.log,pytest_router.log}`
  - *2026-01-20T015442Z:* Implemented router prompt overrides, config wiring, logging + `last_prompt` state annotation, and documented router behavior in the orchestration README/index while expanding router tests.
    - Metrics: `ruff check scripts/orchestration/router.py scripts/orchestration/config.py scripts/orchestration/state.py scripts/orchestration/loop.py scripts/orchestration/supervisor.py tests/tools/test_orchestration_router.py`, `pytest --collect-only tests/tools/test_orchestration_router.py -v`, `pytest tests/tools/test_orchestration_router.py -v`
    - Artifacts: `.artifacts/orch-router-001/{ruff_check.log,pytest_collect_router.log,pytest_router.log}`
  - *2026-01-20T020234Z:* Added router mode config (`router_first`/`router_only`), router-only enforcement, router prompt template, and documented mode precedence; expanded router tests for mode selection and router-only gating.
    - Metrics: `ruff check scripts/orchestration/router.py scripts/orchestration/config.py scripts/orchestration/state.py scripts/orchestration/loop.py scripts/orchestration/supervisor.py tests/tools/test_orchestration_router.py`, `pytest --collect-only tests/tools/test_orchestration_router.py -v`, `pytest tests/tools/test_orchestration_router.py -v`
    - Artifacts: `.artifacts/orch-router-001/{ruff_check.log,pytest_collect_router.log,pytest_router.log}`
  - *2026-01-20T020954Z:* Relocated router tests into the orchestration submodule, removed the main-repo test entry, and updated testing docs to reference the submodule selector.
    - Metrics: `ruff check scripts/orchestration/tests/test_router.py`, `pytest --collect-only scripts/orchestration/tests/test_router.py -v`, `pytest scripts/orchestration/tests/test_router.py -v`
    - Artifacts: `.artifacts/orch-router-001/{ruff_check.log,pytest_collect_router.log,pytest_router.log}`
  - *2026-01-20T023143Z:* Added loss gating to the long integration test by extracting final intensity_scaler_inv_loss metrics, writing train_metrics.json, and failing when val_intensity_scaler_inv_loss > 50 (no long integration run yet).
    - Artifacts: `.artifacts/orch-router-001/2026-01-20_integration_loss_gate_note.md`
  - *2026-01-20T023226Z:* Ran the long integration test with loss gating; val_intensity_scaler_inv_loss=38.9062 (<= 50) and train_metrics.json recorded.
    - Metrics: `RUN_LONG_INTEGRATION=1 INTEGRATION_OUTPUT_DIR=.artifacts/integration_manual_1000_512/2026-01-20T023226Z/output pytest tests/test_integration_manual_1000_512.py -v`
    - Artifacts: `.artifacts/integration_manual_1000_512/2026-01-20T023226Z/{pytest_manual_1000_512_run.log,output/train_metrics.json,output/train.log,output/inference.log}`
  - *2026-01-20T013743Z:* Added Phase B checklist item to create `prompts/router.md` with a strict single-line output contract. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.
  - *2026-01-20T015415Z:* Added Phase D for router-first/router-only mode support, with config + tests + doc updates and exit criteria coverage. Artifacts: `plans/active/ORCH-ROUTER-001/{implementation.md,summary.md}`.

### [ORCH-ORCHESTRATOR-001] Combined orchestrator entrypoint + shared runner refactor
- Depends on: ORCH-ROUTER-001 (router selection logic)
- Priority: Medium
- Status: in_progress — Phase C complete; full-suite regression gate pending
- Owner/Date: user+Codex/2026-01-20
- Working Plan: `plans/active/ORCH-ORCHESTRATOR-001/implementation.md`
- Summary: `plans/active/ORCH-ORCHESTRATOR-001/summary.md`
- Reports Hub: `plans/active/ORCH-ORCHESTRATOR-001/reports/`
- Spec Owner: `scripts/orchestration/README.md`
- Test Strategy: `plans/active/ORCH-ORCHESTRATOR-001/test_strategy.md`
- Goals:
  - Add a single orchestrator entrypoint that can run supervisor/main prompts via router selection.
  - Refactor shared logic out of supervisor/loop to reuse runner utilities.
  - Preserve sync-via-git semantics and logging conventions.
- Exit Criteria:
  - Combined mode executes supervisor/main in sequence with router cadence.
  - Sync-via-git role mode respects expected_actor and state handoff semantics.
  - Review cadence runs once per iteration in combined mode.
  - Orchestrator tests pass and docs updated.
- Attempts History:
  - *2026-01-20T025735Z:* Drafted minimal design + implementation plan + test strategy. Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/{design.md,implementation.md,test_strategy.md}`.
  - *2026-01-20T032058Z:* Implemented shared runner + combined orchestrator + wrapper, refactored supervisor/loop to use runner utilities, added combined-mode tests, and updated orchestration docs/test registries.
    - Metrics: `ruff check scripts/orchestration/runner.py scripts/orchestration/orchestrator.py scripts/orchestration/supervisor.py scripts/orchestration/loop.py scripts/orchestration/tests/test_orchestrator.py`, `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T032058Z/{ruff_check.log,pytest_collect_orchestrator.log,pytest_orchestrator.log}`
    - Next Actions: decide whether to run the broader regression suite to satisfy the full-suite exit criterion.
  - *2026-01-20T032929Z:* Added coverage for galph-only router override and router-disabled behavior, refreshed plan evidence links, and reran the orchestrator tests.
    - Metrics: `ruff check scripts/orchestration/tests/test_orchestrator.py`, `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T032929Z/{ruff_check.log,pytest_collect_orchestrator.log,pytest_orchestrator.log}`
    - Next Actions: decide whether to run the broader regression suite to satisfy the full-suite exit criterion.
  - *2026-01-20T034106Z:* Debugged combined-mode error handling (non-data-contract issue): validated config expectation for `logs_dir`, isolated `run_combined_iteration` prompt-selection failures, added failing tests for missing prompt/router_only output, and implemented failure stamping + logging plus role-mode prompt override forwarding.
    - Metrics: `ruff check scripts/orchestration/orchestrator.py scripts/orchestration/tests/test_orchestrator.py`, `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T034106Z/{ruff_check.log,pytest_collect_orchestrator.log,pytest_orchestrator.log,summary.md}`
    - Next Actions: decide whether to run the broader regression suite to satisfy the full-suite exit criterion.
  - *2026-01-20T034858Z:* Added role-mode guard/forwarding tests (role required, sync required, prompt env forwarding) and refreshed test registry.
    - Metrics: `ruff check scripts/orchestration/tests/test_orchestrator.py`, `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T034858Z/{ruff_check.log,pytest_collect_orchestrator.log,pytest_orchestrator.log,summary.md}`
    - Next Actions: decide whether to run the broader regression suite to satisfy the full-suite exit criterion.
  - *2026-01-20T050619Z:* Updated the plan to add Phase D combined-mode auto-commit (local-only, dry-run/no-git) and expanded the test strategy for new auto-commit coverage.
    - Metrics: N/A — planning update only
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/{implementation.md,test_strategy.md,summary.md}`
  - *2026-01-20T051859Z:* Implemented combined auto-commit helpers + flags, wired best-effort auto-commit after galph/ralph, added Phase D tests, and updated orchestration/testing docs.
    - Metrics: `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T051859Z/{pytest_collect_orchestrator.log,pytest_orchestrator.log}`
  - *2026-01-20T052323Z:* Ran integration marker gate for combined auto-commit changes.
    - Metrics: `pytest -v -m integration` (1 passed, 3 skipped)
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T052323Z/pytest_integration.log`
  - *2026-01-20T055056Z:* Added iteration tags to combined auto-commit commit messages, wired the iteration through combined mode, and added test coverage plus README updates.
    - Metrics: `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T055056Z/{pytest_collect_orchestrator.log,pytest_orchestrator.log}`
  - *2026-01-20T055542Z:* Added role-prefixed combined auto-commit messages (SUPERVISOR AUTO / RALPH AUTO), expanded auto-commit tests, and refreshed README guidance.
    - Metrics: `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T055542Z/{pytest_collect_orchestrator.log,pytest_orchestrator.log}`
  - *2026-01-20T061629Z:* Expanded reviewer prompt requirements to include deeper change analysis, plan/design/implementation quality, and architecture consistency checks.
    - Metrics: N/A (prompt-only update)
    - Artifacts: `prompts/reviewer.md`
  - *2026-01-20T061929Z:* Added prompt names to combined auto-commit commit messages, updated auto-commit tests, and refreshed combined-mode documentation.
    - Metrics: `pytest --collect-only scripts/orchestration/tests/test_orchestrator.py -v`, `pytest scripts/orchestration/tests/test_orchestrator.py -v`
    - Artifacts: `plans/active/ORCH-ORCHESTRATOR-001/reports/2026-01-20T061929Z/{pytest_collect_orchestrator.log,pytest_orchestrator.log}`
  - *2026-01-20T062508Z:* Updated reviewer prompt output requirements to write `user_input.md` when new actionable findings are discovered.
    - Metrics: N/A (prompt-only update)
    - Artifacts: `prompts/reviewer.md`

### [ORCH-AGENT-DISPATCH-001] Per-role/per-prompt agent dispatch (codex vs claude)
- Depends on: ORCH-ORCHESTRATOR-001 (combined mode baseline)
- Priority: Medium
- Status: in_progress — Phase C tests complete; full-suite regression gate pending
- Owner/Date: Codex/2026-01-20
- Working Plan: `plans/active/ORCH-AGENT-DISPATCH-001/implementation.md`
- Summary: `plans/active/ORCH-AGENT-DISPATCH-001/summary.md`
- Reports Hub: `plans/active/ORCH-AGENT-DISPATCH-001/reports/`
- Spec Owner: `scripts/orchestration/README.md`
- Test Strategy: `plans/active/ORCH-AGENT-DISPATCH-001/test_strategy.md`
- Goals:
  - Allow selecting different agent CLIs by role or prompt (ex: codex for supervisor.md, claude for main.md).
  - Preserve default behavior when no agent mapping is configured.
  - Make combined mode resolve agent per selected prompt with explicit logging.
- Exit Criteria:
  - Agent resolution precedence implemented and documented.
  - Combined mode uses router-selected prompt to resolve agent.
  - Tests pass and orchestration docs/test registry updated with evidence.
- Attempts History:
  - *2026-01-20T053513Z:* Drafted implementation plan, summary, and test strategy for agent dispatch. Artifacts: `plans/active/ORCH-AGENT-DISPATCH-001/{implementation.md,summary.md,test_strategy.md}`.
  - *2026-01-20T055000Z:* Implemented per-role/per-prompt agent dispatch (config + CLI), added resolver tests, wired supervisor/loop/orchestrator logging, and updated orchestration docs/test registry.
    - Metrics: `ruff check scripts/orchestration/agent_dispatch.py scripts/orchestration/orchestrator.py scripts/orchestration/supervisor.py scripts/orchestration/loop.py scripts/orchestration/tests/test_agent_dispatch.py`, `pytest --collect-only scripts/orchestration/tests/test_agent_dispatch.py -v`, `pytest scripts/orchestration/tests/test_agent_dispatch.py -v`
    - Artifacts: `plans/active/ORCH-AGENT-DISPATCH-001/reports/2026-01-20T055000Z/{ruff_check.log,pytest_collect_agent_dispatch.log,pytest_agent_dispatch.log,summary.md}`
    - Next Actions: decide whether to run the broader regression suite to satisfy the full-suite exit criterion.

### [DOC-HYGIENE-20260120] Reviewer doc/prompt fixes
- Depends on: ORCH-ORCHESTRATOR-001 (reviewer override flow)
- Priority: High (blocking reviewer gate)
- Status: done — 2026-01-20
- Owner/Date: Codex/2026-01-20
- Working Plan: N/A (single-loop documentation cleanup)
- Summary: Fix the broken references flagged in reviewer findings — point `docs/GRIDSIZE_N_GROUPS_GUIDE.md` to the real configuration/data-contract docs and update `prompts/arch_writer.md` to cite existing spec anchors so authors land on valid sections.
- Reports Hub: `plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T150500Z/` (planning notes + summary)
- Goals:
  - Ensure all “Related Documentation” links in the gridsize guide resolve to real files.
  - Update prompt guidance so architecture writers cite live spec anchors (`pipeline-normative`, `data-formats-normative`) instead of 404s.
- Exit Criteria:
  - The docs build without broken links for the updated targets.
  - `prompts/arch_writer.md` references anchors that exist in the checked-in specs.
- Attempts History:
  - *2026-01-20T150500Z:* Replaced the stale quick links in `docs/GRIDSIZE_N_GROUPS_GUIDE.md` with `docs/CONFIGURATION.md`, `../specs/data_contracts.md`, and `docs/COMMANDS_REFERENCE.md`, and rewired `prompts/arch_writer.md` to reference `../specs/spec-ptycho-workflow.md#pipeline-normative` and `../specs/spec-ptycho-interfaces.md#data-formats-normative`. Logged the change under the DEBUG-SIM-LINES-DOSE-001 artifacts hub because the reviewer override was processed in that focus.
