# Agent Implementation Checklist: Phase 2 - Statistical Aggregation and Plotting

**Overall Goal for this Phase:** To enhance the `aggregate_and_plot_results.py` script to handle the new trial directory structure, compute robust statistics (median, percentiles), and generate plots with percentile bands while gracefully handling failed training runs.

**Instructions for Agent:**
1. Copy this checklist into your working memory.
2. Update the `State` for each item as you progress: `[ ]` (Open) -> `[P]` (In Progress) -> `[D]` (Done).
3. Follow the `How/Why & API Guidance` column carefully for implementation details.

---

| ID | Task Description | State | How/Why & API Guidance |
| :-- | :-- | :-- | :-- |
| **Section 0: Preparation & Context Priming** |
| 0.A | **Review Key Documents & APIs** | `[D]` | **Why:** To understand the current aggregation script and the new requirements. <br> **Docs:** `docs/studies/multirun/plan_statistical_generalization.md`, `scripts/studies/aggregate_and_plot_results.py`. <br> **APIs:** `pandas.groupby().quantile()`, `matplotlib.pyplot.fill_between()`, `numpy.isnan()`, `numpy.isinf()`. |
| 0.B | **Identify Target Files for Modification** | `[D]` | **Why:** To have a clear list of files that will be touched during this phase. <br> **Files:** `scripts/studies/aggregate_and_plot_results.py` (Modify). |
| **Section 1: Enhanced File Discovery for Multi-Trial Structure** |
| 1.A | **Update file discovery logic** | `[D]` | **Why:** The script currently expects `train_SIZE/comparison_metrics.csv` but now needs to find `train_SIZE/trial_N/comparison_metrics.csv`. <br> **How:** Modify the file discovery function to use recursive search with `glob.glob()` pattern like `train_*/trial_*/comparison_metrics.csv`. Store both training size and trial number for each discovered file. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 1.B | **Extract training size and trial info** | `[D]` | **Why:** Statistical aggregation needs to group by training size across multiple trials. <br> **How:** Parse directory paths to extract `train_size` (e.g., "512" from "train_512") and `trial` (e.g., "1" from "trial_1"). Store this metadata alongside the CSV data. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 1.C | **Validate discovered files** | `[D]` | **Why:** Ensure the script doesn't crash on incomplete or missing trial data. <br> **How:** Check that each discovered CSV file is readable and contains expected columns. Log warnings for missing trials but continue processing available data. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| **Section 2: Robust Data Loading with Failure Handling** |
| 2.A | **Implement NaN/failure detection** | `[D]` | **Why:** Failed training runs may produce NaN metrics or missing files. These should be treated as poor performance, not excluded from analysis. <br> **How:** After loading each CSV, check for NaN values using `pandas.isna()`. For each metric, define failure replacement values: PSNR/SSIM/FRC50 → 0 (poor quality), MAE/MSE → `np.inf` (high error). Replace NaN values accordingly. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 2.B | **Handle missing comparison files** | `[D]` | **Why:** If a trial completely failed, its `comparison_metrics.csv` might not exist. <br> **How:** For each expected trial (based on discovered trial directories), if the comparison file is missing, create a synthetic row with failure values for all metrics. This ensures every trial contributes to the statistics. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 2.C | **Validate metric ranges** | `[D]` | **Why:** Some metrics have expected ranges (e.g., PSNR > 0, SSIM ∈ [0,1]). Values outside these ranges indicate evaluation failures. <br> **How:** After loading, validate each metric against expected ranges. Replace out-of-range values with failure replacements. Log warnings for each replacement made. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| **Section 3: Statistical Aggregation with Percentiles** |
| 3.A | **Implement percentile aggregation** | `[D]` | **Why:** Replace mean/std with median and percentiles for robust statistics. <br> **How:** Group data by `(model_type, train_size)` using `pandas.groupby()`. For each group, compute `.quantile([0.25, 0.5, 0.75])` for each metric. Store results with column names like `metric_median`, `metric_p25`, `metric_p75`. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 3.B | **Handle insufficient trial data** | `[D]` | **Why:** If a training size has very few successful trials, percentile calculation may be unreliable. <br> **How:** Check that each group has at least 3 trials. If fewer, compute available statistics but flag with warnings. For single trials, set median = value, p25 = p75 = median. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 3.C | **Export aggregated statistics** | `[D]` | **Why:** The results CSV should contain the new percentile-based statistics. <br> **How:** Modify the CSV export to include `_median`, `_p25`, `_p75` columns for each metric instead of `_mean`, `_std`. Ensure the file format is compatible with existing visualization scripts. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| **Section 4: Enhanced Plotting with Percentile Bands** |
| 4.A | **Update main plotting function** | `[D]` | **Why:** Replace mean ± std visualization with median and percentile bands. <br> **How:** Modify the plotting function to use `median` as the central line and `plt.fill_between(x, p25, p75, alpha=0.3)` for the shaded region. Update legend to indicate "Median ± IQR" instead of "Mean ± Std". <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 4.B | **Handle edge cases in plotting** | `[D]` | **Why:** If p25 = p75 (e.g., from a single trial), fill_between produces a line instead of a band. <br> **How:** Detect when p25 ≈ p75 and plot only the median line with a different style (e.g., dashed) to indicate limited trial data. Add a note to the plot legend. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 4.C | **Update plot titles and labels** | `[D]` | **Why:** To clearly communicate the new statistical approach. <br> **How:** Update plot titles to mention "Median Performance" and "Interquartile Range". Update axis labels and figure captions to reflect the robust statistics being displayed. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| **Section 5: Testing and Verification** |
| 5.A | **Create mock multi-trial dataset** | `[D]` | **Why:** To test the new aggregation logic without running full training. <br> **How:** Create a test directory structure `test_output/train_512/trial_{1,2,3}/comparison_metrics.csv` with known metric values (e.g., PSNR: [80, 85, 90]). Include one trial with NaN values to test failure handling. <br> **File:** Create temporary test files. |
| 5.B | **Test statistical aggregation** | `[D]` | **Why:** Verify that median and percentiles are computed correctly. <br> **How:** Run the modified script on the mock dataset. Verify that for PSNR values [80, 85, 90]: median=85, p25=82.5, p75=87.5. Verify that NaN values are replaced with 0 for PSNR. <br> **File:** Run script and check outputs. |
| 5.C | **Test plot generation** | `[D]` | **Why:** Ensure the new plotting logic produces valid visualizations. <br> **How:** Generate plots from the mock data. Verify that: 1) Median line is displayed, 2) Percentile band is visible, 3) Legend indicates median/IQR, 4) Plot doesn't crash with edge cases. <br> **File:** Check generated plot files. |
| **Section 6: Integration and Finalization** |
| 6.A | **Test with real Phase 1 output** | `[D]` | **Why:** Verify compatibility with the actual trial directory structure from Phase 1. <br> **How:** If any Phase 1 trial results exist, test the script on real multi-trial data. If not available, create a realistic mock structure matching Phase 1 output paths. <br> **File:** Test on real or realistic data. |
| 6.B | **Update script documentation** | `[D]` | **Why:** To document the new behavior for future users. <br> **How:** Add docstrings explaining the trial discovery logic, failure handling, and percentile aggregation. Update any help text or comments to reflect the new approach. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |
| 6.C | **Performance optimization** | `[D]` | **Why:** Processing many trials may be slower than the original single-file approach. <br> **How:** Ensure efficient file loading (avoid redundant reads). Consider using `pandas.concat()` for combining trial data instead of iterative appending. Profile if necessary. <br> **File:** `scripts/studies/aggregate_and_plot_results.py`. |