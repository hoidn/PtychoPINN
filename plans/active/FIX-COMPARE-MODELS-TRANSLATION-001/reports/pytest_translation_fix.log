============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 2 items

tests/study/test_dose_overlap_comparison.py::test_pinn_reconstruction_reassembles_batched_predictions PASSED [ 50%]
tests/study/test_dose_overlap_comparison.py::test_pinn_reconstruction_reassembles_full_train_split FAILED [100%]

=================================== FAILURES ===================================
____________ test_pinn_reconstruction_reassembles_full_train_split _____________

    def test_pinn_reconstruction_reassembles_full_train_split():
        """
        Test that ReassemblePatchesLayer can handle large dense datasets (>=5k patches)
        without Translation layer shape mismatches.
    
        Exit criteria:
        - Layer processes >=5k patches successfully via batched reassembly path
        - Translation layer receives matching patch/offset tensor shapes in each batch
        - Output shape is correct (1, padded_size, padded_size, 1) for complex tensors
        - No ValueError from Translation layer about mismatched input shapes
    
        This regression test guards the fix in ptycho/custom_layers.py:ReassemblePatchesLayer
        that switches to batched processing for large patch counts to avoid the Translation
        ValueError that blocked dense Phase G comparisons.
        """
        import tensorflow as tf
        import numpy as np
        from ptycho.custom_layers import ReassemblePatchesLayer
        from ptycho import params
    
        # Simulate dense dataset dimensions matching Phase G dense train split
        # Dense fly64 has ~5088 patches (B=159 batches of 32 patches each, C=4 channels)
        B = 159  # Number of prediction batches
        N = 138  # Patch size (fly64 reconstruction size)
        C = 4    # gridsizeÂ² = 2Â² = 4 channels for overlapping patches
    
        # Create synthetic patches in channel format (B, N, N, C)
        # Use small random values to keep memory reasonable
        patches = tf.random.normal((B, N, N, C), dtype=tf.float32)
    
        # Create synthetic positions in channel format (B, 1, 2, C)
        # Positions should be in range that makes sense for reassembly
        positions = tf.random.uniform((B, 1, 2, C), minval=-50, maxval=50, dtype=tf.float32)
    
        # Set up params.cfg for the layer (required by reassembly helpers)
        params.set('gridsize', 2)
        params.set('N', N)
        # Padded size typically N + some padding (e.g., 10px on each side)
        padded_size = N + 20
        params.set('padded_size', padded_size)
        params.set('max_position_jitter', 0)  # Required by get_padded_size()
    
        # Create layer with batch_size=64 (default) to trigger batching for B*C=636 patches
        layer = ReassemblePatchesLayer(batch_size=64)
    
        try:
            # Call layer - this should use batched reassembly internally
            # since B*C = 159*4 = 636 > 64
>           result = layer([patches, positions])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/study/test_dose_overlap_comparison.py:795: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122: in error_handler
    raise e.with_traceback(filtered_tb) from None
ptycho/custom_layers.py:176: in call
    return tf.cond(
ptycho/custom_layers.py:167: in use_batched
    return hh.reassemble_patches(patches,
ptycho/tf_helper.py:1045: in reassemble_patches
    assembled_real = fn_reassemble_real(real, average = average, **kwargs) / mk_norm(real,
ptycho/tf_helper.py:1022: in mk_norm
    assembled_ones = fn_reassemble_real(ones, average = False)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:678: in newf
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1294: in reassemble_patches_position_batched_real
    return _reassemble_position_batched(imgs, input_positions, padded_size, batch_size, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:976: in _reassemble_position_batched
    return tf.cond(
ptycho/tf_helper.py:961: in batched_approach
    _, final_canvas = tf.while_loop(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

i = <tf.Tensor: shape=(), dtype=int32, numpy=0>
canvas = <tf.Tensor: shape=(1, 142, 142, 1), dtype=float32, numpy=
array([[[[0.],
         [0.],
         [0.],
         ...,
 ...     [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]]]], dtype=float32)>

    def body(i, canvas):
        # Calculate batch boundaries
        start_idx = i
        end_idx = tf.minimum(i + batch_size, num_patches)
    
        # Extract batch - handle case where batch might be smaller than batch_size
        batch_imgs = imgs_flat[start_idx:end_idx]
        batch_offsets = offsets_flat[start_idx:end_idx]
    
        # Ensure offsets have the right shape: (batch_size, 2)
        batch_offsets = tf.ensure_shape(batch_offsets, [None, 2])
    
        # Only process if we have images in the batch
        def process_batch():
            batch_imgs_padded = pad_patches(batch_imgs, padded_size)
            batch_translated = Translation(jitter_stddev=0.0, use_xla=should_use_xla())([batch_imgs_padded, -batch_offsets])
            # Sum directly over batch dimension to accumulate onto canvas
            # Shape: (batch_size_actual, padded_size, padded_size, 1) -> (1, padded_size, padded_size, 1)
            batch_summed = tf.reduce_sum(batch_translated, axis=0, keepdims=True)
            return batch_summed
    
        def skip_batch():
            return tf.zeros_like(canvas)
    
        # Only process if we have a non-empty batch
        batch_result = tf.cond(
            tf.greater(end_idx, start_idx),
            process_batch,
            skip_batch
        )
    
>       return end_idx, canvas + batch_result
                        ^^^^^^^^^^^^^^^^^^^^^
E       tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ReassemblePatchesLayer.call().
E       
E       [1m{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: [0m
E       
E       Arguments received by ReassemblePatchesLayer.call():
E         â€¢ inputs=['tf.Tensor(shape=(159, 138, 138, 4), dtype=float32)', 'tf.Tensor(shape=(159, 1, 2, 4), dtype=float32)']

ptycho/tf_helper.py:959: InvalidArgumentError
----------------------------- Captured stdout call -----------------------------
DEBUG: Setting gridsize to 2 in params
DEBUG: Setting N to 138 in params
DEBUG: Setting padded_size to 158 in params
DEBUG: Setting max_position_jitter to 0 in params
----------------------------- Captured stderr call -----------------------------
I0000 00:00:1763054676.358850 2190021 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1763054676.360242 2190021 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1763054677.138957 2190021 service.cc:152] XLA service 0x1d129680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1763054677.138979 2190021 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-11-13 09:24:37.152574: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1763054677.173517 2190021 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1763054677.768033 2190021 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-11-13 09:24:39.020433: W tensorflow/core/framework/op_kernel.cc:1844] INVALID_ARGUMENT: required broadcastable shapes
2025-11-13 09:24:39.020451: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: required broadcastable shapes
=========================== short test summary info ============================
FAILED tests/study/test_dose_overlap_comparison.py::test_pinn_reconstruction_reassembles_full_train_split - tensorflow.python.framework.errors_impl.InvalidArgumentError: Exception encountered when calling ReassemblePatchesLayer.call().

[1m{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} required broadcastable shapes [Op:AddV2] name: [0m

Arguments received by ReassemblePatchesLayer.call():
  â€¢ inputs=['tf.Tensor(shape=(159, 138, 138, 4), dtype=float32)', 'tf.Tensor(shape=(159, 1, 2, 4), dtype=float32)']
========================= 1 failed, 1 passed in 6.68s ==========================
