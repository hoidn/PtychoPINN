============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_workflows_components.py::TestWorkflowsComponentsRun::test_run_cdi_example_invokes_training FAILED [100%]

=================================== FAILURES ===================================
_______ TestWorkflowsComponentsRun.test_run_cdi_example_invokes_training _______

self = <test_workflows_components.TestWorkflowsComponentsRun object at 0x7b7481991890>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7b747c580790>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'sigmoid', 'batch_size': 16, 'big_gridsize': 10, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', obj...e_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False)
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7b73967e1290>

    def test_run_cdi_example_invokes_training(
        self,
        monkeypatch,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data
    ):
        """
        CRITICAL PARITY TEST: run_cdi_example_torch must invoke training orchestration.
    
        Requirement: Phase D2.C must implement full workflow orchestration following
        TensorFlow baseline ptycho/workflows/components.py:676-723 and mirroring
        the reconstructor lifecycle per specs/ptychodus_api_spec.md §4.5.
    
        Red-phase contract:
        - Entry signature: run_cdi_example_torch(train_data, test_data, config, do_stitching=False, ...)
        - MUST call train_cdi_model_torch(train_data, test_data, config) first
        - When do_stitching=False: return (None, None, results_dict)
        - When do_stitching=True + test_data: invoke reassemble helper, return (amp, phase, results)
        - results dict MUST contain keys from training (history, containers)
    
        Test mechanism:
        - Use monkeypatch to spy on train_cdi_model_torch call
        - Pass minimal RawData + do_stitching=False (no inference path required)
        - Assert train_cdi_model_torch was invoked with correct args
        - Validate return signature matches TensorFlow baseline
        """
        # Import the module under test
        from ptycho_torch.workflows import components as torch_components
    
        # Spy flag to track train_cdi_model_torch invocation
        train_cdi_model_torch_called = {"called": False, "args": None}
    
        def mock_train_cdi_model_torch(train_data, test_data, config):
            """Spy that records train_cdi_model_torch invocation."""
            train_cdi_model_torch_called["called"] = True
            train_cdi_model_torch_called["args"] = (train_data, test_data, config)
            # Return minimal training results dict
            return {
                "history": {"train_loss": [0.5, 0.3]},
                "train_container": {"sentinel": "train"},
                "test_container": None,
            }
    
        # Patch train_cdi_model_torch
        monkeypatch.setattr(
            "ptycho_torch.workflows.components.train_cdi_model_torch",
            mock_train_cdi_model_torch
        )
    
        # Call run_cdi_example_torch with do_stitching=False (Phase D2.C red phase)
>       recon_amp, recon_phase, results = torch_components.run_cdi_example_torch(
            train_data=dummy_raw_data,
            test_data=None,
            config=minimal_training_config,
            flip_x=False,
            flip_y=False,
            transpose=False,
            M=20,
            do_stitching=False,
        )

tests/torch/test_workflows_components.py:443: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

train_data = <ptycho.raw_data.RawData object at 0x7b73967e1290>
test_data = None
config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', obj...e_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False)
flip_x = False, flip_y = False, transpose = False, M = 20, do_stitching = False

    def run_cdi_example_torch(
        train_data: Union[RawData, 'RawDataTorch', 'PtychoDataContainerTorch'],
        test_data: Optional[Union[RawData, 'RawDataTorch', 'PtychoDataContainerTorch']],
        config: TrainingConfig,
        flip_x: bool = False,
        flip_y: bool = False,
        transpose: bool = False,
        M: int = 20,
        do_stitching: bool = False
    ) -> Tuple[Optional[Any], Optional[Any], Dict[str, Any]]:
        """
        Run the main CDI example execution flow using PyTorch backend.
    
        This function provides API parity with ptycho.workflows.components.run_cdi_example,
        enabling transparent backend selection from Ptychodus per specs/ptychodus_api_spec.md §4.5.
    
        CRITICAL: This function MUST call update_legacy_dict(params.cfg, config) before
        delegating to core modules to prevent CONFIG-001 violations (empty params.cfg
        causing silent shape mismatches downstream).
    
        Args:
            train_data: Training data (RawData, RawDataTorch, or PtychoDataContainerTorch)
            test_data: Optional test data (same type constraints as train_data)
            config: TrainingConfig instance (TensorFlow dataclass, translated via config_bridge)
            flip_x: Whether to flip the x coordinates during reconstruction
            flip_y: Whether to flip the y coordinates during reconstruction
            transpose: Whether to transpose the image by swapping dimensions
            M: Parameter for reassemble_position function (default: 20)
            do_stitching: Whether to perform image stitching after training
    
        Returns:
            Tuple containing:
            - reconstructed amplitude (or None if stitching disabled)
            - reconstructed phase (or None if stitching disabled)
            - results dictionary (training history, containers, metrics)
    
        Raises:
            NotImplementedError: Phase D2.B/C not yet implemented (scaffold only)
    
        Phase D2.A Scaffold Status:
            - Entry signature: ✅ COMPLETE (matches TensorFlow)
            - update_legacy_dict call: ✅ COMPLETE (CONFIG-001 compliance)
            - Placeholder logic: ✅ COMPLETE (raises NotImplementedError)
            - Torch-optional: ✅ COMPLETE (importable without torch)
    
        Phase D2.B/C TODO:
            - Implement train_cdi_model_torch delegation (Lightning trainer orchestration)
            - Implement reassemble_cdi_image_torch (optional stitching path)
            - Add MLflow disable flag handling
            - Validate deterministic seeds from config
    
        Example (Post D2.B/C):
            >>> from ptycho_torch.workflows.components import run_cdi_example_torch
            >>> from ptycho.config.config import TrainingConfig, ModelConfig
            >>> from ptycho.raw_data import RawData
            >>>
            >>> # Load data
            >>> train_data = RawData.from_file("train.npz")
            >>> config = TrainingConfig(model=ModelConfig(N=64), ...)
            >>>
            >>> # Execute PyTorch pipeline
            >>> amp, phase, results = run_cdi_example_torch(
            ...     train_data, None, config, do_stitching=False
            ... )
        """
        # CRITICAL: Update params.cfg before delegating (CONFIG-001 compliance)
        # This ensures legacy modules invoked downstream observe correct configuration state
        ptycho_config.update_legacy_dict(params.cfg, config)
        logger.info("PyTorch workflow: params.cfg synchronized with TrainingConfig")
    
        # Phase D2.B TODO: Implement training delegation
        # Expected flow:
        # 1. Convert train_data → PtychoDataContainerTorch via Phase C adapters
        # 2. Invoke train_cdi_model_torch (Lightning orchestration)
        # 3. If do_stitching + test_data: invoke reassemble_cdi_image_torch
        # 4. Return (amplitude, phase, results)
    
>       raise NotImplementedError(
            "PyTorch training path not yet implemented. "
            "Phase D2.B will implement Lightning trainer orchestration. "
            "See plans/active/INTEGRATE-PYTORCH-001/phase_d_workflow.md for roadmap."
        )
E       NotImplementedError: PyTorch training path not yet implemented. Phase D2.B will implement Lightning trainer orchestration. See plans/active/INTEGRATE-PYTORCH-001/phase_d_workflow.md for roadmap.

ptycho_torch/workflows/components.py:166: NotImplementedError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (10, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10,)
xcoords shape: (10,)
ycoords shape: (10,)
xcoords_start shape: (10,)
ycoords_start shape: (10,)
---------------------------- Captured stderr setup -----------------------------
2025-10-17 02:58:26.182032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760695106.193152 3557458 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760695106.196982 3557458 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1760695106.207724 3557458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760695106.207741 3557458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760695106.207743 3557458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760695106.207745 3557458 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-17 02:58:26.210534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
=========================== short test summary info ============================
FAILED tests/torch/test_workflows_components.py::TestWorkflowsComponentsRun::test_run_cdi_example_invokes_training - NotImplementedError: PyTorch training path not yet implemented. Phase D2.B will implement Lightning trainer orchestration. See plans/active/INTEGRATE-PYTORCH-001/phase_d_workflow.md for roadmap.
============================== 1 failed in 3.82s ===============================
