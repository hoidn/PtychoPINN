Phase R Backend Selector Integration — Artifact Inventory
========================================================

Date: 2025-11-13
Focus: INTEGRATE-PYTORCH-PARITY-001 — PyTorch backend API parity reactivation
Phase: CLI routing via backend selector

## Production Code Changes

1. scripts/training/train.py (lines 21-30, 176-188)
   - Replaced direct import of run_cdi_example with backend_selector.run_cdi_example_with_backend
   - Added backend-guarded persistence logic:
     * TensorFlow: calls model_manager.save() and save_outputs() as before
     * PyTorch: skips TensorFlow-only helpers, logs bundle_path from results
   - Preserves CONFIG-001 compliance via update_legacy_dict(params.cfg, config) at line 132

2. scripts/inference/inference.py (lines 37-41, 439-445)
   - Replaced direct import of load_inference_bundle with backend_selector.load_inference_bundle_with_backend
   - Updated load call to pass InferenceConfig for backend routing
   - Documented that update_legacy_dict is called inside the backend-specific loader (CONFIG-001)

## Test Coverage

1. tests/scripts/test_training_backend_selector.py (162 lines)
   - TestTrainingCliBackendDispatch::test_pytorch_backend_dispatch
     * Verifies training CLI calls run_cdi_example_with_backend with backend='pytorch'
     * Asserts model_manager.save() and save_outputs() are NOT called for PyTorch
     * Confirms results['backend'] == 'pytorch' and bundle_path is logged
   - TestTrainingCliBackendDispatch::test_tensorflow_backend_persistence
     * Verifies TensorFlow backend still calls model_manager.save() and save_outputs()
     * Confirms backward compatibility for existing TensorFlow workflows

2. tests/scripts/test_inference_backend_selector.py (164 lines)
   - TestInferenceCliBackendDispatch::test_pytorch_backend_dispatch
     * Verifies inference CLI calls load_inference_bundle_with_backend with backend='pytorch'
     * Confirms PyTorch model is returned and params_dict restored
   - TestInferenceCliBackendDispatch::test_tensorflow_backend_dispatch
     * Verifies TensorFlow backend routing continues to work
   - TestInferenceCliBackendDispatch::test_backend_selector_preserves_config_001_compliance
     * Documents that params.cfg restoration happens inside backend-specific loaders

## Test Evidence

1. green/pytest_training_backend_dispatch.log
   - Command: pytest tests/scripts/test_training_backend_selector.py::TestTrainingCliBackendDispatch -vv
   - Result: 2 passed in 3.70s
   - Status: GREEN ✅

2. green/pytest_inference_backend_dispatch.log
   - Command: pytest tests/scripts/test_inference_backend_selector.py::TestInferenceCliBackendDispatch -vv
   - Result: 3 passed in 3.66s
   - Status: GREEN ✅

## Policy Compliance

- POLICY-001: PyTorch>=2.2 enforced (tests show "PyTorch version: 2.8.0+cu128")
- CONFIG-001: update_legacy_dict called in training CLI before backend dispatch (train.py:132)
- TYPE-PATH-001: Path objects handled correctly in backend_selector

## Next Steps

Ready for next increment: End-to-end CLI execution tests with real PyTorch backend invocation.
