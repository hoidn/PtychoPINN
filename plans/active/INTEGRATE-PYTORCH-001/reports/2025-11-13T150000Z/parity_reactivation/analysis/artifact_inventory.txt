# Artifact Inventory - GPU-First Execution Config Defaults (2025-11-13)

## Overview
Extended PyTorch execution config defaults with dispatcher-level GPU-first auto-instantiation.
When torch_execution_config=None, backend_selector now creates a PyTorchExecutionConfig() with
auto-resolution to 'cuda' (if available) or 'cpu' (with POLICY-001 warning).

## Code Changes

### Backend Selector Auto-Instantiation
**File:** ptycho/workflows/backend_selector.py:161-168
**Purpose:** Auto-instantiate PyTorchExecutionConfig when torch_execution_config=None
**Changes:**
- Added conditional check: if torch_execution_config is None
- Instantiates PyTorchExecutionConfig() which triggers auto-resolution in __post_init__
- Logs resolved accelerator with POLICY-001 compliance message
- Ensures Ptychodus callers inherit GPU-first defaults without explicit config

### Test Coverage Extensions
**File:** tests/torch/test_execution_config_defaults.py:185-252
**Purpose:** test_backend_selector_inherits_gpu_first_defaults
**Coverage:**
- Mocks torch.cuda.is_available() to return True
- Patches ptycho_torch.workflows.components.run_cdi_example_torch
- Calls run_cdi_example_with_backend with torch_execution_config=None
- Verifies execution_config.accelerator == 'cuda'

**File:** tests/torch/test_execution_config_defaults.py:254-326
**Purpose:** test_backend_selector_cpu_fallback_with_warning
**Coverage:**
- Mocks torch.cuda.is_available() to return False
- Patches run_cdi_example_torch to capture execution_config
- Verifies execution_config.accelerator == 'cpu'
- Verifies POLICY-001 warning is emitted with "No CUDA device detected"

## Test Evidence

### Pytest Execution (GREEN)
**Selector:** pytest tests/torch/test_execution_config_defaults.py -vv
**Result:** 7 PASSED, 1 SKIPPED in 3.60s
**Log:** plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/green/pytest_execution_config_defaults.log

**Test Breakdown:**
1. test_auto_prefers_cuda: PASSED (existing)
2. test_auto_warns_and_falls_back_to_cpu: PASSED (existing)
3. test_explicit_cpu_bypasses_auto_resolution: PASSED (existing)
4. test_explicit_cuda_bypasses_auto_resolution: PASSED (existing)
5. test_workflow_auto_instantiates_with_hardware_detection: PASSED (existing)
6. test_backend_selector_warns_on_cpu_only_hosts: SKIPPED (CUDA available on host)
7. test_backend_selector_inherits_gpu_first_defaults: PASSED (NEW)
8. test_backend_selector_cpu_fallback_with_warning: PASSED (NEW)

## Policy Compliance

### POLICY-001 (PyTorch GPU-First)
**Compliance:** FULL
- Backend selector auto-instantiates PyTorchExecutionConfig when torch_execution_config=None
- Auto-resolution prefers 'cuda' on CUDA-capable hosts
- Falls back to 'cpu' with POLICY-001 warning on CPU-only hosts
- Ptychodus callers inherit GPU baseline without explicit configuration

### CONFIG-001 (Legacy Params Bridge)
**Status:** PRESERVED
- No changes to update_legacy_dict calls
- Backend selector still synchronizes params.cfg before dispatch

### CONFIG-002 (Execution Config Scope)
**Status:** PRESERVED
- torch_execution_config remains optional parameter
- Auto-instantiation only occurs when explicitly None
- Explicit configs bypass auto-resolution

### CONFIG-LOGGER-001 (Logger Backend)
**Status:** PRESERVED
- Default logger_backend='csv' inherited via PyTorchExecutionConfig()
- No changes to logging configuration

## Integration Points

### Backend Selector Flow (Updated)
1. Client calls run_cdi_example_with_backend(..., torch_execution_config=None)
2. Dispatcher calls update_legacy_dict (CONFIG-001 gate)
3. **NEW:** If torch_execution_config is None, instantiate PyTorchExecutionConfig()
4. __post_init__ auto-resolves accelerator: 'auto' â†’ 'cuda'/'cpu'
5. Dispatcher delegates to torch_components.run_cdi_example_torch(..., execution_config=torch_execution_config)
6. PyTorch workflow receives fully-resolved execution config

### Backward Compatibility
- Existing callers passing explicit torch_execution_config: UNCHANGED
- TensorFlow backend (config.backend='tensorflow'): UNCHANGED
- PyTorch workflows with execution_config=None: NOW GPU-FIRST

## Known Limitations

### CPU-Only Host Warning Test
- test_backend_selector_warns_on_cpu_only_hosts: SKIPPED on CUDA hosts
- Cannot verify CPU fallback warning on GPU-capable test machines
- Test design allows manual verification on CPU-only CI runners

## References

- POLICY-001: docs/findings.md:7 (PyTorch GPU-first policy)
- CONFIG-001: docs/findings.md:9 (params.cfg bridge)
- CONFIG-002: docs/findings.md:10 (execution config scope)
- CONFIG-LOGGER-001: docs/findings.md:11 (logger backend defaults)
- Backend Selector: ptycho/workflows/backend_selector.py
- Execution Config: ptycho/config/config.py:PyTorchExecutionConfig

## Next Steps

None - dispatcher-level GPU-first defaults complete. Focus can shift to:
- CLI smoke testing with auto-instantiated configs
- Ptychodus integration verification
- Documentation updates in docs/workflows/pytorch.md
