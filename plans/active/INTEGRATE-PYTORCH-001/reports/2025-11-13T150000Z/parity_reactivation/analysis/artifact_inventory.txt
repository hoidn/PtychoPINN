# INTEGRATE-PYTORCH-PARITY-001 — CUDA Default Evidence (2025-11-13T20:20:00Z)

## Code Changes

### CLI Defaults Updated
- scripts/training/train.py:252: --torch-accelerator default changed from 'auto' to 'cuda'
- scripts/inference/inference.py:104: --torch-accelerator default changed from 'auto' to 'cuda'
- Help text updated to document CPU override path: --torch-accelerator cpu

### resolve_accelerator Enhancement
- ptycho_torch/cli/shared.py:26-104: Enhanced resolve_accelerator() function
  - Added auto-detection logic: 'auto' → 'cuda' when torch.cuda.is_available()
  - Falls back to 'cpu' with POLICY-001 UserWarning when CUDA unavailable
  - Emits actionable error message with PyTorch installation URL

### Test Updates
- tests/torch/test_cli_shared.py:121-164: Updated test_all_accelerator_values_passthrough
  - Excluded 'auto' from passthrough list (now special-cased)
  - Added new test_resolve_accelerator_auto_defaults covering CUDA detection logic

## Test Evidence

### Pytest GREEN (3 PASSED in 3.65s)
- Location: green/pytest_cuda_default_exec_config.log
- Selector: tests/scripts/test_training_backend_selector.py::TestTrainingCliBackendDispatch::test_pytorch_execution_config_flags
- Selector: tests/scripts/test_inference_backend_selector.py::TestInferenceCliBackendDispatch::test_pytorch_backend_moves_model_to_execution_device
- Selector: tests/torch/test_cli_shared.py::TestResolveAccelerator::test_resolve_accelerator_auto_defaults
- Result: All execution-config and auto-detection tests pass

## PyTorch Training CLI Smoke (CUDA Default)

### Command
```bash
CUDA_VISIBLE_DEVICES="0" python scripts/training/train.py \
  --train_data_file tike_outputs/fly001_final_downsampled/fly001_final_downsampled_data_transposed.npz \
  --backend pytorch \
  --n_images 100 \
  --nepochs 2 \
  --model_type pinn \
  --output_dir plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/cli/pytorch_cli_smoke_training/train_outputs \
  --torch-num-workers 0 \
  --torch-learning-rate 1e-3 \
  --torch-scheduler Default \
  --torch-logger csv
```
Note: --torch-accelerator flag OMITTED (defaults to 'cuda')

### Evidence
- Log: cli/pytorch_cli_smoke_training/train_cuda_default.log
- Key Lines:
  - "GPU available: True (cuda), used: True"
  - "CUDA_VISIBLE_DEVICES: [0]"
  - "NVIDIA GeForce RTX 3090"
- Bundle: cli/pytorch_cli_smoke_training/train_outputs/wts.h5.zip
- Status: SUCCESS (2 epochs completed, bundle saved)

## PyTorch Inference CLI Smoke (CUDA Default)

### Command
```bash
CUDA_VISIBLE_DEVICES="0" python scripts/inference/inference.py \
  --model_path plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/cli/pytorch_cli_smoke_training/train_outputs \
  --test_data tests/fixtures/pytorch_integration/minimal_dataset_v1.npz \
  --backend pytorch \
  --torch-num-workers 0 \
  --torch-inference-batch-size 2 \
  --output_dir plans/active/INTEGRATE-PYTORCH-001/reports/2025-11-13T150000Z/parity_reactivation/cli/pytorch_cli_smoke_training/inference_outputs
```
Note: --torch-accelerator flag OMITTED (defaults to 'cuda')

### Evidence
- Log: cli/pytorch_cli_smoke_training/inference_cuda_default.log
- Key Lines:
  - "PyTorch model moved to device: cuda"
  - "PyTorch inference config: accelerator=cuda, num_workers=0, inference_batch_size=2"
- Outputs:
  - reconstructed_amplitude.png (17K)
  - reconstructed_phase.png (23K)
- Status: SUCCESS (inference completed, PNGs generated)

## GPU Hardware

- Model: NVIDIA GeForce RTX 3090
- Driver: 570.195.03
- CUDA Version: 12.8 (PyTorch 2.8.0+cu128)

## Policy Compliance

- POLICY-001: GPU baseline enforced via CUDA default + auto-detection
- CONFIG-001: update_legacy_dict bridge remains intact
- CONFIG-LOGGER-001: CSV logger used (zero deps)
- EXEC-ACCUM-001: accumulate_grad_batches=1 (manual optimization safe)
- DATA-SUP-001: PINN mode used (no label requirements)
- DEVICE-MISMATCH-001: Resolved (commit 85478a67)

## Findings References

- POLICY-001: PyTorch GPU baseline mandatory
- CONFIG-001: Config bridge flow
- CONFIG-LOGGER-001: CSV logger default
- DEVICE-MISMATCH-001: Model device placement fix

## Next Actions

- Mark CUDA default work complete in fix_plan.md
- Update workflows/pytorch.md §12 table to reflect new CUDA default
- Prepend Turn Summary to initiative summary.md
