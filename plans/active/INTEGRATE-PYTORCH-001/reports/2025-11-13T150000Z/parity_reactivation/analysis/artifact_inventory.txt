# Artifact Inventory - CUDA Default Baseline (2025-11-12T20:24:00Z)

## Code Changes (Commit 420e2f14)
- scripts/training/train.py:252: --torch-accelerator default='cuda' (was 'auto')  
- scripts/inference/inference.py:104: --torch-accelerator default='cuda' (already correct, help text updated)
- Help text: Added POLICY-001 reference and documented CPU override path

## Test Evidence (GREEN)
- Selector: pytest tests/scripts/test_training_backend_selector.py::TestTrainingCliBackendDispatch::test_pytorch_execution_config_flags tests/scripts/test_inference_backend_selector.py::TestInferenceCliBackendDispatch::test_pytorch_backend_moves_model_to_execution_device tests/torch/test_cli_shared.py::TestResolveAccelerator::test_resolve_accelerator_auto_defaults -vv
- Result: 3 PASSED in 3.65s
- Log: green/pytest_cuda_default_exec_config.log
- PyTorch version: 2.8.0+cu128

## CLI Smoke Evidence (GPU Baseline)

### Training (CUDA Default)
- Command: python scripts/training/train.py ... --backend pytorch ... (NO --torch-accelerator flag)
- Log: cli/pytorch_cli_smoke_training/train_cuda_default.log
- Key Evidence:
  * "PyTorch execution config built: accelerator=cuda, num_workers=0, learning_rate=0.001, logger_backend=csv"
  * "GPU available: True (cuda), used: True"
  * "NVIDIA GeForce RTX 3090, Compute Capability 8.6"
- Status: Training completed successfully (2 epochs), bundle saved to wts.h5.zip (8.2M)

### Inference (CUDA Default)
- Command: python scripts/inference/inference.py ... --backend pytorch ... (NO --torch-accelerator flag)
- Log: cli/pytorch_cli_smoke_training/inference_cuda_default.log
- Key Evidence:
  * "PyTorch inference config: accelerator=cuda, num_workers=0, inference_batch_size=2"
  * "Inference process completed successfully."
- Outputs:
  * reconstructed_amplitude.png (24K)
  * reconstructed_phase.png (16K)
- Amplitude range: [0.0000, 126.2376]
- Phase range: [-3.1416, 3.1416]

## GPU Environment
- GPU: NVIDIA GeForce RTX 3090
- CUDA: Available and used
- Compute capability: 8.6
- Memory: 22259 MB

## Policy Compliance
- POLICY-001: GPU baseline enforced via CUDA default
- CONFIG-001: update_legacy_dict bridge confirmed
- CONFIG-LOGGER-001: CSV logger active
- DEVICE-MISMATCH-001: Resolved (commit 85478a67)

## References
- Commit: 420e2f14
- Focus: INTEGRATE-PYTORCH-PARITY-001
- Docs: docs/workflows/pytorch.md ยง12/ยง13
