# Artifact Inventory — Supervised Loss Mapping Fix (2025-11-13T184500Z)

## Green Evidence (Tests Passing)
- green/pytest_backend_selector_cli.log
  - 3 PASSED in 5.25s
  - test_pytorch_execution_config_flags (training + inference)
  - test_supervised_mode_enforces_mae_loss (new regression coverage)
  - Verifies supervised mode forces loss_function='MAE' before Lightning instantiation

## CLI Attempts (Blocked by Downstream Issues)
- cli/pytorch_cli_smoke_training/train.log
  - Original attempt with --torch-accumulate-grad-batches 2
  - Blocked: manual optimization incompatible with automatic accumulation
  - Evidence: red/blocked_20251113T184100Z_manual_optim_accum.md
  
- cli/pytorch_cli_smoke_training/train_clean.log
  - Retry without accumulate flag
  - SUCCESS: Loss mapping fixed - no loss_name AttributeError
  - Blocked: KeyError 'label_amp' (supervised requires ground-truth labels)
  - Evidence: red/blocked_20251113T184300Z_supervised_data_contract.md

## Code Changes
- ptycho_torch/workflows/components.py:667-682
  - Added supervised→MAE loss enforcement in _train_with_lightning
  - Detects mode='Supervised' and overrides loss_function='MAE'
  - Prevents AttributeError: 'loss_name' missing
  
- tests/scripts/test_training_backend_selector.py:312-422
  - New test: test_supervised_mode_enforces_mae_loss
  - Regression coverage for supervised loss mapping

## Commit
- 2f36b6c6 "INTEGRATE-PYTORCH-PARITY-001 ptycho_torch: enforce loss_function='MAE' for supervised mode"
- Phase: R (supervised loss mapping)
- Tests: pytest_backend_selector_cli (3 PASSED)

## Outstanding Blockers
1. Manual optimization + accumulate_grad_batches incompatibility (defer)
2. Supervised mode requires labeled data (label_amp/label_phase keys) (defer)

## Next Actions
Per input.md Do Now steps 5-6:
- Switch to unsupervised (PINN) mode for CLI smoke validation
- OR defer supervised CLI smoke until labeled synthetic dataset available
- Document current progress in hub summaries
