============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 236 items / 2 skipped

tests/image/test_cropping.py::TestCroppingAlignment::test_align_for_evaluation_bounding_box PASSED [  0%]
tests/image/test_cropping.py::TestCroppingAlignment::test_align_for_evaluation_coordinates_format PASSED [  0%]
tests/image/test_cropping.py::TestCroppingAlignment::test_align_for_evaluation_shapes PASSED [  1%]
tests/image/test_cropping.py::TestCroppingAlignment::test_align_for_evaluation_with_squeeze PASSED [  1%]
tests/image/test_cropping.py::TestCroppingAlignment::test_center_crop_exact_size PASSED [  2%]
tests/image/test_registration.py::TestRegistration::test_apply_shift_and_crop_basic PASSED [  2%]
tests/image/test_registration.py::TestRegistration::test_apply_shift_and_crop_zero_offset PASSED [  2%]
tests/image/test_registration.py::TestRegistration::test_different_image_content PASSED [  3%]
tests/image/test_registration.py::TestRegistration::test_edge_case_maximum_shift PASSED [  3%]
tests/image/test_registration.py::TestRegistration::test_edge_case_single_pixel_shift PASSED [  4%]
tests/image/test_registration.py::TestRegistration::test_find_offset_known_shift_complex PASSED [  4%]
tests/image/test_registration.py::TestRegistration::test_find_offset_known_shift_real PASSED [  5%]
tests/image/test_registration.py::TestRegistration::test_input_validation_2d_requirement PASSED [  5%]
tests/image/test_registration.py::TestRegistration::test_input_validation_excessive_offset PASSED [  5%]
tests/image/test_registration.py::TestRegistration::test_input_validation_shape_matching PASSED [  6%]
tests/image/test_registration.py::TestRegistration::test_noise_robustness PASSED [  6%]
tests/image/test_registration.py::TestRegistration::test_register_and_align_convenience PASSED [  7%]
tests/image/test_registration.py::TestRegistration::test_registration_sign_verification PASSED [  7%]
tests/image/test_registration.py::TestRegistration::test_round_trip_registration PASSED [  8%]
tests/image/test_registration.py::TestRegistration::test_shift_and_crop_preserves_data_type PASSED [  8%]
tests/test_baselines.py::TestBaselines::test_build_model_always_creates_single_channel_output PASSED [  8%]
tests/test_cli_args.py::TestCliArgs::test_add_logging_arguments PASSED   [  9%]
tests/test_cli_args.py::TestCliArgs::test_console_level_choices PASSED   [  9%]
tests/test_cli_args.py::TestCliArgs::test_get_logging_config_custom_level PASSED [ 10%]
tests/test_cli_args.py::TestCliArgs::test_get_logging_config_defaults PASSED [ 10%]
tests/test_cli_args.py::TestCliArgs::test_get_logging_config_quiet PASSED [ 11%]
tests/test_cli_args.py::TestCliArgs::test_get_logging_config_verbose PASSED [ 11%]
tests/test_cli_args.py::TestCliArgs::test_quiet_verbose_mutually_exclusive PASSED [ 11%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_backward_compatibility PASSED [ 12%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_different_seeds_produce_different_results PASSED [ 12%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_edge_case_k_less_than_c PASSED [ 13%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_edge_case_more_samples_than_points PASSED [ 13%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_edge_case_small_dataset PASSED [ 13%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_efficient_grouping_output_shape PASSED [ 14%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_efficient_grouping_spatial_coherence PASSED [ 14%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_efficient_grouping_valid_indices PASSED [ 15%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_generate_grouped_data_gridsize_1 PASSED [ 15%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_generate_grouped_data_integration PASSED [ 16%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_memory_efficiency PASSED [ 16%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_no_cache_files_created PASSED [ 16%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_performance_improvement PASSED [ 17%]
tests/test_coordinate_grouping.py::TestCoordinateGrouping::test_reproducibility_with_seed PASSED [ 17%]
tests/test_coordinate_grouping.py::TestIntegrationWithExistingCode::test_existing_tests_still_pass PASSED [ 18%]
tests/test_generic_loader.py::TestGenericLoader::test_generic_loader_roundtrip SKIPPED [ 18%]
tests/test_generic_loader.py::test_generic_loader PASSED                 [ 19%]
tests/test_integration_baseline_gs2.py::TestBaselineGridsize2Integration::test_baseline_gridsize2_end_to_end SKIPPED [ 19%]
tests/test_integration_workflow.py::TestFullWorkflow::test_train_save_load_infer_cycle PASSED [ 19%]
tests/test_log_config.py::TestLogConfig::test_backward_compatibility PASSED [ 20%]
tests/test_log_config.py::TestLogConfig::test_conflicting_flags_verbose_overrides PASSED [ 20%]
tests/test_log_config.py::TestLogConfig::test_custom_console_level PASSED [ 21%]
tests/test_log_config.py::TestLogConfig::test_default_setup_logging_creates_log_directory_and_file PASSED [ 21%]
tests/test_log_config.py::TestLogConfig::test_quiet_flag_overrides_console_level PASSED [ 22%]
tests/test_log_config.py::TestLogConfig::test_quiet_mode_disables_console PASSED [ 22%]
tests/test_log_config.py::TestLogConfig::test_setup_logging_clears_existing_handlers PASSED [ 22%]
tests/test_log_config.py::TestLogConfig::test_string_path_support PASSED [ 23%]
tests/test_log_config.py::TestLogConfig::test_verbose_mode_enables_debug_console PASSED [ 23%]
tests/test_misc.py::test_memoize_simulated_data SKIPPED (Deprecated:...) [ 24%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_configuration_mismatch_warnings PASSED [ 24%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_end_to_end_workflow_consistency PASSED [ 25%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_metadata_backward_compatibility PASSED [ 25%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_metadata_persistence_single_nphotons PASSED [ 25%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_multiple_nphotons_metadata_consistency PASSED [ 26%]
tests/test_nphotons_metadata_integration.py::TestNphotonsMetadataIntegration::test_training_with_mismatched_config_warns_but_continues PASSED [ 26%]
tests/test_oversampling.py::TestAutomaticOversampling::test_automatic_oversampling_triggers PASSED [ 27%]
tests/test_oversampling.py::TestAutomaticOversampling::test_gridsize_1_no_oversampling PASSED [ 27%]
tests/test_oversampling.py::TestAutomaticOversampling::test_oversampling_with_different_k_values PASSED [ 27%]
tests/test_oversampling.py::TestAutomaticOversampling::test_reproducibility_with_seed PASSED [ 28%]
tests/test_oversampling.py::TestAutomaticOversampling::test_standard_sampling_no_oversampling PASSED [ 28%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_batch_processing PASSED [ 29%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_complex128_dtype PASSED [ 29%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_complex64_dtype PASSED [ 30%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_fill_modes PASSED [ 30%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_float32_dtype PASSED [ 30%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_float64_dtype PASSED [ 31%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_float64_with_translation PASSED [ 31%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_interpolation_modes PASSED [ 32%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_jit_compilation_float32 PASSED [ 32%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_jit_compilation_float64 PASSED [ 33%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_mixed_precision_translation PASSED [ 33%]
tests/test_projective_warp_xla.py::TestProjectiveWarpXLA::test_tfa_params_conversion PASSED [ 33%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_content_validity PASSED [ 34%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_edge_case_k_less_than_c PASSED [ 34%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_edge_case_more_samples_than_points PASSED [ 35%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_edge_case_small_dataset PASSED [ 35%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_memory_efficiency PASSED [ 36%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_output_shape PASSED [ 36%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_performance_improvement PASSED [ 36%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_reproducibility PASSED [ 37%]
tests/test_raw_data_grouping.py::TestRawDataGrouping::test_uniform_sampling PASSED [ 37%]
tests/test_scaling_regression.py::TestScalingRegression::test_both_arrays_scaled_identically PASSED [ 38%]
tests/test_scaling_regression.py::TestScalingRegression::test_different_nphotons_produce_proportional_scaling PASSED [ 38%]
tests/test_scaling_regression.py::TestScalingRegression::test_intensity_scale_is_valid PASSED [ 38%]
tests/test_scaling_regression.py::TestScalingRegression::test_phase_is_not_scaled PASSED [ 39%]
tests/test_scaling_regression.py::TestScalingRegression::test_scaling_is_reversible PASSED [ 39%]
tests/test_scaling_regression.py::TestScalingRegression::test_scaling_preserves_physics PASSED [ 40%]
tests/test_scaling_regression.py::TestScalingAssertions::test_assertions_catch_invalid_intensity_scale PASSED [ 40%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_default_behavior_is_random PASSED [ 41%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_handles_edge_cases PASSED [ 41%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_is_deterministic PASSED [ 41%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_order PASSED [ 42%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_uses_first_n_points PASSED [ 42%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_with_gridsize_greater_than_1 PASSED [ 43%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_sampling_with_seed_parameter PASSED [ 43%]
tests/test_sequential_sampling.py::TestSequentialSampling::test_sequential_vs_random_coverage PASSED [ 44%]
tests/test_sequential_sampling.py::TestIntegrationWithWorkflow::test_cli_argument_parsing PASSED [ 44%]
tests/test_sequential_sampling.py::TestIntegrationWithWorkflow::test_config_flag_exists PASSED [ 44%]
tests/test_subsampling.py::TestSubsampling::test_different_seeds_produce_different_results PASSED [ 45%]
tests/test_subsampling.py::TestSubsampling::test_interaction_with_config_dataclass PASSED [ 45%]
tests/test_subsampling.py::TestSubsampling::test_legacy_n_images_behavior PASSED [ 46%]
tests/test_subsampling.py::TestSubsampling::test_n_subsample_overrides_n_images PASSED [ 46%]
tests/test_subsampling.py::TestSubsampling::test_no_subsample_uses_full_dataset PASSED [ 47%]
tests/test_subsampling.py::TestSubsampling::test_reproducible_subsampling_with_seed PASSED [ 47%]
tests/test_subsampling.py::TestSubsampling::test_sorted_indices_for_consistency PASSED [ 47%]
tests/test_subsampling.py::TestSubsampling::test_subsample_larger_than_dataset PASSED [ 48%]
tests/test_subsampling.py::TestSubsampling::test_subsample_with_n_subsample PASSED [ 48%]
tests/test_subsampling.py::TestSubsampling::test_subsample_zero_edge_case PASSED [ 49%]
tests/test_subsampling.py::TestSubsampling::test_y_patches_subsampled_consistently PASSED [ 49%]
tests/test_tf_helper.py::TestReassemblePosition::test_basic_functionality PASSED [ 50%]
tests/test_tf_helper.py::TestReassemblePosition::test_different_patch_values_blend PASSED [ 50%]
tests/test_tf_helper.py::TestReassemblePosition::test_identical_patches_single_vs_double PASSED [ 50%]
tests/test_tf_helper.py::TestReassemblePosition::test_perfect_overlap_averages_to_identity PASSED [ 51%]
tests/test_tf_helper.py::TestTranslateFunction::test_batch_translation PASSED [ 51%]
tests/test_tf_helper.py::TestTranslateFunction::test_complex_tensor_translation PASSED [ 52%]
tests/test_tf_helper.py::TestTranslateFunction::test_edge_cases PASSED   [ 52%]
tests/test_tf_helper.py::TestTranslateFunction::test_integer_translation PASSED [ 52%]
tests/test_tf_helper.py::TestTranslateFunction::test_subpixel_translation PASSED [ 53%]
tests/test_tf_helper.py::TestTranslateFunction::test_translate_core_matches_addons SKIPPED [ 53%]
tests/test_tf_helper.py::TestTranslateFunction::test_zero_translation PASSED [ 54%]
tests/test_tf_helper_edge_aware.py::TestTranslateSmoothPatterns::test_complex_smooth_translation PASSED [ 54%]
tests/test_tf_helper_edge_aware.py::TestTranslateSmoothPatterns::test_gaussian_probe_translation SKIPPED [ 55%]
tests/test_tf_helper_edge_aware.py::TestTranslateSmoothPatterns::test_smooth_object_translation SKIPPED [ 55%]
tests/test_tf_helper_edge_aware.py::TestTranslateEdgeCases::test_boundary_behavior SKIPPED [ 55%]
tests/test_tf_helper_edge_aware.py::TestTranslateEdgeCases::test_document_edge_differences SKIPPED [ 56%]
tests/test_tf_helper_edge_aware.py::TestPtychoPINNRelevantCases::test_batch_smooth_patterns SKIPPED [ 56%]
tests/test_tf_helper_edge_aware.py::TestPtychoPINNRelevantCases::test_typical_probe_sizes SKIPPED [ 57%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_exception_propagation PASSED [ 57%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_load_valid_model_directory PASSED [ 58%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_missing_diffraction_model PASSED [ 58%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_missing_model_archive PASSED [ 58%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_nonexistent_directory PASSED [ 59%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_not_a_directory PASSED [ 59%]
tests/test_workflow_components.py::TestLoadInferenceBundle::test_path_conversion PASSED [ 60%]
tests/tools/test_generate_test_index.py::GenerateTestIndexTests::test_get_module_docstring_handles_missing_docstring PASSED [ 60%]
tests/tools/test_generate_test_index.py::GenerateTestIndexTests::test_get_module_docstring_reads_existing_docstring PASSED [ 61%]
tests/tools/test_generate_test_index.py::GenerateTestIndexTests::test_get_test_functions_lists_key_tests PASSED [ 61%]
tests/tools/test_update_tool.py::TestUpdateTool::test_update_function PASSED [ 61%]
tests/tools/test_update_tool.py::test_update_function PASSED             [ 62%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_defaults_to_tensorflow_backend PASSED [ 62%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_selects_pytorch_backend PASSED [ 63%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_pytorch_backend_calls_update_legacy_dict PASSED [ 63%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_pytorch_unavailable_raises_error PASSED [ 63%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_inference_config_supports_backend_selection PASSED [ 64%]
tests/torch/test_backend_selection.py::TestBackendSelection::test_backend_selection_preserves_api_parity PASSED [ 64%]
tests/torch/test_config_bridge.py::TestConfigBridgeMVP::test_mvp_config_bridge_populates_params_cfg PASSED [ 65%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_direct_fields[N-direct] PASSED [ 65%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_direct_fields[n_filters_scale-direct] PASSED [ 66%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_direct_fields[object_big-direct] PASSED [ 66%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_direct_fields[probe_big-direct] PASSED [ 66%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_direct_fields[batch_size-direct] PASSED [ 67%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[gridsize-tuple-to-int] PASSED [ 67%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[model_type-unsupervised] PASSED [ 68%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[model_type-supervised] PASSED [ 68%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[amp_activation-silu] PASSED [ 69%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[amp_activation-SiLU] PASSED [ 69%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_transform_fields[amp_activation-passthrough] PASSED [ 69%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nepochs-rename] PASSED [ 70%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nll_weight-true] PASSED [ 70%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nll_weight-false] PASSED [ 71%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_override_fields[pad_object-default] PASSED [ 71%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_override_fields[pad_object-override] PASSED [ 72%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_override_fields[gaussian_smoothing_sigma-default] PASSED [ 72%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_override_fields[gaussian_smoothing_sigma-override] PASSED [ 72%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[mae_weight-default] PASSED [ 73%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[mae_weight-override] PASSED [ 73%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[realspace_mae_weight-default] PASSED [ 74%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[realspace_weight-default] PASSED [ 74%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[positions_provided-default] PASSED [ 75%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[probe_trainable-default] PASSED [ 75%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[sequential_sampling-default] PASSED [ 75%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_inference_config_override_fields[debug-default] PASSED [ 76%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_inference_config_override_fields[debug-override] PASSED [ 76%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_probe_mask_translation[probe_mask-default] PASSED [ 77%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_config_probe_mask_override PASSED [ 77%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_default_divergence_detection[nphotons-divergence] PASSED [ 77%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_default_divergence_detection[probe_scale-divergence] PASSED [ 78%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_gridsize_error_handling[gridsize-non-square] PASSED [ 78%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_type_error_handling[model_type-invalid-enum] PASSED [ 79%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_activation_error_handling[amp_activation-unknown] PASSED [ 79%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_train_data_file_required_error PASSED [ 80%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_model_path_required_error PASSED [ 80%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_nphotons_default_divergence_error PASSED [ 80%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_nphotons_override_passes_validation PASSED [ 81%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_n_subsample_missing_override_uses_none PASSED [ 81%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_n_subsample_explicit_override PASSED [ 82%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_inference_config_n_subsample_missing_override_uses_none PASSED [ 82%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_inference_config_n_subsample_explicit_override PASSED [ 83%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_n_groups_missing_override_warning PASSED [ 83%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_test_data_file_training_missing_warning PASSED [ 83%]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_params_cfg_matches_baseline PASSED [ 84%]
tests/torch/test_data_pipeline.py::TestRawDataTorchAdapter::test_raw_data_torch_matches_tensorflow PASSED [ 84%]
tests/torch/test_data_pipeline.py::TestDataContainerParity::test_data_container_shapes_and_dtypes PASSED [ 85%]
tests/torch/test_data_pipeline.py::TestGroundTruthLoading::test_y_patches_are_complex64 PASSED [ 85%]
tests/torch/test_data_pipeline.py::TestMemmapBridgeParity::test_memmap_loader_matches_raw_data_torch PASSED [ 86%]
tests/torch/test_data_pipeline.py::TestMemmapBridgeParity::test_deterministic_generation_validation PASSED [ 86%]
tests/torch/test_dataloader.py::TestDataloaderCanonicalKeySupport::test_backward_compat_legacy_diff3d PASSED [ 86%]
tests/torch/test_dataloader.py::TestDataloaderCanonicalKeySupport::test_error_when_no_diffraction_key PASSED [ 87%]
tests/torch/test_dataloader.py::TestDataloaderCanonicalKeySupport::test_loads_canonical_diffraction PASSED [ 87%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_auto_transposes_legacy_hwn_format PASSED [ 88%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_handles_edge_case_square_dataset PASSED [ 88%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_npz_headers_also_transposes_shape PASSED [ 88%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_preserves_canonical_nwh_format PASSED [ 89%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_real_dataset_dimensions PASSED [ 89%]
tests/torch/test_dataloader.py::TestDataloaderFormatAutoTranspose::test_works_with_diff3d_legacy_key PASSED [ 90%]
tests/torch/test_integration_workflow_torch.py::TestPyTorchIntegrationWorkflow::test_pytorch_tf_output_parity SKIPPED [ 90%]
tests/torch/test_integration_workflow_torch.py::TestPyTorchIntegrationWorkflow::test_pytorch_train_save_load_infer_cycle FAILED [ 91%]
tests/torch/test_model_manager.py::TestSaveTorchBundle::test_archive_structure PASSED [ 91%]
tests/torch/test_model_manager.py::TestSaveTorchBundle::test_params_snapshot PASSED [ 91%]
tests/torch/test_model_manager.py::TestLoadTorchBundle::test_load_round_trip_updates_params_cfg PASSED [ 92%]
tests/torch/test_model_manager.py::TestLoadTorchBundle::test_missing_params_raises_value_error PASSED [ 92%]
tests/torch/test_model_manager.py::TestLoadTorchBundle::test_load_round_trip_returns_model_stub XFAIL [ 93%]
tests/torch/test_tf_helper.py::TestTorchTFHelper::test_combine_complex SKIPPED [ 93%]
tests/torch/test_tf_helper.py::TestTorchTFHelper::test_get_mask SKIPPED  [ 94%]
tests/torch/test_tf_helper.py::TestTorchTFHelper::test_placeholder_torch_functions SKIPPED [ 94%]
tests/torch/test_train_probe_size.py::TestNPZProbeSizeExtraction::test_infer_probe_size_128 PASSED [ 94%]
tests/torch/test_train_probe_size.py::TestNPZProbeSizeExtraction::test_infer_probe_size_from_npz PASSED [ 95%]
tests/torch/test_train_probe_size.py::TestNPZProbeSizeExtraction::test_infer_probe_size_missing_probe PASSED [ 95%]
tests/torch/test_train_probe_size.py::TestNPZProbeSizeExtraction::test_infer_probe_size_real_dataset PASSED [ 96%]
tests/torch/test_train_probe_size.py::TestNPZProbeSizeExtraction::test_infer_probe_size_rectangular PASSED [ 96%]
tests/torch/test_workflows_components.py::TestWorkflowsComponentsScaffold::test_run_cdi_example_calls_update_legacy_dict PASSED [ 97%]
tests/torch/test_workflows_components.py::TestWorkflowsComponentsTraining::test_train_cdi_model_torch_invokes_lightning PASSED [ 97%]
tests/torch/test_workflows_components.py::TestWorkflowsComponentsRun::test_run_cdi_example_invokes_training PASSED [ 97%]
tests/torch/test_workflows_components.py::TestWorkflowsComponentsRun::test_run_cdi_example_persists_models PASSED [ 98%]
tests/torch/test_workflows_components.py::TestWorkflowsComponentsRun::test_load_inference_bundle_handles_bundle PASSED [ 98%]
tests/torch/test_workflows_components.py::TestTrainWithLightningRed::test_train_with_lightning_instantiates_module FAILED [ 99%]
tests/torch/test_workflows_components.py::TestTrainWithLightningRed::test_train_with_lightning_runs_trainer_fit PASSED [ 99%]
tests/torch/test_workflows_components.py::TestTrainWithLightningRed::test_train_with_lightning_returns_models_dict PASSED [100%]

=================================== FAILURES ===================================
___ TestPyTorchIntegrationWorkflow.test_pytorch_train_save_load_infer_cycle ____

self = <test_integration_workflow_torch.TestPyTorchIntegrationWorkflow testMethod=test_pytorch_train_save_load_infer_cycle>

    def test_pytorch_train_save_load_infer_cycle(self):
        """
        Tests the complete PyTorch train → save → load → infer workflow.
    
        This validates the PyTorch model persistence layer by simulating a real
        user workflow across separate processes, mirroring the TensorFlow integration test.
    
        Phase: E2.B1 (Red Test)
        Expected Behavior (Phase E2.C implementation target):
        1. Training subprocess creates Lightning checkpoint
        2. Checkpoint artifact saved to <output_dir>/checkpoints/ or <output_dir>/wts.pt
        3. Inference subprocess loads checkpoint and generates reconstructions
        4. Output images created in inference output directory
    
        Current Status: FAILING — ptycho_torch training/inference scripts not yet
        integrated with subprocess harness and backend dispatcher.
        """
        # --- 1. Define Paths ---
        data_file = project_root / "datasets" / "Run1084_recon3_postPC_shrunk_3.npz"
        training_output_dir = self.output_path / "training_outputs"
        inference_output_dir = self.output_path / "pytorch_output"
    
        # --- 2. Training Step (PyTorch) ---
        print("--- Running PyTorch Training Step (subprocess) ---")
    
        # NOTE: This command reflects the expected CLI interface after Phase E2.C implementation.
        # Currently, ptycho_torch/train.py does not support these exact flags.
        # The test documents the target API contract.
        train_command = [
            sys.executable, "-m", "ptycho_torch.train",
            "--train_data_file", str(data_file),
            "--test_data_file", str(data_file),
            "--output_dir", str(training_output_dir),
            "--max_epochs", "2",
            "--n_images", "64",
            "--gridsize", "1",
            "--batch_size", "4",
            "--device", "cpu",
            "--disable_mlflow",  # Suppress MLflow for CI (flag to be added per TEST-PYTORCH-001)
        ]
    
        # Expected to fail in Phase E2.B (red phase) because:
        # - ptycho_torch.train may not support these CLI flags yet
        # - Backend dispatcher not wired to route PyTorch workflows
        # - CONFIG-001 gate may not be enforced
        train_result = subprocess.run(train_command, capture_output=True, text=True)
    
        self.assertEqual(
            train_result.returncode, 0,
            f"PyTorch training script failed with stdout:\n{train_result.stdout}\nstderr:\n{train_result.stderr}"
        )
    
        # Check for PyTorch checkpoint artifact
        # Expected format: Lightning checkpoint or custom .pt bundle
        # Phase E2.C implementation should define exact artifact name
        checkpoint_candidates = [
            training_output_dir / "checkpoints" / "last.ckpt",  # Lightning default
            training_output_dir / "wts.pt",  # Custom bundle format
            training_output_dir / "model.pt",  # Alternative naming
        ]
    
        checkpoint_found = any(p.exists() for p in checkpoint_candidates)
        self.assertTrue(
            checkpoint_found,
            f"No PyTorch checkpoint found in {training_output_dir}. Searched: {[str(p) for p in checkpoint_candidates]}"
        )
    
        # --- 3. Inference Step (PyTorch) ---
        print("--- Running PyTorch Inference Step (subprocess) ---")
    
        # NOTE: ptycho_torch/inference.py does not exist yet (per TEST-PYTORCH-001 §Open Questions).
        # This test documents the expected CLI interface for Phase E2.C implementation.
        inference_command = [
            sys.executable, "-m", "ptycho_torch.inference",
            "--model_path", str(training_output_dir),
            "--test_data", str(data_file),
            "--output_dir", str(inference_output_dir),
            "--n_images", "32",
            "--device", "cpu",
        ]
    
        # Expected to fail in Phase E2.B because:
        # - ptycho_torch.inference module does not exist yet
        # - Inference helper needs to be authored (TEST-PYTORCH-001 §Next Steps #3)
        infer_result = subprocess.run(inference_command, capture_output=True, text=True)
    
>       self.assertEqual(
            infer_result.returncode, 0,
            f"PyTorch inference script failed with stdout:\n{infer_result.stdout}\nstderr:\n{infer_result.stderr}"
        )
E       AssertionError: 1 != 0 : PyTorch inference script failed with stdout:
E       Loading Lightning checkpoint from: /tmp/tmpskhbapok/training_outputs/checkpoints/last.ckpt
E       Test data: /home/ollie/Documents/PtychoPINN2/datasets/Run1084_recon3_postPC_shrunk_3.npz
E       Output directory: /tmp/tmpskhbapok/pytorch_output
E       Device: cpu
E       N images: 32
E       
E       stderr:
E       2025-10-17 19:45:54.530334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
E       WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E       E0000 00:00:1760755554.542368 4184295 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E       E0000 00:00:1760755554.546264 4184295 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
E       W0000 00:00:1760755554.557224 4184295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
E       W0000 00:00:1760755554.557243 4184295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
E       W0000 00:00:1760755554.557245 4184295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
E       W0000 00:00:1760755554.557246 4184295 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
E       Traceback (most recent call last):
E         File "/home/ollie/Documents/PtychoPINN2/ptycho_torch/inference.py", line 442, in cli_main
E           model = PtychoPINN_Lightning.load_from_checkpoint(
E                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E         File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py", line 125, in wrapper
E           return self.method(cls, *args, **kwargs)
E                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E         File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/core/module.py", line 1662, in load_from_checkpoint
E           loaded = _load_from_checkpoint(
E                    ^^^^^^^^^^^^^^^^^^^^^^
E         File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/core/saving.py", line 91, in _load_from_checkpoint
E           model = _load_state(cls, checkpoint, strict=strict, **kwargs)
E                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E         File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/core/saving.py", line 165, in _load_state
E           obj = instantiator(cls, _cls_kwargs) if instantiator else cls(**_cls_kwargs)
E                                                                     ^^^^^^^^^^^^^^^^^^
E       TypeError: PtychoPINN_Lightning.__init__() missing 4 required positional arguments: 'model_config', 'data_config', 'training_config', and 'inference_config'
E       
E       During handling of the above exception, another exception occurred:
E       
E       Traceback (most recent call last):
E         File "<frozen runpy>", line 198, in _run_module_as_main
E         File "<frozen runpy>", line 88, in _run_code
E         File "/home/ollie/Documents/PtychoPINN2/ptycho_torch/inference.py", line 574, in <module>
E           sys.exit(cli_main())
E                    ^^^^^^^^^^
E         File "/home/ollie/Documents/PtychoPINN2/ptycho_torch/inference.py", line 453, in cli_main
E           raise RuntimeError(
E       RuntimeError: Failed to load Lightning checkpoint from /tmp/tmpskhbapok/training_outputs/checkpoints/last.ckpt.
E       Error: PtychoPINN_Lightning.__init__() missing 4 required positional arguments: 'model_config', 'data_config', 'training_config', and 'inference_config'
E       Ensure checkpoint was saved during training and is compatible with current code.

tests/torch/test_integration_workflow_torch.py:144: AssertionError
----------------------------- Captured stdout call -----------------------------

Created temporary directory for PyTorch test run: /tmp/tmpskhbapok
--- Running PyTorch Training Step (subprocess) ---
--- Running PyTorch Inference Step (subprocess) ---
Cleaned up temporary directory: /tmp/tmpskhbapok
___ TestTrainWithLightningRed.test_train_with_lightning_instantiates_module ____

train_container = {'X': array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., ... ..., 1.+0.j, 1.+0.j, 1.+0.j],
        [1.+0.j, 1.+0.j, 1.+0.j, ..., 1.+0.j, 1.+0.j, 1.+0.j]]],
      dtype=complex64)}
test_container = None
config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', obj...ensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False, backend='tensorflow')

    def _train_with_lightning(
        train_container: 'PtychoDataContainerTorch',
        test_container: Optional['PtychoDataContainerTorch'],
        config: TrainingConfig
    ) -> Dict[str, Any]:
        """
        Orchestrate Lightning trainer execution for PyTorch model training.
    
        This function implements the Lightning training workflow per Phase D2.B blueprint:
        1. Derives PyTorch config objects from TensorFlow TrainingConfig
        2. Instantiates PtychoPINN_Lightning module with all four config dependencies
        3. Builds train/val dataloaders via _build_lightning_dataloaders helper
        4. Configures Lightning Trainer with checkpoint/logging settings
        5. Executes training via trainer.fit()
        6. Returns structured results dict with history, containers, and module handle
    
        Args:
            train_container: Normalized training data container
            test_container: Optional normalized test data container
            config: TrainingConfig with training hyperparameters
    
        Returns:
            Dict[str, Any]: Training results including:
                - history: Dict with train_loss and optional val_loss trajectories
                - train_container: Original training container
                - test_container: Original test container
                - models: Dict with 'lightning_module' and 'trainer' handles for persistence
    
        Raises:
            RuntimeError: If torch or lightning packages are not installed (POLICY-001)
    
        References:
            - Blueprint: plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-18T020940Z/phase_d2_completion/phase_b2_implementation.md
            - Spec: specs/ptychodus_api_spec.md:187 (reconstructor lifecycle contract)
            - Findings: POLICY-001 (PyTorch mandatory), CONFIG-001 (params.cfg already populated by caller)
        """
        # B2.2: torch-optional imports with POLICY-001 compliant error messaging
        try:
            import torch
            import lightning.pytorch as L
            from ptycho_torch.model import PtychoPINN_Lightning
            from ptycho_torch.config_params import (
                DataConfig as PTDataConfig,
                ModelConfig as PTModelConfig,
                TrainingConfig as PTTrainingConfig,
                InferenceConfig as PTInferenceConfig
            )
        except ImportError as e:
            raise RuntimeError(
                "PyTorch backend requires torch>=2.2 and lightning. "
                "Install with: pip install -e .[torch]\n"
                "See docs/findings.md#policy-001 for PyTorch requirement policy."
            ) from e
    
        logger.info("_train_with_lightning orchestrating Lightning training")
        logger.info(f"Training config: nepochs={config.nepochs}, n_groups={config.n_groups}")
    
        # B2.1: Derive Lightning config objects from TensorFlow TrainingConfig
        # Note: config.model already contains ModelConfig with N, gridsize, etc.
        # We need to construct PyTorch dataclass configs matching these values
    
        # Map model_type: 'pinn' → 'Unsupervised', 'supervised' → 'Supervised'
        mode_map = {'pinn': 'Unsupervised', 'supervised': 'Supervised'}
    
        pt_data_config = PTDataConfig(
            N=config.model.N,
            grid_size=(config.model.gridsize, config.model.gridsize),
            nphotons=config.nphotons,
            K=config.neighbor_count,
        )
    
        pt_model_config = PTModelConfig(
            mode=mode_map.get(config.model.model_type, 'Unsupervised'),
            amp_activation=config.model.amp_activation or 'silu',
            n_filters_scale=config.model.n_filters_scale,
        )
    
        pt_training_config = PTTrainingConfig(
            epochs=config.nepochs,
            learning_rate=1e-4,  # Default; can expose via config later
            device=getattr(config, 'device', 'cpu'),
        )
    
        pt_inference_config = PTInferenceConfig()
        # Minimal for now; persistence may need additional fields
    
        # B2.4: Instantiate PtychoPINN_Lightning with all four config objects
        model = PtychoPINN_Lightning(
            model_config=pt_model_config,
            data_config=pt_data_config,
            training_config=pt_training_config,
            inference_config=pt_inference_config
        )
    
        # Save hyperparameters so checkpoint can reconstruct module without external state
        model.save_hyperparameters()
    
        # B2.3: Build dataloaders via helper
        train_loader, val_loader = _build_lightning_dataloaders(
            train_container, test_container, config
        )
    
        # B2.5: Configure Trainer with settings from config
        output_dir = getattr(config, 'output_dir', Path('./outputs'))
        debug_mode = getattr(config, 'debug', False)
    
        trainer = L.Trainer(
            max_epochs=config.nepochs,
            accelerator='auto',
            devices=1,  # Single device for MVP; multi-GPU later
            log_every_n_steps=1,
            default_root_dir=str(output_dir),
            enable_progress_bar=debug_mode,  # Suppress progress bar unless debug
            deterministic=True,  # Enforce reproducibility
            logger=False,  # Disable default logger for now; MLflow added in B3
        )
    
        # B2.6: Execute training cycle
        logger.info(f"Starting Lightning training: {config.nepochs} epochs")
        try:
>           trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)

ptycho_torch/workflows/components.py:495: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:553: in fit
    model = _maybe_unwrap_optimized(model)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = <test_workflows_components.TestTrainWithLightningRed.test_train_with_lightning_instantiates_module.<locals>.mock_lightning_init.<locals>.StubLightningModule object at 0x7a01bc494810>

    def _maybe_unwrap_optimized(model: object) -> "pl.LightningModule":
        if isinstance(model, OptimizedModule):
            return from_compiled(model)
        if isinstance(model, pl.LightningModule):
            return model
        _check_mixed_imports(model)
>       raise TypeError(
            f"`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `{type(model).__qualname__}`"
        )
E       TypeError: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TestTrainWithLightningRed.test_train_with_lightning_instantiates_module.<locals>.mock_lightning_init.<locals>.StubLightningModule`

../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/lightning/pytorch/utilities/compile.py:111: TypeError

The above exception was the direct cause of the following exception:

self = <test_workflows_components.TestTrainWithLightningRed object at 0x7a0328315290>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7a01bc487110>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'sigmoid', 'backend': 'tensorflow', 'batch_size': 16, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', obj...ensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7a01bc4943d0>

    def test_train_with_lightning_instantiates_module(
        self,
        monkeypatch,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data
    ):
        """
        RED TEST 1: _train_with_lightning MUST instantiate PtychoPINN_Lightning with four configs.
    
        Requirement: specs/ptychodus_api_spec.md:187 reconstructor lifecycle requires
        trained module handles with serialized config for checkpoint reload.
    
        Design contract (phase_b_test_design.md §1):
        - _train_with_lightning receives (train_container, test_container, config)
        - MUST construct ptycho_torch.model.PtychoPINN_Lightning(__init__)
        - Constructor MUST receive exactly (model_config, data_config, training_config, inference_config)
        - This ensures checkpoint.load can reconstruct module without external state
    
        Test mechanism:
        - Monkeypatch PtychoPINN_Lightning to spy on __init__ args
        - Create minimal containers (dicts acceptable for red phase)
        - Invoke _train_with_lightning
        - Assert spy recorded all four config objects
    
        Expected red-phase failure:
        - Stub never instantiates Lightning module
        - Spy not called → assertion fails
        """
        from ptycho_torch.workflows import components as torch_components
    
        # Spy to track Lightning module instantiation
        lightning_init_called = {"called": False, "args": None}
    
        def mock_lightning_init(model_config, data_config, training_config, inference_config):
            """Spy that records PtychoPINN_Lightning.__init__ args."""
            lightning_init_called["called"] = True
            lightning_init_called["args"] = (model_config, data_config, training_config, inference_config)
    
            # Return minimal stub module with required Lightning API
            class StubLightningModule:
                def save_hyperparameters(self):
                    pass
    
            return StubLightningModule()
    
        # Monkeypatch Lightning module constructor
        # Note: actual import path will be ptycho_torch.model.PtychoPINN_Lightning
        # but we monkeypatch at the call site within _train_with_lightning
        monkeypatch.setattr(
            "ptycho_torch.model.PtychoPINN_Lightning",
            mock_lightning_init
        )
    
        # Create minimal train_container (dict placeholder for red phase)
        # Phase C adapters will produce actual PtychoDataContainerTorch
        train_container = {
            "X": np.ones((10, 64, 64)),
            "Y": np.ones((10, 64, 64), dtype=np.complex64),
        }
    
        # Call _train_with_lightning
>       results = torch_components._train_with_lightning(
            train_container=train_container,
            test_container=None,
            config=minimal_training_config
        )

tests/torch/test_workflows_components.py:848: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

train_container = {'X': array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., ... ..., 1.+0.j, 1.+0.j, 1.+0.j],
        [1.+0.j, 1.+0.j, 1.+0.j, ..., 1.+0.j, 1.+0.j, 1.+0.j]]],
      dtype=complex64)}
test_container = None
config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', obj...ensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False, backend='tensorflow')

    def _train_with_lightning(
        train_container: 'PtychoDataContainerTorch',
        test_container: Optional['PtychoDataContainerTorch'],
        config: TrainingConfig
    ) -> Dict[str, Any]:
        """
        Orchestrate Lightning trainer execution for PyTorch model training.
    
        This function implements the Lightning training workflow per Phase D2.B blueprint:
        1. Derives PyTorch config objects from TensorFlow TrainingConfig
        2. Instantiates PtychoPINN_Lightning module with all four config dependencies
        3. Builds train/val dataloaders via _build_lightning_dataloaders helper
        4. Configures Lightning Trainer with checkpoint/logging settings
        5. Executes training via trainer.fit()
        6. Returns structured results dict with history, containers, and module handle
    
        Args:
            train_container: Normalized training data container
            test_container: Optional normalized test data container
            config: TrainingConfig with training hyperparameters
    
        Returns:
            Dict[str, Any]: Training results including:
                - history: Dict with train_loss and optional val_loss trajectories
                - train_container: Original training container
                - test_container: Original test container
                - models: Dict with 'lightning_module' and 'trainer' handles for persistence
    
        Raises:
            RuntimeError: If torch or lightning packages are not installed (POLICY-001)
    
        References:
            - Blueprint: plans/active/INTEGRATE-PYTORCH-001/reports/2025-10-18T020940Z/phase_d2_completion/phase_b2_implementation.md
            - Spec: specs/ptychodus_api_spec.md:187 (reconstructor lifecycle contract)
            - Findings: POLICY-001 (PyTorch mandatory), CONFIG-001 (params.cfg already populated by caller)
        """
        # B2.2: torch-optional imports with POLICY-001 compliant error messaging
        try:
            import torch
            import lightning.pytorch as L
            from ptycho_torch.model import PtychoPINN_Lightning
            from ptycho_torch.config_params import (
                DataConfig as PTDataConfig,
                ModelConfig as PTModelConfig,
                TrainingConfig as PTTrainingConfig,
                InferenceConfig as PTInferenceConfig
            )
        except ImportError as e:
            raise RuntimeError(
                "PyTorch backend requires torch>=2.2 and lightning. "
                "Install with: pip install -e .[torch]\n"
                "See docs/findings.md#policy-001 for PyTorch requirement policy."
            ) from e
    
        logger.info("_train_with_lightning orchestrating Lightning training")
        logger.info(f"Training config: nepochs={config.nepochs}, n_groups={config.n_groups}")
    
        # B2.1: Derive Lightning config objects from TensorFlow TrainingConfig
        # Note: config.model already contains ModelConfig with N, gridsize, etc.
        # We need to construct PyTorch dataclass configs matching these values
    
        # Map model_type: 'pinn' → 'Unsupervised', 'supervised' → 'Supervised'
        mode_map = {'pinn': 'Unsupervised', 'supervised': 'Supervised'}
    
        pt_data_config = PTDataConfig(
            N=config.model.N,
            grid_size=(config.model.gridsize, config.model.gridsize),
            nphotons=config.nphotons,
            K=config.neighbor_count,
        )
    
        pt_model_config = PTModelConfig(
            mode=mode_map.get(config.model.model_type, 'Unsupervised'),
            amp_activation=config.model.amp_activation or 'silu',
            n_filters_scale=config.model.n_filters_scale,
        )
    
        pt_training_config = PTTrainingConfig(
            epochs=config.nepochs,
            learning_rate=1e-4,  # Default; can expose via config later
            device=getattr(config, 'device', 'cpu'),
        )
    
        pt_inference_config = PTInferenceConfig()
        # Minimal for now; persistence may need additional fields
    
        # B2.4: Instantiate PtychoPINN_Lightning with all four config objects
        model = PtychoPINN_Lightning(
            model_config=pt_model_config,
            data_config=pt_data_config,
            training_config=pt_training_config,
            inference_config=pt_inference_config
        )
    
        # Save hyperparameters so checkpoint can reconstruct module without external state
        model.save_hyperparameters()
    
        # B2.3: Build dataloaders via helper
        train_loader, val_loader = _build_lightning_dataloaders(
            train_container, test_container, config
        )
    
        # B2.5: Configure Trainer with settings from config
        output_dir = getattr(config, 'output_dir', Path('./outputs'))
        debug_mode = getattr(config, 'debug', False)
    
        trainer = L.Trainer(
            max_epochs=config.nepochs,
            accelerator='auto',
            devices=1,  # Single device for MVP; multi-GPU later
            log_every_n_steps=1,
            default_root_dir=str(output_dir),
            enable_progress_bar=debug_mode,  # Suppress progress bar unless debug
            deterministic=True,  # Enforce reproducibility
            logger=False,  # Disable default logger for now; MLflow added in B3
        )
    
        # B2.6: Execute training cycle
        logger.info(f"Starting Lightning training: {config.nepochs} epochs")
        try:
            trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)
        except Exception as e:
            logger.error(f"Lightning training failed: {e}")
>           raise RuntimeError(f"Lightning training failed. See logs for details.") from e
E           RuntimeError: Lightning training failed. See logs for details.

ptycho_torch/workflows/components.py:498: RuntimeError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (10, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (10,)
xcoords shape: (10,)
ycoords shape: (10,)
xcoords_start shape: (10,)
ycoords_start shape: (10,)
----------------------------- Captured stderr call -----------------------------
INFO: Seed set to 42
------------------------------ Captured log call -------------------------------
INFO     lightning.fabric.utilities.seed:seed.py:57 Seed set to 42
INFO     pytorch_lightning.utilities.rank_zero:callback_connector.py:108 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
INFO     pytorch_lightning.utilities.rank_zero:setup.py:156 GPU available: True (cuda), used: True
INFO     pytorch_lightning.utilities.rank_zero:setup.py:159 TPU available: False, using: 0 TPU cores
INFO     pytorch_lightning.utilities.rank_zero:setup.py:169 HPU available: False, using: 0 HPUs
ERROR    ptycho_torch.workflows.components:components.py:497 Lightning training failed: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TestTrainWithLightningRed.test_train_with_lightning_instantiates_module.<locals>.mock_lightning_init.<locals>.StubLightningModule`
=============================== warnings summary ===============================
tests/torch/test_config_bridge.py::TestConfigBridgeMVP::test_mvp_config_bridge_populates_params_cfg
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:100: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    spec_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_direct_fields[batch_size-direct]
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:235: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nepochs-rename]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nll_weight-true]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_transform_fields[nll_weight-false]
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:298: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[mae_weight-default]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[mae_weight-override]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[realspace_mae_weight-default]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[realspace_weight-default]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[positions_provided-default]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[probe_trainable-default]
tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_override_fields[sequential_sampling-default]
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:366: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_default_divergence_detection[nphotons-divergence]
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:493: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_train_data_file_required_error
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:575: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_nphotons_override_passes_validation
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:666: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_n_subsample_missing_override_uses_none
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:707: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

tests/torch/test_config_bridge.py::TestConfigBridgeParity::test_training_config_n_subsample_explicit_override
  /home/ollie/Documents/PtychoPINN2/tests/torch/test_config_bridge.py:742: UserWarning: test_data_file not provided in TrainingConfig overrides. Evaluation workflows require test_data_file to be set during inference update. Consider providing: overrides=dict(..., test_data_file=Path('test.npz'))
    tf_train = config_bridge.to_training_config(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
SKIPPED [1] tests/test_benchmark_throughput.py:11: scripts/benchmark_inference_throughput.py not found. This is a pre-existing broken test dependency. Add to fix_plan.md for future resolution.
SKIPPED [1] tests/test_run_baseline.py:4: tests/test_utilities.py not found. This is a pre-existing broken test dependency. Add to fix_plan.md for future resolution.
SKIPPED [1] tests/test_generic_loader.py:46: Data loading failed:
SKIPPED [1] tests/test_integration_baseline_gs2.py:27: Test data not found at /home/ollie/Documents/PtychoPINN2/datasets/fly/fly001_transposed.npz
SKIPPED [1] ../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/_pytest/unittest.py:385: Deprecated: generate_simulated_data API changed from (obj,probe,nimages) to (config,obj,probe) and memoization disabled
SKIPPED [1] tests/test_tf_helper.py:199: TensorFlow Addons removed in TF 2.19 migration
SKIPPED [1] tests/test_tf_helper_edge_aware.py:47: tensorflow_addons not available
SKIPPED [1] tests/test_tf_helper_edge_aware.py:86: tensorflow_addons not available
SKIPPED [1] tests/test_tf_helper_edge_aware.py:198: tensorflow_addons not available
SKIPPED [1] tests/test_tf_helper_edge_aware.py:169: tensorflow_addons not available
SKIPPED [1] tests/test_tf_helper_edge_aware.py:257: tensorflow_addons not available
SKIPPED [1] tests/test_tf_helper_edge_aware.py:227: tensorflow_addons not available
SKIPPED [1] tests/torch/test_integration_workflow_torch.py:165: Deferred to Phase E2.D parity verification
SKIPPED [1] tests/torch/test_tf_helper.py:64: torch tf_helper module not available
SKIPPED [1] tests/torch/test_tf_helper.py:57: torch tf_helper module not available
SKIPPED [1] tests/torch/test_tf_helper.py:74: torch tf_helper module not available - tests would fail
XFAIL tests/torch/test_model_manager.py::TestLoadTorchBundle::test_load_round_trip_returns_model_stub - Phase D4.B1 red phase: load_torch_bundle model reconstruction pending. Expected NotImplementedError raised. This test will pass once Phase D3.C implements model reconstruction logic.
FAILED tests/torch/test_integration_workflow_torch.py::TestPyTorchIntegrationWorkflow::test_pytorch_train_save_load_infer_cycle
FAILED tests/torch/test_workflows_components.py::TestTrainWithLightningRed::test_train_with_lightning_instantiates_module
= 2 failed, 219 passed, 16 skipped, 1 xfailed, 17 warnings in 230.61s (0:03:50) =
