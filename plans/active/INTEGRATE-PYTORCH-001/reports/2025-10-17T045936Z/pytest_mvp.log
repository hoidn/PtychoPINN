============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: not available (/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommWindowRegister)

rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_config_bridge.py::TestConfigBridgeMVP::test_mvp_config_bridge_populates_params_cfg FAILED [100%]

=================================== FAILURES ===================================
_______ TestConfigBridgeMVP.test_mvp_config_bridge_populates_params_cfg ________

self = <test_config_bridge.TestConfigBridgeMVP testMethod=test_mvp_config_bridge_populates_params_cfg>

    def test_mvp_config_bridge_populates_params_cfg(self):
        """Test that PyTorch configs populate params.cfg with MVP fields via bridge adapter.
    
        This test exercises the complete configuration bridge workflow:
        1. Create PyTorch configs using existing singleton pattern
        2. Invoke adapter to translate to TensorFlow dataclass format
        3. Call update_legacy_dict() to populate params.cfg
        4. Verify all MVP fields present with correct values and types
    
        Note: This test will be automatically skipped if PyTorch runtime is unavailable
        (handled by tests/conftest.py). When PyTorch is available, validates full workflow.
        """
        # Import PyTorch configs (existing implementation)
        from ptycho_torch.config_params import DataConfig, ModelConfig, TrainingConfig, InferenceConfig
    
        # Import TensorFlow config utilities
        from ptycho.config.config import (
            ModelConfig as TFModelConfig,
            TrainingConfig as TFTrainingConfig,
            InferenceConfig as TFInferenceConfig,
            update_legacy_dict
        )
        import ptycho.params as params
    
        # 1. Instantiate PyTorch configs with MVP-aligned values
        pt_data = DataConfig(
            N=128,
            grid_size=(2, 2),
            nphotons=1e9,
            K=7  # Maps to neighbor_count in TensorFlow
        )
    
        pt_model = ModelConfig(
            mode='Unsupervised'  # Maps to model_type='pinn' in TensorFlow
        )
    
        pt_train = TrainingConfig(
            epochs=1  # Maps to nepochs in TensorFlow
        )
    
        pt_infer = InferenceConfig(
            batch_size=1
        )
    
        # 2. Import and use the adapter module
        from ptycho_torch import config_bridge
    
        # Call adapter functions to translate PyTorch â†’ TensorFlow dataclasses
        spec_model = config_bridge.to_model_config(pt_data, pt_model)
    
        spec_train = config_bridge.to_training_config(
            spec_model,
            pt_data,
            pt_model,  # PyTorch ModelConfig for intensity_scale_trainable
            pt_train,
            overrides=dict(
                train_data_file=Path('train.npz'),
                n_groups=512,
                neighbor_count=7,
                nphotons=1e9
            )
        )
    
        spec_infer = config_bridge.to_inference_config(
            spec_model,
            pt_data,
            pt_infer,
            overrides=dict(
                model_path=Path('model_dir'),
                test_data_file=Path('test.npz'),
                n_groups=512,
                neighbor_count=7
            )
        )
    
        # 3. Call update_legacy_dict to populate params.cfg
        update_legacy_dict(params.cfg, spec_train)
        update_legacy_dict(params.cfg, spec_infer)
    
        # 4. Assert MVP fields populated correctly
        # Model essentials
        self.assertEqual(params.cfg['N'], 128, "N should match DataConfig.N")
        self.assertEqual(params.cfg['gridsize'], 2, "gridsize should be extracted from grid_size tuple")
        self.assertEqual(params.cfg['model_type'], 'pinn', "model_type should map from mode='Unsupervised'")
    
        # Lifecycle paths (KEY_MAPPINGS translation)
        self.assertEqual(params.cfg['train_data_file_path'], 'train.npz',
                       "train_data_file should map via KEY_MAPPINGS")
        self.assertEqual(params.cfg['test_data_file_path'], 'test.npz',
                       "test_data_file should map via KEY_MAPPINGS")
>       self.assertEqual(params.cfg['model_path'], 'model_dir',
                       "model_path should be converted to string")
E       AssertionError: PosixPath('model_dir') != 'model_dir' : model_path should be converted to string

tests/torch/test_config_bridge.py:140: AssertionError
----------------------------- Captured stderr call -----------------------------
2025-10-16 22:05:33.322970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760677533.334420 3301679 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760677533.337754 3301679 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1760677533.347522 3301679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760677533.347541 3301679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760677533.347544 3301679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760677533.347546 3301679 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-16 22:05:33.350398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
=========================== short test summary info ============================
FAILED tests/torch/test_config_bridge.py::TestConfigBridgeMVP::test_mvp_config_bridge_populates_params_cfg - AssertionError: PosixPath('model_dir') != 'model_dir' : model_path should be converted to string
============================== 1 failed in 2.80s ===============================
============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: not available (/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so: undefined symbol: ncclCommWindowRegister)

rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_config_bridge.py::TestConfigBridgeMVP::test_mvp_config_bridge_populates_params_cfg PASSED [100%]

============================== 1 passed in 2.53s ===============================
