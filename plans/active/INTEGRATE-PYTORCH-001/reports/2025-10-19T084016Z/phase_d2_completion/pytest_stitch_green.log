============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 16 items / 8 deselected / 8 selected

tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_guard_without_train_results PASSED [ 12%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-False] FAILED [ 25%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[True-False-False] FAILED [ 37%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-True-False] FAILED [ 50%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-True] FAILED [ 62%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[True-True-True] FAILED [ 75%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_run_cdi_example_torch_do_stitching_delegates_to_reassemble FAILED [ 87%]
tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_return_contract FAILED [100%]

=================================== FAILURES ===================================
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-False] _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3b910>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc1'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7759fc5b5c90>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
flip_x = False, flip_y = False, transpose = False

    @pytest.mark.parametrize("flip_x,flip_y,transpose", [
        (False, False, False),  # No transforms
        (True, False, False),   # Flip X only
        (False, True, False),   # Flip Y only
        (False, False, True),   # Transpose only
        (True, True, True),     # All transforms
    ])
    def test_reassemble_cdi_image_torch_flip_transpose_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        flip_x,
        flip_y,
        transpose
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch honors flip/transpose parameters.
    
        Requirement: TensorFlow parity per specs/ptychodus_api_spec.md §4.5.
        TensorFlow baseline (ptycho/workflows/components.py:582-666) applies coordinate
        transforms via flip_x, flip_y, transpose parameters before reassembly.
    
        Expected behavior (all parameter combinations):
        - Function accepts flip_x, flip_y, transpose parameters
        - Returns (recon_amp, recon_phase, results) tuple
        - Amplitude/phase are 2D numpy arrays with finite values
        - Output shape invariant under flip/transpose (same canvas size)
        - global_offsets in results dict reflect coordinate transforms
    
        Test mechanism:
        - Parametrize over 5 representative flag combinations
        - Supply train_results with mock Lightning module
        - Assert successful execution (no exceptions)
        - Validate output structure and finiteness
    
        Rationale for parametrization:
        - Documents TF parity requirement explicitly in test corpus
        - Ensures implementation handles all transform combinations
        - Provides clear failure message surfacing which transform broke
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: expect successful stitching with all transform combos
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=flip_x,
            flip_y=flip_y,
            transpose=transpose,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
----------------------------- Captured stderr call -----------------------------
I0000 00:00:1760865151.211019  745906 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1760865151.212387  745906 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22137 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1760865152.254663  745906 service.cc:152] XLA service 0x27b2c600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1760865152.254689  745906 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-10-19 02:12:32.268037: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1760865152.287527  745906 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1760865152.408746  745906 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_flip_transpose_contract[True-False-False] _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3bb90>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc2'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7759a014ee10>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
flip_x = True, flip_y = False, transpose = False

    @pytest.mark.parametrize("flip_x,flip_y,transpose", [
        (False, False, False),  # No transforms
        (True, False, False),   # Flip X only
        (False, True, False),   # Flip Y only
        (False, False, True),   # Transpose only
        (True, True, True),     # All transforms
    ])
    def test_reassemble_cdi_image_torch_flip_transpose_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        flip_x,
        flip_y,
        transpose
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch honors flip/transpose parameters.
    
        Requirement: TensorFlow parity per specs/ptychodus_api_spec.md §4.5.
        TensorFlow baseline (ptycho/workflows/components.py:582-666) applies coordinate
        transforms via flip_x, flip_y, transpose parameters before reassembly.
    
        Expected behavior (all parameter combinations):
        - Function accepts flip_x, flip_y, transpose parameters
        - Returns (recon_amp, recon_phase, results) tuple
        - Amplitude/phase are 2D numpy arrays with finite values
        - Output shape invariant under flip/transpose (same canvas size)
        - global_offsets in results dict reflect coordinate transforms
    
        Test mechanism:
        - Parametrize over 5 representative flag combinations
        - Supply train_results with mock Lightning module
        - Assert successful execution (no exceptions)
        - Validate output structure and finiteness
    
        Rationale for parametrization:
        - Documents TF parity requirement explicitly in test corpus
        - Ensures implementation handles all transform combinations
        - Provides clear failure message surfacing which transform broke
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: expect successful stitching with all transform combos
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=flip_x,
            flip_y=flip_y,
            transpose=transpose,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_flip_transpose_contract[False-True-False] _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e2f850>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc3'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7759a0289a50>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
flip_x = False, flip_y = True, transpose = False

    @pytest.mark.parametrize("flip_x,flip_y,transpose", [
        (False, False, False),  # No transforms
        (True, False, False),   # Flip X only
        (False, True, False),   # Flip Y only
        (False, False, True),   # Transpose only
        (True, True, True),     # All transforms
    ])
    def test_reassemble_cdi_image_torch_flip_transpose_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        flip_x,
        flip_y,
        transpose
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch honors flip/transpose parameters.
    
        Requirement: TensorFlow parity per specs/ptychodus_api_spec.md §4.5.
        TensorFlow baseline (ptycho/workflows/components.py:582-666) applies coordinate
        transforms via flip_x, flip_y, transpose parameters before reassembly.
    
        Expected behavior (all parameter combinations):
        - Function accepts flip_x, flip_y, transpose parameters
        - Returns (recon_amp, recon_phase, results) tuple
        - Amplitude/phase are 2D numpy arrays with finite values
        - Output shape invariant under flip/transpose (same canvas size)
        - global_offsets in results dict reflect coordinate transforms
    
        Test mechanism:
        - Parametrize over 5 representative flag combinations
        - Supply train_results with mock Lightning module
        - Assert successful execution (no exceptions)
        - Validate output structure and finiteness
    
        Rationale for parametrization:
        - Documents TF parity requirement explicitly in test corpus
        - Ensures implementation handles all transform combinations
        - Provides clear failure message surfacing which transform broke
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: expect successful stitching with all transform combos
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=flip_x,
            flip_y=flip_y,
            transpose=transpose,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-True] _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3a910>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc4'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x775984765650>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
flip_x = False, flip_y = False, transpose = True

    @pytest.mark.parametrize("flip_x,flip_y,transpose", [
        (False, False, False),  # No transforms
        (True, False, False),   # Flip X only
        (False, True, False),   # Flip Y only
        (False, False, True),   # Transpose only
        (True, True, True),     # All transforms
    ])
    def test_reassemble_cdi_image_torch_flip_transpose_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        flip_x,
        flip_y,
        transpose
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch honors flip/transpose parameters.
    
        Requirement: TensorFlow parity per specs/ptychodus_api_spec.md §4.5.
        TensorFlow baseline (ptycho/workflows/components.py:582-666) applies coordinate
        transforms via flip_x, flip_y, transpose parameters before reassembly.
    
        Expected behavior (all parameter combinations):
        - Function accepts flip_x, flip_y, transpose parameters
        - Returns (recon_amp, recon_phase, results) tuple
        - Amplitude/phase are 2D numpy arrays with finite values
        - Output shape invariant under flip/transpose (same canvas size)
        - global_offsets in results dict reflect coordinate transforms
    
        Test mechanism:
        - Parametrize over 5 representative flag combinations
        - Supply train_results with mock Lightning module
        - Assert successful execution (no exceptions)
        - Validate output structure and finiteness
    
        Rationale for parametrization:
        - Documents TF parity requirement explicitly in test corpus
        - Ensures implementation handles all transform combinations
        - Provides clear failure message surfacing which transform broke
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: expect successful stitching with all transform combos
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=flip_x,
            flip_y=flip_y,
            transpose=transpose,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_flip_transpose_contract[True-True-True] _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3a190>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc5'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x775984690890>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
flip_x = True, flip_y = True, transpose = True

    @pytest.mark.parametrize("flip_x,flip_y,transpose", [
        (False, False, False),  # No transforms
        (True, False, False),   # Flip X only
        (False, True, False),   # Flip Y only
        (False, False, True),   # Transpose only
        (True, True, True),     # All transforms
    ])
    def test_reassemble_cdi_image_torch_flip_transpose_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        flip_x,
        flip_y,
        transpose
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch honors flip/transpose parameters.
    
        Requirement: TensorFlow parity per specs/ptychodus_api_spec.md §4.5.
        TensorFlow baseline (ptycho/workflows/components.py:582-666) applies coordinate
        transforms via flip_x, flip_y, transpose parameters before reassembly.
    
        Expected behavior (all parameter combinations):
        - Function accepts flip_x, flip_y, transpose parameters
        - Returns (recon_amp, recon_phase, results) tuple
        - Amplitude/phase are 2D numpy arrays with finite values
        - Output shape invariant under flip/transpose (same canvas size)
        - global_offsets in results dict reflect coordinate transforms
    
        Test mechanism:
        - Parametrize over 5 representative flag combinations
        - Supply train_results with mock Lightning module
        - Assert successful execution (no exceptions)
        - Validate output structure and finiteness
    
        Rationale for parametrization:
        - Documents TF parity requirement explicitly in test corpus
        - Ensures implementation handles all transform combinations
        - Provides clear failure message surfacing which transform broke
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: expect successful stitching with all transform combos
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=flip_x,
            flip_y=flip_y,
            transpose=transpose,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1321: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
_ TestReassembleCdiImageTorchGreen.test_run_cdi_example_torch_do_stitching_delegates_to_reassemble _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3be10>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_run_cdi_example_torch_do_0'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x775984684a10>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7759846868d0>

    def test_run_cdi_example_torch_do_stitching_delegates_to_reassemble(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results,
        monkeypatch
    ):
        """
        GREEN TEST: run_cdi_example_torch(do_stitching=True) delegates to stitching path.
    
        Requirement: Phase D2.C workflow integration — ensure orchestration calls reassembly.
    
        TensorFlow baseline (ptycho/workflows/components.py:676-732):
        - run_cdi_example(..., do_stitching=True) invokes reassemble_cdi_image
        - Stitching runs AFTER training completes
        - Returns (recon_amp, recon_phase, results) when stitching enabled
        - Returns (None, None, results) when do_stitching=False
    
        Expected behavior:
        - Runs training (mocked), then calls _reassemble_cdi_image_torch with test_data
        - Stitching results populate amplitude/phase return values
        - Returns (recon_amp, recon_phase, results) when do_stitching=True
    
        Test mechanism:
        - Monkeypatch training path to return stitch_train_results fixture (avoid GPU)
        - Call run_cdi_example_torch with do_stitching=True
        - Assert amplitude/phase are returned (not None)
        - Validate outputs are numpy arrays
    
        Validation coverage:
        - Confirms orchestration wiring exists
        - Ensures stitching path is reachable from public API
        - Documents return value contract for downstream consumers (e.g., ptychodus)
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # Monkeypatch _train_with_lightning to return mock results with Lightning module
        def mock_train_with_lightning(train_container, test_container, config):
            """Stub that returns train_results with mock Lightning module."""
            # Return the stitch_train_results fixture enriched with containers
            results = stitch_train_results.copy()
            results["containers"] = {"train": train_container, "test": test_container}
            return results
    
        monkeypatch.setattr(
            torch_components,
            "_train_with_lightning",
            mock_train_with_lightning
        )
    
        # GREEN PHASE VALIDATION: expect successful stitching
>       recon_amp, recon_phase, results = torch_components.run_cdi_example_torch(
            train_data=dummy_raw_data,
            test_data=dummy_raw_data,  # Use same data for test (deterministic)
            config=minimal_training_config,
            flip_x=False,
            flip_y=False,
            transpose=False,
            M=128,
            do_stitching=True,  # CRITICAL: enable stitching path
        )

tests/torch/test_workflows_components.py:1403: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:165: in run_cdi_example_torch
    recon_amp, recon_phase, reassemble_results = _reassemble_cdi_image_torch(
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
_ TestReassembleCdiImageTorchGreen.test_reassemble_cdi_image_torch_return_contract _

self = <test_workflows_components.TestReassembleCdiImageTorchGreen object at 0x775ab8e3c150>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'silu', 'backend': 'tensorflow', 'batch_size': 2, ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1, model_type='pinn', amp_activation='silu', object...th('/tmp/pytest-of-ollie/pytest-621/test_reassemble_cdi_image_torc6'), sequential_sampling=False, backend='tensorflow')
dummy_raw_data = <ptycho.raw_data.RawData object at 0x7759fc709810>
stitch_train_results = {'history': {'train_loss': [0.1, 0.05]}, 'models': {'lightning_module': MockLightningModule(), 'trainer': None}}

    def test_reassemble_cdi_image_torch_return_contract(
        self,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_raw_data,
        stitch_train_results
    ):
        """
        GREEN TEST: _reassemble_cdi_image_torch returns (recon_amp, recon_phase, results).
    
        Requirement: API parity with TensorFlow reassemble_cdi_image per spec §4.5.
    
        TensorFlow baseline signature (ptycho/workflows/components.py:582):
        ```python
        def reassemble_cdi_image(test_data, config, flip_x=False, flip_y=False,
                                  transpose=False, coord_scale=1, M=None):
            ...
            return recon_amp, recon_phase, results
        ```
    
        Implemented PyTorch signature (ptycho_torch/workflows/components.py:606-614):
        ```python
        def _reassemble_cdi_image_torch(test_data, config, flip_x=False, flip_y=False,
                                         transpose=False, M=None, train_results=None):
            ...
            return recon_amp, recon_phase, results
        ```
    
        Return value contract:
        - recon_amp: 2D numpy array (float), stitched amplitude image
        - recon_phase: 2D numpy array (float), stitched phase image
        - results: dict containing {"obj_tensor_full", "global_offsets", "containers"}
    
        Test mechanism:
        - Supply train_results with mock Lightning module
        - Validate return tuple structure and types
        - Ensure all required keys present in results dict
    
        Rationale:
        - Ensures signature compatibility with TensorFlow baseline
        - Prevents silent breaking changes to return format
        - Codifies downstream consumer expectations (ptychodus integration)
        """
        from ptycho_torch.workflows import components as torch_components
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Bridge config (CONFIG-001)
        update_legacy_dict(params.cfg, minimal_training_config)
    
        # GREEN PHASE VALIDATION: validate return contract
>       recon_amp, recon_phase, results = torch_components._reassemble_cdi_image_torch(
            test_data=dummy_raw_data,
            config=minimal_training_config,
            flip_x=False,
            flip_y=False,
            transpose=False,
            M=128,
            train_results=stitch_train_results  # CRITICAL: provide trained model
        )

tests/torch/test_workflows_components.py:1473: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/workflows/components.py:720: in _reassemble_cdi_image_torch
    obj_image = hh.reassemble_position(obj_tensor_np, global_offsets_np, M=M)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho/tf_helper.py:1255: in reassemble_position
    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153: in error_handler
    raise e.with_traceback(filtered_tb) from None
/tmp/__autograph_generated_fileucaku3ac.py:106: in tf__shift_and_sum
    result = ag__.converted_call(ag__.ld(tf).cond, (ag__.ld(total_texels) < ag__.ld(mem_cap_texels), ag__.ld(_vectorised), ag__.ld(_streaming)), None, fscope)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @ag__.autograph_artifact
    def _streaming():
        with ag__.FunctionScope('_streaming', 'fscope_2', ag__.STD) as fscope_2:
            do_return_2 = False
            retval__2 = ag__.UndefinedReturnValue()
            chunk_sz = ag__.converted_call(ag__.ld(tf).constant, (1024, ag__.ld(tf).int32), None, fscope_2)
            result = ag__.converted_call(ag__.ld(tf).zeros, ([ag__.ld(padded_size), ag__.ld(padded_size), 1],), dict(dtype=ag__.ld(obj_tensor).dtype), fscope_2)
            i = ag__.converted_call(ag__.ld(tf).constant, (0, ag__.ld(tf).int32), None, fscope_2)
    
            @ag__.autograph_artifact
            def cond(i, res):
                with ag__.FunctionScope('cond', 'fscope_3', ag__.STD) as fscope_3:
                    do_return_3 = False
                    retval__3 = ag__.UndefinedReturnValue()
                    try:
                        do_return_3 = True
                        retval__3 = ag__.ld(i) < ag__.ld(num_patches)
                    except:
                        do_return_3 = False
                        raise
                    return fscope_3.ret(retval__3, do_return_3)
    
            @ag__.autograph_artifact
            def body(i, res):
                with ag__.FunctionScope('body', 'fscope_4', ag__.STD) as fscope_4:
                    do_return_4 = False
                    retval__4 = ag__.UndefinedReturnValue()
                    end_idx = ag__.converted_call(ag__.ld(tf).minimum, (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(num_patches)), None, fscope_4)
                    batch_imgs = ag__.ld(cropped_obj)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_offs = ag__.ld(adjusted_offsets)[ag__.ld(i):ag__.ld(end_idx)]
                    batch_imgs = ag__.converted_call(ag__.ld(_tf_pad_sym), (ag__.ld(batch_imgs), ag__.ld(dynamic_pad)), None, fscope_4)
                    batch_offs = ag__.converted_call(ag__.ld(tf).reshape, (ag__.ld(batch_offs), (-1, 2)), None, fscope_4)
                    translated = ag__.converted_call(ag__.ld(translate), (ag__.ld(batch_imgs), ag__.ld(batch_offs)), dict(interpolation='bilinear'), fscope_4)
                    try:
                        do_return_4 = True
                        retval__4 = (ag__.ld(i) + ag__.ld(chunk_sz), ag__.ld(res) + ag__.converted_call(ag__.ld(tf).reduce_sum, (ag__.ld(translated),), dict(axis=0), fscope_4))
                    except:
                        do_return_4 = False
                        raise
                    return fscope_4.ret(retval__4, do_return_4)
>           _, result = ag__.converted_call(ag__.ld(tf).while_loop, (ag__.ld(cond), ag__.ld(body), [ag__.ld(i), ag__.ld(result)]), None, fscope_2)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           ValueError: in user code:
E           
E               File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
E                   _, result = tf.while_loop(cond, body, [i, result])
E           
E               ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.

/tmp/__autograph_generated_fileucaku3ac.py:98: ValueError
---------------------------- Captured stdout setup -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
----------------------------- Captured stdout call -----------------------------
diff3d shape: (20, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (20,)
objectGuess shape: (128, 128)
xcoords shape: (20,)
ycoords shape: (20,)
xcoords_start shape: (20,)
ycoords_start shape: (20,)
DEBUG: nsamples: 10, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (10, 64, 64, 4)
=========================== short test summary info ============================
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-False] - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[True-False-False] - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-True-False] - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[False-False-True] - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_flip_transpose_contract[True-True-True] - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_run_cdi_example_torch_do_stitching_delegates_to_reassemble - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
FAILED tests/torch/test_workflows_components.py::TestReassembleCdiImageTorchGreen::test_reassemble_cdi_image_torch_return_contract - ValueError: in user code:

    File "/home/ollie/Documents/PtychoPINN2/ptycho/tf_helper.py", line 1180, in _streaming  *
        _, result = tf.while_loop(cond, body, [i, result])

    ValueError: Input tensor `cond/zeros:0` enters the loop with shape (None, None, 1), but has shape (None, None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.
================== 7 failed, 1 passed, 8 deselected in 8.95s ===================
