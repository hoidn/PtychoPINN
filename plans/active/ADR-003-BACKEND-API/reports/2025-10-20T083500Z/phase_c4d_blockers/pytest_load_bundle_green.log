============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_model_manager.py::TestLoadTorchBundle::test_reconstructs_models_from_bundle FAILED [100%]

=================================== FAILURES ===================================
___________ TestLoadTorchBundle.test_reconstructs_models_from_bundle ___________

self = <test_model_manager.TestLoadTorchBundle object at 0x75588d15df50>
tmp_path = PosixPath('/tmp/pytest-of-ollie/pytest-742/test_reconstructs_models_from_0')
params_cfg_snapshot = {'N': 64, '_version': '2.0-pytorch', 'amp_activation': 'sigmoid', 'backend': 'tensorflow', ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1.0, model_type='pinn', amp_activation='sigmoid', o...ensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False, backend='tensorflow')
dummy_torch_models = {'autoencoder': DummyModel(
  (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc): Linear(...6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc): Linear(in_features=65536, out_features=128, bias=True)
)}

    def test_reconstructs_models_from_bundle(
        self,
        tmp_path,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_torch_models
    ):
        """
        Phase C4.D A1 TDD RED test: load_torch_bundle must reconstruct both models from wts.h5.zip.
    
        Requirement: ADR-003-BACKEND-API Phase C4.D — unblock integration workflow by
        implementing bundle loader that returns {'diffraction_to_obj', 'autoencoder'}
        model dict + hydrated config per spec §4.6–§4.8 and CONFIG-001.
    
        This test establishes the acceptance criteria for load_torch_bundle completion:
        - Function MUST accept bundle base_path and return models dict + config
        - Models dict MUST contain both 'diffraction_to_obj' and 'autoencoder' keys
        - Each value MUST be a loaded nn.Module (or sentinel dict during torch-optional)
        - Config MUST be reconstructed from serialized metadata (params.dill)
        - params.cfg MUST be populated via CONFIG-001 bridge before model loading
    
        Red-phase expectation (Phase A1):
        - Currently RAISES NotImplementedError at ptycho_torch/model_manager.py:267
        - Capturing RED log to pytest_load_bundle_red.log per plan guidance
    
        Green-phase expectation (Phase A2/A3):
        - RETURNS (models_dict, config) where models_dict has both model keys
        - Each model is reconstructed via create_torch_model_with_gridsize helper
        - Integration test passes bundle to workflows without NotImplementedError
    
        Test mechanism (mirroring TensorFlow analogue):
        - Generate temporary bundle via save_torch_bundle with minimal dual models
        - Call load_torch_bundle expecting models dict return (not single model tuple)
        - Validate returned structure matches TensorFlow ModelManager.load_multiple_models
        - Assert both model names present in returned dict keys
        """
        pytest.importorskip("ptycho_torch.model_manager", reason="model_manager module not yet implemented")
    
        from ptycho_torch.model_manager import save_torch_bundle, load_torch_bundle
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Save lightweight bundle with dual models (Phase A1 guidance: reuse minimal config)
        update_legacy_dict(params_cfg_snapshot, minimal_training_config)
        base_path = tmp_path / "c4d_bundle_loader_test"
    
        save_torch_bundle(
            models_dict=dummy_torch_models,
            base_path=str(base_path),
            config=minimal_training_config
        )
    
        # Clear params.cfg to simulate fresh inference process (CONFIG-001 requirement)
        params.cfg.clear()
        assert params.cfg.get('N') is None, "Sanity check: params.cfg should be empty before load"
    
        # Phase A2/A3: load_torch_bundle should return models dict + config
        # (Currently raises NotImplementedError — RED baseline for Phase A1)
>       models_dict, loaded_config = load_torch_bundle(str(base_path))
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/torch/test_model_manager.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/model_manager.py:345: in load_torch_bundle
    model = create_torch_model_with_gridsize(gridsize, N, params_dict)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho_torch/model_manager.py:249: in create_torch_model_with_gridsize
    model = PtychoPINN_Lightning(
ptycho_torch/model.py:1034: in __init__
    self.model = PtychoPINN(model_config, data_config, training_config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho_torch/model.py:875: in __init__
    self.autoencoder = Autoencoder(model_config, data_config)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho_torch/model.py:490: in __init__
    self.encoder = Encoder(model_config, data_config) # Pass configs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ptycho_torch/model.py:199: in __init__
    self.blocks = nn.ModuleList([
ptycho_torch/model.py:200: in <listcomp>
    ConvPoolBlock(in_channels=self.filters[i-1],
ptycho_torch/model.py:117: in __init__
    super(ConvPoolBlock, self).__init__(in_channels, out_channels,
ptycho_torch/model.py:80: in __init__
    self.conv1 = nn.Conv2d(in_channels = in_channels,
../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/torch/nn/modules/conv.py:515: in __init__
    super().__init__(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <[AttributeError("'Conv2d' object has no attribute 'bias'") raised in repr()] Conv2d object at 0x7557b2ef37d0>
in_channels = 1, out_channels = 32.0, kernel_size = (3, 3), stride = (1, 1)
padding = (1, 1), dilation = (1, 1), transposed = False, output_padding = (0, 0)
groups = 1, bias = True, padding_mode = 'zeros', device = None, dtype = None

    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: tuple[int, ...],
        stride: tuple[int, ...],
        padding: Union[str, tuple[int, ...]],
        dilation: tuple[int, ...],
        transposed: bool,
        output_padding: tuple[int, ...],
        groups: int,
        bias: bool,
        padding_mode: str,
        device=None,
        dtype=None,
    ) -> None:
        factory_kwargs = {"device": device, "dtype": dtype}
        super().__init__()
        if groups <= 0:
            raise ValueError("groups must be a positive integer")
        if in_channels % groups != 0:
            raise ValueError("in_channels must be divisible by groups")
        if out_channels % groups != 0:
            raise ValueError("out_channels must be divisible by groups")
        valid_padding_strings = {"same", "valid"}
        if isinstance(padding, str):
            if padding not in valid_padding_strings:
                raise ValueError(
                    f"Invalid padding string {padding!r}, should be one of {valid_padding_strings}"
                )
            if padding == "same" and any(s != 1 for s in stride):
                raise ValueError(
                    "padding='same' is not supported for strided convolutions"
                )
    
        valid_padding_modes = {"zeros", "reflect", "replicate", "circular"}
        if padding_mode not in valid_padding_modes:
            raise ValueError(
                f"padding_mode must be one of {valid_padding_modes}, but got padding_mode='{padding_mode}'"
            )
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.transposed = transposed
        self.output_padding = output_padding
        self.groups = groups
        self.padding_mode = padding_mode
        # `_reversed_padding_repeated_twice` is the padding to be passed to
        # `F.pad` if needed (e.g., for non-zero padding types that are
        # implemented as two ops: padding + conv). `F.pad` accepts paddings in
        # reverse order than the dimension.
        if isinstance(self.padding, str):
            self._reversed_padding_repeated_twice = [0, 0] * len(kernel_size)
            if padding == "same":
                for d, k, i in zip(
                    dilation, kernel_size, range(len(kernel_size) - 1, -1, -1)
                ):
                    total_padding = d * (k - 1)
                    left_pad = total_padding // 2
                    self._reversed_padding_repeated_twice[2 * i] = left_pad
                    self._reversed_padding_repeated_twice[2 * i + 1] = (
                        total_padding - left_pad
                    )
        else:
            self._reversed_padding_repeated_twice = _reverse_repeat_tuple(
                self.padding, 2
            )
    
        if transposed:
            self.weight = Parameter(
                torch.empty(
                    (in_channels, out_channels // groups, *kernel_size),
                    **factory_kwargs,
                )
            )
        else:
            self.weight = Parameter(
>               torch.empty(
                    (out_channels, in_channels // groups, *kernel_size),
                    **factory_kwargs,
                )
            )
E           TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
E            * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E            * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/torch/nn/modules/conv.py:167: TypeError
---------------------------- Captured stderr setup -----------------------------
2025-10-20 01:04:13.826001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760947453.837966 1540826 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760947453.841777 1540826 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1760947453.852773 1540826 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947453.852790 1540826 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947453.852793 1540826 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947453.852795 1540826 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-20 01:04:13.855581: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----------------------------- Captured stdout call -----------------------------
No GPU found, using CPU instead.
----------------------------- Captured stderr call -----------------------------
2025-10-20 01:04:16.010382: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-10-20 01:04:16.010421: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=""
2025-10-20 01:04:16.010427: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to an empty string - this hides all GPUs from CUDA
2025-10-20 01:04:16.010431: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module
2025-10-20 01:04:16.010435: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: ollie-System-Product-Name
2025-10-20 01:04:16.010438: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: ollie-System-Product-Name
2025-10-20 01:04:16.010464: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 570.172.8
2025-10-20 01:04:16.010479: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 570.172.8
2025-10-20 01:04:16.010483: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 570.172.8
=========================== short test summary info ============================
FAILED tests/torch/test_model_manager.py::TestLoadTorchBundle::test_reconstructs_models_from_bundle - TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
============================== 1 failed in 7.37s ===============================
============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_model_manager.py::TestLoadTorchBundle::test_reconstructs_models_from_bundle FAILED [100%]

=================================== FAILURES ===================================
___________ TestLoadTorchBundle.test_reconstructs_models_from_bundle ___________

self = <test_model_manager.TestLoadTorchBundle object at 0x7f3455955bd0>
tmp_path = PosixPath('/tmp/pytest-of-ollie/pytest-743/test_reconstructs_models_from_0')
params_cfg_snapshot = {'N': 64, '_version': '2.0-pytorch', 'amp_activation': 'sigmoid', 'backend': 'tensorflow', ...}
minimal_training_config = TrainingConfig(model=ModelConfig(N=64, gridsize=2, n_filters_scale=1.0, model_type='pinn', amp_activation='sigmoid', o...ensity_scale_trainable=True, output_dir=PosixPath('training_outputs'), sequential_sampling=False, backend='tensorflow')
dummy_torch_models = {'autoencoder': DummyModel(
  (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc): Linear(...6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (fc): Linear(in_features=65536, out_features=128, bias=True)
)}

    def test_reconstructs_models_from_bundle(
        self,
        tmp_path,
        params_cfg_snapshot,
        minimal_training_config,
        dummy_torch_models
    ):
        """
        Phase C4.D A1 TDD RED test: load_torch_bundle must reconstruct both models from wts.h5.zip.
    
        Requirement: ADR-003-BACKEND-API Phase C4.D — unblock integration workflow by
        implementing bundle loader that returns {'diffraction_to_obj', 'autoencoder'}
        model dict + hydrated config per spec §4.6–§4.8 and CONFIG-001.
    
        This test establishes the acceptance criteria for load_torch_bundle completion:
        - Function MUST accept bundle base_path and return models dict + config
        - Models dict MUST contain both 'diffraction_to_obj' and 'autoencoder' keys
        - Each value MUST be a loaded nn.Module (or sentinel dict during torch-optional)
        - Config MUST be reconstructed from serialized metadata (params.dill)
        - params.cfg MUST be populated via CONFIG-001 bridge before model loading
    
        Red-phase expectation (Phase A1):
        - Currently RAISES NotImplementedError at ptycho_torch/model_manager.py:267
        - Capturing RED log to pytest_load_bundle_red.log per plan guidance
    
        Green-phase expectation (Phase A2/A3):
        - RETURNS (models_dict, config) where models_dict has both model keys
        - Each model is reconstructed via create_torch_model_with_gridsize helper
        - Integration test passes bundle to workflows without NotImplementedError
    
        Test mechanism (mirroring TensorFlow analogue):
        - Generate temporary bundle via save_torch_bundle with minimal dual models
        - Call load_torch_bundle expecting models dict return (not single model tuple)
        - Validate returned structure matches TensorFlow ModelManager.load_multiple_models
        - Assert both model names present in returned dict keys
        """
        pytest.importorskip("ptycho_torch.model_manager", reason="model_manager module not yet implemented")
    
        from ptycho_torch.model_manager import save_torch_bundle, load_torch_bundle
        from ptycho.config.config import update_legacy_dict
        from ptycho import params
    
        # Save lightweight bundle with dual models (Phase A1 guidance: reuse minimal config)
        update_legacy_dict(params_cfg_snapshot, minimal_training_config)
        base_path = tmp_path / "c4d_bundle_loader_test"
    
        save_torch_bundle(
            models_dict=dummy_torch_models,
            base_path=str(base_path),
            config=minimal_training_config
        )
    
        # Clear params.cfg to simulate fresh inference process (CONFIG-001 requirement)
        params.cfg.clear()
        assert params.cfg.get('N') is None, "Sanity check: params.cfg should be empty before load"
    
        # Phase A2/A3: load_torch_bundle should return models dict + config
        # (Currently raises NotImplementedError — RED baseline for Phase A1)
>       models_dict, loaded_config = load_torch_bundle(str(base_path))
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/torch/test_model_manager.py:710: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
ptycho_torch/model_manager.py:353: in load_torch_bundle
    model.load_state_dict(state_dict)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = PtychoPINN_Lightning(
  (model): PtychoPINN(
    (autoencoder): Autoencoder(
      (encoder): Encoder(
        (blocks...  (probe_illumination): ProbeIllumination()
      (pad_and_diffract): LambdaLayer()
    )
  )
  (Loss): PoissonLoss()
)
state_dict = OrderedDict([('conv.weight', tensor([[[[ 0.1782,  0.0047,  0.3016],
          [ 0.1538,  0.1467,  0.2932],
          [...    -1.8348e-03,  2.4902e-03,  7.6536e-04,  3.6408e-03,  1.3094e-04,
         2.7074e-04, -3.5313e-04,  2.8188e-03]))])
strict = True, assign = False

    def load_state_dict(
        self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False
    ):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~torch.nn.Module.state_dict` function.
    
        .. warning::
            If :attr:`assign` is ``True`` the optimizer must be created after
            the call to :attr:`load_state_dict` unless
            :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``
            assign (bool, optional): When set to ``False``, the properties of the tensors
                in the current module are preserved whereas setting it to ``True`` preserves
                properties of the Tensors in the state dict. The only
                exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`
                for which the value from the module is preserved. Default: ``False``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * ``missing_keys`` is a list of str containing any keys that are expected
                    by this module but missing from the provided ``state_dict``.
                * ``unexpected_keys`` is a list of str containing the keys that are not
                    expected by this module but present in the provided ``state_dict``.
    
        Note:
            If a parameter or buffer is registered as ``None`` and its corresponding key
            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a
            ``RuntimeError``.
        """
        if not isinstance(state_dict, Mapping):
            raise TypeError(
                f"Expected state_dict to be dict-like, got {type(state_dict)}."
            )
    
        missing_keys: list[str] = []
        unexpected_keys: list[str] = []
        error_msgs: list[str] = []
    
        # copy state_dict so _load_from_state_dict can modify it
        metadata = getattr(state_dict, "_metadata", None)
        state_dict = OrderedDict(state_dict)
        if metadata is not None:
            # mypy isn't aware that "_metadata" exists in state_dict
            state_dict._metadata = metadata  # type: ignore[attr-defined]
    
        def load(module, local_state_dict, prefix=""):
            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
            if assign:
                local_metadata["assign_to_params_buffers"] = assign
            module._load_from_state_dict(
                local_state_dict,
                prefix,
                local_metadata,
                True,
                missing_keys,
                unexpected_keys,
                error_msgs,
            )
            for name, child in module._modules.items():
                if child is not None:
                    child_prefix = prefix + name + "."
                    child_state_dict = {
                        k: v
                        for k, v in local_state_dict.items()
                        if k.startswith(child_prefix)
                    }
                    load(child, child_state_dict, child_prefix)  # noqa: F821
    
            # Note that the hook can modify missing_keys and unexpected_keys.
            incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)
            for hook in module._load_state_dict_post_hooks.values():
                out = hook(module, incompatible_keys)
                assert out is None, (
                    "Hooks registered with ``register_load_state_dict_post_hook`` are not"
                    "expected to return new values, if incompatible_keys need to be modified,"
                    "it should be done inplace."
                )
    
        load(self, state_dict)
        del load
    
        if strict:
            if len(unexpected_keys) > 0:
                error_msgs.insert(
                    0,
                    "Unexpected key(s) in state_dict: {}. ".format(
                        ", ".join(f'"{k}"' for k in unexpected_keys)
                    ),
                )
            if len(missing_keys) > 0:
                error_msgs.insert(
                    0,
                    "Missing key(s) in state_dict: {}. ".format(
                        ", ".join(f'"{k}"' for k in missing_keys)
                    ),
                )
    
        if len(error_msgs) > 0:
>           raise RuntimeError(
                "Error(s) in loading state_dict for {}:\n\t{}".format(
                    self.__class__.__name__, "\n\t".join(error_msgs)
                )
            )
E           RuntimeError: Error(s) in loading state_dict for PtychoPINN_Lightning:
E           	Missing key(s) in state_dict: "model.autoencoder.encoder.blocks.0.conv1.weight", "model.autoencoder.encoder.blocks.0.conv1.bias", "model.autoencoder.encoder.blocks.0.conv2.weight", "model.autoencoder.encoder.blocks.0.conv2.bias", "model.autoencoder.encoder.blocks.1.conv1.weight", "model.autoencoder.encoder.blocks.1.conv1.bias", "model.autoencoder.encoder.blocks.1.conv2.weight", "model.autoencoder.encoder.blocks.1.conv2.bias", "model.autoencoder.encoder.blocks.2.conv1.weight", "model.autoencoder.encoder.blocks.2.conv1.bias", "model.autoencoder.encoder.blocks.2.conv2.weight", "model.autoencoder.encoder.blocks.2.conv2.bias", "model.autoencoder.decoder_amp.blocks.0.conv1.weight", "model.autoencoder.decoder_amp.blocks.0.conv1.bias", "model.autoencoder.decoder_amp.blocks.0.conv2.weight", "model.autoencoder.decoder_amp.blocks.0.conv2.bias", "model.autoencoder.decoder_amp.blocks.1.conv1.weight", "model.autoencoder.decoder_amp.blocks.1.conv1.bias", "model.autoencoder.decoder_amp.blocks.1.conv2.weight", "model.autoencoder.decoder_amp.blocks.1.conv2.bias", "model.autoencoder.decoder_amp.amp.conv1.weight", "model.autoencoder.decoder_amp.amp.conv1.bias", "model.autoencoder.decoder_amp.amp.conv_up_block.conv1.weight", "model.autoencoder.decoder_amp.amp.conv_up_block.conv1.bias", "model.autoencoder.decoder_amp.amp.conv_up_block.conv2.weight", "model.autoencoder.decoder_amp.amp.conv_up_block.conv2.bias", "model.autoencoder.decoder_amp.amp.conv2.weight", "model.autoencoder.decoder_amp.amp.conv2.bias", "model.autoencoder.decoder_phase.blocks.0.conv1.weight", "model.autoencoder.decoder_phase.blocks.0.conv1.bias", "model.autoencoder.decoder_phase.blocks.0.conv2.weight", "model.autoencoder.decoder_phase.blocks.0.conv2.bias", "model.autoencoder.decoder_phase.blocks.1.conv1.weight", "model.autoencoder.decoder_phase.blocks.1.conv1.bias", "model.autoencoder.decoder_phase.blocks.1.conv2.weight", "model.autoencoder.decoder_phase.blocks.1.conv2.bias", "model.autoencoder.decoder_phase.phase.conv1.weight", "model.autoencoder.decoder_phase.phase.conv1.bias", "model.autoencoder.decoder_phase.phase.conv_up_block.conv1.weight", "model.autoencoder.decoder_phase.phase.conv_up_block.conv1.bias", "model.autoencoder.decoder_phase.phase.conv_up_block.conv2.weight", "model.autoencoder.decoder_phase.phase.conv_up_block.conv2.bias", "model.autoencoder.decoder_phase.phase.conv2.weight", "model.autoencoder.decoder_phase.phase.conv2.bias". 
E           	Unexpected key(s) in state_dict: "conv.weight", "conv.bias", "fc.weight", "fc.bias".

../../miniconda3/envs/ptycho311/lib/python3.11/site-packages/torch/nn/modules/module.py:2624: RuntimeError
---------------------------- Captured stderr setup -----------------------------
2025-10-20 01:04:35.930058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760947475.941403 1541013 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1760947475.945182 1541013 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1760947475.956450 1541013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947475.956475 1541013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947475.956478 1541013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1760947475.956480 1541013 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-20 01:04:35.959242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
----------------------------- Captured stdout call -----------------------------
No GPU found, using CPU instead.
Decoder Block 1: No attention module added.
Decoder Block 2: No attention module added.
Decoder Block 1: No attention module added.
Decoder Block 2: No attention module added.
----------------------------- Captured stderr call -----------------------------
2025-10-20 01:04:38.108112: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2025-10-20 01:04:38.108147: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=""
2025-10-20 01:04:38.108154: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to an empty string - this hides all GPUs from CUDA
2025-10-20 01:04:38.108157: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module
2025-10-20 01:04:38.108161: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: ollie-System-Product-Name
2025-10-20 01:04:38.108164: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: ollie-System-Product-Name
2025-10-20 01:04:38.108189: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 570.172.8
2025-10-20 01:04:38.108205: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 570.172.8
2025-10-20 01:04:38.108208: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 570.172.8
=========================== short test summary info ============================
FAILED tests/torch/test_model_manager.py::TestLoadTorchBundle::test_reconstructs_models_from_bundle - RuntimeError: Error(s) in loading state_dict for PtychoPINN_Lightning:
	Missing key(s) in state_dict: "model.autoencoder.encoder.blocks.0.conv1.weight", "model.autoencoder.encoder.blocks.0.conv1.bias", "model.autoencoder.encoder.blocks.0.conv2.weight", "model.autoencoder.encoder.blocks.0.conv2.bias", "model.autoencoder.encoder.blocks.1.conv1.weight", "model.autoencoder.encoder.blocks.1.conv1.bias", "model.autoencoder.encoder.blocks.1.conv2.weight", "model.autoencoder.encoder.blocks.1.conv2.bias", "model.autoencoder.encoder.blocks.2.conv1.weight", "model.autoencoder.encoder.blocks.2.conv1.bias", "model.autoencoder.encoder.blocks.2.conv2.weight", "model.autoencoder.encoder.blocks.2.conv2.bias", "model.autoencoder.decoder_amp.blocks.0.conv1.weight", "model.autoencoder.decoder_amp.blocks.0.conv1.bias", "model.autoencoder.decoder_amp.blocks.0.conv2.weight", "model.autoencoder.decoder_amp.blocks.0.conv2.bias", "model.autoencoder.decoder_amp.blocks.1.conv1.weight", "model.autoencoder.decoder_amp.blocks.1.conv1.bias", "model.autoencoder.decoder_amp.blocks.1.conv2.weight", "model.autoencoder.decoder_amp.blocks.1.conv2.bias", "model.autoencoder.decoder_amp.amp.conv1.weight", "model.autoencoder.decoder_amp.amp.conv1.bias", "model.autoencoder.decoder_amp.amp.conv_up_block.conv1.weight", "model.autoencoder.decoder_amp.amp.conv_up_block.conv1.bias", "model.autoencoder.decoder_amp.amp.conv_up_block.conv2.weight", "model.autoencoder.decoder_amp.amp.conv_up_block.conv2.bias", "model.autoencoder.decoder_amp.amp.conv2.weight", "model.autoencoder.decoder_amp.amp.conv2.bias", "model.autoencoder.decoder_phase.blocks.0.conv1.weight", "model.autoencoder.decoder_phase.blocks.0.conv1.bias", "model.autoencoder.decoder_phase.blocks.0.conv2.weight", "model.autoencoder.decoder_phase.blocks.0.conv2.bias", "model.autoencoder.decoder_phase.blocks.1.conv1.weight", "model.autoencoder.decoder_phase.blocks.1.conv1.bias", "model.autoencoder.decoder_phase.blocks.1.conv2.weight", "model.autoencoder.decoder_phase.blocks.1.conv2.bias", "model.autoencoder.decoder_phase.phase.conv1.weight", "model.autoencoder.decoder_phase.phase.conv1.bias", "model.autoencoder.decoder_phase.phase.conv_up_block.conv1.weight", "model.autoencoder.decoder_phase.phase.conv_up_block.conv1.bias", "model.autoencoder.decoder_phase.phase.conv_up_block.conv2.weight", "model.autoencoder.decoder_phase.phase.conv_up_block.conv2.bias", "model.autoencoder.decoder_phase.phase.conv2.weight", "model.autoencoder.decoder_phase.phase.conv2.bias". 
	Unexpected key(s) in state_dict: "conv.weight", "conv.bias", "fc.weight", "fc.bias".
============================== 1 failed in 7.38s ===============================
