============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 1 item

tests/torch/test_workflows_components.py::TestWorkflowsComponentsTraining::test_lightning_training_respects_gridsize FAILED [100%]

=================================== FAILURES ===================================
__ TestWorkflowsComponentsTraining.test_lightning_training_respects_gridsize ___

self = <test_workflows_components.TestWorkflowsComponentsTraining object at 0x725a07b661d0>
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x725a07c78390>
params_cfg_snapshot = {'N': 64, 'amp_activation': 'sigmoid', 'backend': 'pytorch', 'batch_size': 16, ...}
dummy_raw_data = <ptycho.raw_data.RawData object at 0x72594ce50d10>

    def test_lightning_training_respects_gridsize(
        self,
        monkeypatch,
        params_cfg_snapshot,
        dummy_raw_data
    ):
        """
        Gridsize Channel Parity Test — _train_with_lightning MUST propagate gridsize to model channels.
    
        Requirement: docs/findings.md#BUG-TF-001 — gridsize > 1 yields channel mismatches
        unless params.cfg['gridsize'] AND PyTorch model configs synchronize C = gridsize**2.
    
        Design contract (phase_c4d_blockers/plan.md §B1-B2):
        - When config.model.gridsize=2, PyTorch DataConfig MUST set C=4 (2×2)
        - ModelConfig MUST set C_model=4 and C_forward=4 to match grouping
        - PtychoPINN_Lightning first conv layer MUST expect 4 input channels (not 1)
    
        Test mechanism:
        - Create TrainingConfig with gridsize=2
        - Monkeypatch PtychoPINN_Lightning to inspect first conv layer input channels
        - Invoke _train_with_lightning
        - Assert first conv layer has in_channels == gridsize**2 == 4
    
        Expected failure mode (RED phase):
        - _train_with_lightning manually builds PTDataConfig with default C=1
        - Lightning module created with C_model=1 → first conv expects 1 channel
        - Assertion fails: in_channels=1 != expected 4
    
        GREEN phase fix:
        - Refactor _train_with_lightning to reuse config_factory.create_training_payload
        - Factory propagates gridsize → C via grid_size tuple → C = grid_size[0]*grid_size[1]
        - ModelConfig receives C_model=4, Lightning module conv layers match
        """
        from ptycho.config.config import TrainingConfig, ModelConfig
        from ptycho_torch.workflows import components as torch_components
    
        # Spy to track Lightning module instantiation and inspect model structure
        lightning_init_spy = {"called": False, "first_conv_in_channels": None}
    
        # Store original PtychoPINN_Lightning before patching
        from ptycho_torch.model import PtychoPINN_Lightning as OriginalLightningModule
    
        def mock_lightning_init(model_config, data_config, training_config, inference_config):
            """Spy that captures PtychoPINN_Lightning model structure."""
            import torch
            import lightning.pytorch as L
    
            # Record that init was called
            lightning_init_spy["called"] = True
    
            # Use the ORIGINAL Lightning module (not the patched version) to inspect architecture
            module = OriginalLightningModule(
                model_config=model_config,
                data_config=data_config,
                training_config=training_config,
                inference_config=inference_config
            )
    
            # Extract first conv layer input channels from the model
            # The PtychoPINN architecture: model.autoencoder.encoder contains Conv2d layers
            # Find the first Conv2d layer and record its in_channels
            for layer in module.model.autoencoder.encoder.modules():
                if isinstance(layer, torch.nn.Conv2d):
                    lightning_init_spy["first_conv_in_channels"] = layer.in_channels
                    break
    
            # Return a stub module to avoid full training execution
            class StubLightningModule(L.LightningModule):
                def __init__(self):
                    super().__init__()
                    self.dummy_param = torch.nn.Parameter(torch.zeros(1))
    
                def training_step(self, batch, batch_idx):
                    return torch.tensor(0.0, requires_grad=True)
    
                def configure_optimizers(self):
                    return torch.optim.Adam(self.parameters(), lr=1e-3)
    
            return StubLightningModule()
    
