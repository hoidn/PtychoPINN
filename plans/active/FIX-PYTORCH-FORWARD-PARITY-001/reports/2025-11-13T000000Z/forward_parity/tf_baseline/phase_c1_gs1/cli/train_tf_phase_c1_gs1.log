TF_XLA_FLAGS=
USE_XLA_TRANSLATE=
2025-11-14 07:59:11.193703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1763135951.205160 3085614 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1763135951.208798 3085614 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1763135951.219107 3085614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1763135951.219116 3085614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1763135951.219117 3085614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1763135951.219119 3085614 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-11-14 07:59:11.221855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-14 07:59:14,018 - INFO - Configuration setup complete
2025-11-14 07:59:14,018 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_train.npz'), test_data_file=PosixPath('datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_test.npz'), batch_size=4, nepochs=10, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_groups=256, n_images=None, n_subsample=None, subsample_seed=None, neighbor_count=1, enable_oversampling=False, neighbor_pool_size=None, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('outputs/tf_forward_parity_baseline/gs1_phase_c1'), sequential_sampling=False, backend='tensorflow', torch_loss_mode='poisson')
2025-11-14 07:59:14,018 - INFO - Legacy mode: using 256 groups (gridsize=1)
2025-11-14 07:59:14,018 - INFO - Starting training with n_subsample=256, n_groups=256, stitching=enabled
2025-11-14 07:59:14,018 - INFO - Loading data from datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_train.npz with n_images=256, n_subsample=256
2025-11-14 07:59:15,140 - INFO - Independent sampling: subsampling 256 images from 7403 total
2025-11-14 07:59:15,140 - INFO - Randomly subsampled 256 images
diff3d shape: (256, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (256,)
objectGuess shape: (232, 232)
xcoords shape: (256,)
ycoords shape: (256,)
xcoords_start shape: (256,)
ycoords_start shape: (256,)
2025-11-14 07:59:16,261 - INFO - Loading data from datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_test.npz with n_images=None, n_subsample=None
2025-11-14 07:59:17,405 - INFO - Using full dataset of 7597 images
diff3d shape: (7597, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (7597,)
objectGuess shape: (232, 232)
xcoords shape: (7597,)
ycoords shape: (7597,)
xcoords_start shape: (7597,)
ycoords_start shape: (7597,)
2025-11-14 07:59:17,450 - INFO - Loaded test data from datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_test.npz
2025-11-14 07:59:17,451 - INFO - Backend dispatcher: params.cfg synchronized with TrainingConfig (backend=tensorflow)
2025-11-14 07:59:17,451 - INFO - Backend dispatcher: routing to TensorFlow workflow (ptycho.workflows.components)
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] generate_grouped_data called with: nsamples=256, n_points=256, C=1, K=1
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Parameters: gridsize=1, N=64, sequential_sampling=False
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Oversampling flags: enable_oversampling=False, neighbor_pool_size=None, effective_K=1
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Oversampling check: nsamples > n_points = 256 > 256 = False
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Oversampling check: C > 1 = 1 > 1 = False
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] needs_oversampling = False
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-11-14 07:59:17,451 - INFO - Using efficient random sampling strategy for gridsize=1
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Taking efficient branch: standard sample-then-group
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently called with: nsamples=256, K=1, C=1
2025-11-14 07:59:17,451 - INFO - Generating 256 groups efficiently from 256 points (K=1, C=1)
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Standard case: using 256 groups from 256 points
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Using all 256 points as seeds (no sampling needed)
2025-11-14 07:59:17,451 - INFO - Using all 256 points as seeds
2025-11-14 07:59:17,451 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently completed: generated 256 groups
2025-11-14 07:59:17,451 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-11-14 07:59:17,451 - INFO - [OVERSAMPLING DEBUG] Generated 256 groups in total
2025-11-14 07:59:17,451 - INFO - Generated 256 groups efficiently
I0000 00:00:1763135957.588188 3085614 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1763135957.589557 3085614 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=127.500 global_offsets=(256, 1, 2, 1) mean=93.734 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] generate_grouped_data called with: nsamples=256, n_points=7597, C=1, K=1
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Parameters: gridsize=1, N=64, sequential_sampling=False
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Oversampling flags: enable_oversampling=False, neighbor_pool_size=None, effective_K=1
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Oversampling check: nsamples > n_points = 256 > 7597 = False
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Oversampling check: C > 1 = 1 > 1 = False
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] needs_oversampling = False
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-11-14 07:59:17,989 - INFO - Using efficient random sampling strategy for gridsize=1
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Taking efficient branch: standard sample-then-group
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently called with: nsamples=256, K=1, C=1
2025-11-14 07:59:17,989 - INFO - Generating 256 groups efficiently from 7597 points (K=1, C=1)
2025-11-14 07:59:17,989 - INFO - [OVERSAMPLING DEBUG] Standard case: using 256 groups from 7597 points
2025-11-14 07:59:17,990 - INFO - [OVERSAMPLING DEBUG] Randomly sampled 256 seed points
2025-11-14 07:59:17,990 - INFO - Sampled 256 seed points from 7597 total points
2025-11-14 07:59:17,990 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-11-14 07:59:17,990 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently completed: generated 256 groups
2025-11-14 07:59:17,990 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-11-14 07:59:17,990 - INFO - [OVERSAMPLING DEBUG] Generated 256 groups in total
2025-11-14 07:59:17,990 - INFO - Generated 256 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=4082.254 global_offsets=(256, 1, 2, 1) mean=137.231 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-11-14 07:59:18.655585: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-11-14 07:59:18.655597: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1763135958.655612 3085614 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1763135958.672808 3085614 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-11-14 07:59:18.672890: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1763135958.672966 3085614 cupti_tracer.cc:1249] CUPTI activity buffer flushed
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
backend: tensorflow
batch_size: 4
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
enable_oversampling: False
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_groups: 256
neighbor_count: 1
nepochs: 10
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: outputs/tf_forward_parity_baseline/gs1_phase_c1
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_test.npz
torch_loss_mode: poisson
train_data_file_path: datasets/fly001_reconstructed_prepared/fly001_reconstructed_final_downsampled_data_train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/10
input shape (None, 64, 64, 1)
2025-11-14 07:59:19,369 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-11-14 07:59:21,485 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-11-14 07:59:22.686472: W tensorflow/core/common_runtime/type_inference.cc:340] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_INT32
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_FLOAT
    }
  }
}

	for Tuple type infernce function 0
	while inferring type of node 'StatefulPartitionedCall/functional_1/padded_obj_2_1/cond/output/_165'
I0000 00:00:1763135963.605474 3085756 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1763135964.049436 3085756 cuda_solvers.cc:175] Creating GpuSolver handles for stream 0xd579b10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5:54[0m 6s/step - intensity_scaler_inv_loss: 169.9056 - loss: -2763661.2500 - pred_intensity_loss: -2763661.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 352.0984 - loss: -2305455.5000 - pred_intensity_loss: -2305455.5000 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 307.1512 - loss: -2411530.5000 - pred_intensity_loss: -2411530.5000 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 278.6422 - loss: -2478217.2500 - pred_intensity_loss: -2478217.2500 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 256.7287 - loss: -2526051.5000 - pred_intensity_loss: -2526051.5000 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 239.4472 - loss: -2562463.7500 - pred_intensity_loss: -2562463.7500 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 225.7560 - loss: -2590352.2500 - pred_intensity_loss: -2590352.2500 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 214.4524 - loss: -2612800.7500 - pred_intensity_loss: -2612800.7500 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 204.9352 - loss: -2630770.2500 - pred_intensity_loss: -2630770.2500 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 196.8184 - loss: -2645575.2500 - pred_intensity_loss: -2645575.2500 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 189.7483 - loss: -2658333.5000 - pred_intensity_loss: -2658333.5000 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 183.5955 - loss: -2669237.0000 - pred_intensity_loss: -2669237.0000 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 178.2058 - loss: -2678715.5000 - pred_intensity_loss: -2678715.5000 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 19ms/step - intensity_scaler_inv_loss: 177.2036 - loss: -2680460.5000 - pred_intensity_loss: -2680459.0000 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-11-14 07:59:26,394 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m8s[0m 38ms/step - intensity_scaler_inv_loss: 117.0678 - loss: -2785154.7500 - pred_intensity_loss: -2785058.5000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 78.4724 - val_loss: -2853634.7500 - val_pred_intensity_loss: -2846148.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 30ms/step - intensity_scaler_inv_loss: 87.7876 - loss: -2834551.2500 - pred_intensity_loss: -2834551.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 83.5585 - loss: -2834969.0000 - pred_intensity_loss: -2834969.0000 - trimmed_obj_loss: 0.0000e+00[1m 9/61[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 83.8318 - loss: -2830057.2500 - pred_intensity_loss: -2830057.2500 - trimmed_obj_loss: 0.0000e+00[1m13/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 84.0728 - loss: -2830139.5000 - pred_intensity_loss: -2830139.5000 - trimmed_obj_loss: 0.0000e+00[1m18/61[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 84.1752 - loss: -2829309.0000 - pred_intensity_loss: -2829309.0000 - trimmed_obj_loss: 0.0000e+00[1m23/61[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 83.8222 - loss: -2829725.2500 - pred_intensity_loss: -2829725.2500 - trimmed_obj_loss: 0.0000e+00[1m28/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 83.4723 - loss: -2831359.0000 - pred_intensity_loss: -2831359.0000 - trimmed_obj_loss: 0.0000e+00[1m33/61[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 82.9720 - loss: -2832165.0000 - pred_intensity_loss: -2832165.0000 - trimmed_obj_loss: 0.0000e+00[1m38/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 82.5237 - loss: -2832652.5000 - pred_intensity_loss: -2832652.5000 - trimmed_obj_loss: 0.0000e+00[1m43/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 82.1059 - loss: -2832924.7500 - pred_intensity_loss: -2832924.7500 - trimmed_obj_loss: 0.0000e+00[1m48/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 81.7152 - loss: -2833192.0000 - pred_intensity_loss: -2833192.0000 - trimmed_obj_loss: 0.0000e+00[1m53/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 81.4062 - loss: -2833263.7500 - pred_intensity_loss: -2833263.7500 - trimmed_obj_loss: 0.0000e+00[1m58/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 81.1241 - loss: -2833395.7500 - pred_intensity_loss: -2833395.7500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 78.6560 - loss: -2836280.7500 - pred_intensity_loss: -2836323.5000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 75.4737 - val_loss: -2855061.7500 - val_pred_intensity_loss: -2847466.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 64.1498 - loss: -2888685.2500 - pred_intensity_loss: -2888685.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 70.5406 - loss: -2861560.2500 - pred_intensity_loss: -2861560.2500 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.2632 - loss: -2856077.0000 - pred_intensity_loss: -2856077.0000 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.5841 - loss: -2852209.0000 - pred_intensity_loss: -2852209.0000 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.7706 - loss: -2849110.7500 - pred_intensity_loss: -2849110.7500 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.6920 - loss: -2847151.5000 - pred_intensity_loss: -2847151.5000 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.4998 - loss: -2846142.7500 - pred_intensity_loss: -2846142.7500 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 71.2400 - loss: -2845499.0000 - pred_intensity_loss: -2845499.0000 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 70.8832 - loss: -2845196.5000 - pred_intensity_loss: -2845196.5000 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 70.4855 - loss: -2844892.7500 - pred_intensity_loss: -2844892.7500 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 70.0368 - loss: -2844569.2500 - pred_intensity_loss: -2844569.2500 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 69.5466 - loss: -2844376.7500 - pred_intensity_loss: -2844376.7500 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 69.0370 - loss: -2844264.7500 - pred_intensity_loss: -2844264.7500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 62.9636 - loss: -2842789.2500 - pred_intensity_loss: -2842815.2500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 50.1732 - val_loss: -2864497.5000 - val_pred_intensity_loss: -2857744.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 49.0703 - loss: -2879410.5000 - pred_intensity_loss: -2879410.5000 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 51.3591 - loss: -2846539.0000 - pred_intensity_loss: -2846539.0000 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 51.2980 - loss: -2844438.0000 - pred_intensity_loss: -2844438.0000 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 50.9647 - loss: -2843284.2500 - pred_intensity_loss: -2843284.2500 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 50.6315 - loss: -2842921.2500 - pred_intensity_loss: -2842921.2500 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 50.3385 - loss: -2842925.7500 - pred_intensity_loss: -2842925.7500 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 50.0011 - loss: -2843305.2500 - pred_intensity_loss: -2843305.2500 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 49.6474 - loss: -2843551.2500 - pred_intensity_loss: -2843551.2500 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 49.2677 - loss: -2843979.2500 - pred_intensity_loss: -2843979.2500 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 48.9043 - loss: -2844254.7500 - pred_intensity_loss: -2844254.7500 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 48.5513 - loss: -2844396.5000 - pred_intensity_loss: -2844396.5000 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 48.2043 - loss: -2844722.7500 - pred_intensity_loss: -2844722.7500 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 47.8685 - loss: -2845000.5000 - pred_intensity_loss: -2845000.5000 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 43.8443 - loss: -2849412.0000 - pred_intensity_loss: -2849357.7500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 37.6077 - val_loss: -2867365.0000 - val_pred_intensity_loss: -2861232.5000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 40.6832 - loss: -2798226.2500 - pred_intensity_loss: -2798226.2500 - trimmed_obj_loss: 0.0000e+00[1m 6/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 37.7717 - loss: -2854019.2500 - pred_intensity_loss: -2854019.2500 - trimmed_obj_loss: 0.0000e+00[1m11/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 37.2632 - loss: -2856703.0000 - pred_intensity_loss: -2856703.0000 - trimmed_obj_loss: 0.0000e+00[1m16/61[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.9930 - loss: -2858667.2500 - pred_intensity_loss: -2858667.2500 - trimmed_obj_loss: 0.0000e+00[1m21/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.8218 - loss: -2860222.5000 - pred_intensity_loss: -2860222.5000 - trimmed_obj_loss: 0.0000e+00[1m26/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.7249 - loss: -2860632.2500 - pred_intensity_loss: -2860632.2500 - trimmed_obj_loss: 0.0000e+00[1m31/61[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.6240 - loss: -2860870.0000 - pred_intensity_loss: -2860870.0000 - trimmed_obj_loss: 0.0000e+00[1m36/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.4761 - loss: -2860709.0000 - pred_intensity_loss: -2860709.0000 - trimmed_obj_loss: 0.0000e+00[1m41/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.3709 - loss: -2860386.7500 - pred_intensity_loss: -2860386.7500 - trimmed_obj_loss: 0.0000e+00[1m46/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.2832 - loss: -2859827.7500 - pred_intensity_loss: -2859827.7500 - trimmed_obj_loss: 0.0000e+00[1m51/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.1893 - loss: -2859234.2500 - pred_intensity_loss: -2859234.2500 - trimmed_obj_loss: 0.0000e+00[1m56/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.0988 - loss: -2858708.0000 - pred_intensity_loss: -2858708.0000 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 36.0177 - loss: -2858131.2500 - pred_intensity_loss: -2858133.2500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 35.0159 - loss: -2851756.7500 - pred_intensity_loss: -2851870.7500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 31.2648 - val_loss: -2868819.7500 - val_pred_intensity_loss: -2862739.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 33.7816 - loss: -2899912.5000 - pred_intensity_loss: -2899912.5000 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 35.2667 - loss: -2874651.2500 - pred_intensity_loss: -2874651.2500 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 35.3823 - loss: -2865210.2500 - pred_intensity_loss: -2865210.2500 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 35.1921 - loss: -2862361.2500 - pred_intensity_loss: -2862361.2500 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 35.0434 - loss: -2859471.2500 - pred_intensity_loss: -2859471.2500 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 34.8714 - loss: -2856377.7500 - pred_intensity_loss: -2856377.7500 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 34.6937 - loss: -2854666.0000 - pred_intensity_loss: -2854666.0000 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 34.4924 - loss: -2853280.7500 - pred_intensity_loss: -2853280.7500 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 34.3070 - loss: -2852387.2500 - pred_intensity_loss: -2852387.2500 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 34.1350 - loss: -2851969.0000 - pred_intensity_loss: -2851969.0000 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 33.9920 - loss: -2851731.0000 - pred_intensity_loss: -2851731.0000 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 33.8527 - loss: -2851632.0000 - pred_intensity_loss: -2851632.0000 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 33.7163 - loss: -2851614.2500 - pred_intensity_loss: -2851614.2500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 32.0017 - loss: -2852465.0000 - pred_intensity_loss: -2852669.0000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 28.9325 - val_loss: -2869181.2500 - val_pred_intensity_loss: -2863140.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 30ms/step - intensity_scaler_inv_loss: 32.3792 - loss: -2829063.5000 - pred_intensity_loss: -2829063.5000 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 31.2474 - loss: -2844010.2500 - pred_intensity_loss: -2844010.2500 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 30.6699 - loss: -2851562.7500 - pred_intensity_loss: -2851562.7500 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 30.5353 - loss: -2856304.2500 - pred_intensity_loss: -2856304.2500 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.4531 - loss: -2857473.0000 - pred_intensity_loss: -2857473.0000 - trimmed_obj_loss: 0.0000e+00[1m24/61[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.3778 - loss: -2857369.5000 - pred_intensity_loss: -2857369.5000 - trimmed_obj_loss: 0.0000e+00[1m28/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.3275 - loss: -2857158.0000 - pred_intensity_loss: -2857158.0000 - trimmed_obj_loss: 0.0000e+00[1m33/61[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.2717 - loss: -2856640.0000 - pred_intensity_loss: -2856640.0000 - trimmed_obj_loss: 0.0000e+00[1m38/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.2337 - loss: -2856065.7500 - pred_intensity_loss: -2856065.7500 - trimmed_obj_loss: 0.0000e+00[1m43/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.1929 - loss: -2855966.7500 - pred_intensity_loss: -2855966.7500 - trimmed_obj_loss: 0.0000e+00[1m48/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.1534 - loss: -2855988.7500 - pred_intensity_loss: -2855988.7500 - trimmed_obj_loss: 0.0000e+00[1m53/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.1088 - loss: -2855912.0000 - pred_intensity_loss: -2855912.0000 - trimmed_obj_loss: 0.0000e+00[1m58/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.0579 - loss: -2855735.2500 - pred_intensity_loss: -2855735.2500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 29.4630 - loss: -2852983.0000 - pred_intensity_loss: -2852807.7500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 27.9143 - val_loss: -2869427.0000 - val_pred_intensity_loss: -2863383.5000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 34.1289 - loss: -2866661.2500 - pred_intensity_loss: -2866661.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 30.9273 - loss: -2865407.2500 - pred_intensity_loss: -2865407.2500 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.2144 - loss: -2862371.0000 - pred_intensity_loss: -2862371.0000 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 30.0200 - loss: -2858852.0000 - pred_intensity_loss: -2858852.0000 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 29.7804 - loss: -2857688.0000 - pred_intensity_loss: -2857688.0000 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 29.5527 - loss: -2857005.0000 - pred_intensity_loss: -2857005.0000 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 29.3516 - loss: -2856608.5000 - pred_intensity_loss: -2856608.5000 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 29.2135 - loss: -2856556.7500 - pred_intensity_loss: -2856556.7500 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 29.0989 - loss: -2856401.2500 - pred_intensity_loss: -2856401.2500 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.9922 - loss: -2856319.2500 - pred_intensity_loss: -2856319.2500 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.8930 - loss: -2856221.5000 - pred_intensity_loss: -2856221.5000 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.8154 - loss: -2855973.7500 - pred_intensity_loss: -2855973.7500 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.7498 - loss: -2855743.7500 - pred_intensity_loss: -2855743.7500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 27.9796 - loss: -2853283.2500 - pred_intensity_loss: -2853131.0000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 26.1282 - val_loss: -2869709.0000 - val_pred_intensity_loss: -2863668.7500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 27.8880 - loss: -2858027.5000 - pred_intensity_loss: -2858027.5000 - trimmed_obj_loss: 0.0000e+00[1m 6/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.6445 - loss: -2840497.2500 - pred_intensity_loss: -2840497.2500 - trimmed_obj_loss: 0.0000e+00[1m11/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.4036 - loss: -2845793.7500 - pred_intensity_loss: -2845793.7500 - trimmed_obj_loss: 0.0000e+00[1m16/61[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.3051 - loss: -2846229.2500 - pred_intensity_loss: -2846229.2500 - trimmed_obj_loss: 0.0000e+00[1m21/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.2013 - loss: -2847151.2500 - pred_intensity_loss: -2847151.2500 - trimmed_obj_loss: 0.0000e+00[1m26/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 28.0625 - loss: -2848202.7500 - pred_intensity_loss: -2848202.7500 - trimmed_obj_loss: 0.0000e+00[1m31/61[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.9311 - loss: -2848869.7500 - pred_intensity_loss: -2848869.7500 - trimmed_obj_loss: 0.0000e+00[1m36/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.8462 - loss: -2849549.5000 - pred_intensity_loss: -2849549.5000 - trimmed_obj_loss: 0.0000e+00[1m41/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.7565 - loss: -2850295.7500 - pred_intensity_loss: -2850295.7500 - trimmed_obj_loss: 0.0000e+00[1m46/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.6713 - loss: -2851041.5000 - pred_intensity_loss: -2851041.5000 - trimmed_obj_loss: 0.0000e+00[1m51/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.5971 - loss: -2851752.0000 - pred_intensity_loss: -2851752.0000 - trimmed_obj_loss: 0.0000e+00[1m56/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.5352 - loss: -2852039.7500 - pred_intensity_loss: -2852039.7500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 27.4855 - loss: -2852118.2500 - pred_intensity_loss: -2852116.7500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 26.9183 - loss: -2853485.2500 - pred_intensity_loss: -2853395.2500 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 25.5542 - val_loss: -2869842.2500 - val_pred_intensity_loss: -2863777.0000 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/10
[1m 1/61[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 29ms/step - intensity_scaler_inv_loss: 26.0096 - loss: -2881601.0000 - pred_intensity_loss: -2881601.0000 - trimmed_obj_loss: 0.0000e+00[1m 5/61[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 13ms/step - intensity_scaler_inv_loss: 26.1360 - loss: -2874669.5000 - pred_intensity_loss: -2874669.5000 - trimmed_obj_loss: 0.0000e+00[1m10/61[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1270 - loss: -2876097.5000 - pred_intensity_loss: -2876097.5000 - trimmed_obj_loss: 0.0000e+00[1m15/61[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1886 - loss: -2874581.7500 - pred_intensity_loss: -2874581.7500 - trimmed_obj_loss: 0.0000e+00[1m20/61[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1549 - loss: -2873686.2500 - pred_intensity_loss: -2873686.2500 - trimmed_obj_loss: 0.0000e+00[1m25/61[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1618 - loss: -2872886.0000 - pred_intensity_loss: -2872886.0000 - trimmed_obj_loss: 0.0000e+00[1m30/61[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1538 - loss: -2872073.0000 - pred_intensity_loss: -2872073.0000 - trimmed_obj_loss: 0.0000e+00[1m35/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1450 - loss: -2870473.7500 - pred_intensity_loss: -2870473.7500 - trimmed_obj_loss: 0.0000e+00[1m40/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1320 - loss: -2868977.2500 - pred_intensity_loss: -2868977.2500 - trimmed_obj_loss: 0.0000e+00[1m45/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.1133 - loss: -2867734.5000 - pred_intensity_loss: -2867734.5000 - trimmed_obj_loss: 0.0000e+00[1m50/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.0931 - loss: -2866849.2500 - pred_intensity_loss: -2866849.2500 - trimmed_obj_loss: 0.0000e+00[1m55/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.0687 - loss: -2865992.5000 - pred_intensity_loss: -2865992.5000 - trimmed_obj_loss: 0.0000e+00[1m60/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 12ms/step - intensity_scaler_inv_loss: 26.0463 - loss: -2865083.2500 - pred_intensity_loss: -2865083.2500 - trimmed_obj_loss: 0.0000e+00[1m61/61[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 13ms/step - intensity_scaler_inv_loss: 25.7319 - loss: -2853705.0000 - pred_intensity_loss: -2853716.5000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 24.0142 - val_loss: -2870074.5000 - val_pred_intensity_loss: -2864035.2500 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
W0000 00:00:1763135974.827672 3085614 loop_optimizer.cc:934] Skipping loop optimization for Merge node with control input: functional_1/padded_obj_2_1/cond/branch_executed/_9
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (None, 64, 64, 1)
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 903ms/step[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 1048576 into shape (9,9,64,64,1)
2025-11-14 07:59:35,197 - INFO - Performing image stitching...
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] generate_grouped_data called with: nsamples=256, n_points=7597, C=1, K=1
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Parameters: gridsize=1, N=64, sequential_sampling=False
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Oversampling flags: enable_oversampling=False, neighbor_pool_size=None, effective_K=1
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Oversampling check: nsamples > n_points = 256 > 7597 = False
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Oversampling check: C > 1 = 1 > 1 = False
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] needs_oversampling = False
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-11-14 07:59:35,197 - INFO - Using efficient random sampling strategy for gridsize=1
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Taking efficient branch: standard sample-then-group
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently called with: nsamples=256, K=1, C=1
2025-11-14 07:59:35,197 - INFO - Generating 256 groups efficiently from 7597 points (K=1, C=1)
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Standard case: using 256 groups from 7597 points
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Randomly sampled 256 seed points
2025-11-14 07:59:35,197 - INFO - Sampled 256 seed points from 7597 total points
2025-11-14 07:59:35,197 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] _generate_groups_efficiently completed: generated 256 groups
2025-11-14 07:59:35,197 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-11-14 07:59:35,197 - INFO - [OVERSAMPLING DEBUG] Generated 256 groups in total
2025-11-14 07:59:35,197 - INFO - Generated 256 groups efficiently
I0000 00:00:1763135975.904967 3085755 service.cc:152] XLA service 0x767d7817bda0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1763135975.904991 3085755 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-11-14 07:59:35.950206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-11-14 07:59:36.018708: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at if_op.cc:285 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[] on XLA_GPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}){{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}
The op is created at: 
dummy_file_name:10:dummy_function_name
	tf2xla conversion failed while converting functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File "Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
File "Documents/PtychoPINN/scripts/training/train.py", line 419, in main
File "Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
File "Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 566, in predict
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 260, in one_step_on_data_distributed
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 250, in one_step_on_data
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 105, in predict_step
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 183, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/function.py", line 206, in _run_through_graph
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 644, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "Documents/PtychoPINN/ptycho/custom_layers.py", line 155, in call
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1070, in reassemble_patches
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 678, in newf
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1318, in reassemble_patches_position_batched_real
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1001, in _reassemble_position_batched

2025-11-14 07:59:36.020541: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[] on XLA_GPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}){{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}
The op is created at: 
dummy_file_name:10:dummy_function_name
	tf2xla conversion failed while converting functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File "Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
File "Documents/PtychoPINN/scripts/training/train.py", line 419, in main
File "Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
File "Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 566, in predict
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 260, in one_step_on_data_distributed
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 250, in one_step_on_data
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 105, in predict_step
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 183, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/function.py", line 206, in _run_through_graph
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 644, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "Documents/PtychoPINN/ptycho/custom_layers.py", line 155, in call
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1070, in reassemble_patches
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 678, in newf
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1318, in reassemble_patches_position_batched_real
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1001, in _reassemble_position_batched

	 [[functional_2_1/padded_obj_2_1/cond]]
	tf2xla conversion failed while converting __inference_one_step_on_data_29189[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
2025-11-14 07:59:36.020576: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[] on XLA_GPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}){{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}
The op is created at: 
dummy_file_name:10:dummy_function_name
	tf2xla conversion failed while converting functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File "Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
File "Documents/PtychoPINN/scripts/training/train.py", line 419, in main
File "Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
File "Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 566, in predict
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 260, in one_step_on_data_distributed
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 250, in one_step_on_data
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 105, in predict_step
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 183, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/function.py", line 206, in _run_through_graph
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 644, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "Documents/PtychoPINN/ptycho/custom_layers.py", line 155, in call
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1070, in reassemble_patches
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 678, in newf
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1318, in reassemble_patches_position_batched_real
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1001, in _reassemble_position_batched

	 [[functional_2_1/padded_obj_2_1/cond]]
	tf2xla conversion failed while converting __inference_one_step_on_data_29189[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
	 [[StatefulPartitionedCall]]
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=3591.047 global_offsets=(256, 1, 2, 1) mean=138.017 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
2025-11-14 07:59:36,080 - ERROR - An error occurred during execution: Graph execution error:

Detected at node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0 defined at (most recent call last):
<stack traces unavailable>
Detected at node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0 defined at (most recent call last):
<stack traces unavailable>
Detected unsupported operations when trying to compile graph functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[] on XLA_GPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}){{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}
The op is created at: 
dummy_file_name:10:dummy_function_name
	tf2xla conversion failed while converting functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File "Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
File "Documents/PtychoPINN/scripts/training/train.py", line 419, in main
File "Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
File "Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 566, in predict
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 260, in one_step_on_data_distributed
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 250, in one_step_on_data
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 105, in predict_step
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 183, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/function.py", line 206, in _run_through_graph
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 644, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "Documents/PtychoPINN/ptycho/custom_layers.py", line 155, in call
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1070, in reassemble_patches
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 678, in newf
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1318, in reassemble_patches_position_batched_real
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1001, in _reassemble_position_batched

	 [[functional_2_1/padded_obj_2_1/cond]]
	tf2xla conversion failed while converting __inference_one_step_on_data_29189[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
	 [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_29282]
Traceback (most recent call last):
  File "/home/ollie/Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
    main()
  File "/home/ollie/Documents/PtychoPINN/scripts/training/train.py", line 419, in main
    recon_amp, recon_phase, results = run_cdi_example_with_backend(
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ollie/Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
    recon_amp, recon_phase, results = tf_components.run_cdi_example(
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ollie/Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
    recon_amp, recon_phase, reassemble_results = reassemble_cdi_image(
                                                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ollie/Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
    obj_tensor_full, global_offsets = nbutils.reconstruct_image(test_container)
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ollie/Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
    obj_tensor_full = diffraction_to_obj.predict(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/tensorflow/python/eager/execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0 defined at (most recent call last):
<stack traces unavailable>
Detected at node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0 defined at (most recent call last):
<stack traces unavailable>
Detected unsupported operations when trying to compile graph functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[] on XLA_GPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_GPU_JIT devices compatible with node {{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}){{node functional_2_1/padded_obj_2_1/cond/translation_37_1/ImageProjectiveTransformV3_tfg_inlined_functional_2_1/padded_obj_2_1/cond_0}}
The op is created at: 
dummy_file_name:10:dummy_function_name
	tf2xla conversion failed while converting functional_2_1_padded_obj_2_1_cond_true_28100_tfg_region_specialized_functional_2_1_padded_obj_2_1_cond_0_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.

Stack trace for op definition: 
File "Documents/PtychoPINN/scripts/training/train.py", line 440, in <module>
File "Documents/PtychoPINN/scripts/training/train.py", line 419, in main
File "Documents/PtychoPINN/ptycho/workflows/backend_selector.py", line 141, in run_cdi_example_with_backend
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 853, in run_cdi_example
File "Documents/PtychoPINN/ptycho/workflows/components.py", line 777, in reassemble_cdi_image
File "Documents/PtychoPINN/ptycho/nbutils.py", line 186, in reconstruct_image
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 566, in predict
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 260, in one_step_on_data_distributed
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 250, in one_step_on_data
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py", line 105, in predict_step
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 183, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/function.py", line 206, in _run_through_graph
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/models/functional.py", line 644, in call
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py", line 941, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 117, in error_handler
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/ops/operation.py", line 59, in __call__
File "miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 156, in error_handler
File "Documents/PtychoPINN/ptycho/custom_layers.py", line 155, in call
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1070, in reassemble_patches
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 678, in newf
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1318, in reassemble_patches_position_batched_real
File "Documents/PtychoPINN/ptycho/tf_helper.py", line 1001, in _reassemble_position_batched

	 [[functional_2_1/padded_obj_2_1/cond]]
	tf2xla conversion failed while converting __inference_one_step_on_data_29189[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.
	 [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_29282]
