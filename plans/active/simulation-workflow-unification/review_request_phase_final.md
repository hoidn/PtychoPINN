# Review Request: Phase Final - Deprecation, Documentation & Cleanup

**Initiative:** Simulation Workflow Unification
**Generated:** 2025-08-03 01:14:00

This document contains all necessary information to review the work completed for Phase Final.

## Instructions for Reviewer

1.  Analyze the planning documents and the code changes (`git diff`) below.
2.  Create a new file named `review_phase_final.md` in this same directory (`plans/active/simulation-workflow-unification/`).
3.  In your review file, you **MUST** provide a clear verdict on a single line: `VERDICT: ACCEPT` or `VERDICT: REJECT`.
4.  If rejecting, you **MUST** provide a list of specific, actionable fixes under a "Required Fixes" heading.

---
## 1. Planning Documents

### R&D Plan (`plan.md`)
# R&D Plan: Simulation Workflow Unification

*Created: 2025-08-02*

## üéØ **OBJECTIVE & HYPOTHESIS**

**Project/Initiative Name:** Simulation Workflow Unification

**Problem Statement:** The current simulation pipeline, specifically the workflow invoked by `scripts/simulation/simulate_and_save.py`, contains a critical architectural flaw. It relies on a legacy, monolithic function (`RawData.from_simulation`) that improperly mixes data preparation and physics simulation. This leads to a tensor shape mismatch bug when using `gridsize > 1`, causing the simulation to crash. Furthermore, this legacy path is inconsistent with the modern, more robust data generation logic used by the main training pipeline, creating architectural debt and maintenance challenges.

**Proposed Solution / Hypothesis:**
- **Solution:** We will refactor the `simulate_and_save.py` workflow to abandon the monolithic `RawData.from_simulation` method. Instead, it will be re-implemented to explicitly orchestrate the distinct steps of coordinate grouping, ground truth patch extraction, and diffraction simulation using the modern, modular helper functions that are already proven in the main training pipeline. This will align the simulation workflow with the project's best practices of explicit, decoupled logic.
- **Hypothesis:** By refactoring the simulation pipeline to use a modular, step-by-step approach, we will not only fix the `gridsize > 1` bug but also improve the pipeline's correctness, maintainability, and consistency with the rest of the codebase. This architectural alignment will prevent future regressions and make the simulation tools more robust and easier to debug.

---

## üõ†Ô∏è **METHODOLOGY / SOLUTION APPROACH**

The core of this initiative is to decompose and re-orchestrate the simulation logic. Instead of relying on a single black-box function, the `simulate_and_save.py` script will be modified to manage the data flow explicitly.

### The Refactored Workflow:

1. **Load Inputs:** Load `objectGuess` and `probeGuess` from specified files.

2. **Generate & Group Coordinates:** Use the modular `ptycho.raw_data.group_coords()` function to generate scan positions and group them according to the `gridsize`.

3. **Extract Ground Truth Patches (Y):** Use the modular `ptycho.raw_data.get_image_patches()` to extract object patches in the correct multi-channel "Channel Format".

4. **Format Conversion & Simulation (X):**
   - Explicitly convert the Y patches from "Channel Format" to "Flat Format" using `ptycho.tf_helper._channel_to_flat()`.
   - Call the core physics engine `ptycho.diffsim.illuminate_and_diffract()` with the correctly formatted flat tensor.
   - Convert the resulting flat diffraction tensor back to "Channel Format" using `ptycho.tf_helper._flat_to_channel()`.

5. **Assemble & Save:** Combine all generated arrays into a final `.npz` file that adheres to the project's data contracts.

This approach isolates the change to the high-level orchestration script, leaving the core, stable components (`illuminate_and_diffract`, `group_coords`, etc.) unmodified.

---

## üéØ **DELIVERABLES**

1. **Refactored Simulation Script:** An updated `scripts/simulation/simulate_and_save.py` that implements the new, modular workflow.

2. **New Integration Test Suite:** A new test file, `tests/simulation/test_simulate_and_save.py`, that provides comprehensive validation for the refactored pipeline.

3. **Updated Documentation:** Revisions to `scripts/simulation/CLAUDE.md` and `README.md` to reflect the unified and corrected architecture.

4. **Deprecation of Legacy Method:** The `RawData.from_simulation` method will be marked with a `DeprecationWarning` to guide future development.

---

## ‚úÖ **VALIDATION & VERIFICATION PLAN**

This initiative's success depends on rigorous validation to ensure correctness and prevent regressions.

### Unit / Integration Tests:

A new integration test suite (`tests/simulation/test_simulate_and_save.py`) will be created to verify the end-to-end behavior of the refactored `simulate_and_save.py` script. The tests will:

1. **Verify gridsize=1 Regression:** Run the script with `gridsize=1` and assert that the output `.npz` file contains tensors with the correct single-channel shapes (e.g., `(B, N, N)`).

2. **Verify gridsize=2 Correctness:** Run the script with `gridsize=2` and assert that the output `.npz` file contains tensors with the correct multi-channel shapes (e.g., `(B, N, N, 4)`).

3. **Verify Probe Override:** Run the script with the `--probe-file` argument and assert that the `probeGuess` in the output file matches the external probe.

4. **Content Sanity Check:** Perform basic checks on the output data to ensure it is physically plausible (e.g., non-zero, correct data types).

5. **Data Contract Compliance:** Verify that all output files strictly adhere to the specifications in `docs/data_contracts.md`:
   - `diffraction` is `float32` amplitude (not intensity)
   - `Y` patches (if generated) are `complex64` and 3D
   - All required keys are present with correct shapes

### Success Criteria:

- The `ValueError` crash when running `simulate_and_save.py` with `gridsize > 1` is resolved.
- The refactored script produces valid, training-ready datasets that conform to the project's data contracts for both `gridsize=1` and `gridsize > 1`.
- All new integration tests pass, confirming both the fix and the absence of regressions in the `gridsize=1` case.
- The simulation pipeline's logic is now explicit, modular, and consistent with the main training pipeline's data handling.
- Performance benchmarks show no significant regression compared to the legacy implementation.

---

## üöÄ **RISK MITIGATION**

**Risk:** The refactoring introduces a subtle bug that leads to silent data corruption (e.g., mismatch between coordinates and patches).
- **Mitigation:** The new integration test suite will include content validation to catch such issues. Visual inspection of the output using `visualize_dataset.py` will be a required manual step during development.

**Risk:** The change breaks an unknown, downstream dependency on the old `RawData.from_simulation` method.
- **Mitigation:** The method will be deprecated with a warning first, not immediately removed. A codebase-wide search for its usage will be performed. The focus of the change is on the `simulate_and_save.py` script, which is the primary known user.

**Risk:** The refactoring is more complex than anticipated and takes longer than planned.
- **Mitigation:** The phased implementation plan will break the work into manageable chunks. The core components (`group_coords`, `get_image_patches`, `illuminate_and_diffract`) are already implemented and tested, reducing the scope to orchestration logic.

**Risk:** Performance regression due to explicit format conversions.
- **Mitigation:** Performance benchmarks will be included in the test suite to ensure the refactored pipeline maintains acceptable performance levels.

---

## üìÅ **File Organization**

**Initiative Path:** `plans/active/simulation-workflow-unification/`

**Next Step:** Run `/implementation` to generate the phased implementation plan.

### Implementation Plan (`implementation.md`)
<!-- ACTIVE IMPLEMENTATION PLAN -->
<!-- DO NOT MISTAKE THIS FOR A TEMPLATE. THIS IS THE OFFICIAL SOURCE OF TRUTH FOR THE PROJECT'S PHASED PLAN. -->

# Phased Implementation Plan

**Project:** Simulation Workflow Unification
**Initiative Path:** `plans/active/simulation-workflow-unification/`

---
## Git Workflow Information
**Feature Branch:** feature/simulation-workflow-unification
**Baseline Branch:** feature/2x2study
**Baseline Commit Hash:** bd0dc5b66b4128d75284203f62e6134d74626192
**Last Phase Commit Hash:** bd0dc5b66b4128d75284203f62e6134d74626192
---

**Created:** 2025-08-02
**Core Technologies:** Python, NumPy, TensorFlow, ptychography simulation

---

## üìÑ **DOCUMENT HIERARCHY**

This document orchestrates the implementation of the objective defined in the main R&D plan. The full set of documents for this initiative is:

- **`plan.md`** - The high-level R&D Plan
  - **`implementation.md`** - This file - The Phased Implementation Plan
    - `phase_1_checklist.md` - Detailed checklist for Phase 1
    - `phase_2_checklist.md` - Detailed checklist for Phase 2
    - `phase_final_checklist.md` - Checklist for the Final Phase

---

## üéØ **PHASE-BASED IMPLEMENTATION**

**Overall Goal:** Fix the gridsize > 1 crash in simulate_and_save.py by refactoring it to use explicit, modular orchestration instead of the monolithic RawData.from_simulation method.

**Total Estimated Duration:** 3 days

---

## üìã **IMPLEMENTATION PHASES**

### **Phase 1: Core Refactoring - Replace Monolithic Function**

**Goal:** To refactor `scripts/simulation/simulate_and_save.py` to use explicit orchestration of modular functions instead of the monolithic `RawData.from_simulation` method.

**Deliverable:** A refactored `simulate_and_save.py` script that explicitly orchestrates coordinate grouping, patch extraction, and diffraction simulation, fixing the gridsize > 1 crash.

**Estimated Duration:** 1 day

**Key Tasks:**
- Analyze the current `simulate_and_save.py` implementation and identify all usages of `RawData.from_simulation`.
- Implement the new orchestration workflow:
  - Load inputs (`objectGuess`, `probeGuess`) from NPZ files
  - Use `ptycho.raw_data.group_coords()` for coordinate generation and grouping
  - Use `ptycho.raw_data.get_image_patches()` for patch extraction
  - Handle format conversions between Channel and Flat formats using `tf_helper` functions
  - Use `ptycho.diffsim.illuminate_and_diffract()` for simulation
  - Assemble and save results according to data contracts
- Ensure the refactored script maintains all existing command-line arguments and functionality.
- Add debug logging to trace the data flow and tensor shapes throughout the pipeline.

**Dependencies:** None (first phase)

**Implementation Checklist:** `phase_1_checklist.md`

**Success Test:** Running `python scripts/simulation/simulate_and_save.py --input-file datasets/fly/fly001_transposed.npz --output-file test_sim.npz --gridsize 2` completes without errors and produces a valid NPZ file.

---

### **Phase 2: Integration Testing & Validation**

**Goal:** To create a comprehensive test suite that validates the refactored simulation pipeline for both gridsize=1 and gridsize > 1 cases.

**Deliverable:** A new test file `tests/simulation/test_simulate_and_save.py` with comprehensive integration tests covering all validation scenarios from the R&D plan.

**Estimated Duration:** 1 day

**Key Tasks:**
- Create the test directory structure `tests/simulation/` if it doesn't exist.
- Implement integration tests for:
  - Gridsize=1 regression test (verify single-channel output shapes)
  - Gridsize=2 correctness test (verify multi-channel output shapes)
  - Probe override functionality test
  - Data contract compliance verification
  - Content sanity checks (non-zero values, correct data types)
- Add performance benchmarks to ensure no significant regression.
- Create visual validation scripts using `visualize_dataset.py` for manual inspection.
- Run the full test suite and ensure all tests pass.

**Dependencies:** Requires Phase 1 completion.

**Implementation Checklist:** `phase_2_checklist.md`

**Success Test:** Running `pytest tests/simulation/test_simulate_and_save.py -v` shows all tests passing with 100% success rate.

---

### **Final Phase: Deprecation, Documentation & Cleanup**

**Goal:** To add deprecation warnings to the legacy method, update all documentation, and ensure the solution is production-ready.

**Deliverable:** Complete documentation updates, deprecation warnings in place, and all success criteria from the R&D plan verified.

**Estimated Duration:** 1 day

**Key Tasks:**
- Add `DeprecationWarning` to `RawData.from_simulation` method with guidance to use the new approach.
- Search codebase for any other usages of `RawData.from_simulation` and document findings.
- Update `scripts/simulation/CLAUDE.md` with the new architecture and usage examples.
- Update `scripts/simulation/README.md` with clear documentation of the changes.
- Update the main `CLAUDE.md` if necessary to reflect the unified simulation workflow.
- Verify all success criteria from the R&D plan are met:
  - No crashes with gridsize > 1
  - Data contract compliance
  - Performance benchmarks acceptable
  - All tests passing
- Create a migration guide for any downstream users of the deprecated method.

**Dependencies:** All previous phases complete.

**Implementation Checklist:** `phase_final_checklist.md`

**Success Test:** All R&D plan success criteria are verified as complete, documentation is updated, and deprecation warnings are properly displayed when using the legacy method.

---

## üìä **PROGRESS TRACKING**

### Phase Status:
- [ ] **Phase 1:** Core Refactoring - Replace Monolithic Function - 0% complete
- [ ] **Phase 2:** Integration Testing & Validation - 0% complete
- [ ] **Final Phase:** Deprecation, Documentation & Cleanup - 0% complete

**Current Phase:** Phase 1: Core Refactoring - Replace Monolithic Function
**Overall Progress:** ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%

---

## üöÄ **GETTING STARTED**

1. **Generate Phase 1 Checklist:** Run `/phase-checklist 1` to create the detailed checklist.
2. **Begin Implementation:** Follow the checklist tasks in order.
3. **Track Progress:** Update task states in the checklist as you work.
4. **Request Review:** Run `/complete-phase` when all Phase 1 tasks are done to generate a review request.

---

## ‚ö†Ô∏è **RISK MITIGATION**

**Potential Blockers:**
- **Risk:** The modular functions (`group_coords`, `get_image_patches`) may have undocumented assumptions or bugs.
  - **Mitigation:** Add comprehensive debug logging and validate intermediate results against known-good data.
- **Risk:** Format conversions between Channel and Flat formats may introduce subtle bugs.
  - **Mitigation:** Create unit tests specifically for the format conversion functions and validate with known test cases.
- **Risk:** Performance regression due to explicit orchestration overhead.
  - **Mitigation:** Profile both old and new implementations early in Phase 1, optimize if necessary.

**Rollback Plan:**
- **Git:** Each phase will be a separate, reviewed commit on the feature branch, allowing for easy reverts.
- **Legacy Path:** The original `RawData.from_simulation` remains available (with deprecation warning) as a fallback.

### Phase Checklist (`phase_final_checklist.md`)
(See full content in the actual file - all tasks marked as [D] - Done)

---
## 2. Code Changes for This Phase

**Baseline Commit:** `bd0dc5b66b4128d75284203f62e6134d74626192`
**Current Branch:** `feature/simulation-workflow-unification`
**Changes since last phase:**
*Note: Jupyter notebook (.ipynb) files are excluded from this diff for clarity*

```diffdiff --git a/.claude/commands/generate-agent-checklist-v2.md b/.claude/commands/generate-agent-checklist-v2.md
new file mode 100644
index 0000000..993033f
--- /dev/null
+++ b/.claude/commands/generate-agent-checklist-v2.md
@@ -0,0 +1,441 @@
+# Command: /generate-agent-checklist-gemini
+
+**Goal:** Autonomously generate and execute a plan to ensure every project module has a high-quality, standardized docstring. This involves creating new docstrings where missing and improving existing ones.
+
+**Usage:**
+`/generate-agent-checklist-gemini "I want every .py module in the ptycho library to have a public-interface-focused docstring."`
+
+---
+
+## üî¥ **CRITICAL: MANDATORY EXECUTION FLOW**
+
+**YOUR ROLE IS AN AUTONOMOUS ORCHESTRATOR AND FILE MANAGER. YOU DO NOT PERFORM THE ANALYSIS.**
+1.  You MUST gather the user's high-level objective from the command arguments.
+2.  You MUST run `repomix` to create a complete, fresh snapshot of the codebase context.
+3.  You MUST build a structured prompt file (`tmp/doc-plan-prompt.md`) to delegate the analysis and planning to Gemini.
+4.  You MUST execute `gemini -p "@tmp/doc-plan-prompt.md"`.
+5.  You MUST parse Gemini's structured response to create the three critical state files: `modules_prioritized.txt`, `dependency_report.txt`, and `docstring_progress.md`.
+6.  You MUST then proceed to Phase 2 (Sub-Agent Orchestration) using these Gemini-generated files as the source of truth.
+
+**DO NOT:**
+-   ‚ùå Run `find`, `pydeps`, or any other manual analysis tool. Gemini is now responsible for all of Phase 1.
+-   ‚ùå Create the plan yourself. Your job is to run the process and manage the state.
+-   ‚ùå Proceed to Phase 2 if Gemini's analysis fails or returns an invalid format.
+
+---
+
+## ü§ñ **YOUR EXECUTION WORKFLOW**
+
+### **Phase 1: Gemini-Powered Strategic Analysis**
+
+In this phase, you'll execute commands to have Gemini analyze the codebase and generate a prioritized plan for adding docstrings.
+
+#### **Step 1.A: Aggregate Codebase Context**
+
+First, create a complete snapshot of the project for Gemini to analyze. This uses repomix to gather all relevant Python and markdown files while excluding unnecessary content like notebooks, review files, and archived plans.
+
+```bash
+# The user's high-level objective is in $ARGUMENTS
+npx repomix@latest . \
+  --include "ptycho/**/*.py,*.md,docs/**/*.md,.claude/**/*.md,plans/active/**/*.md" \
+  -i "**/*.ipynb,build/**,node_modules/**,dist/**,*.lock,**/review_request*.md,plans/archive/**,plans/examples/**,tensorflow/**,tmp/**"
+
+if [ ! -s ./repomix-output.xml ]; then
+    echo "‚ùå ERROR: Repomix failed to generate the codebase context. Aborting."
+    exit 1
+fi
+echo "‚úÖ Codebase context aggregated into repomix-output.xml."
+```
+
+#### **Step 1.B: Build Gemini Prompt File**
+
+Create a structured prompt file that delegates the analysis task to Gemini. This uses an append-only approach to avoid complex string substitutions.
+
+```bash
+# This script builds a highly-structured prompt file for Gemini to generate a
+# phased, strategic plan for adding module-level docstrings.
+
+# The prompt is constructed incrementally to safely handle user input and large
+# context files.
+
+# --- Step 1: Start building the prompt file with the core task and persona ---
+cat > ./tmp/doc-plan-prompt.md << 'EOF'
+<task>
+You are an expert Staff Engineer specializing in large-scale codebase analysis and technical documentation strategy. Your primary skills are in understanding system architecture, data flow, state management, and API contracts.
+
+Your task is to perform an architectural deep-dive of the provided codebase and generate a comprehensive, prioritized documentation strategy. Your final report must be structured as a phased, actionable work plan.
+
+<persona>
+- You think in terms of data contracts, not just function calls.
+- You are obsessed with identifying and documenting state dependencies (e.g., global configurations) because they are a primary source of bugs.
+- You prioritize clarity in the public API of each module.
+- You believe a documentation plan is only as good as the analysis that underpins it.
+</persona>
+
+<thinking_workflow>
+To produce the final report, you MUST follow this internal thought process:
+
+1.  **Full Analysis:** Systematically enumerate and analyze every target Python module (`.py` files in `ptycho/`, excluding `__init__.py`). For each module, gather the details required by the per-module template in the output format.
+2.  **Strategic Grouping:** After analyzing all modules, identify logical, thematic phases for the documentation effort (e.g., "Phase 1: Configuration & State", "Phase 2: Core Physics & Tensor Ops", "Phase 3: Data Pipeline", etc.). Assign each module to one of these strategic phases.
+3.  **Final Report Generation:** Construct the final output. First, write down your strategic grouping and rationale. Then, present the detailed module-by-module plan, organized under the phase headings you just defined.
+</thinking_workflow>
+
+<user_objective>
+EOF
+
+# --- Step 2: Append the user's high-level objective from the command arguments ---
+echo "$ARGUMENTS" >> ./tmp/doc-plan-prompt.md
+
+# --- Step 3: Append the closing tag for the objective and the detailed output format instructions ---
+# We use 'cat >>' to append the next large static block.
+cat >> ./tmp/doc-plan-prompt.md << 'EOF'
+</user_objective>
+
+<output_format>
+Your final output must be a single, comprehensive report starting with your strategic analysis, followed by the detailed, phased plan.
+
+<analysis_and_strategy>
+This section must contain your high-level strategic thinking.
+
+**Architectural Pillars:**
+[Briefly describe the 3-4 main architectural pillars you identified.]
+
+**Proposed Documentation Phases:**
+[List the strategic phases you've decided on and provide a 1-sentence rationale for each. For example:]
+- **Phase 1: Configuration & Foundational Utilities:** Document the core state management and widely used helpers first, as they are dependencies for everything else.
+- **Phase 2: Core Physics & Tensor Operations:** Focus on the stable, foundational modules that define the system's scientific and computational contracts.
+- **Phase 3: Data Ingestion Pipeline:** Document the flow of data from raw files to model-ready tensors.
+- **Phase 4: Model & Training Workflows:** Document the central model architecture and the high-level orchestrators.
+</analysis_and_strategy>
+
+<prioritized_documentation_plan>
+This section must contain the detailed module-by-module plan, grouped under the phase headings you defined above. Each module entry must strictly adhere to the following Markdown format.
+
+---
+## Phase 1: Configuration & Foundational Utilities
+
+- **File:** `[path/to/module.py]`
+  - **Priority:** `[CRITICAL | HIGH | MEDIUM | LOW]`
+  - **Role & Architectural Significance:** A concise summary of this module's purpose and its importance in the system's architecture.
+  - **Key Public API(s):** List the most important public functions or classes.
+  - **Data Flow Contract (Inputs/Outputs):**
+    - **Input:** Describe the primary data consumed, including source, type, and shape.
+    - **Output:** Describe the primary data produced, including destination, type, and shape.
+  - **State Dependencies:** Explicitly identify any dependencies on external or global state. If none, state "None."
+  - **Dependencies (Internal):** List key internal `ptycho` modules this module imports.
+  - **Consumers (Internal):** List key internal `ptycho` modules that import this one.
+  - **Docstring Action Plan:** `[NO_CHANGE | IMPROVE | REWRITE | CREATE]` - Provide a concrete, actionable recommendation. (e.g., "CREATE: The module is undocumented.", "IMPROVE: Add a workflow example showing interaction with `loader.py`.", "REWRITE: The current docstring is outdated and incorrectly describes the algorithm. Must update to reflect the 'sample-then-group' logic.").
+
+## Phase 2: Core Physics & Tensor Operations
+... (and so on for each phase and module)
+</prioritized_documentation_plan>
+</output_format>
+
+<gold_standard_example>
+Here is an example of the expected quality and detail for a single module entry under a phase heading. Your analysis for every module must match this level of depth.
+
+## Phase 3: Data Ingestion Pipeline
+
+- **File:** `ptycho/raw_data.py`
+  - **Priority:** `HIGH`
+  - **Role & Architectural Significance:** The primary data ingestion layer. Its key architectural role is to abstract away raw file formats and enforce physical coherence of scan positions *before* they enter the main ML pipeline, which is crucial for the validity of `gridsize > 1` training.
+  - **Key Public API(s):** `RawData` class, `RawData.generate_grouped_data()`.
+  - **Data Flow Contract (Inputs/Outputs):**
+    - **Input:** Raw `.npz` files containing NumPy arrays. Key arrays include `'diffraction'` with shape `(num_scans, N, N)` and `'xcoords'`/`'ycoords'` with shape `(num_scans,)`.
+    - **Output:** A dictionary of grouped NumPy arrays consumed by `ptycho.loader`. The output shape is critically dependent on `params.get('gridsize')`:
+      - **If `gridsize > 1`**: Arrays are in "Channel Format", e.g., the `X` (diffraction) array has shape `(nsamples, N, N, gridsize**2)`.
+      - **If `gridsize == 1`**: Arrays represent individual patches, e.g., the `X` (diffraction) array has shape `(nsamples, N, N, 1)`.
+  - **State Dependencies:** Critically dependent on the global `ptycho.params.get('gridsize')` which algorithmically changes its grouping strategy from sequential slicing to a robust "sample-then-group" method.
+  - **Dependencies (Internal):** `ptycho.params`, `ptycho.config.config`, `ptycho.tf_helper`.
+  - **Consumers (Internal):** `ptycho.loader`, `ptycho.workflows.components`.
+  - **Docstring Action Plan:** `REWRITE` - The current docstring is outdated. It incorrectly describes the algorithm as "group-then-sample" and must be updated to reflect the current, performance-optimized "sample-then-group" logic. The critical state dependency on `gridsize` and the conditional output shapes must also be explicitly documented.
+</gold_standard_example>
+EOF
+
+# --- Step 4: Add the opening tag for the codebase context ---
+echo "<codebase_context>" >> ./tmp/doc-plan-prompt.md
+
+# --- Step 5: Append the full codebase context from the repomix output file ---
+cat ./repomix-output.xml >> ./tmp/doc-plan-prompt.md
+
+# --- Step 6: Append the closing tags to finalize the prompt file ---
+echo "</codebase_context>" >> ./tmp/doc-plan-prompt.md
+echo "</task>" >> ./tmp/doc-plan-prompt.md
+
+echo "‚úÖ Successfully built structured prompt file: ./tmp/doc-plan-prompt.md"
+```
+
+#### **Step 1.C: Execute Gemini Analysis**
+
+Run Gemini with the prompt file to generate the prioritized module list and dependency report.
+
+```bash
+# Execute Gemini with the fully-formed prompt file and capture response
+GEMINI_RESPONSE=$(gemini -p "@./tmp/doc-plan-prompt.md") || {
+    echo "‚ùå ERROR: Gemini command failed"
+    exit 1
+}
+
+# Save the raw response for debugging if needed
+echo "$GEMINI_RESPONSE" > ./gemini_response_raw.txt
+```
+
+#### **Step 1.D: Create State Files from Gemini's Output**
+
+Parse Gemini's structured response to create the three state files that will guide Phase 2.
+
+```bash
+# Parse the Gemini response that was captured in the previous step
+
+# Create modules_prioritized.txt
+awk '/---PRIORITIZED_MODULES_START---/,/---PRIORITIZED_MODULES_END---/' ./gemini_response_raw.txt | sed '1d;$d' > modules_prioritized.txt
+
+# Create dependency_report.txt
+awk '/---DEPENDENCY_REPORT_START---/,/---DEPENDENCY_REPORT_END---/' ./gemini_response_raw.txt | sed '1d;$d' > dependency_report.txt
+
+# Verify that the files were created
+if [ ! -s modules_prioritized.txt ]; then
+    echo "‚ùå ERROR: Gemini failed to return a prioritized module list. Aborting."
+    exit 1
+fi
+
+# Create the progress tracker from the prioritized list
+( echo "# Docstring Progress Tracker"; echo ""; cat modules_prioritized.txt | while read -r line; do echo "- [ ] \`$line\`"; done ) > docstring_progress.md
+
+echo "‚úÖ Gemini analysis complete. State files created:"
+echo "  - modules_prioritized.txt"
+echo "  - dependency_report.txt"
+echo "  - docstring_progress.md"
+```
+
+---
+
+### **Phase 2: Sub-Agent Orchestration**
+
+*(You will now begin the execution loop, delegating tasks to sub-agents with the updated, smarter instructions.)*
+
+| ID | Task Description | State | How/Why & API Guidance |
+| :-- | :--- | :--- | :--- |
+| 2.A | **Orchestrate Documentation of Each Module** | `[ ]` | **Why:** To process each module independently by delegating to specialized sub-agents. <br> **How:** Begin a loop. For each file path in `modules_prioritized.txt`: <br> 1. **Invoke a new, single-purpose "Authoring Sub-Agent."** <br> 2. Provide it with the FULL instructions from the **"Sub-Agent Instructions: Docstring Authoring (v6)"** section, including Gemini's recommentation / analysis relevant to that module. <br> 3. Pass the specific module's file path and the `dependency_report.txt` file as context. <br> 4. After the sub-agent successfully completes, mark the corresponding item as done in `docstring_progress.md` and proceed to the next module in the loop. |
+
+---
+
+### **Phase 3: Final Verification & Commit**
+
+*(You will execute these final steps after the loop in Phase 2 is complete.)*
+
+| ID | Task Description | State | How/Why & API Guidance |
+| :-- | :--- | :--- | :--- |
+| 3.A | **Verify All Modules are Documented** | `[ ]` | **Why:** To ensure no modules were missed by the sub-agents. <br> **How:** Run a script that reads `modules_prioritized.txt` and checks that each file now starts with a `"""` docstring. |
+| 3.B | **Invoke Verification Sub-Agent** | `[ ]` | **Why:** To ensure docstrings are consistent and architecturally sound. <br> **How:** Invoke a final "Verification Sub-Agent" with the instructions from the **"Sub-Agent Instructions: Final Verification"** section. |
+| 3.C | **Run Automated Style Linting** | `[ ]` | **Why:** To enforce a consistent documentation style. <br> **How:** Install and run `pydocstyle`. <br> ```bash <br> pip install pydocstyle && pydocstyle ptycho/ <br> ``` |
+| 3.D | **Final Code Commit** | `[ ]` | **Why:** To save the completed documentation work. <br> **How:** Stage all the modified Python files and commit them with a detailed message reflecting the new capability. <br> ```bash <br> git add ptycho/**/*.py <br> git commit -m "docs: Add or improve module-level docstrings via AI agent" -m "Ensures all core library modules have a high-quality, standardized docstring. Creates new docstrings where missing and refactors existing ones to meet project standards." <br> ``` |
+
+---
+
+### **Sub-Agent Instructions: Docstring Authoring (v6)**
+
+*(Orchestrator: You will provide these new, smarter instructions to each sub-agent you invoke in Phase 2.A.)*
+
+**Your Goal:** Ensure the specified Python module has a single, high-quality, developer-focused module-level docstring that adheres to the project's standards. This involves either **creating a new docstring** if one is missing, or **reviewing and improving an existing one**.
+
+**Your Context:**
+*   **Target Module:** `<path/to/module.py>` (Its full content is available in the `repomix` context)
+*   **Dependency Report:** `ptycho/dependency_report.txt`
+*   **Additional Context:** [Gemini's analysis and recommendations for this module]
+
+**Your Workflow:**
+
+**1. Assessment & Triage:**
+   - **Action:** Examine the source code of the Target Module.
+   - **Check:** Does a module-level docstring (one that starts the file, using `"""` or `'''`) already exist?
+
+**2.a. If Docstring is Missing (Creation Workflow):**
+   - **Analysis:** Perform dependency analysis to define the module's public API and its consumers.
+   - **Drafting:** Write a new docstring from scratch, strictly adhering to the **"Hardened Docstring Template"**.
+   - **Verification:** Run a script to ensure your new docstring is under the 15% size limit. Refactor for conciseness if needed.
+   - **Finalization:** Insert the new docstring at the top of the target file.
+
+**2.b. If Docstring Exists (Review & Refactor Workflow):**
+   - **Analysis:** Critically evaluate the existing docstring against the principles, the **"Hardened Docstring Template"**, and the **"Docstring Anti-Patterns"**.
+   - **Identify Gaps:** Determine what is missing or incorrect. Does it lack a usage example? Is the architectural role unclear? Does it fail to mention data contracts?
+   - **Refactor:** Create a new, improved version of the docstring.
+     - You **MUST** preserve any valuable, accurate information from the original.
+     - You **MUST** fix all identified gaps and anti-patterns.
+     - You **MUST** improve the docstring, unless you believe it is already perfect.
+     - You should ensure the docstring is no longer than 15% of the original file size, but occasionally exceeding this limit is acceptable
+     - The final output **MUST** be 100% compliant with the "Hardened Docstring Template," regardless of the original's structure.
+   - **Verification & Replacement:** Ensure the refactored docstring meets the 15% size limit, then replace the old docstring in the file with your new, improved version.
+
+---
+
+### **Hardened Docstring Template (for Authoring Sub-Agent)**
+
+*Your docstring must follow the structure and quality of the examples below. Choose the example that best fits the nature of the module you are documenting.*
+
+---
+#### **Example 1: For Modules with Complex Logic & Hidden State (e.g., `raw_data.py`)**
+
+```python
+"""
+Ptychography data ingestion and scan-point grouping.
+
+This module serves as the primary ingestion layer for the PtychoPINN data pipeline.
+It is responsible for taking raw ptychographic data and wrapping it in a `RawData` object.
+Its most critical function, `generate_grouped_data()`, assembles individual scan
+points into physically coherent groups for training.
+
+Architecture Role:
+    Raw NPZ file -> raw_data.py (RawData) -> Grouped Data Dict -> loader.py
+"""
+
+"""
+Public Interface:
+    `RawData.generate_grouped_data(N, K=4, nsamples=1, ...)`
+        - Purpose: The core function for sampling and grouping scan points.
+        - Critical Behavior (Conditional on `params.get('gridsize')`):
+            - **If `gridsize == 1`:** Performs simple sequential slicing.
+            - **If `gridsize > 1`:** Implements a robust "group-then-sample"
+              strategy to avoid spatial bias.
+        - Key Parameters:
+            - `nsamples` (int): For `gridsize=1`, this is the number of images.
+              For `gridsize>1`, this is the number of *groups*.
+"""
+
+"""
+Workflow Usage Example:
+    ```python
+    from ptycho.raw_data import RawData
+    from ptycho import params
+
+    # 1. Instantiate RawData from a raw NPZ file's contents.
+    raw_data = RawData(xcoords=data['xcoords'], ...)
+
+    # 2. Set the external state that controls the module's behavior.
+    params.set('gridsize', 2)
+
+    # 3. Generate the grouped data dictionary.
+    grouped_data_dict = raw_data.generate_grouped_data(N=64, nsamples=1000)
+    ```
+"""
+
+"""
+Architectural Notes & Dependencies:
+- This module has a critical implicit dependency on the global `params.get('gridsize')`
+  value, which completely changes its sampling algorithm.
+- It automatically creates a cache file (`*.groups_cache.npz`) to accelerate
+  subsequent runs.
+"""
+```
+
+---
+#### **Example 2: For Modules Defined by Data/Tensor Transformations (e.g., `tf_helper.py`)**
+
+```python
+"""
+Low-level TensorFlow operations for ptychographic data manipulation.
+
+This module provides a suite of high-performance, tensor-based functions for
+the core computational tasks in the PtychoPINN pipeline, primarily patch
+extraction, reassembly, and tensor format conversions. It is a foundational
+library used by the data pipeline, model, and evaluation modules.
+"""
+
+"""
+Key Tensor Formats:
+This module defines and converts between three standard data layouts for batches
+of ptychographic patches:
+
+- **Grid Format:** `(B, G, G, N, N, 1)`
+  - Represents patches organized in their spatial grid structure.
+- **Channel Format:** `(B, N, N, G*G)`
+  - Stacks patches in the channel dimension. Required for CNN input.
+- **Flat Format:** `(B*G*G, N, N, 1)`
+  - Each patch is an independent item in the batch.
+"""
+
+"""
+Public Interface:
+    `reassemble_position(obj_tensor, global_offsets, M=10)`
+        - **Purpose:** The primary function for stitching patches back into a full
+          object image based on their precise, non-uniform scan coordinates.
+        - **Algorithm:** Uses a batched shift-and-sum operation with automatic
+          memory management for large datasets.
+        - **Parameters:**
+            - `obj_tensor` (Tensor): Complex patches in `Flat Format`.
+            - `global_offsets` (Tensor): The `(y, x)` scan coordinates for each patch.
+            - `M` (int): The size of the central region of each patch to use for
+              the reassembly, which helps avoid edge artifacts.
+"""
+
+"""
+Usage Example:
+    This example shows the canonical `Grid -> Channel -> Flat -> Reassembly`
+    workflow that this module enables.
+
+    ```python
+    import ptycho.tf_helper as hh
+    import tensorflow as tf
+
+    # 1. Start with data in Grid Format. Shape: (10, 2, 2, 64, 64, 1)
+    patch_grid = tf.random.normal((10, 2, 2, 64, 64, 1))
+    
+    # 2. Convert to Channel Format for a CNN. Shape: (10, 64, 64, 4)
+    patch_channels = hh.grid_to_channel(patch_grid)
+    
+    # ... (model processing) ...
+
+    # 3. Convert to Flat Format for reassembly. Shape: (40, 64, 64, 1)
+    patches_flat = hh.channel_to_flat(patch_channels)
+
+    # 4. Reassemble the flat patches into a final image.
+    scan_coords = tf.random.uniform((40, 1, 1, 2), maxval=100)
+    reconstructed_image = hh.reassemble_position(patches_flat, scan_coords, M=20)
+    ```
+"""
+```
+
+---
+
+### **Docstring Anti-Patterns (To Be Avoided by Sub-Agents)**
+
+Your generated docstrings will be rejected if they contain the following:
+
+*   **Vague Summaries:** Avoid generic phrases like "This module contains helper functions" or "Utilities for data processing." Be specific about its role.
+*   **Marketing Language:** Do not use subjective fluff like "critical," "essential," "high-performance," or specific speedup numbers. Instead, explain *how* it is performant (e.g., "Uses a batched algorithm to manage memory").
+*   **Implementation Details:** Do not explain the line-by-line logic of the code. Focus on the public contract: what goes in, what comes out, and what it's for.
+*   **Isolated Examples:** Do not provide usage examples that are just a single function call with placeholder variables. The example must show a realistic interaction between modules.
+*   **Inaccurate Consumer Lists:** Do not guess which modules use this one. The dependency report is the source of truth.
+
+---
+
+### **Sub-Agent Instructions: Final Verification**
+
+*(Orchestrator: You will provide these instructions to the sub-agent you invoke in Phase 3.B.)*
+
+**Your Goal:** To perform a final consistency and architectural accuracy check on all newly created or updated docstrings.
+
+**Your Context:**
+*   The list of all documented modules: `modules_prioritized.txt`
+*   The full dependency map: `dependency_report.txt`
+*   The PtychoPINN architecture understanding from `docs/DEVELOPER_GUIDE.md` and `docs/architecture.md`
+
+**Your Workflow:**
+1.  **Read All Docstrings:** Load the module-level docstring from every file listed in `modules_prioritized.txt`.
+2.  **Cross-Reference Architecture Claims:** For each docstring:
+    *   Verify "primary consumers" claims against actual dependency data in `ptycho/dependency_report.txt`.
+    *   Check that architectural role descriptions align with the actual system design.
+    *   Validate that workflow examples show realistic integration patterns.
+3.  **Identify Inconsistencies:**
+    *   Module claims to be used by X, but dependency report shows no such link.
+    *   Usage examples show patterns not actually used in the codebase.
+    *   Circular or contradictory architectural role descriptions.
+    *   Incorrect data flow or integration claims.
+4.  **Generate Report:** Create `docstring_consistency_report.md` with:
+    *   **Pass/Fail Summary:** Overall assessment.
+    *   **Inconsistencies Found:** Specific issues requiring fixes.
+    *   **Architecture Accuracy:** Assessment of architectural claims.
+    *   **Recommendations:** Suggested improvements for consistency.
+5.  **Report Findings:** Return the path to the generated report. The Orchestrator will decide if fixes are needed before proceeding.
+
+
diff --git a/build/lib/build/lib/build/lib/build/lib/diagram/pinn.py b/build/lib/build/lib/build/lib/build/lib/diagram/pinn.py
deleted file mode 100644
index 2e5d21a..0000000
--- a/build/lib/build/lib/build/lib/build/lib/diagram/pinn.py
+++ /dev/null
@@ -1,293 +0,0 @@
-
-import numpy as np
-import sys
-sys.path.append('../')
-from pycore.tikzeng import *
-
-offset = -1.5
-scale = .3
-decoder_offset = 0
-def ppos(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    nums = np.array([float(n) for n in nums])
-    nums[0] += decoder_offset
-    new = str(tuple(n * scale for n in nums))
-    print(new)
-    return new
-
-def ppos_encoder(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    new = str(tuple(float(n) * scale for n in nums))
-    print(new)
-    return new
-
-## vim macro
-"""/\dcw{}jk?codek$a"jkpa", jk/\a\d"""
-patch_size = 26
-# size of the probe-illuminated patches
-probe_scale = 1.2
-zoff = -10 #* scale
-xext = 31
-xpatch = 31.2
-patch_width = .5
-diff_width = .5
-diff_spacing = 7 * probe_scale
-xdiff = 37
-xdiff2 = 44
-probe_size = 32
-
-diff2_spacing = .2
-diff2_dx = 2
-diff2_dy = .5
-diff2_dz = 0.5
-diff2_width = 3
-amp_suffix = '_1'
-phase_suffix = '_2'
-
-legend_offset_y = -20
-legend_boxsize = 8
-legend_width = 0
-legend_spacing_x = 6 / (2 * scale)
-legend_offset_x = -7
-legend_spacing_y = -4 / (2 * scale)
-legend_patch_width = .1
-offset2 = offset * (legend_boxsize / 32)
-
-img_path_fmt = '../../notebooks/images/{}'
-
-input1 = img_path_fmt.format('in1.png')
-input2 = img_path_fmt.format('in2.png')
-input3 = img_path_fmt.format('in3.png')
-input4 = img_path_fmt.format('in4.png')
-
-output1 = img_path_fmt.format('out1.png')
-output2 = img_path_fmt.format('out2.png')
-output3 = img_path_fmt.format('out3.png')
-output4 = img_path_fmt.format('out4.png')
-
-patch1_path = img_path_fmt.format('patch1.png')
-patch2_path = img_path_fmt.format('patch2.png')
-patch3_path = img_path_fmt.format('patch3.png')
-patch4_path = img_path_fmt.format('patch4.png')
-
-phase_path = img_path_fmt.format('phase.png')
-amp_path = img_path_fmt.format('amp.png')
-full_obj_path = img_path_fmt.format('full_obj.png')
-
-im_size = 13 * scale
-inp_x = -7
-outp_x = 50
-
-encoder = [
-    to_input(input1, to=ppos("({},{},{})".format(inp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(input2, to=ppos("({},{},{})".format(inp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(input3, to=ppos("({},{},{})".format(inp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(input4, to=ppos("({},{},{})".format(inp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-    to_ConvRelu("conv11", '', 64, offset=ppos_encoder("(0,0,0)"), to=ppos_encoder("(0,0,0)"),
-        height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_ConvRelu("conv12", '', '', offset=ppos_encoder("(.4,0,0)"), to=ppos_encoder("(0,0,0)"), height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_Pool("pool1", offset=ppos_encoder("(0,0,0)"), to="(conv12-east)", height=32* scale, depth=32* scale),
-
-    to_ConvRelu("conv21", '', '', offset=ppos_encoder("(5,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_ConvRelu("conv22", '', 128, offset=ppos_encoder("(5.8,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_Pool("pool2", offset=ppos_encoder("(0,0,0)"), to="(conv22-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool1", "conv21"),
-
-    to_ConvRelu("conv31", '', 256, offset=ppos_encoder("(10,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_ConvRelu("conv32", '', '', offset=ppos_encoder("(11.6,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_Pool("pool3", offset=ppos_encoder("(0,0,0)"), to="(conv32-east)", height=8* scale, depth=8* scale),
-    to_connection( "pool2", "conv31"),
-]
-
-def last_decoder(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_Sigmoid("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = 'A(r)')
-    elif pos_sign == -1:
-        return to_Tanh("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = r'$\bm{\phi(r)}$')
-    else:
-        raise ValueError
-
-def last_decoder_img(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_input(amp_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    elif pos_sign == -1:
-        return to_input(phase_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    else:
-        raise ValueError
-
-def mk_decoder(name_suffix = '0', pos_sign = 1):
-    return [
-    to_ConvRelu("up11" + name_suffix, '', 256, offset=ppos("(12,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_ConvRelu("up12" + name_suffix, '', '', offset=ppos("(13.6,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_UnPool("unpool1" + name_suffix, offset=ppos("(0,0,0)"), to="(up12" + name_suffix + "-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool3", "up11" + name_suffix),
-
-    to_ConvRelu("up21" + name_suffix, '', 128, offset=ppos("(18,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_ConvRelu("up22" + name_suffix, '', '', offset=ppos("(18.8,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_UnPool("unpool2" + name_suffix, offset=ppos("(0,0,0)"), to="(up22" + name_suffix + "-east)", height=32* scale, depth=32* scale),
-    to_connection( "unpool1" + name_suffix, "up21" + name_suffix),
-
-#    to_Conv("up31" + name_suffix, '', 1, offset=ppos("(23,0,0)"),
-#        to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-#        depth=32* scale, width=2 * scale),
-    last_decoder(pos_sign, name_suffix),
-    last_decoder_img(pos_sign, name_suffix),
-    to_connection( "unpool2" + name_suffix, last + name_suffix)
-    #to_connection( "unpool2" + name_suffix, "up31" + name_suffix)
-    ]
-#last = "up31"
-last = "last"
-
-forward_map =\
-[
-    to_Sum("sum1", offset=ppos("(27.5,0,0)"), to=ppos("(0, 0, 0)"), radius=2.5 * scale, opacity=0.6),
-    to_connection(last+ amp_suffix, "sum1"),
-    to_connection(last+ phase_suffix, "sum1"),
-    to_Extract("extract1", '', 4, offset=ppos("({},0,0)".format(xext)),
-        to=ppos("(0,0,0)"), height=64* scale / 2, depth=64* scale / 2, width=2* scale,
-        caption = ''),
-    to_input(full_obj_path, to = ppos("({},0,0)".format(xext)), width = im_size,
-        height = im_size),
-    to_connection("sum1", "extract1"),
-    to_Patch("patch1", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch4", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch2", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch3", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale)] +\
-    to_Illumination("probe2", patch2_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * 1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch2", "probe2")] +\
-    to_Illumination("probe3", patch3_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * .5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch3", "probe3")] +\
-    to_Illumination("probe1", patch1_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch1", "probe1")] +\
-    to_Illumination("probe4", patch4_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2,
-        caption = r'$\bm{\times}$ Probe${(\bm{r - r_i})}$') +\
-    [to_connection( "patch4", "probe4")] +\
-    [
-#        to_Diffraction("diff1", '', 4, offset=ppos("({},0,0)".format(xdiff2)),
-#        to=ppos("({},{},{})".format(diff2_dx * 1.5, diff2_dy * 1.5, diff2_dz * 1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-#    to_Diffraction("diff2", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing)),
-#        to=ppos("({},{},{})".format(diff2_dx * .5, diff2_dy * .5, diff2_dz * .5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_Diffraction("diff3", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 2)),
-        to=ppos("({},{},{})".format(diff2_dx * -.5, diff2_dy * -.5, diff2_dz * -.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-        caption = ''),
-#    to_Diffraction("diff4", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 3)),
-#        to=ppos("({},{},{})".format(diff2_dx * -1.5, diff2_dy * -1.5, diff2_dz * -1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_connection("probe2", "diff3"),#top
-    to_connection("probe1", "diff3"),
-    to_connection("probe3", "diff3"),
-    to_connection("probe4", "diff3"),# bottom
-#    to_connection("probe2", "diff1"),#top
-#    to_connection("probe1", "diff3"),
-#    to_connection("probe3", "diff2"),
-#    to_connection("probe4", "diff4"),# bottom
-
-    to_input(output1, to=ppos("({},{},{})".format(outp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(output2, to=ppos("({},{},{})".format(outp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(output3, to=ppos("({},{},{})".format(outp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(output4, to=ppos("({},{},{})".format(outp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-
-    to_ConvRelu("conv_relu_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~ReLU($\cdot$)""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~ReLU($\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Pool("pool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""AvgPool2D($\cdot$)"""),
-
-    to_UnPool("unpool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-        legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Upsample($\cdot$)"""),
-
-    to_Tanh("tanh_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 0,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~$i \bm{\pi \tanh(\cdot)}$""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~$i \pi \tanh(\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Sigmoid("sigmoid_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 1,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~Sigmoid$(\cdot)$""",
-        s_filer = '', n_filer = ''),
-
-    to_Patch("patch1_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch4_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch2_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch3_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale,
-        caption = r"""Crop$(\cdot)$\linebreak Shift$(\cdot)$""",),
-        #caption = r"""Illuminate$(\cdot)$""",),
-
-    to_Diffraction("diff_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 3,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Diffract$(\bm{\cdot})$ \linebreak $\sim $Poisson$(\bm{\cdot}^2)$""",
-        s_filer = '', n_filer = ''),
-
-]
-
-arch = [to_head( '..' ),
-    to_cor(),
-    to_begin()] +\
-    encoder + mk_decoder(amp_suffix, pos_sign = 1) +\
-    mk_decoder(phase_suffix, pos_sign = -1) + forward_map +\
-    [to_end()]
-
-def main():
-    namefile = str(sys.argv[0]).split('.')[0]
-    to_generate(arch, namefile + '.tex' )
-
-if __name__ == '__main__':
-    main()
diff --git a/build/lib/build/lib/build/lib/build/lib/diagram/tikzeng.py b/build/lib/build/lib/build/lib/build/lib/diagram/tikzeng.py
deleted file mode 100644
index 4de56da..0000000
--- a/build/lib/build/lib/build/lib/build/lib/diagram/tikzeng.py
+++ /dev/null
@@ -1,374 +0,0 @@
-
-import os
-
-def to_head( projectpath ):
-    pathlayers = os.path.join( projectpath, 'layers/' ).replace('\\', '/')
-    return r"""
-\documentclass[border=8pt, multi, tikz]{standalone}
-\usepackage{import}
-\usepackage{bm}
-\usepackage{transparent}
-\subimport{"""+ pathlayers + r"""}{init}
-\usetikzlibrary{positioning}
-\usetikzlibrary{3d} %for including external image
-"""
-
-def to_cor():
-    return r"""
-\def\ConvColor{rgb:yellow,5;red,2.5;white,5}
-\def\ConvReluColor{rgb:yellow,5;red,5;white,5}
-\def\PoolColor{rgb:red,1;black,0.3}
-\def\UnpoolColor{rgb:blue,2;green,1;black,0.3}
-\def\FcColor{rgb:blue,5;red,2.5;white,5}
-\def\FcReluColor{rgb:blue,5;red,5;white,4}
-\def\SoftmaxColor{rgb:magenta,5;black,7}
-\def\SumColor{rgb:blue,5;green,15}
-\def\DcnvColor{rgb:blue,5;green,2.5;white,5}
-"""
-
-def to_begin():
-    return r"""
-\newcommand{\copymidarrow}{\tikz \draw[-Stealth,line width=0.8mm,draw={rgb:blue,4;red,1;green,1;black,3}] (-0.3,0) -- ++(0.3,0);}
-
-\begin{document}
-\begin{tikzpicture}
-\tikzstyle{connection}=[ultra thick,every node/.style={sloped,allow upside down},draw=\edgecolor,opacity=0.7]
-\tikzstyle{copyconnection}=[ultra thick,every node/.style={sloped,allow upside down},draw={rgb:blue,4;red,1;green,1;black,3},opacity=0.7]
-"""
-
-# layers definition
-
-def to_input( pathfile, to='(-3,0,0)', width=8, height=8, name="temp" ):
-    return r"""
-\node[canvas is zy plane at x=0] (""" + name + """) at """+ to +""" {\includegraphics[width="""+ str(width)+"cm"+""",height="""+ str(height)+"cm"+"""]{"""+ pathfile +"""}};
-"""
-
-# Conv
-def to_Conv( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_ConvRelu( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# Conv,Conv,relu
-# Bottleneck
-def to_ConvConvRelu( name, s_filer=256, n_filer=(64,64), offset="(0,0,0)", to="(0,0,0)", width=(2,2), height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name +""",
-        caption="""+ caption +""",
-        xlabel={{ """+ str(n_filer[0]) +""", """+ str(n_filer[1]) +""" }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        bandfill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width={ """+ str(width[0]) +""" , """+ str(width[1]) +""" },
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# Pool
-def to_Pool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+name+""",
-        caption="""+ caption +r""",
-        fill=\PoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# unpool4,
-def to_UnPool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+ name +r""",
-        caption="""+ caption +r""",
-        fill=\UnpoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_ConvRes( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Pad( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sigmoid( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:violet,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Tanh( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Patch( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.1, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        bandopacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-# bandfill={rgb:blue,1;red,2},
-
-def to_Extract( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)",
-        width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;green,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_Illumination( name, filepath, s_filer=256, n_filer=64,
-    offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-    opacity=0.2, caption=" " , im_size = 4):
-    return [r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;blue,3},
-        bandfill={rgb:black,1;blue,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-""",
-    to_input(filepath, to = to, width = im_size, height = im_size)]
-
-def to_Diffraction( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.4, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:violet,1;red,3},
-        bandfill={rgb:white,1;red,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# ConvSoftMax
-def to_ConvSoftMax( name, s_filer=40, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# SoftMax
-def to_SoftMax( name, s_filer=10, offset="(0,0,0)", to="(0,0,0)", width=1.5, height=3, depth=25, opacity=0.8, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        xlabel={{" ","dummy"}},
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sum( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=""" + r'$\times$' + """
-        }
-    };
-"""
-
-def to_Prod( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=$x$
-        }
-    };
-"""
-
-# \times?
-
-def to_connection( of, to):
-    return r"""
-\draw [connection]  ("""+of+"""-east)    -- node {\midarrow} ("""+to+"""-west);
-"""
-
-def to_skip( of, to, pos=1.25):
-    return r"""
-\path ("""+ of +"""-southeast) -- ("""+ of +"""-northeast) coordinate[pos="""+ str(pos) +"""] ("""+ of +"""-top) ;
-\path ("""+ to +"""-south)  -- ("""+ to +"""-north)  coordinate[pos="""+ str(pos) +"""] ("""+ to +"""-top) ;
-\draw [copyconnection]  ("""+of+"""-northeast)
--- node {\copymidarrow}("""+of+"""-top)
--- node {\copymidarrow}("""+to+"""-top)
--- node {\copymidarrow} ("""+to+"""-north);
-"""
-
-def to_end():
-    return r"""
-\end{tikzpicture}
-\end{document}
-"""
-
-def to_generate( arch, pathname="file.tex" ):
-    with open(pathname, "w") as f:
-        for c in arch:
-            print(c)
-            f.write( c )
-
diff --git a/build/lib/build/lib/build/lib/build/lib/loaders/__init__.py b/build/lib/build/lib/build/lib/build/lib/loaders/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/loaders/als.py b/build/lib/build/lib/build/lib/build/lib/loaders/als.py
deleted file mode 100644
index d1b9b0a..0000000
--- a/build/lib/build/lib/build/lib/build/lib/loaders/als.py
+++ /dev/null
@@ -1,47 +0,0 @@
-import numpy as np
-from ptycho.raw_data import RawData
-
-import pkg_resources
-
-def load_single_object(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects. We ASSUME we're processing
-    a single object. The first train_size samples will be used for training and the entire dataset 
-    will be used for evaluation.
-
-    Args:
-        file_path: Path to the data file.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = data['diffraction']
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                          diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                xcoords_start[:train_size], ycoords_start[:train_size],
-                                diff3d[:train_size], probeGuess,
-                                scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
-
diff --git a/build/lib/build/lib/build/lib/build/lib/loaders/xpp.py b/build/lib/build/lib/build/lib/build/lib/loaders/xpp.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/notebooks/dose.py b/build/lib/build/lib/build/lib/build/lib/notebooks/dose.py
deleted file mode 100644
index f98380e..0000000
--- a/build/lib/build/lib/build/lib/build/lib/notebooks/dose.py
+++ /dev/null
@@ -1,235 +0,0 @@
-import argparse
-
-def init(nphotons, loss_fn='nll'):
-    from ptycho.params import cfg
-    cfg['positions.provided'] = False
-    cfg['data_source'] = 'lines'
-    cfg['set_phi'] = False
-    cfg['nepochs'] = 60 
-
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 3
-    cfg['output_prefix'] = 'lines3'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-    cfg['probe.trainable'] = False
-
-    cfg['outer_offset_train'] = 8
-    cfg['outer_offset_test'] = 20
-    cfg['nimgs_train'] = 2
-    cfg['nimgs_test'] = 2
-
-    cfg['nphotons'] = nphotons
-
-    if loss_fn == 'mae':
-        cfg['mae_weight'] = 1.
-        cfg['nll_weight'] = 0.
-    elif loss_fn == 'nll':
-        pass  # Keep the current behavior
-    else:
-        raise ValueError(f"Invalid loss_fn: {loss_fn}. Must be 'mae' or 'nll'.")
-
-def plot_results(stitched_obj, YY_ground_truth, d):
-    import matplotlib.pyplot as plt
-    import numpy as np
-
-    fig, axs = plt.subplots(1, 1, figsize=(5, 5))
-
-    # reconstructed amplitude images
-    img1 = axs.imshow(np.absolute(stitched_obj)[0], cmap='jet', interpolation='none')
-    axs.set_title(f'Reconstructed amplitude - FRC50: {d["frc50"][0]:.2f}')
-
-    fig.colorbar(img1, ax=axs)
-
-def execute(nphotons, reload_modules=False):
-    from ptycho.tf_helper import pad
-    from ptycho.evaluation import save_metrics, trim
-    from ptycho.tf_helper import pad
-    from ptycho.params import cfg
-    cfg['nphotons'] = nphotons
-
-    cfg['data_source'] = 'lines'
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 10
-    cfg['output_prefix'] = 'lines2'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-
-    from ptycho import train
-    if reload_modules:
-        reload(train.generate_data)
-        reload(train.train_pinn.model)
-        reload(train.train_pinn)
-        reload(train)
-
-    stitched_obj, YY_ground_truth = train.stitched_obj, train.YY_ground_truth
-
-    from ptycho.train_pinn import train as train_pinn, eval as eval_pinn
-    from ptycho import misc
-
-    plot_results(stitched_obj, YY_ground_truth, train.d)
-    # Corrected the indentation and scope of the return statement
-    return train.d, YY_ground_truth, stitched_obj, train.train_output
-
-def parse_arguments():
-    parser = argparse.ArgumentParser(description='Ptychographic reconstruction script.')
-    parser.add_argument('nphotons', type=float, help='Number of photons')
-    args = parser.parse_args()
-    return args.nphotons
-
-if __name__ == '__main__':
-    nphotons = parse_arguments()
-    init(nphotons)
-
-    d, YY_ground_truth, stitched_obj = execute(nphotons)
-
-from importlib import reload
-def run_experiment_with_photons(photons_list, loss_fn='nll'):
-    print("DEBUG: Starting run_experiment_with_photons")
-    results = {}
-    first_iteration = True
-    for nphotons in photons_list:
-        init(nphotons, loss_fn=loss_fn)
-        print("DEBUG: nphotons set to", nphotons, "in run_experiment_with_photons")
-        if  first_iteration:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=False)
-        else:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=True)
-        first_iteration = False
-        results[nphotons] = {'d': d, 'YY_ground_truth': YY_ground_truth, 'stitched_obj': stitched_obj, 'train_output': train_output}
-    return results
-import os
-import dill
-import pandas as pd
-import numpy as np
-from matplotlib.image import imread
-
-def has_amp_recon(subdir):
-    return os.path.exists(os.path.join(subdir, 'amp_recon.png'))
-
-def load_recent_experiment_data(directory, N):
-    subdirs = [os.path.join(directory, d) for d in os.listdir(directory) if is_valid_run(os.path.join(directory, d)) and has_amp_recon(os.path.join(directory, d))]
-    print(subdirs)
-    recent_subdirs = subdirs[:N]
-    subdirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)
-
-    data = {}
-    for subdir in recent_subdirs:
-        params_path = os.path.join(subdir, 'params.dill')
-        metrics_path = os.path.join(subdir, 'metrics.csv')
-
-        with open(params_path, 'rb') as f:
-            params = dill.load(f)
-        metrics = pd.read_csv(metrics_path)
-
-        nphotons = (np.log10(params['nphotons']))
-        print('NPOHOT {}'.format(nphotons))
-        #if nphotons not in data or os.path.getmtime(params_path) > os.path.getmtime(os.path.join(data[nphotons]['dir'], 'params.dill')):
-        amp_recon_path = os.path.join(subdir, 'amp_recon.png')
-        amp_recon = imread(amp_recon_path)
-        data[nphotons] = {'params': params, 'metrics': metrics, 'amp_recon': amp_recon, 'dir': subdir}
-
-    return {k: {'params': v['params'], 'metrics': v['metrics']} for k, v in data.items()}
-def is_valid_run(subdir):
-    return os.path.exists(os.path.join(subdir, 'params.dill'))
-import matplotlib.pyplot as plt
-
-def generate_and_save_heatmap(experiment_entry, ax=None, photon_dose=None):
-    if ax is None:
-        fig, ax = plt.subplots()
-    stitched_obj = experiment_entry['stitched_obj'][0, :, :, 0]
-    metrics = experiment_entry['d']
-    frc50 = metrics.get('frc50', [None])[0]
-    psnr = metrics.get('psnr', [None])[0]
-
-    ax.imshow(np.abs(stitched_obj), cmap='jet', interpolation='nearest')
-    title = f'FRC50: {frc50:.2f}, PSNR: {psnr:.2f}'
-    if photon_dose is not None:
-        title = f'Photons: {photon_dose:.0e}, ' + title
-    ax.set_title(title)
-    ax.axis('off')
-
-def generate_2x2_heatmap_plots(res, layout=(1, 4), filename='heatmap_plots.png', axs=None,
-                               fig = None):
-#    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 4*layout[0]))
-#    axs = axs.flatten()
-    for i, (photon_dose, experiment_entry) in enumerate(res.items()):
-        generate_and_save_heatmap(experiment_entry, axs[i], photon_dose)
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.close(fig)
-
-def plot_heatmap_from_experiment(res, nphot, index):
-    import matplotlib.pyplot as plt
-    c = res[nphot]['train_output']['dataset']
-    plt.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    #plt.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    plt.title(f'{nphot:.0e} photons', fontsize = 10)
-    plt.savefig(f'heatmap_photon_dose_{nphot:.0e}_index_{index}.png')
-    #plt.show()
-def plot_heatmaps_for_all_photons(res, index):
-    for nphot in res.keys():
-        plot_heatmap_from_experiment(res, nphot, index)
-    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0]))
-
-def generate_2x2_heatmap_plots_using_function(res, index, layout=(1, 4), filename='heatmap_plots_2x2.png', border_color='black', border_width=2, axs=None):
-    a, b = layout
-    #fig, axs = plt.subplots(1, b, figsize=(24, 3))
-    #fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0])) if axs is None else (None, axs)
-    axs = axs.flatten()
-    photon_doses = list(res.keys())[: b]  # Select the first 4 photon doses for the 2x2 grid
-    for i, nphot in enumerate(photon_doses):
-        ax = axs[i]
-        c = res[nphot]['train_output']['dataset']
-        heatmap = ax.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        for spine in ax.spines.values():
-            spine.set_edgecolor(border_color)
-            spine.set_linewidth(border_width)
-        #ax.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        #ax.set_title(f'{nphot:.0e} photons', fontsize=16)
-        ax.axis('off')
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.show()
-
-def stack_and_display_horizontal_plots(res, index, layout=(1, 4), figsize=(24, 8), crop_size=None):
-    from matplotlib import pyplot as plt
-    import numpy as np
-
-    a, b = layout
-    fig, axs = plt.subplots(2, b, figsize=figsize)
-
-    if crop_size is not None:
-        def crop_center(img, cropx, cropy):
-            y, x = img.shape
-            startx = x // 2 - (cropx // 2)
-            starty = y // 2 - (cropy // 2)
-            return img[starty:starty + cropy, startx:startx + cropx]
-
-        cropped_res = {}
-        for dose, entry in res.items():
-            stitched_obj = entry['stitched_obj'][0, :, :, 0]
-            cropped_obj = crop_center(stitched_obj, crop_size, crop_size)
-            padded_obj = np.pad(cropped_obj, ((0, crop_size - cropped_obj.shape[0]), (0, crop_size - cropped_obj.shape[1])), mode='constant')
-            cropped_res[dose] = {'stitched_obj': np.expand_dims(np.expand_dims(padded_obj, axis=0), axis=-1), **{k: v for k, v in entry.items() if k != 'stitched_obj'}}
-
-        generate_2x2_heatmap_plots(cropped_res, layout=layout, axs=axs[0])
-    else:
-        generate_2x2_heatmap_plots(res, layout=layout, axs=axs[0])
-
-    generate_2x2_heatmap_plots_using_function(res, index, layout=layout, axs=axs[1], border_color='black', border_width=2)
-    plt.tight_layout()
-    fig.savefig(f'stacked_dose_progression_index_{index}.png')
-    plt.show()
diff --git a/build/lib/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py b/build/lib/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/build/lib/build/lib/notebooks/train_and_infer.py b/build/lib/build/lib/build/lib/build/lib/notebooks/train_and_infer.py
deleted file mode 100644
index 6a33f16..0000000
--- a/build/lib/build/lib/build/lib/build/lib/notebooks/train_and_infer.py
+++ /dev/null
@@ -1,159 +0,0 @@
-import logging
-import sys
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-
-from ptycho.workflows.components import (
-    load_data,
-    run_cdi_example,
-    save_outputs
-)
-from ptycho.config.config import TrainingConfig, InferenceConfig, ModelConfig, update_legacy_dict
-from ptycho import model_manager, params, probe
-from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer, probeshow
-
-# Configure logging
-logging.basicConfig(level=logging.INFO,
-                   format='%(asctime)s - %(levelname)s - %(message)s',
-                   handlers=[
-                       logging.StreamHandler(sys.stdout),
-                       logging.FileHandler('train_and_infer.log')
-                   ])
-logger = logging.getLogger(__name__)
-
-def train_model(config: TrainingConfig):
-    """Train the model using provided configuration."""
-    logger.info("Starting training process...")
-    
-    try:
-        # Load training data
-        ptycho_data = load_data(str(config.train_data_file), n_images=512)
-        
-        # Load test data if provided
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        # Run training
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        
-        # Save model and outputs
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-        
-        return recon_amp, recon_phase, results
-    
-    except Exception as e:
-        logger.error(f"Training failed: {e}")
-        raise
-
-def perform_inference(model: tf.keras.Model, test_data, K: int = 7, nsamples: int = 1):
-    """Perform inference using trained model."""
-    logger.info("Starting inference process...")
-    
-    try:
-        # Set probe guess and random seeds
-        probe.set_probe_guess(None, test_data.probeGuess)
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate test dataset
-        test_dataset = test_data.generate_grouped_data(params.cfg['N'], K=K, nsamples=nsamples)
-        
-        # Create data container
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        
-        # Reassemble position
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-        
-        # Process ePIE results
-        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-    
-    except Exception as e:
-        logger.error(f"Inference failed: {e}")
-        raise
-
-def plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase):
-    """Plot comparison between reconstructed and ePIE results."""
-    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
-    
-    # Plot phases
-    im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    fig.colorbar(im_pinn_phase, ax=axs[0, 0])
-    
-    im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    fig.colorbar(im_epie_phase, ax=axs[0, 1])
-    
-    # Plot amplitudes
-    im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    fig.colorbar(im_pinn_amp, ax=axs[1, 0])
-    
-    im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-    axs[1, 1].set_title('ePIE Amplitude')
-    fig.colorbar(im_epie_amp, ax=axs[1, 1])
-    
-    # Remove ticks
-    for ax in axs.flat:
-        ax.set_xticks([])
-        ax.set_yticks([])
-    
-    plt.tight_layout()
-    return fig
-
-def plot_probe(test_data):
-    """Generate probe visualization."""
-    return probeshow(test_data.probeGuess, test_data)
-
-# Example usage in notebook:
-"""
-# Configuration
-train_config = TrainingConfig(
-    model=ModelConfig(),
-    train_data_file=Path('path/to/train_data.npz'),
-    test_data_file=Path('path/to/test_data.npz'),
-    output_dir=Path('output_directory'),
-    debug=False
-)
-
-# Update global params
-update_legacy_dict(params.cfg, train_config)
-
-# Train model
-recon_amp, recon_phase, results = train_model(train_config)
-
-# Load model for inference
-model, _ = model_manager.ModelManager.load_model(train_config.output_dir)
-
-# Load test data
-test_data = load_data('path/to/test_data.npz')
-
-# Perform inference
-reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-    model, test_data, K=7, nsamples=1
-)
-
-# Plot results
-fig = plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase)
-plt.show()
-
-# Plot probe visualization
-probe_fig = plot_probe(test_data)
-plt.show()
-"""
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py
deleted file mode 100644
index 2d66523..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py
+++ /dev/null
@@ -1,13 +0,0 @@
-import os
-
-class Configuration:
-    def __init__(self, debug: bool = False, log_file_prefix: str = "logs"):
-        self.debug = debug
-        self.log_file_prefix = log_file_prefix
-
-    def getDebugFlag(self) -> bool:
-        return self.debug
-
-    def getLogFilePrefix(self) -> str:
-        return self.log_file_prefix
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/debug.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/debug.py
deleted file mode 100644
index a5bf044..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/debug.py
+++ /dev/null
@@ -1,174 +0,0 @@
-from .serializer import Serializer
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-
-# spec
-#    @depends_on(Logger, Configuration, FunctionMapping)
-#    interface Debug {
-#        """
-#        Applies the debugging process to the function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - Configuration must allow debugging.
-#
-#        Postconditions:
-#        - If debugging is allowed by the Configuration:
-#          - Returns a new function that wraps the original function with debugging functionality.
-#          - The returned function, when called, performs two forms of logging:
-#            1. Prints function call and return information to the console, surrounded by XML tags
-#               containing the callable's module path and name. The console log messages are in the
-#               format `<module.function>CALL/RETURN args/result</module.function>`. For all array
-#               or tensor types (i.e., objects with a .shape and/or .dtype attribute), the shapes
-#               and data types are also printed.
-#            2. Serializes function inputs and outputs to a log file using the `logCall` and `logReturn`
-#               methods of the Logger interface. The serialized data can be loaded using the `LoadLog`
-#               method. If serialization fails, the console logging still occurs, but no log file is
-#               generated for that invocation.
-#          - Logs only the first two invocations of the function.
-#        - If debugging is not allowed by the Configuration:
-#          - Returns the original function unchanged, without any debugging functionality.
-#        """
-#        Callable decorate(Callable func);
-#    };
-
-## implementation
-import time
-import os
-import pickle
-import json
-from typing import Callable, Any, List, Union, Optional
-import re
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-class Debug:
-    def __init__(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-
-    def decorate(self, func: Callable) -> Callable:
-        increment_count = make_invocation_counter()
-        if not self.configuration.getDebugFlag():
-            return func
-
-        else:
-            module_path = self.function_mapping.get_module_path(func)
-            function_name = func.__name__
-
-            def wrapper(*args: Any, **kwargs: Any) -> Any:
-                invocation_count = increment_count()
-                if invocation_count > 2:
-                    return func(*args, **kwargs)
-                
-                log_file_path = self.function_mapping.get_log_file_path(func)
-                os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
-
-                try:
-                    serialized_args = self.serializer.serialize(args)
-                    serialized_kwargs = self.serializer.serialize(kwargs)
-                    self.logger.logCall(serialized_args, serialized_kwargs, log_file_path)
-                except ValueError:
-                    pass  # If serialization fails, just proceed with console logging
-
-                console_log_start = f"<{module_path}.{function_name}>CALL"
-                console_log_args = self._formatConsoleLog(args)
-                console_log_kwargs = self._formatConsoleLog(kwargs)
-                print(console_log_start)
-                print(console_log_args)
-                print(console_log_kwargs)
-
-                start_time = time.time()
-
-                result = func(*args, **kwargs)
-                try:
-                    serialized_result = self.serializer.serialize(result)
-                    self.logger.logReturn(serialized_result, time.time() - start_time, log_file_path)
-
-                    console_log_end = f"</{module_path}.{function_name}>RETURN"
-                    console_log_result = self._formatConsoleLog(result)
-                    print(console_log_end + " " + console_log_result)
-
-                except Exception as e:
-                    self.logger.logError(str(e), log_file_path)
-                    print(f"<{module_path}.{function_name}>ERROR {str(e)}")
-                return result
-
-            return wrapper
-
-    def _formatConsoleLog(self, data: Any) -> str:
-        if not isinstance(data, tuple):
-            data = (data,)
-
-        formatted_data = []
-        for item in data:
-            if hasattr(item, 'shape') and hasattr(item, 'dtype'):
-                formatted_data.append(f"type={type(item)}, shape={item.shape}, dtype={item.dtype}")
-            elif isinstance(item, (int, float, str, bool)):
-                formatted_data.append(f"type={type(item)}, {item}")
-            else:
-                formatted_data.append(f"type={type(item)}")
-        return ", ".join(formatted_data)
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-import unittest
-
-class TestDebug(unittest.TestCase):
-    def setUp(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.debug = Debug(self.configuration, self.serializer, self.logger, self.function_mapping)
-
-    def test_decorate_call(self):
-        @self.debug.decorate
-        def add(x, y):
-            return x + y
-
-        result = add(3, 4)
-        self.assertEqual(result, 7)
-
-    def test_decorate_return(self):
-        @self.debug.decorate
-        def multiply(x, y):
-            return x * y
-
-        result = multiply(2, 3)
-        self.assertEqual(result, 6)
-        result = multiply(4, 5)
-        self.assertEqual(result, 20)
-        result = multiply(6, 7)  # This call should not be logged
-        self.assertEqual(result, 42)
-
-    def test_decorate_error(self):
-        @self.debug.decorate
-        def divide(x, y):
-            return x / y
-
-        with self.assertRaises(ZeroDivisionError):
-            divide(1, 0)
-
-#    def test_format_console_log(self):
-#        data = (3, "hello")
-#        formatted_log = self.debug._formatConsoleLog(data)
-#        self.assertEqual(formatted_log, "3, hello")
-
-obj = Debug()
-debug = obj.decorate
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py
deleted file mode 100644
index a9be5de..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py
+++ /dev/null
@@ -1,185 +0,0 @@
-# spec
-#    interface FunctionMapping {
-#        """
-#        Retrieves the log file path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - `log_directory` must be a valid directory path.
-#        - Expected JSON format: { "log_directory": "string" }
-#
-#        Postconditions:
-#        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-#        - If `log_directory` is not provided or is an empty string, returns an empty string.
-#        """
-#        string getLogFilePath(Callable func, string log_directory);
-#
-#        """
-#        Loads a function given its log file path or module path.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid log file path or empty string.
-#        - `module_path` must be a valid module path or empty string.
-#        - Expected JSON format: { "log_file_path": "string", "module_path": "string" }
-#
-#        Postconditions:
-#        - Returns the function object if successfully loaded.
-#        - If the function cannot be found or imported, returns None.
-#        """
-#        Union[Callable, None] loadFunction(string log_file_path, string module_path);
-#
-#        """
-#        Retrieves the module path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#
-#        Postconditions:
-#        - Returns the module path for the given function, formatted as `module.fname`.
-#        - If `func` is a built-in function or does not have a valid module path, returns an empty string.
-#        """
-#        string getModulePath(Callable func);
-#    };
-
-# implementation
-import os
-import shutil
-import importlib
-from typing import Callable, Optional
-
-def dprint(*args):
-    pass
-
-class FunctionMapping:
-    def __init__(self, log_directory: str = "logs"):
-        self.log_directory = log_directory
-
-    def get_log_file_path(self, func: Callable) -> str:
-        """
-        Retrieves the log file path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_log_file_path(sample_function)
-        'test_logs/__main__.sample_function.log'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        log_file_path = f"{self.log_directory}/{module_name}.{func_name}.log"
-        return log_file_path
-
-    def save_function(self, log_file_path: str, func: Callable) -> None:
-        module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-        module = importlib.import_module(module_path)
-        setattr(module, func_name, func)
-
-    def load_function_from_path(self, log_file_path: str) -> Optional[Callable]:
-        try:
-            dprint(f"log_file_path: {log_file_path}")
-            module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-            dprint(f"module_path: {module_path}")
-            dprint(f"func_name: {func_name}")
-            dprint(f"Importing module: {module_path}")
-            module = importlib.import_module(module_path)
-            dprint(f"Imported module: {module}")
-            dprint(f"Retrieving function: {func_name}")
-            func = getattr(module, func_name, None)
-            dprint(f"Retrieved function: {func}")
-            return func
-        except Exception as e:
-            dprint(f"Error loading function: {e}")
-            return None
-
-    def get_module_and_function_from_log_path(self, log_file_path: str) -> tuple:
-        dprint(f"log_file_path: {log_file_path}")
-        log_file_path = log_file_path.replace(f"{self.log_directory}/", "")
-        dprint(f"log_file_path after removing log_directory: {log_file_path}")
-        log_file_path = log_file_path.replace(".log", "")
-        dprint(f"log_file_path after removing .log: {log_file_path}")
-        parts = log_file_path.rsplit(".", 1)
-        print(parts)
-        dprint(f"parts: {parts}")
-        module_path = parts[0]
-        dprint(f"module_path: {module_path}")
-        func_name = parts[1]
-        dprint(f"func_name: {func_name}")
-        return module_path, func_name
-
-    def load_function(self, log_file_path: str) -> Optional[Callable]:
-        """
-        Loads a function given its log file path.
-        
-        Preconditions:
-        - `log_file_path` must be valid.
-        
-        Postconditions:
-        - Returns the function object if successfully loaded.
-        - If the function cannot be found or imported, returns None.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> log_file_path = function_mapping.get_log_file_path(sample_function)
-        >>> loaded_func = function_mapping.load_function(log_file_path)
-        """
-        return self.load_function_from_path(log_file_path)
-
-    def get_module_path(self, func: Callable) -> str:
-        """
-        Retrieves the module path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the module path for the given function, formatted as `module.fname`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_module_path(sample_function)
-        '__main__.sample_function'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        module_path = f"{module_name}.{func_name}"
-        return module_path
-
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-def sample_function():
-    return "sample function executed"
-
-def another_function():
-    return "another function executed"
-
-def test_get_log_file_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_log_file_path(sample_function)
-    assert path == 'test_logs/__main__.sample_function.log', f"Expected 'test_logs/__main__.sample_function.log', got '{path}'"
-
-def test_load_function():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    log_file_path = function_mapping.get_log_file_path(sample_function)
-    
-    loaded_func = function_mapping.load_function(log_file_path=log_file_path)
-    assert loaded_func is not None, "Expected function to be loaded, but got None"
-    assert loaded_func.__name__ == 'sample_function', f"Expected 'sample_function', got '{loaded_func.__name__}'"
-
-def test_get_module_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_module_path(sample_function)
-    assert path == '__main__.sample_function', f"Expected '__main__.sample_function', got '{path}'"
-
-if __name__ == "__main__":
-    test_get_log_file_path()
-    test_load_function()
-    test_get_module_path()
-    print("All tests passed!")
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/logger.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/logger.py
deleted file mode 100644
index 8def564..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/logger.py
+++ /dev/null
@@ -1,242 +0,0 @@
-from .serializer import Serializer
-# spec
-#    @depends_on(Serializer)
-#    interface Logger {
-#        """
-#        Logs function call details to a specified log file.
-#
-#        Preconditions:
-#        - `args` and `kwargs` are serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized function arguments and keyword arguments are written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logCall(bytes args, bytes kwargs, string log_file_path);
-#
-#        """
-#        Logs function return details to the specified log file.
-#
-#        Preconditions:
-#        - `result` is serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized `result` and `execution_time` are appended to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logReturn(bytes result, float execution_time, string log_file_path);
-#
-#        """
-#        Logs an error message to the specified log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The `error` message is written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logError(string error, string log_file_path);
-#
-#        """
-#        Loads a logged dataset from a log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with read permissions.
-#          The file must contain valid JSON-formatted log entries.
-#
-#        Postconditions:
-#        - Returns a list or tuple containing the logged inputs and output.
-#        - If there is an error during loading, returns an empty list or tuple.
-#        """
-#        Union[list, tuple] loadLog(Configuration configuration);
-#
-#        """
-#        Searches the log directory and returns all valid log file paths.
-#
-#        Preconditions:
-#        - `log_directory` must be a valid directory path with read permissions.
-#
-#        Postconditions:
-#        - Returns a list of valid log file paths adhering to the format ^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.?
-#        - Invalid log file paths are filtered out using the validateLogFilePath method.
-#        - If there are no valid log files or an error occurs during searching, returns an empty list.
-#        """
-#        list[str] searchLogDirectory(string log_directory);
-#
-#        """
-#        Validates a log file path against the expected format.
-#
-#        Preconditions:
-#        - `log_file_path` must be a string representing a file path.
-#
-#        Postconditions:
-#        - Returns True if the `log_file_path` adheres to the format '^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.', False otherwise.
-#        """
-#        bool validateLogFilePath(string log_file_path);
-#    };
-
-import json
-import os
-import sys
-import pickle
-from typing import Any, Union, List
-import re
-
-class Logger:
-    def __init__(self):
-        self.serializer = Serializer()
-
-    def logCall(self, args: bytes, kwargs: bytes, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "args": args.hex(),
-                    "kwargs": kwargs.hex()
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function call: {e}", file=sys.stderr)
-
-    def logReturn(self, result: bytes, execution_time: float, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "result": result.hex(),
-                    "execution_time": execution_time
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function return: {e}", file=sys.stderr)
-
-    def logError(self, error: str, log_file_path: str) -> None:
-        pass
-#        try:
-#            with open(log_file_path, 'a') as log_file:
-#                log_entry = json.dumps({
-#                    "error": error
-#                })
-#                log_file.write(log_entry + "\n")
-#        except Exception as e:
-#            print(f"Error logging error: {e}", file=sys.stderr)
-
-    def loadLog(self, log_file_path: str) -> Union[List, tuple]:
-        logs = []
-        try:
-            with open(log_file_path, 'r') as log_file:
-                for line in log_file:
-                    log_entry = json.loads(line)
-                    if "args" in log_entry:
-                        log_entry["args"] = bytes.fromhex(log_entry["args"])
-                    if "kwargs" in log_entry:
-                        log_entry["kwargs"] = bytes.fromhex(log_entry["kwargs"])
-                    if "result" in log_entry:
-                        log_entry["result"] = bytes.fromhex(log_entry["result"])
-                    logs.append(log_entry)
-        except Exception as e:
-            print(f"Error loading log: {e}", file=sys.stderr)
-        return logs
-
-    def searchLogDirectory(self, log_directory: str) -> List[str]:
-        valid_log_files = []
-        try:
-            for root, _, files in os.walk(log_directory):
-                for file in files:
-                    file_path = os.path.relpath(os.path.join(root, file), start=log_directory)
-                    if self.validateLogFilePath(file_path):
-                        valid_log_files.append(os.path.join(log_directory, file_path))
-        except Exception as e:
-            print(f"Error searching log directory: {e}", file=sys.stderr)
-        return valid_log_files
-
-    def validateLogFilePath(self, log_file_path: str) -> bool:
-        return True
-        pattern = r'^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$'
-        return re.match(pattern, log_file_path) is not None
-
-import unittest
-import tempfile
-
-class TestLogger(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.test_dir = tempfile.TemporaryDirectory()
-        self.test_file = os.path.join(self.test_dir.name, 'test.log')
-        
-    def tearDown(self):
-        self.test_dir.cleanup()
-
-    def test_logCall(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        self.logger.logCall(args, kwargs, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["args"], args.hex())
-            self.assertEqual(log_entry["kwargs"], kwargs.hex())
-
-    def test_logReturn(self):
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["result"], result.hex())
-            self.assertEqual(log_entry["execution_time"], execution_time)
-
-    def test_logError(self):
-        error = "Test error message"
-        self.logger.logError(error, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["error"], error)
-
-    def test_loadLog(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        
-        self.logger.logCall(args, kwargs, self.test_file)
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        logs = self.logger.loadLog(self.test_file)
-        self.assertEqual(len(logs), 2)
-        self.assertEqual(logs[0]["args"], args)
-        self.assertEqual(logs[0]["kwargs"], kwargs)
-        self.assertEqual(logs[1]["result"], result)
-        self.assertEqual(logs[1]["execution_time"], execution_time)
-
-    def test_searchLogDirectory(self):
-        valid_file = os.path.join(self.test_dir.name, 'logs/module.samplefunc.log')
-        invalid_file = os.path.join(self.test_dir.name, 'invalid.log')
-        
-        os.makedirs(os.path.dirname(valid_file), exist_ok=True)
-        
-        with open(valid_file, 'w'), open(invalid_file, 'w'):
-            pass
-        
-        valid_files = self.logger.searchLogDirectory(self.test_dir.name)
-        self.assertIn(valid_file, valid_files)
-        self.assertNotIn(invalid_file, valid_files)
-
-    def test_validateLogFilePath(self):
-        valid_path = 'logs/module.samplefunc.log'
-        invalid_path = 'invalid.log'
-        
-        self.assertTrue(self.logger.validateLogFilePath(valid_path))
-        self.assertFalse(self.logger.validateLogFilePath(invalid_path))
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py
deleted file mode 100644
index bbf4035..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py
+++ /dev/null
@@ -1,92 +0,0 @@
-# spec
-#module DebuggingSystem {
-#
-#    interface Serializer {
-#        """
-#        Serializes Python objects to a binary format using pickle.
-#
-#        Preconditions:
-#        - `input_data` must be a picklable Python object.
-#
-#        Postconditions:
-#        - Returns the serialized binary data of the input object.
-#        - Raises ValueError if the input data is not picklable.
-#        """
-#        bytes serialize(Any input_data);
-#
-#        """
-#        Deserializes Python objects from a binary format using pickle.
-#
-#        Preconditions:
-#        - `serialized_data` must be a valid pickle-serialized binary string.
-#
-#        Postconditions:
-#        - Returns the deserialized Python object.
-#        - Raises ValueError if the binary data could not be deserialized.
-#        """
-#        Any deserialize(bytes serialized_data);
-#    };
-
-import doctest
-import pickle
-from typing import Any, List
-
-class Serializer:
-    def serialize(self, input_data: Any) -> bytes:
-        """
-        Serializes Python objects to a binary format using pickle.
-
-        Preconditions:
-        - `input_data` must be a picklable Python object.
-
-        Postconditions:
-        - Returns the serialized binary data of the input object.
-        - Raises ValueError if the input data is not picklable.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> type(serialized_data)
-        <class 'bytes'>
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.serialize(lambda x: x)  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Input data is not picklable
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.dumps(input_data)
-        except (pickle.PicklingError, AttributeError, TypeError):
-            raise ValueError("Input data is not picklable")
-
-    def deserialize(self, serialized_data: bytes) -> Any:
-        """
-        Deserializes Python objects from a binary format using pickle.
-
-        Preconditions:
-        - `serialized_data` must be a valid pickle-serialized binary string.
-
-        Postconditions:
-        - Returns the deserialized Python object.
-        - Raises ValueError if the binary data could not be deserialized.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.loads(serialized_data)
-        except (pickle.UnpicklingError, EOFError, AttributeError, ImportError, IndexError):
-            raise ValueError("Could not deserialize the binary data")
-doctest.testmod(verbose=True)
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/testing.py b/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/testing.py
deleted file mode 100644
index 079233e..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/autotest/testing.py
+++ /dev/null
@@ -1,163 +0,0 @@
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-import unittest
-from logger import Logger
-from functionmapping import FunctionMapping
-
-from typing import List, Tuple, Any, Optional, Callable, Union
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-    def testCallable(self, log_path_prefix: str, func: Callable) -> bool:
-        print(f"Debug: testCallable called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            for i in range(len(logs) // 2):
-                args = logs[2 * i]['args']
-                kwargs = logs[2 * i]['kwargs']
-                expected_output = logs[2 * i + 1]['result']
-                try:
-                    deserialized_args = self.logger.serializer.deserialize(args)
-                    deserialized_kwargs = self.logger.serializer.deserialize(kwargs)
-                    deserialized_expected_output = self.logger.serializer.deserialize(expected_output)
-                    actual_output = func(*deserialized_args, **deserialized_kwargs)
-                    #print(f"Debug: Actual output: {actual_output}")
-                    if actual_output != deserialized_expected_output:
-                        print("Debug: Test failed")
-                        return False
-                except Exception as e:
-                    print(f"Error testing function: {e}")
-                    return False
-        print("Debug: Test passed")
-        return True
-
-    def createTestCase(self, log_path_prefix: str) -> Union[tuple, None]:
-        print(f"Debug: createTestCase called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            if logs:
-                log = logs[0]
-                inputs = log['args']
-                expected_output = log['result']
-                func = self.function_mapping.load_function(log_file)
-                print(f"Debug: Loaded function: {func}")
-                if func is not None:
-                    return (inputs, expected_output, func)
-        print("Debug: No test case found")
-        return None
-
-    def runTestSuite(self, log_path_prefix: str) -> TestSummary:
-        print(f"Debug: runTestSuite called with log_path_prefix: {log_path_prefix}")
-        summary = TestSummary()
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            test_case = self.createTestCase(log_path_prefix)
-            if test_case is not None:
-                inputs, expected_output, func = test_case
-                if self.testCallable(log_path_prefix, func):
-                    summary.increment_passed()
-                else:
-                    summary.increment_failed()
-            else:
-                summary.increment_skipped()
-        print(f"Debug: Test summary: {summary}")
-        return summary
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-
-def add(x, y):
-    return x + y
-
-def multiply(x, y):
-    return x * y
-
-def divide(x, y):
-    return x / y
-
-class TestTesting(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.testing = Testing(self.logger, self.function_mapping)
-
-    def test_testCallable(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.assertTrue(self.testing.testCallable(log_path_prefix, add))
-
-    def test_createTestCase(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        test_case = self.testing.createTestCase(log_path_prefix)
-        self.assertIsNotNone(test_case)
-        inputs, expected_output, func = test_case
-        self.assertEqual(self.logger.serializer.deserialize(inputs), (3, 4))
-        self.assertEqual(self.logger.serializer.deserialize(expected_output), 7)
-        self.assertEqual(func, add)
-
-    def test_runTestSuite(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.logger.logReturn(log_path_prefix + '/multiply', (3, 4), 12)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        self.function_mapping.save_function(log_path_prefix + '/multiply', multiply)
-        summary = self.testing.runTestSuite(log_path_prefix)
-        self.assertIsInstance(summary, TestSummary)
-        self.assertEqual(summary.passed, 2)
-        self.assertEqual(summary.failed, 0)
-        self.assertEqual(summary.skipped, 0)
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/baselines.py b/build/lib/build/lib/build/lib/build/lib/ptycho/baselines.py
deleted file mode 100644
index 7511803..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/baselines.py
+++ /dev/null
@@ -1,93 +0,0 @@
-# based on https://github.com/mcherukara/PtychoNN/tree/master/TF2
-# with minor changes to make comparison to PtychoPINN easier
-from .tf_helper import *
-from . import params
-import tensorflow as tf
-import numpy as np
-
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras import Sequential
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-
-tf.keras.backend.clear_session()
-np.random.seed(123)
-
-h,w=params.get('N'), params.get('N')
-nepochs=params.get('nepochs')
-wt_path = 'wts4' #Where to store network weights
-batch_size = 32
-
-n_filters_scale = params.params()['n_filters_scale']
-
-#Keras modules
-from tensorflow.keras.layers import UpSampling2D
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-
-#checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.hdf5' %wt_path,
-#                                            monitor='val_loss', verbose=1, save_best_only=True,
-#                                            save_weights_only=False, mode='auto', period=1)
-
-def build_model(X_train, Y_I_train, Y_phi_train):
-    tf.keras.backend.clear_session()
-    c = X_train.shape[-1]
-    input_img = Input(shape=(h, w, c))
-
-    x = Conv_Pool_block(input_img,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    #Activations are all ReLu
-
-    encoded=x
-
-    #Decoding arm 1
-    x1=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded1 = Conv2D(c, (3, 3), padding='same')(x1)
-
-    #Decoding arm 2
-    x2=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded2 = Conv2D(c, (3, 3), padding='same')(x2)
-    #Put together
-    autoencoder = Model(input_img, [decoded1, decoded2])
-    # Masked MAE creates a more apples-to-apples comparison with the main
-    # model, but it doesn't seem to affect the image quality
-    #autoencoder.compile(optimizer='adam', loss=masked_mae)
-    autoencoder.compile(optimizer='adam', loss='mean_absolute_error')
-    return autoencoder
-
-def train(X_train, Y_I_train, Y_phi_train, autoencoder = None):
-    if autoencoder is None:
-        autoencoder = build_model(X_train, Y_I_train, Y_phi_train)
-
-    print (autoencoder.summary())
-    #plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-
-    #history=autoencoder.fit(X_train * params.params()['intensity_scale'],
-    history=autoencoder.fit(X_train,
-        [Y_I_train, Y_phi_train], shuffle=True,
-        batch_size=batch_size, verbose=1, epochs=nepochs,
-        validation_split = 0.05, callbacks=[reduce_lr, earlystop])
-    return autoencoder, history
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/classes.py b/build/lib/build/lib/build/lib/build/lib/ptycho/classes.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/config/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/config/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/config/config.py b/build/lib/build/lib/build/lib/build/lib/ptycho/config/config.py
deleted file mode 100644
index c49e74c..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/config/config.py
+++ /dev/null
@@ -1,149 +0,0 @@
-from dataclasses import dataclass, asdict
-from pathlib import Path
-from typing import Dict, Any, Optional, Literal
-import yaml
-
-@dataclass(frozen=True)
-class ModelConfig:
-    """Core model architecture parameters."""
-    N: Literal[64, 128, 256] = 64
-    gridsize: int = 1
-    n_filters_scale: int = 2
-    model_type: Literal['pinn', 'supervised'] = 'pinn'
-    amp_activation: Literal['sigmoid', 'swish', 'softplus', 'relu'] = 'sigmoid'
-    object_big: bool = True
-    probe_big: bool = True  # Changed default
-    probe_mask: bool = False  # Changed default
-    pad_object: bool = True
-    probe_scale: float = 4.
-    gaussian_smoothing_sigma: float = 0.0
-
-@dataclass(frozen=True)
-class TrainingConfig:
-    """Training specific configuration."""
-    model: ModelConfig
-    train_data_file: Path  # Added
-    test_data_file: Optional[Path] = None  # Added
-    batch_size: int = 16
-    nepochs: int = 50
-    mae_weight: float = 0.0
-    nll_weight: float = 1.0
-    realspace_mae_weight: float = 0.0
-    realspace_weight: float = 0.0
-    nphotons: float = 1e9
-    positions_provided: bool = True  
-    probe_trainable: bool = False
-    intensity_scale_trainable: bool = True  # Changed default
-    output_dir: Path = Path("training_outputs")
-
-@dataclass(frozen=True)
-class InferenceConfig:
-    """Inference specific configuration."""
-    model: ModelConfig
-    model_path: Path
-    test_data_file: Path
-    debug: bool = False
-    output_dir: Path = Path("inference_outputs")
-
-def validate_model_config(config: ModelConfig) -> None:
-    """Validate model configuration."""
-    if config.gridsize <= 0:
-        raise ValueError(f"gridsize must be positive, got {config.gridsize}")
-    if config.n_filters_scale <= 0:
-        raise ValueError(f"n_filters_scale must be positive, got {config.n_filters_scale}")
-    if config.probe_scale <= 0:
-        raise ValueError(f"probe_scale must be positive, got {config.probe_scale}")
-    if config.gaussian_smoothing_sigma < 0:
-        raise ValueError(f"gaussian_smoothing_sigma must be non-negative, got {config.gaussian_smoothing_sigma}")
-
-def validate_training_config(config: TrainingConfig) -> None:
-    """Validate training configuration."""
-    validate_model_config(config.model)
-    if config.batch_size <= 0 or (config.batch_size & (config.batch_size - 1)):
-        raise ValueError(f"batch_size must be positive power of 2, got {config.batch_size}")
-    if config.nepochs <= 0:
-        raise ValueError(f"nepochs must be positive, got {config.nepochs}")
-    if not (0 <= config.mae_weight <= 1):
-        raise ValueError(f"mae_weight must be in [0,1], got {config.mae_weight}")
-    if not (0 <= config.nll_weight <= 1):
-        raise ValueError(f"nll_weight must be in [0,1], got {config.nll_weight}")
-    if config.nphotons <= 0:
-        raise ValueError(f"nphotons must be positive, got {config.nphotons}")
-
-def validate_inference_config(config: InferenceConfig) -> None:
-    """Validate inference configuration."""
-    validate_model_config(config.model)
-    if not config.model_path.exists():
-        raise ValueError(f"model_path does not exist: {config.model_path}")
-
-def load_yaml_config(path: Path) -> Dict[str, Any]:
-    """Load YAML configuration file.
-    
-    Args:
-        path: Path to YAML config file
-        
-    Returns:
-        Dictionary containing configuration values
-        
-    Raises:
-        OSError: If file cannot be read
-        yaml.YAMLError: If YAML is invalid
-    """
-    try:
-        with open(path) as f:
-            return yaml.safe_load(f)
-    except (OSError, yaml.YAMLError) as e:
-        raise type(e)(f"Failed to load config from {path}: {str(e)}")
-
-def dataclass_to_legacy_dict(obj: Any) -> Dict[str, Any]:
-    """Convert dataclass to legacy dictionary format with key mappings.
-    
-    Args:
-        obj: Dataclass instance to convert
-        
-    Returns:
-        Dictionary with legacy parameter names and values
-    """
-    # Key mappings from dataclass field names to legacy param names
-    KEY_MAPPINGS = {
-        'object_big': 'object.big',
-        'probe_big': 'probe.big', 
-        'probe_mask': 'probe.mask',
-        'probe_trainable': 'probe.trainable',
-        'intensity_scale_trainable': 'intensity_scale.trainable',
-        'positions_provided': 'positions.provided',
-        'output_dir': 'output_prefix'
-    }
-
-    # Convert dataclass to dict
-    d = asdict(obj)
-
-    # Handle nested ModelConfig
-    if 'model' in d:
-        model_dict = d.pop('model')
-        d.update(model_dict)
-
-    # Apply key mappings
-    for old_key, new_key in KEY_MAPPINGS.items():
-        if old_key in d:
-            d[new_key] = d.pop(old_key)
-
-    # Convert Path to string
-    if 'output_dir' in d:
-        d['output_prefix'] = str(d.pop('output_dir'))
-
-    return d
-
-def update_legacy_dict(cfg: Dict[str, Any], dataclass_obj: Any) -> None:
-    """Update legacy dictionary with dataclass values.
-    
-    Updates all values from the dataclass, adding new keys if needed.
-    
-    Args:
-        cfg: Legacy dictionary to update
-        dataclass_obj: Dataclass instance containing new values
-    """
-    new_values = dataclass_to_legacy_dict(dataclass_obj)
-    
-    # Update all values from dataclass
-    cfg.update(new_values)
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py b/build/lib/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py
deleted file mode 100644
index 6a49d58..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py
+++ /dev/null
@@ -1,189 +0,0 @@
-from sklearn.utils import shuffle
-import numpy as np
-
-from ptycho import params
-from ptycho import diffsim as datasets
-import tensorflow as tf
-
-from .loader import PtychoDataset, PtychoDataContainer
-from ptycho import loader
-from ptycho import probe
-
-if params.get('outer_offset_train') is None or params.get('outer_offset_test') is None:
-    assert params.get('data_source') == 'generic'
-
-def load_simulated_data(size, probe, outer_offset_train, outer_offset_test, jitter_scale, intensity_scale=None):
-    np.random.seed(1)
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), size, probe, outer_offset_train, jitter_scale=jitter_scale, which = 'train')
-    params.cfg['intensity_scale'] = intensity_scale
-
-    np.random.seed(2)
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, which = 'test')
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_experimental_data(probe, outer_offset_train, outer_offset_test, jitter_scale):
-    from ptycho import experimental
-    YY_I, YY_phi = experimental.get_full_experimental('train')
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), experimental.train_size, probe, outer_offset_train, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    YY_I, YY_phi = experimental.get_full_experimental('test')
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), experimental.test_size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_xpp_data(probeGuess):
-    from ptycho import xpp
-    train_data_container = loader.load(xpp.get_data, probeGuess, which='train')
-    test_data_container = loader.load(xpp.get_data, probeGuess, which='test')
-    return train_data_container, test_data_container
-
-def load_generic_data(probeGuess, N):
-    from ptycho.raw_data import RawData
-    train_data_file_path = params.get('train_data_file_path')
-    test_data_file_path = params.get('test_data_file_path')
-
-    train_raw = RawData.from_file(train_data_file_path)
-    test_raw = RawData.from_file(test_data_file_path)
-
-    dset_train = train_raw.generate_grouped_data(N, K=7, nsamples=1)
-    dset_test = test_raw.generate_grouped_data(N, K=7, nsamples=1)
-
-    train_data_container = loader.load(lambda: dset_train, probeGuess, which=None, create_split=False)
-    test_data_container = loader.load(lambda: dset_test, probeGuess, which=None, create_split=False)
-    return train_data_container, test_data_container
-
-def shuffle_data(X, Y_I, Y_phi, random_state=0):
-    indices = np.arange(len(Y_I))
-    indices_shuffled = shuffle(indices, random_state=random_state)
-
-    X_shuffled = X[indices_shuffled]
-    Y_I_shuffled = Y_I[indices_shuffled]
-    Y_phi_shuffled = Y_phi[indices_shuffled]
-
-    return X_shuffled, Y_I_shuffled, Y_phi_shuffled, indices_shuffled
-
-def get_clipped_object(YY_full, outer_offset):
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-
-    extra_size = (YY_full.shape[1] - (params.cfg['N'] + (params.cfg['gridsize'] - 1) * params.cfg['offset'])) % (outer_offset // 2)
-    if extra_size > 0:
-        YY_ground_truth = YY_full[:, :-extra_size, :-extra_size]
-    else:
-        print('discarding length {} from test image'.format(extra_size))
-        YY_ground_truth = YY_full
-    YY_ground_truth = YY_ground_truth[:, clipleft:-clipright, clipleft:-clipright]
-    return YY_ground_truth
-
-def get_clip_sizes(outer_offset):
-    N = params.cfg['N']
-    gridsize = params.cfg['gridsize']
-    offset = params.cfg['offset']
-    bordersize = (N - outer_offset / 2) / 2
-    borderleft = int(np.ceil(bordersize))
-    borderright = int(np.floor(bordersize))
-    clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-    clipleft = int(np.ceil(clipsize))
-    clipright = int(np.floor(clipsize))
-    return borderleft, borderright, clipleft, clipright
-
-def stitch_data(b, norm_Y_I_test=1, norm=True, part='amp', outer_offset=None, nimgs=None):
-    # channel size must be 1, or not present
-    if b.shape[-1] != 1:
-        assert b.shape[-1] == params.get(['N'])
-    if nimgs is None:
-        nimgs = params.get('nimgs_test')
-    if outer_offset is None:
-        outer_offset = params.get('outer_offset_test')
-    nsegments = int(np.sqrt((int(tf.size(b)) / nimgs) / (params.cfg['N']**2)))
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    else:
-        img_recon = np.reshape((getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    return stitched
-
-def reassemble(b, norm_Y_I = 1., part='amp', **kwargs):
-    stitched = stitch_data(b, norm_Y_I, norm=False, part=part, **kwargs)
-    return stitched
-
-def process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test):
-    X_train, Y_I_train, Y_phi_train, indices_shuffled = shuffle_data(np.array(X_train), np.array(Y_I_train), np.array(Y_phi_train))
-    if params.get('outer_offset_train') is not None:
-        YY_ground_truth_all = get_clipped_object(YY_test_full, outer_offset_test)
-        YY_ground_truth = YY_ground_truth_all[0, ...]
-        print('DEBUG: generating grid-mode ground truth image')
-    else:
-        YY_ground_truth = None
-        print('DEBUG: No ground truth image in non-grid mode')
-    return X_train, Y_I_train, Y_phi_train, YY_ground_truth
-
-def create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                          X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true):
-    return PtychoDataset(
-        PtychoDataContainer(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true, None, None, None, probe.get_probe(params)),
-        PtychoDataContainer(X_test, Y_I_test, Y_phi_test, intensity_scale, YY_test_full, coords_test_nominal, coords_test_true, None, None, None, probe.get_probe(params)),
-    )
-
-def generate_data(probeGuess = None):
-    # TODO handle probeGuess None case
-    data_source = params.params()['data_source']
-    probe_np = probe.get_probe(params)
-    outer_offset_train = params.cfg['outer_offset_train']
-    outer_offset_test = params.cfg['outer_offset_test']
-    YY_test_full = None
-    norm_Y_I_test = None
-
-    if data_source in ['lines', 'grf', 'points', 'testimg', 'diagonals', 'V']:
-        size = params.cfg['size']
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_simulated_data(size, probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'experimental':
-        # Ensure nimgs parameters are 1 for experimental data
-        assert params.get('nimgs_train') == 1, "nimgs_train must be 1 for experimental data"
-        assert params.get('nimgs_test') == 1, "nimgs_test must be 1 for experimental data"
-        
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_experimental_data(probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'xpp':
-        test_data_container, train_data_container = load_xpp_data(probeGuess)
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        YY_test_full = None
-    elif data_source == 'generic':
-        train_data_container, test_data_container = load_generic_data(probeGuess, params.cfg['N'])
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        print('INFO: train data:')
-        print(train_data_container)
-        print('INFO: test data:')
-        print(test_data_container)
-    else:
-        raise ValueError("Invalid data source")
-
-    params.cfg['intensity_scale'] = intensity_scale
-    return ptycho_dataset.train_data.X, ptycho_dataset.train_data.Y_I, ptycho_dataset.train_data.Y_phi, ptycho_dataset.test_data.X, ptycho_dataset.test_data.Y_I, ptycho_dataset.test_data.Y_phi, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py
deleted file mode 100644
index 1c4bac9..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import numpy as np
-
-def draw_lines(shape, num):
-    num_vertical = num_horizontal = num_diagonal = num
-    # Create a 2D NumPy array with zeros
-    arr = np.zeros(shape)
-    n, m = shape
-
-    # Draw vertical lines
-    for i in range(num_vertical):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        arr[:, x] = 1
-
-    # Draw horizontal lines
-    for i in range(num_horizontal):
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        arr[y, :] = 1
-
-    # Draw diagonal lines
-    for i in range(num_diagonal):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        off = min(x, y)
-        x = x - off
-        y = y - off
-        ix = np.arange(x, n - y)
-        iy = np.arange(y, m - x)
-        arr[ix, iy] = 1
-        arr[ix, -iy] = 1
-
-    return arr
-
-
-from scipy.ndimage import gaussian_filter as gf
-def mk_diags(N, sigma = .75):
-    img = draw_lines((N, N), 40)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/grf.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/grf.py
deleted file mode 100644
index 8ab01fd..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/grf.py
+++ /dev/null
@@ -1,73 +0,0 @@
-# credit https://github.com/PabloVD/MapGenerator
-
-import matplotlib.pyplot as plt
-import numpy as np
-import powerbox as pbox
-from scipy import interpolate, ndimage
-
-#--- Parameters for GRF---#
-
-
-# Number of bins per dimension
-boxsize = 100#(max(xx.shape) + 1) // 2#xx.shape[0] // 2
-# Number of bins per dimension in the high resolution  box
-
-# Define power spectrum as a power law with an spectral index indexlaw
-# With lower the spectral indexes, small structures are removed
-def powerspec(k,indexlaw):
-    return k**indexlaw
-
-# Filter the field with a gaussian window
-def smooth_field(field,sigmagauss,gridsize=boxsize):
-
-    x, y = np.linspace(0,field.shape[0],num=field.shape[0]), np.linspace(0,field.shape[1],num=field.shape[1])
-
-    # Interpolation
-    f = interpolate.interp2d(x,y,field,kind="linear")
-
-    qx = np.linspace(x[0],x[-1], num = gridsize)
-    qy = np.linspace(y[0],y[-1], num = gridsize)
-
-    # Filtering
-    smooth = ndimage.filters.gaussian_filter(f(qx,qy),sigmagauss)
-    return smooth
-
-# Remove regions below sea level
-def mainland(field,threshold):
-    for i, row in enumerate(field):
-        for j, el in enumerate(row):
-            if el<threshold:   field[i,j]=0.
-    return field
-
-# Normalize the values of the field between 0 and 1
-def normalize_field(field):
-    min, max = np.amin(field), np.amax(field)
-    newfield = (field-min)/(max-min)
-    return newfield
-
-# Generate a map of islands applying different processes:
-# 1. Generate a random gaussian field given a power spectrum
-# 2. Normalize the field between 0 and 1
-# 3. Smooth the field with a gaussian filter
-# 4. Retain only the mainland above a certain threshold
-def generate_map(indexlaw,sigma,threshold, boxsize):
-    # Number of bins per dimension in the high resolution  box
-    highboxsize = 2*boxsize
-    field = pbox.powerbox.PowerBox(boxsize, lambda k: powerspec(k,indexlaw), dim=2, boxlength=100.).delta_x()
-    field = normalize_field(field)
-    field = smooth_field(field,sigma,gridsize=highboxsize)
-    return field
-
-def mk_grf(N):
-    assert not N % 2
-    boxsize = N // 2
-    # Threshold for the sea level
-    threshold = 0.4
-    # Sigma for the gaussian smoothing
-    sigma = 1
-    # Spectral index for the power spectrum
-    indexlaw = -.4
-    res = np.zeros((N, N, 1))
-    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-    return res
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/points.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/points.py
deleted file mode 100644
index eb415e4..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/points.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def randones(N, pct = .1):
-    """
-    Return array whose entries are randomly either 0 or 1.
-    """
-    rows, cols = N, N
-
-    # define the percentage of entries to increment
-    pct = 0.1
-
-    # create a 2D numpy array of all 0s
-    arr = np.zeros((rows, cols))
-
-    # determine the number of entries to increment
-    num_entries = int(rows * cols * pct)
-
-    # randomly select indices to increment with replacement
-    indices = np.random.choice(rows * cols, num_entries)
-
-    # increment the values at the selected indices by 1
-    np.add.at(arr, np.unravel_index(indices, (rows, cols)), 1)
-
-    # print the resulting array
-    return arr
-
-
-def mk_points(N, sigma = 1, pct = .15):
-    img = randones(N, pct = pct)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py
deleted file mode 100644
index 5f49b13..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-import os
-from scipy import misc
-from imageio import imread
-from ptycho import tf_helper as hh
-from ptycho import params
-import tensorflow as tf
-
-def first_and_last(it):
-    it = iter(it)  # Ensure it's an iterator
-    try:
-        first = next(it)  # Get the first item
-    except StopIteration:
-        return  # If the iterator is empty, return an empty iterator
-    last = None
-    for last in it:  # Traverse the rest of the iterator to find the last item
-        pass
-    if last is None:
-        yield first
-    else:
-        yield first
-        yield last
-
-path = './'
-image = imread(os.path.join(path,'williamson.jpeg')).astype(float)
-image /= image.mean()
-image = image[None, 100:, :, :1]
-
-N = params.get('size')
-imgs = hh.extract_patches(image, N, N)
-imgs = tf.reshape(imgs, (-1,) + (N, N))
-
-# Convert TensorFlow tensor to NumPy array for reversible operations
-imgs_np = imgs.numpy()
-rev = imgs_np[::-1]  # Reversing using NumPy slicing
-
-# Convert back to TensorFlow tensor if needed
-rev_tensor = tf.convert_to_tensor(rev, dtype=tf.float32)
-it = iter(imgs_np)  # Iterator for original order
-rev_it = iter(rev_tensor)  # Iterator for reversed order
-
-def get_block(reverse = False):
-    if reverse:
-        return np.array(next(rev_it))
-    return np.array(next(it))
-
-def get_img(N = None, sigma = .5, reverse = False):
-    img = get_block(reverse = reverse)
-    # Anti-aliasing
-    img = gf(img, sigma)
-    img = img[:, :, None]
-    return img
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py b/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py
deleted file mode 100644
index 5676c59..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py
+++ /dev/null
@@ -1,78 +0,0 @@
-import numpy as np
-import scipy.ndimage
-import matplotlib.pyplot as plt
-
-from scipy.ndimage import zoom
-import numpy as np
-
-from PIL import Image, ImageDraw, ImageFont
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def letter_to_array(letter, font_path, font_size, image_size):
-    # Create a blank image
-    img = Image.new('L', image_size, 255)  # 'L' stands for 8-bit pixels, black and white
-
-    # Get drawing context
-    d = ImageDraw.Draw(img)
-
-    # Define font
-    font = ImageFont.truetype(font_path, font_size)
-
-    # Get text width and height
-    text_width, text_height = d.textsize(letter, font=font)
-
-    # Calculate X, Y position of the text
-    x = (image_size[0] - text_width) / 2
-    y = (image_size[1] - text_height) / 2
-
-    # Draw the text onto the image
-    d.text((x, y), letter, font=font, fill=(0))
-
-    # Convert the image data to a numpy array
-    data = np.array(img)
-
-    # Convert to binary (0 and 1)
-    binary_data = np.where(data < 128, 1, 0)
-
-    return binary_data
-
-# Use a font available on your system (this path is for demonstration; adjust accordingly)
-font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
-sprite = letter_to_array('V', font_path, font_size=50, image_size=(60, 60))
-
-def create_canvas(size):
-    return np.zeros((size, size))
-
-def create_sprite():
-    return sprite
-
-def add_sprite_to_canvas(canvas, sprite, repetitions):
-    for _ in range(repetitions):
-        scale = 0.05 + .4 * np.random.rand()
-        scaled_sprite = scipy.ndimage.zoom(sprite, scale)
-
-        tx = np.random.randint(0, canvas.shape[0] - scaled_sprite.shape[0])
-        ty = np.random.randint(0, canvas.shape[1] - scaled_sprite.shape[1])
-
-        x_end = min(tx + scaled_sprite.shape[0], canvas.shape[0])
-        y_end = min(ty + scaled_sprite.shape[1], canvas.shape[1])
-
-        canvas[tx:x_end, ty:y_end] += scaled_sprite[:x_end-tx, :y_end-ty]
-
-#def visualize_canvas(canvas):
-#    plt.imshow(canvas, cmap='gray')
-#    plt.show()
-
-def mk_vs(N, nfeats = 1000):
-    from . import fourier as f
-    assert not N % 2
-    canvas = create_canvas(N)
-    sprite = create_sprite()
-    add_sprite_to_canvas(canvas, sprite, nfeats)
-    res = canvas[..., None]
-    res = f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-    return res / res.max()
-#    res = np.zeros((N, N, 1))
-#    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-#    return res
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/diffsim.py b/build/lib/build/lib/build/lib/build/lib/ptycho/diffsim.py
deleted file mode 100644
index be005a6..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/diffsim.py
+++ /dev/null
@@ -1,234 +0,0 @@
-from skimage import draw, morphology
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import matplotlib.pyplot as plt
-import numpy as np
-import tensorflow as tf
-
-from . import fourier as f
-from . import tf_helper as hh
-from . import params as p
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-
-N = 64
-
-def observe_amplitude(amplitude):
-    """
-    Sample photons from wave amplitudes by drwaing from the corresponding Poisson distributions
-    """
-    return tf.sqrt((hh.tfd.Independent(hh.tfd.Poisson(amplitude**2))).sample())# + 0.5
-
-def count_photons(obj):
-    return tf.math.reduce_sum(obj**2, (1, 2))
-
-def scale_nphotons(padded_obj):
-    """
-    Calculate the object amplitude normalization factor that gives the desired
-    *expected* number of observed photons, averaged over an entire dataset.
-
-    Returns a single scalar.
-    """
-    mean_photons = tf.math.reduce_mean(count_photons(padded_obj))
-    norm = tf.math.sqrt(p.get('nphotons') / mean_photons)
-    return norm
-
-def diffract_obj(sample, draw_poisson = True):
-    N = p.get('N')
-    amplitude = hh.pad_and_diffract(sample, N, N, pad=False)[1]
-    if draw_poisson:
-        observed_amp = observe_amplitude(amplitude)
-        return observed_amp
-    else:
-        return amplitude
-
-def illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = None):
-    """
-    Illuminate object with real or complex probe, then apply diffraction map.
-
-    Returned Y_I and Y_phi are amplitude and phase *after* illumination with the
-    probe.
-    """
-    # ensure probe is broadcastable
-    if len(probe.shape) == 2:
-        assert probe.shape[0] == probe.shape[1]
-        probe = probe[..., None]
-    elif len(probe.shape) == 3:
-        assert probe.shape[-1] == 1
-    if intensity_scale is None:
-        probe_amplitude = tf.cast(tf.abs(probe), Y_I.dtype)
-        intensity_scale = scale_nphotons(Y_I * probe_amplitude[None, ...]).numpy()
-    batch_size = p.get('batch_size')
-    obj = intensity_scale * hh.combine_complex(Y_I, Y_phi)
-    obj = obj * tf.cast(probe[None, ...], obj.dtype)
-    Y_I = tf.math.abs(obj)
-
-    X = (tf.data.Dataset.from_tensor_slices(obj)
-               .batch(batch_size)
-               .prefetch(tf.data.AUTOTUNE)
-               .map(diffract_obj)
-               .cache())
-    X = np.vstack(list(iter(X)))
-    X, Y_I, Y_phi =\
-        X / intensity_scale, Y_I / intensity_scale, Y_phi
-
-    X, Y_I, Y_phi =\
-        hh.togrid(X, Y_I, Y_phi)
-
-    X, Y_I, Y_phi =\
-        hh.grid_to_channel(X, Y_I, Y_phi)
-
-    return X, Y_I, Y_phi, intensity_scale
-
-def mk_rand(N):
-    return int(N * np.random.uniform())
-
-def mk_lines_img(N = 64, nlines = 10):
-    image = np.zeros((N, N))
-    for _ in range(nlines):
-        rr, cc = draw.line(mk_rand(N), mk_rand(N), mk_rand(N), mk_rand(N))
-        image[rr, cc] = 1
-    res = np.zeros((N, N, 3))
-    res[:, :, :] = image[..., None]
-    return f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-
-def mk_noise(N = 64, nlines = 10):
-    return np.random.uniform(size = N * N).reshape((N, N, 1))
-
-from ptycho.misc import memoize_disk_and_memory
-
-def extract_coords(size, repeats = 1, coord_type = 'offsets',
-        outer_offset = None, **kwargs):
-    """
-    Return nominal offset coords in channel format. x and y offsets are
-    stacked in the third dimension.
-
-    offset coordinates are r - r', where
-        r' is the patch center of mass
-        r is the center of mass of that patch's solution region / grid,
-            which contains gridsize**2 patches
-    """
-    x = tf.range(size, dtype = tf.float32)
-    y = tf.range(size, dtype = tf.float32)
-    xx, yy = tf.meshgrid(x, y)
-    xx = xx[None, ..., None]
-    yy = yy[None, ..., None]
-    def _extract_coords(zz, fn):
-        ix = fn(zz)
-        ix = tf.reduce_mean(ix, axis = (1, 2))
-        return tf.repeat(ix, repeats, axis = 0)[:, None, None, :]
-    def outer(img):
-        return hh.extract_outer(img, fmt = 'grid', outer_offset = outer_offset)
-    def inner(img):
-        return hh.extract_nested_patches(img, fmt = 'channel',
-            outer_offset = outer_offset)
-    def get_patch_offsets(coords):
-        offsets_x = coords[1][0] - coords[0][0]
-        offsets_y = coords[1][1] - coords[0][1]
-        return tf.stack([offsets_x, offsets_y], axis = 2)[:, :, :, 0, :]
-    ix = _extract_coords(xx, inner)
-    iy = _extract_coords(yy, inner)
-    ix_offsets = _extract_coords(xx, outer)
-    iy_offsets = _extract_coords(yy, outer)
-    coords = ((ix, iy), (ix_offsets, iy_offsets))
-    if coord_type == 'offsets':
-        return get_patch_offsets(coords)
-    elif coord_type == 'global':
-        return (ix, iy)
-    else:
-        raise ValueError
-
-def add_position_jitter(coords, jitter_scale):
-    shape = coords.shape
-    jitter = jitter_scale * tf.random.normal(shape)
-    return jitter + coords
-
-def scan_and_normalize(jitter_scale = None, YY_I = None, YY_phi = None,
-        **kwargs):
-    """
-    Inputs:
-    4d tensors of full (arbitrary-sized) object phase and amplitude.
-
-    Returns (normalized) amplitude and phase and scan point offsets.
-
-    coords: tuple of two tuples. First gives center coords for each
-    small image patch. Second gives offset coords for each solution
-    region.
-    """
-    size = YY_I.shape[1]
-    n = YY_I.shape[0]
-    coords = true_coords = extract_coords(size, n, **kwargs)
-    if jitter_scale is not None:
-        print('simulating gaussian position jitter, scale', jitter_scale)
-        true_coords = add_position_jitter(coords, jitter_scale)
-
-    Y_I, Y_phi, _Y_I_full, norm_Y_I = hh.preprocess_objects(YY_I,
-        offsets_xy = true_coords, Y_phi = YY_phi, **kwargs)
-    return Y_I, Y_phi, _Y_I_full, norm_Y_I, (coords, true_coords)
-
-import math
-def dummy_phi(Y_I):
-    return tf.cast(tf.constant(math.pi), tf.float32) *\
-        tf.cast(tf.math.tanh( (Y_I - tf.math.reduce_max(Y_I) / 2) /
-            (3 * tf.math.reduce_mean(Y_I))), tf.float32)
-
-def sim_object_image(size, which = 'train'):
-    if p.get('data_source') == 'lines':
-        return mk_lines_img(2 * size, nlines = 400)[size // 2: -size // 2, size // 2: -size // 2, :1]
-    elif p.get('data_source') == 'grf':
-        from .datagen import grf
-        return grf.mk_grf(size)
-    elif p.get('data_source') == 'points':
-        from .datagen import points
-        return points.mk_points(size)
-    elif p.get('data_source') == 'testimg':
-        from .datagen import testimg
-        if which == 'train':
-            return testimg.get_img(size)
-        elif which == 'test':
-            return testimg.get_img(size, reverse = True)
-        else:
-            raise ValueError
-    elif p.get('data_source') == 'testimg_reverse':
-        from .datagen import testimg
-        return testimg.get_img(size, reverse = True)
-    elif p.get('data_source') == 'diagonals':
-        from .datagen import diagonals
-        return diagonals.mk_diags(size)
-    elif p.get('data_source') == 'V':
-        from .datagen import vendetta
-        return vendetta.mk_vs(size)
-    else:
-        raise ValueError
-
-@memoize_disk_and_memory
-def mk_simdata(n, size, probe, outer_offset, intensity_scale = None,
-        YY_I = None, YY_phi = None, dict_fmt = False,  which = 'train', **kwargs):
-    if YY_I is None:
-        YY_I = np.array([sim_object_image(size, which = which)
-              for _ in range(n)])
-    if p.get('set_phi') and YY_phi is None:
-        YY_phi = dummy_phi(YY_I)
-    Y_I, Y_phi, _, norm_Y_I, coords = scan_and_normalize(YY_I = YY_I,
-        YY_phi = YY_phi, outer_offset = outer_offset, **kwargs)
-    if dict_fmt:
-        d = dict()
-        d['I_pre_probe'] = Y_I
-        d['phi_pre_probe'] = Y_phi
-    X, Y_I, Y_phi, intensity_scale =\
-        illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = intensity_scale)
-    if YY_phi is None:
-        YY_full = hh.combine_complex(YY_I, tf.zeros_like(YY_I))
-    else:
-        YY_full = hh.combine_complex(YY_I, YY_phi)
-    if dict_fmt:
-        d['X'] = X
-        d['Y_I'] = Y_I
-        d['Y_phi'] = Y_phi
-        d['intensity_scale'] = intensity_scale
-        d['norm_Y_I'] = norm_Y_I
-        d['coords'] = coords
-        return d
-    return X, Y_I, Y_phi, intensity_scale, YY_full,\
-        norm_Y_I, coords
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/evaluation.py b/build/lib/build/lib/build/lib/build/lib/ptycho/evaluation.py
deleted file mode 100644
index 51274e4..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/evaluation.py
+++ /dev/null
@@ -1,275 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib
-import tensorflow as tf
-
-from ptycho import params
-from ptycho import misc
-
-def recon_patches(patches):
-    """
-    chop channel dimension size to 1, then patch together a single image
-    """
-    from ptycho import generate_data as data
-    return data.reassemble(patches[:, :, :, :1])[0]
-
-def symmetrize(arr):
-    return (arr + arr[::-1, ::-1]) / 2
-
-def symmetrize_3d(arr):
-    return (arr + arr[:, ::-1, ::-1]) / 2
-
-def cropshow(arr, *args, crop = True, **kwargs):
-    if crop:
-        arr = arr[16:-16, 16:-16]
-    plt.imshow(arr, *args, **kwargs)
-
-from scipy.ndimage import gaussian_filter as gf
-
-def summarize(i, a, b, X_test, Y_I_test, Y_phi_test, probe, channel = 0, **kwargs):
-    from . import params as cfg
-    plt.rcParams["figure.figsize"] = (10, 10)
-    vmin = 0
-    vmax = np.absolute(b)[i].max()
-
-    heatmaps = {}  # initialize the dictionary to store the heatmaps
-    probe = np.absolute(probe)
-    aa, bb = 3, 3
-    plt.subplot(aa, bb, 1)
-    plt.title('True amp.\n(illuminated)')
-    true_amp_illuminated = (Y_I_test[i, :, :, channel])
-    cropshow(true_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_illuminated'] = true_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 2)
-    plt.title('Reconstructed amp.\n(illuminated)')
-    rec_amp_illuminated = (np.absolute(b))[i] * probe[..., None]
-    cropshow(rec_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_illuminated'] = rec_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 3)
-    plt.title('True phase')
-    true_phase = ((Y_phi_test * (probe > .01)[..., None]))[i, :, :, channel]
-    cropshow(true_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['true_phase'] = true_phase  # add to the dictionary
-
-    plt.subplot(aa, bb, 4)
-    plt.title('True amp.\n(full)')
-    true_amp_full = (Y_I_test[i, :, :, channel] / (probe + 1e-9))
-    cropshow(true_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_full'] = true_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 5)
-    plt.title('Reconstructed amp. (full)')
-    rec_amp_full = (np.absolute(b))[i]
-    cropshow(rec_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_full'] = rec_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 6)
-    plt.title('Reconstructed phase')
-    rec_phase = (np.angle(b) * (probe > .01)[..., None])[i]
-    rec_phase[np.isclose(rec_phase,  0)] = np.nan
-    cropshow(rec_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['rec_phase'] = rec_phase  # add to the dictionary
-    print('phase min:', np.min((np.angle(b) * (probe > .01)[..., None])),
-        'phase max:', np.max((np.angle(b) * (probe > .01)[..., None])))
-
-    plt.subplot(aa, bb, 7)
-    plt.title('True diffraction')
-    true_diffraction = np.log(cfg.get('intensity_scale') * X_test)[i, :, :, channel]
-    plt.imshow(true_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['true_diffraction'] = true_diffraction  # add to the dictionary
-
-    plt.subplot(aa, bb, 8)
-    plt.title('Recon diffraction')
-    rec_diffraction = np.log(a)[i, :, :, channel]
-    plt.imshow(rec_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['rec_diffraction'] = rec_diffraction  # add to the dictionary
-
-    return heatmaps
-
-def plt_metrics(history, loss_type = 'MAE', metric2 = 'padded_obj_loss'):
-    hist=history
-    epochs=np.asarray(history.epoch)+1
-
-    plt.style.use('seaborn-white')
-    matplotlib.rc('font',family='Times New Roman')
-    matplotlib.rcParams['font.size'] = 12
-
-    f, axarr = plt.subplots(2, sharex=True, figsize=(12, 8))
-
-    axarr[0].set(ylabel='Loss')
-    axarr[0].plot(epochs,hist.history['loss'], 'C3o', label='Diffraction {} Training'.format(loss_type))
-    axarr[0].plot(epochs,hist.history['val_loss'], 'C3-', label='Diffraction {} Validation'.format(loss_type))
-    axarr[0].grid()
-    axarr[0].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-
-    axarr[1].set(ylabel='Loss')
-    axarr[1].plot(epochs,hist.history[metric2], 'C0o', label='Object {} Training'.format(loss_type))
-    axarr[1].plot(epochs,hist.history['val_' + metric2], 'C0-', label='Object {} Validation'.format(loss_type))
-    axarr[1].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-    plt.xlabel('Epochs')
-    plt.tight_layout()
-    #plt.semilogy()
-    axarr[1].grid()
-
-import scipy.fftpack as fftpack
-fp = fftpack
-
-def trim(arr2d):
-    offset = params.get('offset')
-    assert not (offset % 2)
-    return arr2d[offset // 2:-offset // 2, offset // 2:-offset // 2]
-
-def mae(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean(np.absolute(target - scale * pred))
-
-def mse(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean((target - scale * pred)**2)
-
-def psnr(target, pred, normalize = True, shift = False):
-    """
-    for phase inputs, assume that global shift has already been taken care off
-    """
-    import cv2
-    target = np.array(target)
-    pred = np.array(pred)
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    if shift:
-        offset = min(np.min(target), np.min(pred))
-        target = target - offset
-        pred = pred - offset
-    pred = scale * pred
-    return cv2.PSNR(target, pred)
-
-def fft2d(aphi):
-    F1 = fftpack.fft2((aphi).astype(float))
-    F2 = fftpack.fftshift(F1)
-    return F2
-
-def highpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-
-    F2[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 0
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def lowpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-    mask = np.zeros_like(F2)
-    mask[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 1.
-    F2 = F2 * mask
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def frc50(target, pred, sigma = 1):
-    if np.isnan(pred).all():
-        raise ValueError
-    if np.max(target) == np.min(target) == 0:
-        return None, np.nan
-    from FRC import fourier_ring_corr as frc
-    shellcorr = frc.FSC(np.array(target), np.array(pred))
-    shellcorr = gf(shellcorr, sigma)
-    return shellcorr, np.where(shellcorr < .5)[0][0]
-
-
-
-def eval_reconstruction(stitched_obj, ground_truth_obj, lowpass_n = 1,
-        label = ''):
-    # TODO consistent shapes
-    assert stitched_obj.shape[1] == ground_truth_obj.shape[1]
-    assert np.ndim(ground_truth_obj) == 3
-    assert int(np.ndim(stitched_obj)) in [3, 4]
-    if np.ndim(stitched_obj) == 4:
-        stitched_obj = stitched_obj[0]
-    YY_ground_truth = np.absolute(ground_truth_obj)
-    YY_phi_ground_truth = np.angle(ground_truth_obj)
-
-    phi_pred = trim(
-        highpass2d(
-            np.squeeze(np.angle(stitched_obj)), n = lowpass_n
-        )
-    )
-    phi_target = trim(
-        highpass2d(
-            np.squeeze(YY_phi_ground_truth), n = lowpass_n
-        )
-    )
-    amp_target = tf.cast(trim(YY_ground_truth), tf.float32)
-    amp_pred = trim(np.absolute(stitched_obj))
-
-    # TODO complex FRC?
-    mae_amp = mae(amp_target, amp_pred) # PINN
-    mse_amp = mse(amp_target, amp_pred) # PINN
-    psnr_amp = psnr(amp_target[:, :, 0], amp_pred[:, :, 0], normalize = True,
-        shift = False)
-    frc_amp, frc50_amp = frc50(amp_target[:, :, 0], amp_pred[:, :, 0])
-
-    mae_phi = mae(phi_target, phi_pred, normalize=False) # PINN
-    mse_phi = mse(phi_target, phi_pred, normalize=False) # PINN
-    psnr_phi = psnr(phi_target, phi_pred, normalize = False, shift = True)
-    frc_phi, frc50_phi = frc50(phi_target, phi_pred)
-
-    return {'mae': (mae_amp, mae_phi),
-        'mse': (mse_amp, mse_phi),
-        'psnr': (psnr_amp, psnr_phi),
-        'frc50': (frc50_amp, frc50_phi),
-        'frc': (frc_amp, frc_phi)}
-
-
-import pandas as pd
-import os
-import dill
-def save_metrics(stitched_obj, YY_ground_truth,  label = ''):
-    """
-    evaluate reconstruction and save the result to disk.
-    """
-    out_prefix = misc.get_path_prefix()
-    os.makedirs(out_prefix, exist_ok=True)
-    metrics = eval_reconstruction(stitched_obj, YY_ground_truth, label = label)
-    metrics['label'] = label
-    d = {**params.cfg, **metrics}
-    with open(out_prefix + '/params.dill', 'wb') as f:
-        dill.dump(d, f)
-    df = pd.DataFrame({k: d[k] for k in ['mae', 'mse', 'psnr', 'frc50']})
-    df.to_csv(out_prefix + '/metrics.csv')
-    return {k: metrics[k] for k in ['mae', 'mse', 'psnr', 'frc50', 'frc']}
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/experimental.py b/build/lib/build/lib/build/lib/build/lib/ptycho/experimental.py
deleted file mode 100644
index adbb619..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/experimental.py
+++ /dev/null
@@ -1,116 +0,0 @@
-from skimage.transform import resize
-from tqdm.notebook import tqdm as tqdm
-import matplotlib.pyplot as plt
-import numpy as np
-import scipy.signal
-import sys
-
-from . import tf_helper as hh
-
-path = '.'
-
-sys.path.append(path)
-sys.path.append('PtychoNN/TF2/')
-
-N = 64
-### Read experimental diffraction data and reconstructed images
-
-data_diffr = np.load(path+'/PtychoNN/data/20191008_39_diff.npz')['arr_0']
-data_diffr.shape
-
-data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)
-for i in tqdm(range(data_diffr.shape[0])):
-    for j in range(data_diffr.shape[1]):
-        data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)
-        data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])
-
-real_space = np.load(path+'/PtychoNN/data/20191008_39_amp_pha_10nm_full.npy')
-amp = np.abs(real_space)
-ph = np.angle(real_space)
-amp.shape
-
-### Split data and then shuffle
-
-nlines = 100 #How many lines of data to use for training?
-nltest = 60 #How many lines for the test set?
-tst_strt = amp.shape[0]-nltest #Where to index from
-print(tst_strt)
-train_size = 272
-test_size = 248
-
-def stack(a1, a2):
-    return np.array((a1, a2)).reshape((-1, N, N, 1))
-
-def augment_inversion(Y_I_train, Y_phi_train):
-    phi = stack(Y_phi_train, -Y_phi_train)
-    return stack(Y_I_train, Y_I_train[:, ::-1, ::-1, :]), stack(Y_phi_train, -Y_phi_train)
-
-def reconstruct_object(data4d, scan_grid_offset):
-    """
-    Given a 4d object patches, reconstruct the whole object
-    """
-    return hh.extract_patches_inverse(
-       data4d.reshape((data4d.shape[0], data4d.shape[1], -1))[None, ...],
-       N, True, gridsize = data4d.shape[0],
-       offset = scan_grid_offset)
-
-from ptycho.misc import memoize_disk_and_memory
-@memoize_disk_and_memory
-def get_full_experimental(which):
-    """
-    Returns (normalized) amplitude and phase for n generated objects
-    """
-    inverted_patches_I = reconstruct_object(amp, offset_experimental)
-    inverted_patches_phi = reconstruct_object(ph, offset_experimental)
-    print('GROUND TRUTH FULL SHAPE:', inverted_patches_I.shape)
-    if which == 'train':
-        YY_I = inverted_patches_I[:, :train_size, :train_size, :]
-        YY_phi = inverted_patches_phi[:, :train_size, :train_size, :]
-    elif which == 'test':
-        YY_I = inverted_patches_I[:, -test_size:, -test_size:, :]
-        YY_phi = inverted_patches_phi[:, -test_size:, -test_size:, :]
-    else:
-        raise ValueError
-    return YY_I, YY_phi
-
-
-X_train = data_diffr_red[:nlines,:].reshape(-1,N,N)[:,:,:,np.newaxis]
-X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,N,N)[:,:,:,np.newaxis]
-Y_I_train = amp[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_I_test = amp[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_train = ph[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_test = ph[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-
-ntrain = X_train.shape[0]*X_train.shape[1]
-ntest = X_test.shape[0]*X_test.shape[1]
-
-print(X_train.shape, X_test.shape)
-
-
-tmp1, tmp2 = Y_I_train, Y_I_test
-
-img = np.zeros((544, 544), dtype = 'float32')[None, ..., None]
-offset_experimental = 3
-
-## Recover shift between scan points
-def cross_image(im1, im2):
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
-
-cross = cross_image(amp[0, 0], amp[1, 0])
-ref = cross_image(amp[0, 0], amp[0, 0])
-
-cmax = lambda cross: np.array(np.where(cross.ravel()[np.argmax(cross)] == cross))
-
-plt.imshow(cross)
-
-cmax(cross), cmax(cross) - cmax(ref)
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/export.py b/build/lib/build/lib/build/lib/build/lib/ptycho/export.py
deleted file mode 100644
index ba05094..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/export.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import dill
-import matplotlib.pyplot as plt
-import numpy as np
-from ptycho.misc import get_path_prefix
-from ptycho.params import get
-
-def save_recons(model_type, stitched_obj):
-    from ptycho.generate_data import YY_ground_truth
-    from ptycho.evaluation import save_metrics
-    try:
-        out_prefix = get('output_prefix')
-        if YY_ground_truth is not None:
-            plt.imsave(out_prefix + 'amp_orig.png',
-                       np.absolute(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-            plt.imsave(out_prefix + 'phi_orig.png',
-                       np.angle(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-        if stitched_obj is not None:
-            plt.imsave(out_prefix + 'amp_recon.png', np.absolute(stitched_obj[0][:, :, 0]), cmap='jet')
-            plt.imsave(out_prefix + 'phi_recon.png', np.angle(stitched_obj[0][:, :, 0]), cmap='jet')
-
-        with open(out_prefix + '/recon.dill', 'wb') as f:
-            dump_data = {'stitched_obj_amp': np.absolute(stitched_obj[0][:, :, 0] if stitched_obj is not None else np.array([])),
-                         'stitched_obj_phase': np.angle(stitched_obj[0][:, :, 0]) if stitched_obj is not None else np.array([])}
-            if YY_ground_truth is not None:
-                dump_data.update({'YY_ground_truth_amp': np.absolute(YY_ground_truth[:, :, 0]),
-                                  'YY_ground_truth_phi': np.angle(YY_ground_truth[:, :, 0])})
-            dill.dump(dump_data, f)
-        if YY_ground_truth is not None and stitched_obj is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth or stitched_obj is None, metrics cannot be calculated.'}
-
-        if YY_ground_truth is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth is None, metrics cannot be calculated.'}
-        return d
-    except ImportError as e:
-        print('object stitching failed. No images will be saved.')
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/fourier.py b/build/lib/build/lib/build/lib/build/lib/ptycho/fourier.py
deleted file mode 100644
index 1cf06f5..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/fourier.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import pandas as pd
-import numpy as np
-
-from scipy.fft import fft, fftfreq, ifft, fft2, ifft2, ifftshift
-import matplotlib.pyplot as plt
-from scipy.fftpack import fft, fftshift
-from scipy.signal import butter
-from scipy import signal
-from scipy.signal import convolve2d as conv2
-
-from skimage import color, data, restoration
-from scipy.ndimage import gaussian_filter as gf
-
-def plot_df(*args):
-    df = pd.DataFrame([p for p, _ in args]).T
-    df.columns = [l for _, l in args ]
-    return df.plot()
-
-def lowpass_g(size, y, sym = False):
-    from scipy.signal.windows import gaussian
-    L = gaussian(len(y), std = len(y) / (size * np.pi**2), sym = sym)
-    L /= L.max()
-    return L
-
-def highpass_g(size, y):
-    return 1 - lowpass_g(size, y)
-
-def bandpass_g(L, H, y):
-    L = lowpass_g(L, y)
-    H = highpass_g(H, y)
-    return L * H
-
-def clip_high(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    x2[(N - nz) // 2 : (N + nz) // 2] = 0
-    #x2[(-nz) // 2:] = 0
-    return x2
-
-def clip_low(x, frac_zero, invert = False):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    mask = np.ones_like(x)
-    mask[:( nz) // 2 ] = 0
-    mask[(-nz) // 2:] = 0
-    if invert:
-        mask = 1 - mask
-    x2 = x2 * mask
-
-#     x2[:( nz) // 2 ] = 0
-#     x2[(-nz) // 2:] = 0
-    return x2, mask
-
-def clip_low_window(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = np.ones_like(x)
-    x2[:( nz) // 2 ] = 0
-    x2[(-nz) // 2:] = 0
-    return x2
-
-def if_mag(arr, phase = 0, truncate = False, toreal = 'psd', **kwargs):
-    #print("arr shape", arr.shape)
-    #trunc = len(arr) - unpadded_length
-    phase = np.exp(1j * phase)
-    tmp = ifft(arr)
-    if toreal == 'psd':
-        real = np.real(np.sqrt(np.conjugate(tmp) * tmp))
-    elif toreal == 'real':
-        real = np.real(tmp)
-    else:
-        raise ValueError
-    if truncate:
-        raise NotImplementedError
-        #return real[trunc // 2: -trunc // 2]
-    return real
-
-def power(arr):
-    ampsq = arr * np.conjugate(arr)
-    return np.real(ampsq)
-
-def mag(x):
-    return np.sqrt(power(x))
-
-def lorenz(gamma, x, x0):
-    return ( 1. / (np.pi * gamma)) * (gamma**2) / ((x - x0)**2 + gamma**2)
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/generate_data.py b/build/lib/build/lib/build/lib/build/lib/ptycho/generate_data.py
deleted file mode 100644
index 21c4079..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/generate_data.py
+++ /dev/null
@@ -1,11 +0,0 @@
-import numpy as np
-from .data_preprocessing import generate_data
-from . import params as p
-
-# TODO passing the probe should be mandatory, to enforce side-effect free behavior.
-def main(probeGuess = None):
-    X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = generate_data(probeGuess)
-    print(np.linalg.norm(ptycho_dataset.train_data.X[0]) / np.linalg.norm(np.abs(ptycho_dataset.train_data.Y[0])))
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
-X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = main(probeGuess = p.get('probe'))
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/image/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/image/__init__.py
deleted file mode 100644
index 48b86dc..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/image/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .stitching import stitch_patches, reassemble_patches
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/image/stitching.py b/build/lib/build/lib/build/lib/build/lib/ptycho/image/stitching.py
deleted file mode 100644
index 9b26c64..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/image/stitching.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, config, *, 
-                  norm_Y_I: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # Get N from config at the start
-    N = config['N']
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        N = config['N']
-        gridsize = config['gridsize']
-        offset = config['offset']
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    outer_offset = config.get('outer_offset_test', config['offset'])
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / config['nimgs_test']) / (config['N']**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-def reassemble_patches(patches, config, *, norm_Y_I=1., part='amp', norm=False):
-    """
-    High-level convenience function for stitching patches using config parameters.
-    
-    Args:
-        patches: Patches to reassemble
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        part: Which part to extract (default: 'amp')
-        norm: Whether to normalize (default: False)
-    """
-    return stitch_patches(
-        patches,
-        config,
-        norm_Y_I=norm_Y_I,
-        norm=norm,
-        part=part
-    )
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/inference.py b/build/lib/build/lib/build/lib/build/lib/ptycho/inference.py
deleted file mode 100644
index be7ef91..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/inference.py
+++ /dev/null
@@ -1,63 +0,0 @@
-from ptycho.model_manager import ModelManager
-from tensorflow.keras.models import Model
-from ptycho import params
-from ptycho.loader import PtychoDataContainer
-import numpy as np
-
-# TODO this module is for inference-only workflows. it needs to be consolidated with train_pinn
-
-def load_pretrained_model(model_path: str) -> Model:
-    """
-    Load a pre-trained model from an H5 file.
-    """
-    model = ModelManager.load_model(model_path)
-    return model
-
-def prepare_data(data_container: PtychoDataContainer) -> tuple:
-    """
-    Prepare data for inference.
-    """
-    from ptycho import model
-    X = data_container.X * model.params()['intensity_scale']
-    coords_nominal = data_container.coords_nominal
-    return X, coords_nominal
-
-def perform_inference(model: Model, X: np.ndarray, coords_nominal: np.ndarray) -> dict:
-    """
-    Perform inference using the pre-trained model and prepared data.
-    """
-    from ptycho import model
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = model.predict([X, coords_nominal])
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi
-    }
-
-def inference_flow(model_path: str, data_container: PtychoDataContainer) -> dict:
-    """
-    The main flow for model inference, integrating the steps.
-    """
-    pre_trained_model = load_pretrained_model(model_path or params.get('h5_path'))
-    X, coords_nominal = prepare_data(data_container)
-    inference_results = perform_inference(pre_trained_model, X, coords_nominal)
-    return inference_results
-
-# Example usage
-# model_path = 'path/to/model.h5'
-# data_container = PtychoDataContainer(...)
-# results = inference_flow(model_path, data_container)
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def reassemble_with_config(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/loader.py b/build/lib/build/lib/build/lib/build/lib/ptycho/loader.py
deleted file mode 100644
index b1421e4..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/loader.py
+++ /dev/null
@@ -1,318 +0,0 @@
-"""Generic loader for datasets with non-rectangular scan point patterns."""
-
-import numpy as np
-import tensorflow as tf
-from typing import Callable
-
-from .params import params, get
-from .autotest.debug import debug
-from . import diffsim as datasets
-from . import tf_helper as hh
-from .raw_data import RawData, key_coords_offsets, key_coords_relative 
-
-class PtychoDataset:
-    @debug
-    def __init__(self, train_data, test_data):
-        self.train_data = train_data
-        self.test_data = test_data
-
-class PtychoDataContainer:
-    """
-    A class to contain ptycho data attributes for easy access and manipulation.
-    """
-    @debug
-    def __init__(self, X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, nn_indices, global_offsets, local_offsets, probeGuess):
-        self.X = X
-        self.Y_I = Y_I
-        self.Y_phi = Y_phi
-        self.norm_Y_I = norm_Y_I
-        self.YY_full = YY_full
-        self.coords_nominal = coords_nominal
-        self.coords = coords_nominal
-        self.coords_true = coords_true
-        self.nn_indices = nn_indices
-        self.global_offsets = global_offsets
-        self.local_offsets = local_offsets
-        self.probe = probeGuess
-
-        from .tf_helper import combine_complex
-        self.Y = combine_complex(Y_I, Y_phi)
-
-    @debug
-    def __repr__(self):
-        repr_str = '<PtychoDataContainer'
-        for attr_name in ['X', 'Y_I', 'Y_phi', 'norm_Y_I', 'YY_full', 'coords_nominal', 'coords_true', 'nn_indices', 'global_offsets', 'local_offsets', 'probe']:
-            attr = getattr(self, attr_name)
-            if attr is not None:
-                if isinstance(attr, np.ndarray):
-                    if np.iscomplexobj(attr):
-                        repr_str += f' {attr_name}={attr.shape} mean_amplitude={np.mean(np.abs(attr)):.3f}'
-                    else:
-                        repr_str += f' {attr_name}={attr.shape} mean={attr.mean():.3f}'
-                else:
-                    repr_str += f' {attr_name}={attr.shape}'
-        repr_str += '>'
-        return repr_str
-
-    @staticmethod
-    @debug
-    def from_raw_data_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess=None, N=None, K=7, nsamples=1):
-        """
-        Static method constructor that composes a call to RawData.from_coords_without_pc() and loader.load,
-        then initializes attributes.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-            N (int, optional): The size of the image. Defaults to None.
-            K (int, optional): The number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): The number of samples. Defaults to 1.
-
-        Returns:
-            PtychoDataContainer: An instance of the PtychoDataContainer class.
-        """
-        from . import params as cfg
-        if N is None:
-            N = cfg.get('N')
-        train_raw = RawData.from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-        
-        dset_train = train_raw.generate_grouped_data(N, K=K, nsamples=nsamples)
-
-        # Use loader.load() to handle the conversion to PtychoData
-        return load(lambda: dset_train, probeGuess, which=None, create_split=False)
-
-    #@debug
-    def to_npz(self, file_path: str) -> None:
-        """
-        Write the underlying arrays to an npz file.
-
-        Args:
-            file_path (str): Path to the output npz file.
-        """
-        np.savez(
-            file_path,
-            X=self.X.numpy() if tf.is_tensor(self.X) else self.X,
-            Y_I=self.Y_I.numpy() if tf.is_tensor(self.Y_I) else self.Y_I,
-            Y_phi=self.Y_phi.numpy() if tf.is_tensor(self.Y_phi) else self.Y_phi,
-            norm_Y_I=self.norm_Y_I,
-            YY_full=self.YY_full,
-            coords_nominal=self.coords_nominal.numpy() if tf.is_tensor(self.coords_nominal) else self.coords_nominal,
-            coords_true=self.coords_true.numpy() if tf.is_tensor(self.coords_true) else self.coords_true,
-            nn_indices=self.nn_indices,
-            global_offsets=self.global_offsets,
-            local_offsets=self.local_offsets,
-            probe=self.probe.numpy() if tf.is_tensor(self.probe) else self.probe
-        )
-
-    # TODO is this deprecated, given the above method to_npz()?
-
-@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset['coords_offsets']
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset['coords_relative']
-    coords_true = dset['coords_relative']
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    Y = tf.ones_like(X)
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-@debug
-def split_data(X_full, coords_nominal, coords_true, train_frac, which):
-    """
-    Splits the data into training and testing sets based on the specified fraction.
-
-    Args:
-        X_full (np.ndarray): The full dataset to be split.
-        coords_nominal (np.ndarray): The nominal coordinates associated with the dataset.
-        coords_true (np.ndarray): The true coordinates associated with the dataset.
-        train_frac (float): The fraction of the dataset to be used for training.
-        which (str): A string indicating whether to return the 'train' or 'test' split.
-
-    Returns:
-        tuple: A tuple containing the split data and coordinates.
-    """
-    n_train = int(len(X_full) * train_frac)
-    if which == 'train':
-        return X_full[:n_train], coords_nominal[:n_train], coords_true[:n_train]
-    elif which == 'test':
-        return X_full[n_train:], coords_nominal[n_train:], coords_true[n_train:]
-    else:
-        raise ValueError("Invalid split type specified: must be 'train' or 'test'.")
-
-@debug
-def split_tensor(tensor, frac, which='test'):
-    """
-    Splits a tensor into training and test portions based on the specified fraction.
-
-    :param tensor: The tensor to split.
-    :param frac: Fraction of the data to be used for training.
-    :param which: Specifies whether to return the training ('train') or test ('test') portion.
-    :return: The appropriate portion of the tensor based on the specified fraction and 'which' parameter.
-    """
-    n_train = int(len(tensor) * frac)
-    return tensor[:n_train] if which == 'train' else tensor[n_train:]
-
-# TODO this should be a method of PtychoDataContainer
-#@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset[key_coords_offsets]
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset[key_coords_relative]
-    coords_true = dset[key_coords_relative]
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-#    try:
-#        Y = get_image_patches(gt_image, global_offsets, coords_true) * cfg.get('probe_mask')[..., 0]
-#    except:
-#        Y = tf.zeros_like(X)
-
-    norm_Y_I = datasets.scale_nphotons(X)
-
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    # TODO we shouldn't be nuking the ground truth
-##    try:
-#    if dset['Y'] is None:
-#        Y = get_image_patches(gt_image,
-#            global_offsets, coords_true) * probe.get_probe_mask_real(cfg.get('N'))
-#        print("loader: generating ground truth patches from image and offsets")
-#    else:
-#        Y = dset['Y']
-#        print("loader: using provided ground truth patches")
-    if dset['Y'] is None:
-        Y = tf.ones_like(X)
-        print("loader: setting dummy Y ground truth")
-    else:
-        Y = dset['Y']
-        print("loader: using provided ground truth patches")
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    # TODO this should be baked into the model pipeline. If we can
-    # assume consistent normalization, we can get rid of intensity_scale
-    # as a model parameter since the post normalization average L2 norm
-    # will be fixed. Normalizing in the model's dataloader will make
-    # things more self-contained and avoid the need for separately
-    # scaling simulated datasets. While we're at it we should get rid of
-    # all the unecessary multiiplying and dividing by intensity_scale.
-    # As long as nphotons is a dataset-level attribute (i.e. an attribute of RawData 
-    # and PtychoDataContainer), nothing is lost
-    # by keeping the diffraction in normalized format everywhere except
-    # before the Poisson NLL calculation in model.py.
-
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    #print('X NORM', X_full_norm)
-    return X_full_norm * X_full
-
-#@debug
-def crop(arr2d, size):
-    N, M = arr2d.shape
-    return arr2d[N // 2 - (size) // 2: N // 2+ (size) // 2, N // 2 - (size) // 2: N // 2 + (size) // 2]
-
-@debug
-def get_gt_patch(offset, N, gt_image):
-    from . import tf_helper as hh
-    return crop(
-        hh.translate(gt_image, offset),
-        N // 2)
-
-def load_xpp_npz(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                                 diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                       xcoords_start[:train_size], ycoords_start[:train_size],
-                                       diff3d[:train_size], probeGuess,
-                                       scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/logging.py b/build/lib/build/lib/build/lib/build/lib/ptycho/logging.py
deleted file mode 100644
index d9ca4fe..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/logging.py
+++ /dev/null
@@ -1,315 +0,0 @@
-"""
-Module for logging and inspecting function inputs, outputs, and execution times.
-
-Provides the `debug` decorator to log function invocations, including serialized inputs,
-outputs, and execution times. Supports logging to console and disk files.
-
-Includes `load_logged_data` function to load logged data from disk for a specific invocation.
-
-Handles serialization of NumPy arrays, TensorFlow tensors, and custom objects.
-
-Logging controlled by `params.get('debug')` configuration.
-
-Key components:
-- `debug` decorator
-- `load_logged_data` function
-- Helper functions: `make_invocation_counter`, `serialize_input`
-- Custom exceptions: `SerializationError`, `LoggedDataNotFoundError`
-"""
-import functools
-import inspect
-import json
-import numpy as np
-import os
-import tensorflow as tf
-from datetime import datetime
-from typing import Any, Callable, Dict, List, Tuple
-
-import ptycho.params as params
-
-class SerializationError(Exception):
-    pass
-
-class LoggedDataNotFoundError(Exception):
-    pass
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-# TODO surround each function's output section in xml tags with the function / 
-# method path
-def debug(log_to_file: bool = True):
-    def decorator(func: Callable):
-        increment_count = make_invocation_counter()
-
-        @functools.wraps(func)
-        def wrapper(*args: Any, **kwargs: Any) -> Any:
-            if params.get('debug'):
-                invocation_count = increment_count()
-
-                if invocation_count <= 2:
-                    timestamp = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
-                    module_path = inspect.getmodule(func).__name__
-                    function_name = func.__name__
-
-                    def serialize_input(arg: Any) -> str:
-                        if isinstance(arg, np.ndarray):
-                            return f"NumPy array with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, tf.Tensor):
-                            return f"TensorFlow tensor with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, (int, float, str, bool)):
-                            return f"{type(arg).__name__} with value {arg}"
-                        else:
-                            return str(type(arg))
-
-                    serializable_inputs = {
-                        'args': [serialize_input(arg) for arg in args],
-                        'kwargs': {key: serialize_input(value) for key, value in kwargs.items()}
-                    }
-
-                    log_message = f"Calling function {function_name} in module {module_path} with inputs: {json.dumps(serializable_inputs, default=str)}"
-                    print(log_message)
-
-                    if log_to_file:
-                        log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-                        os.makedirs(log_directory, exist_ok=True)
-                        log_file_path = os.path.join(log_directory, f"{function_name}_{timestamp}.log")
-                        try:
-                            with open(log_file_path, 'w') as log_file:
-                                log_file.write(log_message + '\n')
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                    start_time = datetime.now()
-                    try:
-                        result = func(*args, **kwargs)
-                    except Exception as e:
-                        error_message = f"Error executing function {function_name} in module {module_path}: {str(e)}"
-                        print(error_message)
-                        raise e
-                    end_time = datetime.now()
-                    execution_time = end_time - start_time
-
-                    serializable_result = serialize_input(result)
-
-                    log_message = f"Function {function_name} in module {module_path} returned: {serializable_result}"
-                    print(log_message)
-                    print(f"Execution time: {execution_time}")
-
-                    if log_to_file:
-                        try:
-                            with open(log_file_path, 'a') as log_file:
-                                log_file.write(log_message + '\n')
-                                log_file.write(f"Execution time: {execution_time}\n")
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                else:
-                    result = func(*args, **kwargs)
-
-            else:
-                result = func(*args, **kwargs)
-
-            return result
-
-        return wrapper
-
-    return decorator
-
-def load_logged_data(module_path: str, function_name: str, invocation_index: int = 0) -> Tuple[Dict[str, Any], Any]:
-    log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-    log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-    log_files.sort()
-
-    if invocation_index >= len(log_files):
-        raise LoggedDataNotFoundError(f"Invocation index {invocation_index} not found for function {function_name} in module {module_path}")
-
-    log_file_path = os.path.join(log_directory, log_files[invocation_index])
-
-    try:
-        with open(log_file_path, 'r') as log_file:
-            lines = log_file.readlines()
-            inputs_line = lines[0].strip()
-            outputs_line = lines[1].strip()
-
-            inputs_start = inputs_line.find(': ') + 2
-            outputs_start = outputs_line.find(': ') + 2
-
-            inputs_json = inputs_line[inputs_start:]
-            outputs_str = outputs_line[outputs_start:]
-
-            inputs = json.loads(inputs_json)
-            outputs = outputs_str
-
-            return inputs, outputs
-    except (IOError, json.JSONDecodeError) as e:
-        raise LoggedDataNotFoundError(f"Error loading logged data for function {function_name} in module {module_path}: {str(e)}")
-
-import os
-import json
-from typing import List, Tuple, Union
-from ptycho.logging import LoggedDataNotFoundError, load_logged_data
-
-def get_type_and_dim(serialized_data: str) -> str:
-    if serialized_data.startswith("NumPy array"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"NumPy array, shape: {shape}, dtype: {dtype}"
-    elif serialized_data.startswith("TensorFlow tensor"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"TensorFlow tensor, shape: {shape}, dtype: {dtype}"
-    else:
-        return serialized_data.split(" ")[0]
-
-def process_log_file(module_path: str, function_name: str) -> None:
-    if function_name.startswith("__init__"):
-        return
-
-    invocation_index = 0
-    try:
-        inputs, outputs = load_logged_data(module_path, function_name, invocation_index)
-    except LoggedDataNotFoundError:
-        return
-
-    input_types_dims = []
-    for input_data in inputs["args"]:
-        input_types_dims.append(get_type_and_dim(input_data))
-    for input_name, input_data in inputs["kwargs"].items():
-        input_types_dims.append(f"{input_name}: {get_type_and_dim(input_data)}")
-
-    output_type_dim = get_type_and_dim(outputs)
-
-    print(f"Module: {module_path}, Function: {function_name}")
-    print("Input types and dimensionalities:")
-    for input_type_dim in input_types_dims:
-        print(f"  - {input_type_dim}")
-    print(f"Output type and dimensionality: {output_type_dim}")
-    print()
-
-def extract_logged_data(log_directory: str) -> None:
-    for module_name in os.listdir(log_directory):
-        module_directory = os.path.join(log_directory, module_name)
-        for log_file in os.listdir(module_directory):
-            function_name = log_file.split("_")[0]
-            process_log_file(module_name, function_name)
-
-# TODO this function belongs among the tests
-def main() -> None:
-    log_directory = "logs/"
-    extract_logged_data(log_directory)
-
-####
-# tests
-####
-# Test case 1: Function with serializable inputs and output
-@debug()
-def add_numbers(a: int, b: int) -> int:
-    return a + b
-
-# Test case 2: Function with NumPy array input and output
-@debug()
-def multiply_array(arr: np.ndarray) -> np.ndarray:
-    return arr * 2
-
-# Test case 3: Function with TensorFlow tensor input and output
-@debug()
-def add_tensors(t1: tf.Tensor, t2: tf.Tensor) -> tf.Tensor:
-    return t1 + t2
-
-# Test case 4: Function with mixed input types and custom object output
-class CustomResult:
-    def __init__(self, value: str):
-        self.value = value
-
-@debug()
-def process_data(data: Any, flag: bool) -> CustomResult:
-    if flag:
-        return CustomResult("Processed: " + str(data))
-    else:
-        return CustomResult("Skipped: " + str(data))
-
-# Test case 5: Function with exception
-@debug()
-def divide_numbers(a: int, b: int) -> float:
-    return a / b
-
-# Test case 6: Loading logged data from disk
-@debug(log_to_file=True)
-def multiply_numbers(a: int, b: int) -> int:
-    return a * b
-
-## Set the debug parameter to True
-#params.cfg['debug'] = True
-#
-## Running the tests
-#add_numbers(3, 5)
-#add_numbers(4, 6)
-#add_numbers(5, 7)  # This invocation will not be logged
-#multiply_array(np.array([1, 2, 3]))
-#multiply_array(np.array([4, 5, 6]))
-#multiply_array(np.array([7, 8, 9]))  # This invocation will not be logged
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#add_tensors(tf.constant([[1.0, 2.0], [3.0, 4.0]]), tf.constant([[5.0, 6.0], [7.0, 8.0]]))
-#add_tensors(tf.constant([1.0, 2.0, 3.0]), tf.constant([4.0, 5.0, 6.0]))  # This invocation will not be logged
-#process_data({"key": "value"}, True)
-#process_data({"key": "value"}, False)
-#process_data([1, 2, 3], True)  # This invocation will not be logged
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(20, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(30, 0)  # This invocation will not be logged
-#except ZeroDivisionError:
-#    pass
-#
-#multiply_numbers(2, 3)
-#multiply_numbers(4, 5)
-#multiply_numbers(6, 7)  # This invocation will not be logged
-#
-## Loading logged data from disk
-#module_path = "__main__"
-#function_name = "multiply_numbers"
-#invocation_index = 0
-#
-#inputs, output = load_logged_data(module_path, function_name, invocation_index)
-#
-#print(f"Loaded inputs: {inputs}")
-#print(f"Loaded output: {output}")
-#
-## Cleanup: Remove the logged data files
-#log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-#log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-#for log_file in log_files:
-#    log_file_path = os.path.join(log_directory, log_file)
-#    os.remove(log_file_path)
-#
-## Set the debug parameter to False
-#params.cfg['debug'] = False
-#
-## Running the tests again (no logging should occur)
-#add_numbers(3, 5)
-#multiply_array(np.array([1, 2, 3]))
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#process_data({"key": "value"}, True)
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#multiply_numbers(2, 3)
-#
-#
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/losses.py b/build/lib/build/lib/build/lib/build/lib/ptycho/losses.py
deleted file mode 100644
index 1efd8b0..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/losses.py
+++ /dev/null
@@ -1,17 +0,0 @@
-#def I_channel_MAE(y_true,y_pred, center_target = True):
-#    if center_target:
-#        y_true = center_channels(y_true
-#    return tf.reduce_mean(tf.keras.losses.MeanAbsoluteError(y_true,y_pred))
-
-#def symmetrized_loss(target, pred, loss_fn):
-#    """
-#    Calculate loss function on an image, taking into account that the
-#    prediction may be coordinate-inverted relative to the target
-#    """
-#    abs1 = (target)
-#    abs2 = (pred)
-#    abs3 = abs2[:, ::-1, ::-1, :]
-#    target_sym = (symmetrize_3d(target))
-#    a, b, c = loss_fn(abs1, abs2), loss_fn(abs1, abs3), loss_fn(target_sym, pred)
-#    return tf.minimum(a,
-#                      tf.minimum(b, c))
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/misc.py b/build/lib/build/lib/build/lib/build/lib/ptycho/misc.py
deleted file mode 100644
index 003189f..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/misc.py
+++ /dev/null
@@ -1,330 +0,0 @@
-import numpy as np
-import matplotlib.cm as cm
-import scipy.cluster.vq as scv
-from ptycho import params
-from datetime import datetime
-
-# TODO multiple creations of this directory
-def get_path_prefix():
-    label = params.cfg['label']
-    prefix = params.params()['output_prefix']
-    now = datetime.now() # current date and time
-    try:
-        date_time = params.get('timestamp')
-    except KeyError:
-        date_time = now.strftime("%m/%d/%Y, %H:%M:%S")
-        params.set('timestamp', date_time)
-    date_time = date_time.replace('/', '-').replace(':', '.').replace(', ', '-')
-
-    #print('offset', offset)
-    out_prefix = '{}/{}_{}/'.format(prefix, date_time, label)
-    return out_prefix
-
-# Convert RGB colormap images to grayscale
-def colormap2arr(arr,cmap):
-    # http://stackoverflow.com/questions/3720840/how-to-reverse-color-map-image-to-scalar-values/3722674#3722674
-    gradient=cmap(np.linspace(0.0,1.0,1000))
-
-    # Reshape arr to something like (240*240, 4), all the 4-tuples in a long list...
-    arr2=arr.reshape((arr.shape[0]*arr.shape[1],arr.shape[2]))
-
-    # Use vector quantization to shift the values in arr2 to the nearest point in
-    # the code book (gradient).
-    code,dist=scv.vq(arr2,gradient)
-
-    # code is an array of length arr2 (240*240), holding the code book index for
-    # each observation. (arr2 are the "observations".)
-    # Scale the values so they are from 0 to 1.
-    values=code.astype('float')/gradient.shape[0]
-
-    # Reshape values back to (240,240)
-    values=values.reshape(arr.shape[0],arr.shape[1])
-    values=values[::-1]
-    return values
-
-import functools
-import hashlib
-import json
-import os
-import tensorflow as tf
-
-#https://chat.openai.com/c/8273412b-f3fb-405c-a7a4-c0466bb43b04
-import os
-import functools
-import hashlib
-import json
-import numpy as np
-import tensorflow as tf
-
-def memoize_disk_and_memory(func):
-    from ptycho.params import cfg
-    from ptycho import probe
-    memory_cache = {}
-    disk_cache_dir = 'memoized_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def process_dict(d):
-        processed = {}
-        for k, v in d.items():
-            if isinstance(v, tf.Tensor):
-                processed[k] = ('tensor', v.numpy())
-            elif isinstance(v, np.ndarray):
-                processed[k] = ('array', v)
-            elif isinstance(v, dict):
-                processed[k] = ('dict', process_dict(v))
-            else:
-                processed[k] = ('primitive', v)
-        return processed
-
-    def reconstruct_dict(d):
-        reconstructed = {}
-        for k, (type_, value) in d.items():
-            if type_ == 'tensor' or type_ == 'array':
-                reconstructed[k] = value
-            elif type_ == 'dict':
-                reconstructed[k] = reconstruct_dict(value)
-            else:  # primitive
-                reconstructed[k] = value
-        return reconstructed
-
-    @functools.wraps(func)
-    def wrapper(*args, **kwargs):
-        cfg_keys = ['offset', 'N', 'outer_offset_train', 'outer_offset_test',
-                    'nphotons', 'nimgs_train', 'nimgs_test', 'set_phi',
-                    'data_source', 'gridsize', 'big_gridsize', 'default_probe_scale']
-        hash_input = {k: cfg[k] for k in cfg_keys if k in cfg}
-        hash_input.update({f'arg_{i}': json.dumps(arg, default=str) for i, arg in enumerate(args)})
-        hash_input.update({f'kwarg_{k}': json.dumps(v, default=str) for k, v in kwargs.items()})
-        hash_input_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha1(hash_input_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-        else:
-            disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-            if os.path.exists(disk_cache_file):
-                print("Loading result from disk cache.")
-                loaded_data = np.load(disk_cache_file, allow_pickle=True)
-                if 'dict_data' in loaded_data:
-                    result = reconstruct_dict(loaded_data['dict_data'].item())
-                elif 'result' in loaded_data:
-                    result = loaded_data['result']
-                else:
-                    result = tuple(loaded_data[key] for key in loaded_data.keys())
-                    if len(result) == 1:
-                        result = result[0]
-            else:
-                print("No cached result found. Calculating and caching the result.")
-                result = func(*args, **kwargs)
-                if isinstance(result, (np.ndarray, tf.Tensor)):
-                    np.savez(disk_cache_file, result=result.numpy() if isinstance(result, tf.Tensor) else result)
-                elif isinstance(result, tuple):
-                    np.savez(disk_cache_file, **{f'arr_{i}': arr.numpy() if isinstance(arr, tf.Tensor) else arr for i, arr in enumerate(result)})
-                elif isinstance(result, dict):
-                    processed_dict = process_dict(result)
-                    np.savez(disk_cache_file, dict_data=processed_dict)
-                else:
-                    raise ValueError("Invalid function output. Expected numpy array, TensorFlow tensor, tuple, or dictionary with values as arrays/tensors/primitives.")
-                memory_cache[hash_hex] = result
-        return result
-    return wrapper
-
-
-##########
-# unit test
-##########
-#
-#import numpy as np
-#import tensorflow as tf
-#
-## Define test functions
-#@memoize_disk_and_memory
-#def test_function1(x):
-#    return np.random.rand(x, x)
-#
-#@memoize_disk_and_memory
-#def test_function2(x):
-#    return tf.random.uniform((x, x))
-#
-#@memoize_disk_and_memory
-#def test_function3(x):
-#    return np.random.rand(x, x), tf.random.uniform((x, x))
-#
-## First run - cache miss
-#result1_first = test_function1(5)
-#result2_first = test_function2(5)
-#result3_first = test_function3(5)
-#
-## Second run - cache hit
-#result1_second = test_function1(5)
-#result2_second = test_function2(5)
-#result3_second = test_function3(5)
-#
-## Test if the memoized results match the first run results
-#np.testing.assert_array_equal(result1_first, result1_second)
-#np.testing.assert_array_equal(result2_first, result2_second)
-#
-#np.testing.assert_array_equal(result3_first[0], result3_second[0])
-#np.testing.assert_array_equal(result3_first[1], result3_second[1])
-#
-## Test if memoization works with different function arguments
-#result1_diff_arg = test_function1(6)
-#np.testing.assert_raises(AssertionError, np.testing.assert_array_equal, result1_first, result1_diff_arg)
-#
-
-import functools
-import numpy as np
-import tensorflow as tf
-
-def make_invocation_counter():
-    count = 0
-
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-
-    return increment
-
-######
-## logging decorator
-######
-# TODO deprecated, moved to logging.py
-#def g(h):
-#    increment_count = make_invocation_counter()
-#
-#    def wrapper(f):
-#        @functools.wraps(f)
-#        def inner(*args, **kwargs):
-#            invocation_count = increment_count()
-#            if invocation_count <= 2:
-#                return h(f)(*args, **kwargs)
-#            else:
-#                return f(*args, **kwargs)
-#
-#        return inner
-#
-#    return wrapper
-#
-#@g
-#def debug(func):
-#    def wrapper(*args, **kwargs):
-#        def get_type_and_shape(x):
-#            if isinstance(x, np.ndarray):
-#                return f"{type(x)} with shape {x.shape}"
-#            elif isinstance(x, tf.Tensor):
-#                return f"{type(x)} with shape {x.shape}"
-#            else:
-#                return str(type(x))
-#
-#        args_types = [get_type_and_shape(arg) for arg in args]
-#        kwargs_types = {k: get_type_and_shape(v) for k, v in kwargs.items()}
-#
-#        print(f"Calling {func.__name__} with args types: {args_types}, kwargs types: {kwargs_types}")
-#        result = func(*args, **kwargs)
-#        
-#        result_type = get_type_and_shape(result)
-#        print(f"{func.__name__} returned {result_type}")
-#        
-#        return result
-#    return wrapper
-
-import scipy.signal
-import functools
-import hashlib
-import json
-import os
-import numpy as np
-
-def memoize_simulated_data(func):
-    memory_cache = {}
-    disk_cache_dir = 'memoized_simulated_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def array_to_bytes(arr):
-        return arr.tobytes(), arr.dtype.str, arr.shape
-
-    def bytes_to_array(data, dtype, shape):
-        return np.frombuffer(data, dtype=np.dtype(dtype)).reshape(shape)
-
-    @functools.wraps(func)
-    def wrapper(objectGuess, probeGuess, nimages, buffer, random_seed=None, return_patches=True):
-        from ptycho.loader import RawData
-        # Create a unique hash for the input parameters
-        hash_input = {
-            'objectGuess': array_to_bytes(objectGuess),
-            'probeGuess': array_to_bytes(probeGuess),
-            'nimages': nimages,
-            'buffer': buffer,
-            'random_seed': random_seed,
-            'return_patches': return_patches
-        }
-        hash_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha256(hash_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-
-        disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-        if os.path.exists(disk_cache_file):
-            print("Loading result from disk cache.")
-            with np.load(disk_cache_file, allow_pickle=True) as data:
-                raw_data_dict = data['raw_data'].item()
-                raw_data = RawData(
-                    xcoords=raw_data_dict['xcoords'],
-                    ycoords=raw_data_dict['ycoords'],
-                    xcoords_start=raw_data_dict['xcoords_start'],
-                    ycoords_start=raw_data_dict['ycoords_start'],
-                    diff3d=raw_data_dict['diff3d'],
-                    probeGuess=raw_data_dict['probeGuess']
-                )
-                if return_patches:
-                    patches = data['patches']
-                    result = (raw_data, patches)
-                else:
-                    result = raw_data
-        else:
-            print("No cached result found. Calculating and caching the result.")
-            result = func(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches)
-            
-            if isinstance(result, tuple):
-                raw_data, patches = result
-            else:
-                raw_data = result
-                patches = None
-
-            raw_data_dict = {
-                'xcoords': raw_data.xcoords,
-                'ycoords': raw_data.ycoords,
-                'xcoords_start': raw_data.xcoords_start,
-                'ycoords_start': raw_data.ycoords_start,
-                'diff3d': raw_data.diff3d,
-                'probeGuess': raw_data.probeGuess
-            }
-
-            np.savez(disk_cache_file, raw_data=raw_data_dict, patches=patches)
-
-        memory_cache[hash_hex] = result
-        return result
-
-    return wrapper
-
-def cross_image(im1, im2):
-    """
-    Find offsets through 2d autocorrelation
-    """
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/model.py b/build/lib/build/lib/build/lib/build/lib/ptycho/model.py
deleted file mode 100644
index a182376..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/model.py
+++ /dev/null
@@ -1,477 +0,0 @@
-# TODO s
-# - complex convolution
-# - Use tensor views:
-#     https://chat.openai.com/c/e6d5e400-daf9-44b7-8ef9-d49f21a634a3
-# -difference maps?
-# -double -> float32
-# Apply real space loss to both amplitude and phase of the object
-
-from datetime import datetime
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras.activations import relu, sigmoid, tanh, swish, softplus
-from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, InputLayer, Lambda, Dense
-from tensorflow.keras.layers import Layer
-from tensorflow.keras import layers
-import glob
-import math
-import numpy as np
-import os
-import tensorflow.compat.v2 as tf
-import tensorflow_probability as tfp
-
-from .loader import PtychoDataContainer
-from . import tf_helper as hh
-from . import params as cfg
-params = cfg.params
-
-import tensorflow_addons as tfa
-gaussian_filter2d = tfa.image.gaussian_filter2d
-
-def complex_gaussian_filter2d(input_tensor, filter_shape, sigma):
-    """
-    Apply Gaussian filter to complex-valued tensor.
-    
-    Args:
-    input_tensor: Complex-valued input tensor
-    filter_shape: Tuple of integers specifying the filter shape
-    sigma: Float or tuple of floats for the Gaussian kernel standard deviation
-    
-    Returns:
-    Complex-valued tensor after applying Gaussian filter
-    """
-    real_part = tf.math.real(input_tensor)
-    imag_part = tf.math.imag(input_tensor)
-    
-    filtered_real = gaussian_filter2d(real_part, filter_shape=filter_shape, sigma=sigma)
-    filtered_imag = gaussian_filter2d(imag_part, filter_shape=filter_shape, sigma=sigma)
-    
-    return tf.complex(filtered_real, filtered_imag)
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-# sets the number of convolutional filters
-
-n_filters_scale =  cfg.get('n_filters_scale')
-N = cfg.get('N')
-gridsize = cfg.get('gridsize')
-offset = cfg.get('offset')
-
-from . import probe
-tprobe = params()['probe']
-
-probe_mask = probe.get_probe_mask(N)
-#probe_mask = cfg.get('probe_mask')[:, :, :, 0]
-
-if len(tprobe.shape) == 3:
-    initial_probe_guess = tprobe[None, ...]
-    #probe_mask = probe_mask[None, ...]
-elif len(tprobe.shape) == 4:
-    initial_probe_guess = tprobe
-else:
-    raise ValueError
-
-initial_probe_guess = tf.Variable(
-            initial_value=tf.cast(initial_probe_guess, tf.complex64),
-            trainable=params()['probe.trainable'],
-        )
-
-# TODO hyperparameters:
-# TODO total variation loss
-# -probe smoothing scale(?)
-class ProbeIllumination(tf.keras.layers.Layer):
-    def __init__(self, name = None):
-        super(ProbeIllumination, self).__init__(name = name)
-        self.w = initial_probe_guess
-        self.sigma = cfg.get('gaussian_smoothing_sigma')
-
-    def call(self, inputs):
-        # x is expected to have shape (batch_size, N, N, gridsize**2)
-        # where N is the size of each patch and gridsize**2 is the number of patches
-        x = inputs[0]
-        
-        # self.w has shape (1, N, N, 1) or (1, N, N, gridsize**2) if probe.big is True
-        # probe_mask has shape (N, N, 1)
-        
-        # Apply multiplication first
-        illuminated = self.w * x
-        
-        # Apply Gaussian smoothing only if sigma is not 0
-        if self.sigma != 0:
-            smoothed = complex_gaussian_filter2d(illuminated, filter_shape=(3, 3), sigma=self.sigma)
-        else:
-            smoothed = illuminated
-        
-        if cfg.get('probe.mask'):
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed * tf.cast(probe_mask, tf.complex64), (self.w * tf.cast(probe_mask, tf.complex64))[None, ...]
-        else:
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed, (self.w)[None, ...]
-
-probe_illumination = ProbeIllumination()
-
-nphotons = cfg.get('nphotons')
-
-# TODO scaling could be done on a shot-by-shot basis, but IIRC I tried this
-# and there were issues
-log_scale_guess = np.log(cfg.get('intensity_scale'))
-log_scale = tf.Variable(
-            initial_value=tf.constant(float(log_scale_guess)),
-            trainable = params()['intensity_scale.trainable'],
-        )
-
-class IntensityScaler(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return x / tf.math.exp(self.w)
-
-# TODO use a bijector instead of separately defining the transform and its
-# inverse
-class IntensityScaler_inv(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler_inv, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return tf.math.exp(self.w) * x
-
-def scale(inputs):
-    x, = inputs
-    res = x / tf.math.exp(log_scale)
-    return res
-
-def inv_scale(inputs):
-    x, = inputs
-    return tf.math.exp(log_scale) * x
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-lambda_norm = Lambda(lambda x: tf.math.reduce_sum(x**2, axis = [1, 2]))
-input_img = Input(shape=(N, N, gridsize**2), name = 'input')
-input_positions = Input(shape=(1, 2, gridsize**2), name = 'input_positions')
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-def create_encoder(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 128:
-        filters = [n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 256:
-        filters = [n_filters_scale * 8, n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Pool_block(x, num_filters)
-    
-    return x
-
-def create_decoder_base(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    return x
-
-def get_resolution_scale_factor(N):
-    """
-    Calculate the resolution-dependent filter count programmatically.
-    
-    Args:
-    N (int): The input resolution (must be a power of 2)
-    
-    Returns:
-    int: The scale factor for the given resolution
-    
-    Raises:
-    ValueError: If the input size is not a power of 2 or is outside the supported range
-    """
-    if N < 64 or N > 1024:
-        raise ValueError(f"Input size {N} is outside the supported range (64 to 1024)")
-    
-    if not (N & (N - 1) == 0) or N == 0:
-        raise ValueError(f"Input size {N} is not a power of 2")
-    
-    # Calculate the scale factor
-    # For N=64, we want 32; for N=128, we want 16; for N=256, we want 8, etc.
-    # This can be achieved by dividing 2048 by N
-    return 2048 // N
-
-def create_decoder_last(input_tensor, n_filters_scale, conv1, conv2, act=tf.keras.activations.sigmoid, name=''):
-    N = cfg.get('N')
-    gridsize = cfg.get('gridsize')
-
-    scale_factor = get_resolution_scale_factor(N)
-    if cfg.get('pad_object'):
-        c_outer = 4
-        x1 = conv1(input_tensor[..., :-c_outer])
-        x1 = act(x1)
-        x1 = tf.keras.layers.ZeroPadding2D(((N // 4), (N // 4)), name=name + '_padded')(x1)
-        
-        if not cfg.get('probe.big'):
-            return x1
-        
-        x2 = Conv_Up_block(input_tensor[..., -c_outer:], n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = swish(x2)
-        
-        # Drop the central region of x2
-        center_mask = hh.mk_centermask(x2, N, 1, kind='border')
-        x2_masked = x2 * center_mask
-        
-        outputs = x1 + x2_masked
-        return outputs
-
-    else:
-        x2 = Conv_Up_block(input_tensor, n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = act(x2)
-        return x2
-
-
-def create_decoder_phase(input_tensor, n_filters_scale, gridsize, big):
-    num_filters = gridsize**2 if big else 1
-    conv1 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    act = tf.keras.layers.Lambda(lambda x: math.pi * tf.keras.activations.tanh(x), name='phi')
-    
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act, name='phase')
-    return outputs
-
-
-def create_autoencoder(input_tensor, n_filters_scale, gridsize, big):
-    encoded = create_encoder(input_tensor, n_filters_scale)
-    decoded_amp = create_decoder_amp(encoded, n_filters_scale)
-    decoded_phase = create_decoder_phase(encoded, n_filters_scale, gridsize, big)
-    
-    return decoded_amp, decoded_phase
-
-
-def get_amp_activation():
-    if cfg.get('amp_activation') == 'sigmoid':
-        return lambda x: sigmoid(x)
-    elif cfg.get('amp_activation') == 'swish':
-        return lambda x: swish(x)
-    elif cfg.get('amp_activation') == 'softplus':
-        return lambda x: softplus(x)
-    elif cfg.get('amp_activation') == 'relu':
-        return lambda x: relu(x)
-    else:
-        return ValueError
-
-def create_decoder_amp(input_tensor, n_filters_scale):
-    # Placeholder convolution layers and activation as defined in the original DecoderAmp class
-    conv1 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    act = Lambda(get_amp_activation(), name='amp')
-
-    x = create_decoder_base(input_tensor, n_filters_scale)
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act,
-        name = 'amp')
-    return outputs
-
-normed_input = scale([input_img])
-decoded1, decoded2 = create_autoencoder(normed_input, n_filters_scale, gridsize,
-    cfg.get('object.big'))
-
-# Combine the two decoded outputs
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]), name='obj')([decoded1, decoded2])
-
-if cfg.get('object.big'):
-    # If 'object.big' is true, reassemble the patches
-    padded_obj_2 = Lambda(lambda x: hh.reassemble_patches(x[0], fn_reassemble_real=hh.mk_reassemble_position_real(x[1])), name = 'padded_obj_2')([obj, input_positions])
-else:
-    # If 'object.big' is not true, pad the reconstruction
-    padded_obj_2 = Lambda(lambda x: hh.pad_reconstruction(x), name = 'padded_obj_2')(obj)
-
-# TODO rename?
-# Trim the object reconstruction to N x N
-trimmed_obj = Lambda(hh.trim_reconstruction, name = 'trimmed_obj')(padded_obj_2)
-
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x:
-    hh.extract_patches_position(x[0], x[1], 0.),
-    name = 'padded_objs_with_offsets')([padded_obj_2, input_positions])
-
-# Apply the probe illumination
-padded_objs_with_offsets, probe = probe_illumination([padded_objs_with_offsets])
-flat_illuminated = padded_objs_with_offsets
-
-# Apply pad and diffract operation
-padded_objs_with_offsets, pred_diff = Lambda(lambda x: hh.pad_and_diffract(x, N, N, pad=False), name = 'pred_amplitude')(padded_objs_with_offsets)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-# Scale the amplitude
-pred_amp_scaled = inv_scale([pred_diff])
-
-
-# TODO Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
-dist_poisson_intensity = tfpl.DistributionLambda(lambda amplitude:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               (amplitude**2)))))
-pred_intensity_sampled = dist_poisson_intensity(pred_amp_scaled)
-
-# Poisson distribution over expected diffraction intensity (i.e. photons per
-# pixel)
-def negloglik(x, rv_x):
-    return -rv_x.log_prob(x)
-fn_poisson_nll = lambda A_target, A_pred: negloglik(A_target**2, dist_poisson_intensity(A_pred))
-
-autoencoder = Model([input_img, input_positions], [trimmed_obj, pred_amp_scaled, pred_intensity_sampled])
-
-autoencoder_no_nll = Model(inputs = [input_img, input_positions],
-        outputs = [pred_amp_scaled])
-
-#encode_obj_to_diffraction = tf.keras.Model(inputs=[obj, input_positions],
-#                           outputs=[pred_diff, flat_illuminated])
-diffraction_to_obj = tf.keras.Model(inputs=[input_img, input_positions],
-                           outputs=[trimmed_obj])
-
-mae_weight = cfg.get('mae_weight') # should normally be 0
-nll_weight = cfg.get('nll_weight') # should normally be 1
-# Total variation regularization on real space amplitude
-realspace_weight = cfg.get('realspace_weight')#1e2
-optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
-
-autoencoder.compile(optimizer= optimizer,
-     #loss=[lambda target, pred: hh.total_variation(pred),
-     loss=[hh.realspace_loss,
-        'mean_absolute_error', negloglik, 'mean_absolute_error'],
-     loss_weights = [realspace_weight, mae_weight, nll_weight, 0.])
-
-print (autoencoder.summary())
-
-# Create a TensorBoard callback
-logs = "logs/" + datetime.now().strftime("%Y%m%d-%H%M%S")
-
-tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,
-                                                 histogram_freq=1,
-                                                 profile_batch='500,520')
-
-def prepare_inputs(train_data: PtychoDataContainer):
-    """training inputs"""
-    return [train_data.X * cfg.get('intensity_scale'), train_data.coords]
-
-def prepare_outputs(train_data: PtychoDataContainer):
-    """training outputs"""
-    return [hh.center_channels(train_data.Y_I, train_data.coords)[:, :, :, :1],
-                (cfg.get('intensity_scale') * train_data.X),
-                (cfg.get('intensity_scale') * train_data.X)**2]
-
-#def train(epochs, X_train, coords_train, Y_obj_train):
-def train(epochs, trainset: PtychoDataContainer):
-    assert type(trainset) == PtychoDataContainer
-    coords_train = trainset.coords
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint(
-                            '%s/weights.{epoch:02d}.h5' %wt_path,
-                            monitor='val_loss', verbose=1, save_best_only=True,
-                            save_weights_only=False, mode='auto', period=1)
-
-    batch_size = params()['batch_size']
-    history=autoencoder.fit(
-#        prepare_inputs(X_train, coords_train),
-#        prepare_outputs(Y_obj_train, coords_train, X_train),
-        prepare_inputs(trainset),
-        prepare_outputs(trainset),
-        shuffle=True, batch_size=batch_size, verbose=1,
-        epochs=epochs, validation_split = 0.05,
-        callbacks=[reduce_lr, earlystop])
-        #callbacks=[reduce_lr, earlystop, tboard_callback])
-    return history
-import numpy as np
-
-def print_model_diagnostics(model):
-    """
-    Prints diagnostic information for a given TensorFlow/Keras model.
-
-    Parameters:
-    - model: A TensorFlow/Keras model object.
-    """
-    # Print the model summary to get the architecture, layer types, output shapes, and parameter counts.
-    model.summary()
-
-    # Print input shape
-    print("Model Input Shape(s):")
-    for input_layer in model.inputs:
-        print(input_layer.shape)
-
-    # Print output shape
-    print("Model Output Shape(s):")
-    for output_layer in model.outputs:
-        print(output_layer.shape)
-
-    # Print total number of parameters
-    print("Total Parameters:", model.count_params())
-
-    # Print trainable and non-trainable parameter counts
-    trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
-    non_trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])
-    print("Trainable Parameters:", trainable_count)
-    print("Non-trainable Parameters:", non_trainable_count)
-
-    # If the model uses any custom layers, print their names and configurations
-    print("Custom Layers (if any):")
-    for layer in model.layers:
-        if hasattr(layer, 'custom_objects'):
-            print(f"{layer.name}: {layer.custom_objects}")
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/model_manager.py b/build/lib/build/lib/build/lib/build/lib/ptycho/model_manager.py
deleted file mode 100644
index 2ee4937..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/model_manager.py
+++ /dev/null
@@ -1,202 +0,0 @@
-# model_manager.py
-
-import os
-import h5py
-import dill
-import tempfile
-import zipfile
-import shutil
-import tensorflow as tf
-from typing import Dict, List, Any, Optional
-from ptycho import params
-
-class ModelManager:
-    @staticmethod
-    def save_model(model: tf.keras.Model, model_dir: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model (tf.keras.Model): The model to save.
-            model_dir (str): Directory path for saving the model.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the model.
-            intensity_scale (float): The intensity scale used in the model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            os.makedirs(model_dir, exist_ok=True)
-            
-            # Save the model
-            model.save(model_dir, save_format="tf")
-            
-            # Save custom objects
-            with open(custom_objects_path, 'wb') as f:
-                dill.dump(custom_objects, f)
-            
-            # Save parameters including intensity_scale
-            params_dict = params.cfg.copy()
-            params_dict['intensity_scale'] = intensity_scale
-            params_dict['_version'] = '1.0'  # Add version information
-            with open(params_path, 'wb') as f:
-                dill.dump(params_dict, f)
-            
-            # Save intensity_scale as an attribute in the HDF5 file
-            with h5py.File(model_file, 'a') as hf:
-                hf.attrs['intensity_scale'] = intensity_scale
-        
-        except Exception as e:
-            print(f"Error saving model to {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def load_model(model_dir: str) -> tf.keras.Model:
-        """
-        Load a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model_dir (str): Directory containing the model files.
-
-        Returns:
-            tf.keras.Model: The loaded model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            
-            # Load parameters
-            with open(params_path, 'rb') as f:
-                loaded_params = dill.load(f)
-            
-            # Check version and handle any necessary migrations
-            version = loaded_params.pop('_version', '1.0')
-            # Here you could add logic to handle different versions if needed
-            
-            # Update params.cfg with loaded parameters
-            params.cfg.update(loaded_params)
-            
-            # Load custom objects
-            with open(custom_objects_path, 'rb') as f:
-                custom_objects = dill.load(f)
-            
-            # Load intensity scale
-            with h5py.File(model_file, 'r') as hf:
-                intensity_scale = hf.attrs['intensity_scale']
-            
-            # Set intensity scale in params
-            params.set('intensity_scale', intensity_scale)
-
-            # Load and return the model
-            return tf.keras.models.load_model(model_dir, custom_objects=custom_objects)
-        
-        except Exception as e:
-            print(f"Error loading model from {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def save_multiple_models(models_dict: Dict[str, tf.keras.Model], base_path: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save multiple models into a single zip archive.
-
-        Args:
-            models_dict (Dict[str, tf.keras.Model]): Dictionary of models to save.
-            base_path (str): Base path for saving the zip archive.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the models.
-            intensity_scale (float): The intensity scale used in the models.
-        """
-        zip_path = f"{base_path}.zip"
-        os.makedirs(os.path.dirname(zip_path), exist_ok=True)
-        
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Save manifest of included models
-            manifest = {'models': list(models_dict.keys()), 'version': '1.0'}
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'wb') as f:
-                dill.dump(manifest, f)
-            
-            # Save each model to temp directory
-            for model_name, model in models_dict.items():
-                model_subdir = os.path.join(temp_dir, model_name)
-                os.makedirs(model_subdir, exist_ok=True)
-                ModelManager.save_model(model, model_subdir, custom_objects, intensity_scale)
-            
-            # Create zip archive
-            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
-                for root, _, files in os.walk(temp_dir):
-                    for file in files:
-                        full_path = os.path.join(root, file)
-                        arc_path = os.path.relpath(full_path, temp_dir)
-                        zf.write(full_path, arc_path)
-
-    @staticmethod
-    def load_multiple_models(base_path: str, model_names: Optional[List[str]] = None) -> Dict[str, tf.keras.Model]:
-        """
-        Load multiple models from a zip archive.
-
-        Args:
-            base_path (str): Base path of the zip archive.
-            model_names (Optional[List[str]]): List of model names to load. If None, loads all models.
-
-        Returns:
-            Dict[str, tf.keras.Model]: Dictionary of loaded models.
-        """
-        zip_path = f"{base_path}.zip"
-        if not os.path.exists(zip_path):
-            raise FileNotFoundError(f"Model archive not found: {zip_path}")
-            
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Extract zip archive
-            with zipfile.ZipFile(zip_path, 'r') as zf:
-                zf.extractall(temp_dir)
-            
-            # Load manifest
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'rb') as f:
-                manifest = dill.load(f)
-            
-            # Determine which models to load
-            available_models = manifest['models']
-            if model_names is None:
-                model_names = available_models
-            else:
-                # Validate requested models exist
-                missing = set(model_names) - set(available_models)
-                if missing:
-                    raise ValueError(f"Requested models not found in archive: {missing}")
-            
-            # Load each requested model
-            loaded_models = {}
-            for model_name in model_names:
-                model_subdir = os.path.join(temp_dir, model_name)
-                loaded_models[model_name] = ModelManager.load_model(model_subdir)
-            
-            return loaded_models
-
-
-def save(out_prefix: str) -> None:
-    """Save models to a zip archive."""
-    from ptycho import model
-    from ptycho.model import ProbeIllumination, IntensityScaler, IntensityScaler_inv, negloglik
-    from ptycho.tf_helper import Translation
-    from ptycho.tf_helper import realspace_loss as hh_realspace_loss
-
-    model_path = os.path.join(out_prefix, params.get('h5_path'))
-    custom_objects = {
-        'ProbeIllumination': ProbeIllumination,
-        'IntensityScaler': IntensityScaler,
-        'IntensityScaler_inv': IntensityScaler_inv,
-        'Translation': Translation,
-        'negloglik': negloglik,
-        'realspace_loss': hh_realspace_loss
-    }
-    
-    models_to_save = {
-        'autoencoder': model.autoencoder,
-        'diffraction_to_obj': model.diffraction_to_obj
-    }
-    
-    ModelManager.save_multiple_models(models_to_save, model_path, custom_objects, params.get('intensity_scale'))
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/nbutils.py b/build/lib/build/lib/build/lib/build/lib/ptycho/nbutils.py
deleted file mode 100644
index fe53aab..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/nbutils.py
+++ /dev/null
@@ -1,217 +0,0 @@
-import matplotlib.pyplot as plt
-from ptycho import model
-import numpy as np
-
-def crop_to_non_uniform_region_with_buffer(img_array, buffer=0):
-    """
-    Crop the image to the non-uniform region with an additional buffer in each direction.
-
-    Parameters:
-    - img_array: The numpy array of the image.
-    - buffer: The number of pixels to expand the cropped region in each direction.
-
-    Returns:
-    - cropped_img_array: The numpy array of the cropped image.
-    """
-
-    # Convert to grayscale if it is not already
-    if len(img_array.shape) == 3:
-        gray_img_array = img_array[:, :, 0]
-    else:
-        gray_img_array = img_array
-
-    # Find the background pixel value, assuming it is the mode of the corner pixels
-    corner_pixels = [gray_img_array[0, 0], gray_img_array[0, -1], gray_img_array[-1, 0], gray_img_array[-1, -1]]
-    background_pixel = max(set(corner_pixels), key=corner_pixels.count)
-
-    # Detect the non-uniform region
-    rows, cols = np.where(gray_img_array != background_pixel)
-    if rows.size > 0 and cols.size > 0:
-        row_min, row_max, col_min, col_max = rows.min(), rows.max(), cols.min(), cols.max()
-        # Apply the buffer, ensuring we don't go out of the image bounds
-        row_min = max(row_min - buffer, 0)
-        row_max = min(row_max + buffer, gray_img_array.shape[0] - 1)
-        col_min = max(col_min - buffer, 0)
-        col_max = min(col_max + buffer, gray_img_array.shape[1] - 1)
-    else:
-        raise ValueError("No non-uniform region found")
-
-    # Crop the image to the non-uniform region with the buffer
-    cropped_img_array = gray_img_array[row_min:row_max+1, col_min:col_max+1]
-
-    return cropped_img_array
-
-import matplotlib.pyplot as plt
-
-def mk_comparison(method1, method2, method1_name='PtychoNN', method2_name='ground truth', method0=None, method0_name='ePIE', phase_vmin=None, phase_vmax=None):
-    """
-    Create a comparison plot of phase and amplitude images for 2 or 3 methods.
-
-    Parameters:
-    - method1: Complex 2D array of method1 data
-    - method2: Complex 2D array of method2 data
-    - method1_name: Name of the first method (default: 'PtychoNN')
-    - method2_name: Name of the second method (default: 'ground truth')
-    - method0: Complex 2D array of method0 data (optional)
-    - method0_name: Name of the optional third method (default: 'ePIE')
-    - phase_vmin: Minimum data value for phase plots (optional)
-    - phase_vmax: Maximum data value for phase plots (optional)
-    """
-    num_methods = 3 if method0 is not None else 2
-    fig, axs = plt.subplots(2, num_methods, figsize=(5*num_methods, 10))
-
-    methods = [method0, method1, method2] if num_methods == 3 else [method1, method2]
-    method_names = [method0_name, method1_name, method2_name] if num_methods == 3 else [method1_name, method2_name]
-
-    for i, (method, name) in enumerate(zip(methods, method_names)):
-        # Phase plot
-        phase_img = axs[0, i].imshow(np.angle(method), cmap='gray', vmin=phase_vmin, vmax=phase_vmax)
-        axs[0, i].set_title(f'{name} Phase')
-        axs[0, i].axis('off')
-        fig.colorbar(phase_img, ax=axs[0, i], orientation='vertical')
-
-        # Amplitude plot
-        amp_img = axs[1, i].imshow(np.abs(method), cmap='viridis')
-        axs[1, i].set_title(f'{name} Amplitude')
-        axs[1, i].axis('off')
-        fig.colorbar(amp_img, ax=axs[1, i], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-    plt.show()
-
-def compare(obj_tensor_full, global_offsets, objectGuess, ptychonn_tensor=None):
-    from ptycho import loader
-
-    # Process PtychoPINN data
-    ptychopinn_image = loader.reassemble_position(obj_tensor_full, global_offsets[:, :, :, :], M=20)
-    ptychopinn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychopinn_image[..., 0]), buffer=-20)
-    ptychopinn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychopinn_image[..., 0]), buffer=-20)
-
-    # Process ground truth data
-    gt_phase = crop_to_non_uniform_region_with_buffer(np.angle(objectGuess), buffer=-20)
-    gt_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(objectGuess), buffer=-20)
-
-    # Process PtychoNN data if provided
-    if ptychonn_tensor is not None:
-        ptychonn_image = loader.reassemble_position(ptychonn_tensor, global_offsets[:, :, :, :], M=20)
-        ptychonn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychonn_image[..., 0]), buffer=-20)
-        ptychonn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychonn_image[..., 0]), buffer=-20)
-        
-        # Create comparison with all three methods
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth',
-                      method0=ptychonn_phase + 1j * ptychonn_amplitude, 
-                      method0_name='PtychoNN')
-    else:
-        # Create comparison with only PtychoPINN and ground truth
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth')
-
-# TODO type annotation
-def reconstruct_image(test_data, diffraction_to_obj = None):
-    global_offsets = test_data.global_offsets
-    local_offsets = test_data.local_offsets
-
-    if diffraction_to_obj is None:
-        diffraction_to_obj = model.diffraction_to_obj
-    obj_tensor_full = diffraction_to_obj.predict(
-                    [test_data.X * model.params()['intensity_scale'],
-                    local_offsets])
-    return obj_tensor_full, global_offsets
-
-def print_shapes(test_data):
-    for key, value in test_data.items():
-        if value is not None:
-            if isinstance(value, tuple):
-                print(f"{key}\t")
-                for i, array in enumerate(value):
-                    print(f"  Array {i+1}{array.shape}, \t {array.dtype}")
-            else:
-                print(f"{key}\t{value.shape}, {value.dtype}")
-
-def probeshow(probeGuess, test_data):
-    # Creating a figure with three subplots
-    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
-
-    # Plotting the magnitude of the complex array
-    img1 = ax1.imshow(np.abs(probeGuess), cmap='viridis')
-    ax1.set_title('probe amplitude')
-    fig.colorbar(img1, ax=ax1, orientation='vertical')
-
-    # Plotting the phase of the complex array
-    img2 = ax2.imshow(np.angle(probeGuess), cmap='jet')
-    ax2.set_title('probe phase')
-    fig.colorbar(img2, ax=ax2, orientation='vertical')
-
-    # Plotting the scan point positions
-    ax3.scatter(*(test_data.global_offsets.squeeze().T))
-    ax3.set_title('scan point positions')
-
-    # Improving layout
-    plt.tight_layout()
-    plt.show()
-
-
-def track_dict_changes(input_dict, callback):
-    # Copy the original dictionary to track changes
-    original_dict = input_dict.copy()
-    # Execute the callback function
-    callback(input_dict)
-    # Determine which keys have changed or added
-    changed_or_added_keys = [key for key in input_dict if input_dict.get(key) != original_dict.get(key)]
-    return changed_or_added_keys
-
-def mk_epie_comparison2x2(ptycho_pinn_phase, epie_phase, ptycho_pinn_amplitude,epie_amplitude):
-    # Create a 2x2 subplot
-    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
-
-    # PtychoPINN phase with color bar
-    ptycho_pinn_phase_img = axs[0, 0].imshow(ptycho_pinn_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    axs[0, 0].axis('off')
-    fig.colorbar(ptycho_pinn_phase_img, ax=axs[0, 0], orientation='vertical')
-
-    # ePIE phase with color bar
-    epie_phase_img = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    axs[0, 1].axis('off')
-    fig.colorbar(epie_phase_img, ax=axs[0, 1], orientation='vertical')
-
-    # PtychoPINN amplitude with color bar
-    ptycho_pinn_amplitude_img = axs[1, 0].imshow(ptycho_pinn_amplitude, cmap='gray')#,
-                                               # vmin = .2
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    axs[1, 0].axis('off')
-    fig.colorbar(ptycho_pinn_amplitude_img, ax=axs[1, 0], orientation='vertical')
-
-    # ePIE amplitude with color bar
-    epie_amplitude_img = axs[1, 1].imshow(epie_amplitude, cmap='gray')
-    axs[1, 1].set_title('ePIE Amplitude')
-    axs[1, 1].axis('off')
-    fig.colorbar(epie_amplitude_img, ax=axs[1, 1], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-
-    plt.show()
-
-# object heatmaps
-## Creating a figure and two subplots
-#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
-#
-## Plotting the amplitude of the complex object
-#ax1.imshow(np.absolute(objectGuess), cmap='viridis')
-#ax1.set_title('Amplitude')
-#
-## Plotting the phase of the complex object
-#ax2.imshow(np.angle(objectGuess), cmap='viridis')
-#ax2.set_title('Phase')
-#
-## Adjust layout
-#plt.tight_layout()
-#plt.show()
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py b/build/lib/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py
deleted file mode 100644
index 9c653ea..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py
+++ /dev/null
@@ -1,266 +0,0 @@
-# ptycho_simulation.py
-
-import numpy as np
-import matplotlib.pyplot as plt
-from mpl_toolkits.axes_grid1 import make_axes_locatable
-from typing import Union, Tuple, Dict
-from ptycho.loader import RawData
-from ptycho import tf_helper as hh
-from ptycho import probe
-from ptycho import baselines as bl
-
-def load_probe_object(file_path: str) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Load object and probe guesses from a .npz file.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-
-    Returns:
-        tuple: A tuple containing (objectGuess, probeGuess)
-
-    Raises:
-        ValueError: If required data is missing from the .npz file or if data is invalid.
-        RuntimeError: If an error occurs during file loading.
-    """
-    try:
-        with np.load(file_path) as data:
-            if 'objectGuess' not in data or 'probeGuess' not in data:
-                raise ValueError("The .npz file must contain 'objectGuess' and 'probeGuess'")
-            
-            objectGuess = data['objectGuess']
-            probeGuess = data['probeGuess']
-
-        # Validate extracted data
-        if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-            raise ValueError("objectGuess and probeGuess must be 2D arrays")
-        if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-            raise ValueError("objectGuess and probeGuess must be complex-valued")
-
-        return objectGuess, probeGuess
-
-    except Exception as e:
-        raise RuntimeError(f"Error loading data from {file_path}: {str(e)}")
-
-from ptycho.misc import memoize_simulated_data
-
-#@memoize_simulated_data
-def generate_simulated_data(objectGuess: np.ndarray, probeGuess: np.ndarray, nimages: int, buffer: float, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    Args:
-        objectGuess (np.ndarray): Complex-valued 2D array representing the object.
-        probeGuess (np.ndarray): Complex-valued 2D array representing the probe.
-        nimages (int): Number of scan positions to generate.
-        buffer (float): Border size to avoid when generating coordinates.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation.
-    """
-    # Input validation
-    if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-        raise ValueError("objectGuess and probeGuess must be 2D arrays")
-    if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-        raise ValueError("objectGuess and probeGuess must be complex-valued")
-    if nimages <= 0 or buffer < 0:
-        raise ValueError("nimages must be positive and buffer must be non-negative")
-
-    # Get object dimensions
-    height, width = objectGuess.shape
-
-    # Ensure buffer doesn't exceed image dimensions
-    buffer = min(buffer, min(height, width) / 2 - 1)
-
-    # Set random seed if provided
-    if random_seed is not None:
-        np.random.seed(random_seed)
-
-    # Generate random coordinates (floats)
-    xcoords = np.random.uniform(buffer, width - buffer, nimages)
-    ycoords = np.random.uniform(buffer, height - buffer, nimages)
-
-    # Create scan_index
-    scan_index = np.zeros(nimages, dtype=int)
-
-    # Generate simulated data
-    return RawData.from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index, return_patches=return_patches)
-
-def simulate_from_npz(file_path: str, nimages: int, buffer: float = None, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Load object and probe guesses from a .npz file and generate simulated ptychography data.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-        nimages (int): Number of scan positions to generate.
-        buffer (float, optional): Border size to avoid when generating coordinates. 
-                                  If None, defaults to 35% of the smaller dimension of objectGuess.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation or file loading.
-    """
-    # Load guesses from file
-    objectGuess, probeGuess = load_probe_object(file_path)
-
-    # Set default buffer if not provided
-    if buffer is None:
-        buffer = min(objectGuess.shape) * 0.35  # 35% of the smaller dimension
-
-    # Generate simulated data
-    return generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches=return_patches)
-
-def plot_complex_image(ax: plt.Axes, data: np.ndarray, title: str) -> None:
-    """Helper function to plot complex-valued images."""
-    im = ax.imshow(np.abs(data), cmap='viridis')
-    ax.set_title(f"{title} (Magnitude)")
-    divider = make_axes_locatable(ax)
-    cax = divider.append_axes("right", size="5%", pad=0.05)
-    plt.colorbar(im, cax=cax)
-
-    ax_phase = divider.append_axes("bottom", size="100%", pad=0.2, sharex=ax)
-    im_phase = ax_phase.imshow(np.angle(data), cmap='hsv')
-    ax_phase.set_title(f"{title} (Phase)")
-    cax_phase = divider.append_axes("bottom", size="5%", pad=0.5)
-    plt.colorbar(im_phase, cax=cax_phase, orientation="horizontal")
-
-def visualize_simulated_data(data: Dict[str, np.ndarray], output_dir: str) -> None:
-    """
-    Visualize the simulated ptychography data and save all plots in a single image file.
-
-    Args:
-        data (dict): Dictionary containing the loaded simulated data.
-        output_dir (str): Directory to save the output plot.
-    """
-    import os
-
-    # Create output directory if it doesn't exist
-    os.makedirs(output_dir, exist_ok=True)
-
-    # Create a large figure with multiple subplots
-    fig = plt.figure(figsize=(24, 30))
-    gs = fig.add_gridspec(5, 3, height_ratios=[1, 0.2, 1, 0.2, 1])
-
-    # Plot probe guess
-    ax_probe = fig.add_subplot(gs[0, 0])
-    plot_complex_image(ax_probe, data['probe_guess'], "Probe Guess")
-
-    # Plot object guess
-    ax_object = fig.add_subplot(gs[0, 1])
-    plot_complex_image(ax_object, data['object'], "Object Guess")
-
-    # Plot scan positions
-    ax_scan = fig.add_subplot(gs[0, 2])
-    ax_scan.scatter(data['x_coordinates'], data['y_coordinates'], alpha=0.5)
-    ax_scan.set_title("Scan Positions")
-    ax_scan.set_xlabel("X Coordinate")
-    ax_scan.set_ylabel("Y Coordinate")
-    ax_scan.set_aspect('equal')
-
-    # Add title for diffraction patterns
-    fig.text(0.5, 0.62, "Sample Diffraction Patterns", ha='center', va='center', fontsize=16)
-
-    # Plot a sample of diffraction patterns
-    for i in range(3):
-        if i < min(3, data['diffraction_patterns'].shape[0]):
-            ax = fig.add_subplot(gs[2, i])
-            im = ax.imshow(np.log(data['diffraction_patterns'][i]), cmap='viridis')
-            ax.set_title(f"Pattern {i}")
-            plt.colorbar(im, ax=ax)
-
-    # Add title for ground truth patches
-    fig.text(0.5, 0.22, "Sample Ground Truth Patches", ha='center', va='center', fontsize=16)
-
-    # Plot ground truth patches
-    for i in range(3):
-        if i < min(3, data['ground_truth_patches'].shape[0]):
-            ax = fig.add_subplot(gs[4, i])
-            plot_complex_image(ax, data['ground_truth_patches'][i], f"Patch {i}")
-
-    plt.tight_layout()
-    plt.savefig(os.path.join(output_dir, "simulated_data_visualization.png"), dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-    print(f"All plots have been saved to: {os.path.join(output_dir, 'simulated_data_visualization.png')}")
-
-def plot_random_groups(tmp: RawData, K: int, figsize: Tuple[int, int] = (15, 5), seed: int = None) -> None:
-    """
-    Plot a random selection of K groups of (diffraction image, Y amplitude, Y phase) from a RawData object.
-
-    Args:
-        tmp (RawData): The RawData object containing the ptychography data.
-        K (int): Number of groups to plot.
-        figsize (tuple): Figure size for each group plot. Default is (15, 5).
-        seed (int): Random seed for reproducibility. Default is None.
-
-    Raises:
-        ValueError: If K is greater than the number of available diffraction patterns.
-    """
-    if K > tmp.diff3d.shape[0]:
-        raise ValueError(f"K ({K}) cannot be greater than the number of diffraction patterns ({tmp.diff3d.shape[0]})")
-
-    # Set random seed if provided
-    if seed is not None:
-        np.random.seed(seed)
-
-    # Randomly select K indices
-    indices = np.random.choice(tmp.diff3d.shape[0], K, replace=False)
-
-    for idx in indices:
-        fig, axes = plt.subplots(1, 3, figsize=figsize)
-        fig.suptitle(f"Group {idx}")
-
-        # Plot diffraction image (log scale for better visibility)
-        diff_img = axes[0].imshow(np.log1p(1 + 100 * tmp.diff3d[idx]), cmap='jet')
-        axes[0].set_title("Diffraction (log scale)")
-        plt.colorbar(diff_img, ax=axes[0])
-
-        # Plot Y amplitude
-        amp_img = axes[1].imshow(np.abs(tmp.Y[idx]), cmap='viridis')
-        axes[1].set_title("Y Amplitude")
-        plt.colorbar(amp_img, ax=axes[1])
-
-        # Plot Y phase
-        phase_img = axes[2].imshow(np.angle(tmp.Y[idx]), cmap='twilight')
-        axes[2].set_title("Y Phase")
-        plt.colorbar(phase_img, ax=axes[2])
-
-        # Remove axis ticks for cleaner look
-        for ax in axes:
-            ax.set_xticks([])
-            ax.set_yticks([])
-
-        plt.tight_layout()
-        plt.show()
-
-def compare_reconstructions(obj_tensor_full: np.ndarray, global_offsets: np.ndarray, ground_truth: np.ndarray, ptychonn_tensor: np.ndarray) -> None:
-    """
-    Compare the reconstructed object with the ground truth and PtychoNN prediction.
-
-    Args:
-        obj_tensor_full (np.ndarray): Full reconstructed object tensor.
-        global_offsets (np.ndarray): Global offsets for positioning.
-        ground_truth (np.ndarray): Ground truth object.
-        ptychonn_tensor (np.ndarray): PtychoNN predicted object tensor.
-    """
-    from ptycho import nbutils
-    irange = int(np.max(global_offsets[:, 0, 1, 0]) - np.min(global_offsets[:, 0, 1, 0]))
-    trimmed_ground_truth = hh.trim_reconstruction(ground_truth[None, ..., None], irange)[0, :, :, 0]
-    
-    nbutils.compare(obj_tensor_full, global_offsets, trimmed_ground_truth, ptychonn_tensor=ptychonn_tensor)
-
-# Add any additional helper functions or classes as needed
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/params.py b/build/lib/build/lib/build/lib/build/lib/ptycho/params.py
deleted file mode 100644
index 3215103..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/params.py
+++ /dev/null
@@ -1,86 +0,0 @@
-"""
-Stores global variables for data generation and model configuration
-"""
-import numpy as np
-import tensorflow as tf
-# TODO naming convention for different types of parameters
-# TODO what default value and initialization for the probe scale?
-cfg = {
-    'N': 64, 'offset': 4, 'gridsize': 2,
-    'outer_offset_train': None, 'outer_offset_test': None, 'batch_size': 16,
-    'nepochs': 60, 'n_filters_scale': 2, 'output_prefix': 'outputs',
-    'big_gridsize': 10, 'max_position_jitter': 10, 'sim_jitter_scale': 0.,
-    'default_probe_scale': 0.7, 'mae_weight': 0., 'nll_weight': 1., 'tv_weight': 0.,
-    'realspace_mae_weight': 0., 'realspace_weight': 0., 'nphotons': 1e9,
-    'nimgs_train': 9, 'nimgs_test': 3,
-    'data_source': 'generic', 'probe.trainable': False,
-    'intensity_scale.trainable': False, 'positions.provided': False,
-    'object.big': True, 'probe.big': False, 'probe_scale': 10., 'set_phi': False,
-    'probe.mask': True, 'pad_object': True, 'model_type': 'pinn', 'label': '', 'size': 392,
-    'amp_activation': 'sigmoid', 'h5_path': 'wts.h5', 'npseed': 42,
-    'debug': True,
-    'gaussian_smoothing_sigma': 0.0  # New parameter for Gaussian smoothing sigma
-    }
-
-# TODO parameter description
-# probe.big: if True, increase the real space solution from 32x32 to 64x64
-
-# TODO bigoffset should be a derived quantity, at least for simulation
-def get_bigN():
-    N = cfg['N']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return N + (gridsize - 1) * offset
-
-def get_padding_size():
-    buffer = cfg['max_position_jitter']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return (gridsize - 1) * offset + buffer
-
-def get_padded_size():
-    bigN = get_bigN()
-    buffer = cfg['max_position_jitter']
-    return bigN + buffer
-
-def params():
-    d = {k:v for k, v in cfg.items()}
-    d['bigN'] = get_bigN()
-    return d
-
-# TODO refactor
-def validate():
-    valid_data_sources = ['lines', 'grf', 'experimental', 'points',
-        'testimg', 'diagonals', 'xpp', 'V', 'generic']
-    assert cfg['data_source'] in valid_data_sources, \
-        f"Invalid data source: {cfg['data_source']}. Must be one of {valid_data_sources}."
-    if cfg['realspace_mae_weight'] > 0.:
-        assert cfg['realspace_weight'] > 0
-    return True
-
-def set(key, value):
-    print("DEBUG: Setting", key, "to", value, "in params")
-    cfg[key] = value
-    assert validate()
-
-def get(key):
-    if key == 'bigN':
-        cfg['bigN'] = get_bigN()
-        return cfg['bigN']
-    return cfg[key]
-
-def print_params():
-    """Print all parameters with special handling for arrays/tensors"""
-    all_params = params()
-    print("Current Parameters:")
-    print("-" * 20)
-    for key, value in sorted(all_params.items()):
-        if isinstance(value, (np.ndarray, tf.Tensor)):
-            print(f"{key}:")
-            print(f"  shape: {value.shape}")
-            print(f"  mean: {np.mean(value):.3f}")
-            print(f"  std: {np.std(value):.3f}")
-            print(f"  min: {np.min(value):.3f}")
-            print(f"  max: {np.max(value):.3f}")
-        else:
-            print(f"{key}: {value}")
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/physics.py b/build/lib/build/lib/build/lib/build/lib/ptycho/physics.py
deleted file mode 100644
index a19c0e5..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/physics.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from . import params as p
-from . import tf_helper as hh
-import tensorflow as tf
-import numpy as np
-import pdb
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/plotting.py b/build/lib/build/lib/build/lib/build/lib/ptycho/plotting.py
deleted file mode 100644
index f02404a..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/plotting.py
+++ /dev/null
@@ -1,94 +0,0 @@
-import matplotlib.pyplot as plt
-from ipywidgets import interactive
-
-def ishow_imgs(*arrs_list, styles = None, labels = None,
-              log = False, height = '550px',
-              nested_label_callback = None):
-    """
-    Plot a series of curves interactively.
-    """
-    plt.rcParams["figure.figsize"]=(12, 9)
-    #labels = [label1, label2]
-    if labels is None:
-        labels = [''] * len(arrs_list)
-    def f(i):
-        for j, patterns in enumerate(arrs_list):
-            if styles is not None:
-                extra_args = (styles[j],)
-            else:
-                extra_args = ()
-            try:
-                for k in range(len(patterns[i])):
-                    len(patterns[i][k]) # TODO hack
-                    if nested_label_callback is not None:
-                        label = nested_label_callback(patterns[i], k)
-                    else:
-                        label = k
-                    plt.imshow(patterns[i][k], *extra_args, label = label)
-            except: # TODO except what?
-                if j < 2:
-                    plt.imshow(patterns[i], label = labels[j])
-                else:
-                    plt.imshow(patterns[i], *extra_args)
-
-    interactive_plot = interactive(f, i=(0, len(arrs_list[0]) - 1), step = 1)
-    output = interactive_plot.children[-1]
-    output.layout.height = height
-    return interactive_plot
-
-# Implementing actual plotting functions and the decorator for visual output
-
-import matplotlib.pyplot as plt
-import numpy as np
-
-from functools import wraps
-
-def plotting_function(func):
-    @wraps(func)
-    def wrapper(layout=(1, 1), display: bool = False, save: bool = False, save_path: str = "", *args, **kwargs):
-        standalone = 'ax' not in kwargs or kwargs['ax'] is None
-        if standalone:
-            fig, axs = plt.subplots(layout[0], layout[1], figsize=(layout[1]*3, layout[0]*3))
-            if layout == (1, 1):
-                axs = np.array([axs])
-            else:
-                axs = axs.reshape(layout[0], layout[1])
-            kwargs['ax'] = axs
-        result = func(*args, **kwargs)
-        if standalone:
-            plt.tight_layout()
-            if save:
-                plt.savefig(save_path if save_path else "/mnt/data/plot.png")
-            if display:
-                plt.show()
-        return result
-    return wrapper
-
-@plotting_function
-def plot_subfigure(ax=None, title: str = "Subfigure", *args, **kwargs):
-    rows, cols = ax.shape if isinstance(ax, np.ndarray) else (1, 1)
-    for i in range(rows):
-        for j in range(cols):
-            ax[i, j].plot([1, 2, 3], [1, 2, 3])
-            ax[i, j].set_title(f"{title} {i+1},{j+1}")
-
-def compose_and_save_figure():
-    fig = plt.figure(figsize=(10, 6))
-    gs = fig.add_gridspec(2, 2)
-
-    ax1 = fig.add_subplot(gs[0, 0])
-    ax2 = fig.add_subplot(gs[0, 1])
-    ax3 = fig.add_subplot(gs[1, :])
-
-    # Adjusting the plotting function to accept individual Axes
-    plot_subfigure(ax=np.array([[ax1]]), title="Plot 1")
-    plot_subfigure(ax=np.array([[ax2]]), title="Plot 2")
-    plot_subfigure(ax=np.array([[ax3]]), layout=(1, 1), title="Plot 3")
-
-    plt.tight_layout()
-    save_path = "/mnt/data/composed_figure.png"
-    plt.savefig(save_path)
-    plt.show()
-## To visually check, we'll call the plot_subfigure function directly with a layout parameter for standalone mode
-#plot_subfigure(layout=(2, 2), display=True, save=True, title="Standalone Plot", save_path="/mnt/data/standalone_plot.png")
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/probe.py b/build/lib/build/lib/build/lib/build/lib/ptycho/probe.py
deleted file mode 100644
index 387fcf0..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/probe.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import tensorflow as tf
-import numpy as np
-from . import fourier as f
-from . import params
-
-def get_lowpass_filter(scale, N):
-    return f.lowpass_g(scale, np.ones(N), sym=True)
-
-def get_default_probe(N, fmt='tf'):
-    scale = params.cfg['default_probe_scale']
-    filt = get_lowpass_filter(scale, N)
-    probe_np = f.gf(((np.einsum('i,j->ij', filt, filt)) > .5).astype(float), 1) + 1e-9
-    if fmt == 'np':
-        return probe_np
-    elif fmt == 'tf':
-        return tf.convert_to_tensor(probe_np, tf.complex64)[..., None]
-    else:
-        raise ValueError("Invalid format specified")
-
-def get_probe(params):
-    probe_tf = params.get('probe')
-    assert len(probe_tf.shape) == 3
-    return probe_tf
-
-def to_np(probe):
-    assert len(probe.shape) == 3
-    return np.array(probe[:, :, 0])
-
-def get_squared_distance(N):
-    centered_indices = np.arange(N) - N // 2 + .5
-    x, y = np.meshgrid(centered_indices, centered_indices)
-    return np.sqrt(x*x+y*y)
-
-def get_probe_mask_real(N):
-    return (get_squared_distance(N) < N // 4)[..., None]
-
-def get_probe_mask(N):
-    probe_mask_real = get_probe_mask_real(N)
-    probe_mask = tf.convert_to_tensor(probe_mask_real, tf.complex64)
-    #return tf.convert_to_tensor(probe_mask, tf.complex64)[..., None]
-    return tf.convert_to_tensor(probe_mask, tf.complex64)
-
-def set_probe(probe):
-    assert len(probe.shape) == 3 or len(probe.shape) == 4
-    assert probe.shape[0] == probe.shape[1]
-    assert probe.shape[-1] == 1
-    if len(probe.shape) == 4:
-        assert probe.shape[-2] == 1
-        probe = probe[:, :, :]
-        print('coercing probe shape to 3d')
-
-    # This function still modifies global state
-    mask = tf.cast(get_probe_mask(params.get('N')), probe.dtype)
-    probe_scale = params.get('probe_scale')
-    tamped_probe = mask * probe
-    norm = float(probe_scale * tf.reduce_mean(tf.math.abs(tamped_probe)))
-    params.set('probe', probe / norm)
-
-def set_probe_guess(X_train = None, probe_guess = None):
-    N = params.get('N')
-    if probe_guess is None:
-        mu = 0.
-        tmp = X_train.mean(axis = (0, 3))
-        probe_fif = np.absolute(f.fftshift(f.ifft2(f.ifftshift(tmp))))[N // 2, :]
-
-        # variance increments of a slice down the middle
-        d_second_moment = (probe_fif / probe_fif.sum()) * ((np.arange(N) - N // 2)**2)
-        probe_sigma_guess = np.sqrt(d_second_moment.sum())
-        probe_guess = np.exp(-( (get_squared_distance(N) - mu)**2 / ( 2.0 * probe_sigma_guess**2 )))[..., None]\
-            + 1e-9
-        probe_guess *= get_probe_mask_real(N)
-        probe_guess *= (np.sum(get_default_probe(N)) / np.sum(probe_guess))
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.float32)
-    else:
-        if probe_guess.ndim not in [2, 3]:
-            raise ValueError("probe_guess must have 2 or 3 dimensions")
-        if probe_guess.ndim == 2:
-            probe_guess = probe_guess[..., None]
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.complex64)
-
-    #params.set('probe', t_probe_guess)
-    set_probe(t_probe_guess)
-    return t_probe_guess
-
-def set_default_probe():
-    """
-    use an idealized disk shaped probe. Only for simulated data workflows.
-    """
-    set_probe(get_default_probe(params.get('N'), fmt = 'tf'))
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/raw_data.py b/build/lib/build/lib/build/lib/build/lib/ptycho/raw_data.py
deleted file mode 100644
index 16131a2..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/raw_data.py
+++ /dev/null
@@ -1,474 +0,0 @@
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional
-from scipy.spatial import cKDTree
-from ptycho import params
-from ptycho.autotest.debug import debug
-from ptycho import diffsim as datasets
-from ptycho import tf_helper as hh
-
-# Constants, # TODO cleanup / refactor
-local_offset_sign = 1
-key_coords_offsets = 'coords_start_offsets'
-key_coords_relative = 'coords_start_relative'
-
-class RawData:
-    #@debug
-    def __init__(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess,
-             scan_index, objectGuess = None, Y = None, norm_Y_I = None):
-        # Sanity checks
-        self._check_data_validity(xcoords, ycoords, xcoords_start, ycoords_start, diff3d,
-                    probeGuess, scan_index)
-
-        # TODO these should go in the data validation method
-        assert len(xcoords.shape) == 1, f"Expected xcoords to be 1D, got shape {xcoords.shape}"
-        assert len(ycoords.shape) == 1, f"Expected ycoords to be 1D, got shape {ycoords.shape}"
-        assert len(xcoords_start.shape) == 1, f"Expected xcoords_start to be 1D, got shape {xcoords_start.shape}"
-        assert len(ycoords_start.shape) == 1, f"Expected ycoords_start to be 1D, got shape {ycoords_start.shape}"
-        if diff3d is not None:
-            assert len(diff3d.shape) == 3, f"Expected diff3d to be 3D, got shape {diff3d.shape}"
-            print(f"diff3d shape: {diff3d.shape}")
-            assert diff3d.shape[1] == diff3d.shape[2]
-        if probeGuess is not None:
-            assert len(probeGuess.shape) == 2, f"Expected probeGuess to be 2D, got shape {probeGuess.shape}"
-            print(f"probeGuess shape: {probeGuess.shape}")
-        if scan_index is not None:
-            assert len(scan_index.shape) == 1, f"Expected scan_index to be 1D, got shape {scan_index.shape}"
-            print(f"scan_index shape: {scan_index.shape}")
-        if objectGuess is not None:
-            print(f"objectGuess shape: {objectGuess.shape}")
-            assert len(objectGuess.shape) == 2
-
-        print(f"xcoords shape: {xcoords.shape}")
-        print(f"ycoords shape: {ycoords.shape}")
-        print(f"xcoords_start shape: {xcoords_start.shape}")
-        print(f"ycoords_start shape: {ycoords_start.shape}")
-
-        # Assigning values if checks pass
-        self.xcoords = xcoords
-        self.ycoords = ycoords
-        self.xcoords_start = xcoords_start
-        self.ycoords_start = ycoords_start
-        self.diff3d = diff3d
-        self.probeGuess = probeGuess
-        self.scan_index = scan_index
-        self.objectGuess = objectGuess
-        # TODO validity checks
-        self.Y = Y
-        self.norm_Y_I = norm_Y_I
-
-    @staticmethod
-    #@debug
-    def from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index,
-                               objectGuess=None):
-        """
-        Static method to create a RawData instance without separate start coordinates.
-        The start coordinates are set to be the same as the xcoords and ycoords.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        return RawData(xcoords, ycoords, xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-
-    @staticmethod
-    def from_simulation(xcoords, ycoords, probeGuess,
-                 objectGuess, scan_index = None):
-        """
-        Create a RawData instance from simulation data.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            objectGuess (np.ndarray): initial guess of the object.
-            scan_index (np.ndarray, optional): array indicating the scan index for each diffraction pattern.
-
-        Returns:
-            RawData: An instance of the RawData class with simulated data.
-        """
-        from ptycho.diffsim import illuminate_and_diffract
-        xcoords_start = xcoords
-        ycoords_start = ycoords
-        global_offsets, local_offsets, nn_indices = calculate_relative_coords(
-                    xcoords, ycoords)
-
-        Y_obj = get_image_patches(objectGuess, global_offsets, local_offsets) 
-        Y_I = tf.math.abs(Y_obj)
-        Y_phi = tf.math.angle(Y_obj)
-        X, Y_I_xprobe, Y_phi_xprobe, intensity_scale = illuminate_and_diffract(Y_I, Y_phi, probeGuess)
-        norm_Y_I = datasets.scale_nphotons(X)
-        assert X.shape[-1] == 1, "gridsize must be set to one when simulating in this mode"
-        # TODO RawData should have a method for generating the illuminated ground truth object
-        return RawData(xcoords, ycoords, xcoords_start, ycoords_start, tf.squeeze(X).numpy(),
-                       probeGuess, scan_index, objectGuess,
-                       Y = tf.squeeze(hh.combine_complex( Y_I_xprobe, Y_phi_xprobe)).numpy(),
-                       norm_Y_I = norm_Y_I)
-
-    #@debug
-    def __str__(self):
-        parts = [
-            "RawData:",
-            f"  xcoords: {self.xcoords.shape if self.xcoords is not None else 'None'}",
-            f"  ycoords: {self.ycoords.shape if self.ycoords is not None else 'None'}",
-            f"  xcoords_start: {self.xcoords_start.shape if self.xcoords_start is not None else 'None'}",
-            f"  ycoords_start: {self.ycoords_start.shape if self.ycoords_start is not None else 'None'}",
-            f"  diff3d: {self.diff3d.shape if self.diff3d is not None else 'None'}",
-            f"  probeGuess: {self.probeGuess.shape if self.probeGuess is not None else 'None'}",
-            f"  scan_index: {self.scan_index.shape if self.scan_index is not None else 'None'}",
-            f"  objectGuess: {self.objectGuess.shape if self.objectGuess is not None else 'None'}"
-        ]
-        return "\n".join(parts)
-
-    #@debug
-    def to_file(self, file_path: str) -> None:
-        """
-        Method to write the RawData object to a file using numpy.savez.
-
-        Args:
-            file_path (str): Path to the file where the data will be saved.
-        """
-        np.savez(file_path,
-                 xcoords=self.xcoords,
-                 ycoords=self.ycoords,
-                 xcoords_start=self.xcoords_start,
-                 ycoords_start=self.ycoords_start,
-                 diff3d=self.diff3d,
-                 probeGuess=self.probeGuess,
-                 objectGuess=self.objectGuess,
-                 scan_index=self.scan_index)
-
-    @staticmethod
-    #@debug
-    def from_file(train_data_file_path: str) -> 'RawData':
-        """
-        Static method to create a RawData instance from a file.
-
-        Args:
-            train_data_file_path (str): Path to the file containing the data.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        # Load training data
-        train_data = np.load(train_data_file_path)
-        train_raw_data = RawData(
-            xcoords=train_data['xcoords'],
-            ycoords=train_data['ycoords'],
-            xcoords_start=train_data['xcoords_start'],
-            ycoords_start=train_data['ycoords_start'],
-            diff3d=train_data['diff3d'],
-            probeGuess=train_data['probeGuess'],
-            objectGuess=train_data['objectGuess'],
-            scan_index=train_data['scan_index']
-        )
-        return train_raw_data
-
-    @staticmethod
-    #@debug
-    def from_files(train_data_file_path, test_data_file_path):
-        """
-        Static method to instantiate RawData objects from training and test data files.
-
-        The data files should be NumPy .npz files with the following keys:
-        - 'xcoords': x coordinates of the scan points
-        - 'ycoords': y coordinates of the scan points
-        - 'xcoords_start': starting x coordinates for the scan
-        - 'ycoords_start': starting y coordinates for the scan
-        - 'diff3d': diffraction patterns
-        - 'probeGuess': initial guess of the probe function
-        - 'scan_index': array indicating the scan index for each diffraction pattern
-
-        Args:
-            train_data_file_path (str): Path to the training data file.
-            test_data_file_path (str): Path to the test data file.
-
-        Returns:
-            tuple: A tuple containing the instantiated RawData objects for training and test data.
-        """
-        # Load training data
-        train_raw_data = RawData.from_file(train_data_file_path)
-
-        # Load test data
-        test_raw_data = RawData.from_file(test_data_file_path)
-
-        return train_raw_data, test_raw_data
-
-    #@debug
-    def generate_grouped_data(self, N, K = 7, nsamples = 1):
-        """
-        Generate nearest-neighbor solution region grouping.
-
-        Args:
-            N (int): Size of the solution region.
-            K (int, optional): Number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): Number of samples. Defaults to 1.
-
-        Returns:
-            dict: Dictionary containing grouped data.
-        """
-        print('DEBUG:', 'nsamples:', nsamples)
-        return get_neighbor_diffraction_and_positions(self, N, K=K, nsamples=nsamples)
-
-    #@debug
-    def _check_data_validity(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-        """
-        Check if the input data is valid.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            xcoords_start (np.ndarray): starting x coordinates for the scan.
-            ycoords_start (np.ndarray): starting y coordinates for the scan.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-
-        Raises:
-            ValueError: If coordinate arrays don't have matching shapes.
-        """
-        # Check if coordinate arrays have matching shapes
-        if not (xcoords.shape == ycoords.shape == xcoords_start.shape == ycoords_start.shape):
-            raise ValueError("Coordinate arrays must have matching shapes.")
-
-#@debug
-def calculate_relative_coords(xcoords, ycoords, K = 6, C = None, nsamples = 10):
-    """
-    Group scan indices and coordinates into solution regions, then
-    calculate coords_offsets (global solution region coordinates) and
-    coords_relative (local solution patch coords) from ptycho_data using
-    the provided index_grouping_cb callback function.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        tuple: A tuple containing coords_offsets, coords_relative, and nn_indices.
-    """
-    nn_indices, coords_nn = group_coords(xcoords, ycoords, K = K, C = C, nsamples = nsamples)
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-    return coords_offsets, coords_relative, nn_indices
-
-#@debug
-def get_image_patches(gt_image, global_offsets, local_offsets):
-    """
-    Generate and return image patches in channel format using a single canvas.
-
-    Args:
-        gt_image (tensor): Ground truth image tensor.
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Image patches in channel format.
-    """
-    # Get necessary parameters
-    gridsize = params.get('gridsize')
-    N = params.get('N')
-    B = global_offsets.shape[0]
-    c = gridsize**2
-
-    # Pad the ground truth image once
-    gt_padded = hh.pad(gt_image[None, ..., None], N // 2)
-
-    # Calculate the combined offsets by adding global and local offsets
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    offsets_f = hh._channel_to_flat(offsets_c)
-
-    # Create a canvas to store the extracted patches
-    canvas = np.zeros((B, N, N, c))
-
-    # Iterate over the combined offsets and extract patches one by one
-    for i in range(B * c):
-        offset = -offsets_f[i, :, :, 0]
-        translated_patch = hh.translate(gt_padded, offset)
-        canvas[i // c, :, :, i % c] = np.array(translated_patch)[0, :N, :N, 0]
-
-    # Convert the canvas to a TensorFlow tensor and return it
-    return tf.convert_to_tensor(canvas)
-
-#@debug
-def group_coords(xcoords: np.ndarray, ycoords: np.ndarray, K: int, C: Optional[int], nsamples: int) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int): Number of nearest neighbors to consider.
-        C (Optional[int]): Number of coordinates per solution region. If None, uses gridsize^2.
-        nsamples (int): Number of samples to generate.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray]: A tuple containing:
-            - nn_indices: shape (M, C)
-            - coords_nn: shape (M, 1, 2, C)
-    """
-    gridsize = params.get('gridsize')
-    if C is None:
-        C = gridsize**2
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords, ycoords)
-    else:
-        nn_indices = get_neighbor_indices(xcoords, ycoords, K=K)
-        nn_indices = sample_rows(nn_indices, C, nsamples).reshape(-1, C)
-
-    coords_nn = np.transpose(np.array([xcoords[nn_indices],
-                            ycoords[nn_indices]]),
-                            [1, 0, 2])[:, None, :, :]
-    return nn_indices, coords_nn[:, :, :, :]
-
-#@debug
-def get_relative_coords(coords_nn):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, 1, 2, C).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    assert len(coords_nn.shape) == 4
-    coords_offsets = np.mean(coords_nn, axis=3)[..., None]
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-    return coords_offsets, coords_relative
-
-#@debug
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    Assign each pattern index to itself.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-
-    Returns:
-        np.ndarray: Array of self-indices.
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-#@debug
-def get_neighbor_indices(xcoords, ycoords, K = 3):
-    """
-    Get K nearest neighbor indices for each point.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors to find. Defaults to 3.
-
-    Returns:
-        np.ndarray: Array of nearest neighbor indices.
-    """
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-#@debug
-def sample_rows(indices, n, m):
-    """
-    Sample rows from the given indices.
-
-    Args:
-        indices (np.ndarray): Array of indices to sample from.
-        n (int): Number of samples per row.
-        m (int): Number of rows to generate.
-
-    Returns:
-        np.ndarray: Sampled indices array.
-    """
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-#@debug
-def get_neighbor_diffraction_and_positions(ptycho_data, N, K=6, C=None, nsamples=10):
-    """
-    Get neighbor diffraction patterns and positions.
-
-    Args:
-        ptycho_data (RawData): An instance of the RawData class.
-        N (int): Size of the solution region.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        dict: A dictionary containing grouped data and metadata.
-    """
-    nn_indices, coords_nn = group_coords(ptycho_data.xcoords, ptycho_data.ycoords,
-                                         K = K, C = C, nsamples = nsamples)
-
-    diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-    if ptycho_data.Y is not None:
-        Y4d_nn = np.transpose(ptycho_data.Y[nn_indices], [0, 2, 3, 1])
-    else:
-        Y4d_nn = None
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if ptycho_data.xcoords_start is not None:
-        coords_start_nn = np.transpose(np.array([ptycho_data.xcoords_start[nn_indices], ptycho_data.ycoords_start[nn_indices]]),
-                                       [1, 0, 2])[:, None, :, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'Y': Y4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    """
-    Normalize the diffraction data.
-
-    Args:
-        dset (dict): Dictionary containing the dataset.
-        N (int): Size of the solution region.
-
-    Returns:
-        np.ndarray: Normalized diffraction data.
-    """
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    return X_full_norm * X_full
-
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py b/build/lib/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
deleted file mode 100644
index e283054..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import numpy as np
-from ptycho.nongrid_simulation import generate_simulated_data
-from ptycho.loader import RawData
-import os
-import shutil
-
-def test_memoize_simulated_data():
-    # Create sample input data
-    objectGuess = np.random.rand(128, 128) + 1j * np.random.rand(128, 128)
-    probeGuess = np.random.rand(32, 32) + 1j * np.random.rand(32, 32)
-    nimages = 100
-    buffer = 10
-    random_seed = 42
-
-    # Clear the cache directory before starting the test
-    cache_dir = 'memoized_simulated_data'
-    if os.path.exists(cache_dir):
-        shutil.rmtree(cache_dir)
-
-    # First call, should compute the result and cache it
-    result1 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result1, tuple), "Result should be a tuple"
-    assert len(result1) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result1[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result1[1], np.ndarray), "Second element should be a numpy array"
-
-    # Second call, should load the result from the cache
-    result2 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result2, tuple), "Result should be a tuple"
-    assert len(result2) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result2[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result2[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are identical
-    assert np.array_equal(result1[0].diff3d, result2[0].diff3d), "Cached result differs from original"
-    assert np.array_equal(result1[1], result2[1]), "Cached patches differ from original"
-
-    # Third call with different random seed, should compute a new result
-    result3 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed=123)
-    assert isinstance(result3, tuple), "Result should be a tuple"
-    assert len(result3) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result3[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result3[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are different
-    assert not np.array_equal(result1[0].diff3d, result3[0].diff3d), "Results with different seeds should differ"
-
-    print("All tests passed successfully!")
-
-if __name__ == "__main__":
-    test_memoize_simulated_data()
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py b/build/lib/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py
deleted file mode 100644
index e56140a..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from tensorflow.keras.models import Sequential
-from tensorflow.keras.layers import Dense
-from ptycho.model_manager import ModelManager
-
-def test_save_and_load_model():
-    # Create a simple model for testing
-    model = Sequential([
-        Dense(64, activation='relu', input_shape=(32,)),
-        Dense(10, activation='softmax')
-    ])
-    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
-
-    # Define custom objects and intensity scale for testing
-    custom_objects = {'custom_activation': tf.nn.relu}
-    intensity_scale = 2.5
-
-    # Save the model
-    model_path = 'test_model.h5'
-    ModelManager.save_model(model, model_path, custom_objects, intensity_scale)
-
-    # Ensure the .dill file is created
-    assert os.path.exists(model_path + ".dill")
-
-    # Load the model
-    loaded_model = ModelManager.load_model(model_path)
-
-    # Check if the loaded model has the same architecture
-    assert np.array_equal(model.get_weights()[0], loaded_model.get_weights()[0])
-
-    # Clean up
-    os.remove(model_path)
-    os.remove(model_path + ".dill")
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/tf_helper.py b/build/lib/build/lib/build/lib/build/lib/ptycho/tf_helper.py
deleted file mode 100644
index fc1233f..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/tf_helper.py
+++ /dev/null
@@ -1,707 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional, Union, Callable, Any
-
-# Check if there are any GPUs available and set memory growth accordingly
-physical_devices = tf.config.list_physical_devices('GPU')
-if physical_devices:
-    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
-    tf.config.experimental.set_memory_growth(physical_devices[0], True)
-else:
-    print("No GPU found, using CPU instead.")
-
-
-import tensorflow.compat.v2 as tf
-tf.enable_v2_behavior()
-
-from tensorflow.keras import Model
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, UpSampling2D
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import tensorflow_probability as tfp
-
-from .params import params, cfg, get, get_padded_size
-#from .logging import debug
-from .autotest.debug import debug
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-support_threshold = .0
-#@debug
-def get_mask(input: tf.Tensor, support_threshold: float) -> tf.Tensor:
-    mask = tf.where(input > support_threshold, tf.ones_like(input),
-                    tf.zeros_like(input))
-    return mask
-
-#@debug
-def combine_complex(amp: tf.Tensor, phi: tf.Tensor) -> tf.Tensor:
-    output = tf.cast(amp, tf.complex64) * tf.exp(
-        1j * tf.cast(phi, tf.complex64))
-    return output
-
-#@debug
-def pad_obj(input: tf.Tensor, h: int, w: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((h // 4, w // 4), name = 'padded_obj')(input)
-
-#@debug
-def pad_and_diffract(input: tf.Tensor, h: int, w: int, pad: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses sysmmetric FT - L2 norm is conserved
-    """
-    input = tf.ensure_shape(input, (None, h, w, 1))
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = (((fft2d(
-        (tf.cast((input), tf.complex64))[..., 0]
-        ))))
-    input = (( tf.math.real(tf.math.conj((input)) * input) / (h * w)))
-    input = (( tf.expand_dims(
-                              tf.math.sqrt(
-            fftshift(input, (-2, -1))), 3)
-        ))
-    return padded, input
-
-#@debug
-def _fromgrid(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return tf.reshape(img, (-1, N, N, 1))
-
-#@debug
-def _togrid(img: tf.Tensor, gridsize: Optional[int] = None, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e. from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return tf.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-#@debug
-def togrid(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return [_togrid(img) for img in imgs]
-
-#@debug
-def _grid_to_channel(grid: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = tf.transpose(grid, [0, 3, 4, 1, 2, 5], conjugate=False)
-    _, ww, hh = img.shape[:3]
-    img = tf.reshape(img, (-1, ww, hh, gridsize**2))
-    return img
-
-#@debug
-def grid_to_channel(*grids: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_grid_to_channel(g) for g in grids]
-
-#@debug
-def _flat_to_channel(img: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = tf.reshape(img, (-1, gridsize**2, N, N))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _flat_to_channel_2(img: tf.Tensor) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = tf.reshape(img, (-1, gridsize**2, N, M))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _channel_to_flat(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    shape = tf.shape(img)
-    b, h, w, c = shape[0], shape[1], shape[2], shape[3]
-    #_, h, w, c = img.shape
-    img = tf.transpose(img, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, h, w, 1))
-    return img
-
-#@debug
-def _channel_to_patches(channel: tf.Tensor) -> tf.Tensor:
-    """
-    reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = tf.transpose(channel, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-#@debug
-def channel_to_flat(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_channel_to_flat(g) for g in imgs]
-
-#@debug
-def extract_patches(x: tf.Tensor, N: int, offset: int) -> tf.Tensor:
-    return tf.image.extract_patches(
-        x,
-        [1, N, N, 1],
-        [1, offset,offset, 1],
-        [1, 1, 1, 1],
-        padding="VALID"
-    )
-
-#@debug
-def extract_outer(img: tf.Tensor, fmt: str = 'grid',
-        bigN: Optional[int] = None, outer_offset: Optional[int] = None) -> tf.Tensor:#,
-    """
-        Extract big patches (overlapping bigN x bigN regions over an
-        entire input img)
-    """
-    if bigN is None:
-        bigN = get('bigN')
-    assert img.shape[-1] == 1
-    grid = tf.reshape(
-        extract_patches(img, bigN, outer_offset // 2),
-        (-1, bigN, bigN, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)
-    else:
-        raise ValueError
-
-#@debug
-def extract_inner_grid(grid: tf.Tensor) -> tf.Tensor:
-    N = cfg['N']
-    offset = params()['offset']
-    return extract_patches(grid, N, offset)
-
-#@debug
-def extract_nested_patches(img: tf.Tensor, fmt: str = 'flat',
-        extract_inner_fn: Callable[[tf.Tensor], tf.Tensor] = extract_inner_grid,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-
-    This function and extract_outer are only used to extract nominal
-    coordinates, so it is not necessary for them to use jitter padding
-    """
-    N = cfg['N']
-    offset = params()['offset']
-    gridsize = params()['gridsize']
-    assert img.shape[-1] == 1
-    outer_grid = extract_outer(img, fmt = 'grid', **kwargs)
-    grid = tf.reshape(
-        extract_inner_fn(outer_grid),
-        (-1, gridsize, gridsize, N, N, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)#, outer_grid # TODO second output is for debugging
-    else:
-        raise ValueError
-
-#@debug
-def mk_extract_inner_position(offsets_xy: tf.Tensor) -> Callable[[tf.Tensor], Tuple[tf.Tensor]]:
-    #@debug
-    def inner(grid: tf.Tensor) -> Tuple[tf.Tensor]:
-        return extract_patches_position(grid, offsets_xy),
-    return inner
-
-#@debug
-def extract_nested_patches_position(img: tf.Tensor, offsets_xy: tf.Tensor, fmt: str = 'flat',
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-    """
-    return extract_nested_patches(img, fmt = fmt,
-        extract_inner_fn = mk_extract_inner_position(offsets_xy),
-        **kwargs)
-
-@tf.function
-#@debug
-def extract_patches_inverse(y: tf.Tensor, N: int, average: bool, gridsize: Optional[int] = None, offset: Optional[int] = None) -> tf.Tensor:
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if offset is None:
-        offset = params()['offset']
-    target_size = N + (gridsize - 1) * offset
-    b = tf.shape(y)[0]
-
-    _x = tf.zeros((b, target_size, target_size, 1), dtype = y.dtype)
-    _y = extract_patches(_x, N, offset)
-    if average:
-        grad = tf.gradients(_y, _x)[0]
-        return tf.gradients(_y, _x, grad_ys=y)[0] / grad
-    else:
-        return tf.gradients(_y, _x, grad_ys=y)[0]
-
-#@debug
-def reassemble_patches_real(channels: tf.Tensor, average: bool = True, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = _channel_to_patches(channels)
-    N = params()['N']
-    return extract_patches_inverse(real, N, average, **kwargs)
-
-#@debug
-def pad_patches(imgs: tf.Tensor, padded_size: Optional[int] = None) -> tf.Tensor:
-    N = params()['N']
-    if padded_size is None:
-        padded_size = get_padded_size()
-    return tfkl.ZeroPadding2D(((padded_size - N) // 2, (padded_size - N) // 2))(imgs)
-
-#@debug
-def pad(imgs: tf.Tensor, size: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((size, size))(imgs)
-
-#@debug
-def trim_reconstruction(x: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert int(shape[1]) == int(shape[2])
-    try:
-        clipsize = (int(shape[1]) - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize: -clipsize,
-            clipsize: -clipsize, :]
-
-#@debug
-def extract_patches_position(imgs: tf.Tensor, offsets_xy: tf.Tensor, jitter: float = 0.) -> tf.Tensor:
-    """
-    Expects offsets_xy in channel format.
-
-    imgs must be in flat format with a single image per solution region, i.e.
-    (batch size, M, M, 1) where M = N + some padding size.
-
-    Returns shifted images in channel format, cropped symmetrically
-
-    no negative sign
-    """
-    if  imgs.get_shape()[0] is not None:
-        assert int(imgs.get_shape()[0]) == int(offsets_xy.get_shape()[0])
-    assert int(imgs.get_shape()[3]) == 1
-    assert int(offsets_xy.get_shape()[2]) == 2
-    assert int(imgs.get_shape()[3]) == 1
-    gridsize = params()['gridsize']
-    assert int(offsets_xy.get_shape()[3]) == gridsize**2
-    offsets_flat = flatten_offsets(offsets_xy)
-    stacked = tf.repeat(imgs, gridsize**2, axis = 3)
-    flat_padded = _channel_to_flat(stacked)
-    channels_translated = trim_reconstruction(
-        Translation()([flat_padded, offsets_flat, jitter]))
-    return channels_translated
-
-#@debug
-def center_channels(channels: tf.Tensor, offsets_xy: tf.Tensor) -> tf.Tensor:
-    """
-    Undo image patch offsets
-    """
-    ct = Translation()([_channel_to_flat(channels), flatten_offsets(-offsets_xy), 0.])
-    channels_centered = _flat_to_channel(ct)
-    return channels_centered
-
-#@debug
-def is_complex_tensor(tensor: tf.Tensor) -> bool:
-    """Check if the tensor is of complex dtype."""
-    return tensor.dtype in [tf.complex64, tf.complex128]
-
-#@debug
-def complexify_helper(separate: Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]], combine: Callable[[tf.Tensor, tf.Tensor], tf.Tensor]) -> Callable:
-    """
-    Create a "complexify" function based on the provided separation and combination methods.
-    """
-    #@debug
-    def complexify(fn: Callable[..., tf.Tensor]) -> Callable[..., tf.Tensor]:
-        #@debug
-        def newf(*args: Any, **kwargs: Any) -> tf.Tensor:
-            channels = args[0]
-            if is_complex_tensor(channels):
-                part1, part2 = separate(channels)
-                assembled_part1 = fn(part1, *args[1:], **kwargs)
-                assembled_part2 = fn(part2, *args[1:], **kwargs)
-                return combine(assembled_part1, assembled_part2)
-            else:
-                return fn(*args, **kwargs)
-        return newf
-    return complexify
-
-#@debug
-def separate_real_imag(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.real(channels), tf.math.imag(channels)
-
-#@debug
-def combine_real_imag(real: Union[tf.Tensor, np.ndarray], imag: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:
-    return tf.cast(tf.dtypes.complex(real, imag), tf.complex64)
-
-#@debug
-def separate_amp_phase(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.abs(channels), tf.math.angle(channels)
-
-complexify_function = complexify_helper(separate_real_imag, combine_real_imag)
-complexify_amp_phase = complexify_helper(separate_amp_phase, combine_complex)
-complexify_sum_amp_phase = complexify_helper(separate_amp_phase, lambda a, b: a + b)
-complexify_sum_real_imag = complexify_helper(separate_real_imag, lambda a, b: a + b)
-
-
-from tensorflow_addons.image import translate as _translate
-
-#from ptycho.misc import debug
-@complexify_function
-#@debug
-def translate(imgs: tf.Tensor, offsets: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    # TODO assert dimensionality of translations is 2; i.e. B, 2
-    return _translate(imgs, offsets, **kwargs)
-
-# TODO consolidate this and translate()
-class Translation(tf.keras.layers.Layer):
-    def __init__(self) -> None:
-        super(Translation, self).__init__()
-    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor, float]) -> tf.Tensor:
-        imgs, offsets, jitter = inputs
-        jitter = tf.random.normal(tf.shape(offsets), stddev = jitter)
-        return translate(imgs, offsets + jitter, interpolation = 'bilinear')
-
-#@debug
-def flatten_offsets(channels: tf.Tensor) -> tf.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-#@debug
-def pad_reconstruction(channels: tf.Tensor) -> tf.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-#@debug
-def _reassemble_patches_position_real(imgs: tf.Tensor, offsets_xy: tf.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, 0.])
-    if agg:
-        imgs_merged = tf.reduce_sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N = padded_size),
-                    axis = 3)[..., None]
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N = padded_size)
-
-#@debug
-def mk_centermask(inputs: tf.Tensor, N: int, c: int, kind: str = 'center') -> tf.Tensor:
-    b = tf.shape(inputs)[0]
-#    if get('probe.big'):
-#        ones = tf.ones((b, N, N, c), dtype = inputs.dtype)
-#    else:
-#        ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-#        ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-    ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-#@debug
-def mk_norm(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor]) -> tf.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    # TODO if probe.big is True, shouldn't the ones fill the full N x N region?
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average = False)
-    norm = assembled_ones + .001
-    return norm
-
-#@debug
-def reassemble_patches(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = tf.math.real(channels)
-    imag = tf.math.imag(channels)
-    assembled_real = fn_reassemble_real(real, average = average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average = average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return tf.dtypes.complex(assembled_real, assembled_imag)
-
-#@debug
-def shift_and_sum(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    from . import tf_helper as hh
-    assert len(obj_tensor.shape) == 4
-    assert obj_tensor.dtype == np.complex64
-    assert len(global_offsets.shape) == 4
-    assert global_offsets.dtype == np.float64
-    # Extract necessary parameters
-    N = params()['N']
-    # Select the central part of the object tensor
-    obj_tensor = obj_tensor[:, N // 2 - M // 2: N // 2 + M // 2, N // 2 - M // 2: N // 2 + M // 2, :]
-    # Calculate the center of mass of global_offsets
-    center_of_mass = tf.reduce_mean(tf.cast(global_offsets, tf.float32), axis=0)
-    # Adjust global_offsets by subtracting the center of mass
-    adjusted_offsets = tf.cast(global_offsets, tf.float32) - center_of_mass
-    # Calculate dynamic padding based on maximum adjusted offset
-    max_offset = tf.reduce_max(tf.abs(adjusted_offsets))
-    dynamic_pad = int(tf.cast(tf.math.ceil(max_offset), tf.int32))
-    print('PADDING SIZE:', dynamic_pad)
-    
-    # Create a canvas to store the shifted and summed object tensors
-    result = tf.zeros_like(hh.pad(obj_tensor[0:1], dynamic_pad))
-    
-    # Iterate over the adjusted offsets and perform shift-and-sum
-    for i in range(len(adjusted_offsets)):
-        # Apply dynamic padding to the current object tensor
-        padded_obj_tensor = hh.pad(obj_tensor[i:i+1], dynamic_pad)
-        # Squeeze and cast adjusted offset to 2D float for translation
-        offset_2d = tf.cast(tf.squeeze(adjusted_offsets[i]), tf.float32)
-        # Translate the padded object tensor
-        translated_obj = hh.translate(padded_obj_tensor, offset_2d, interpolation='bilinear')
-        # Accumulate the translated object tensor
-        result += translated_obj[0]
-    
-    # TODO: how could we support multiple scans?
-    return result[0]
-
-#@debug
-def reassemble_whole_object(patches: tf.Tensor, offsets: tf.Tensor, size: int = 226, norm: bool = False) -> tf.Tensor:
-    """
-    patches: tensor of shape (B, N, N, gridsize**2) containing reconstruction patches
-
-    reassembles the NxN patches into a single size x size x 1 mage, given the
-        provided offsets
-
-    This function inverts the offsets, so it's not necessary to multiply by -1
-    """
-    img = tf.reduce_sum(
-        reassemble_patches(patches, fn_reassemble_real=mk_reassemble_position_real(
-        offsets, padded_size = size)),
-        axis = 0)
-    if norm:
-        return img / reassemble_whole_object(tf.ones_like(patches), offsets, size = size, norm = False)
-    return img
-
-def reassemble_position(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    ones = tf.ones_like(obj_tensor)
-    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
-        (1e-9 + shift_and_sum(ones, global_offsets, M = M))
-
-#@debug
-def mk_reassemble_position_real(input_positions: tf.Tensor, **outer_kwargs: Any) -> Callable[[tf.Tensor], tf.Tensor]:
-    #@debug
-    def reassemble_patches_position_real(imgs: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-#@debug
-def preprocess_objects(Y_I: np.ndarray, Y_phi: Optional[np.ndarray] = None,
-        offsets_xy: Optional[tf.Tensor] = None, **kwargs: Any) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
-    """
-    Extracts normalized object patches from full real-space images, using the
-    nested grid format.
-    """
-    _Y_I_full = Y_I
-    if Y_phi is None:
-        Y_phi = np.zeros_like(Y_I)
-
-    if offsets_xy is None or tf.math.reduce_all(offsets_xy == 0):
-        print('Sampling on regular grid')
-        Y_I, Y_phi = \
-            [extract_nested_patches(imgs, fmt= 'channel', **kwargs)
-                for imgs in [Y_I, Y_phi]]
-    else:
-        print('Using provided scan point offsets')
-        Y_I, Y_phi = \
-            [extract_nested_patches_position(imgs, offsets_xy, fmt= 'channel',
-                    **kwargs)
-                for imgs in [Y_I, Y_phi]]
-
-    assert Y_I.shape[-1] == get('gridsize')**2
-    norm_Y_I = tf.math.reduce_max(Y_I, axis = (1, 2, 3))[:, None, None, None]
-    norm_Y_I = tf.math.reduce_mean(norm_Y_I)
-    Y_I /= norm_Y_I
-
-    Y_I, Y_phi =\
-        channel_to_flat(Y_I, Y_phi)
-    return Y_I, Y_phi, _Y_I_full / norm_Y_I, norm_Y_I
-
-#@debug
-def reassemble_nested_average(output_tensor: tf.Tensor, cropN: Optional[int] = None, M: Optional[int] = None, n_imgs: int = 1,
-        offset: int = 4) -> tf.Tensor:
-    """
-    Stitch reconstruction patches from (first) model output into full
-    reconstructed images, averaging the overlaps
-    """
-    assert len(output_tensor.shape) == 4
-    bsize = int(output_tensor.shape[0] / n_imgs)
-    output_tensor = output_tensor[:bsize, ...]
-    if M is None:
-        M = int(np.sqrt(bsize))
-    if cropN is None:
-        cropN = params.params()['cropN']
-    patches = _togrid(trim_reconstruction(output_tensor, cropN), gridsize = M,
-        N = cropN)
-    patches = tf.reshape(patches, (-1, M, M, cropN**2))
-    obj_recon = complexify_function(extract_patches_inverse)(patches, cropN,
-        True, gridsize = M, offset = offset)
-    return obj_recon
-
-
-#@debug
-def gram_matrix(input_tensor: tf.Tensor) -> tf.Tensor:
-    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
-    input_shape = tf.shape(input_tensor)
-    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
-    return result/(num_locations)
-
-#@debug
-def high_pass_x_y(image: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
-    x_var = image[:,:,1:,:] - image[:,:,:-1,:]
-    y_var = image[:,1:,:,:] - image[:,:-1,:,:]
-    return x_var, y_var
-
-pp = tfk.Sequential([
-    Lambda(lambda x: tf.image.grayscale_to_rgb(x)),
-])
-#@debug
-def perceptual_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    """
-    target = pp(target)
-    pred = pp(pred)
-
-    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-    vgg.trainable = False
-
-    outputs = [vgg.get_layer('block2_conv2').output]
-    feat_model = Model(vgg.input, outputs)
-    activatedModelVal = feat_model(pred)
-    actualModelVal = feat_model(target)
-    return meanSquaredLoss(gram_matrix(actualModelVal),gram_matrix(activatedModelVal))
-
-#@debug
-def meanSquaredLoss(y_true: tf.Tensor, y_pred: tf.Tensor, center_target: bool = True) -> tf.Tensor:
-    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))
-
-#@debug
-def masked_MAE_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    bigN
-    """
-    mae = tf.keras.metrics.mean_absolute_error
-    mask = params()['probe_mask']
-    pred = trim_reconstruction(
-            reassemble_patches(mask * pred))
-    target = trim_reconstruction(
-            reassemble_patches(tf.math.abs(mask) * target))
-    return mae(target, pred)
-
-
-@complexify_sum_real_imag
-#@debug
-def total_variation_complex(obj: tf.Tensor) -> tf.Tensor:
-    """ calculate summed total variation of the real and imaginary components
-        of a tensor
-    """
-    x_deltas, y_deltas = high_pass_x_y(obj)
-    return tf.reduce_sum(x_deltas**2) + tf.reduce_sum(y_deltas**2)
-
-#@debug
-def total_variation(obj: tf.Tensor, amp_only: bool = False) -> tf.Tensor:
-    if amp_only:
-        obj = Lambda(lambda x: tf.math.abs(x))(obj)
-    return total_variation_complex(obj)
-
-@complexify_sum_amp_phase
-#@debug
-def complex_mae(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    mae = tf.keras.metrics.mean_absolute_error
-    return mae(target, pred)
-
-#@debug
-def masked_mae(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    mae = tf.keras.metrics.mean_absolute_error
-    pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-    return mae(target, pred)
-
-#@debug
-def realspace_loss(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    if not get('probe.big'):
-        pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-
-    if get('tv_weight') > 0:
-        tv_loss = total_variation(pred) * get('tv_weight')
-    else:
-        tv_loss = 0.
-
-    if get('realspace_mae_weight') > 0:
-        mae_loss = complex_mae(target, pred) * get('realspace_mae_weight')
-    else:
-        mae_loss = 0.
-    return tv_loss + mae_loss
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/train.py b/build/lib/build/lib/build/lib/build/lib/ptycho/train.py
deleted file mode 100644
index 7f93781..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/train.py
+++ /dev/null
@@ -1,121 +0,0 @@
-# train.py
-
-import os
-from ptycho.model_manager import ModelManager
-from ptycho import model_manager
-from ptycho.export import save_recons
-from datetime import datetime
-import matplotlib
-import matplotlib.pyplot as plt
-import dill
-import argparse
-from ptycho import params
-from ptycho import misc
-import numpy as np
-import h5py
-
-plt.rcParams["figure.figsize"] = (10, 10)
-matplotlib.rcParams['font.size'] = 12
-
-save_model = True
-save_data = False
-
-parser = argparse.ArgumentParser(description='Script to set attributes for ptycho program')
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(
-                        prog = 'PtychoPINN',
-                        description = 'Generate / load data and train the model',
-                        )
-    parser.add_argument('--model_type', type=str, default='pinn', help='model type (pinn or supervised)')
-    parser.add_argument('--output_prefix', type=str, default='lines2', help='output directory prefix')
-    parser.add_argument('--data_source', type=str, default='lines', help='Dataset specification')
-    parser.add_argument('--set_phi', action='store_true', default=False, help='If true, simulated objects are given non-zero phase')
-    parser.add_argument('--nepochs', type=int, default=60, help='Number of epochs')
-    parser.add_argument('--offset', type=int, default=4, help='Scan point spacing for simulated (grid-sampled) data')
-    parser.add_argument('--gridsize', type=int, default=2, help='Solution region grid size (e.g. 2 -> 2x2, etc.)')
-    parser.add_argument('--object_big', type=bool, default=True, help='If true, reconstruct the entire solution region for each set of patterns, instead of just the central N x N region.')
-    parser.add_argument('--nll_weight', type=float, default=1., help='Diffraction reconstruction NLL loss weight')
-    parser.add_argument('--mae_weight', type=float, default=0., help='Diffraction reconstruction MAE loss weight')
-    parser.add_argument('--nimgs_train', type=int, default=params.cfg['nimgs_train'], help='Number of generated training images')
-    parser.add_argument('--nimgs_test', type=int, default=params.cfg['nimgs_test'], help='Number of generated testing images')
-    parser.add_argument('--outer_offset_train', type=int, default=None, help='Scan point grid offset for (generated) training datasets')
-    parser.add_argument('--outer_offset_test', type=int, default=None, help='Scan point grid offset for (generated) testing datasets')
-    parser.add_argument('--n_filters_scale', type=int, default=2, help='Number of filters scale')
-    parser.add_argument('--max_position_jitter', type=int, default=10, help='Solution region is expanded around the edges by this amount')
-    parser.add_argument('--intensity_scale_trainable', type=bool, default=True, help='If true, sets the model-internal normalization of diffraction amplitudes to trainable')
-    parser.add_argument('--positions_provided', type=bool, default=False, help='[deprecated] Whether nominal or true (nominal + jitter) positions are provided in simulation runs')
-    parser.add_argument('--label', type=str, default='', help='[deprecated] Name of this run')
-    args = parser.parse_args()
-
-    model_type = params.cfg['model_type'] = args.model_type
-    label = params.cfg['label'] = args.label
-    params.cfg['positions.provided'] = args.positions_provided
-    params.cfg['data_source'] = args.data_source
-    params.cfg['set_phi'] = args.set_phi
-    params.cfg['nepochs'] = args.nepochs
-    offset = params.cfg['offset'] = args.offset
-    params.cfg['max_position_jitter'] = args.max_position_jitter
-    params.cfg['output_prefix'] = args.output_prefix
-    params.cfg['gridsize'] = args.gridsize
-    params.cfg['n_filters_scale'] = args.n_filters_scale
-    params.cfg['object.big'] = args.object_big
-    params.cfg['intensity_scale.trainable'] = args.intensity_scale_trainable
-    params.cfg['nll_weight'] = args.nll_weight
-    params.cfg['mae_weight'] = args.mae_weight
-    params.cfg['nimgs_train'] = args.nimgs_train
-    params.cfg['nimgs_test'] = args.nimgs_test
-    params.cfg['outer_offset_train'] = args.outer_offset_train
-    params.cfg['outer_offset_test'] = args.outer_offset_test
-else:
-    model_type = params.cfg['model_type']
-    label = params.cfg['label']
-    offset = params.cfg['offset']
-params.cfg['output_prefix'] = misc.get_path_prefix()
-
-out_prefix = params.get('output_prefix')
-os.makedirs(out_prefix, exist_ok=True)
-
-from ptycho import generate_data
-ptycho_dataset = generate_data.ptycho_dataset
-YY_ground_truth = generate_data.YY_ground_truth
-YY_test_full = generate_data.YY_test_full
-Y_I_test = generate_data.Y_I_test
-Y_phi_test = generate_data.Y_phi_test
-X_test = generate_data.X_test
-norm_Y_I_test = generate_data.norm_Y_I_test
-from ptycho import model
-from ptycho.evaluation import save_metrics
-
-if model_type == 'pinn':
-    from ptycho import train_pinn
-    print("DEBUG: generate_data diff norm {}".format(np.mean(np.abs(ptycho_dataset.train_data.X))))
-    train_output = train_pinn.train_eval(ptycho_dataset)
-    pred_amp = train_output['pred_amp']
-    history = train_output['history']
-    reconstructed_obj = train_output['reconstructed_obj']
-    stitched_obj = train_output['stitched_obj']
-
-elif model_type == 'supervised':
-    from ptycho.train_supervised import stitched_obj
-    from ptycho import train_supervised
-    history = train_supervised.history
-    reconstructed_obj = train_supervised.reconstructed_obj
-else:
-    raise ValueError
-
-d = save_recons(model_type, stitched_obj)
-
-with open(out_prefix + '/history.dill', 'wb') as file_pi:
-    dill.dump(history.history, file_pi)
-
-if save_model:
-    model_manager.save(out_prefix)
-
-if save_data:
-    with open(out_prefix + '/test_data.dill', 'wb') as f:
-        dill.dump(
-            {'YY_test_full': YY_test_full,
-             'Y_I_test': Y_I_test,
-             'Y_phi_test': Y_phi_test,
-             'X_test': X_test}, f)
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/train_pinn.py b/build/lib/build/lib/build/lib/build/lib/ptycho/train_pinn.py
deleted file mode 100644
index 05fbd5b..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/train_pinn.py
+++ /dev/null
@@ -1,121 +0,0 @@
-from ptycho import params
-from .loader import PtychoDataContainer
-from .image import reassemble_patches
-
-def train(train_data: PtychoDataContainer, intensity_scale=None, model_instance=None):
-    from . import params as p
-    # Model requires intensity_scale to be defined to set the initial
-    # value of the corresponding model parameter
-    if intensity_scale is None:
-        intensity_scale = calculate_intensity_scale(train_data)
-    p.set('intensity_scale', intensity_scale)
-
-    from ptycho import probe
-    probe.set_probe_guess(None, train_data.probe)
-
-    from ptycho import model
-    if model_instance is None:
-        model_instance = model.autoencoder
-    nepochs = params.cfg['nepochs']
-    params.print_params()
-    return model_instance, model.train(nepochs, train_data)
-
-def train_eval(ptycho_dataset):
-    ## TODO reconstructed_obj -> pred_Y or something
-    model_instance, history = train(ptycho_dataset.train_data)
-    results = {
-        'history': history,
-        'model_instance': model_instance
-    }
-    if ptycho_dataset.test_data is not None:
-        eval_results = eval(ptycho_dataset.test_data, history, trained_model=model_instance)
-        # Get config from the dataset
-        config = ptycho_dataset.test_data.config if hasattr(ptycho_dataset.test_data, 'config') else params.cfg
-        try:
-            stitched_obj = reassemble_patches(eval_results['reconstructed_obj'], config, part='complex')
-        except ValueError as e:
-            print(e)
-            stitched_obj = None
-
-        results.update({
-            'reconstructed_obj': eval_results['reconstructed_obj'],
-            'pred_amp': eval_results['pred_amp'],
-            'reconstructed_obj_cdi': eval_results['reconstructed_obj_cdi'],
-            'stitched_obj': stitched_obj,
-        })
-    return results
-
-from tensorflow.keras.models import load_model
-# Enhance the existing eval function to optionally load a model for inference
-def eval(test_data, history=None, trained_model=None, model_path=None):
-    """
-    Evaluate the model on test data. Optionally load a model if a path is provided.
-
-    Parameters:
-    - test_data: The test data for evaluation.
-    - history: Training history, if available.
-    - trained_model: An already trained model instance, if available.
-    - model_path: Path to a saved model, if loading is required.
-
-    Returns:
-    - Evaluation results including reconstructed objects and prediction amplitudes.
-    """
-    from ptycho.data_preprocessing import reassemble
-
-    from ptycho import probe
-    probe.set_probe_guess(None, test_data.probe)
-    # TODO enforce that the train and test probes are the same
-    print('INFO:', 'setting probe from test data container. It MUST be consistent with the training probe')
-
-    from ptycho import model
-    if model_path is not None:
-        print(f"Loading model from {model_path}")
-        trained_model = load_model(model_path)
-    elif trained_model is None:
-        raise ValueError("Either a trained model instance or a model path must be provided.")
-
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = trained_model.predict(
-        [test_data.X * model.params()['intensity_scale'], test_data.coords_nominal]
-    )
-    try:
-        stitched_obj = reassemble(reconstructed_obj, part='complex')
-    except (ValueError, TypeError) as e:
-        stitched_obj = None
-        print('Object stitching failed:', e)
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi,
-        'stitched_obj': stitched_obj
-    }
-
-def calculate_intensity_scale(ptycho_data_container: PtychoDataContainer) -> float:
-    import tensorflow as tf
-    import numpy as np
-    from . import params as p
-    def count_photons(obj):
-        pcount = np.mean(tf.math.reduce_sum(obj**2, (1, 2)))
-        return pcount
-
-    def scale_nphotons(X):
-        # TODO assumes X is already normalized. this should be enforced
-        return tf.math.sqrt(p.get('nphotons')) / (p.get('N') / 2)
-
-    # Calculate the intensity scale using the adapted scale_nphotons function
-    intensity_scale = scale_nphotons(ptycho_data_container.X).numpy()
-
-    return intensity_scale
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_eval_result(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/train_supervised.py b/build/lib/build/lib/build/lib/build/lib/ptycho/train_supervised.py
deleted file mode 100644
index 3ab4e9f..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/train_supervised.py
+++ /dev/null
@@ -1,73 +0,0 @@
-from ptycho.generate_data import *
-from ptycho import tf_helper as hh
-from ptycho import baselines as bl
-from ptycho import params as p
-from ptycho.image import reassemble_patches
-
-offset = p.get('offset')
-
-# For comparison to the 'baseline' model (PtychoNN) we need to crop/shift in a different way
-def xyshift(arr4d, dx, dy):
-    assert len(arr4d.shape) == 4
-    from scipy.ndimage.interpolation import shift
-    arr4d = np.roll(arr4d, dx, axis = 1)
-    arr4d = np.roll(arr4d, dy, axis = 2)
-    return arr4d
-
-def get_recon_patches_single_channel(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0] * bl.params.params()['intensity_scale']])
-    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-#    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0]])
-#    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-
-def get_recon_patches_grid(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_overlap_pred_I, baseline_overlap_pred_phi = model.predict(
-        [X_test[:, :, :, :4]  * bl.params.params()['intensity_scale']])
-    obj_stitched = hh.combine_complex(baseline_overlap_pred_I[:, :, :, :1], baseline_overlap_pred_phi[:, :, :, :1])
-    return xyshift(obj_stitched, -offset // 2, -offset // 2)
-
-if p.cfg['gridsize'] == 2:
-    model, history = bl.train((X_train[:, :, :, :4]),
-                              Y_I_train[:, :, :, :4], Y_phi_train[:, :, :, :4])
-
-    reconstructed_obj = get_recon_patches_grid(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-elif p.cfg['gridsize'] == 1:
-    model, history = bl.train((X_train[:, :, :, :1]), Y_I_train[:, :, :, :1], Y_phi_train[:, :, :, :1])
-
-    # TODO match above
-    reconstructed_obj = get_recon_patches_single_channel(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-    reconstructed_obj_train = get_recon_patches_single_channel(X_train)
-
-else:
-    raise ValueError
-
-try:
-    stitched_obj = reassemble_patches(reconstructed_obj, config, part='complex')
-except (ValueError, TypeError) as e:
-    print('object stitching failed:', e)
-
-# New alternative implementation 
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_reconstruction(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/trash/model2.py b/build/lib/build/lib/build/lib/build/lib/ptycho/trash/model2.py
deleted file mode 100644
index fde7a52..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/trash/model2.py
+++ /dev/null
@@ -1,148 +0,0 @@
-from . import tf_helper as hh
-from .params import params
-
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras import Sequential
-from tensorflow.keras.activations import sigmoid, tanh
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras.layers import Lambda
-import glob
-import math
-import numpy as np
-import os
-import tensorflow as tf
-import tensorflow_probability as tfp
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-
-N = params()['N']
-w = params()['w']
-h = params()['h']
-gridsize = params()['gridsize']
-offset = params()['offset']
-tprobe = params()['probe']
-batch_size = params()['batch_size']
-# TODO don't rely on this
-intensity_scale = params()['intensity_scale']
-
-# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N // 2,N // 2,3))
-vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-vgg.trainable = False
-
-outputs = [vgg.get_layer('block2_conv2').output]
-feat_model = Model(vgg.input, outputs)
-# feat_model.trainable = False
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-input_img = Input(shape=(h, w, gridsize**2), name = 'input')
-
-x = hh.Conv_Pool_block(input_img,32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-
-encoded=x
-
-#Decoding arm for amplitude
-x1=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x1=hh.Conv_Up_block(x1,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-decoded1 = Conv2D(gridsize**2, (3, 3), padding='same')(x1)
-decoded1 = Lambda(lambda x: sigmoid(x), name='amp')(decoded1)
-
-#Decoding arm for phase
-x2=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x2=hh.Conv_Up_block(x2,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-#x2=Conv_Up_block(x2,32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-
-decoded2 = Conv2D(gridsize**2, (3, 3), padding='same')(x2)
-decoded2 = Lambda(lambda x: math.pi * tanh(x), name='phi')(decoded2)
-
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]),
-                     name='obj')([decoded1, decoded2])
-
-padded_obj = tfkl.ZeroPadding2D(((h // 4), (w // 4)), name = 'padded_obj')(obj)
-padded_obj_2 = Lambda(lambda x:
-    hh.reassemble_patches(x), name = 'padded_obj_2',
-    )(padded_obj)
-#padded_obj_2 = tfkl.ZeroPadding2D((offset // 2 , offset // 2), name = 'padded_obj_2')(padded_obj)
-
-trimmed_obj = Lambda(lambda x: x[:, (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        :], name = 'trimmed_obj')(padded_obj_2)
-
-# TODO average?
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x: hh.flatten_overlaps(x, fmt = 'flat'), name = 'padded_objs_with_offsets')(padded_obj_2)
-# Apply the probe
-padded_objs_with_offsets = Lambda(lambda x: tf.cast(tprobe, tf.complex64) * x,
-                                  name = 'padded_objs_with_offsets_illuminated')(padded_objs_with_offsets)
-
-# TODO refactor
-# Diffracted amplitude
-padded_objs_with_offsets, pred_diff = hh.pad_and_diffract(padded_objs_with_offsets, h, w, pad=False)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-pred_intensity = tfpl.DistributionLambda(lambda t:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               ((t * intensity_scale)**2))
-                                       )))(pred_diff)
-
-#def mul_gaussian_noise(image):
-#    # image must be scaled in [0, 1]
-#    with tf.name_scope('Add_gaussian_noise'):
-#        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=1, dtype=tf.float32)
-#        noise_img = image * noise
-#    return noise_img
-
-negloglik = lambda x, rv_x: -rv_x.log_prob((x))
-
-# The first output exposes the real space object reconstruction and
-# though it does not contribute to the training loss, it's used to
-# calculate reconstruction errors for evaluation
-autoencoder = Model([input_img], [trimmed_obj, pred_diff, pred_intensity, pred_diff])
-#autoencoder = Model([input_img], [padded_obj, pred_diff, pred_intensity, pred_diff])
-
-encode_obj_to_diffraction = tf.keras.Model(inputs=[padded_obj],
-                           outputs=[pred_diff])
-
-diffraction_to_obj = tf.keras.Model(inputs=[input_img],
-                           outputs=[obj])
-
-autoencoder.compile(optimizer='adam',
-     loss=['mean_absolute_error', 'mean_absolute_error', negloglik, hh.total_variation_loss],
-     loss_weights = [0., 0., 1., 0.])
-
-print (autoencoder.summary())
-#plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-def train(epochs, X_train, Y_I_train):
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.h5' %wt_path,
-                                                monitor='val_loss', verbose=1, save_best_only=True,
-                                                save_weights_only=False, mode='auto', period=1)
-
-
-    history=autoencoder.fit([X_train], [Y_I_train, X_train, (intensity_scale * X_train)**2,
-                                       X_train], shuffle=True, batch_size=batch_size, verbose=1,
-                               epochs=epochs, validation_split = 0.05, callbacks=[reduce_lr, earlystop, checkpoints])
-    return history
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/visualization.py b/build/lib/build/lib/build/lib/build/lib/ptycho/visualization.py
deleted file mode 100644
index 91f038e..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/visualization.py
+++ /dev/null
@@ -1,22 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-
-def display_imgs(x, y=None, log = False, cbar = False, figsize=(10, 2), **kwargs):
-  if not isinstance(x, (np.ndarray, np.generic)):
-    x = np.array(x)
-  #plt.ioff()
-  n = x.shape[0]
-  fig, axs = plt.subplots(1, n, figsize = figsize)
-  if y is not None:
-    fig.suptitle(np.argmax(y, axis=1))
-  for i in range(n):
-    if log:
-        axs.flat[i].imshow(np.log(.01 + x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    else:
-        axs.flat[i].imshow((x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    axs.flat[i].axis('off')
-  if cbar:
-    plt.colorbar()
-  plt.show()
-  plt.close()
-  plt.ion()
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/__init__.py b/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/components.py b/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/components.py
deleted file mode 100644
index b030f63..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/components.py
+++ /dev/null
@@ -1,455 +0,0 @@
-import argparse
-import yaml
-import os
-import numpy as np
-import tensorflow as tf
-from ptycho import params as p
-from ptycho import probe
-from ptycho.loader import RawData, PtychoDataContainer
-import logging
-import matplotlib.pyplot as plt
-from typing import Union, Optional, Dict, Any, Tuple, Literal
-from pathlib import Path
-from ptycho.config.config import TrainingConfig, ModelConfig, dataclass_to_legacy_dict
-from dataclasses import fields
-from ptycho import loader, probe
-from typing import Union, Optional, Tuple, Dict, Any
-from ptycho.raw_data import RawData
-from ptycho.loader import PtychoDataContainer
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import params
-from ptycho.image import reassemble_patches
-
-# Set up logging
-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
-logger = logging.getLogger(__name__)
-
-from dataclasses import fields
-from ptycho.config.config import ModelConfig, TrainingConfig
-
-def update_config_from_dict(config_updates: dict):
-    """
-    Updates the application's configuration from a dictionary, ideal for notebook workflows.
-
-    Args:
-        config_updates (dict): A dictionary of parameters to update.
-    """
-    # 1. Create a mutable dictionary from the default dataclass values
-    model_defaults = {f.name: f.default for f in fields(ModelConfig)}
-    training_defaults = {f.name: f.default for f in fields(TrainingConfig) if f.name != 'model'}
-    
-    # Merge them
-    full_config_dict = {**model_defaults, **training_defaults}
-
-    # 2. Update with the user's dictionary
-    for key, value in config_updates.items():
-        if key in full_config_dict:
-            full_config_dict[key] = value
-        else:
-            # Optionally warn about unused keys
-            logger.warning(f"Configuration key '{key}' is not a recognized parameter.")
-
-    # 3. Re-construct the dataclasses
-    model_args = {k: v for k, v in full_config_dict.items() if k in model_defaults}
-    training_args = {k: v for k, v in full_config_dict.items() if k in training_defaults}
-
-    # Handle required Path objects if they are not set
-    if training_args.get('train_data_file') is None:
-        # Assign a dummy path or handle as an error if it's essential for all workflows
-        training_args['train_data_file'] = Path("dummy_path.npz")
-
-    final_model_config = ModelConfig(**model_args)
-    final_training_config = TrainingConfig(model=final_model_config, **training_args)
-    
-    # 4. Update the legacy global params dictionary
-    update_legacy_dict(params.cfg, final_training_config)
-    
-    logger.info("Configuration updated programmatically for interactive session.")
-    params.print_params()
-
-def load_data(file_path, n_images=None, flip_x=False, flip_y=False, swap_xy=False, n_samples=1, coord_scale=1.0):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        n_images (int, optional): Number of data points to include in the training set. Defaults to 512.
-        flip_x (bool, optional): If True, flip the sign of x coordinates. Defaults to False.
-        flip_y (bool, optional): If True, flip the sign of y coordinates. Defaults to False.
-        swap_xy (bool, optional): If True, swap x and y coordinates. Defaults to False.
-        n_samples (int, optional): Number of samples to generate. Defaults to 1.
-        coord_scale (float, optional): Scale factor for x and y coordinates. Defaults to 1.0.
-
-    Returns:
-        RawData: RawData object containing the dataset.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Apply coordinate transformations
-    if flip_x:
-        xcoords = -xcoords
-        xcoords_start = -xcoords_start
-        #probeGuess = probeGuess[::-1, :]
-    if flip_y:
-        ycoords = -ycoords
-        ycoords_start = -ycoords_start
-        #probeGuess = probeGuess[:, ::-1]
-    if swap_xy:
-        xcoords, ycoords = ycoords, xcoords
-        xcoords_start, ycoords_start = ycoords_start, xcoords_start
-        #probeGuess = np.transpose(probeGuess)
-
-    # Apply coordinate scaling
-    xcoords *= coord_scale
-    ycoords *= coord_scale
-    xcoords_start *= coord_scale
-    ycoords_start *= coord_scale
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    if n_images is None:
-        n_images = xcoords.shape[0]
-
-    # Create RawData object for the training subset
-    ptycho_data = RawData(xcoords[:n_images], ycoords[:n_images],
-                          xcoords_start[:n_images], ycoords_start[:n_images],
-                          diff3d[:n_images], probeGuess,
-                          scan_index[:n_images], objectGuess=objectGuess)
-
-    return ptycho_data
-
-def parse_arguments():
-    """Parse command-line arguments based on TrainingConfig fields."""
-    logger = logging.getLogger(__name__)
-    parser = argparse.ArgumentParser(description="Non-grid CDI Example Script")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    
-    # Add arguments based on TrainingConfig fields
-    for field in fields(TrainingConfig):
-        if field.name == 'model':
-            # Handle ModelConfig fields
-            for model_field in fields(ModelConfig):
-                # Special handling for Literal types
-                if hasattr(model_field.type, "__origin__") and model_field.type.__origin__ is Literal:
-                    choices = list(model_field.type.__args__)
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=str,
-                        choices=choices,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}, choices: {choices}"
-                    )
-                else:
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=model_field.type,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}"
-                    )
-        else:
-            # Handle path fields specially
-            if field.type == Path or str(field.type).startswith("typing.Optional[pathlib.Path"):
-                logger.debug(f"Field: {field.name}")
-                logger.debug(f"Field type: {field.type}")
-                logger.debug(f"Field default: {field.default}")
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=lambda x: (logger.debug(f"Converting path value: {x}"), Path(x) if x is not None else None)[1],
-                    default=None if field.default == None else str(field.default),
-                    help=f"Path for {field.name}"
-                )
-            else:
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=field.type,
-                    default=field.default,
-                    help=f"Training parameter: {field.name}"
-                )
-    
-    return parser.parse_args()
-
-def load_yaml_config(file_path: str) -> Dict[str, Any]:
-    """Load configuration from a YAML file."""
-    try:
-        with open(file_path, 'r') as file:
-            return yaml.safe_load(file)
-    except (yaml.YAMLError, IOError) as e:
-        logger.error(f"Error loading YAML config: {e}")
-        raise
-
-
-#def validate_config(config: Dict[str, Any]) -> None:
-#    """Validate the configuration."""
-#    if 'train_data_file_path' not in config or config['train_data_file_path'] is None:
-#        raise ValueError("train_data_file_path is a required parameter and must be provided")
-
-def setup_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> TrainingConfig:
-    """Set up the configuration by merging defaults, YAML file, and command-line arguments."""
-    try:
-        yaml_config = load_yaml_config(yaml_path) if yaml_path else None
-        args_config = vars(args)
-        
-        # Convert string paths to Path objects
-        for key in ['train_data_file', 'test_data_file', 'output_dir']:
-            if key in args_config and args_config[key] is not None:
-                args_config[key] = Path(args_config[key])
-        
-        # Create ModelConfig from args
-        model_fields = {f.name for f in fields(ModelConfig)}
-        model_args = {k: v for k, v in args_config.items() if k in model_fields}
-        model_config = ModelConfig(**model_args)
-        
-        # Create TrainingConfig
-        training_fields = {f.name for f in fields(TrainingConfig)}
-        training_args = {k: v for k, v in args_config.items() 
-                        if k in training_fields and k != 'model'}
-        config = TrainingConfig(model=model_config, **training_args)
-        
-        # Update the global configuration
-        update_legacy_dict(params.cfg, config)
-        
-        logger.info("Configuration setup complete")
-        logger.info(f"Final configuration: {config}")
-        
-        return config
-    except (yaml.YAMLError, IOError, ValueError) as e:
-        logger.error(f"Error setting up configuration: {e}")
-        raise
-
-def load_and_prepare_data(data_file_path: str) -> Tuple[RawData, RawData, Any]:
-    """
-    Load and prepare the data from a single file path.
-
-    Args:
-        data_file_path (str): Path to the data file
-
-    Returns:
-        Tuple[RawData, RawData, Any]: A tuple containing the full dataset, training subset, and additional data
-    """
-    # TODO deprecated
-    from ptycho.loader import load_xpp_npz
-    if not os.path.exists(data_file_path):
-        raise FileNotFoundError(f"Data file not found: {data_file_path}")
-
-    try:
-        return load_xpp_npz(data_file_path)
-    except Exception as e:
-        logger.error(f"Error loading data from {data_file_path}: {str(e)}")
-        raise
-
-from typing import Union
-from ptycho.loader import RawData, PtychoDataContainer
-
-def create_ptycho_data_container(data: Union[RawData, PtychoDataContainer], config: TrainingConfig) -> PtychoDataContainer:
-    """
-    Factory function to create or return a PtychoDataContainer.
-
-    Args:
-        data (Union[RawData, PtychoDataContainer]): Input data, either RawData or PtychoDataContainer.
-        config (TrainingConfig): Training configuration object.
-
-    Returns:
-        PtychoDataContainer: The resulting PtychoDataContainer.
-
-    Raises:
-        TypeError: If the input data is neither RawData nor PtychoDataContainer.
-    """
-    if isinstance(data, PtychoDataContainer):
-        return data
-    elif isinstance(data, RawData):
-        dataset = data.generate_grouped_data(config.model.N, K=7, nsamples=1)
-        return loader.load(lambda: dataset, data.probeGuess, which=None, create_split=False)
-    else:
-        raise TypeError("data must be either RawData or PtychoDataContainer")
-
-def train_cdi_model(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig
-) -> Dict[str, Any]:
-    """
-    Train the CDI model.
-
-    Args:
-        train_data (Union[RawData, PtychoDataContainer]): Training data.
-        config (Dict[str, Any]): Configuration dictionary.
-
-    Returns:
-        Dict[str, Any]: Results dictionary containing training history.
-    """
-    from ptycho.loader import PtychoDataset
-    from ptycho import train_pinn
-    # Convert input data to PtychoDataContainer
-    train_container = create_ptycho_data_container(train_data, config)
-    if test_data is not None:
-        test_container = create_ptycho_data_container(test_data, config)
-    else:
-        test_container = None
-
-    # Initialize probe
-    probe.set_probe_guess(None, train_container.probe)
-
-#    # Calculate intensity scale
-#    intensity_scale = train_pinn.calculate_intensity_scale(train_container)
-
-    # Train the model
-    results = train_pinn.train_eval(PtychoDataset(train_container, test_container))
-    results['train_container'] = train_container
-    results['test_container'] = test_container
-    #history = train_pinn.train(train_container)
-    
-    return results
-
-def reassemble_cdi_image(
-    test_data: Union[RawData, PtychoDataContainer],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20,
-    coord_scale: float = 1.0
-) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
-    """
-    Reassemble the CDI image using the trained model.
-
-    Args:
-        test_data (Union[RawData, PtychoDataContainer]): Test data.
-        config (Dict[str, Any]): Configuration dictionary.
-        flip_x (bool): Whether to flip the x coordinates. Default is False.
-        flip_y (bool): Whether to flip the y coordinates. Default is False.
-        transpose (bool): Whether to transpose the image by swapping the 1st and 2nd dimensions. Default is False.
-        M (int): Parameter for reassemble_position function. Default is 20.
-        coord_scale (float): Scale factor for x and y coordinates. Default is 1.0.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray, Dict[str, Any]]: 
-        Reconstructed amplitude, reconstructed phase, and results dictionary.
-    """
-    # TODO use train_pinn.eval to get reconstructed diffraction amplitude
-    test_container = create_ptycho_data_container(test_data, config)
-    
-    from ptycho import nbutils
-    obj_tensor_full, global_offsets = nbutils.reconstruct_image(test_container)
-    
-    # Log the shape of global_offsets
-    logger.info(f"Shape of global_offsets: {global_offsets.shape}")
-
-    # Assert that obj_tensor_full is a 4D tensor
-    assert obj_tensor_full.ndim == 4, f"Expected obj_tensor_full to be a 4D tensor, but got shape {obj_tensor_full.shape}"
-
-    # Transpose the image if requested
-    if transpose:
-        obj_tensor_full = np.transpose(obj_tensor_full, (0, 2, 1, 3))
-
-    # Flip coordinates if requested
-    if flip_x:
-        global_offsets[:, 0, 0, :] = -global_offsets[:, 0, 0, :]
-    if flip_y:
-        global_offsets[:, 0, 1, :] = -global_offsets[:, 0, 1, :]
-    
-    # Scale coordinates
-    global_offsets *= coord_scale
-    
-    from ptycho import tf_helper as hh
-    obj_image = hh.reassemble_position(obj_tensor_full, global_offsets, M=M)
-    
-    recon_amp = np.absolute(obj_image)
-    recon_phase = np.angle(obj_image)
-    
-    results = {
-        "obj_tensor_full": obj_tensor_full,
-        "global_offsets": global_offsets,
-        "recon_amp": recon_amp,
-        "recon_phase": recon_phase
-    }
-    
-    return recon_amp, recon_phase, results
-
-def run_cdi_example(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20
-) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Dict[str, Any]]:
-    """
-    Run the main CDI example execution flow.
-
-    Args:
-        train_data: Training data
-        test_data: Optional test data
-        config: Training configuration parameters
-        flip_x: Whether to flip the x coordinates
-        flip_y: Whether to flip the y coordinates
-        transpose: Whether to transpose the image by swapping dimensions
-        M: Parameter for reassemble_position function
-
-    Returns:
-        Tuple containing:
-        - reconstructed amplitude (or None)
-        - reconstructed phase (or None)
-        - results dictionary
-    """
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    # Train the model
-    train_results = train_cdi_model(train_data, test_data, config)
-    
-    recon_amp, recon_phase = None, None
-    
-    # Reassemble test image if test data is provided and reconstructed_obj is available
-    if test_data is not None and 'reconstructed_obj' in train_results:
-        recon_amp, recon_phase, reassemble_results = reassemble_cdi_image(
-            test_data, config, flip_x, flip_y, transpose, M=M
-        )
-        train_results.update(reassemble_results)
-    
-    return recon_amp, recon_phase, train_results
-
-
-def save_outputs(amplitude: Optional[np.ndarray], phase: Optional[np.ndarray], results: Dict[str, Any], output_prefix: str) -> None:
-    """Save the generated images and results."""
-    os.makedirs(output_prefix, exist_ok=True)
-    
-    # TODO Save training history with tensorboard / mlflow
-    
-    # Save test results if available
-    if amplitude is not None and phase is not None:
-        logger.info(f"Amplitude array shape: {amplitude.shape}")
-        logger.info(f"Phase array shape: {phase.shape}")
-        
-        # Squeeze any extra dimensions
-        amplitude = np.squeeze(amplitude)
-        phase = np.squeeze(phase)
-        
-        logger.info(f"Squeezed amplitude shape: {amplitude.shape}")
-        logger.info(f"Squeezed phase shape: {phase.shape}")
-        
-        # Save as PNG files using plt.figure() to handle 2D arrays properly
-        plt.figure(figsize=(8,8))
-        plt.imshow(amplitude, cmap='gray')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_amplitude.png"))
-        plt.close()
-        
-        plt.figure(figsize=(8,8))
-        plt.imshow(phase, cmap='viridis')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_phase.png"))
-        plt.close()
-        
-    logger.info(f"Outputs saved to {output_prefix}")
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py b/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py
deleted file mode 100644
index 5d1f9ad..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho import evaluation, params
-from typing import Dict, Any
-
-def visualize_results(results: Dict[str, Any], test_data, i: int = 200, output_prefix: str = 'output'):
-    """
-    Visualize the results using the evaluation.summarize function.
-
-    Args:
-    results (Dict[str, Any]): Dictionary containing the results from the CDI process.
-    test_data: The test data used for evaluation.
-    i (int): Index of the sample to visualize. Default is 200.
-    output_prefix (str): Directory to save the output files. Default is 'output'.
-    """
-    # Extract necessary data from results and test_data
-    pred_amp = results['pred_amp']
-    reconstructed_obj = results['reconstructed_obj']
-    X_test = test_data.X
-    Y_I_test = test_data.Y_I
-    Y_phi_test = test_data.Y_phi
-    probe = np.absolute(params.get('probe')[:, :, 0, 0])
-
-    # Call the summarize function
-    heatmaps = evaluation.summarize(i, results['pred_amp'] + 1, results['reconstructed_obj'], 
-                                    X_test, Y_I_test, Y_phi_test,
-                                    probe, channel=0, crop=False)
-
-    # Save the heatmaps
-    for name, heatmap in heatmaps.items():
-        plt.figure(figsize=(10, 10))
-        plt.imshow(heatmap, cmap='jet')
-        plt.colorbar()
-        plt.title(name)
-        plt.savefig(f"{output_prefix}/{name}.png")
-        plt.close()
-
-    print(f"Heatmaps saved to {output_prefix}")
-
-if __name__ == "__main__":
-    # This is where you would load your results and test_data
-    # For example:
-    # from ptycho.workflows.components import load_and_prepare_data
-    # test_data = load_and_prepare_data("path_to_test_data.npz")
-    # results = ... # Load your results here
-
-    # visualize_results(results, test_data)
-    pass  # Remove this line when uncommenting the code above
diff --git a/build/lib/build/lib/build/lib/build/lib/ptycho/xpp.py b/build/lib/build/lib/build/lib/build/lib/ptycho/xpp.py
deleted file mode 100644
index 15c881b..0000000
--- a/build/lib/build/lib/build/lib/build/lib/ptycho/xpp.py
+++ /dev/null
@@ -1,23 +0,0 @@
-import numpy as np
-import pkg_resources
-
-from .loader import load_xpp_npz as load_ptycho_data
-
-train_frac = .5
-N = 64
-gridh, gridw = 32, 32
-
-np.random.seed(7)
-
-def get_data(**kwargs):
-    return dset, train_frac
-
-
-data_file_path = pkg_resources.resource_filename(__name__, 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-ptycho_data, ptycho_data_train, obj = load_ptycho_data(data_file_path)
-print('raw diffraction shape', obj['diffraction'].shape)
-# TODO cast to complex64?
-probeGuess = obj['probeGuess']
-objectGuess = obj['objectGuess']
-
-## TODO refactor actual / nominal positions
diff --git a/build/lib/build/lib/build/lib/build/lib/scripts/inference/inference.py b/build/lib/build/lib/build/lib/build/lib/scripts/inference/inference.py
deleted file mode 100644
index 41951e8..0000000
--- a/build/lib/build/lib/build/lib/build/lib/scripts/inference/inference.py
+++ /dev/null
@@ -1,384 +0,0 @@
-#!/usr/bin/env python
-# coding: utf-8
-# TODO needs to be updated to use the new-style config dataclasses
-# MAYBE only generate the comparison plot when ground truth object is provided
-# MAYBE save output to npz file, not just image
-
-"""
-Inference script for ptychography reconstruction.
-
-This script loads a trained model and test data, performs inference,
-and saves the reconstructed image comparison and optionally a probe visualization.
-
-Usage:
-    python inference_script.py --model_prefix <model_prefix> --test_data <test_data_file> [--output_path <output_path>]
-                               [--visualize_probe] [--K <K>] [--nsamples <nsamples>]
-
-Arguments:
-    --model_prefix: Path prefix for the saved model and its configuration
-    --test_data: Path to the .npz file containing test data
-    --output_path: Path prefix for saving output files and images (default: './')
-    --visualize_probe: Flag to generate and save probe visualization
-    --K: Number of nearest neighbors for grouped data generation (default: 7)
-    --nsamples: Number of samples for grouped data generation (default: 1)
-"""
-
-from typing import Optional
-import argparse
-import logging
-import os
-import sys
-import time
-import signal
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-from ptycho import probe, params, train_pinn
-from ptycho.model_manager import ModelManager
-from ptycho.raw_data import RawData
-from ptycho.workflows.components import load_data, setup_configuration, parse_arguments
-from ptycho.config.config import InferenceConfig, ModelConfig, validate_inference_config, update_legacy_dict
-
-# Set up logging
-logging.basicConfig(level=logging.INFO,
-                    format='%(asctime)s - %(levelname)s - %(message)s',
-                    handlers=[
-                        logging.StreamHandler(sys.stdout),
-                        logging.FileHandler('inference.log')
-                    ])
-logger = logging.getLogger(__name__)
-
-# Redirect print statements to logger
-print = logger.info
-
-# Global flag for graceful shutdown
-shutdown_requested = False
-
-def signal_handler(signum, frame):
-    global shutdown_requested
-    shutdown_requested = True
-    print(f"Received signal {signum}. Initiating graceful shutdown...")
-
-# Register signal handlers
-signal.signal(signal.SIGINT, signal_handler)
-signal.signal(signal.SIGTERM, signal_handler)
-
-def parse_arguments() -> argparse.Namespace:
-    """Parse command line arguments."""
-    parser = argparse.ArgumentParser(description="Ptychography Inference Script")
-    parser.add_argument("--model_path", type=str, required=True,
-                       help="Path to the saved model")
-    parser.add_argument("--test_data", type=str, required=True,
-                       help="Path to the test data file")
-    parser.add_argument("--config", type=str, required=False, default=None,
-                       help="Optional path to YAML configuration file to override defaults")
-    parser.add_argument("--output_dir", type=str, default='inference_outputs',
-                       help="Directory for saving output files and images")
-    parser.add_argument("--debug", action="store_true",
-                       help="Enable debug mode")
-    return parser.parse_args()
-
-def setup_inference_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> InferenceConfig:
-    """Setup inference configuration from arguments and YAML file."""
-    if yaml_path:
-        base_config = setup_configuration(args, yaml_path)
-        model_config = base_config.model
-    else:
-        # Use default ModelConfig when no YAML provided
-        model_config = ModelConfig()
-    
-    inference_config = InferenceConfig(
-        model=model_config,
-        model_path=Path(args.model_path),
-        test_data_file=Path(args.test_data),
-        debug=args.debug,
-        output_dir=Path(args.output_dir)
-    )
-    
-    validate_inference_config(inference_config)
-    return inference_config
-
-
-def load_model(model_path: Path) -> tuple:
-    """Load the saved model and its configuration."""
-    try:
-        print(f"Attempting to load model from: {model_path}")
-        print(f"Current working directory: {os.getcwd()}")
-        
-        # Check if the path is a directory and contains wts.h5.zip
-        model_zip = os.path.join(model_path, "wts.h5")
-        if not os.path.exists(f"{model_zip}.zip"):
-            raise ValueError(f"Model archive not found at: {model_zip}.zip")
-            
-        # Load multiple models
-        models_dict = ModelManager.load_multiple_models(model_zip)
-        
-        # Get the diffraction_to_obj model which is what we need for inference
-        if 'diffraction_to_obj' not in models_dict:
-            raise ValueError("No diffraction_to_obj model found in saved models")
-            
-        model = models_dict['diffraction_to_obj']
-        config = params.cfg  # ModelManager updates global config when loading
-
-        print(f"Successfully loaded model from {model_path}")
-        print(f"Model configuration: {config}")
-
-        return model, config
-
-    except Exception as e:
-        raise ValueError(f"Failed to load model: {str(e)}")
-
-def perform_inference(model: tf.keras.Model, test_data: RawData, config: dict, K: int, nsamples: int) -> tuple:
-    """
-    Perform inference using the loaded model and test data.
-
-    Args:
-        model (tf.keras.Model): The loaded TensorFlow model.
-        test_data (RawData): The RawData object containing test data.
-        config (dict): The model's configuration dictionary.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Returns:
-        tuple: (np.ndarray, np.ndarray, np.ndarray, np.ndarray) - Reconstructed amplitude, 
-               reconstructed phase, ePIE amplitude, and ePIE phase.
-
-    Raises:
-        ValueError: If there's an error during inference.
-    """
-    from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer
-    try:
-        # Set probe guess
-        probe.set_probe_guess(None, test_data.probeGuess)
-
-        # Set random seeds
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate grouped data
-        test_dataset = test_data.generate_grouped_data(config['N'], K=K, nsamples=nsamples)
-        
-        # Create PtychoDataContainer
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        start_time = time.time()
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        reconstruction_time = time.time() - start_time
-        print(f"Reconstruction completed in {reconstruction_time:.2f} seconds")
-
-        # Process the reconstructed image
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-
-#        # Process ePIE results for comparison
-#        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-#        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        epie_phase = np.angle(test_data.objectGuess)
-        epie_amplitude = np.abs(test_data.objectGuess)
-
-        print(f"Reconstructed amplitude shape: {reconstructed_amplitude.shape}")
-        print(f"Reconstructed phase shape: {reconstructed_phase.shape}")
-        print(f"ePIE amplitude shape: {epie_amplitude.shape}")
-        print(f"ePIE phase shape: {epie_phase.shape}")
-
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-
-    except Exception as e:
-        print(f"Error during inference: {str(e)}")
-        raise ValueError(f"Error during inference: {str(e)}")
-
-def save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_path):
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Create the comparison figure with a smaller size
-        fig, axs = plt.subplots(2, 2, figsize=(4, 4))
-        
-        # PtychoPINN phase
-        im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-        axs[0, 0].set_title('PtychoPINN Phase')
-        fig.colorbar(im_pinn_phase, ax=axs[0, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE phase
-        im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-        axs[0, 1].set_title('ePIE Phase')
-        fig.colorbar(im_epie_phase, ax=axs[0, 1], fraction=0.046, pad=0.04)
-        
-        # PtychoPINN amplitude
-        im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-        axs[1, 0].set_title('PtychoPINN Amplitude')
-        fig.colorbar(im_pinn_amp, ax=axs[1, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE amplitude
-        im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-        axs[1, 1].set_title('ePIE Amplitude')
-        fig.colorbar(im_epie_amp, ax=axs[1, 1], fraction=0.046, pad=0.04)
-        
-        # Remove axis ticks
-        for ax in axs.flat:
-            ax.set_xticks([])
-            ax.set_yticks([])
-        
-        # Adjust layout with specific padding
-        plt.tight_layout(pad=1.5)
-        
-        # Save the figure with adjusted DPI and ensuring the entire figure is saved
-        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.5)
-        plt.close(fig)
-
-        print(f"Comparison image saved to: {output_path}")
-
-    except Exception as e:
-        print(f"Error saving comparison image: {str(e)}")
-
-def save_probe_visualization(test_data: RawData, output_path: str):
-    """
-    Generate and save the probe visualization.
-
-    Args:
-        test_data (RawData): The RawData object containing test data.
-        output_path (str): Path to save the probe visualization.
-
-    Raises:
-        OSError: If there's an error creating the output directory or saving the image.
-    """
-    from ptycho.nbutils import probeshow
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Generate the probe visualization
-        fig = probeshow(test_data.probeGuess, test_data)
-        
-        # Save the figure
-        fig.savefig(output_path, dpi=300, bbox_inches='tight')
-        plt.close(fig)
-
-        print(f"Probe visualization saved to: {output_path}")
-
-    except OSError as e:
-        raise OSError(f"Error saving probe visualization: {str(e)}")
-
-def main(model_prefix: str, test_data_file: str, output_path: str, visualize_probe: bool, K: int, nsamples: int) -> None:
-    """
-    Main function to orchestrate the inference process.
-
-    Args:
-        model_prefix (str): Path prefix for the saved model and its configuration.
-        test_data_file (str): Path to the .npz file containing test data.
-        output_path (str): Path prefix for saving output files and images.
-        visualize_probe (bool): Flag to generate and save probe visualization.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Raises:
-        Exception: If any error occurs during the inference process.
-    """
-    print("Starting inference process...")
-    start_time = time.time()
-
-    try:
-        # Load model
-        print("Loading model...")
-        model, config = load_model(model_prefix)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(test_data_file)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping inference process.")
-            return
-
-        # Perform inference
-        print(f"Performing inference with K={K} and nsamples={nsamples}...")
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(model, test_data, config, K, nsamples)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping before saving results.")
-            return
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = os.path.join(output_path, "reconstruction_comparison.png")
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_image_path)
-
-        # Save probe visualization if requested
-        if visualize_probe:
-            print("Generating and saving probe visualization...")
-            probe_output_path = os.path.join(output_path, "probe_visualization.png")
-            save_probe_visualization(test_data, probe_output_path)
-
-        print("Inference process completed successfully.")
-
-    except FileNotFoundError as e:
-        print(f"File not found error: {str(e)}")
-        raise
-    except ValueError as e:
-        print(f"Value error: {str(e)}")
-        raise
-    except OSError as e:
-        print(f"OS error: {str(e)}")
-        raise
-    except Exception as e:
-        print(f"An unexpected error occurred: {str(e)}")
-        raise
-    finally:
-        # Perform any necessary cleanup
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-    end_time = time.time()
-    print(f"Total execution time: {end_time - start_time:.2f} seconds")
-
-def main():
-    """Main entry point for the ptychography inference script."""
-    try:
-        print("Starting ptychography inference script...")
-        args = parse_arguments()
-        config = setup_inference_configuration(args, args.config)
-        
-        # Update global params with new-style config
-        update_legacy_dict(params.cfg, config)
-
-        # Load model
-        print("Loading model...")
-        model, _ = load_model(config.model_path)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(args.test_data)
-
-        # Perform inference
-        print("Performing inference...")
-        # TODO might want to reduce K
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-            model, test_data, params.cfg, K=7, nsamples=1)
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = config.output_dir / "reconstruction_comparison.png"
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, 
-                            epie_amplitude, epie_phase, output_image_path)
-
-        print("Inference process completed successfully.")
-        sys.exit(0)
-    except Exception as e:
-        print(f"Script execution failed: {str(e)}")
-        sys.exit(1)
-    finally:
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py b/build/lib/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py
deleted file mode 100644
index 008d7f5..0000000
--- a/build/lib/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py
+++ /dev/null
@@ -1,73 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho.loader import PtychoDataContainer
-
-def load_ptycho_data(file_path: str) -> PtychoDataContainer:
-    """
-    Load the npz-serialized ptycho data.
-
-    Args:
-        file_path (str): Path to the npz file.
-
-    Returns:
-        PtychoDataContainer: Loaded ptycho data.
-    """
-    data = np.load(file_path, allow_pickle=True)
-    return PtychoDataContainer(
-        X=data['X'],
-        Y_I=data['Y_I'],
-        Y_phi=data['Y_phi'],
-        norm_Y_I=data['norm_Y_I'],
-        YY_full=data['YY_full'],
-        coords_nominal=data['coords_nominal'],
-        coords_true=data['coords_true'],
-        nn_indices=data['nn_indices'],
-        global_offsets=data['global_offsets'],
-        local_offsets=data['local_offsets'],
-        probeGuess=data['probe']
-    )
-
-def inspect_ptycho_frames(data: PtychoDataContainer, num_frames: int = 2):
-    """
-    Visually inspect a couple of frames from X, Y_I, and Y_phi.
-
-    Args:
-        data (PtychoDataContainer): Loaded ptycho data.
-        num_frames (int): Number of frames to display. Defaults to 2.
-    """
-    fig, axes = plt.subplots(3, num_frames, figsize=(5*num_frames, 15))
-    
-    for i in range(num_frames):
-        axes[0, i].imshow(data.X[i, ..., 0], cmap='viridis')
-        axes[0, i].set_title(f'X - Frame {i}')
-        axes[0, i].axis('off')
-        
-        axes[1, i].imshow(data.Y_I[i, ..., 0], cmap='viridis')
-        axes[1, i].set_title(f'Y_I - Frame {i}')
-        axes[1, i].axis('off')
-        
-        axes[2, i].imshow(data.Y_phi[i, ..., 0], cmap='viridis')
-        axes[2, i].set_title(f'Y_phi - Frame {i}')
-        axes[2, i].axis('off')
-    
-    plt.tight_layout()
-    plt.show()
-
-if __name__ == "__main__":
-    import sys
-
-    if len(sys.argv) < 2:
-        print("Usage: python inspect_ptycho_data.py <path_to_npz_file>")
-        sys.exit(1)
-
-    file_path = sys.argv[1]
-    
-    try:
-        # Load the data
-        ptycho_data = load_ptycho_data(file_path)
-        
-        # Inspect the frames
-        inspect_ptycho_frames(ptycho_data)
-    except Exception as e:
-        print(f"An error occurred: {e}")
-        sys.exit(1)
diff --git a/build/lib/build/lib/build/lib/build/lib/scripts/simulation/simulation.py b/build/lib/build/lib/build/lib/build/lib/scripts/simulation/simulation.py
deleted file mode 100644
index 3dbea64..0000000
--- a/build/lib/build/lib/build/lib/build/lib/scripts/simulation/simulation.py
+++ /dev/null
@@ -1,276 +0,0 @@
-#!/usr/bin/env python3
-# ptycho_simulate_cli.py
-
-import argparse
-import os
-import sys
-import matplotlib.pyplot as plt
-from ptycho.workflows.components import (
-    setup_configuration,
-    run_cdi_example,
-    update_params,
-)
-
-def save_plot_to_file(fig, filename):
-    fig.savefig(filename, dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-def generate_html_report(output_dir, image_files, args, params):
-    import base64
-
-    html_content = """
-    <!DOCTYPE html>
-    <html lang="en">
-    <head>
-        <meta charset="UTF-8">
-        <meta name="viewport" content="width=device-width, initial-scale=1.0">
-        <title>Ptychography Simulation Report</title>
-        <style>
-            body {
-                font-family: Arial, sans-serif;
-                line-height: 1.6;
-                color: #333;
-                max-width: 1000px;
-                margin: 0 auto;
-                padding: 20px;
-            }
-            h1, h2 {
-                color: #2c3e50;
-                text-align: center;
-            }
-            .image-container {
-                margin-bottom: 30px;
-            }
-            img {
-                max-width: 100%;
-                height: auto;
-                display: block;
-                margin: 0 auto;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 5px;
-            }
-            .image-title {
-                font-weight: bold;
-                margin-top: 10px;
-                text-align: center;
-            }
-            .command, .parameters {
-                background-color: #f4f4f4;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 10px;
-                margin-bottom: 20px;
-                white-space: pre-wrap;
-                word-wrap: break-word;
-            }
-            .parameter-name {
-                font-weight: bold;
-            }
-            .parameter-description {
-                margin-left: 20px;
-                margin-bottom: 10px;
-            }
-        </style>
-    </head>
-    <body>
-        <h1>Ptychography Simulation Report</h1>
-        
-        <h2>Launch Command</h2>
-        <div class="command">
-        {' '.join(sys.argv)}
-        </div>
-        
-        <h2>Model Parameters</h2>
-        <div class="parameters">
-    """
-
-    for key, value in params.items():
-        html_content += f'<p><span class="parameter-name">{key}:</span> {value}</p>\n'
-        if key == "N":
-            html_content += '<p class="parameter-description">Size of the simulation grid.</p>\n'
-        elif key == "probe_scale":
-            html_content += '<p class="parameter-description">Probe scale factor.</p>\n'
-        elif key == "nphotons":
-            html_content += '<p class="parameter-description">Number of photons.</p>\n'
-        elif key == "mae_weight":
-            html_content += '<p class="parameter-description">Weight for MAE loss.</p>\n'
-        elif key == "nll_weight":
-            html_content += '<p class="parameter-description">Weight for NLL loss.</p>\n'
-        elif key == "nepochs":
-            html_content += '<p class="parameter-description">Number of epochs for training.</p>\n'
-        elif key == "intensity_scale.trainable":
-            html_content += '<p class="parameter-description">Whether intensity scale is trainable.</p>\n'
-        elif key == "positions.provided":
-            html_content += '<p class="parameter-description">Whether positions are provided.</p>\n'
-        elif key == "probe.big":
-            html_content += '<p class="parameter-description">Whether to use a big probe.</p>\n'
-        elif key == "probe.mask":
-            html_content += '<p class="parameter-description">Whether to use a probe mask.</p>\n'
-        elif key == "data_source":
-            html_content += '<p class="parameter-description">Type of data source.</p>\n'
-        elif key == "gridsize":
-            html_content += '<p class="parameter-description">Grid size for simulation.</p>\n'
-
-    html_content += """
-        </div>
-        
-        <h2>Visualizations</h2>
-    """
-
-    for image_file in image_files:
-        image_name = os.path.basename(image_file)
-        image_title = image_name.replace('_', ' ').replace('.png', '').title()
-        
-        # Read the image file and encode it in base64
-        with open(image_file, 'rb') as img_f:
-            image_data = img_f.read()
-            encoded_image = base64.b64encode(image_data).decode('utf-8')
-        
-        # Determine the image's MIME type
-        mime_type = 'image/png'  # Adjust if using other image formats
-        
-        # Embed the image in the HTML using a data URI
-        html_content += f"""
-        <div class="image-container">
-            <img src="data:{mime_type};base64,{encoded_image}" alt="{image_title}">
-            <p class="image-title">{image_title}</p>
-        </div>
-        """
-
-    html_content += """
-    </body>
-    </html>
-    """
-
-    with open(os.path.join(output_dir, 'report.html'), 'w') as f:
-        f.write(html_content)
-
-def main():
-    parser = argparse.ArgumentParser(description="Simulate ptychography data and generate visualizations.")
-    parser.add_argument("input_file", help="Path to the input .npz file containing probe and object guesses.")
-    parser.add_argument("output_dir", help="Directory to save output visualizations.")
-    parser.add_argument("--nimages", type=int, default=2000, help="Number of images to simulate.")
-    parser.add_argument("--seed", type=int, default=None, help="Random seed for reproducibility.")
-    parser.add_argument("--nepochs", type=int, default=50, help="Number of epochs for training.")
-    parser.add_argument("--output_prefix", default="tmp", help="Prefix for output files.")
-    parser.add_argument("--intensity_scale_trainable", action="store_true", default=False, help="Make intensity scale trainable.")
-    parser.add_argument("--positions_provided", action="store_true", default=True, help="Positions are provided.")
-    parser.add_argument("--probe_big", action="store_true", default=True, help="Use big probe.")
-    parser.add_argument("--probe_mask", action="store_true", default=False, help="Use probe mask.")
-    parser.add_argument("--data_source", default="generic", help="Data source type.")
-    parser.add_argument("--gridsize", type=int, default=1, help="Grid size.")
-    parser.add_argument("--train_data_file_path", default=None, help="Path to train data file.")
-    parser.add_argument("--test_data_file_path", default=None, help="Path to test data file.")
-    parser.add_argument("--N", type=int, default=128, help="Size of the simulation grid.")
-    parser.add_argument("--probe_scale", type=int, default=4, help="Probe scale factor.")
-    parser.add_argument("--nphotons", type=float, default=1e9, help="Number of photons.")
-    parser.add_argument("--mae_weight", type=float, default=1, help="Weight for MAE loss.")
-    parser.add_argument("--nll_weight", type=float, default=0, help="Weight for NLL loss.")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    args = parser.parse_args()
-
-    os.makedirs(args.output_dir, exist_ok=True)
-
-    params = {
-        "nepochs": args.nepochs,
-        "output_prefix": args.output_prefix,
-        "intensity_scale.trainable": args.intensity_scale_trainable,
-        "positions.provided": args.positions_provided,
-        "probe.big": args.probe_big,
-        "probe.mask": args.probe_mask,
-        "data_source": args.data_source,
-        "gridsize": args.gridsize,
-        "train_data_file_path": args.train_data_file_path,
-        "test_data_file_path": args.test_data_file_path,
-        "N": args.N,
-        "probe_scale": args.probe_scale,
-        "nphotons": args.nphotons,
-        "mae_weight": args.mae_weight,
-        "nll_weight": args.nll_weight,
-    }
-    
-
-    update_params(params)
-    config = setup_configuration(args, args.config)
-
-    from ptycho import probe
-    from ptycho.nongrid_simulation import (
-        simulate_from_npz,
-        visualize_simulated_data,
-        plot_random_groups,
-        compare_reconstructions,
-    )
-    from ptycho import tf_helper as hh
-    from ptycho import baselines as bl
-    from ptycho.workflows.components import create_ptycho_data_container
-
-    # Simulate data
-    simulated_data, ground_truth_patches = simulate_from_npz(
-        args.input_file, args.nimages, random_seed=args.seed
-    )
-
-    # Set the probe
-    probe.set_probe_guess(None, simulated_data.probeGuess)
-
-    # Prepare data for visualization
-    data_for_vis = {
-        'diffraction_patterns': simulated_data.diff3d,
-        'ground_truth_patches': ground_truth_patches,
-        'probe_guess': simulated_data.probeGuess,
-        'object': simulated_data.objectGuess,
-        'x_coordinates': simulated_data.xcoords,
-        'y_coordinates': simulated_data.ycoords,
-    }
-
-    # Generate and save visualizations
-    image_files = []
-
-    # Visualize simulated data
-    #plt.figure(figsize=(20, 20))
-    visualize_simulated_data(data_for_vis, args.output_dir)
-    filename = os.path.join(args.output_dir, "simulated_data_visualization.png")
-    #plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    #plt.close()
-
-    # Plot random groups
-    for i in range(3):  # Generate 3 sets of random groups
-        plt.figure(figsize=(15, 15))
-        plot_random_groups(simulated_data, K=5, seed=args.seed)
-        filename = os.path.join(args.output_dir, f'random_groups_{i+1}.png')
-        plt.savefig(filename, dpi=300, bbox_inches='tight')
-        image_files.append(filename)
-        plt.close()
-
-    # Run CDI example and compare reconstructions
-    config = setup_configuration(args, None)
-    train_data = create_ptycho_data_container(simulated_data, config)
-    recon_amp, recon_phase, results = run_cdi_example(train_data, train_data, config)
-
-    # Train baseline model
-    baseline_model = bl.train(train_data.X[:, :, :, :1], train_data.Y_I[:, :, :, :1], train_data.Y_phi[:, :, :, :1])
-    baseline_pred_I, baseline_pred_phi = baseline_model[0].predict([train_data.X[:, :, :, 0]])
-
-    # Compare reconstructions
-    plt.figure(figsize=(20, 20))
-    compare_reconstructions(
-        results['obj_tensor_full'],
-        results['global_offsets'],
-        simulated_data.objectGuess,
-        hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-    )
-    filename = os.path.join(args.output_dir, 'reconstruction_comparison.png')
-    plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    plt.close()
-
-    # Generate HTML report with embedded images, launch command, and model parameters
-    generate_html_report(args.output_dir, image_files, args, params)
-
-    print(f"Simulation and visualization complete. Results saved in {args.output_dir}")
-    print(f"Open {os.path.join(args.output_dir, 'report.html')} to view the visualizations.")
-
-if __name__ == "__main__":
-    main()
-
diff --git a/build/lib/build/lib/build/lib/build/lib/scripts/stitch_patches.py b/build/lib/build/lib/build/lib/build/lib/scripts/stitch_patches.py
deleted file mode 100644
index 4f88936..0000000
--- a/build/lib/build/lib/build/lib/build/lib/scripts/stitch_patches.py
+++ /dev/null
@@ -1,93 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, *, 
-                  N: int,
-                  gridsize: int,
-                  offset: int,
-                  nimgs_test: int,
-                  outer_offset_test: int = None,
-                  norm_Y_I_test: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        N: Size of each square patch
-        gridsize: Grid size for patch arrangement  
-        offset: Spacing between patches
-        nimgs_test: Number of test images
-        outer_offset_test: Offset between outer patches
-        norm_Y_I_test: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # if the channel dimension exists, its size must be 1
-    if patches.shape[-1] != 1:
-        assert patches.shape[-1] == N
-
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    # Handle optional parameters
-    nimgs = nimgs_test
-    outer_offset = outer_offset_test if outer_offset_test is not None else offset
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / nimgs) / (N**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-
-# Usage example
-#stitched = stitch_patches(ptycho_dataset.test_data.Y[:, :, :, :1],
-#              N=64,
-#              gridsize=2,
-#              offset=4,
-#              nimgs_test=1,
-#              outer_offset_test=20,
-#              norm_Y_I_test=ptycho_dataset.test_data.norm_Y_I,
-#              norm=True, 
-#              part='complex')
-#plt.imshow(np.abs(stitched[0, :, :, 0]))
diff --git a/build/lib/build/lib/build/lib/build/lib/scripts/training/train.py b/build/lib/build/lib/build/lib/build/lib/scripts/training/train.py
deleted file mode 100644
index 983f262..0000000
--- a/build/lib/build/lib/build/lib/build/lib/scripts/training/train.py
+++ /dev/null
@@ -1,62 +0,0 @@
-#!/usr/bin/env python
-
-import logging
-import sys
-
-# Set up file handler for debug logging
-file_handler = logging.FileHandler('train_debug.log')
-file_handler.setLevel(logging.DEBUG)
-file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Set up console handler for info logging
-console_handler = logging.StreamHandler(sys.stdout)
-console_handler.setLevel(logging.INFO)
-console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Configure root logger
-logging.getLogger().setLevel(logging.DEBUG)
-logging.getLogger().addHandler(file_handler)
-logging.getLogger().addHandler(console_handler)
-
-from ptycho.workflows.components import (
-    parse_arguments,
-    setup_configuration,
-    load_data,
-    run_cdi_example,
-    save_outputs,
-    logger
-)
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import model_manager, params
-def main() -> None:
-    """Main function to orchestrate the CDI example script execution."""
-    args = parse_arguments()
-    
-    # Handle legacy argument name
-    if hasattr(args, 'train_data_file_path'):
-        args.train_data_file = args.train_data_file_path
-        delattr(args, 'train_data_file_path')
-        
-    config = setup_configuration(args, args.config)
-    
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    try:
-
-        #ptycho_data, ptycho_data_train, obj = load_and_prepare_data(config['train_data_file_path'])
-        ptycho_data = load_data(str(config.train_data_file), n_images = 512)
-        
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-    except Exception as e:
-        logger.error(f"An error occurred during execution: {e}")
-        raise
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py b/build/lib/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py
deleted file mode 100644
index 8e729d2..0000000
--- a/build/lib/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py
+++ /dev/null
@@ -1,49 +0,0 @@
-from ptycho.tf_helper import complexify_function, complexify_amp_phase, combine_complex
-import tensorflow as tf
-import numpy as np
-
-
-# Sample function to be complexified
-def sample_fn(tensor, *args, **kwargs):
-    return tensor * 2
-
-# Complexify the sample function
-complexified_fn = complexify_function(sample_fn)
-complexified_amp_phase_fn = complexify_amp_phase(sample_fn)
-
-def test_complexify_function():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    expected_output = tf.constant([2.0 + 4.0j, 6.0 + 8.0j], dtype=tf.complex64)
-    assert tf.math.reduce_all(complexified_fn(complex_tensor) == expected_output), "Failed on complex tensor"
-
-def test_complexify_amp_phase():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    # Doubling the amplitude
-    expected_amplitude = tf.math.abs(complex_tensor) * 2
-    # Doubling the phase (modulus to keep it within -pi to pi)
-    expected_phase = tf.math.angle(complex_tensor) * 2 % (2 * tf.constant(np.pi))
-    # Construct the expected tensor
-    expected_tensor = combine_complex(expected_amplitude, expected_phase)
-    # Compare the reconstructed tensor to the expected tensor
-    error = tf.math.abs(complexified_amp_phase_fn(complex_tensor) - expected_tensor)
-    assert tf.math.reduce_max(error) < 1e-6, "Failed on complex tensor"
-
-
-# Execute the tests
-test_complexify_function()
-
-with tf.device('/CPU:0'):
-    # Force CPU execution because one of the first two tests fails on GPU
-    test_complexify_amp_phase()
-
-print("All tests passed!")
diff --git a/build/lib/build/lib/build/lib/build/lib/tests/test_generate_data.py b/build/lib/build/lib/build/lib/build/lib/tests/test_generate_data.py
deleted file mode 100644
index 405bef0..0000000
--- a/build/lib/build/lib/build/lib/build/lib/tests/test_generate_data.py
+++ /dev/null
@@ -1,7 +0,0 @@
-# Test for generate_data module in the ptycho package
-
-from ptycho import generate_data as init
-
-def test_placeholder():
-    # Placeholder test to ensure the import works
-    assert hasattr(init, 'PtychoData'), "generate_data module should have PtychoData class"
diff --git a/build/lib/build/lib/build/lib/build/lib/tests/test_generic_loader.py b/build/lib/build/lib/build/lib/build/lib/tests/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/build/lib/build/lib/tests/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/build/lib/build/lib/tests/test_tf_helper.py b/build/lib/build/lib/build/lib/build/lib/tests/test_tf_helper.py
deleted file mode 100644
index 337e29e..0000000
--- a/build/lib/build/lib/build/lib/build/lib/tests/test_tf_helper.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import unittest
-import tensorflow as tf
-import numpy as np
-from ptycho.tf_helper import get_mask, combine_complex, pad_obj
-
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import tensorflow as tf
-from ptycho.tf_helper import get_mask, _fromgrid, params
-
-class TestFromGrid(unittest.TestCase):
-
-    def test_fromgrid(self):
-        print("Debug: Starting test_fromgrid")
-        # Set up parameters for the test
-        gridsize = params()['gridsize']
-        N = params()['N']
-        print(f"Debug: Test parameters - gridsize = {gridsize}, N = {N}")
-        # Create a sample input tensor in grid format
-        input_tensor = tf.random.uniform((1, gridsize, gridsize, N, N), dtype=tf.float32)
-        print(f"Debug: Input tensor shape = {input_tensor.shape}")
-        # Calculate the expected output shape
-        expected_shape = (1, N, N, 1)
-        print(f"Debug: Expected output shape = {expected_shape}")
-        # Run the _fromgrid function
-        output_tensor = _fromgrid(input_tensor)
-        print(f"Debug: Output tensor shape = {output_tensor.shape}")
-        # Check if the output shape matches the expected shape
-        self.assertEqual(output_tensor.shape, expected_shape)
-
-with tf.device('/CPU:0'):
-    def test_complexify_amp_phase():
-        # Test with real tensor
-        real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-        assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-    def test_get_mask():
-        input_tensor = tf.constant([[0.1, 0.5], [0.9, 0.0]], dtype=tf.float32)
-        expected_output = tf.constant([[0, 1], [1, 0]], dtype=tf.float32)
-        threshold = 0.2
-        output = get_mask(input_tensor, threshold)
-        self.assertTrue(tf.reduce_all(tf.equal(output, expected_output)))
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import numpy as np
-import tensorflow as tf
-from ptycho.tf_helper import combine_complex
-
-class TestCombineComplex(unittest.TestCase):
-
-def test_combine_complex():
-    amp = tf.constant([1.0, 2.0], dtype=tf.float32)
-    phi = tf.constant([0.0, np.pi], dtype=tf.float32)
-    expected_output = tf.constant([1.0 + 0j, -2.0 + 0j], dtype=tf.complex64)
-    output_complex = combine_complex(amp, phi)
-    # Use a tolerance when comparing complex numbers
-    tolerance = 1e-5
-    self.assertTrue(tf.reduce_all(tf.math.abs(output_complex - expected_output) < tolerance))
-
-def test_pad_and_diffract():
-    # Create a sample input tensor
-    input_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
-    input_tensor = tf.reshape(input_tensor, (1, 2, 2, 1))  # Reshape to (batch, height, width, channels)
-    # Define the desired output height and width
-    desired_height = 4
-    desired_width = 4
-    # Expected output tensor values based on provided output
-    expected_output_values = [0.0, 0.70710677, 1.0, 0.70710677, 0.35355338, 1.4577379, 1.9039432, 1.2747549, 0.5, 1.8027756]
-    # Run pad_and_diffract function
-    _, output_tensor = pad_and_diffract(input_tensor, desired_height, desired_width)
-    # Flatten the output tensor and slice the first 10 values for comparison
-    output_values = output_tensor.numpy().flatten()[:10]
-    # Check if the output values match the expected values within a tolerance
-    for expected, actual in zip(expected_output_values, output_values):
-        self.assertAlmostEqual(expected, actual, places=5)
-
-# Execute the tests
-if __name__ == "__main__":
-    test_complexify_function()
-    with tf.device('/CPU:0'):
-        # Force CPU execution because one of the first two tests fails on GPU
-        test_complexify_amp_phase()
-        test_get_mask()
-        test_combine_complex()
-        test_pad_and_diffract()
-
-if __name__ == '__main__':
-    unittest.main()
-
diff --git a/build/lib/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py b/build/lib/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py
deleted file mode 100644
index 20e2574..0000000
--- a/build/lib/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py
+++ /dev/null
@@ -1,326 +0,0 @@
-import torch
-import numpy as np
-from .tf_helper import *
-
-def test_get_mask():
-    input_tensor = torch.tensor([[1.0, 0.5, 0.8], [0.3, 0.9, 0.2]])
-    support_threshold = 0.6
-    expected_output = torch.tensor([[1.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
-    assert torch.all(torch.eq(get_mask(input_tensor, support_threshold), expected_output))
-
-def test_combine_complex():
-    amp = torch.tensor([[1.0, 0.5], [0.8, 0.3]])
-    phi = torch.tensor([[0.0, np.pi/2], [np.pi/4, np.pi]])
-    expected_output = torch.view_as_complex(torch.tensor([[[1.0, 0.0], [0.0, 0.5]], [[0.5657, 0.5657], [-0.3, 0.0]]]))
-    assert torch.allclose(combine_complex(amp, phi), expected_output)
-
-def test_pad_obj():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_obj(input_tensor, h, w), expected_output))
-
-def test__fromgrid():
-    params()['N'] = 2
-    img = torch.ones((1, 2, 2, 2, 2, 1))
-    expected_output = torch.ones((4, 2, 2, 1))
-    assert torch.all(torch.eq(_fromgrid(img), expected_output))
-
-def test__togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img = torch.ones((4, 2, 2, 1))
-    expected_output = torch.ones((1, 2, 2, 2, 2, 1))
-    assert torch.all(torch.eq(_togrid(img), expected_output))
-
-def test_togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img1 = torch.ones((4, 2, 2, 1))
-    img2 = torch.ones((4, 2, 2, 1))
-    expected_output = (torch.ones((1, 2, 2, 2, 2, 1)), torch.ones((1, 2, 2, 2, 2, 1)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(togrid(img1, img2), expected_output))
-
-def test__grid_to_channel():
-    params()['gridsize'] = 2
-    grid = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_grid_to_channel(grid), expected_output))
-
-def test_grid_to_channel():
-    params()['gridsize'] = 2
-    grid1 = torch.ones((1, 2, 2, 3, 3, 1))
-    grid2 = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = (torch.ones((1, 3, 3, 4)), torch.ones((1, 3, 3, 4)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(grid_to_channel(grid1, grid2), expected_output))
-
-def test__flat_to_channel():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    img = torch.ones((4, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_flat_to_channel(img), expected_output))
-
-def test__flat_to_channel_2():
-    params()['gridsize'] = 2
-    img = torch.ones((1, 3, 4, 1))
-    expected_output = torch.ones((1, 3, 4, 4))
-    assert torch.all(torch.eq(_flat_to_channel_2(img), expected_output))
-
-def test__channel_to_flat():
-    img = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3, 3, 1))
-    assert torch.all(torch.eq(_channel_to_flat(img), expected_output))
-
-def test__channel_to_patches():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    channel = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((1, 2, 2, 9))
-    assert torch.all(torch.eq(_channel_to_patches(channel), expected_output))
-
-def test_pad_patches():
-    imgs = torch.ones((1, 4, 4, 1))
-    padded_size = 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_patches(imgs, padded_size), expected_output))
-
-def test_pad():
-    imgs = torch.ones((1, 4, 4, 1))
-    size = 2
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad(imgs, size), expected_output))
-
-def test_trim_reconstruction():
-    x = torch.ones((1, 8, 8, 1))
-    N = 4
-    expected_output = torch.ones((1, 4, 4, 1))
-    assert torch.all(torch.eq(trim_reconstruction(x, N), expected_output))
-
-def test_flatten_offsets():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3))
-    assert torch.all(torch.eq(flatten_offsets(channels), expected_output))
-
-def test_pad_reconstruction():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 7, 7, 1))
-    assert torch.all(torch.eq(pad_reconstruction(channels), expected_output))
-
-def test_pad_and_diffract():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    padded_expected = torch.ones((1, 8, 8, 1))
-    input_expected = torch.ones((1, 8, 8, 1))
-    padded, input = pad_and_diffract(input_tensor, h, w)
-    assert torch.all(torch.eq(padded, padded_expected))
-    assert torch.allclose(input, input_expected, atol=1e-6)
-
-import torch
-from typing import Callable
-
-def test_mk_centermask():
-    inputs = torch.ones((2, 8, 8, 3))
-    N = 4
-    c = 3
-
-    # Test case 1: Check if the function returns the correct center mask when kind='center'
-    expected_center_mask = torch.zeros((2, 8, 8, 3))
-    expected_center_mask[:, 2:6, 2:6, :] = 1
-    center_mask = mk_centermask(inputs, N, c, kind='center')
-    assert torch.allclose(center_mask, expected_center_mask)
-
-    # Test case 2: Check if the function returns the correct border mask when kind='border'
-    expected_border_mask = torch.ones((2, 8, 8, 3))
-    expected_border_mask[:, 2:6, 2:6, :] = 0
-    border_mask = mk_centermask(inputs, N, c, kind='border')
-    assert torch.allclose(border_mask, expected_border_mask)
-
-    # Test case 3: Check if the function raises a ValueError when kind is not 'center' or 'border'
-    try:
-        mk_centermask(inputs, N, c, kind='invalid')
-        assert False, "Expected ValueError was not raised"
-    except ValueError:
-        pass
-
-def test_mk_norm():
-    channels = torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function returns the correct norm values
-    expected_norm = torch.ones((2, 8, 8, 4)) * 2 + 0.001
-    norm = mk_norm(channels, mock_fn_reassemble_real)
-    assert torch.allclose(norm, expected_norm)
-
-    # Test case 2: Check if the function handles different input shapes correctly
-    channels_2 = torch.ones((4, 16, 16, 8))
-    expected_norm_2 = torch.ones((4, 16, 16, 8)) * 2 + 0.001
-    norm_2 = mk_norm(channels_2, mock_fn_reassemble_real)
-    assert torch.allclose(norm_2, expected_norm_2)
-
-def test_reassemble_patches():
-    channels = torch.ones((2, 8, 8, 4)) + 1j * torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function correctly reassembles patches when average=False
-    expected_output = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output = reassemble_patches(channels, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the function correctly reassembles patches when average=True
-    expected_output_avg = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output_avg = reassemble_patches(channels, mock_fn_reassemble_real, average=True)
-    assert torch.allclose(output_avg, expected_output_avg)
-
-    # Test case 3: Check if the function handles complex input channels correctly
-    channels_real = torch.ones((2, 8, 8, 4))
-    channels_imag = torch.ones((2, 8, 8, 4)) * 2
-    channels_complex = torch.complex(channels_real, channels_imag)
-    expected_output_complex = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 4
-    output_complex = reassemble_patches(channels_complex, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output_complex, expected_output_complex)
-
-def test__reassemble_patches_position_real():
-    imgs = torch.ones((2, 8, 8, 4))
-    offsets_xy = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-    padded_size = 16
-
-    # Mock Translation class
-    class MockTranslation:
-        def __call__(self, inputs):
-            return inputs[0] + inputs[1].unsqueeze(-1).unsqueeze(-1)
-
-    # Mock helper functions
-    def mock_flatten_offsets(offsets_xy):
-        return offsets_xy.view(-1, 2)
-
-    def mock__channel_to_flat(imgs):
-        return imgs.view(-1, 8, 8, 1)
-
-    def mock_pad_patches(imgs_flat, padded_size):
-        return torch.ones((8, padded_size, padded_size, 1))
-
-    def mock__flat_to_channel(imgs_flat_bigN_translated, N):
-        return imgs_flat_bigN_translated.view(2, N, N, 4)
-
-    # Test case 1: Check if the function correctly reassembles patches when agg=True
-    expected_output_agg = torch.ones((2, padded_size, padded_size, 1)) * 4
-    output_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=True, padded_size=padded_size,
-                                                   flatten_offsets=mock_flatten_offsets,
-                                                   _channel_to_flat=mock__channel_to_flat,
-                                                   pad_patches=mock_pad_patches,
-                                                   Translation=MockTranslation(),
-                                                   _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg, expected_output_agg)
-
-    # Test case 2: Check if the function correctly reassembles patches when agg=False
-    expected_output_no_agg = torch.ones((2, padded_size, padded_size, 4))
-    output_no_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=False, padded_size=padded_size,
-                                                      flatten_offsets=mock_flatten_offsets,
-                                                      _channel_to_flat=mock__channel_to_flat,
-                                                      pad_patches=mock_pad_patches,
-                                                      Translation=MockTranslation(),
-                                                      _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_no_agg, expected_output_no_agg)
-
-    # Test case 3: Check if the function handles different input shapes and offsets correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    offsets_xy_2 = torch.tensor([[[1, 1], [2, 2], [3, 3], [4, 4]], [[5, 5], [6, 6], [7, 7], [8, 8]]])
-    padded_size_2 = 32
-    expected_output_agg_2 = torch.ones((4, padded_size_2, padded_size_2, 1)) * 8
-    output_agg_2 = _reassemble_patches_position_real(imgs_2, offsets_xy_2, agg=True, padded_size=padded_size_2,
-                                                     flatten_offsets=mock_flatten_offsets,
-                                                     _channel_to_flat=mock__channel_to_flat,
-                                                     pad_patches=mock_pad_patches,
-                                                     Translation=MockTranslation(),
-                                                     _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg_2, expected_output_agg_2)
-
-def test_mk_reassemble_position_real():
-    input_positions = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-
-    # Mock _reassemble_patches_position_real function
-    def mock__reassemble_patches_position_real(imgs, offsets_xy, **kwargs):
-        return imgs + offsets_xy.sum()
-
-    # Test case 1: Check if the function returns a callable that correctly reassembles patches
-    imgs = torch.ones((2, 8, 8, 4))
-    expected_output = imgs + 10
-    reassemble_fn = mk_reassemble_position_real(input_positions)
-    output = reassemble_fn(imgs)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the returned callable handles different input shapes and keyword arguments correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    expected_output_2 = imgs_2 + 10
-    output_2 = reassemble_fn(imgs_2)
-    assert torch.allclose(output_2, expected_output_2)
-
-    import torch
-import numpy as np
-
-def test_translate():
-    # Test case 1: Single input tensor
-    tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    output = translate(tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
-    # Test case 2: Batched input tensors
-    batch_size = 2
-    channels = 3
-    height = 4
-    width = 5
-    imgs = torch.randn(batch_size, channels, height, width)
-    offsets = torch.tensor([[1.0, -1.0], [-2.0, 2.0]], dtype=torch.float32)
-    expected_output = torch.tensor([
-        [
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.1132, 0.1562, 0.1697],
-             [0.0000, 0.7470, 0.8155, 0.1878, 0.4034],
-             [0.0000, 1.3378, 0.9931, 0.2400, 0.2372]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.6398, 0.8829, 0.9593],
-             [0.0000, 1.0086, 1.1025, 0.2537, 0.5450],
-             [0.0000, 0.8617, 0.6401, 0.1547, 0.1529]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.2566, 0.3541, 0.3848],
-             [0.0000, 0.5297, 0.5783, 0.1331, 0.2861],
-             [0.0000, 0.6287, 0.4674, 0.1129, 0.1117]]
-        ],
-        [
-            [[0.0000, 0.9102, 0.8985, 0.0256, 0.1092],
-             [0.0000, 0.0082, 0.1560, 0.1651, 0.1176],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.6713, 0.6630, 0.0189, 0.0806],
-             [0.0000, 0.0118, 0.2246, 0.2374, 0.1691],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.5032, 0.4970, 0.0142, 0.0604],
-             [0.0000, 0.0117, 0.2213, 0.2342, 0.1667],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]
-        ]
-    ], dtype=torch.float32)
-    output = translate(imgs, offsets)
-    assert torch.allclose(output, expected_output, atol=1e-4)
-
-    # Test case 3: Complex input tensor
-    real_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    imag_tensor = torch.tensor([[0.5, 1.0, 1.5], [2.0, 2.5, 3.0]], dtype=torch.float32)
-    complex_tensor = torch.complex(real_tensor, imag_tensor)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_real_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    expected_imag_output = torch.tensor([[2.5, 3.0, 0.0], [1.0, 1.5, 0.0]], dtype=torch.float32)
-    expected_output = torch.complex(expected_real_output, expected_imag_output)
-    output = translate(complex_tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
diff --git a/build/lib/build/lib/build/lib/build/lib/torch/tests/tf_helper.py b/build/lib/build/lib/build/lib/build/lib/torch/tests/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/build/lib/build/lib/torch/tests/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/build/lib/build/lib/build/lib/torch/tf_helper.py b/build/lib/build/lib/build/lib/build/lib/torch/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/build/lib/build/lib/torch/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/build/lib/build/lib/diagram/pinn.py b/build/lib/build/lib/build/lib/diagram/pinn.py
deleted file mode 100644
index 2e5d21a..0000000
--- a/build/lib/build/lib/build/lib/diagram/pinn.py
+++ /dev/null
@@ -1,293 +0,0 @@
-
-import numpy as np
-import sys
-sys.path.append('../')
-from pycore.tikzeng import *
-
-offset = -1.5
-scale = .3
-decoder_offset = 0
-def ppos(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    nums = np.array([float(n) for n in nums])
-    nums[0] += decoder_offset
-    new = str(tuple(n * scale for n in nums))
-    print(new)
-    return new
-
-def ppos_encoder(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    new = str(tuple(float(n) * scale for n in nums))
-    print(new)
-    return new
-
-## vim macro
-"""/\dcw{}jk?codek$a"jkpa", jk/\a\d"""
-patch_size = 26
-# size of the probe-illuminated patches
-probe_scale = 1.2
-zoff = -10 #* scale
-xext = 31
-xpatch = 31.2
-patch_width = .5
-diff_width = .5
-diff_spacing = 7 * probe_scale
-xdiff = 37
-xdiff2 = 44
-probe_size = 32
-
-diff2_spacing = .2
-diff2_dx = 2
-diff2_dy = .5
-diff2_dz = 0.5
-diff2_width = 3
-amp_suffix = '_1'
-phase_suffix = '_2'
-
-legend_offset_y = -20
-legend_boxsize = 8
-legend_width = 0
-legend_spacing_x = 6 / (2 * scale)
-legend_offset_x = -7
-legend_spacing_y = -4 / (2 * scale)
-legend_patch_width = .1
-offset2 = offset * (legend_boxsize / 32)
-
-img_path_fmt = '../../notebooks/images/{}'
-
-input1 = img_path_fmt.format('in1.png')
-input2 = img_path_fmt.format('in2.png')
-input3 = img_path_fmt.format('in3.png')
-input4 = img_path_fmt.format('in4.png')
-
-output1 = img_path_fmt.format('out1.png')
-output2 = img_path_fmt.format('out2.png')
-output3 = img_path_fmt.format('out3.png')
-output4 = img_path_fmt.format('out4.png')
-
-patch1_path = img_path_fmt.format('patch1.png')
-patch2_path = img_path_fmt.format('patch2.png')
-patch3_path = img_path_fmt.format('patch3.png')
-patch4_path = img_path_fmt.format('patch4.png')
-
-phase_path = img_path_fmt.format('phase.png')
-amp_path = img_path_fmt.format('amp.png')
-full_obj_path = img_path_fmt.format('full_obj.png')
-
-im_size = 13 * scale
-inp_x = -7
-outp_x = 50
-
-encoder = [
-    to_input(input1, to=ppos("({},{},{})".format(inp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(input2, to=ppos("({},{},{})".format(inp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(input3, to=ppos("({},{},{})".format(inp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(input4, to=ppos("({},{},{})".format(inp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-    to_ConvRelu("conv11", '', 64, offset=ppos_encoder("(0,0,0)"), to=ppos_encoder("(0,0,0)"),
-        height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_ConvRelu("conv12", '', '', offset=ppos_encoder("(.4,0,0)"), to=ppos_encoder("(0,0,0)"), height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_Pool("pool1", offset=ppos_encoder("(0,0,0)"), to="(conv12-east)", height=32* scale, depth=32* scale),
-
-    to_ConvRelu("conv21", '', '', offset=ppos_encoder("(5,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_ConvRelu("conv22", '', 128, offset=ppos_encoder("(5.8,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_Pool("pool2", offset=ppos_encoder("(0,0,0)"), to="(conv22-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool1", "conv21"),
-
-    to_ConvRelu("conv31", '', 256, offset=ppos_encoder("(10,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_ConvRelu("conv32", '', '', offset=ppos_encoder("(11.6,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_Pool("pool3", offset=ppos_encoder("(0,0,0)"), to="(conv32-east)", height=8* scale, depth=8* scale),
-    to_connection( "pool2", "conv31"),
-]
-
-def last_decoder(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_Sigmoid("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = 'A(r)')
-    elif pos_sign == -1:
-        return to_Tanh("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = r'$\bm{\phi(r)}$')
-    else:
-        raise ValueError
-
-def last_decoder_img(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_input(amp_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    elif pos_sign == -1:
-        return to_input(phase_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    else:
-        raise ValueError
-
-def mk_decoder(name_suffix = '0', pos_sign = 1):
-    return [
-    to_ConvRelu("up11" + name_suffix, '', 256, offset=ppos("(12,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_ConvRelu("up12" + name_suffix, '', '', offset=ppos("(13.6,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_UnPool("unpool1" + name_suffix, offset=ppos("(0,0,0)"), to="(up12" + name_suffix + "-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool3", "up11" + name_suffix),
-
-    to_ConvRelu("up21" + name_suffix, '', 128, offset=ppos("(18,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_ConvRelu("up22" + name_suffix, '', '', offset=ppos("(18.8,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_UnPool("unpool2" + name_suffix, offset=ppos("(0,0,0)"), to="(up22" + name_suffix + "-east)", height=32* scale, depth=32* scale),
-    to_connection( "unpool1" + name_suffix, "up21" + name_suffix),
-
-#    to_Conv("up31" + name_suffix, '', 1, offset=ppos("(23,0,0)"),
-#        to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-#        depth=32* scale, width=2 * scale),
-    last_decoder(pos_sign, name_suffix),
-    last_decoder_img(pos_sign, name_suffix),
-    to_connection( "unpool2" + name_suffix, last + name_suffix)
-    #to_connection( "unpool2" + name_suffix, "up31" + name_suffix)
-    ]
-#last = "up31"
-last = "last"
-
-forward_map =\
-[
-    to_Sum("sum1", offset=ppos("(27.5,0,0)"), to=ppos("(0, 0, 0)"), radius=2.5 * scale, opacity=0.6),
-    to_connection(last+ amp_suffix, "sum1"),
-    to_connection(last+ phase_suffix, "sum1"),
-    to_Extract("extract1", '', 4, offset=ppos("({},0,0)".format(xext)),
-        to=ppos("(0,0,0)"), height=64* scale / 2, depth=64* scale / 2, width=2* scale,
-        caption = ''),
-    to_input(full_obj_path, to = ppos("({},0,0)".format(xext)), width = im_size,
-        height = im_size),
-    to_connection("sum1", "extract1"),
-    to_Patch("patch1", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch4", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch2", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch3", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale)] +\
-    to_Illumination("probe2", patch2_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * 1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch2", "probe2")] +\
-    to_Illumination("probe3", patch3_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * .5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch3", "probe3")] +\
-    to_Illumination("probe1", patch1_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch1", "probe1")] +\
-    to_Illumination("probe4", patch4_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2,
-        caption = r'$\bm{\times}$ Probe${(\bm{r - r_i})}$') +\
-    [to_connection( "patch4", "probe4")] +\
-    [
-#        to_Diffraction("diff1", '', 4, offset=ppos("({},0,0)".format(xdiff2)),
-#        to=ppos("({},{},{})".format(diff2_dx * 1.5, diff2_dy * 1.5, diff2_dz * 1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-#    to_Diffraction("diff2", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing)),
-#        to=ppos("({},{},{})".format(diff2_dx * .5, diff2_dy * .5, diff2_dz * .5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_Diffraction("diff3", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 2)),
-        to=ppos("({},{},{})".format(diff2_dx * -.5, diff2_dy * -.5, diff2_dz * -.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-        caption = ''),
-#    to_Diffraction("diff4", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 3)),
-#        to=ppos("({},{},{})".format(diff2_dx * -1.5, diff2_dy * -1.5, diff2_dz * -1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_connection("probe2", "diff3"),#top
-    to_connection("probe1", "diff3"),
-    to_connection("probe3", "diff3"),
-    to_connection("probe4", "diff3"),# bottom
-#    to_connection("probe2", "diff1"),#top
-#    to_connection("probe1", "diff3"),
-#    to_connection("probe3", "diff2"),
-#    to_connection("probe4", "diff4"),# bottom
-
-    to_input(output1, to=ppos("({},{},{})".format(outp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(output2, to=ppos("({},{},{})".format(outp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(output3, to=ppos("({},{},{})".format(outp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(output4, to=ppos("({},{},{})".format(outp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-
-    to_ConvRelu("conv_relu_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~ReLU($\cdot$)""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~ReLU($\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Pool("pool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""AvgPool2D($\cdot$)"""),
-
-    to_UnPool("unpool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-        legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Upsample($\cdot$)"""),
-
-    to_Tanh("tanh_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 0,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~$i \bm{\pi \tanh(\cdot)}$""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~$i \pi \tanh(\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Sigmoid("sigmoid_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 1,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~Sigmoid$(\cdot)$""",
-        s_filer = '', n_filer = ''),
-
-    to_Patch("patch1_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch4_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch2_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch3_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale,
-        caption = r"""Crop$(\cdot)$\linebreak Shift$(\cdot)$""",),
-        #caption = r"""Illuminate$(\cdot)$""",),
-
-    to_Diffraction("diff_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 3,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Diffract$(\bm{\cdot})$ \linebreak $\sim $Poisson$(\bm{\cdot}^2)$""",
-        s_filer = '', n_filer = ''),
-
-]
-
-arch = [to_head( '..' ),
-    to_cor(),
-    to_begin()] +\
-    encoder + mk_decoder(amp_suffix, pos_sign = 1) +\
-    mk_decoder(phase_suffix, pos_sign = -1) + forward_map +\
-    [to_end()]
-
-def main():
-    namefile = str(sys.argv[0]).split('.')[0]
-    to_generate(arch, namefile + '.tex' )
-
-if __name__ == '__main__':
-    main()
diff --git a/build/lib/build/lib/build/lib/diagram/tikzeng.py b/build/lib/build/lib/build/lib/diagram/tikzeng.py
deleted file mode 100644
index 4de56da..0000000
--- a/build/lib/build/lib/build/lib/diagram/tikzeng.py
+++ /dev/null
@@ -1,374 +0,0 @@
-
-import os
-
-def to_head( projectpath ):
-    pathlayers = os.path.join( projectpath, 'layers/' ).replace('\\', '/')
-    return r"""
-\documentclass[border=8pt, multi, tikz]{standalone}
-\usepackage{import}
-\usepackage{bm}
-\usepackage{transparent}
-\subimport{"""+ pathlayers + r"""}{init}
-\usetikzlibrary{positioning}
-\usetikzlibrary{3d} %for including external image
-"""
-
-def to_cor():
-    return r"""
-\def\ConvColor{rgb:yellow,5;red,2.5;white,5}
-\def\ConvReluColor{rgb:yellow,5;red,5;white,5}
-\def\PoolColor{rgb:red,1;black,0.3}
-\def\UnpoolColor{rgb:blue,2;green,1;black,0.3}
-\def\FcColor{rgb:blue,5;red,2.5;white,5}
-\def\FcReluColor{rgb:blue,5;red,5;white,4}
-\def\SoftmaxColor{rgb:magenta,5;black,7}
-\def\SumColor{rgb:blue,5;green,15}
-\def\DcnvColor{rgb:blue,5;green,2.5;white,5}
-"""
-
-def to_begin():
-    return r"""
-\newcommand{\copymidarrow}{\tikz \draw[-Stealth,line width=0.8mm,draw={rgb:blue,4;red,1;green,1;black,3}] (-0.3,0) -- ++(0.3,0);}
-
-\begin{document}
-\begin{tikzpicture}
-\tikzstyle{connection}=[ultra thick,every node/.style={sloped,allow upside down},draw=\edgecolor,opacity=0.7]
-\tikzstyle{copyconnection}=[ultra thick,every node/.style={sloped,allow upside down},draw={rgb:blue,4;red,1;green,1;black,3},opacity=0.7]
-"""
-
-# layers definition
-
-def to_input( pathfile, to='(-3,0,0)', width=8, height=8, name="temp" ):
-    return r"""
-\node[canvas is zy plane at x=0] (""" + name + """) at """+ to +""" {\includegraphics[width="""+ str(width)+"cm"+""",height="""+ str(height)+"cm"+"""]{"""+ pathfile +"""}};
-"""
-
-# Conv
-def to_Conv( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_ConvRelu( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# Conv,Conv,relu
-# Bottleneck
-def to_ConvConvRelu( name, s_filer=256, n_filer=(64,64), offset="(0,0,0)", to="(0,0,0)", width=(2,2), height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name +""",
-        caption="""+ caption +""",
-        xlabel={{ """+ str(n_filer[0]) +""", """+ str(n_filer[1]) +""" }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        bandfill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width={ """+ str(width[0]) +""" , """+ str(width[1]) +""" },
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# Pool
-def to_Pool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+name+""",
-        caption="""+ caption +r""",
-        fill=\PoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# unpool4,
-def to_UnPool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+ name +r""",
-        caption="""+ caption +r""",
-        fill=\UnpoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_ConvRes( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Pad( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sigmoid( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:violet,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Tanh( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Patch( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.1, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        bandopacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-# bandfill={rgb:blue,1;red,2},
-
-def to_Extract( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)",
-        width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;green,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_Illumination( name, filepath, s_filer=256, n_filer=64,
-    offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-    opacity=0.2, caption=" " , im_size = 4):
-    return [r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;blue,3},
-        bandfill={rgb:black,1;blue,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-""",
-    to_input(filepath, to = to, width = im_size, height = im_size)]
-
-def to_Diffraction( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.4, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:violet,1;red,3},
-        bandfill={rgb:white,1;red,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# ConvSoftMax
-def to_ConvSoftMax( name, s_filer=40, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# SoftMax
-def to_SoftMax( name, s_filer=10, offset="(0,0,0)", to="(0,0,0)", width=1.5, height=3, depth=25, opacity=0.8, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        xlabel={{" ","dummy"}},
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sum( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=""" + r'$\times$' + """
-        }
-    };
-"""
-
-def to_Prod( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=$x$
-        }
-    };
-"""
-
-# \times?
-
-def to_connection( of, to):
-    return r"""
-\draw [connection]  ("""+of+"""-east)    -- node {\midarrow} ("""+to+"""-west);
-"""
-
-def to_skip( of, to, pos=1.25):
-    return r"""
-\path ("""+ of +"""-southeast) -- ("""+ of +"""-northeast) coordinate[pos="""+ str(pos) +"""] ("""+ of +"""-top) ;
-\path ("""+ to +"""-south)  -- ("""+ to +"""-north)  coordinate[pos="""+ str(pos) +"""] ("""+ to +"""-top) ;
-\draw [copyconnection]  ("""+of+"""-northeast)
--- node {\copymidarrow}("""+of+"""-top)
--- node {\copymidarrow}("""+to+"""-top)
--- node {\copymidarrow} ("""+to+"""-north);
-"""
-
-def to_end():
-    return r"""
-\end{tikzpicture}
-\end{document}
-"""
-
-def to_generate( arch, pathname="file.tex" ):
-    with open(pathname, "w") as f:
-        for c in arch:
-            print(c)
-            f.write( c )
-
diff --git a/build/lib/build/lib/build/lib/loaders/__init__.py b/build/lib/build/lib/build/lib/loaders/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/loaders/als.py b/build/lib/build/lib/build/lib/loaders/als.py
deleted file mode 100644
index d1b9b0a..0000000
--- a/build/lib/build/lib/build/lib/loaders/als.py
+++ /dev/null
@@ -1,47 +0,0 @@
-import numpy as np
-from ptycho.raw_data import RawData
-
-import pkg_resources
-
-def load_single_object(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects. We ASSUME we're processing
-    a single object. The first train_size samples will be used for training and the entire dataset 
-    will be used for evaluation.
-
-    Args:
-        file_path: Path to the data file.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = data['diffraction']
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                          diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                xcoords_start[:train_size], ycoords_start[:train_size],
-                                diff3d[:train_size], probeGuess,
-                                scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
-
diff --git a/build/lib/build/lib/build/lib/loaders/xpp.py b/build/lib/build/lib/build/lib/loaders/xpp.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/notebooks/dose.py b/build/lib/build/lib/build/lib/notebooks/dose.py
deleted file mode 100644
index f98380e..0000000
--- a/build/lib/build/lib/build/lib/notebooks/dose.py
+++ /dev/null
@@ -1,235 +0,0 @@
-import argparse
-
-def init(nphotons, loss_fn='nll'):
-    from ptycho.params import cfg
-    cfg['positions.provided'] = False
-    cfg['data_source'] = 'lines'
-    cfg['set_phi'] = False
-    cfg['nepochs'] = 60 
-
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 3
-    cfg['output_prefix'] = 'lines3'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-    cfg['probe.trainable'] = False
-
-    cfg['outer_offset_train'] = 8
-    cfg['outer_offset_test'] = 20
-    cfg['nimgs_train'] = 2
-    cfg['nimgs_test'] = 2
-
-    cfg['nphotons'] = nphotons
-
-    if loss_fn == 'mae':
-        cfg['mae_weight'] = 1.
-        cfg['nll_weight'] = 0.
-    elif loss_fn == 'nll':
-        pass  # Keep the current behavior
-    else:
-        raise ValueError(f"Invalid loss_fn: {loss_fn}. Must be 'mae' or 'nll'.")
-
-def plot_results(stitched_obj, YY_ground_truth, d):
-    import matplotlib.pyplot as plt
-    import numpy as np
-
-    fig, axs = plt.subplots(1, 1, figsize=(5, 5))
-
-    # reconstructed amplitude images
-    img1 = axs.imshow(np.absolute(stitched_obj)[0], cmap='jet', interpolation='none')
-    axs.set_title(f'Reconstructed amplitude - FRC50: {d["frc50"][0]:.2f}')
-
-    fig.colorbar(img1, ax=axs)
-
-def execute(nphotons, reload_modules=False):
-    from ptycho.tf_helper import pad
-    from ptycho.evaluation import save_metrics, trim
-    from ptycho.tf_helper import pad
-    from ptycho.params import cfg
-    cfg['nphotons'] = nphotons
-
-    cfg['data_source'] = 'lines'
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 10
-    cfg['output_prefix'] = 'lines2'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-
-    from ptycho import train
-    if reload_modules:
-        reload(train.generate_data)
-        reload(train.train_pinn.model)
-        reload(train.train_pinn)
-        reload(train)
-
-    stitched_obj, YY_ground_truth = train.stitched_obj, train.YY_ground_truth
-
-    from ptycho.train_pinn import train as train_pinn, eval as eval_pinn
-    from ptycho import misc
-
-    plot_results(stitched_obj, YY_ground_truth, train.d)
-    # Corrected the indentation and scope of the return statement
-    return train.d, YY_ground_truth, stitched_obj, train.train_output
-
-def parse_arguments():
-    parser = argparse.ArgumentParser(description='Ptychographic reconstruction script.')
-    parser.add_argument('nphotons', type=float, help='Number of photons')
-    args = parser.parse_args()
-    return args.nphotons
-
-if __name__ == '__main__':
-    nphotons = parse_arguments()
-    init(nphotons)
-
-    d, YY_ground_truth, stitched_obj = execute(nphotons)
-
-from importlib import reload
-def run_experiment_with_photons(photons_list, loss_fn='nll'):
-    print("DEBUG: Starting run_experiment_with_photons")
-    results = {}
-    first_iteration = True
-    for nphotons in photons_list:
-        init(nphotons, loss_fn=loss_fn)
-        print("DEBUG: nphotons set to", nphotons, "in run_experiment_with_photons")
-        if  first_iteration:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=False)
-        else:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=True)
-        first_iteration = False
-        results[nphotons] = {'d': d, 'YY_ground_truth': YY_ground_truth, 'stitched_obj': stitched_obj, 'train_output': train_output}
-    return results
-import os
-import dill
-import pandas as pd
-import numpy as np
-from matplotlib.image import imread
-
-def has_amp_recon(subdir):
-    return os.path.exists(os.path.join(subdir, 'amp_recon.png'))
-
-def load_recent_experiment_data(directory, N):
-    subdirs = [os.path.join(directory, d) for d in os.listdir(directory) if is_valid_run(os.path.join(directory, d)) and has_amp_recon(os.path.join(directory, d))]
-    print(subdirs)
-    recent_subdirs = subdirs[:N]
-    subdirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)
-
-    data = {}
-    for subdir in recent_subdirs:
-        params_path = os.path.join(subdir, 'params.dill')
-        metrics_path = os.path.join(subdir, 'metrics.csv')
-
-        with open(params_path, 'rb') as f:
-            params = dill.load(f)
-        metrics = pd.read_csv(metrics_path)
-
-        nphotons = (np.log10(params['nphotons']))
-        print('NPOHOT {}'.format(nphotons))
-        #if nphotons not in data or os.path.getmtime(params_path) > os.path.getmtime(os.path.join(data[nphotons]['dir'], 'params.dill')):
-        amp_recon_path = os.path.join(subdir, 'amp_recon.png')
-        amp_recon = imread(amp_recon_path)
-        data[nphotons] = {'params': params, 'metrics': metrics, 'amp_recon': amp_recon, 'dir': subdir}
-
-    return {k: {'params': v['params'], 'metrics': v['metrics']} for k, v in data.items()}
-def is_valid_run(subdir):
-    return os.path.exists(os.path.join(subdir, 'params.dill'))
-import matplotlib.pyplot as plt
-
-def generate_and_save_heatmap(experiment_entry, ax=None, photon_dose=None):
-    if ax is None:
-        fig, ax = plt.subplots()
-    stitched_obj = experiment_entry['stitched_obj'][0, :, :, 0]
-    metrics = experiment_entry['d']
-    frc50 = metrics.get('frc50', [None])[0]
-    psnr = metrics.get('psnr', [None])[0]
-
-    ax.imshow(np.abs(stitched_obj), cmap='jet', interpolation='nearest')
-    title = f'FRC50: {frc50:.2f}, PSNR: {psnr:.2f}'
-    if photon_dose is not None:
-        title = f'Photons: {photon_dose:.0e}, ' + title
-    ax.set_title(title)
-    ax.axis('off')
-
-def generate_2x2_heatmap_plots(res, layout=(1, 4), filename='heatmap_plots.png', axs=None,
-                               fig = None):
-#    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 4*layout[0]))
-#    axs = axs.flatten()
-    for i, (photon_dose, experiment_entry) in enumerate(res.items()):
-        generate_and_save_heatmap(experiment_entry, axs[i], photon_dose)
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.close(fig)
-
-def plot_heatmap_from_experiment(res, nphot, index):
-    import matplotlib.pyplot as plt
-    c = res[nphot]['train_output']['dataset']
-    plt.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    #plt.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    plt.title(f'{nphot:.0e} photons', fontsize = 10)
-    plt.savefig(f'heatmap_photon_dose_{nphot:.0e}_index_{index}.png')
-    #plt.show()
-def plot_heatmaps_for_all_photons(res, index):
-    for nphot in res.keys():
-        plot_heatmap_from_experiment(res, nphot, index)
-    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0]))
-
-def generate_2x2_heatmap_plots_using_function(res, index, layout=(1, 4), filename='heatmap_plots_2x2.png', border_color='black', border_width=2, axs=None):
-    a, b = layout
-    #fig, axs = plt.subplots(1, b, figsize=(24, 3))
-    #fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0])) if axs is None else (None, axs)
-    axs = axs.flatten()
-    photon_doses = list(res.keys())[: b]  # Select the first 4 photon doses for the 2x2 grid
-    for i, nphot in enumerate(photon_doses):
-        ax = axs[i]
-        c = res[nphot]['train_output']['dataset']
-        heatmap = ax.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        for spine in ax.spines.values():
-            spine.set_edgecolor(border_color)
-            spine.set_linewidth(border_width)
-        #ax.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        #ax.set_title(f'{nphot:.0e} photons', fontsize=16)
-        ax.axis('off')
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.show()
-
-def stack_and_display_horizontal_plots(res, index, layout=(1, 4), figsize=(24, 8), crop_size=None):
-    from matplotlib import pyplot as plt
-    import numpy as np
-
-    a, b = layout
-    fig, axs = plt.subplots(2, b, figsize=figsize)
-
-    if crop_size is not None:
-        def crop_center(img, cropx, cropy):
-            y, x = img.shape
-            startx = x // 2 - (cropx // 2)
-            starty = y // 2 - (cropy // 2)
-            return img[starty:starty + cropy, startx:startx + cropx]
-
-        cropped_res = {}
-        for dose, entry in res.items():
-            stitched_obj = entry['stitched_obj'][0, :, :, 0]
-            cropped_obj = crop_center(stitched_obj, crop_size, crop_size)
-            padded_obj = np.pad(cropped_obj, ((0, crop_size - cropped_obj.shape[0]), (0, crop_size - cropped_obj.shape[1])), mode='constant')
-            cropped_res[dose] = {'stitched_obj': np.expand_dims(np.expand_dims(padded_obj, axis=0), axis=-1), **{k: v for k, v in entry.items() if k != 'stitched_obj'}}
-
-        generate_2x2_heatmap_plots(cropped_res, layout=layout, axs=axs[0])
-    else:
-        generate_2x2_heatmap_plots(res, layout=layout, axs=axs[0])
-
-    generate_2x2_heatmap_plots_using_function(res, index, layout=layout, axs=axs[1], border_color='black', border_width=2)
-    plt.tight_layout()
-    fig.savefig(f'stacked_dose_progression_index_{index}.png')
-    plt.show()
diff --git a/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py b/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/build/lib/notebooks/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/build/lib/notebooks/train_and_infer.py b/build/lib/build/lib/build/lib/notebooks/train_and_infer.py
deleted file mode 100644
index 6a33f16..0000000
--- a/build/lib/build/lib/build/lib/notebooks/train_and_infer.py
+++ /dev/null
@@ -1,159 +0,0 @@
-import logging
-import sys
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-
-from ptycho.workflows.components import (
-    load_data,
-    run_cdi_example,
-    save_outputs
-)
-from ptycho.config.config import TrainingConfig, InferenceConfig, ModelConfig, update_legacy_dict
-from ptycho import model_manager, params, probe
-from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer, probeshow
-
-# Configure logging
-logging.basicConfig(level=logging.INFO,
-                   format='%(asctime)s - %(levelname)s - %(message)s',
-                   handlers=[
-                       logging.StreamHandler(sys.stdout),
-                       logging.FileHandler('train_and_infer.log')
-                   ])
-logger = logging.getLogger(__name__)
-
-def train_model(config: TrainingConfig):
-    """Train the model using provided configuration."""
-    logger.info("Starting training process...")
-    
-    try:
-        # Load training data
-        ptycho_data = load_data(str(config.train_data_file), n_images=512)
-        
-        # Load test data if provided
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        # Run training
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        
-        # Save model and outputs
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-        
-        return recon_amp, recon_phase, results
-    
-    except Exception as e:
-        logger.error(f"Training failed: {e}")
-        raise
-
-def perform_inference(model: tf.keras.Model, test_data, K: int = 7, nsamples: int = 1):
-    """Perform inference using trained model."""
-    logger.info("Starting inference process...")
-    
-    try:
-        # Set probe guess and random seeds
-        probe.set_probe_guess(None, test_data.probeGuess)
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate test dataset
-        test_dataset = test_data.generate_grouped_data(params.cfg['N'], K=K, nsamples=nsamples)
-        
-        # Create data container
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        
-        # Reassemble position
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-        
-        # Process ePIE results
-        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-    
-    except Exception as e:
-        logger.error(f"Inference failed: {e}")
-        raise
-
-def plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase):
-    """Plot comparison between reconstructed and ePIE results."""
-    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
-    
-    # Plot phases
-    im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    fig.colorbar(im_pinn_phase, ax=axs[0, 0])
-    
-    im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    fig.colorbar(im_epie_phase, ax=axs[0, 1])
-    
-    # Plot amplitudes
-    im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    fig.colorbar(im_pinn_amp, ax=axs[1, 0])
-    
-    im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-    axs[1, 1].set_title('ePIE Amplitude')
-    fig.colorbar(im_epie_amp, ax=axs[1, 1])
-    
-    # Remove ticks
-    for ax in axs.flat:
-        ax.set_xticks([])
-        ax.set_yticks([])
-    
-    plt.tight_layout()
-    return fig
-
-def plot_probe(test_data):
-    """Generate probe visualization."""
-    return probeshow(test_data.probeGuess, test_data)
-
-# Example usage in notebook:
-"""
-# Configuration
-train_config = TrainingConfig(
-    model=ModelConfig(),
-    train_data_file=Path('path/to/train_data.npz'),
-    test_data_file=Path('path/to/test_data.npz'),
-    output_dir=Path('output_directory'),
-    debug=False
-)
-
-# Update global params
-update_legacy_dict(params.cfg, train_config)
-
-# Train model
-recon_amp, recon_phase, results = train_model(train_config)
-
-# Load model for inference
-model, _ = model_manager.ModelManager.load_model(train_config.output_dir)
-
-# Load test data
-test_data = load_data('path/to/test_data.npz')
-
-# Perform inference
-reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-    model, test_data, K=7, nsamples=1
-)
-
-# Plot results
-fig = plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase)
-plt.show()
-
-# Plot probe visualization
-probe_fig = plot_probe(test_data)
-plt.show()
-"""
diff --git a/build/lib/build/lib/build/lib/ptycho/__init__.py b/build/lib/build/lib/build/lib/ptycho/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/__init__.py b/build/lib/build/lib/build/lib/ptycho/autotest/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py b/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py
deleted file mode 100644
index 2d66523..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/configuration.py
+++ /dev/null
@@ -1,13 +0,0 @@
-import os
-
-class Configuration:
-    def __init__(self, debug: bool = False, log_file_prefix: str = "logs"):
-        self.debug = debug
-        self.log_file_prefix = log_file_prefix
-
-    def getDebugFlag(self) -> bool:
-        return self.debug
-
-    def getLogFilePrefix(self) -> str:
-        return self.log_file_prefix
-
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/debug.py b/build/lib/build/lib/build/lib/ptycho/autotest/debug.py
deleted file mode 100644
index a5bf044..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/debug.py
+++ /dev/null
@@ -1,174 +0,0 @@
-from .serializer import Serializer
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-
-# spec
-#    @depends_on(Logger, Configuration, FunctionMapping)
-#    interface Debug {
-#        """
-#        Applies the debugging process to the function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - Configuration must allow debugging.
-#
-#        Postconditions:
-#        - If debugging is allowed by the Configuration:
-#          - Returns a new function that wraps the original function with debugging functionality.
-#          - The returned function, when called, performs two forms of logging:
-#            1. Prints function call and return information to the console, surrounded by XML tags
-#               containing the callable's module path and name. The console log messages are in the
-#               format `<module.function>CALL/RETURN args/result</module.function>`. For all array
-#               or tensor types (i.e., objects with a .shape and/or .dtype attribute), the shapes
-#               and data types are also printed.
-#            2. Serializes function inputs and outputs to a log file using the `logCall` and `logReturn`
-#               methods of the Logger interface. The serialized data can be loaded using the `LoadLog`
-#               method. If serialization fails, the console logging still occurs, but no log file is
-#               generated for that invocation.
-#          - Logs only the first two invocations of the function.
-#        - If debugging is not allowed by the Configuration:
-#          - Returns the original function unchanged, without any debugging functionality.
-#        """
-#        Callable decorate(Callable func);
-#    };
-
-## implementation
-import time
-import os
-import pickle
-import json
-from typing import Callable, Any, List, Union, Optional
-import re
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-class Debug:
-    def __init__(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-
-    def decorate(self, func: Callable) -> Callable:
-        increment_count = make_invocation_counter()
-        if not self.configuration.getDebugFlag():
-            return func
-
-        else:
-            module_path = self.function_mapping.get_module_path(func)
-            function_name = func.__name__
-
-            def wrapper(*args: Any, **kwargs: Any) -> Any:
-                invocation_count = increment_count()
-                if invocation_count > 2:
-                    return func(*args, **kwargs)
-                
-                log_file_path = self.function_mapping.get_log_file_path(func)
-                os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
-
-                try:
-                    serialized_args = self.serializer.serialize(args)
-                    serialized_kwargs = self.serializer.serialize(kwargs)
-                    self.logger.logCall(serialized_args, serialized_kwargs, log_file_path)
-                except ValueError:
-                    pass  # If serialization fails, just proceed with console logging
-
-                console_log_start = f"<{module_path}.{function_name}>CALL"
-                console_log_args = self._formatConsoleLog(args)
-                console_log_kwargs = self._formatConsoleLog(kwargs)
-                print(console_log_start)
-                print(console_log_args)
-                print(console_log_kwargs)
-
-                start_time = time.time()
-
-                result = func(*args, **kwargs)
-                try:
-                    serialized_result = self.serializer.serialize(result)
-                    self.logger.logReturn(serialized_result, time.time() - start_time, log_file_path)
-
-                    console_log_end = f"</{module_path}.{function_name}>RETURN"
-                    console_log_result = self._formatConsoleLog(result)
-                    print(console_log_end + " " + console_log_result)
-
-                except Exception as e:
-                    self.logger.logError(str(e), log_file_path)
-                    print(f"<{module_path}.{function_name}>ERROR {str(e)}")
-                return result
-
-            return wrapper
-
-    def _formatConsoleLog(self, data: Any) -> str:
-        if not isinstance(data, tuple):
-            data = (data,)
-
-        formatted_data = []
-        for item in data:
-            if hasattr(item, 'shape') and hasattr(item, 'dtype'):
-                formatted_data.append(f"type={type(item)}, shape={item.shape}, dtype={item.dtype}")
-            elif isinstance(item, (int, float, str, bool)):
-                formatted_data.append(f"type={type(item)}, {item}")
-            else:
-                formatted_data.append(f"type={type(item)}")
-        return ", ".join(formatted_data)
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-import unittest
-
-class TestDebug(unittest.TestCase):
-    def setUp(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.debug = Debug(self.configuration, self.serializer, self.logger, self.function_mapping)
-
-    def test_decorate_call(self):
-        @self.debug.decorate
-        def add(x, y):
-            return x + y
-
-        result = add(3, 4)
-        self.assertEqual(result, 7)
-
-    def test_decorate_return(self):
-        @self.debug.decorate
-        def multiply(x, y):
-            return x * y
-
-        result = multiply(2, 3)
-        self.assertEqual(result, 6)
-        result = multiply(4, 5)
-        self.assertEqual(result, 20)
-        result = multiply(6, 7)  # This call should not be logged
-        self.assertEqual(result, 42)
-
-    def test_decorate_error(self):
-        @self.debug.decorate
-        def divide(x, y):
-            return x / y
-
-        with self.assertRaises(ZeroDivisionError):
-            divide(1, 0)
-
-#    def test_format_console_log(self):
-#        data = (3, "hello")
-#        formatted_log = self.debug._formatConsoleLog(data)
-#        self.assertEqual(formatted_log, "3, hello")
-
-obj = Debug()
-debug = obj.decorate
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
-
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py b/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py
deleted file mode 100644
index a9be5de..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/functionmapping.py
+++ /dev/null
@@ -1,185 +0,0 @@
-# spec
-#    interface FunctionMapping {
-#        """
-#        Retrieves the log file path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - `log_directory` must be a valid directory path.
-#        - Expected JSON format: { "log_directory": "string" }
-#
-#        Postconditions:
-#        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-#        - If `log_directory` is not provided or is an empty string, returns an empty string.
-#        """
-#        string getLogFilePath(Callable func, string log_directory);
-#
-#        """
-#        Loads a function given its log file path or module path.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid log file path or empty string.
-#        - `module_path` must be a valid module path or empty string.
-#        - Expected JSON format: { "log_file_path": "string", "module_path": "string" }
-#
-#        Postconditions:
-#        - Returns the function object if successfully loaded.
-#        - If the function cannot be found or imported, returns None.
-#        """
-#        Union[Callable, None] loadFunction(string log_file_path, string module_path);
-#
-#        """
-#        Retrieves the module path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#
-#        Postconditions:
-#        - Returns the module path for the given function, formatted as `module.fname`.
-#        - If `func` is a built-in function or does not have a valid module path, returns an empty string.
-#        """
-#        string getModulePath(Callable func);
-#    };
-
-# implementation
-import os
-import shutil
-import importlib
-from typing import Callable, Optional
-
-def dprint(*args):
-    pass
-
-class FunctionMapping:
-    def __init__(self, log_directory: str = "logs"):
-        self.log_directory = log_directory
-
-    def get_log_file_path(self, func: Callable) -> str:
-        """
-        Retrieves the log file path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_log_file_path(sample_function)
-        'test_logs/__main__.sample_function.log'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        log_file_path = f"{self.log_directory}/{module_name}.{func_name}.log"
-        return log_file_path
-
-    def save_function(self, log_file_path: str, func: Callable) -> None:
-        module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-        module = importlib.import_module(module_path)
-        setattr(module, func_name, func)
-
-    def load_function_from_path(self, log_file_path: str) -> Optional[Callable]:
-        try:
-            dprint(f"log_file_path: {log_file_path}")
-            module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-            dprint(f"module_path: {module_path}")
-            dprint(f"func_name: {func_name}")
-            dprint(f"Importing module: {module_path}")
-            module = importlib.import_module(module_path)
-            dprint(f"Imported module: {module}")
-            dprint(f"Retrieving function: {func_name}")
-            func = getattr(module, func_name, None)
-            dprint(f"Retrieved function: {func}")
-            return func
-        except Exception as e:
-            dprint(f"Error loading function: {e}")
-            return None
-
-    def get_module_and_function_from_log_path(self, log_file_path: str) -> tuple:
-        dprint(f"log_file_path: {log_file_path}")
-        log_file_path = log_file_path.replace(f"{self.log_directory}/", "")
-        dprint(f"log_file_path after removing log_directory: {log_file_path}")
-        log_file_path = log_file_path.replace(".log", "")
-        dprint(f"log_file_path after removing .log: {log_file_path}")
-        parts = log_file_path.rsplit(".", 1)
-        print(parts)
-        dprint(f"parts: {parts}")
-        module_path = parts[0]
-        dprint(f"module_path: {module_path}")
-        func_name = parts[1]
-        dprint(f"func_name: {func_name}")
-        return module_path, func_name
-
-    def load_function(self, log_file_path: str) -> Optional[Callable]:
-        """
-        Loads a function given its log file path.
-        
-        Preconditions:
-        - `log_file_path` must be valid.
-        
-        Postconditions:
-        - Returns the function object if successfully loaded.
-        - If the function cannot be found or imported, returns None.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> log_file_path = function_mapping.get_log_file_path(sample_function)
-        >>> loaded_func = function_mapping.load_function(log_file_path)
-        """
-        return self.load_function_from_path(log_file_path)
-
-    def get_module_path(self, func: Callable) -> str:
-        """
-        Retrieves the module path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the module path for the given function, formatted as `module.fname`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_module_path(sample_function)
-        '__main__.sample_function'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        module_path = f"{module_name}.{func_name}"
-        return module_path
-
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-def sample_function():
-    return "sample function executed"
-
-def another_function():
-    return "another function executed"
-
-def test_get_log_file_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_log_file_path(sample_function)
-    assert path == 'test_logs/__main__.sample_function.log', f"Expected 'test_logs/__main__.sample_function.log', got '{path}'"
-
-def test_load_function():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    log_file_path = function_mapping.get_log_file_path(sample_function)
-    
-    loaded_func = function_mapping.load_function(log_file_path=log_file_path)
-    assert loaded_func is not None, "Expected function to be loaded, but got None"
-    assert loaded_func.__name__ == 'sample_function', f"Expected 'sample_function', got '{loaded_func.__name__}'"
-
-def test_get_module_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_module_path(sample_function)
-    assert path == '__main__.sample_function', f"Expected '__main__.sample_function', got '{path}'"
-
-if __name__ == "__main__":
-    test_get_log_file_path()
-    test_load_function()
-    test_get_module_path()
-    print("All tests passed!")
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/logger.py b/build/lib/build/lib/build/lib/ptycho/autotest/logger.py
deleted file mode 100644
index 8def564..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/logger.py
+++ /dev/null
@@ -1,242 +0,0 @@
-from .serializer import Serializer
-# spec
-#    @depends_on(Serializer)
-#    interface Logger {
-#        """
-#        Logs function call details to a specified log file.
-#
-#        Preconditions:
-#        - `args` and `kwargs` are serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized function arguments and keyword arguments are written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logCall(bytes args, bytes kwargs, string log_file_path);
-#
-#        """
-#        Logs function return details to the specified log file.
-#
-#        Preconditions:
-#        - `result` is serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized `result` and `execution_time` are appended to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logReturn(bytes result, float execution_time, string log_file_path);
-#
-#        """
-#        Logs an error message to the specified log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The `error` message is written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logError(string error, string log_file_path);
-#
-#        """
-#        Loads a logged dataset from a log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with read permissions.
-#          The file must contain valid JSON-formatted log entries.
-#
-#        Postconditions:
-#        - Returns a list or tuple containing the logged inputs and output.
-#        - If there is an error during loading, returns an empty list or tuple.
-#        """
-#        Union[list, tuple] loadLog(Configuration configuration);
-#
-#        """
-#        Searches the log directory and returns all valid log file paths.
-#
-#        Preconditions:
-#        - `log_directory` must be a valid directory path with read permissions.
-#
-#        Postconditions:
-#        - Returns a list of valid log file paths adhering to the format ^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.?
-#        - Invalid log file paths are filtered out using the validateLogFilePath method.
-#        - If there are no valid log files or an error occurs during searching, returns an empty list.
-#        """
-#        list[str] searchLogDirectory(string log_directory);
-#
-#        """
-#        Validates a log file path against the expected format.
-#
-#        Preconditions:
-#        - `log_file_path` must be a string representing a file path.
-#
-#        Postconditions:
-#        - Returns True if the `log_file_path` adheres to the format '^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.', False otherwise.
-#        """
-#        bool validateLogFilePath(string log_file_path);
-#    };
-
-import json
-import os
-import sys
-import pickle
-from typing import Any, Union, List
-import re
-
-class Logger:
-    def __init__(self):
-        self.serializer = Serializer()
-
-    def logCall(self, args: bytes, kwargs: bytes, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "args": args.hex(),
-                    "kwargs": kwargs.hex()
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function call: {e}", file=sys.stderr)
-
-    def logReturn(self, result: bytes, execution_time: float, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "result": result.hex(),
-                    "execution_time": execution_time
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function return: {e}", file=sys.stderr)
-
-    def logError(self, error: str, log_file_path: str) -> None:
-        pass
-#        try:
-#            with open(log_file_path, 'a') as log_file:
-#                log_entry = json.dumps({
-#                    "error": error
-#                })
-#                log_file.write(log_entry + "\n")
-#        except Exception as e:
-#            print(f"Error logging error: {e}", file=sys.stderr)
-
-    def loadLog(self, log_file_path: str) -> Union[List, tuple]:
-        logs = []
-        try:
-            with open(log_file_path, 'r') as log_file:
-                for line in log_file:
-                    log_entry = json.loads(line)
-                    if "args" in log_entry:
-                        log_entry["args"] = bytes.fromhex(log_entry["args"])
-                    if "kwargs" in log_entry:
-                        log_entry["kwargs"] = bytes.fromhex(log_entry["kwargs"])
-                    if "result" in log_entry:
-                        log_entry["result"] = bytes.fromhex(log_entry["result"])
-                    logs.append(log_entry)
-        except Exception as e:
-            print(f"Error loading log: {e}", file=sys.stderr)
-        return logs
-
-    def searchLogDirectory(self, log_directory: str) -> List[str]:
-        valid_log_files = []
-        try:
-            for root, _, files in os.walk(log_directory):
-                for file in files:
-                    file_path = os.path.relpath(os.path.join(root, file), start=log_directory)
-                    if self.validateLogFilePath(file_path):
-                        valid_log_files.append(os.path.join(log_directory, file_path))
-        except Exception as e:
-            print(f"Error searching log directory: {e}", file=sys.stderr)
-        return valid_log_files
-
-    def validateLogFilePath(self, log_file_path: str) -> bool:
-        return True
-        pattern = r'^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$'
-        return re.match(pattern, log_file_path) is not None
-
-import unittest
-import tempfile
-
-class TestLogger(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.test_dir = tempfile.TemporaryDirectory()
-        self.test_file = os.path.join(self.test_dir.name, 'test.log')
-        
-    def tearDown(self):
-        self.test_dir.cleanup()
-
-    def test_logCall(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        self.logger.logCall(args, kwargs, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["args"], args.hex())
-            self.assertEqual(log_entry["kwargs"], kwargs.hex())
-
-    def test_logReturn(self):
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["result"], result.hex())
-            self.assertEqual(log_entry["execution_time"], execution_time)
-
-    def test_logError(self):
-        error = "Test error message"
-        self.logger.logError(error, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["error"], error)
-
-    def test_loadLog(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        
-        self.logger.logCall(args, kwargs, self.test_file)
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        logs = self.logger.loadLog(self.test_file)
-        self.assertEqual(len(logs), 2)
-        self.assertEqual(logs[0]["args"], args)
-        self.assertEqual(logs[0]["kwargs"], kwargs)
-        self.assertEqual(logs[1]["result"], result)
-        self.assertEqual(logs[1]["execution_time"], execution_time)
-
-    def test_searchLogDirectory(self):
-        valid_file = os.path.join(self.test_dir.name, 'logs/module.samplefunc.log')
-        invalid_file = os.path.join(self.test_dir.name, 'invalid.log')
-        
-        os.makedirs(os.path.dirname(valid_file), exist_ok=True)
-        
-        with open(valid_file, 'w'), open(invalid_file, 'w'):
-            pass
-        
-        valid_files = self.logger.searchLogDirectory(self.test_dir.name)
-        self.assertIn(valid_file, valid_files)
-        self.assertNotIn(invalid_file, valid_files)
-
-    def test_validateLogFilePath(self):
-        valid_path = 'logs/module.samplefunc.log'
-        invalid_path = 'invalid.log'
-        
-        self.assertTrue(self.logger.validateLogFilePath(valid_path))
-        self.assertFalse(self.logger.validateLogFilePath(invalid_path))
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py b/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py
deleted file mode 100644
index bbf4035..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/serializer.py
+++ /dev/null
@@ -1,92 +0,0 @@
-# spec
-#module DebuggingSystem {
-#
-#    interface Serializer {
-#        """
-#        Serializes Python objects to a binary format using pickle.
-#
-#        Preconditions:
-#        - `input_data` must be a picklable Python object.
-#
-#        Postconditions:
-#        - Returns the serialized binary data of the input object.
-#        - Raises ValueError if the input data is not picklable.
-#        """
-#        bytes serialize(Any input_data);
-#
-#        """
-#        Deserializes Python objects from a binary format using pickle.
-#
-#        Preconditions:
-#        - `serialized_data` must be a valid pickle-serialized binary string.
-#
-#        Postconditions:
-#        - Returns the deserialized Python object.
-#        - Raises ValueError if the binary data could not be deserialized.
-#        """
-#        Any deserialize(bytes serialized_data);
-#    };
-
-import doctest
-import pickle
-from typing import Any, List
-
-class Serializer:
-    def serialize(self, input_data: Any) -> bytes:
-        """
-        Serializes Python objects to a binary format using pickle.
-
-        Preconditions:
-        - `input_data` must be a picklable Python object.
-
-        Postconditions:
-        - Returns the serialized binary data of the input object.
-        - Raises ValueError if the input data is not picklable.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> type(serialized_data)
-        <class 'bytes'>
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.serialize(lambda x: x)  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Input data is not picklable
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.dumps(input_data)
-        except (pickle.PicklingError, AttributeError, TypeError):
-            raise ValueError("Input data is not picklable")
-
-    def deserialize(self, serialized_data: bytes) -> Any:
-        """
-        Deserializes Python objects from a binary format using pickle.
-
-        Preconditions:
-        - `serialized_data` must be a valid pickle-serialized binary string.
-
-        Postconditions:
-        - Returns the deserialized Python object.
-        - Raises ValueError if the binary data could not be deserialized.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.loads(serialized_data)
-        except (pickle.UnpicklingError, EOFError, AttributeError, ImportError, IndexError):
-            raise ValueError("Could not deserialize the binary data")
-doctest.testmod(verbose=True)
-
diff --git a/build/lib/build/lib/build/lib/ptycho/autotest/testing.py b/build/lib/build/lib/build/lib/ptycho/autotest/testing.py
deleted file mode 100644
index 079233e..0000000
--- a/build/lib/build/lib/build/lib/ptycho/autotest/testing.py
+++ /dev/null
@@ -1,163 +0,0 @@
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-import unittest
-from logger import Logger
-from functionmapping import FunctionMapping
-
-from typing import List, Tuple, Any, Optional, Callable, Union
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-    def testCallable(self, log_path_prefix: str, func: Callable) -> bool:
-        print(f"Debug: testCallable called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            for i in range(len(logs) // 2):
-                args = logs[2 * i]['args']
-                kwargs = logs[2 * i]['kwargs']
-                expected_output = logs[2 * i + 1]['result']
-                try:
-                    deserialized_args = self.logger.serializer.deserialize(args)
-                    deserialized_kwargs = self.logger.serializer.deserialize(kwargs)
-                    deserialized_expected_output = self.logger.serializer.deserialize(expected_output)
-                    actual_output = func(*deserialized_args, **deserialized_kwargs)
-                    #print(f"Debug: Actual output: {actual_output}")
-                    if actual_output != deserialized_expected_output:
-                        print("Debug: Test failed")
-                        return False
-                except Exception as e:
-                    print(f"Error testing function: {e}")
-                    return False
-        print("Debug: Test passed")
-        return True
-
-    def createTestCase(self, log_path_prefix: str) -> Union[tuple, None]:
-        print(f"Debug: createTestCase called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            if logs:
-                log = logs[0]
-                inputs = log['args']
-                expected_output = log['result']
-                func = self.function_mapping.load_function(log_file)
-                print(f"Debug: Loaded function: {func}")
-                if func is not None:
-                    return (inputs, expected_output, func)
-        print("Debug: No test case found")
-        return None
-
-    def runTestSuite(self, log_path_prefix: str) -> TestSummary:
-        print(f"Debug: runTestSuite called with log_path_prefix: {log_path_prefix}")
-        summary = TestSummary()
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            test_case = self.createTestCase(log_path_prefix)
-            if test_case is not None:
-                inputs, expected_output, func = test_case
-                if self.testCallable(log_path_prefix, func):
-                    summary.increment_passed()
-                else:
-                    summary.increment_failed()
-            else:
-                summary.increment_skipped()
-        print(f"Debug: Test summary: {summary}")
-        return summary
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-
-def add(x, y):
-    return x + y
-
-def multiply(x, y):
-    return x * y
-
-def divide(x, y):
-    return x / y
-
-class TestTesting(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.testing = Testing(self.logger, self.function_mapping)
-
-    def test_testCallable(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.assertTrue(self.testing.testCallable(log_path_prefix, add))
-
-    def test_createTestCase(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        test_case = self.testing.createTestCase(log_path_prefix)
-        self.assertIsNotNone(test_case)
-        inputs, expected_output, func = test_case
-        self.assertEqual(self.logger.serializer.deserialize(inputs), (3, 4))
-        self.assertEqual(self.logger.serializer.deserialize(expected_output), 7)
-        self.assertEqual(func, add)
-
-    def test_runTestSuite(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.logger.logReturn(log_path_prefix + '/multiply', (3, 4), 12)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        self.function_mapping.save_function(log_path_prefix + '/multiply', multiply)
-        summary = self.testing.runTestSuite(log_path_prefix)
-        self.assertIsInstance(summary, TestSummary)
-        self.assertEqual(summary.passed, 2)
-        self.assertEqual(summary.failed, 0)
-        self.assertEqual(summary.skipped, 0)
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/build/lib/ptycho/baselines.py b/build/lib/build/lib/build/lib/ptycho/baselines.py
deleted file mode 100644
index 7511803..0000000
--- a/build/lib/build/lib/build/lib/ptycho/baselines.py
+++ /dev/null
@@ -1,93 +0,0 @@
-# based on https://github.com/mcherukara/PtychoNN/tree/master/TF2
-# with minor changes to make comparison to PtychoPINN easier
-from .tf_helper import *
-from . import params
-import tensorflow as tf
-import numpy as np
-
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras import Sequential
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-
-tf.keras.backend.clear_session()
-np.random.seed(123)
-
-h,w=params.get('N'), params.get('N')
-nepochs=params.get('nepochs')
-wt_path = 'wts4' #Where to store network weights
-batch_size = 32
-
-n_filters_scale = params.params()['n_filters_scale']
-
-#Keras modules
-from tensorflow.keras.layers import UpSampling2D
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-
-#checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.hdf5' %wt_path,
-#                                            monitor='val_loss', verbose=1, save_best_only=True,
-#                                            save_weights_only=False, mode='auto', period=1)
-
-def build_model(X_train, Y_I_train, Y_phi_train):
-    tf.keras.backend.clear_session()
-    c = X_train.shape[-1]
-    input_img = Input(shape=(h, w, c))
-
-    x = Conv_Pool_block(input_img,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    #Activations are all ReLu
-
-    encoded=x
-
-    #Decoding arm 1
-    x1=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded1 = Conv2D(c, (3, 3), padding='same')(x1)
-
-    #Decoding arm 2
-    x2=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded2 = Conv2D(c, (3, 3), padding='same')(x2)
-    #Put together
-    autoencoder = Model(input_img, [decoded1, decoded2])
-    # Masked MAE creates a more apples-to-apples comparison with the main
-    # model, but it doesn't seem to affect the image quality
-    #autoencoder.compile(optimizer='adam', loss=masked_mae)
-    autoencoder.compile(optimizer='adam', loss='mean_absolute_error')
-    return autoencoder
-
-def train(X_train, Y_I_train, Y_phi_train, autoencoder = None):
-    if autoencoder is None:
-        autoencoder = build_model(X_train, Y_I_train, Y_phi_train)
-
-    print (autoencoder.summary())
-    #plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-
-    #history=autoencoder.fit(X_train * params.params()['intensity_scale'],
-    history=autoencoder.fit(X_train,
-        [Y_I_train, Y_phi_train], shuffle=True,
-        batch_size=batch_size, verbose=1, epochs=nepochs,
-        validation_split = 0.05, callbacks=[reduce_lr, earlystop])
-    return autoencoder, history
diff --git a/build/lib/build/lib/build/lib/ptycho/classes.py b/build/lib/build/lib/build/lib/ptycho/classes.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/config/__init__.py b/build/lib/build/lib/build/lib/ptycho/config/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/config/config.py b/build/lib/build/lib/build/lib/ptycho/config/config.py
deleted file mode 100644
index c49e74c..0000000
--- a/build/lib/build/lib/build/lib/ptycho/config/config.py
+++ /dev/null
@@ -1,149 +0,0 @@
-from dataclasses import dataclass, asdict
-from pathlib import Path
-from typing import Dict, Any, Optional, Literal
-import yaml
-
-@dataclass(frozen=True)
-class ModelConfig:
-    """Core model architecture parameters."""
-    N: Literal[64, 128, 256] = 64
-    gridsize: int = 1
-    n_filters_scale: int = 2
-    model_type: Literal['pinn', 'supervised'] = 'pinn'
-    amp_activation: Literal['sigmoid', 'swish', 'softplus', 'relu'] = 'sigmoid'
-    object_big: bool = True
-    probe_big: bool = True  # Changed default
-    probe_mask: bool = False  # Changed default
-    pad_object: bool = True
-    probe_scale: float = 4.
-    gaussian_smoothing_sigma: float = 0.0
-
-@dataclass(frozen=True)
-class TrainingConfig:
-    """Training specific configuration."""
-    model: ModelConfig
-    train_data_file: Path  # Added
-    test_data_file: Optional[Path] = None  # Added
-    batch_size: int = 16
-    nepochs: int = 50
-    mae_weight: float = 0.0
-    nll_weight: float = 1.0
-    realspace_mae_weight: float = 0.0
-    realspace_weight: float = 0.0
-    nphotons: float = 1e9
-    positions_provided: bool = True  
-    probe_trainable: bool = False
-    intensity_scale_trainable: bool = True  # Changed default
-    output_dir: Path = Path("training_outputs")
-
-@dataclass(frozen=True)
-class InferenceConfig:
-    """Inference specific configuration."""
-    model: ModelConfig
-    model_path: Path
-    test_data_file: Path
-    debug: bool = False
-    output_dir: Path = Path("inference_outputs")
-
-def validate_model_config(config: ModelConfig) -> None:
-    """Validate model configuration."""
-    if config.gridsize <= 0:
-        raise ValueError(f"gridsize must be positive, got {config.gridsize}")
-    if config.n_filters_scale <= 0:
-        raise ValueError(f"n_filters_scale must be positive, got {config.n_filters_scale}")
-    if config.probe_scale <= 0:
-        raise ValueError(f"probe_scale must be positive, got {config.probe_scale}")
-    if config.gaussian_smoothing_sigma < 0:
-        raise ValueError(f"gaussian_smoothing_sigma must be non-negative, got {config.gaussian_smoothing_sigma}")
-
-def validate_training_config(config: TrainingConfig) -> None:
-    """Validate training configuration."""
-    validate_model_config(config.model)
-    if config.batch_size <= 0 or (config.batch_size & (config.batch_size - 1)):
-        raise ValueError(f"batch_size must be positive power of 2, got {config.batch_size}")
-    if config.nepochs <= 0:
-        raise ValueError(f"nepochs must be positive, got {config.nepochs}")
-    if not (0 <= config.mae_weight <= 1):
-        raise ValueError(f"mae_weight must be in [0,1], got {config.mae_weight}")
-    if not (0 <= config.nll_weight <= 1):
-        raise ValueError(f"nll_weight must be in [0,1], got {config.nll_weight}")
-    if config.nphotons <= 0:
-        raise ValueError(f"nphotons must be positive, got {config.nphotons}")
-
-def validate_inference_config(config: InferenceConfig) -> None:
-    """Validate inference configuration."""
-    validate_model_config(config.model)
-    if not config.model_path.exists():
-        raise ValueError(f"model_path does not exist: {config.model_path}")
-
-def load_yaml_config(path: Path) -> Dict[str, Any]:
-    """Load YAML configuration file.
-    
-    Args:
-        path: Path to YAML config file
-        
-    Returns:
-        Dictionary containing configuration values
-        
-    Raises:
-        OSError: If file cannot be read
-        yaml.YAMLError: If YAML is invalid
-    """
-    try:
-        with open(path) as f:
-            return yaml.safe_load(f)
-    except (OSError, yaml.YAMLError) as e:
-        raise type(e)(f"Failed to load config from {path}: {str(e)}")
-
-def dataclass_to_legacy_dict(obj: Any) -> Dict[str, Any]:
-    """Convert dataclass to legacy dictionary format with key mappings.
-    
-    Args:
-        obj: Dataclass instance to convert
-        
-    Returns:
-        Dictionary with legacy parameter names and values
-    """
-    # Key mappings from dataclass field names to legacy param names
-    KEY_MAPPINGS = {
-        'object_big': 'object.big',
-        'probe_big': 'probe.big', 
-        'probe_mask': 'probe.mask',
-        'probe_trainable': 'probe.trainable',
-        'intensity_scale_trainable': 'intensity_scale.trainable',
-        'positions_provided': 'positions.provided',
-        'output_dir': 'output_prefix'
-    }
-
-    # Convert dataclass to dict
-    d = asdict(obj)
-
-    # Handle nested ModelConfig
-    if 'model' in d:
-        model_dict = d.pop('model')
-        d.update(model_dict)
-
-    # Apply key mappings
-    for old_key, new_key in KEY_MAPPINGS.items():
-        if old_key in d:
-            d[new_key] = d.pop(old_key)
-
-    # Convert Path to string
-    if 'output_dir' in d:
-        d['output_prefix'] = str(d.pop('output_dir'))
-
-    return d
-
-def update_legacy_dict(cfg: Dict[str, Any], dataclass_obj: Any) -> None:
-    """Update legacy dictionary with dataclass values.
-    
-    Updates all values from the dataclass, adding new keys if needed.
-    
-    Args:
-        cfg: Legacy dictionary to update
-        dataclass_obj: Dataclass instance containing new values
-    """
-    new_values = dataclass_to_legacy_dict(dataclass_obj)
-    
-    # Update all values from dataclass
-    cfg.update(new_values)
diff --git a/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py b/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py
deleted file mode 100644
index 6a49d58..0000000
--- a/build/lib/build/lib/build/lib/ptycho/data_preprocessing.py
+++ /dev/null
@@ -1,189 +0,0 @@
-from sklearn.utils import shuffle
-import numpy as np
-
-from ptycho import params
-from ptycho import diffsim as datasets
-import tensorflow as tf
-
-from .loader import PtychoDataset, PtychoDataContainer
-from ptycho import loader
-from ptycho import probe
-
-if params.get('outer_offset_train') is None or params.get('outer_offset_test') is None:
-    assert params.get('data_source') == 'generic'
-
-def load_simulated_data(size, probe, outer_offset_train, outer_offset_test, jitter_scale, intensity_scale=None):
-    np.random.seed(1)
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), size, probe, outer_offset_train, jitter_scale=jitter_scale, which = 'train')
-    params.cfg['intensity_scale'] = intensity_scale
-
-    np.random.seed(2)
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, which = 'test')
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_experimental_data(probe, outer_offset_train, outer_offset_test, jitter_scale):
-    from ptycho import experimental
-    YY_I, YY_phi = experimental.get_full_experimental('train')
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), experimental.train_size, probe, outer_offset_train, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    YY_I, YY_phi = experimental.get_full_experimental('test')
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), experimental.test_size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_xpp_data(probeGuess):
-    from ptycho import xpp
-    train_data_container = loader.load(xpp.get_data, probeGuess, which='train')
-    test_data_container = loader.load(xpp.get_data, probeGuess, which='test')
-    return train_data_container, test_data_container
-
-def load_generic_data(probeGuess, N):
-    from ptycho.raw_data import RawData
-    train_data_file_path = params.get('train_data_file_path')
-    test_data_file_path = params.get('test_data_file_path')
-
-    train_raw = RawData.from_file(train_data_file_path)
-    test_raw = RawData.from_file(test_data_file_path)
-
-    dset_train = train_raw.generate_grouped_data(N, K=7, nsamples=1)
-    dset_test = test_raw.generate_grouped_data(N, K=7, nsamples=1)
-
-    train_data_container = loader.load(lambda: dset_train, probeGuess, which=None, create_split=False)
-    test_data_container = loader.load(lambda: dset_test, probeGuess, which=None, create_split=False)
-    return train_data_container, test_data_container
-
-def shuffle_data(X, Y_I, Y_phi, random_state=0):
-    indices = np.arange(len(Y_I))
-    indices_shuffled = shuffle(indices, random_state=random_state)
-
-    X_shuffled = X[indices_shuffled]
-    Y_I_shuffled = Y_I[indices_shuffled]
-    Y_phi_shuffled = Y_phi[indices_shuffled]
-
-    return X_shuffled, Y_I_shuffled, Y_phi_shuffled, indices_shuffled
-
-def get_clipped_object(YY_full, outer_offset):
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-
-    extra_size = (YY_full.shape[1] - (params.cfg['N'] + (params.cfg['gridsize'] - 1) * params.cfg['offset'])) % (outer_offset // 2)
-    if extra_size > 0:
-        YY_ground_truth = YY_full[:, :-extra_size, :-extra_size]
-    else:
-        print('discarding length {} from test image'.format(extra_size))
-        YY_ground_truth = YY_full
-    YY_ground_truth = YY_ground_truth[:, clipleft:-clipright, clipleft:-clipright]
-    return YY_ground_truth
-
-def get_clip_sizes(outer_offset):
-    N = params.cfg['N']
-    gridsize = params.cfg['gridsize']
-    offset = params.cfg['offset']
-    bordersize = (N - outer_offset / 2) / 2
-    borderleft = int(np.ceil(bordersize))
-    borderright = int(np.floor(bordersize))
-    clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-    clipleft = int(np.ceil(clipsize))
-    clipright = int(np.floor(clipsize))
-    return borderleft, borderright, clipleft, clipright
-
-def stitch_data(b, norm_Y_I_test=1, norm=True, part='amp', outer_offset=None, nimgs=None):
-    # channel size must be 1, or not present
-    if b.shape[-1] != 1:
-        assert b.shape[-1] == params.get(['N'])
-    if nimgs is None:
-        nimgs = params.get('nimgs_test')
-    if outer_offset is None:
-        outer_offset = params.get('outer_offset_test')
-    nsegments = int(np.sqrt((int(tf.size(b)) / nimgs) / (params.cfg['N']**2)))
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    else:
-        img_recon = np.reshape((getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    return stitched
-
-def reassemble(b, norm_Y_I = 1., part='amp', **kwargs):
-    stitched = stitch_data(b, norm_Y_I, norm=False, part=part, **kwargs)
-    return stitched
-
-def process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test):
-    X_train, Y_I_train, Y_phi_train, indices_shuffled = shuffle_data(np.array(X_train), np.array(Y_I_train), np.array(Y_phi_train))
-    if params.get('outer_offset_train') is not None:
-        YY_ground_truth_all = get_clipped_object(YY_test_full, outer_offset_test)
-        YY_ground_truth = YY_ground_truth_all[0, ...]
-        print('DEBUG: generating grid-mode ground truth image')
-    else:
-        YY_ground_truth = None
-        print('DEBUG: No ground truth image in non-grid mode')
-    return X_train, Y_I_train, Y_phi_train, YY_ground_truth
-
-def create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                          X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true):
-    return PtychoDataset(
-        PtychoDataContainer(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true, None, None, None, probe.get_probe(params)),
-        PtychoDataContainer(X_test, Y_I_test, Y_phi_test, intensity_scale, YY_test_full, coords_test_nominal, coords_test_true, None, None, None, probe.get_probe(params)),
-    )
-
-def generate_data(probeGuess = None):
-    # TODO handle probeGuess None case
-    data_source = params.params()['data_source']
-    probe_np = probe.get_probe(params)
-    outer_offset_train = params.cfg['outer_offset_train']
-    outer_offset_test = params.cfg['outer_offset_test']
-    YY_test_full = None
-    norm_Y_I_test = None
-
-    if data_source in ['lines', 'grf', 'points', 'testimg', 'diagonals', 'V']:
-        size = params.cfg['size']
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_simulated_data(size, probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'experimental':
-        # Ensure nimgs parameters are 1 for experimental data
-        assert params.get('nimgs_train') == 1, "nimgs_train must be 1 for experimental data"
-        assert params.get('nimgs_test') == 1, "nimgs_test must be 1 for experimental data"
-        
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_experimental_data(probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'xpp':
-        test_data_container, train_data_container = load_xpp_data(probeGuess)
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        YY_test_full = None
-    elif data_source == 'generic':
-        train_data_container, test_data_container = load_generic_data(probeGuess, params.cfg['N'])
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        print('INFO: train data:')
-        print(train_data_container)
-        print('INFO: test data:')
-        print(test_data_container)
-    else:
-        raise ValueError("Invalid data source")
-
-    params.cfg['intensity_scale'] = intensity_scale
-    return ptycho_dataset.train_data.X, ptycho_dataset.train_data.Y_I, ptycho_dataset.train_data.Y_phi, ptycho_dataset.test_data.X, ptycho_dataset.test_data.Y_I, ptycho_dataset.test_data.Y_phi, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/__init__.py b/build/lib/build/lib/build/lib/ptycho/datagen/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py b/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py
deleted file mode 100644
index 1c4bac9..0000000
--- a/build/lib/build/lib/build/lib/ptycho/datagen/diagonals.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import numpy as np
-
-def draw_lines(shape, num):
-    num_vertical = num_horizontal = num_diagonal = num
-    # Create a 2D NumPy array with zeros
-    arr = np.zeros(shape)
-    n, m = shape
-
-    # Draw vertical lines
-    for i in range(num_vertical):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        arr[:, x] = 1
-
-    # Draw horizontal lines
-    for i in range(num_horizontal):
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        arr[y, :] = 1
-
-    # Draw diagonal lines
-    for i in range(num_diagonal):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        off = min(x, y)
-        x = x - off
-        y = y - off
-        ix = np.arange(x, n - y)
-        iy = np.arange(y, m - x)
-        arr[ix, iy] = 1
-        arr[ix, -iy] = 1
-
-    return arr
-
-
-from scipy.ndimage import gaussian_filter as gf
-def mk_diags(N, sigma = .75):
-    img = draw_lines((N, N), 40)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/grf.py b/build/lib/build/lib/build/lib/ptycho/datagen/grf.py
deleted file mode 100644
index 8ab01fd..0000000
--- a/build/lib/build/lib/build/lib/ptycho/datagen/grf.py
+++ /dev/null
@@ -1,73 +0,0 @@
-# credit https://github.com/PabloVD/MapGenerator
-
-import matplotlib.pyplot as plt
-import numpy as np
-import powerbox as pbox
-from scipy import interpolate, ndimage
-
-#--- Parameters for GRF---#
-
-
-# Number of bins per dimension
-boxsize = 100#(max(xx.shape) + 1) // 2#xx.shape[0] // 2
-# Number of bins per dimension in the high resolution  box
-
-# Define power spectrum as a power law with an spectral index indexlaw
-# With lower the spectral indexes, small structures are removed
-def powerspec(k,indexlaw):
-    return k**indexlaw
-
-# Filter the field with a gaussian window
-def smooth_field(field,sigmagauss,gridsize=boxsize):
-
-    x, y = np.linspace(0,field.shape[0],num=field.shape[0]), np.linspace(0,field.shape[1],num=field.shape[1])
-
-    # Interpolation
-    f = interpolate.interp2d(x,y,field,kind="linear")
-
-    qx = np.linspace(x[0],x[-1], num = gridsize)
-    qy = np.linspace(y[0],y[-1], num = gridsize)
-
-    # Filtering
-    smooth = ndimage.filters.gaussian_filter(f(qx,qy),sigmagauss)
-    return smooth
-
-# Remove regions below sea level
-def mainland(field,threshold):
-    for i, row in enumerate(field):
-        for j, el in enumerate(row):
-            if el<threshold:   field[i,j]=0.
-    return field
-
-# Normalize the values of the field between 0 and 1
-def normalize_field(field):
-    min, max = np.amin(field), np.amax(field)
-    newfield = (field-min)/(max-min)
-    return newfield
-
-# Generate a map of islands applying different processes:
-# 1. Generate a random gaussian field given a power spectrum
-# 2. Normalize the field between 0 and 1
-# 3. Smooth the field with a gaussian filter
-# 4. Retain only the mainland above a certain threshold
-def generate_map(indexlaw,sigma,threshold, boxsize):
-    # Number of bins per dimension in the high resolution  box
-    highboxsize = 2*boxsize
-    field = pbox.powerbox.PowerBox(boxsize, lambda k: powerspec(k,indexlaw), dim=2, boxlength=100.).delta_x()
-    field = normalize_field(field)
-    field = smooth_field(field,sigma,gridsize=highboxsize)
-    return field
-
-def mk_grf(N):
-    assert not N % 2
-    boxsize = N // 2
-    # Threshold for the sea level
-    threshold = 0.4
-    # Sigma for the gaussian smoothing
-    sigma = 1
-    # Spectral index for the power spectrum
-    indexlaw = -.4
-    res = np.zeros((N, N, 1))
-    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-    return res
-
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/points.py b/build/lib/build/lib/build/lib/ptycho/datagen/points.py
deleted file mode 100644
index eb415e4..0000000
--- a/build/lib/build/lib/build/lib/ptycho/datagen/points.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def randones(N, pct = .1):
-    """
-    Return array whose entries are randomly either 0 or 1.
-    """
-    rows, cols = N, N
-
-    # define the percentage of entries to increment
-    pct = 0.1
-
-    # create a 2D numpy array of all 0s
-    arr = np.zeros((rows, cols))
-
-    # determine the number of entries to increment
-    num_entries = int(rows * cols * pct)
-
-    # randomly select indices to increment with replacement
-    indices = np.random.choice(rows * cols, num_entries)
-
-    # increment the values at the selected indices by 1
-    np.add.at(arr, np.unravel_index(indices, (rows, cols)), 1)
-
-    # print the resulting array
-    return arr
-
-
-def mk_points(N, sigma = 1, pct = .15):
-    img = randones(N, pct = pct)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py b/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py
deleted file mode 100644
index 5f49b13..0000000
--- a/build/lib/build/lib/build/lib/ptycho/datagen/testimg.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-import os
-from scipy import misc
-from imageio import imread
-from ptycho import tf_helper as hh
-from ptycho import params
-import tensorflow as tf
-
-def first_and_last(it):
-    it = iter(it)  # Ensure it's an iterator
-    try:
-        first = next(it)  # Get the first item
-    except StopIteration:
-        return  # If the iterator is empty, return an empty iterator
-    last = None
-    for last in it:  # Traverse the rest of the iterator to find the last item
-        pass
-    if last is None:
-        yield first
-    else:
-        yield first
-        yield last
-
-path = './'
-image = imread(os.path.join(path,'williamson.jpeg')).astype(float)
-image /= image.mean()
-image = image[None, 100:, :, :1]
-
-N = params.get('size')
-imgs = hh.extract_patches(image, N, N)
-imgs = tf.reshape(imgs, (-1,) + (N, N))
-
-# Convert TensorFlow tensor to NumPy array for reversible operations
-imgs_np = imgs.numpy()
-rev = imgs_np[::-1]  # Reversing using NumPy slicing
-
-# Convert back to TensorFlow tensor if needed
-rev_tensor = tf.convert_to_tensor(rev, dtype=tf.float32)
-it = iter(imgs_np)  # Iterator for original order
-rev_it = iter(rev_tensor)  # Iterator for reversed order
-
-def get_block(reverse = False):
-    if reverse:
-        return np.array(next(rev_it))
-    return np.array(next(it))
-
-def get_img(N = None, sigma = .5, reverse = False):
-    img = get_block(reverse = reverse)
-    # Anti-aliasing
-    img = gf(img, sigma)
-    img = img[:, :, None]
-    return img
-
diff --git a/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py b/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py
deleted file mode 100644
index 5676c59..0000000
--- a/build/lib/build/lib/build/lib/ptycho/datagen/vendetta.py
+++ /dev/null
@@ -1,78 +0,0 @@
-import numpy as np
-import scipy.ndimage
-import matplotlib.pyplot as plt
-
-from scipy.ndimage import zoom
-import numpy as np
-
-from PIL import Image, ImageDraw, ImageFont
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def letter_to_array(letter, font_path, font_size, image_size):
-    # Create a blank image
-    img = Image.new('L', image_size, 255)  # 'L' stands for 8-bit pixels, black and white
-
-    # Get drawing context
-    d = ImageDraw.Draw(img)
-
-    # Define font
-    font = ImageFont.truetype(font_path, font_size)
-
-    # Get text width and height
-    text_width, text_height = d.textsize(letter, font=font)
-
-    # Calculate X, Y position of the text
-    x = (image_size[0] - text_width) / 2
-    y = (image_size[1] - text_height) / 2
-
-    # Draw the text onto the image
-    d.text((x, y), letter, font=font, fill=(0))
-
-    # Convert the image data to a numpy array
-    data = np.array(img)
-
-    # Convert to binary (0 and 1)
-    binary_data = np.where(data < 128, 1, 0)
-
-    return binary_data
-
-# Use a font available on your system (this path is for demonstration; adjust accordingly)
-font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
-sprite = letter_to_array('V', font_path, font_size=50, image_size=(60, 60))
-
-def create_canvas(size):
-    return np.zeros((size, size))
-
-def create_sprite():
-    return sprite
-
-def add_sprite_to_canvas(canvas, sprite, repetitions):
-    for _ in range(repetitions):
-        scale = 0.05 + .4 * np.random.rand()
-        scaled_sprite = scipy.ndimage.zoom(sprite, scale)
-
-        tx = np.random.randint(0, canvas.shape[0] - scaled_sprite.shape[0])
-        ty = np.random.randint(0, canvas.shape[1] - scaled_sprite.shape[1])
-
-        x_end = min(tx + scaled_sprite.shape[0], canvas.shape[0])
-        y_end = min(ty + scaled_sprite.shape[1], canvas.shape[1])
-
-        canvas[tx:x_end, ty:y_end] += scaled_sprite[:x_end-tx, :y_end-ty]
-
-#def visualize_canvas(canvas):
-#    plt.imshow(canvas, cmap='gray')
-#    plt.show()
-
-def mk_vs(N, nfeats = 1000):
-    from . import fourier as f
-    assert not N % 2
-    canvas = create_canvas(N)
-    sprite = create_sprite()
-    add_sprite_to_canvas(canvas, sprite, nfeats)
-    res = canvas[..., None]
-    res = f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-    return res / res.max()
-#    res = np.zeros((N, N, 1))
-#    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-#    return res
diff --git a/build/lib/build/lib/build/lib/ptycho/diffsim.py b/build/lib/build/lib/build/lib/ptycho/diffsim.py
deleted file mode 100644
index be005a6..0000000
--- a/build/lib/build/lib/build/lib/ptycho/diffsim.py
+++ /dev/null
@@ -1,234 +0,0 @@
-from skimage import draw, morphology
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import matplotlib.pyplot as plt
-import numpy as np
-import tensorflow as tf
-
-from . import fourier as f
-from . import tf_helper as hh
-from . import params as p
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-
-N = 64
-
-def observe_amplitude(amplitude):
-    """
-    Sample photons from wave amplitudes by drwaing from the corresponding Poisson distributions
-    """
-    return tf.sqrt((hh.tfd.Independent(hh.tfd.Poisson(amplitude**2))).sample())# + 0.5
-
-def count_photons(obj):
-    return tf.math.reduce_sum(obj**2, (1, 2))
-
-def scale_nphotons(padded_obj):
-    """
-    Calculate the object amplitude normalization factor that gives the desired
-    *expected* number of observed photons, averaged over an entire dataset.
-
-    Returns a single scalar.
-    """
-    mean_photons = tf.math.reduce_mean(count_photons(padded_obj))
-    norm = tf.math.sqrt(p.get('nphotons') / mean_photons)
-    return norm
-
-def diffract_obj(sample, draw_poisson = True):
-    N = p.get('N')
-    amplitude = hh.pad_and_diffract(sample, N, N, pad=False)[1]
-    if draw_poisson:
-        observed_amp = observe_amplitude(amplitude)
-        return observed_amp
-    else:
-        return amplitude
-
-def illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = None):
-    """
-    Illuminate object with real or complex probe, then apply diffraction map.
-
-    Returned Y_I and Y_phi are amplitude and phase *after* illumination with the
-    probe.
-    """
-    # ensure probe is broadcastable
-    if len(probe.shape) == 2:
-        assert probe.shape[0] == probe.shape[1]
-        probe = probe[..., None]
-    elif len(probe.shape) == 3:
-        assert probe.shape[-1] == 1
-    if intensity_scale is None:
-        probe_amplitude = tf.cast(tf.abs(probe), Y_I.dtype)
-        intensity_scale = scale_nphotons(Y_I * probe_amplitude[None, ...]).numpy()
-    batch_size = p.get('batch_size')
-    obj = intensity_scale * hh.combine_complex(Y_I, Y_phi)
-    obj = obj * tf.cast(probe[None, ...], obj.dtype)
-    Y_I = tf.math.abs(obj)
-
-    X = (tf.data.Dataset.from_tensor_slices(obj)
-               .batch(batch_size)
-               .prefetch(tf.data.AUTOTUNE)
-               .map(diffract_obj)
-               .cache())
-    X = np.vstack(list(iter(X)))
-    X, Y_I, Y_phi =\
-        X / intensity_scale, Y_I / intensity_scale, Y_phi
-
-    X, Y_I, Y_phi =\
-        hh.togrid(X, Y_I, Y_phi)
-
-    X, Y_I, Y_phi =\
-        hh.grid_to_channel(X, Y_I, Y_phi)
-
-    return X, Y_I, Y_phi, intensity_scale
-
-def mk_rand(N):
-    return int(N * np.random.uniform())
-
-def mk_lines_img(N = 64, nlines = 10):
-    image = np.zeros((N, N))
-    for _ in range(nlines):
-        rr, cc = draw.line(mk_rand(N), mk_rand(N), mk_rand(N), mk_rand(N))
-        image[rr, cc] = 1
-    res = np.zeros((N, N, 3))
-    res[:, :, :] = image[..., None]
-    return f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-
-def mk_noise(N = 64, nlines = 10):
-    return np.random.uniform(size = N * N).reshape((N, N, 1))
-
-from ptycho.misc import memoize_disk_and_memory
-
-def extract_coords(size, repeats = 1, coord_type = 'offsets',
-        outer_offset = None, **kwargs):
-    """
-    Return nominal offset coords in channel format. x and y offsets are
-    stacked in the third dimension.
-
-    offset coordinates are r - r', where
-        r' is the patch center of mass
-        r is the center of mass of that patch's solution region / grid,
-            which contains gridsize**2 patches
-    """
-    x = tf.range(size, dtype = tf.float32)
-    y = tf.range(size, dtype = tf.float32)
-    xx, yy = tf.meshgrid(x, y)
-    xx = xx[None, ..., None]
-    yy = yy[None, ..., None]
-    def _extract_coords(zz, fn):
-        ix = fn(zz)
-        ix = tf.reduce_mean(ix, axis = (1, 2))
-        return tf.repeat(ix, repeats, axis = 0)[:, None, None, :]
-    def outer(img):
-        return hh.extract_outer(img, fmt = 'grid', outer_offset = outer_offset)
-    def inner(img):
-        return hh.extract_nested_patches(img, fmt = 'channel',
-            outer_offset = outer_offset)
-    def get_patch_offsets(coords):
-        offsets_x = coords[1][0] - coords[0][0]
-        offsets_y = coords[1][1] - coords[0][1]
-        return tf.stack([offsets_x, offsets_y], axis = 2)[:, :, :, 0, :]
-    ix = _extract_coords(xx, inner)
-    iy = _extract_coords(yy, inner)
-    ix_offsets = _extract_coords(xx, outer)
-    iy_offsets = _extract_coords(yy, outer)
-    coords = ((ix, iy), (ix_offsets, iy_offsets))
-    if coord_type == 'offsets':
-        return get_patch_offsets(coords)
-    elif coord_type == 'global':
-        return (ix, iy)
-    else:
-        raise ValueError
-
-def add_position_jitter(coords, jitter_scale):
-    shape = coords.shape
-    jitter = jitter_scale * tf.random.normal(shape)
-    return jitter + coords
-
-def scan_and_normalize(jitter_scale = None, YY_I = None, YY_phi = None,
-        **kwargs):
-    """
-    Inputs:
-    4d tensors of full (arbitrary-sized) object phase and amplitude.
-
-    Returns (normalized) amplitude and phase and scan point offsets.
-
-    coords: tuple of two tuples. First gives center coords for each
-    small image patch. Second gives offset coords for each solution
-    region.
-    """
-    size = YY_I.shape[1]
-    n = YY_I.shape[0]
-    coords = true_coords = extract_coords(size, n, **kwargs)
-    if jitter_scale is not None:
-        print('simulating gaussian position jitter, scale', jitter_scale)
-        true_coords = add_position_jitter(coords, jitter_scale)
-
-    Y_I, Y_phi, _Y_I_full, norm_Y_I = hh.preprocess_objects(YY_I,
-        offsets_xy = true_coords, Y_phi = YY_phi, **kwargs)
-    return Y_I, Y_phi, _Y_I_full, norm_Y_I, (coords, true_coords)
-
-import math
-def dummy_phi(Y_I):
-    return tf.cast(tf.constant(math.pi), tf.float32) *\
-        tf.cast(tf.math.tanh( (Y_I - tf.math.reduce_max(Y_I) / 2) /
-            (3 * tf.math.reduce_mean(Y_I))), tf.float32)
-
-def sim_object_image(size, which = 'train'):
-    if p.get('data_source') == 'lines':
-        return mk_lines_img(2 * size, nlines = 400)[size // 2: -size // 2, size // 2: -size // 2, :1]
-    elif p.get('data_source') == 'grf':
-        from .datagen import grf
-        return grf.mk_grf(size)
-    elif p.get('data_source') == 'points':
-        from .datagen import points
-        return points.mk_points(size)
-    elif p.get('data_source') == 'testimg':
-        from .datagen import testimg
-        if which == 'train':
-            return testimg.get_img(size)
-        elif which == 'test':
-            return testimg.get_img(size, reverse = True)
-        else:
-            raise ValueError
-    elif p.get('data_source') == 'testimg_reverse':
-        from .datagen import testimg
-        return testimg.get_img(size, reverse = True)
-    elif p.get('data_source') == 'diagonals':
-        from .datagen import diagonals
-        return diagonals.mk_diags(size)
-    elif p.get('data_source') == 'V':
-        from .datagen import vendetta
-        return vendetta.mk_vs(size)
-    else:
-        raise ValueError
-
-@memoize_disk_and_memory
-def mk_simdata(n, size, probe, outer_offset, intensity_scale = None,
-        YY_I = None, YY_phi = None, dict_fmt = False,  which = 'train', **kwargs):
-    if YY_I is None:
-        YY_I = np.array([sim_object_image(size, which = which)
-              for _ in range(n)])
-    if p.get('set_phi') and YY_phi is None:
-        YY_phi = dummy_phi(YY_I)
-    Y_I, Y_phi, _, norm_Y_I, coords = scan_and_normalize(YY_I = YY_I,
-        YY_phi = YY_phi, outer_offset = outer_offset, **kwargs)
-    if dict_fmt:
-        d = dict()
-        d['I_pre_probe'] = Y_I
-        d['phi_pre_probe'] = Y_phi
-    X, Y_I, Y_phi, intensity_scale =\
-        illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = intensity_scale)
-    if YY_phi is None:
-        YY_full = hh.combine_complex(YY_I, tf.zeros_like(YY_I))
-    else:
-        YY_full = hh.combine_complex(YY_I, YY_phi)
-    if dict_fmt:
-        d['X'] = X
-        d['Y_I'] = Y_I
-        d['Y_phi'] = Y_phi
-        d['intensity_scale'] = intensity_scale
-        d['norm_Y_I'] = norm_Y_I
-        d['coords'] = coords
-        return d
-    return X, Y_I, Y_phi, intensity_scale, YY_full,\
-        norm_Y_I, coords
diff --git a/build/lib/build/lib/build/lib/ptycho/evaluation.py b/build/lib/build/lib/build/lib/ptycho/evaluation.py
deleted file mode 100644
index 51274e4..0000000
--- a/build/lib/build/lib/build/lib/ptycho/evaluation.py
+++ /dev/null
@@ -1,275 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib
-import tensorflow as tf
-
-from ptycho import params
-from ptycho import misc
-
-def recon_patches(patches):
-    """
-    chop channel dimension size to 1, then patch together a single image
-    """
-    from ptycho import generate_data as data
-    return data.reassemble(patches[:, :, :, :1])[0]
-
-def symmetrize(arr):
-    return (arr + arr[::-1, ::-1]) / 2
-
-def symmetrize_3d(arr):
-    return (arr + arr[:, ::-1, ::-1]) / 2
-
-def cropshow(arr, *args, crop = True, **kwargs):
-    if crop:
-        arr = arr[16:-16, 16:-16]
-    plt.imshow(arr, *args, **kwargs)
-
-from scipy.ndimage import gaussian_filter as gf
-
-def summarize(i, a, b, X_test, Y_I_test, Y_phi_test, probe, channel = 0, **kwargs):
-    from . import params as cfg
-    plt.rcParams["figure.figsize"] = (10, 10)
-    vmin = 0
-    vmax = np.absolute(b)[i].max()
-
-    heatmaps = {}  # initialize the dictionary to store the heatmaps
-    probe = np.absolute(probe)
-    aa, bb = 3, 3
-    plt.subplot(aa, bb, 1)
-    plt.title('True amp.\n(illuminated)')
-    true_amp_illuminated = (Y_I_test[i, :, :, channel])
-    cropshow(true_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_illuminated'] = true_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 2)
-    plt.title('Reconstructed amp.\n(illuminated)')
-    rec_amp_illuminated = (np.absolute(b))[i] * probe[..., None]
-    cropshow(rec_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_illuminated'] = rec_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 3)
-    plt.title('True phase')
-    true_phase = ((Y_phi_test * (probe > .01)[..., None]))[i, :, :, channel]
-    cropshow(true_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['true_phase'] = true_phase  # add to the dictionary
-
-    plt.subplot(aa, bb, 4)
-    plt.title('True amp.\n(full)')
-    true_amp_full = (Y_I_test[i, :, :, channel] / (probe + 1e-9))
-    cropshow(true_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_full'] = true_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 5)
-    plt.title('Reconstructed amp. (full)')
-    rec_amp_full = (np.absolute(b))[i]
-    cropshow(rec_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_full'] = rec_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 6)
-    plt.title('Reconstructed phase')
-    rec_phase = (np.angle(b) * (probe > .01)[..., None])[i]
-    rec_phase[np.isclose(rec_phase,  0)] = np.nan
-    cropshow(rec_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['rec_phase'] = rec_phase  # add to the dictionary
-    print('phase min:', np.min((np.angle(b) * (probe > .01)[..., None])),
-        'phase max:', np.max((np.angle(b) * (probe > .01)[..., None])))
-
-    plt.subplot(aa, bb, 7)
-    plt.title('True diffraction')
-    true_diffraction = np.log(cfg.get('intensity_scale') * X_test)[i, :, :, channel]
-    plt.imshow(true_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['true_diffraction'] = true_diffraction  # add to the dictionary
-
-    plt.subplot(aa, bb, 8)
-    plt.title('Recon diffraction')
-    rec_diffraction = np.log(a)[i, :, :, channel]
-    plt.imshow(rec_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['rec_diffraction'] = rec_diffraction  # add to the dictionary
-
-    return heatmaps
-
-def plt_metrics(history, loss_type = 'MAE', metric2 = 'padded_obj_loss'):
-    hist=history
-    epochs=np.asarray(history.epoch)+1
-
-    plt.style.use('seaborn-white')
-    matplotlib.rc('font',family='Times New Roman')
-    matplotlib.rcParams['font.size'] = 12
-
-    f, axarr = plt.subplots(2, sharex=True, figsize=(12, 8))
-
-    axarr[0].set(ylabel='Loss')
-    axarr[0].plot(epochs,hist.history['loss'], 'C3o', label='Diffraction {} Training'.format(loss_type))
-    axarr[0].plot(epochs,hist.history['val_loss'], 'C3-', label='Diffraction {} Validation'.format(loss_type))
-    axarr[0].grid()
-    axarr[0].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-
-    axarr[1].set(ylabel='Loss')
-    axarr[1].plot(epochs,hist.history[metric2], 'C0o', label='Object {} Training'.format(loss_type))
-    axarr[1].plot(epochs,hist.history['val_' + metric2], 'C0-', label='Object {} Validation'.format(loss_type))
-    axarr[1].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-    plt.xlabel('Epochs')
-    plt.tight_layout()
-    #plt.semilogy()
-    axarr[1].grid()
-
-import scipy.fftpack as fftpack
-fp = fftpack
-
-def trim(arr2d):
-    offset = params.get('offset')
-    assert not (offset % 2)
-    return arr2d[offset // 2:-offset // 2, offset // 2:-offset // 2]
-
-def mae(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean(np.absolute(target - scale * pred))
-
-def mse(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean((target - scale * pred)**2)
-
-def psnr(target, pred, normalize = True, shift = False):
-    """
-    for phase inputs, assume that global shift has already been taken care off
-    """
-    import cv2
-    target = np.array(target)
-    pred = np.array(pred)
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    if shift:
-        offset = min(np.min(target), np.min(pred))
-        target = target - offset
-        pred = pred - offset
-    pred = scale * pred
-    return cv2.PSNR(target, pred)
-
-def fft2d(aphi):
-    F1 = fftpack.fft2((aphi).astype(float))
-    F2 = fftpack.fftshift(F1)
-    return F2
-
-def highpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-
-    F2[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 0
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def lowpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-    mask = np.zeros_like(F2)
-    mask[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 1.
-    F2 = F2 * mask
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def frc50(target, pred, sigma = 1):
-    if np.isnan(pred).all():
-        raise ValueError
-    if np.max(target) == np.min(target) == 0:
-        return None, np.nan
-    from FRC import fourier_ring_corr as frc
-    shellcorr = frc.FSC(np.array(target), np.array(pred))
-    shellcorr = gf(shellcorr, sigma)
-    return shellcorr, np.where(shellcorr < .5)[0][0]
-
-
-
-def eval_reconstruction(stitched_obj, ground_truth_obj, lowpass_n = 1,
-        label = ''):
-    # TODO consistent shapes
-    assert stitched_obj.shape[1] == ground_truth_obj.shape[1]
-    assert np.ndim(ground_truth_obj) == 3
-    assert int(np.ndim(stitched_obj)) in [3, 4]
-    if np.ndim(stitched_obj) == 4:
-        stitched_obj = stitched_obj[0]
-    YY_ground_truth = np.absolute(ground_truth_obj)
-    YY_phi_ground_truth = np.angle(ground_truth_obj)
-
-    phi_pred = trim(
-        highpass2d(
-            np.squeeze(np.angle(stitched_obj)), n = lowpass_n
-        )
-    )
-    phi_target = trim(
-        highpass2d(
-            np.squeeze(YY_phi_ground_truth), n = lowpass_n
-        )
-    )
-    amp_target = tf.cast(trim(YY_ground_truth), tf.float32)
-    amp_pred = trim(np.absolute(stitched_obj))
-
-    # TODO complex FRC?
-    mae_amp = mae(amp_target, amp_pred) # PINN
-    mse_amp = mse(amp_target, amp_pred) # PINN
-    psnr_amp = psnr(amp_target[:, :, 0], amp_pred[:, :, 0], normalize = True,
-        shift = False)
-    frc_amp, frc50_amp = frc50(amp_target[:, :, 0], amp_pred[:, :, 0])
-
-    mae_phi = mae(phi_target, phi_pred, normalize=False) # PINN
-    mse_phi = mse(phi_target, phi_pred, normalize=False) # PINN
-    psnr_phi = psnr(phi_target, phi_pred, normalize = False, shift = True)
-    frc_phi, frc50_phi = frc50(phi_target, phi_pred)
-
-    return {'mae': (mae_amp, mae_phi),
-        'mse': (mse_amp, mse_phi),
-        'psnr': (psnr_amp, psnr_phi),
-        'frc50': (frc50_amp, frc50_phi),
-        'frc': (frc_amp, frc_phi)}
-
-
-import pandas as pd
-import os
-import dill
-def save_metrics(stitched_obj, YY_ground_truth,  label = ''):
-    """
-    evaluate reconstruction and save the result to disk.
-    """
-    out_prefix = misc.get_path_prefix()
-    os.makedirs(out_prefix, exist_ok=True)
-    metrics = eval_reconstruction(stitched_obj, YY_ground_truth, label = label)
-    metrics['label'] = label
-    d = {**params.cfg, **metrics}
-    with open(out_prefix + '/params.dill', 'wb') as f:
-        dill.dump(d, f)
-    df = pd.DataFrame({k: d[k] for k in ['mae', 'mse', 'psnr', 'frc50']})
-    df.to_csv(out_prefix + '/metrics.csv')
-    return {k: metrics[k] for k in ['mae', 'mse', 'psnr', 'frc50', 'frc']}
diff --git a/build/lib/build/lib/build/lib/ptycho/experimental.py b/build/lib/build/lib/build/lib/ptycho/experimental.py
deleted file mode 100644
index adbb619..0000000
--- a/build/lib/build/lib/build/lib/ptycho/experimental.py
+++ /dev/null
@@ -1,116 +0,0 @@
-from skimage.transform import resize
-from tqdm.notebook import tqdm as tqdm
-import matplotlib.pyplot as plt
-import numpy as np
-import scipy.signal
-import sys
-
-from . import tf_helper as hh
-
-path = '.'
-
-sys.path.append(path)
-sys.path.append('PtychoNN/TF2/')
-
-N = 64
-### Read experimental diffraction data and reconstructed images
-
-data_diffr = np.load(path+'/PtychoNN/data/20191008_39_diff.npz')['arr_0']
-data_diffr.shape
-
-data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)
-for i in tqdm(range(data_diffr.shape[0])):
-    for j in range(data_diffr.shape[1]):
-        data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)
-        data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])
-
-real_space = np.load(path+'/PtychoNN/data/20191008_39_amp_pha_10nm_full.npy')
-amp = np.abs(real_space)
-ph = np.angle(real_space)
-amp.shape
-
-### Split data and then shuffle
-
-nlines = 100 #How many lines of data to use for training?
-nltest = 60 #How many lines for the test set?
-tst_strt = amp.shape[0]-nltest #Where to index from
-print(tst_strt)
-train_size = 272
-test_size = 248
-
-def stack(a1, a2):
-    return np.array((a1, a2)).reshape((-1, N, N, 1))
-
-def augment_inversion(Y_I_train, Y_phi_train):
-    phi = stack(Y_phi_train, -Y_phi_train)
-    return stack(Y_I_train, Y_I_train[:, ::-1, ::-1, :]), stack(Y_phi_train, -Y_phi_train)
-
-def reconstruct_object(data4d, scan_grid_offset):
-    """
-    Given a 4d object patches, reconstruct the whole object
-    """
-    return hh.extract_patches_inverse(
-       data4d.reshape((data4d.shape[0], data4d.shape[1], -1))[None, ...],
-       N, True, gridsize = data4d.shape[0],
-       offset = scan_grid_offset)
-
-from ptycho.misc import memoize_disk_and_memory
-@memoize_disk_and_memory
-def get_full_experimental(which):
-    """
-    Returns (normalized) amplitude and phase for n generated objects
-    """
-    inverted_patches_I = reconstruct_object(amp, offset_experimental)
-    inverted_patches_phi = reconstruct_object(ph, offset_experimental)
-    print('GROUND TRUTH FULL SHAPE:', inverted_patches_I.shape)
-    if which == 'train':
-        YY_I = inverted_patches_I[:, :train_size, :train_size, :]
-        YY_phi = inverted_patches_phi[:, :train_size, :train_size, :]
-    elif which == 'test':
-        YY_I = inverted_patches_I[:, -test_size:, -test_size:, :]
-        YY_phi = inverted_patches_phi[:, -test_size:, -test_size:, :]
-    else:
-        raise ValueError
-    return YY_I, YY_phi
-
-
-X_train = data_diffr_red[:nlines,:].reshape(-1,N,N)[:,:,:,np.newaxis]
-X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,N,N)[:,:,:,np.newaxis]
-Y_I_train = amp[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_I_test = amp[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_train = ph[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_test = ph[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-
-ntrain = X_train.shape[0]*X_train.shape[1]
-ntest = X_test.shape[0]*X_test.shape[1]
-
-print(X_train.shape, X_test.shape)
-
-
-tmp1, tmp2 = Y_I_train, Y_I_test
-
-img = np.zeros((544, 544), dtype = 'float32')[None, ..., None]
-offset_experimental = 3
-
-## Recover shift between scan points
-def cross_image(im1, im2):
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
-
-cross = cross_image(amp[0, 0], amp[1, 0])
-ref = cross_image(amp[0, 0], amp[0, 0])
-
-cmax = lambda cross: np.array(np.where(cross.ravel()[np.argmax(cross)] == cross))
-
-plt.imshow(cross)
-
-cmax(cross), cmax(cross) - cmax(ref)
diff --git a/build/lib/build/lib/build/lib/ptycho/export.py b/build/lib/build/lib/build/lib/ptycho/export.py
deleted file mode 100644
index ba05094..0000000
--- a/build/lib/build/lib/build/lib/ptycho/export.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import dill
-import matplotlib.pyplot as plt
-import numpy as np
-from ptycho.misc import get_path_prefix
-from ptycho.params import get
-
-def save_recons(model_type, stitched_obj):
-    from ptycho.generate_data import YY_ground_truth
-    from ptycho.evaluation import save_metrics
-    try:
-        out_prefix = get('output_prefix')
-        if YY_ground_truth is not None:
-            plt.imsave(out_prefix + 'amp_orig.png',
-                       np.absolute(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-            plt.imsave(out_prefix + 'phi_orig.png',
-                       np.angle(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-        if stitched_obj is not None:
-            plt.imsave(out_prefix + 'amp_recon.png', np.absolute(stitched_obj[0][:, :, 0]), cmap='jet')
-            plt.imsave(out_prefix + 'phi_recon.png', np.angle(stitched_obj[0][:, :, 0]), cmap='jet')
-
-        with open(out_prefix + '/recon.dill', 'wb') as f:
-            dump_data = {'stitched_obj_amp': np.absolute(stitched_obj[0][:, :, 0] if stitched_obj is not None else np.array([])),
-                         'stitched_obj_phase': np.angle(stitched_obj[0][:, :, 0]) if stitched_obj is not None else np.array([])}
-            if YY_ground_truth is not None:
-                dump_data.update({'YY_ground_truth_amp': np.absolute(YY_ground_truth[:, :, 0]),
-                                  'YY_ground_truth_phi': np.angle(YY_ground_truth[:, :, 0])})
-            dill.dump(dump_data, f)
-        if YY_ground_truth is not None and stitched_obj is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth or stitched_obj is None, metrics cannot be calculated.'}
-
-        if YY_ground_truth is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth is None, metrics cannot be calculated.'}
-        return d
-    except ImportError as e:
-        print('object stitching failed. No images will be saved.')
diff --git a/build/lib/build/lib/build/lib/ptycho/fourier.py b/build/lib/build/lib/build/lib/ptycho/fourier.py
deleted file mode 100644
index 1cf06f5..0000000
--- a/build/lib/build/lib/build/lib/ptycho/fourier.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import pandas as pd
-import numpy as np
-
-from scipy.fft import fft, fftfreq, ifft, fft2, ifft2, ifftshift
-import matplotlib.pyplot as plt
-from scipy.fftpack import fft, fftshift
-from scipy.signal import butter
-from scipy import signal
-from scipy.signal import convolve2d as conv2
-
-from skimage import color, data, restoration
-from scipy.ndimage import gaussian_filter as gf
-
-def plot_df(*args):
-    df = pd.DataFrame([p for p, _ in args]).T
-    df.columns = [l for _, l in args ]
-    return df.plot()
-
-def lowpass_g(size, y, sym = False):
-    from scipy.signal.windows import gaussian
-    L = gaussian(len(y), std = len(y) / (size * np.pi**2), sym = sym)
-    L /= L.max()
-    return L
-
-def highpass_g(size, y):
-    return 1 - lowpass_g(size, y)
-
-def bandpass_g(L, H, y):
-    L = lowpass_g(L, y)
-    H = highpass_g(H, y)
-    return L * H
-
-def clip_high(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    x2[(N - nz) // 2 : (N + nz) // 2] = 0
-    #x2[(-nz) // 2:] = 0
-    return x2
-
-def clip_low(x, frac_zero, invert = False):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    mask = np.ones_like(x)
-    mask[:( nz) // 2 ] = 0
-    mask[(-nz) // 2:] = 0
-    if invert:
-        mask = 1 - mask
-    x2 = x2 * mask
-
-#     x2[:( nz) // 2 ] = 0
-#     x2[(-nz) // 2:] = 0
-    return x2, mask
-
-def clip_low_window(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = np.ones_like(x)
-    x2[:( nz) // 2 ] = 0
-    x2[(-nz) // 2:] = 0
-    return x2
-
-def if_mag(arr, phase = 0, truncate = False, toreal = 'psd', **kwargs):
-    #print("arr shape", arr.shape)
-    #trunc = len(arr) - unpadded_length
-    phase = np.exp(1j * phase)
-    tmp = ifft(arr)
-    if toreal == 'psd':
-        real = np.real(np.sqrt(np.conjugate(tmp) * tmp))
-    elif toreal == 'real':
-        real = np.real(tmp)
-    else:
-        raise ValueError
-    if truncate:
-        raise NotImplementedError
-        #return real[trunc // 2: -trunc // 2]
-    return real
-
-def power(arr):
-    ampsq = arr * np.conjugate(arr)
-    return np.real(ampsq)
-
-def mag(x):
-    return np.sqrt(power(x))
-
-def lorenz(gamma, x, x0):
-    return ( 1. / (np.pi * gamma)) * (gamma**2) / ((x - x0)**2 + gamma**2)
-
diff --git a/build/lib/build/lib/build/lib/ptycho/generate_data.py b/build/lib/build/lib/build/lib/ptycho/generate_data.py
deleted file mode 100644
index 21c4079..0000000
--- a/build/lib/build/lib/build/lib/ptycho/generate_data.py
+++ /dev/null
@@ -1,11 +0,0 @@
-import numpy as np
-from .data_preprocessing import generate_data
-from . import params as p
-
-# TODO passing the probe should be mandatory, to enforce side-effect free behavior.
-def main(probeGuess = None):
-    X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = generate_data(probeGuess)
-    print(np.linalg.norm(ptycho_dataset.train_data.X[0]) / np.linalg.norm(np.abs(ptycho_dataset.train_data.Y[0])))
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
-X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = main(probeGuess = p.get('probe'))
diff --git a/build/lib/build/lib/build/lib/ptycho/image/__init__.py b/build/lib/build/lib/build/lib/ptycho/image/__init__.py
deleted file mode 100644
index 48b86dc..0000000
--- a/build/lib/build/lib/build/lib/ptycho/image/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .stitching import stitch_patches, reassemble_patches
diff --git a/build/lib/build/lib/build/lib/ptycho/image/stitching.py b/build/lib/build/lib/build/lib/ptycho/image/stitching.py
deleted file mode 100644
index 9b26c64..0000000
--- a/build/lib/build/lib/build/lib/ptycho/image/stitching.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, config, *, 
-                  norm_Y_I: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # Get N from config at the start
-    N = config['N']
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        N = config['N']
-        gridsize = config['gridsize']
-        offset = config['offset']
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    outer_offset = config.get('outer_offset_test', config['offset'])
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / config['nimgs_test']) / (config['N']**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-def reassemble_patches(patches, config, *, norm_Y_I=1., part='amp', norm=False):
-    """
-    High-level convenience function for stitching patches using config parameters.
-    
-    Args:
-        patches: Patches to reassemble
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        part: Which part to extract (default: 'amp')
-        norm: Whether to normalize (default: False)
-    """
-    return stitch_patches(
-        patches,
-        config,
-        norm_Y_I=norm_Y_I,
-        norm=norm,
-        part=part
-    )
diff --git a/build/lib/build/lib/build/lib/ptycho/inference.py b/build/lib/build/lib/build/lib/ptycho/inference.py
deleted file mode 100644
index be7ef91..0000000
--- a/build/lib/build/lib/build/lib/ptycho/inference.py
+++ /dev/null
@@ -1,63 +0,0 @@
-from ptycho.model_manager import ModelManager
-from tensorflow.keras.models import Model
-from ptycho import params
-from ptycho.loader import PtychoDataContainer
-import numpy as np
-
-# TODO this module is for inference-only workflows. it needs to be consolidated with train_pinn
-
-def load_pretrained_model(model_path: str) -> Model:
-    """
-    Load a pre-trained model from an H5 file.
-    """
-    model = ModelManager.load_model(model_path)
-    return model
-
-def prepare_data(data_container: PtychoDataContainer) -> tuple:
-    """
-    Prepare data for inference.
-    """
-    from ptycho import model
-    X = data_container.X * model.params()['intensity_scale']
-    coords_nominal = data_container.coords_nominal
-    return X, coords_nominal
-
-def perform_inference(model: Model, X: np.ndarray, coords_nominal: np.ndarray) -> dict:
-    """
-    Perform inference using the pre-trained model and prepared data.
-    """
-    from ptycho import model
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = model.predict([X, coords_nominal])
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi
-    }
-
-def inference_flow(model_path: str, data_container: PtychoDataContainer) -> dict:
-    """
-    The main flow for model inference, integrating the steps.
-    """
-    pre_trained_model = load_pretrained_model(model_path or params.get('h5_path'))
-    X, coords_nominal = prepare_data(data_container)
-    inference_results = perform_inference(pre_trained_model, X, coords_nominal)
-    return inference_results
-
-# Example usage
-# model_path = 'path/to/model.h5'
-# data_container = PtychoDataContainer(...)
-# results = inference_flow(model_path, data_container)
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def reassemble_with_config(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/ptycho/loader.py b/build/lib/build/lib/build/lib/ptycho/loader.py
deleted file mode 100644
index b1421e4..0000000
--- a/build/lib/build/lib/build/lib/ptycho/loader.py
+++ /dev/null
@@ -1,318 +0,0 @@
-"""Generic loader for datasets with non-rectangular scan point patterns."""
-
-import numpy as np
-import tensorflow as tf
-from typing import Callable
-
-from .params import params, get
-from .autotest.debug import debug
-from . import diffsim as datasets
-from . import tf_helper as hh
-from .raw_data import RawData, key_coords_offsets, key_coords_relative 
-
-class PtychoDataset:
-    @debug
-    def __init__(self, train_data, test_data):
-        self.train_data = train_data
-        self.test_data = test_data
-
-class PtychoDataContainer:
-    """
-    A class to contain ptycho data attributes for easy access and manipulation.
-    """
-    @debug
-    def __init__(self, X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, nn_indices, global_offsets, local_offsets, probeGuess):
-        self.X = X
-        self.Y_I = Y_I
-        self.Y_phi = Y_phi
-        self.norm_Y_I = norm_Y_I
-        self.YY_full = YY_full
-        self.coords_nominal = coords_nominal
-        self.coords = coords_nominal
-        self.coords_true = coords_true
-        self.nn_indices = nn_indices
-        self.global_offsets = global_offsets
-        self.local_offsets = local_offsets
-        self.probe = probeGuess
-
-        from .tf_helper import combine_complex
-        self.Y = combine_complex(Y_I, Y_phi)
-
-    @debug
-    def __repr__(self):
-        repr_str = '<PtychoDataContainer'
-        for attr_name in ['X', 'Y_I', 'Y_phi', 'norm_Y_I', 'YY_full', 'coords_nominal', 'coords_true', 'nn_indices', 'global_offsets', 'local_offsets', 'probe']:
-            attr = getattr(self, attr_name)
-            if attr is not None:
-                if isinstance(attr, np.ndarray):
-                    if np.iscomplexobj(attr):
-                        repr_str += f' {attr_name}={attr.shape} mean_amplitude={np.mean(np.abs(attr)):.3f}'
-                    else:
-                        repr_str += f' {attr_name}={attr.shape} mean={attr.mean():.3f}'
-                else:
-                    repr_str += f' {attr_name}={attr.shape}'
-        repr_str += '>'
-        return repr_str
-
-    @staticmethod
-    @debug
-    def from_raw_data_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess=None, N=None, K=7, nsamples=1):
-        """
-        Static method constructor that composes a call to RawData.from_coords_without_pc() and loader.load,
-        then initializes attributes.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-            N (int, optional): The size of the image. Defaults to None.
-            K (int, optional): The number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): The number of samples. Defaults to 1.
-
-        Returns:
-            PtychoDataContainer: An instance of the PtychoDataContainer class.
-        """
-        from . import params as cfg
-        if N is None:
-            N = cfg.get('N')
-        train_raw = RawData.from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-        
-        dset_train = train_raw.generate_grouped_data(N, K=K, nsamples=nsamples)
-
-        # Use loader.load() to handle the conversion to PtychoData
-        return load(lambda: dset_train, probeGuess, which=None, create_split=False)
-
-    #@debug
-    def to_npz(self, file_path: str) -> None:
-        """
-        Write the underlying arrays to an npz file.
-
-        Args:
-            file_path (str): Path to the output npz file.
-        """
-        np.savez(
-            file_path,
-            X=self.X.numpy() if tf.is_tensor(self.X) else self.X,
-            Y_I=self.Y_I.numpy() if tf.is_tensor(self.Y_I) else self.Y_I,
-            Y_phi=self.Y_phi.numpy() if tf.is_tensor(self.Y_phi) else self.Y_phi,
-            norm_Y_I=self.norm_Y_I,
-            YY_full=self.YY_full,
-            coords_nominal=self.coords_nominal.numpy() if tf.is_tensor(self.coords_nominal) else self.coords_nominal,
-            coords_true=self.coords_true.numpy() if tf.is_tensor(self.coords_true) else self.coords_true,
-            nn_indices=self.nn_indices,
-            global_offsets=self.global_offsets,
-            local_offsets=self.local_offsets,
-            probe=self.probe.numpy() if tf.is_tensor(self.probe) else self.probe
-        )
-
-    # TODO is this deprecated, given the above method to_npz()?
-
-@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset['coords_offsets']
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset['coords_relative']
-    coords_true = dset['coords_relative']
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    Y = tf.ones_like(X)
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-@debug
-def split_data(X_full, coords_nominal, coords_true, train_frac, which):
-    """
-    Splits the data into training and testing sets based on the specified fraction.
-
-    Args:
-        X_full (np.ndarray): The full dataset to be split.
-        coords_nominal (np.ndarray): The nominal coordinates associated with the dataset.
-        coords_true (np.ndarray): The true coordinates associated with the dataset.
-        train_frac (float): The fraction of the dataset to be used for training.
-        which (str): A string indicating whether to return the 'train' or 'test' split.
-
-    Returns:
-        tuple: A tuple containing the split data and coordinates.
-    """
-    n_train = int(len(X_full) * train_frac)
-    if which == 'train':
-        return X_full[:n_train], coords_nominal[:n_train], coords_true[:n_train]
-    elif which == 'test':
-        return X_full[n_train:], coords_nominal[n_train:], coords_true[n_train:]
-    else:
-        raise ValueError("Invalid split type specified: must be 'train' or 'test'.")
-
-@debug
-def split_tensor(tensor, frac, which='test'):
-    """
-    Splits a tensor into training and test portions based on the specified fraction.
-
-    :param tensor: The tensor to split.
-    :param frac: Fraction of the data to be used for training.
-    :param which: Specifies whether to return the training ('train') or test ('test') portion.
-    :return: The appropriate portion of the tensor based on the specified fraction and 'which' parameter.
-    """
-    n_train = int(len(tensor) * frac)
-    return tensor[:n_train] if which == 'train' else tensor[n_train:]
-
-# TODO this should be a method of PtychoDataContainer
-#@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset[key_coords_offsets]
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset[key_coords_relative]
-    coords_true = dset[key_coords_relative]
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-#    try:
-#        Y = get_image_patches(gt_image, global_offsets, coords_true) * cfg.get('probe_mask')[..., 0]
-#    except:
-#        Y = tf.zeros_like(X)
-
-    norm_Y_I = datasets.scale_nphotons(X)
-
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    # TODO we shouldn't be nuking the ground truth
-##    try:
-#    if dset['Y'] is None:
-#        Y = get_image_patches(gt_image,
-#            global_offsets, coords_true) * probe.get_probe_mask_real(cfg.get('N'))
-#        print("loader: generating ground truth patches from image and offsets")
-#    else:
-#        Y = dset['Y']
-#        print("loader: using provided ground truth patches")
-    if dset['Y'] is None:
-        Y = tf.ones_like(X)
-        print("loader: setting dummy Y ground truth")
-    else:
-        Y = dset['Y']
-        print("loader: using provided ground truth patches")
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    # TODO this should be baked into the model pipeline. If we can
-    # assume consistent normalization, we can get rid of intensity_scale
-    # as a model parameter since the post normalization average L2 norm
-    # will be fixed. Normalizing in the model's dataloader will make
-    # things more self-contained and avoid the need for separately
-    # scaling simulated datasets. While we're at it we should get rid of
-    # all the unecessary multiiplying and dividing by intensity_scale.
-    # As long as nphotons is a dataset-level attribute (i.e. an attribute of RawData 
-    # and PtychoDataContainer), nothing is lost
-    # by keeping the diffraction in normalized format everywhere except
-    # before the Poisson NLL calculation in model.py.
-
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    #print('X NORM', X_full_norm)
-    return X_full_norm * X_full
-
-#@debug
-def crop(arr2d, size):
-    N, M = arr2d.shape
-    return arr2d[N // 2 - (size) // 2: N // 2+ (size) // 2, N // 2 - (size) // 2: N // 2 + (size) // 2]
-
-@debug
-def get_gt_patch(offset, N, gt_image):
-    from . import tf_helper as hh
-    return crop(
-        hh.translate(gt_image, offset),
-        N // 2)
-
-def load_xpp_npz(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                                 diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                       xcoords_start[:train_size], ycoords_start[:train_size],
-                                       diff3d[:train_size], probeGuess,
-                                       scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
diff --git a/build/lib/build/lib/build/lib/ptycho/logging.py b/build/lib/build/lib/build/lib/ptycho/logging.py
deleted file mode 100644
index d9ca4fe..0000000
--- a/build/lib/build/lib/build/lib/ptycho/logging.py
+++ /dev/null
@@ -1,315 +0,0 @@
-"""
-Module for logging and inspecting function inputs, outputs, and execution times.
-
-Provides the `debug` decorator to log function invocations, including serialized inputs,
-outputs, and execution times. Supports logging to console and disk files.
-
-Includes `load_logged_data` function to load logged data from disk for a specific invocation.
-
-Handles serialization of NumPy arrays, TensorFlow tensors, and custom objects.
-
-Logging controlled by `params.get('debug')` configuration.
-
-Key components:
-- `debug` decorator
-- `load_logged_data` function
-- Helper functions: `make_invocation_counter`, `serialize_input`
-- Custom exceptions: `SerializationError`, `LoggedDataNotFoundError`
-"""
-import functools
-import inspect
-import json
-import numpy as np
-import os
-import tensorflow as tf
-from datetime import datetime
-from typing import Any, Callable, Dict, List, Tuple
-
-import ptycho.params as params
-
-class SerializationError(Exception):
-    pass
-
-class LoggedDataNotFoundError(Exception):
-    pass
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-# TODO surround each function's output section in xml tags with the function / 
-# method path
-def debug(log_to_file: bool = True):
-    def decorator(func: Callable):
-        increment_count = make_invocation_counter()
-
-        @functools.wraps(func)
-        def wrapper(*args: Any, **kwargs: Any) -> Any:
-            if params.get('debug'):
-                invocation_count = increment_count()
-
-                if invocation_count <= 2:
-                    timestamp = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
-                    module_path = inspect.getmodule(func).__name__
-                    function_name = func.__name__
-
-                    def serialize_input(arg: Any) -> str:
-                        if isinstance(arg, np.ndarray):
-                            return f"NumPy array with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, tf.Tensor):
-                            return f"TensorFlow tensor with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, (int, float, str, bool)):
-                            return f"{type(arg).__name__} with value {arg}"
-                        else:
-                            return str(type(arg))
-
-                    serializable_inputs = {
-                        'args': [serialize_input(arg) for arg in args],
-                        'kwargs': {key: serialize_input(value) for key, value in kwargs.items()}
-                    }
-
-                    log_message = f"Calling function {function_name} in module {module_path} with inputs: {json.dumps(serializable_inputs, default=str)}"
-                    print(log_message)
-
-                    if log_to_file:
-                        log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-                        os.makedirs(log_directory, exist_ok=True)
-                        log_file_path = os.path.join(log_directory, f"{function_name}_{timestamp}.log")
-                        try:
-                            with open(log_file_path, 'w') as log_file:
-                                log_file.write(log_message + '\n')
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                    start_time = datetime.now()
-                    try:
-                        result = func(*args, **kwargs)
-                    except Exception as e:
-                        error_message = f"Error executing function {function_name} in module {module_path}: {str(e)}"
-                        print(error_message)
-                        raise e
-                    end_time = datetime.now()
-                    execution_time = end_time - start_time
-
-                    serializable_result = serialize_input(result)
-
-                    log_message = f"Function {function_name} in module {module_path} returned: {serializable_result}"
-                    print(log_message)
-                    print(f"Execution time: {execution_time}")
-
-                    if log_to_file:
-                        try:
-                            with open(log_file_path, 'a') as log_file:
-                                log_file.write(log_message + '\n')
-                                log_file.write(f"Execution time: {execution_time}\n")
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                else:
-                    result = func(*args, **kwargs)
-
-            else:
-                result = func(*args, **kwargs)
-
-            return result
-
-        return wrapper
-
-    return decorator
-
-def load_logged_data(module_path: str, function_name: str, invocation_index: int = 0) -> Tuple[Dict[str, Any], Any]:
-    log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-    log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-    log_files.sort()
-
-    if invocation_index >= len(log_files):
-        raise LoggedDataNotFoundError(f"Invocation index {invocation_index} not found for function {function_name} in module {module_path}")
-
-    log_file_path = os.path.join(log_directory, log_files[invocation_index])
-
-    try:
-        with open(log_file_path, 'r') as log_file:
-            lines = log_file.readlines()
-            inputs_line = lines[0].strip()
-            outputs_line = lines[1].strip()
-
-            inputs_start = inputs_line.find(': ') + 2
-            outputs_start = outputs_line.find(': ') + 2
-
-            inputs_json = inputs_line[inputs_start:]
-            outputs_str = outputs_line[outputs_start:]
-
-            inputs = json.loads(inputs_json)
-            outputs = outputs_str
-
-            return inputs, outputs
-    except (IOError, json.JSONDecodeError) as e:
-        raise LoggedDataNotFoundError(f"Error loading logged data for function {function_name} in module {module_path}: {str(e)}")
-
-import os
-import json
-from typing import List, Tuple, Union
-from ptycho.logging import LoggedDataNotFoundError, load_logged_data
-
-def get_type_and_dim(serialized_data: str) -> str:
-    if serialized_data.startswith("NumPy array"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"NumPy array, shape: {shape}, dtype: {dtype}"
-    elif serialized_data.startswith("TensorFlow tensor"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"TensorFlow tensor, shape: {shape}, dtype: {dtype}"
-    else:
-        return serialized_data.split(" ")[0]
-
-def process_log_file(module_path: str, function_name: str) -> None:
-    if function_name.startswith("__init__"):
-        return
-
-    invocation_index = 0
-    try:
-        inputs, outputs = load_logged_data(module_path, function_name, invocation_index)
-    except LoggedDataNotFoundError:
-        return
-
-    input_types_dims = []
-    for input_data in inputs["args"]:
-        input_types_dims.append(get_type_and_dim(input_data))
-    for input_name, input_data in inputs["kwargs"].items():
-        input_types_dims.append(f"{input_name}: {get_type_and_dim(input_data)}")
-
-    output_type_dim = get_type_and_dim(outputs)
-
-    print(f"Module: {module_path}, Function: {function_name}")
-    print("Input types and dimensionalities:")
-    for input_type_dim in input_types_dims:
-        print(f"  - {input_type_dim}")
-    print(f"Output type and dimensionality: {output_type_dim}")
-    print()
-
-def extract_logged_data(log_directory: str) -> None:
-    for module_name in os.listdir(log_directory):
-        module_directory = os.path.join(log_directory, module_name)
-        for log_file in os.listdir(module_directory):
-            function_name = log_file.split("_")[0]
-            process_log_file(module_name, function_name)
-
-# TODO this function belongs among the tests
-def main() -> None:
-    log_directory = "logs/"
-    extract_logged_data(log_directory)
-
-####
-# tests
-####
-# Test case 1: Function with serializable inputs and output
-@debug()
-def add_numbers(a: int, b: int) -> int:
-    return a + b
-
-# Test case 2: Function with NumPy array input and output
-@debug()
-def multiply_array(arr: np.ndarray) -> np.ndarray:
-    return arr * 2
-
-# Test case 3: Function with TensorFlow tensor input and output
-@debug()
-def add_tensors(t1: tf.Tensor, t2: tf.Tensor) -> tf.Tensor:
-    return t1 + t2
-
-# Test case 4: Function with mixed input types and custom object output
-class CustomResult:
-    def __init__(self, value: str):
-        self.value = value
-
-@debug()
-def process_data(data: Any, flag: bool) -> CustomResult:
-    if flag:
-        return CustomResult("Processed: " + str(data))
-    else:
-        return CustomResult("Skipped: " + str(data))
-
-# Test case 5: Function with exception
-@debug()
-def divide_numbers(a: int, b: int) -> float:
-    return a / b
-
-# Test case 6: Loading logged data from disk
-@debug(log_to_file=True)
-def multiply_numbers(a: int, b: int) -> int:
-    return a * b
-
-## Set the debug parameter to True
-#params.cfg['debug'] = True
-#
-## Running the tests
-#add_numbers(3, 5)
-#add_numbers(4, 6)
-#add_numbers(5, 7)  # This invocation will not be logged
-#multiply_array(np.array([1, 2, 3]))
-#multiply_array(np.array([4, 5, 6]))
-#multiply_array(np.array([7, 8, 9]))  # This invocation will not be logged
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#add_tensors(tf.constant([[1.0, 2.0], [3.0, 4.0]]), tf.constant([[5.0, 6.0], [7.0, 8.0]]))
-#add_tensors(tf.constant([1.0, 2.0, 3.0]), tf.constant([4.0, 5.0, 6.0]))  # This invocation will not be logged
-#process_data({"key": "value"}, True)
-#process_data({"key": "value"}, False)
-#process_data([1, 2, 3], True)  # This invocation will not be logged
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(20, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(30, 0)  # This invocation will not be logged
-#except ZeroDivisionError:
-#    pass
-#
-#multiply_numbers(2, 3)
-#multiply_numbers(4, 5)
-#multiply_numbers(6, 7)  # This invocation will not be logged
-#
-## Loading logged data from disk
-#module_path = "__main__"
-#function_name = "multiply_numbers"
-#invocation_index = 0
-#
-#inputs, output = load_logged_data(module_path, function_name, invocation_index)
-#
-#print(f"Loaded inputs: {inputs}")
-#print(f"Loaded output: {output}")
-#
-## Cleanup: Remove the logged data files
-#log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-#log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-#for log_file in log_files:
-#    log_file_path = os.path.join(log_directory, log_file)
-#    os.remove(log_file_path)
-#
-## Set the debug parameter to False
-#params.cfg['debug'] = False
-#
-## Running the tests again (no logging should occur)
-#add_numbers(3, 5)
-#multiply_array(np.array([1, 2, 3]))
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#process_data({"key": "value"}, True)
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#multiply_numbers(2, 3)
-#
-#
diff --git a/build/lib/build/lib/build/lib/ptycho/losses.py b/build/lib/build/lib/build/lib/ptycho/losses.py
deleted file mode 100644
index 1efd8b0..0000000
--- a/build/lib/build/lib/build/lib/ptycho/losses.py
+++ /dev/null
@@ -1,17 +0,0 @@
-#def I_channel_MAE(y_true,y_pred, center_target = True):
-#    if center_target:
-#        y_true = center_channels(y_true
-#    return tf.reduce_mean(tf.keras.losses.MeanAbsoluteError(y_true,y_pred))
-
-#def symmetrized_loss(target, pred, loss_fn):
-#    """
-#    Calculate loss function on an image, taking into account that the
-#    prediction may be coordinate-inverted relative to the target
-#    """
-#    abs1 = (target)
-#    abs2 = (pred)
-#    abs3 = abs2[:, ::-1, ::-1, :]
-#    target_sym = (symmetrize_3d(target))
-#    a, b, c = loss_fn(abs1, abs2), loss_fn(abs1, abs3), loss_fn(target_sym, pred)
-#    return tf.minimum(a,
-#                      tf.minimum(b, c))
diff --git a/build/lib/build/lib/build/lib/ptycho/misc.py b/build/lib/build/lib/build/lib/ptycho/misc.py
deleted file mode 100644
index 003189f..0000000
--- a/build/lib/build/lib/build/lib/ptycho/misc.py
+++ /dev/null
@@ -1,330 +0,0 @@
-import numpy as np
-import matplotlib.cm as cm
-import scipy.cluster.vq as scv
-from ptycho import params
-from datetime import datetime
-
-# TODO multiple creations of this directory
-def get_path_prefix():
-    label = params.cfg['label']
-    prefix = params.params()['output_prefix']
-    now = datetime.now() # current date and time
-    try:
-        date_time = params.get('timestamp')
-    except KeyError:
-        date_time = now.strftime("%m/%d/%Y, %H:%M:%S")
-        params.set('timestamp', date_time)
-    date_time = date_time.replace('/', '-').replace(':', '.').replace(', ', '-')
-
-    #print('offset', offset)
-    out_prefix = '{}/{}_{}/'.format(prefix, date_time, label)
-    return out_prefix
-
-# Convert RGB colormap images to grayscale
-def colormap2arr(arr,cmap):
-    # http://stackoverflow.com/questions/3720840/how-to-reverse-color-map-image-to-scalar-values/3722674#3722674
-    gradient=cmap(np.linspace(0.0,1.0,1000))
-
-    # Reshape arr to something like (240*240, 4), all the 4-tuples in a long list...
-    arr2=arr.reshape((arr.shape[0]*arr.shape[1],arr.shape[2]))
-
-    # Use vector quantization to shift the values in arr2 to the nearest point in
-    # the code book (gradient).
-    code,dist=scv.vq(arr2,gradient)
-
-    # code is an array of length arr2 (240*240), holding the code book index for
-    # each observation. (arr2 are the "observations".)
-    # Scale the values so they are from 0 to 1.
-    values=code.astype('float')/gradient.shape[0]
-
-    # Reshape values back to (240,240)
-    values=values.reshape(arr.shape[0],arr.shape[1])
-    values=values[::-1]
-    return values
-
-import functools
-import hashlib
-import json
-import os
-import tensorflow as tf
-
-#https://chat.openai.com/c/8273412b-f3fb-405c-a7a4-c0466bb43b04
-import os
-import functools
-import hashlib
-import json
-import numpy as np
-import tensorflow as tf
-
-def memoize_disk_and_memory(func):
-    from ptycho.params import cfg
-    from ptycho import probe
-    memory_cache = {}
-    disk_cache_dir = 'memoized_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def process_dict(d):
-        processed = {}
-        for k, v in d.items():
-            if isinstance(v, tf.Tensor):
-                processed[k] = ('tensor', v.numpy())
-            elif isinstance(v, np.ndarray):
-                processed[k] = ('array', v)
-            elif isinstance(v, dict):
-                processed[k] = ('dict', process_dict(v))
-            else:
-                processed[k] = ('primitive', v)
-        return processed
-
-    def reconstruct_dict(d):
-        reconstructed = {}
-        for k, (type_, value) in d.items():
-            if type_ == 'tensor' or type_ == 'array':
-                reconstructed[k] = value
-            elif type_ == 'dict':
-                reconstructed[k] = reconstruct_dict(value)
-            else:  # primitive
-                reconstructed[k] = value
-        return reconstructed
-
-    @functools.wraps(func)
-    def wrapper(*args, **kwargs):
-        cfg_keys = ['offset', 'N', 'outer_offset_train', 'outer_offset_test',
-                    'nphotons', 'nimgs_train', 'nimgs_test', 'set_phi',
-                    'data_source', 'gridsize', 'big_gridsize', 'default_probe_scale']
-        hash_input = {k: cfg[k] for k in cfg_keys if k in cfg}
-        hash_input.update({f'arg_{i}': json.dumps(arg, default=str) for i, arg in enumerate(args)})
-        hash_input.update({f'kwarg_{k}': json.dumps(v, default=str) for k, v in kwargs.items()})
-        hash_input_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha1(hash_input_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-        else:
-            disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-            if os.path.exists(disk_cache_file):
-                print("Loading result from disk cache.")
-                loaded_data = np.load(disk_cache_file, allow_pickle=True)
-                if 'dict_data' in loaded_data:
-                    result = reconstruct_dict(loaded_data['dict_data'].item())
-                elif 'result' in loaded_data:
-                    result = loaded_data['result']
-                else:
-                    result = tuple(loaded_data[key] for key in loaded_data.keys())
-                    if len(result) == 1:
-                        result = result[0]
-            else:
-                print("No cached result found. Calculating and caching the result.")
-                result = func(*args, **kwargs)
-                if isinstance(result, (np.ndarray, tf.Tensor)):
-                    np.savez(disk_cache_file, result=result.numpy() if isinstance(result, tf.Tensor) else result)
-                elif isinstance(result, tuple):
-                    np.savez(disk_cache_file, **{f'arr_{i}': arr.numpy() if isinstance(arr, tf.Tensor) else arr for i, arr in enumerate(result)})
-                elif isinstance(result, dict):
-                    processed_dict = process_dict(result)
-                    np.savez(disk_cache_file, dict_data=processed_dict)
-                else:
-                    raise ValueError("Invalid function output. Expected numpy array, TensorFlow tensor, tuple, or dictionary with values as arrays/tensors/primitives.")
-                memory_cache[hash_hex] = result
-        return result
-    return wrapper
-
-
-##########
-# unit test
-##########
-#
-#import numpy as np
-#import tensorflow as tf
-#
-## Define test functions
-#@memoize_disk_and_memory
-#def test_function1(x):
-#    return np.random.rand(x, x)
-#
-#@memoize_disk_and_memory
-#def test_function2(x):
-#    return tf.random.uniform((x, x))
-#
-#@memoize_disk_and_memory
-#def test_function3(x):
-#    return np.random.rand(x, x), tf.random.uniform((x, x))
-#
-## First run - cache miss
-#result1_first = test_function1(5)
-#result2_first = test_function2(5)
-#result3_first = test_function3(5)
-#
-## Second run - cache hit
-#result1_second = test_function1(5)
-#result2_second = test_function2(5)
-#result3_second = test_function3(5)
-#
-## Test if the memoized results match the first run results
-#np.testing.assert_array_equal(result1_first, result1_second)
-#np.testing.assert_array_equal(result2_first, result2_second)
-#
-#np.testing.assert_array_equal(result3_first[0], result3_second[0])
-#np.testing.assert_array_equal(result3_first[1], result3_second[1])
-#
-## Test if memoization works with different function arguments
-#result1_diff_arg = test_function1(6)
-#np.testing.assert_raises(AssertionError, np.testing.assert_array_equal, result1_first, result1_diff_arg)
-#
-
-import functools
-import numpy as np
-import tensorflow as tf
-
-def make_invocation_counter():
-    count = 0
-
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-
-    return increment
-
-######
-## logging decorator
-######
-# TODO deprecated, moved to logging.py
-#def g(h):
-#    increment_count = make_invocation_counter()
-#
-#    def wrapper(f):
-#        @functools.wraps(f)
-#        def inner(*args, **kwargs):
-#            invocation_count = increment_count()
-#            if invocation_count <= 2:
-#                return h(f)(*args, **kwargs)
-#            else:
-#                return f(*args, **kwargs)
-#
-#        return inner
-#
-#    return wrapper
-#
-#@g
-#def debug(func):
-#    def wrapper(*args, **kwargs):
-#        def get_type_and_shape(x):
-#            if isinstance(x, np.ndarray):
-#                return f"{type(x)} with shape {x.shape}"
-#            elif isinstance(x, tf.Tensor):
-#                return f"{type(x)} with shape {x.shape}"
-#            else:
-#                return str(type(x))
-#
-#        args_types = [get_type_and_shape(arg) for arg in args]
-#        kwargs_types = {k: get_type_and_shape(v) for k, v in kwargs.items()}
-#
-#        print(f"Calling {func.__name__} with args types: {args_types}, kwargs types: {kwargs_types}")
-#        result = func(*args, **kwargs)
-#        
-#        result_type = get_type_and_shape(result)
-#        print(f"{func.__name__} returned {result_type}")
-#        
-#        return result
-#    return wrapper
-
-import scipy.signal
-import functools
-import hashlib
-import json
-import os
-import numpy as np
-
-def memoize_simulated_data(func):
-    memory_cache = {}
-    disk_cache_dir = 'memoized_simulated_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def array_to_bytes(arr):
-        return arr.tobytes(), arr.dtype.str, arr.shape
-
-    def bytes_to_array(data, dtype, shape):
-        return np.frombuffer(data, dtype=np.dtype(dtype)).reshape(shape)
-
-    @functools.wraps(func)
-    def wrapper(objectGuess, probeGuess, nimages, buffer, random_seed=None, return_patches=True):
-        from ptycho.loader import RawData
-        # Create a unique hash for the input parameters
-        hash_input = {
-            'objectGuess': array_to_bytes(objectGuess),
-            'probeGuess': array_to_bytes(probeGuess),
-            'nimages': nimages,
-            'buffer': buffer,
-            'random_seed': random_seed,
-            'return_patches': return_patches
-        }
-        hash_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha256(hash_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-
-        disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-        if os.path.exists(disk_cache_file):
-            print("Loading result from disk cache.")
-            with np.load(disk_cache_file, allow_pickle=True) as data:
-                raw_data_dict = data['raw_data'].item()
-                raw_data = RawData(
-                    xcoords=raw_data_dict['xcoords'],
-                    ycoords=raw_data_dict['ycoords'],
-                    xcoords_start=raw_data_dict['xcoords_start'],
-                    ycoords_start=raw_data_dict['ycoords_start'],
-                    diff3d=raw_data_dict['diff3d'],
-                    probeGuess=raw_data_dict['probeGuess']
-                )
-                if return_patches:
-                    patches = data['patches']
-                    result = (raw_data, patches)
-                else:
-                    result = raw_data
-        else:
-            print("No cached result found. Calculating and caching the result.")
-            result = func(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches)
-            
-            if isinstance(result, tuple):
-                raw_data, patches = result
-            else:
-                raw_data = result
-                patches = None
-
-            raw_data_dict = {
-                'xcoords': raw_data.xcoords,
-                'ycoords': raw_data.ycoords,
-                'xcoords_start': raw_data.xcoords_start,
-                'ycoords_start': raw_data.ycoords_start,
-                'diff3d': raw_data.diff3d,
-                'probeGuess': raw_data.probeGuess
-            }
-
-            np.savez(disk_cache_file, raw_data=raw_data_dict, patches=patches)
-
-        memory_cache[hash_hex] = result
-        return result
-
-    return wrapper
-
-def cross_image(im1, im2):
-    """
-    Find offsets through 2d autocorrelation
-    """
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
diff --git a/build/lib/build/lib/build/lib/ptycho/model.py b/build/lib/build/lib/build/lib/ptycho/model.py
deleted file mode 100644
index a182376..0000000
--- a/build/lib/build/lib/build/lib/ptycho/model.py
+++ /dev/null
@@ -1,477 +0,0 @@
-# TODO s
-# - complex convolution
-# - Use tensor views:
-#     https://chat.openai.com/c/e6d5e400-daf9-44b7-8ef9-d49f21a634a3
-# -difference maps?
-# -double -> float32
-# Apply real space loss to both amplitude and phase of the object
-
-from datetime import datetime
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras.activations import relu, sigmoid, tanh, swish, softplus
-from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, InputLayer, Lambda, Dense
-from tensorflow.keras.layers import Layer
-from tensorflow.keras import layers
-import glob
-import math
-import numpy as np
-import os
-import tensorflow.compat.v2 as tf
-import tensorflow_probability as tfp
-
-from .loader import PtychoDataContainer
-from . import tf_helper as hh
-from . import params as cfg
-params = cfg.params
-
-import tensorflow_addons as tfa
-gaussian_filter2d = tfa.image.gaussian_filter2d
-
-def complex_gaussian_filter2d(input_tensor, filter_shape, sigma):
-    """
-    Apply Gaussian filter to complex-valued tensor.
-    
-    Args:
-    input_tensor: Complex-valued input tensor
-    filter_shape: Tuple of integers specifying the filter shape
-    sigma: Float or tuple of floats for the Gaussian kernel standard deviation
-    
-    Returns:
-    Complex-valued tensor after applying Gaussian filter
-    """
-    real_part = tf.math.real(input_tensor)
-    imag_part = tf.math.imag(input_tensor)
-    
-    filtered_real = gaussian_filter2d(real_part, filter_shape=filter_shape, sigma=sigma)
-    filtered_imag = gaussian_filter2d(imag_part, filter_shape=filter_shape, sigma=sigma)
-    
-    return tf.complex(filtered_real, filtered_imag)
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-# sets the number of convolutional filters
-
-n_filters_scale =  cfg.get('n_filters_scale')
-N = cfg.get('N')
-gridsize = cfg.get('gridsize')
-offset = cfg.get('offset')
-
-from . import probe
-tprobe = params()['probe']
-
-probe_mask = probe.get_probe_mask(N)
-#probe_mask = cfg.get('probe_mask')[:, :, :, 0]
-
-if len(tprobe.shape) == 3:
-    initial_probe_guess = tprobe[None, ...]
-    #probe_mask = probe_mask[None, ...]
-elif len(tprobe.shape) == 4:
-    initial_probe_guess = tprobe
-else:
-    raise ValueError
-
-initial_probe_guess = tf.Variable(
-            initial_value=tf.cast(initial_probe_guess, tf.complex64),
-            trainable=params()['probe.trainable'],
-        )
-
-# TODO hyperparameters:
-# TODO total variation loss
-# -probe smoothing scale(?)
-class ProbeIllumination(tf.keras.layers.Layer):
-    def __init__(self, name = None):
-        super(ProbeIllumination, self).__init__(name = name)
-        self.w = initial_probe_guess
-        self.sigma = cfg.get('gaussian_smoothing_sigma')
-
-    def call(self, inputs):
-        # x is expected to have shape (batch_size, N, N, gridsize**2)
-        # where N is the size of each patch and gridsize**2 is the number of patches
-        x = inputs[0]
-        
-        # self.w has shape (1, N, N, 1) or (1, N, N, gridsize**2) if probe.big is True
-        # probe_mask has shape (N, N, 1)
-        
-        # Apply multiplication first
-        illuminated = self.w * x
-        
-        # Apply Gaussian smoothing only if sigma is not 0
-        if self.sigma != 0:
-            smoothed = complex_gaussian_filter2d(illuminated, filter_shape=(3, 3), sigma=self.sigma)
-        else:
-            smoothed = illuminated
-        
-        if cfg.get('probe.mask'):
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed * tf.cast(probe_mask, tf.complex64), (self.w * tf.cast(probe_mask, tf.complex64))[None, ...]
-        else:
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed, (self.w)[None, ...]
-
-probe_illumination = ProbeIllumination()
-
-nphotons = cfg.get('nphotons')
-
-# TODO scaling could be done on a shot-by-shot basis, but IIRC I tried this
-# and there were issues
-log_scale_guess = np.log(cfg.get('intensity_scale'))
-log_scale = tf.Variable(
-            initial_value=tf.constant(float(log_scale_guess)),
-            trainable = params()['intensity_scale.trainable'],
-        )
-
-class IntensityScaler(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return x / tf.math.exp(self.w)
-
-# TODO use a bijector instead of separately defining the transform and its
-# inverse
-class IntensityScaler_inv(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler_inv, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return tf.math.exp(self.w) * x
-
-def scale(inputs):
-    x, = inputs
-    res = x / tf.math.exp(log_scale)
-    return res
-
-def inv_scale(inputs):
-    x, = inputs
-    return tf.math.exp(log_scale) * x
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-lambda_norm = Lambda(lambda x: tf.math.reduce_sum(x**2, axis = [1, 2]))
-input_img = Input(shape=(N, N, gridsize**2), name = 'input')
-input_positions = Input(shape=(1, 2, gridsize**2), name = 'input_positions')
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-def create_encoder(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 128:
-        filters = [n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 256:
-        filters = [n_filters_scale * 8, n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Pool_block(x, num_filters)
-    
-    return x
-
-def create_decoder_base(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    return x
-
-def get_resolution_scale_factor(N):
-    """
-    Calculate the resolution-dependent filter count programmatically.
-    
-    Args:
-    N (int): The input resolution (must be a power of 2)
-    
-    Returns:
-    int: The scale factor for the given resolution
-    
-    Raises:
-    ValueError: If the input size is not a power of 2 or is outside the supported range
-    """
-    if N < 64 or N > 1024:
-        raise ValueError(f"Input size {N} is outside the supported range (64 to 1024)")
-    
-    if not (N & (N - 1) == 0) or N == 0:
-        raise ValueError(f"Input size {N} is not a power of 2")
-    
-    # Calculate the scale factor
-    # For N=64, we want 32; for N=128, we want 16; for N=256, we want 8, etc.
-    # This can be achieved by dividing 2048 by N
-    return 2048 // N
-
-def create_decoder_last(input_tensor, n_filters_scale, conv1, conv2, act=tf.keras.activations.sigmoid, name=''):
-    N = cfg.get('N')
-    gridsize = cfg.get('gridsize')
-
-    scale_factor = get_resolution_scale_factor(N)
-    if cfg.get('pad_object'):
-        c_outer = 4
-        x1 = conv1(input_tensor[..., :-c_outer])
-        x1 = act(x1)
-        x1 = tf.keras.layers.ZeroPadding2D(((N // 4), (N // 4)), name=name + '_padded')(x1)
-        
-        if not cfg.get('probe.big'):
-            return x1
-        
-        x2 = Conv_Up_block(input_tensor[..., -c_outer:], n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = swish(x2)
-        
-        # Drop the central region of x2
-        center_mask = hh.mk_centermask(x2, N, 1, kind='border')
-        x2_masked = x2 * center_mask
-        
-        outputs = x1 + x2_masked
-        return outputs
-
-    else:
-        x2 = Conv_Up_block(input_tensor, n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = act(x2)
-        return x2
-
-
-def create_decoder_phase(input_tensor, n_filters_scale, gridsize, big):
-    num_filters = gridsize**2 if big else 1
-    conv1 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    act = tf.keras.layers.Lambda(lambda x: math.pi * tf.keras.activations.tanh(x), name='phi')
-    
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act, name='phase')
-    return outputs
-
-
-def create_autoencoder(input_tensor, n_filters_scale, gridsize, big):
-    encoded = create_encoder(input_tensor, n_filters_scale)
-    decoded_amp = create_decoder_amp(encoded, n_filters_scale)
-    decoded_phase = create_decoder_phase(encoded, n_filters_scale, gridsize, big)
-    
-    return decoded_amp, decoded_phase
-
-
-def get_amp_activation():
-    if cfg.get('amp_activation') == 'sigmoid':
-        return lambda x: sigmoid(x)
-    elif cfg.get('amp_activation') == 'swish':
-        return lambda x: swish(x)
-    elif cfg.get('amp_activation') == 'softplus':
-        return lambda x: softplus(x)
-    elif cfg.get('amp_activation') == 'relu':
-        return lambda x: relu(x)
-    else:
-        return ValueError
-
-def create_decoder_amp(input_tensor, n_filters_scale):
-    # Placeholder convolution layers and activation as defined in the original DecoderAmp class
-    conv1 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    act = Lambda(get_amp_activation(), name='amp')
-
-    x = create_decoder_base(input_tensor, n_filters_scale)
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act,
-        name = 'amp')
-    return outputs
-
-normed_input = scale([input_img])
-decoded1, decoded2 = create_autoencoder(normed_input, n_filters_scale, gridsize,
-    cfg.get('object.big'))
-
-# Combine the two decoded outputs
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]), name='obj')([decoded1, decoded2])
-
-if cfg.get('object.big'):
-    # If 'object.big' is true, reassemble the patches
-    padded_obj_2 = Lambda(lambda x: hh.reassemble_patches(x[0], fn_reassemble_real=hh.mk_reassemble_position_real(x[1])), name = 'padded_obj_2')([obj, input_positions])
-else:
-    # If 'object.big' is not true, pad the reconstruction
-    padded_obj_2 = Lambda(lambda x: hh.pad_reconstruction(x), name = 'padded_obj_2')(obj)
-
-# TODO rename?
-# Trim the object reconstruction to N x N
-trimmed_obj = Lambda(hh.trim_reconstruction, name = 'trimmed_obj')(padded_obj_2)
-
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x:
-    hh.extract_patches_position(x[0], x[1], 0.),
-    name = 'padded_objs_with_offsets')([padded_obj_2, input_positions])
-
-# Apply the probe illumination
-padded_objs_with_offsets, probe = probe_illumination([padded_objs_with_offsets])
-flat_illuminated = padded_objs_with_offsets
-
-# Apply pad and diffract operation
-padded_objs_with_offsets, pred_diff = Lambda(lambda x: hh.pad_and_diffract(x, N, N, pad=False), name = 'pred_amplitude')(padded_objs_with_offsets)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-# Scale the amplitude
-pred_amp_scaled = inv_scale([pred_diff])
-
-
-# TODO Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
-dist_poisson_intensity = tfpl.DistributionLambda(lambda amplitude:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               (amplitude**2)))))
-pred_intensity_sampled = dist_poisson_intensity(pred_amp_scaled)
-
-# Poisson distribution over expected diffraction intensity (i.e. photons per
-# pixel)
-def negloglik(x, rv_x):
-    return -rv_x.log_prob(x)
-fn_poisson_nll = lambda A_target, A_pred: negloglik(A_target**2, dist_poisson_intensity(A_pred))
-
-autoencoder = Model([input_img, input_positions], [trimmed_obj, pred_amp_scaled, pred_intensity_sampled])
-
-autoencoder_no_nll = Model(inputs = [input_img, input_positions],
-        outputs = [pred_amp_scaled])
-
-#encode_obj_to_diffraction = tf.keras.Model(inputs=[obj, input_positions],
-#                           outputs=[pred_diff, flat_illuminated])
-diffraction_to_obj = tf.keras.Model(inputs=[input_img, input_positions],
-                           outputs=[trimmed_obj])
-
-mae_weight = cfg.get('mae_weight') # should normally be 0
-nll_weight = cfg.get('nll_weight') # should normally be 1
-# Total variation regularization on real space amplitude
-realspace_weight = cfg.get('realspace_weight')#1e2
-optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
-
-autoencoder.compile(optimizer= optimizer,
-     #loss=[lambda target, pred: hh.total_variation(pred),
-     loss=[hh.realspace_loss,
-        'mean_absolute_error', negloglik, 'mean_absolute_error'],
-     loss_weights = [realspace_weight, mae_weight, nll_weight, 0.])
-
-print (autoencoder.summary())
-
-# Create a TensorBoard callback
-logs = "logs/" + datetime.now().strftime("%Y%m%d-%H%M%S")
-
-tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,
-                                                 histogram_freq=1,
-                                                 profile_batch='500,520')
-
-def prepare_inputs(train_data: PtychoDataContainer):
-    """training inputs"""
-    return [train_data.X * cfg.get('intensity_scale'), train_data.coords]
-
-def prepare_outputs(train_data: PtychoDataContainer):
-    """training outputs"""
-    return [hh.center_channels(train_data.Y_I, train_data.coords)[:, :, :, :1],
-                (cfg.get('intensity_scale') * train_data.X),
-                (cfg.get('intensity_scale') * train_data.X)**2]
-
-#def train(epochs, X_train, coords_train, Y_obj_train):
-def train(epochs, trainset: PtychoDataContainer):
-    assert type(trainset) == PtychoDataContainer
-    coords_train = trainset.coords
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint(
-                            '%s/weights.{epoch:02d}.h5' %wt_path,
-                            monitor='val_loss', verbose=1, save_best_only=True,
-                            save_weights_only=False, mode='auto', period=1)
-
-    batch_size = params()['batch_size']
-    history=autoencoder.fit(
-#        prepare_inputs(X_train, coords_train),
-#        prepare_outputs(Y_obj_train, coords_train, X_train),
-        prepare_inputs(trainset),
-        prepare_outputs(trainset),
-        shuffle=True, batch_size=batch_size, verbose=1,
-        epochs=epochs, validation_split = 0.05,
-        callbacks=[reduce_lr, earlystop])
-        #callbacks=[reduce_lr, earlystop, tboard_callback])
-    return history
-import numpy as np
-
-def print_model_diagnostics(model):
-    """
-    Prints diagnostic information for a given TensorFlow/Keras model.
-
-    Parameters:
-    - model: A TensorFlow/Keras model object.
-    """
-    # Print the model summary to get the architecture, layer types, output shapes, and parameter counts.
-    model.summary()
-
-    # Print input shape
-    print("Model Input Shape(s):")
-    for input_layer in model.inputs:
-        print(input_layer.shape)
-
-    # Print output shape
-    print("Model Output Shape(s):")
-    for output_layer in model.outputs:
-        print(output_layer.shape)
-
-    # Print total number of parameters
-    print("Total Parameters:", model.count_params())
-
-    # Print trainable and non-trainable parameter counts
-    trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
-    non_trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])
-    print("Trainable Parameters:", trainable_count)
-    print("Non-trainable Parameters:", non_trainable_count)
-
-    # If the model uses any custom layers, print their names and configurations
-    print("Custom Layers (if any):")
-    for layer in model.layers:
-        if hasattr(layer, 'custom_objects'):
-            print(f"{layer.name}: {layer.custom_objects}")
diff --git a/build/lib/build/lib/build/lib/ptycho/model_manager.py b/build/lib/build/lib/build/lib/ptycho/model_manager.py
deleted file mode 100644
index 2ee4937..0000000
--- a/build/lib/build/lib/build/lib/ptycho/model_manager.py
+++ /dev/null
@@ -1,202 +0,0 @@
-# model_manager.py
-
-import os
-import h5py
-import dill
-import tempfile
-import zipfile
-import shutil
-import tensorflow as tf
-from typing import Dict, List, Any, Optional
-from ptycho import params
-
-class ModelManager:
-    @staticmethod
-    def save_model(model: tf.keras.Model, model_dir: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model (tf.keras.Model): The model to save.
-            model_dir (str): Directory path for saving the model.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the model.
-            intensity_scale (float): The intensity scale used in the model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            os.makedirs(model_dir, exist_ok=True)
-            
-            # Save the model
-            model.save(model_dir, save_format="tf")
-            
-            # Save custom objects
-            with open(custom_objects_path, 'wb') as f:
-                dill.dump(custom_objects, f)
-            
-            # Save parameters including intensity_scale
-            params_dict = params.cfg.copy()
-            params_dict['intensity_scale'] = intensity_scale
-            params_dict['_version'] = '1.0'  # Add version information
-            with open(params_path, 'wb') as f:
-                dill.dump(params_dict, f)
-            
-            # Save intensity_scale as an attribute in the HDF5 file
-            with h5py.File(model_file, 'a') as hf:
-                hf.attrs['intensity_scale'] = intensity_scale
-        
-        except Exception as e:
-            print(f"Error saving model to {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def load_model(model_dir: str) -> tf.keras.Model:
-        """
-        Load a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model_dir (str): Directory containing the model files.
-
-        Returns:
-            tf.keras.Model: The loaded model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            
-            # Load parameters
-            with open(params_path, 'rb') as f:
-                loaded_params = dill.load(f)
-            
-            # Check version and handle any necessary migrations
-            version = loaded_params.pop('_version', '1.0')
-            # Here you could add logic to handle different versions if needed
-            
-            # Update params.cfg with loaded parameters
-            params.cfg.update(loaded_params)
-            
-            # Load custom objects
-            with open(custom_objects_path, 'rb') as f:
-                custom_objects = dill.load(f)
-            
-            # Load intensity scale
-            with h5py.File(model_file, 'r') as hf:
-                intensity_scale = hf.attrs['intensity_scale']
-            
-            # Set intensity scale in params
-            params.set('intensity_scale', intensity_scale)
-
-            # Load and return the model
-            return tf.keras.models.load_model(model_dir, custom_objects=custom_objects)
-        
-        except Exception as e:
-            print(f"Error loading model from {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def save_multiple_models(models_dict: Dict[str, tf.keras.Model], base_path: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save multiple models into a single zip archive.
-
-        Args:
-            models_dict (Dict[str, tf.keras.Model]): Dictionary of models to save.
-            base_path (str): Base path for saving the zip archive.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the models.
-            intensity_scale (float): The intensity scale used in the models.
-        """
-        zip_path = f"{base_path}.zip"
-        os.makedirs(os.path.dirname(zip_path), exist_ok=True)
-        
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Save manifest of included models
-            manifest = {'models': list(models_dict.keys()), 'version': '1.0'}
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'wb') as f:
-                dill.dump(manifest, f)
-            
-            # Save each model to temp directory
-            for model_name, model in models_dict.items():
-                model_subdir = os.path.join(temp_dir, model_name)
-                os.makedirs(model_subdir, exist_ok=True)
-                ModelManager.save_model(model, model_subdir, custom_objects, intensity_scale)
-            
-            # Create zip archive
-            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
-                for root, _, files in os.walk(temp_dir):
-                    for file in files:
-                        full_path = os.path.join(root, file)
-                        arc_path = os.path.relpath(full_path, temp_dir)
-                        zf.write(full_path, arc_path)
-
-    @staticmethod
-    def load_multiple_models(base_path: str, model_names: Optional[List[str]] = None) -> Dict[str, tf.keras.Model]:
-        """
-        Load multiple models from a zip archive.
-
-        Args:
-            base_path (str): Base path of the zip archive.
-            model_names (Optional[List[str]]): List of model names to load. If None, loads all models.
-
-        Returns:
-            Dict[str, tf.keras.Model]: Dictionary of loaded models.
-        """
-        zip_path = f"{base_path}.zip"
-        if not os.path.exists(zip_path):
-            raise FileNotFoundError(f"Model archive not found: {zip_path}")
-            
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Extract zip archive
-            with zipfile.ZipFile(zip_path, 'r') as zf:
-                zf.extractall(temp_dir)
-            
-            # Load manifest
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'rb') as f:
-                manifest = dill.load(f)
-            
-            # Determine which models to load
-            available_models = manifest['models']
-            if model_names is None:
-                model_names = available_models
-            else:
-                # Validate requested models exist
-                missing = set(model_names) - set(available_models)
-                if missing:
-                    raise ValueError(f"Requested models not found in archive: {missing}")
-            
-            # Load each requested model
-            loaded_models = {}
-            for model_name in model_names:
-                model_subdir = os.path.join(temp_dir, model_name)
-                loaded_models[model_name] = ModelManager.load_model(model_subdir)
-            
-            return loaded_models
-
-
-def save(out_prefix: str) -> None:
-    """Save models to a zip archive."""
-    from ptycho import model
-    from ptycho.model import ProbeIllumination, IntensityScaler, IntensityScaler_inv, negloglik
-    from ptycho.tf_helper import Translation
-    from ptycho.tf_helper import realspace_loss as hh_realspace_loss
-
-    model_path = os.path.join(out_prefix, params.get('h5_path'))
-    custom_objects = {
-        'ProbeIllumination': ProbeIllumination,
-        'IntensityScaler': IntensityScaler,
-        'IntensityScaler_inv': IntensityScaler_inv,
-        'Translation': Translation,
-        'negloglik': negloglik,
-        'realspace_loss': hh_realspace_loss
-    }
-    
-    models_to_save = {
-        'autoencoder': model.autoencoder,
-        'diffraction_to_obj': model.diffraction_to_obj
-    }
-    
-    ModelManager.save_multiple_models(models_to_save, model_path, custom_objects, params.get('intensity_scale'))
diff --git a/build/lib/build/lib/build/lib/ptycho/nbutils.py b/build/lib/build/lib/build/lib/ptycho/nbutils.py
deleted file mode 100644
index fe53aab..0000000
--- a/build/lib/build/lib/build/lib/ptycho/nbutils.py
+++ /dev/null
@@ -1,217 +0,0 @@
-import matplotlib.pyplot as plt
-from ptycho import model
-import numpy as np
-
-def crop_to_non_uniform_region_with_buffer(img_array, buffer=0):
-    """
-    Crop the image to the non-uniform region with an additional buffer in each direction.
-
-    Parameters:
-    - img_array: The numpy array of the image.
-    - buffer: The number of pixels to expand the cropped region in each direction.
-
-    Returns:
-    - cropped_img_array: The numpy array of the cropped image.
-    """
-
-    # Convert to grayscale if it is not already
-    if len(img_array.shape) == 3:
-        gray_img_array = img_array[:, :, 0]
-    else:
-        gray_img_array = img_array
-
-    # Find the background pixel value, assuming it is the mode of the corner pixels
-    corner_pixels = [gray_img_array[0, 0], gray_img_array[0, -1], gray_img_array[-1, 0], gray_img_array[-1, -1]]
-    background_pixel = max(set(corner_pixels), key=corner_pixels.count)
-
-    # Detect the non-uniform region
-    rows, cols = np.where(gray_img_array != background_pixel)
-    if rows.size > 0 and cols.size > 0:
-        row_min, row_max, col_min, col_max = rows.min(), rows.max(), cols.min(), cols.max()
-        # Apply the buffer, ensuring we don't go out of the image bounds
-        row_min = max(row_min - buffer, 0)
-        row_max = min(row_max + buffer, gray_img_array.shape[0] - 1)
-        col_min = max(col_min - buffer, 0)
-        col_max = min(col_max + buffer, gray_img_array.shape[1] - 1)
-    else:
-        raise ValueError("No non-uniform region found")
-
-    # Crop the image to the non-uniform region with the buffer
-    cropped_img_array = gray_img_array[row_min:row_max+1, col_min:col_max+1]
-
-    return cropped_img_array
-
-import matplotlib.pyplot as plt
-
-def mk_comparison(method1, method2, method1_name='PtychoNN', method2_name='ground truth', method0=None, method0_name='ePIE', phase_vmin=None, phase_vmax=None):
-    """
-    Create a comparison plot of phase and amplitude images for 2 or 3 methods.
-
-    Parameters:
-    - method1: Complex 2D array of method1 data
-    - method2: Complex 2D array of method2 data
-    - method1_name: Name of the first method (default: 'PtychoNN')
-    - method2_name: Name of the second method (default: 'ground truth')
-    - method0: Complex 2D array of method0 data (optional)
-    - method0_name: Name of the optional third method (default: 'ePIE')
-    - phase_vmin: Minimum data value for phase plots (optional)
-    - phase_vmax: Maximum data value for phase plots (optional)
-    """
-    num_methods = 3 if method0 is not None else 2
-    fig, axs = plt.subplots(2, num_methods, figsize=(5*num_methods, 10))
-
-    methods = [method0, method1, method2] if num_methods == 3 else [method1, method2]
-    method_names = [method0_name, method1_name, method2_name] if num_methods == 3 else [method1_name, method2_name]
-
-    for i, (method, name) in enumerate(zip(methods, method_names)):
-        # Phase plot
-        phase_img = axs[0, i].imshow(np.angle(method), cmap='gray', vmin=phase_vmin, vmax=phase_vmax)
-        axs[0, i].set_title(f'{name} Phase')
-        axs[0, i].axis('off')
-        fig.colorbar(phase_img, ax=axs[0, i], orientation='vertical')
-
-        # Amplitude plot
-        amp_img = axs[1, i].imshow(np.abs(method), cmap='viridis')
-        axs[1, i].set_title(f'{name} Amplitude')
-        axs[1, i].axis('off')
-        fig.colorbar(amp_img, ax=axs[1, i], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-    plt.show()
-
-def compare(obj_tensor_full, global_offsets, objectGuess, ptychonn_tensor=None):
-    from ptycho import loader
-
-    # Process PtychoPINN data
-    ptychopinn_image = loader.reassemble_position(obj_tensor_full, global_offsets[:, :, :, :], M=20)
-    ptychopinn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychopinn_image[..., 0]), buffer=-20)
-    ptychopinn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychopinn_image[..., 0]), buffer=-20)
-
-    # Process ground truth data
-    gt_phase = crop_to_non_uniform_region_with_buffer(np.angle(objectGuess), buffer=-20)
-    gt_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(objectGuess), buffer=-20)
-
-    # Process PtychoNN data if provided
-    if ptychonn_tensor is not None:
-        ptychonn_image = loader.reassemble_position(ptychonn_tensor, global_offsets[:, :, :, :], M=20)
-        ptychonn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychonn_image[..., 0]), buffer=-20)
-        ptychonn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychonn_image[..., 0]), buffer=-20)
-        
-        # Create comparison with all three methods
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth',
-                      method0=ptychonn_phase + 1j * ptychonn_amplitude, 
-                      method0_name='PtychoNN')
-    else:
-        # Create comparison with only PtychoPINN and ground truth
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth')
-
-# TODO type annotation
-def reconstruct_image(test_data, diffraction_to_obj = None):
-    global_offsets = test_data.global_offsets
-    local_offsets = test_data.local_offsets
-
-    if diffraction_to_obj is None:
-        diffraction_to_obj = model.diffraction_to_obj
-    obj_tensor_full = diffraction_to_obj.predict(
-                    [test_data.X * model.params()['intensity_scale'],
-                    local_offsets])
-    return obj_tensor_full, global_offsets
-
-def print_shapes(test_data):
-    for key, value in test_data.items():
-        if value is not None:
-            if isinstance(value, tuple):
-                print(f"{key}\t")
-                for i, array in enumerate(value):
-                    print(f"  Array {i+1}{array.shape}, \t {array.dtype}")
-            else:
-                print(f"{key}\t{value.shape}, {value.dtype}")
-
-def probeshow(probeGuess, test_data):
-    # Creating a figure with three subplots
-    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
-
-    # Plotting the magnitude of the complex array
-    img1 = ax1.imshow(np.abs(probeGuess), cmap='viridis')
-    ax1.set_title('probe amplitude')
-    fig.colorbar(img1, ax=ax1, orientation='vertical')
-
-    # Plotting the phase of the complex array
-    img2 = ax2.imshow(np.angle(probeGuess), cmap='jet')
-    ax2.set_title('probe phase')
-    fig.colorbar(img2, ax=ax2, orientation='vertical')
-
-    # Plotting the scan point positions
-    ax3.scatter(*(test_data.global_offsets.squeeze().T))
-    ax3.set_title('scan point positions')
-
-    # Improving layout
-    plt.tight_layout()
-    plt.show()
-
-
-def track_dict_changes(input_dict, callback):
-    # Copy the original dictionary to track changes
-    original_dict = input_dict.copy()
-    # Execute the callback function
-    callback(input_dict)
-    # Determine which keys have changed or added
-    changed_or_added_keys = [key for key in input_dict if input_dict.get(key) != original_dict.get(key)]
-    return changed_or_added_keys
-
-def mk_epie_comparison2x2(ptycho_pinn_phase, epie_phase, ptycho_pinn_amplitude,epie_amplitude):
-    # Create a 2x2 subplot
-    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
-
-    # PtychoPINN phase with color bar
-    ptycho_pinn_phase_img = axs[0, 0].imshow(ptycho_pinn_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    axs[0, 0].axis('off')
-    fig.colorbar(ptycho_pinn_phase_img, ax=axs[0, 0], orientation='vertical')
-
-    # ePIE phase with color bar
-    epie_phase_img = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    axs[0, 1].axis('off')
-    fig.colorbar(epie_phase_img, ax=axs[0, 1], orientation='vertical')
-
-    # PtychoPINN amplitude with color bar
-    ptycho_pinn_amplitude_img = axs[1, 0].imshow(ptycho_pinn_amplitude, cmap='gray')#,
-                                               # vmin = .2
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    axs[1, 0].axis('off')
-    fig.colorbar(ptycho_pinn_amplitude_img, ax=axs[1, 0], orientation='vertical')
-
-    # ePIE amplitude with color bar
-    epie_amplitude_img = axs[1, 1].imshow(epie_amplitude, cmap='gray')
-    axs[1, 1].set_title('ePIE Amplitude')
-    axs[1, 1].axis('off')
-    fig.colorbar(epie_amplitude_img, ax=axs[1, 1], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-
-    plt.show()
-
-# object heatmaps
-## Creating a figure and two subplots
-#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
-#
-## Plotting the amplitude of the complex object
-#ax1.imshow(np.absolute(objectGuess), cmap='viridis')
-#ax1.set_title('Amplitude')
-#
-## Plotting the phase of the complex object
-#ax2.imshow(np.angle(objectGuess), cmap='viridis')
-#ax2.set_title('Phase')
-#
-## Adjust layout
-#plt.tight_layout()
-#plt.show()
diff --git a/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py b/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py
deleted file mode 100644
index 9c653ea..0000000
--- a/build/lib/build/lib/build/lib/ptycho/nongrid_simulation.py
+++ /dev/null
@@ -1,266 +0,0 @@
-# ptycho_simulation.py
-
-import numpy as np
-import matplotlib.pyplot as plt
-from mpl_toolkits.axes_grid1 import make_axes_locatable
-from typing import Union, Tuple, Dict
-from ptycho.loader import RawData
-from ptycho import tf_helper as hh
-from ptycho import probe
-from ptycho import baselines as bl
-
-def load_probe_object(file_path: str) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Load object and probe guesses from a .npz file.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-
-    Returns:
-        tuple: A tuple containing (objectGuess, probeGuess)
-
-    Raises:
-        ValueError: If required data is missing from the .npz file or if data is invalid.
-        RuntimeError: If an error occurs during file loading.
-    """
-    try:
-        with np.load(file_path) as data:
-            if 'objectGuess' not in data or 'probeGuess' not in data:
-                raise ValueError("The .npz file must contain 'objectGuess' and 'probeGuess'")
-            
-            objectGuess = data['objectGuess']
-            probeGuess = data['probeGuess']
-
-        # Validate extracted data
-        if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-            raise ValueError("objectGuess and probeGuess must be 2D arrays")
-        if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-            raise ValueError("objectGuess and probeGuess must be complex-valued")
-
-        return objectGuess, probeGuess
-
-    except Exception as e:
-        raise RuntimeError(f"Error loading data from {file_path}: {str(e)}")
-
-from ptycho.misc import memoize_simulated_data
-
-#@memoize_simulated_data
-def generate_simulated_data(objectGuess: np.ndarray, probeGuess: np.ndarray, nimages: int, buffer: float, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    Args:
-        objectGuess (np.ndarray): Complex-valued 2D array representing the object.
-        probeGuess (np.ndarray): Complex-valued 2D array representing the probe.
-        nimages (int): Number of scan positions to generate.
-        buffer (float): Border size to avoid when generating coordinates.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation.
-    """
-    # Input validation
-    if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-        raise ValueError("objectGuess and probeGuess must be 2D arrays")
-    if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-        raise ValueError("objectGuess and probeGuess must be complex-valued")
-    if nimages <= 0 or buffer < 0:
-        raise ValueError("nimages must be positive and buffer must be non-negative")
-
-    # Get object dimensions
-    height, width = objectGuess.shape
-
-    # Ensure buffer doesn't exceed image dimensions
-    buffer = min(buffer, min(height, width) / 2 - 1)
-
-    # Set random seed if provided
-    if random_seed is not None:
-        np.random.seed(random_seed)
-
-    # Generate random coordinates (floats)
-    xcoords = np.random.uniform(buffer, width - buffer, nimages)
-    ycoords = np.random.uniform(buffer, height - buffer, nimages)
-
-    # Create scan_index
-    scan_index = np.zeros(nimages, dtype=int)
-
-    # Generate simulated data
-    return RawData.from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index, return_patches=return_patches)
-
-def simulate_from_npz(file_path: str, nimages: int, buffer: float = None, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Load object and probe guesses from a .npz file and generate simulated ptychography data.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-        nimages (int): Number of scan positions to generate.
-        buffer (float, optional): Border size to avoid when generating coordinates. 
-                                  If None, defaults to 35% of the smaller dimension of objectGuess.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation or file loading.
-    """
-    # Load guesses from file
-    objectGuess, probeGuess = load_probe_object(file_path)
-
-    # Set default buffer if not provided
-    if buffer is None:
-        buffer = min(objectGuess.shape) * 0.35  # 35% of the smaller dimension
-
-    # Generate simulated data
-    return generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches=return_patches)
-
-def plot_complex_image(ax: plt.Axes, data: np.ndarray, title: str) -> None:
-    """Helper function to plot complex-valued images."""
-    im = ax.imshow(np.abs(data), cmap='viridis')
-    ax.set_title(f"{title} (Magnitude)")
-    divider = make_axes_locatable(ax)
-    cax = divider.append_axes("right", size="5%", pad=0.05)
-    plt.colorbar(im, cax=cax)
-
-    ax_phase = divider.append_axes("bottom", size="100%", pad=0.2, sharex=ax)
-    im_phase = ax_phase.imshow(np.angle(data), cmap='hsv')
-    ax_phase.set_title(f"{title} (Phase)")
-    cax_phase = divider.append_axes("bottom", size="5%", pad=0.5)
-    plt.colorbar(im_phase, cax=cax_phase, orientation="horizontal")
-
-def visualize_simulated_data(data: Dict[str, np.ndarray], output_dir: str) -> None:
-    """
-    Visualize the simulated ptychography data and save all plots in a single image file.
-
-    Args:
-        data (dict): Dictionary containing the loaded simulated data.
-        output_dir (str): Directory to save the output plot.
-    """
-    import os
-
-    # Create output directory if it doesn't exist
-    os.makedirs(output_dir, exist_ok=True)
-
-    # Create a large figure with multiple subplots
-    fig = plt.figure(figsize=(24, 30))
-    gs = fig.add_gridspec(5, 3, height_ratios=[1, 0.2, 1, 0.2, 1])
-
-    # Plot probe guess
-    ax_probe = fig.add_subplot(gs[0, 0])
-    plot_complex_image(ax_probe, data['probe_guess'], "Probe Guess")
-
-    # Plot object guess
-    ax_object = fig.add_subplot(gs[0, 1])
-    plot_complex_image(ax_object, data['object'], "Object Guess")
-
-    # Plot scan positions
-    ax_scan = fig.add_subplot(gs[0, 2])
-    ax_scan.scatter(data['x_coordinates'], data['y_coordinates'], alpha=0.5)
-    ax_scan.set_title("Scan Positions")
-    ax_scan.set_xlabel("X Coordinate")
-    ax_scan.set_ylabel("Y Coordinate")
-    ax_scan.set_aspect('equal')
-
-    # Add title for diffraction patterns
-    fig.text(0.5, 0.62, "Sample Diffraction Patterns", ha='center', va='center', fontsize=16)
-
-    # Plot a sample of diffraction patterns
-    for i in range(3):
-        if i < min(3, data['diffraction_patterns'].shape[0]):
-            ax = fig.add_subplot(gs[2, i])
-            im = ax.imshow(np.log(data['diffraction_patterns'][i]), cmap='viridis')
-            ax.set_title(f"Pattern {i}")
-            plt.colorbar(im, ax=ax)
-
-    # Add title for ground truth patches
-    fig.text(0.5, 0.22, "Sample Ground Truth Patches", ha='center', va='center', fontsize=16)
-
-    # Plot ground truth patches
-    for i in range(3):
-        if i < min(3, data['ground_truth_patches'].shape[0]):
-            ax = fig.add_subplot(gs[4, i])
-            plot_complex_image(ax, data['ground_truth_patches'][i], f"Patch {i}")
-
-    plt.tight_layout()
-    plt.savefig(os.path.join(output_dir, "simulated_data_visualization.png"), dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-    print(f"All plots have been saved to: {os.path.join(output_dir, 'simulated_data_visualization.png')}")
-
-def plot_random_groups(tmp: RawData, K: int, figsize: Tuple[int, int] = (15, 5), seed: int = None) -> None:
-    """
-    Plot a random selection of K groups of (diffraction image, Y amplitude, Y phase) from a RawData object.
-
-    Args:
-        tmp (RawData): The RawData object containing the ptychography data.
-        K (int): Number of groups to plot.
-        figsize (tuple): Figure size for each group plot. Default is (15, 5).
-        seed (int): Random seed for reproducibility. Default is None.
-
-    Raises:
-        ValueError: If K is greater than the number of available diffraction patterns.
-    """
-    if K > tmp.diff3d.shape[0]:
-        raise ValueError(f"K ({K}) cannot be greater than the number of diffraction patterns ({tmp.diff3d.shape[0]})")
-
-    # Set random seed if provided
-    if seed is not None:
-        np.random.seed(seed)
-
-    # Randomly select K indices
-    indices = np.random.choice(tmp.diff3d.shape[0], K, replace=False)
-
-    for idx in indices:
-        fig, axes = plt.subplots(1, 3, figsize=figsize)
-        fig.suptitle(f"Group {idx}")
-
-        # Plot diffraction image (log scale for better visibility)
-        diff_img = axes[0].imshow(np.log1p(1 + 100 * tmp.diff3d[idx]), cmap='jet')
-        axes[0].set_title("Diffraction (log scale)")
-        plt.colorbar(diff_img, ax=axes[0])
-
-        # Plot Y amplitude
-        amp_img = axes[1].imshow(np.abs(tmp.Y[idx]), cmap='viridis')
-        axes[1].set_title("Y Amplitude")
-        plt.colorbar(amp_img, ax=axes[1])
-
-        # Plot Y phase
-        phase_img = axes[2].imshow(np.angle(tmp.Y[idx]), cmap='twilight')
-        axes[2].set_title("Y Phase")
-        plt.colorbar(phase_img, ax=axes[2])
-
-        # Remove axis ticks for cleaner look
-        for ax in axes:
-            ax.set_xticks([])
-            ax.set_yticks([])
-
-        plt.tight_layout()
-        plt.show()
-
-def compare_reconstructions(obj_tensor_full: np.ndarray, global_offsets: np.ndarray, ground_truth: np.ndarray, ptychonn_tensor: np.ndarray) -> None:
-    """
-    Compare the reconstructed object with the ground truth and PtychoNN prediction.
-
-    Args:
-        obj_tensor_full (np.ndarray): Full reconstructed object tensor.
-        global_offsets (np.ndarray): Global offsets for positioning.
-        ground_truth (np.ndarray): Ground truth object.
-        ptychonn_tensor (np.ndarray): PtychoNN predicted object tensor.
-    """
-    from ptycho import nbutils
-    irange = int(np.max(global_offsets[:, 0, 1, 0]) - np.min(global_offsets[:, 0, 1, 0]))
-    trimmed_ground_truth = hh.trim_reconstruction(ground_truth[None, ..., None], irange)[0, :, :, 0]
-    
-    nbutils.compare(obj_tensor_full, global_offsets, trimmed_ground_truth, ptychonn_tensor=ptychonn_tensor)
-
-# Add any additional helper functions or classes as needed
-
diff --git a/build/lib/build/lib/build/lib/ptycho/params.py b/build/lib/build/lib/build/lib/ptycho/params.py
deleted file mode 100644
index 3215103..0000000
--- a/build/lib/build/lib/build/lib/ptycho/params.py
+++ /dev/null
@@ -1,86 +0,0 @@
-"""
-Stores global variables for data generation and model configuration
-"""
-import numpy as np
-import tensorflow as tf
-# TODO naming convention for different types of parameters
-# TODO what default value and initialization for the probe scale?
-cfg = {
-    'N': 64, 'offset': 4, 'gridsize': 2,
-    'outer_offset_train': None, 'outer_offset_test': None, 'batch_size': 16,
-    'nepochs': 60, 'n_filters_scale': 2, 'output_prefix': 'outputs',
-    'big_gridsize': 10, 'max_position_jitter': 10, 'sim_jitter_scale': 0.,
-    'default_probe_scale': 0.7, 'mae_weight': 0., 'nll_weight': 1., 'tv_weight': 0.,
-    'realspace_mae_weight': 0., 'realspace_weight': 0., 'nphotons': 1e9,
-    'nimgs_train': 9, 'nimgs_test': 3,
-    'data_source': 'generic', 'probe.trainable': False,
-    'intensity_scale.trainable': False, 'positions.provided': False,
-    'object.big': True, 'probe.big': False, 'probe_scale': 10., 'set_phi': False,
-    'probe.mask': True, 'pad_object': True, 'model_type': 'pinn', 'label': '', 'size': 392,
-    'amp_activation': 'sigmoid', 'h5_path': 'wts.h5', 'npseed': 42,
-    'debug': True,
-    'gaussian_smoothing_sigma': 0.0  # New parameter for Gaussian smoothing sigma
-    }
-
-# TODO parameter description
-# probe.big: if True, increase the real space solution from 32x32 to 64x64
-
-# TODO bigoffset should be a derived quantity, at least for simulation
-def get_bigN():
-    N = cfg['N']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return N + (gridsize - 1) * offset
-
-def get_padding_size():
-    buffer = cfg['max_position_jitter']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return (gridsize - 1) * offset + buffer
-
-def get_padded_size():
-    bigN = get_bigN()
-    buffer = cfg['max_position_jitter']
-    return bigN + buffer
-
-def params():
-    d = {k:v for k, v in cfg.items()}
-    d['bigN'] = get_bigN()
-    return d
-
-# TODO refactor
-def validate():
-    valid_data_sources = ['lines', 'grf', 'experimental', 'points',
-        'testimg', 'diagonals', 'xpp', 'V', 'generic']
-    assert cfg['data_source'] in valid_data_sources, \
-        f"Invalid data source: {cfg['data_source']}. Must be one of {valid_data_sources}."
-    if cfg['realspace_mae_weight'] > 0.:
-        assert cfg['realspace_weight'] > 0
-    return True
-
-def set(key, value):
-    print("DEBUG: Setting", key, "to", value, "in params")
-    cfg[key] = value
-    assert validate()
-
-def get(key):
-    if key == 'bigN':
-        cfg['bigN'] = get_bigN()
-        return cfg['bigN']
-    return cfg[key]
-
-def print_params():
-    """Print all parameters with special handling for arrays/tensors"""
-    all_params = params()
-    print("Current Parameters:")
-    print("-" * 20)
-    for key, value in sorted(all_params.items()):
-        if isinstance(value, (np.ndarray, tf.Tensor)):
-            print(f"{key}:")
-            print(f"  shape: {value.shape}")
-            print(f"  mean: {np.mean(value):.3f}")
-            print(f"  std: {np.std(value):.3f}")
-            print(f"  min: {np.min(value):.3f}")
-            print(f"  max: {np.max(value):.3f}")
-        else:
-            print(f"{key}: {value}")
diff --git a/build/lib/build/lib/build/lib/ptycho/physics.py b/build/lib/build/lib/build/lib/ptycho/physics.py
deleted file mode 100644
index a19c0e5..0000000
--- a/build/lib/build/lib/build/lib/ptycho/physics.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from . import params as p
-from . import tf_helper as hh
-import tensorflow as tf
-import numpy as np
-import pdb
diff --git a/build/lib/build/lib/build/lib/ptycho/plotting.py b/build/lib/build/lib/build/lib/ptycho/plotting.py
deleted file mode 100644
index f02404a..0000000
--- a/build/lib/build/lib/build/lib/ptycho/plotting.py
+++ /dev/null
@@ -1,94 +0,0 @@
-import matplotlib.pyplot as plt
-from ipywidgets import interactive
-
-def ishow_imgs(*arrs_list, styles = None, labels = None,
-              log = False, height = '550px',
-              nested_label_callback = None):
-    """
-    Plot a series of curves interactively.
-    """
-    plt.rcParams["figure.figsize"]=(12, 9)
-    #labels = [label1, label2]
-    if labels is None:
-        labels = [''] * len(arrs_list)
-    def f(i):
-        for j, patterns in enumerate(arrs_list):
-            if styles is not None:
-                extra_args = (styles[j],)
-            else:
-                extra_args = ()
-            try:
-                for k in range(len(patterns[i])):
-                    len(patterns[i][k]) # TODO hack
-                    if nested_label_callback is not None:
-                        label = nested_label_callback(patterns[i], k)
-                    else:
-                        label = k
-                    plt.imshow(patterns[i][k], *extra_args, label = label)
-            except: # TODO except what?
-                if j < 2:
-                    plt.imshow(patterns[i], label = labels[j])
-                else:
-                    plt.imshow(patterns[i], *extra_args)
-
-    interactive_plot = interactive(f, i=(0, len(arrs_list[0]) - 1), step = 1)
-    output = interactive_plot.children[-1]
-    output.layout.height = height
-    return interactive_plot
-
-# Implementing actual plotting functions and the decorator for visual output
-
-import matplotlib.pyplot as plt
-import numpy as np
-
-from functools import wraps
-
-def plotting_function(func):
-    @wraps(func)
-    def wrapper(layout=(1, 1), display: bool = False, save: bool = False, save_path: str = "", *args, **kwargs):
-        standalone = 'ax' not in kwargs or kwargs['ax'] is None
-        if standalone:
-            fig, axs = plt.subplots(layout[0], layout[1], figsize=(layout[1]*3, layout[0]*3))
-            if layout == (1, 1):
-                axs = np.array([axs])
-            else:
-                axs = axs.reshape(layout[0], layout[1])
-            kwargs['ax'] = axs
-        result = func(*args, **kwargs)
-        if standalone:
-            plt.tight_layout()
-            if save:
-                plt.savefig(save_path if save_path else "/mnt/data/plot.png")
-            if display:
-                plt.show()
-        return result
-    return wrapper
-
-@plotting_function
-def plot_subfigure(ax=None, title: str = "Subfigure", *args, **kwargs):
-    rows, cols = ax.shape if isinstance(ax, np.ndarray) else (1, 1)
-    for i in range(rows):
-        for j in range(cols):
-            ax[i, j].plot([1, 2, 3], [1, 2, 3])
-            ax[i, j].set_title(f"{title} {i+1},{j+1}")
-
-def compose_and_save_figure():
-    fig = plt.figure(figsize=(10, 6))
-    gs = fig.add_gridspec(2, 2)
-
-    ax1 = fig.add_subplot(gs[0, 0])
-    ax2 = fig.add_subplot(gs[0, 1])
-    ax3 = fig.add_subplot(gs[1, :])
-
-    # Adjusting the plotting function to accept individual Axes
-    plot_subfigure(ax=np.array([[ax1]]), title="Plot 1")
-    plot_subfigure(ax=np.array([[ax2]]), title="Plot 2")
-    plot_subfigure(ax=np.array([[ax3]]), layout=(1, 1), title="Plot 3")
-
-    plt.tight_layout()
-    save_path = "/mnt/data/composed_figure.png"
-    plt.savefig(save_path)
-    plt.show()
-## To visually check, we'll call the plot_subfigure function directly with a layout parameter for standalone mode
-#plot_subfigure(layout=(2, 2), display=True, save=True, title="Standalone Plot", save_path="/mnt/data/standalone_plot.png")
-
diff --git a/build/lib/build/lib/build/lib/ptycho/probe.py b/build/lib/build/lib/build/lib/ptycho/probe.py
deleted file mode 100644
index 387fcf0..0000000
--- a/build/lib/build/lib/build/lib/ptycho/probe.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import tensorflow as tf
-import numpy as np
-from . import fourier as f
-from . import params
-
-def get_lowpass_filter(scale, N):
-    return f.lowpass_g(scale, np.ones(N), sym=True)
-
-def get_default_probe(N, fmt='tf'):
-    scale = params.cfg['default_probe_scale']
-    filt = get_lowpass_filter(scale, N)
-    probe_np = f.gf(((np.einsum('i,j->ij', filt, filt)) > .5).astype(float), 1) + 1e-9
-    if fmt == 'np':
-        return probe_np
-    elif fmt == 'tf':
-        return tf.convert_to_tensor(probe_np, tf.complex64)[..., None]
-    else:
-        raise ValueError("Invalid format specified")
-
-def get_probe(params):
-    probe_tf = params.get('probe')
-    assert len(probe_tf.shape) == 3
-    return probe_tf
-
-def to_np(probe):
-    assert len(probe.shape) == 3
-    return np.array(probe[:, :, 0])
-
-def get_squared_distance(N):
-    centered_indices = np.arange(N) - N // 2 + .5
-    x, y = np.meshgrid(centered_indices, centered_indices)
-    return np.sqrt(x*x+y*y)
-
-def get_probe_mask_real(N):
-    return (get_squared_distance(N) < N // 4)[..., None]
-
-def get_probe_mask(N):
-    probe_mask_real = get_probe_mask_real(N)
-    probe_mask = tf.convert_to_tensor(probe_mask_real, tf.complex64)
-    #return tf.convert_to_tensor(probe_mask, tf.complex64)[..., None]
-    return tf.convert_to_tensor(probe_mask, tf.complex64)
-
-def set_probe(probe):
-    assert len(probe.shape) == 3 or len(probe.shape) == 4
-    assert probe.shape[0] == probe.shape[1]
-    assert probe.shape[-1] == 1
-    if len(probe.shape) == 4:
-        assert probe.shape[-2] == 1
-        probe = probe[:, :, :]
-        print('coercing probe shape to 3d')
-
-    # This function still modifies global state
-    mask = tf.cast(get_probe_mask(params.get('N')), probe.dtype)
-    probe_scale = params.get('probe_scale')
-    tamped_probe = mask * probe
-    norm = float(probe_scale * tf.reduce_mean(tf.math.abs(tamped_probe)))
-    params.set('probe', probe / norm)
-
-def set_probe_guess(X_train = None, probe_guess = None):
-    N = params.get('N')
-    if probe_guess is None:
-        mu = 0.
-        tmp = X_train.mean(axis = (0, 3))
-        probe_fif = np.absolute(f.fftshift(f.ifft2(f.ifftshift(tmp))))[N // 2, :]
-
-        # variance increments of a slice down the middle
-        d_second_moment = (probe_fif / probe_fif.sum()) * ((np.arange(N) - N // 2)**2)
-        probe_sigma_guess = np.sqrt(d_second_moment.sum())
-        probe_guess = np.exp(-( (get_squared_distance(N) - mu)**2 / ( 2.0 * probe_sigma_guess**2 )))[..., None]\
-            + 1e-9
-        probe_guess *= get_probe_mask_real(N)
-        probe_guess *= (np.sum(get_default_probe(N)) / np.sum(probe_guess))
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.float32)
-    else:
-        if probe_guess.ndim not in [2, 3]:
-            raise ValueError("probe_guess must have 2 or 3 dimensions")
-        if probe_guess.ndim == 2:
-            probe_guess = probe_guess[..., None]
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.complex64)
-
-    #params.set('probe', t_probe_guess)
-    set_probe(t_probe_guess)
-    return t_probe_guess
-
-def set_default_probe():
-    """
-    use an idealized disk shaped probe. Only for simulated data workflows.
-    """
-    set_probe(get_default_probe(params.get('N'), fmt = 'tf'))
diff --git a/build/lib/build/lib/build/lib/ptycho/raw_data.py b/build/lib/build/lib/build/lib/ptycho/raw_data.py
deleted file mode 100644
index 16131a2..0000000
--- a/build/lib/build/lib/build/lib/ptycho/raw_data.py
+++ /dev/null
@@ -1,474 +0,0 @@
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional
-from scipy.spatial import cKDTree
-from ptycho import params
-from ptycho.autotest.debug import debug
-from ptycho import diffsim as datasets
-from ptycho import tf_helper as hh
-
-# Constants, # TODO cleanup / refactor
-local_offset_sign = 1
-key_coords_offsets = 'coords_start_offsets'
-key_coords_relative = 'coords_start_relative'
-
-class RawData:
-    #@debug
-    def __init__(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess,
-             scan_index, objectGuess = None, Y = None, norm_Y_I = None):
-        # Sanity checks
-        self._check_data_validity(xcoords, ycoords, xcoords_start, ycoords_start, diff3d,
-                    probeGuess, scan_index)
-
-        # TODO these should go in the data validation method
-        assert len(xcoords.shape) == 1, f"Expected xcoords to be 1D, got shape {xcoords.shape}"
-        assert len(ycoords.shape) == 1, f"Expected ycoords to be 1D, got shape {ycoords.shape}"
-        assert len(xcoords_start.shape) == 1, f"Expected xcoords_start to be 1D, got shape {xcoords_start.shape}"
-        assert len(ycoords_start.shape) == 1, f"Expected ycoords_start to be 1D, got shape {ycoords_start.shape}"
-        if diff3d is not None:
-            assert len(diff3d.shape) == 3, f"Expected diff3d to be 3D, got shape {diff3d.shape}"
-            print(f"diff3d shape: {diff3d.shape}")
-            assert diff3d.shape[1] == diff3d.shape[2]
-        if probeGuess is not None:
-            assert len(probeGuess.shape) == 2, f"Expected probeGuess to be 2D, got shape {probeGuess.shape}"
-            print(f"probeGuess shape: {probeGuess.shape}")
-        if scan_index is not None:
-            assert len(scan_index.shape) == 1, f"Expected scan_index to be 1D, got shape {scan_index.shape}"
-            print(f"scan_index shape: {scan_index.shape}")
-        if objectGuess is not None:
-            print(f"objectGuess shape: {objectGuess.shape}")
-            assert len(objectGuess.shape) == 2
-
-        print(f"xcoords shape: {xcoords.shape}")
-        print(f"ycoords shape: {ycoords.shape}")
-        print(f"xcoords_start shape: {xcoords_start.shape}")
-        print(f"ycoords_start shape: {ycoords_start.shape}")
-
-        # Assigning values if checks pass
-        self.xcoords = xcoords
-        self.ycoords = ycoords
-        self.xcoords_start = xcoords_start
-        self.ycoords_start = ycoords_start
-        self.diff3d = diff3d
-        self.probeGuess = probeGuess
-        self.scan_index = scan_index
-        self.objectGuess = objectGuess
-        # TODO validity checks
-        self.Y = Y
-        self.norm_Y_I = norm_Y_I
-
-    @staticmethod
-    #@debug
-    def from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index,
-                               objectGuess=None):
-        """
-        Static method to create a RawData instance without separate start coordinates.
-        The start coordinates are set to be the same as the xcoords and ycoords.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        return RawData(xcoords, ycoords, xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-
-    @staticmethod
-    def from_simulation(xcoords, ycoords, probeGuess,
-                 objectGuess, scan_index = None):
-        """
-        Create a RawData instance from simulation data.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            objectGuess (np.ndarray): initial guess of the object.
-            scan_index (np.ndarray, optional): array indicating the scan index for each diffraction pattern.
-
-        Returns:
-            RawData: An instance of the RawData class with simulated data.
-        """
-        from ptycho.diffsim import illuminate_and_diffract
-        xcoords_start = xcoords
-        ycoords_start = ycoords
-        global_offsets, local_offsets, nn_indices = calculate_relative_coords(
-                    xcoords, ycoords)
-
-        Y_obj = get_image_patches(objectGuess, global_offsets, local_offsets) 
-        Y_I = tf.math.abs(Y_obj)
-        Y_phi = tf.math.angle(Y_obj)
-        X, Y_I_xprobe, Y_phi_xprobe, intensity_scale = illuminate_and_diffract(Y_I, Y_phi, probeGuess)
-        norm_Y_I = datasets.scale_nphotons(X)
-        assert X.shape[-1] == 1, "gridsize must be set to one when simulating in this mode"
-        # TODO RawData should have a method for generating the illuminated ground truth object
-        return RawData(xcoords, ycoords, xcoords_start, ycoords_start, tf.squeeze(X).numpy(),
-                       probeGuess, scan_index, objectGuess,
-                       Y = tf.squeeze(hh.combine_complex( Y_I_xprobe, Y_phi_xprobe)).numpy(),
-                       norm_Y_I = norm_Y_I)
-
-    #@debug
-    def __str__(self):
-        parts = [
-            "RawData:",
-            f"  xcoords: {self.xcoords.shape if self.xcoords is not None else 'None'}",
-            f"  ycoords: {self.ycoords.shape if self.ycoords is not None else 'None'}",
-            f"  xcoords_start: {self.xcoords_start.shape if self.xcoords_start is not None else 'None'}",
-            f"  ycoords_start: {self.ycoords_start.shape if self.ycoords_start is not None else 'None'}",
-            f"  diff3d: {self.diff3d.shape if self.diff3d is not None else 'None'}",
-            f"  probeGuess: {self.probeGuess.shape if self.probeGuess is not None else 'None'}",
-            f"  scan_index: {self.scan_index.shape if self.scan_index is not None else 'None'}",
-            f"  objectGuess: {self.objectGuess.shape if self.objectGuess is not None else 'None'}"
-        ]
-        return "\n".join(parts)
-
-    #@debug
-    def to_file(self, file_path: str) -> None:
-        """
-        Method to write the RawData object to a file using numpy.savez.
-
-        Args:
-            file_path (str): Path to the file where the data will be saved.
-        """
-        np.savez(file_path,
-                 xcoords=self.xcoords,
-                 ycoords=self.ycoords,
-                 xcoords_start=self.xcoords_start,
-                 ycoords_start=self.ycoords_start,
-                 diff3d=self.diff3d,
-                 probeGuess=self.probeGuess,
-                 objectGuess=self.objectGuess,
-                 scan_index=self.scan_index)
-
-    @staticmethod
-    #@debug
-    def from_file(train_data_file_path: str) -> 'RawData':
-        """
-        Static method to create a RawData instance from a file.
-
-        Args:
-            train_data_file_path (str): Path to the file containing the data.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        # Load training data
-        train_data = np.load(train_data_file_path)
-        train_raw_data = RawData(
-            xcoords=train_data['xcoords'],
-            ycoords=train_data['ycoords'],
-            xcoords_start=train_data['xcoords_start'],
-            ycoords_start=train_data['ycoords_start'],
-            diff3d=train_data['diff3d'],
-            probeGuess=train_data['probeGuess'],
-            objectGuess=train_data['objectGuess'],
-            scan_index=train_data['scan_index']
-        )
-        return train_raw_data
-
-    @staticmethod
-    #@debug
-    def from_files(train_data_file_path, test_data_file_path):
-        """
-        Static method to instantiate RawData objects from training and test data files.
-
-        The data files should be NumPy .npz files with the following keys:
-        - 'xcoords': x coordinates of the scan points
-        - 'ycoords': y coordinates of the scan points
-        - 'xcoords_start': starting x coordinates for the scan
-        - 'ycoords_start': starting y coordinates for the scan
-        - 'diff3d': diffraction patterns
-        - 'probeGuess': initial guess of the probe function
-        - 'scan_index': array indicating the scan index for each diffraction pattern
-
-        Args:
-            train_data_file_path (str): Path to the training data file.
-            test_data_file_path (str): Path to the test data file.
-
-        Returns:
-            tuple: A tuple containing the instantiated RawData objects for training and test data.
-        """
-        # Load training data
-        train_raw_data = RawData.from_file(train_data_file_path)
-
-        # Load test data
-        test_raw_data = RawData.from_file(test_data_file_path)
-
-        return train_raw_data, test_raw_data
-
-    #@debug
-    def generate_grouped_data(self, N, K = 7, nsamples = 1):
-        """
-        Generate nearest-neighbor solution region grouping.
-
-        Args:
-            N (int): Size of the solution region.
-            K (int, optional): Number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): Number of samples. Defaults to 1.
-
-        Returns:
-            dict: Dictionary containing grouped data.
-        """
-        print('DEBUG:', 'nsamples:', nsamples)
-        return get_neighbor_diffraction_and_positions(self, N, K=K, nsamples=nsamples)
-
-    #@debug
-    def _check_data_validity(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-        """
-        Check if the input data is valid.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            xcoords_start (np.ndarray): starting x coordinates for the scan.
-            ycoords_start (np.ndarray): starting y coordinates for the scan.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-
-        Raises:
-            ValueError: If coordinate arrays don't have matching shapes.
-        """
-        # Check if coordinate arrays have matching shapes
-        if not (xcoords.shape == ycoords.shape == xcoords_start.shape == ycoords_start.shape):
-            raise ValueError("Coordinate arrays must have matching shapes.")
-
-#@debug
-def calculate_relative_coords(xcoords, ycoords, K = 6, C = None, nsamples = 10):
-    """
-    Group scan indices and coordinates into solution regions, then
-    calculate coords_offsets (global solution region coordinates) and
-    coords_relative (local solution patch coords) from ptycho_data using
-    the provided index_grouping_cb callback function.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        tuple: A tuple containing coords_offsets, coords_relative, and nn_indices.
-    """
-    nn_indices, coords_nn = group_coords(xcoords, ycoords, K = K, C = C, nsamples = nsamples)
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-    return coords_offsets, coords_relative, nn_indices
-
-#@debug
-def get_image_patches(gt_image, global_offsets, local_offsets):
-    """
-    Generate and return image patches in channel format using a single canvas.
-
-    Args:
-        gt_image (tensor): Ground truth image tensor.
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Image patches in channel format.
-    """
-    # Get necessary parameters
-    gridsize = params.get('gridsize')
-    N = params.get('N')
-    B = global_offsets.shape[0]
-    c = gridsize**2
-
-    # Pad the ground truth image once
-    gt_padded = hh.pad(gt_image[None, ..., None], N // 2)
-
-    # Calculate the combined offsets by adding global and local offsets
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    offsets_f = hh._channel_to_flat(offsets_c)
-
-    # Create a canvas to store the extracted patches
-    canvas = np.zeros((B, N, N, c))
-
-    # Iterate over the combined offsets and extract patches one by one
-    for i in range(B * c):
-        offset = -offsets_f[i, :, :, 0]
-        translated_patch = hh.translate(gt_padded, offset)
-        canvas[i // c, :, :, i % c] = np.array(translated_patch)[0, :N, :N, 0]
-
-    # Convert the canvas to a TensorFlow tensor and return it
-    return tf.convert_to_tensor(canvas)
-
-#@debug
-def group_coords(xcoords: np.ndarray, ycoords: np.ndarray, K: int, C: Optional[int], nsamples: int) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int): Number of nearest neighbors to consider.
-        C (Optional[int]): Number of coordinates per solution region. If None, uses gridsize^2.
-        nsamples (int): Number of samples to generate.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray]: A tuple containing:
-            - nn_indices: shape (M, C)
-            - coords_nn: shape (M, 1, 2, C)
-    """
-    gridsize = params.get('gridsize')
-    if C is None:
-        C = gridsize**2
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords, ycoords)
-    else:
-        nn_indices = get_neighbor_indices(xcoords, ycoords, K=K)
-        nn_indices = sample_rows(nn_indices, C, nsamples).reshape(-1, C)
-
-    coords_nn = np.transpose(np.array([xcoords[nn_indices],
-                            ycoords[nn_indices]]),
-                            [1, 0, 2])[:, None, :, :]
-    return nn_indices, coords_nn[:, :, :, :]
-
-#@debug
-def get_relative_coords(coords_nn):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, 1, 2, C).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    assert len(coords_nn.shape) == 4
-    coords_offsets = np.mean(coords_nn, axis=3)[..., None]
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-    return coords_offsets, coords_relative
-
-#@debug
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    Assign each pattern index to itself.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-
-    Returns:
-        np.ndarray: Array of self-indices.
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-#@debug
-def get_neighbor_indices(xcoords, ycoords, K = 3):
-    """
-    Get K nearest neighbor indices for each point.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors to find. Defaults to 3.
-
-    Returns:
-        np.ndarray: Array of nearest neighbor indices.
-    """
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-#@debug
-def sample_rows(indices, n, m):
-    """
-    Sample rows from the given indices.
-
-    Args:
-        indices (np.ndarray): Array of indices to sample from.
-        n (int): Number of samples per row.
-        m (int): Number of rows to generate.
-
-    Returns:
-        np.ndarray: Sampled indices array.
-    """
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-#@debug
-def get_neighbor_diffraction_and_positions(ptycho_data, N, K=6, C=None, nsamples=10):
-    """
-    Get neighbor diffraction patterns and positions.
-
-    Args:
-        ptycho_data (RawData): An instance of the RawData class.
-        N (int): Size of the solution region.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        dict: A dictionary containing grouped data and metadata.
-    """
-    nn_indices, coords_nn = group_coords(ptycho_data.xcoords, ptycho_data.ycoords,
-                                         K = K, C = C, nsamples = nsamples)
-
-    diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-    if ptycho_data.Y is not None:
-        Y4d_nn = np.transpose(ptycho_data.Y[nn_indices], [0, 2, 3, 1])
-    else:
-        Y4d_nn = None
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if ptycho_data.xcoords_start is not None:
-        coords_start_nn = np.transpose(np.array([ptycho_data.xcoords_start[nn_indices], ptycho_data.ycoords_start[nn_indices]]),
-                                       [1, 0, 2])[:, None, :, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'Y': Y4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    """
-    Normalize the diffraction data.
-
-    Args:
-        dset (dict): Dictionary containing the dataset.
-        N (int): Size of the solution region.
-
-    Returns:
-        np.ndarray: Normalized diffraction data.
-    """
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    return X_full_norm * X_full
-
diff --git a/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py b/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
deleted file mode 100644
index e283054..0000000
--- a/build/lib/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import numpy as np
-from ptycho.nongrid_simulation import generate_simulated_data
-from ptycho.loader import RawData
-import os
-import shutil
-
-def test_memoize_simulated_data():
-    # Create sample input data
-    objectGuess = np.random.rand(128, 128) + 1j * np.random.rand(128, 128)
-    probeGuess = np.random.rand(32, 32) + 1j * np.random.rand(32, 32)
-    nimages = 100
-    buffer = 10
-    random_seed = 42
-
-    # Clear the cache directory before starting the test
-    cache_dir = 'memoized_simulated_data'
-    if os.path.exists(cache_dir):
-        shutil.rmtree(cache_dir)
-
-    # First call, should compute the result and cache it
-    result1 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result1, tuple), "Result should be a tuple"
-    assert len(result1) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result1[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result1[1], np.ndarray), "Second element should be a numpy array"
-
-    # Second call, should load the result from the cache
-    result2 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result2, tuple), "Result should be a tuple"
-    assert len(result2) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result2[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result2[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are identical
-    assert np.array_equal(result1[0].diff3d, result2[0].diff3d), "Cached result differs from original"
-    assert np.array_equal(result1[1], result2[1]), "Cached patches differ from original"
-
-    # Third call with different random seed, should compute a new result
-    result3 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed=123)
-    assert isinstance(result3, tuple), "Result should be a tuple"
-    assert len(result3) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result3[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result3[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are different
-    assert not np.array_equal(result1[0].diff3d, result3[0].diff3d), "Results with different seeds should differ"
-
-    print("All tests passed successfully!")
-
-if __name__ == "__main__":
-    test_memoize_simulated_data()
diff --git a/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py b/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py
deleted file mode 100644
index e56140a..0000000
--- a/build/lib/build/lib/build/lib/ptycho/tests/test_model_manager.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from tensorflow.keras.models import Sequential
-from tensorflow.keras.layers import Dense
-from ptycho.model_manager import ModelManager
-
-def test_save_and_load_model():
-    # Create a simple model for testing
-    model = Sequential([
-        Dense(64, activation='relu', input_shape=(32,)),
-        Dense(10, activation='softmax')
-    ])
-    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
-
-    # Define custom objects and intensity scale for testing
-    custom_objects = {'custom_activation': tf.nn.relu}
-    intensity_scale = 2.5
-
-    # Save the model
-    model_path = 'test_model.h5'
-    ModelManager.save_model(model, model_path, custom_objects, intensity_scale)
-
-    # Ensure the .dill file is created
-    assert os.path.exists(model_path + ".dill")
-
-    # Load the model
-    loaded_model = ModelManager.load_model(model_path)
-
-    # Check if the loaded model has the same architecture
-    assert np.array_equal(model.get_weights()[0], loaded_model.get_weights()[0])
-
-    # Clean up
-    os.remove(model_path)
-    os.remove(model_path + ".dill")
diff --git a/build/lib/build/lib/build/lib/ptycho/tf_helper.py b/build/lib/build/lib/build/lib/ptycho/tf_helper.py
deleted file mode 100644
index fc1233f..0000000
--- a/build/lib/build/lib/build/lib/ptycho/tf_helper.py
+++ /dev/null
@@ -1,707 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional, Union, Callable, Any
-
-# Check if there are any GPUs available and set memory growth accordingly
-physical_devices = tf.config.list_physical_devices('GPU')
-if physical_devices:
-    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
-    tf.config.experimental.set_memory_growth(physical_devices[0], True)
-else:
-    print("No GPU found, using CPU instead.")
-
-
-import tensorflow.compat.v2 as tf
-tf.enable_v2_behavior()
-
-from tensorflow.keras import Model
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, UpSampling2D
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import tensorflow_probability as tfp
-
-from .params import params, cfg, get, get_padded_size
-#from .logging import debug
-from .autotest.debug import debug
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-support_threshold = .0
-#@debug
-def get_mask(input: tf.Tensor, support_threshold: float) -> tf.Tensor:
-    mask = tf.where(input > support_threshold, tf.ones_like(input),
-                    tf.zeros_like(input))
-    return mask
-
-#@debug
-def combine_complex(amp: tf.Tensor, phi: tf.Tensor) -> tf.Tensor:
-    output = tf.cast(amp, tf.complex64) * tf.exp(
-        1j * tf.cast(phi, tf.complex64))
-    return output
-
-#@debug
-def pad_obj(input: tf.Tensor, h: int, w: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((h // 4, w // 4), name = 'padded_obj')(input)
-
-#@debug
-def pad_and_diffract(input: tf.Tensor, h: int, w: int, pad: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses sysmmetric FT - L2 norm is conserved
-    """
-    input = tf.ensure_shape(input, (None, h, w, 1))
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = (((fft2d(
-        (tf.cast((input), tf.complex64))[..., 0]
-        ))))
-    input = (( tf.math.real(tf.math.conj((input)) * input) / (h * w)))
-    input = (( tf.expand_dims(
-                              tf.math.sqrt(
-            fftshift(input, (-2, -1))), 3)
-        ))
-    return padded, input
-
-#@debug
-def _fromgrid(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return tf.reshape(img, (-1, N, N, 1))
-
-#@debug
-def _togrid(img: tf.Tensor, gridsize: Optional[int] = None, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e. from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return tf.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-#@debug
-def togrid(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return [_togrid(img) for img in imgs]
-
-#@debug
-def _grid_to_channel(grid: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = tf.transpose(grid, [0, 3, 4, 1, 2, 5], conjugate=False)
-    _, ww, hh = img.shape[:3]
-    img = tf.reshape(img, (-1, ww, hh, gridsize**2))
-    return img
-
-#@debug
-def grid_to_channel(*grids: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_grid_to_channel(g) for g in grids]
-
-#@debug
-def _flat_to_channel(img: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = tf.reshape(img, (-1, gridsize**2, N, N))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _flat_to_channel_2(img: tf.Tensor) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = tf.reshape(img, (-1, gridsize**2, N, M))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _channel_to_flat(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    shape = tf.shape(img)
-    b, h, w, c = shape[0], shape[1], shape[2], shape[3]
-    #_, h, w, c = img.shape
-    img = tf.transpose(img, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, h, w, 1))
-    return img
-
-#@debug
-def _channel_to_patches(channel: tf.Tensor) -> tf.Tensor:
-    """
-    reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = tf.transpose(channel, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-#@debug
-def channel_to_flat(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_channel_to_flat(g) for g in imgs]
-
-#@debug
-def extract_patches(x: tf.Tensor, N: int, offset: int) -> tf.Tensor:
-    return tf.image.extract_patches(
-        x,
-        [1, N, N, 1],
-        [1, offset,offset, 1],
-        [1, 1, 1, 1],
-        padding="VALID"
-    )
-
-#@debug
-def extract_outer(img: tf.Tensor, fmt: str = 'grid',
-        bigN: Optional[int] = None, outer_offset: Optional[int] = None) -> tf.Tensor:#,
-    """
-        Extract big patches (overlapping bigN x bigN regions over an
-        entire input img)
-    """
-    if bigN is None:
-        bigN = get('bigN')
-    assert img.shape[-1] == 1
-    grid = tf.reshape(
-        extract_patches(img, bigN, outer_offset // 2),
-        (-1, bigN, bigN, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)
-    else:
-        raise ValueError
-
-#@debug
-def extract_inner_grid(grid: tf.Tensor) -> tf.Tensor:
-    N = cfg['N']
-    offset = params()['offset']
-    return extract_patches(grid, N, offset)
-
-#@debug
-def extract_nested_patches(img: tf.Tensor, fmt: str = 'flat',
-        extract_inner_fn: Callable[[tf.Tensor], tf.Tensor] = extract_inner_grid,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-
-    This function and extract_outer are only used to extract nominal
-    coordinates, so it is not necessary for them to use jitter padding
-    """
-    N = cfg['N']
-    offset = params()['offset']
-    gridsize = params()['gridsize']
-    assert img.shape[-1] == 1
-    outer_grid = extract_outer(img, fmt = 'grid', **kwargs)
-    grid = tf.reshape(
-        extract_inner_fn(outer_grid),
-        (-1, gridsize, gridsize, N, N, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)#, outer_grid # TODO second output is for debugging
-    else:
-        raise ValueError
-
-#@debug
-def mk_extract_inner_position(offsets_xy: tf.Tensor) -> Callable[[tf.Tensor], Tuple[tf.Tensor]]:
-    #@debug
-    def inner(grid: tf.Tensor) -> Tuple[tf.Tensor]:
-        return extract_patches_position(grid, offsets_xy),
-    return inner
-
-#@debug
-def extract_nested_patches_position(img: tf.Tensor, offsets_xy: tf.Tensor, fmt: str = 'flat',
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-    """
-    return extract_nested_patches(img, fmt = fmt,
-        extract_inner_fn = mk_extract_inner_position(offsets_xy),
-        **kwargs)
-
-@tf.function
-#@debug
-def extract_patches_inverse(y: tf.Tensor, N: int, average: bool, gridsize: Optional[int] = None, offset: Optional[int] = None) -> tf.Tensor:
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if offset is None:
-        offset = params()['offset']
-    target_size = N + (gridsize - 1) * offset
-    b = tf.shape(y)[0]
-
-    _x = tf.zeros((b, target_size, target_size, 1), dtype = y.dtype)
-    _y = extract_patches(_x, N, offset)
-    if average:
-        grad = tf.gradients(_y, _x)[0]
-        return tf.gradients(_y, _x, grad_ys=y)[0] / grad
-    else:
-        return tf.gradients(_y, _x, grad_ys=y)[0]
-
-#@debug
-def reassemble_patches_real(channels: tf.Tensor, average: bool = True, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = _channel_to_patches(channels)
-    N = params()['N']
-    return extract_patches_inverse(real, N, average, **kwargs)
-
-#@debug
-def pad_patches(imgs: tf.Tensor, padded_size: Optional[int] = None) -> tf.Tensor:
-    N = params()['N']
-    if padded_size is None:
-        padded_size = get_padded_size()
-    return tfkl.ZeroPadding2D(((padded_size - N) // 2, (padded_size - N) // 2))(imgs)
-
-#@debug
-def pad(imgs: tf.Tensor, size: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((size, size))(imgs)
-
-#@debug
-def trim_reconstruction(x: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert int(shape[1]) == int(shape[2])
-    try:
-        clipsize = (int(shape[1]) - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize: -clipsize,
-            clipsize: -clipsize, :]
-
-#@debug
-def extract_patches_position(imgs: tf.Tensor, offsets_xy: tf.Tensor, jitter: float = 0.) -> tf.Tensor:
-    """
-    Expects offsets_xy in channel format.
-
-    imgs must be in flat format with a single image per solution region, i.e.
-    (batch size, M, M, 1) where M = N + some padding size.
-
-    Returns shifted images in channel format, cropped symmetrically
-
-    no negative sign
-    """
-    if  imgs.get_shape()[0] is not None:
-        assert int(imgs.get_shape()[0]) == int(offsets_xy.get_shape()[0])
-    assert int(imgs.get_shape()[3]) == 1
-    assert int(offsets_xy.get_shape()[2]) == 2
-    assert int(imgs.get_shape()[3]) == 1
-    gridsize = params()['gridsize']
-    assert int(offsets_xy.get_shape()[3]) == gridsize**2
-    offsets_flat = flatten_offsets(offsets_xy)
-    stacked = tf.repeat(imgs, gridsize**2, axis = 3)
-    flat_padded = _channel_to_flat(stacked)
-    channels_translated = trim_reconstruction(
-        Translation()([flat_padded, offsets_flat, jitter]))
-    return channels_translated
-
-#@debug
-def center_channels(channels: tf.Tensor, offsets_xy: tf.Tensor) -> tf.Tensor:
-    """
-    Undo image patch offsets
-    """
-    ct = Translation()([_channel_to_flat(channels), flatten_offsets(-offsets_xy), 0.])
-    channels_centered = _flat_to_channel(ct)
-    return channels_centered
-
-#@debug
-def is_complex_tensor(tensor: tf.Tensor) -> bool:
-    """Check if the tensor is of complex dtype."""
-    return tensor.dtype in [tf.complex64, tf.complex128]
-
-#@debug
-def complexify_helper(separate: Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]], combine: Callable[[tf.Tensor, tf.Tensor], tf.Tensor]) -> Callable:
-    """
-    Create a "complexify" function based on the provided separation and combination methods.
-    """
-    #@debug
-    def complexify(fn: Callable[..., tf.Tensor]) -> Callable[..., tf.Tensor]:
-        #@debug
-        def newf(*args: Any, **kwargs: Any) -> tf.Tensor:
-            channels = args[0]
-            if is_complex_tensor(channels):
-                part1, part2 = separate(channels)
-                assembled_part1 = fn(part1, *args[1:], **kwargs)
-                assembled_part2 = fn(part2, *args[1:], **kwargs)
-                return combine(assembled_part1, assembled_part2)
-            else:
-                return fn(*args, **kwargs)
-        return newf
-    return complexify
-
-#@debug
-def separate_real_imag(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.real(channels), tf.math.imag(channels)
-
-#@debug
-def combine_real_imag(real: Union[tf.Tensor, np.ndarray], imag: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:
-    return tf.cast(tf.dtypes.complex(real, imag), tf.complex64)
-
-#@debug
-def separate_amp_phase(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.abs(channels), tf.math.angle(channels)
-
-complexify_function = complexify_helper(separate_real_imag, combine_real_imag)
-complexify_amp_phase = complexify_helper(separate_amp_phase, combine_complex)
-complexify_sum_amp_phase = complexify_helper(separate_amp_phase, lambda a, b: a + b)
-complexify_sum_real_imag = complexify_helper(separate_real_imag, lambda a, b: a + b)
-
-
-from tensorflow_addons.image import translate as _translate
-
-#from ptycho.misc import debug
-@complexify_function
-#@debug
-def translate(imgs: tf.Tensor, offsets: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    # TODO assert dimensionality of translations is 2; i.e. B, 2
-    return _translate(imgs, offsets, **kwargs)
-
-# TODO consolidate this and translate()
-class Translation(tf.keras.layers.Layer):
-    def __init__(self) -> None:
-        super(Translation, self).__init__()
-    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor, float]) -> tf.Tensor:
-        imgs, offsets, jitter = inputs
-        jitter = tf.random.normal(tf.shape(offsets), stddev = jitter)
-        return translate(imgs, offsets + jitter, interpolation = 'bilinear')
-
-#@debug
-def flatten_offsets(channels: tf.Tensor) -> tf.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-#@debug
-def pad_reconstruction(channels: tf.Tensor) -> tf.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-#@debug
-def _reassemble_patches_position_real(imgs: tf.Tensor, offsets_xy: tf.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, 0.])
-    if agg:
-        imgs_merged = tf.reduce_sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N = padded_size),
-                    axis = 3)[..., None]
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N = padded_size)
-
-#@debug
-def mk_centermask(inputs: tf.Tensor, N: int, c: int, kind: str = 'center') -> tf.Tensor:
-    b = tf.shape(inputs)[0]
-#    if get('probe.big'):
-#        ones = tf.ones((b, N, N, c), dtype = inputs.dtype)
-#    else:
-#        ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-#        ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-    ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-#@debug
-def mk_norm(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor]) -> tf.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    # TODO if probe.big is True, shouldn't the ones fill the full N x N region?
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average = False)
-    norm = assembled_ones + .001
-    return norm
-
-#@debug
-def reassemble_patches(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = tf.math.real(channels)
-    imag = tf.math.imag(channels)
-    assembled_real = fn_reassemble_real(real, average = average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average = average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return tf.dtypes.complex(assembled_real, assembled_imag)
-
-#@debug
-def shift_and_sum(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    from . import tf_helper as hh
-    assert len(obj_tensor.shape) == 4
-    assert obj_tensor.dtype == np.complex64
-    assert len(global_offsets.shape) == 4
-    assert global_offsets.dtype == np.float64
-    # Extract necessary parameters
-    N = params()['N']
-    # Select the central part of the object tensor
-    obj_tensor = obj_tensor[:, N // 2 - M // 2: N // 2 + M // 2, N // 2 - M // 2: N // 2 + M // 2, :]
-    # Calculate the center of mass of global_offsets
-    center_of_mass = tf.reduce_mean(tf.cast(global_offsets, tf.float32), axis=0)
-    # Adjust global_offsets by subtracting the center of mass
-    adjusted_offsets = tf.cast(global_offsets, tf.float32) - center_of_mass
-    # Calculate dynamic padding based on maximum adjusted offset
-    max_offset = tf.reduce_max(tf.abs(adjusted_offsets))
-    dynamic_pad = int(tf.cast(tf.math.ceil(max_offset), tf.int32))
-    print('PADDING SIZE:', dynamic_pad)
-    
-    # Create a canvas to store the shifted and summed object tensors
-    result = tf.zeros_like(hh.pad(obj_tensor[0:1], dynamic_pad))
-    
-    # Iterate over the adjusted offsets and perform shift-and-sum
-    for i in range(len(adjusted_offsets)):
-        # Apply dynamic padding to the current object tensor
-        padded_obj_tensor = hh.pad(obj_tensor[i:i+1], dynamic_pad)
-        # Squeeze and cast adjusted offset to 2D float for translation
-        offset_2d = tf.cast(tf.squeeze(adjusted_offsets[i]), tf.float32)
-        # Translate the padded object tensor
-        translated_obj = hh.translate(padded_obj_tensor, offset_2d, interpolation='bilinear')
-        # Accumulate the translated object tensor
-        result += translated_obj[0]
-    
-    # TODO: how could we support multiple scans?
-    return result[0]
-
-#@debug
-def reassemble_whole_object(patches: tf.Tensor, offsets: tf.Tensor, size: int = 226, norm: bool = False) -> tf.Tensor:
-    """
-    patches: tensor of shape (B, N, N, gridsize**2) containing reconstruction patches
-
-    reassembles the NxN patches into a single size x size x 1 mage, given the
-        provided offsets
-
-    This function inverts the offsets, so it's not necessary to multiply by -1
-    """
-    img = tf.reduce_sum(
-        reassemble_patches(patches, fn_reassemble_real=mk_reassemble_position_real(
-        offsets, padded_size = size)),
-        axis = 0)
-    if norm:
-        return img / reassemble_whole_object(tf.ones_like(patches), offsets, size = size, norm = False)
-    return img
-
-def reassemble_position(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    ones = tf.ones_like(obj_tensor)
-    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
-        (1e-9 + shift_and_sum(ones, global_offsets, M = M))
-
-#@debug
-def mk_reassemble_position_real(input_positions: tf.Tensor, **outer_kwargs: Any) -> Callable[[tf.Tensor], tf.Tensor]:
-    #@debug
-    def reassemble_patches_position_real(imgs: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-#@debug
-def preprocess_objects(Y_I: np.ndarray, Y_phi: Optional[np.ndarray] = None,
-        offsets_xy: Optional[tf.Tensor] = None, **kwargs: Any) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
-    """
-    Extracts normalized object patches from full real-space images, using the
-    nested grid format.
-    """
-    _Y_I_full = Y_I
-    if Y_phi is None:
-        Y_phi = np.zeros_like(Y_I)
-
-    if offsets_xy is None or tf.math.reduce_all(offsets_xy == 0):
-        print('Sampling on regular grid')
-        Y_I, Y_phi = \
-            [extract_nested_patches(imgs, fmt= 'channel', **kwargs)
-                for imgs in [Y_I, Y_phi]]
-    else:
-        print('Using provided scan point offsets')
-        Y_I, Y_phi = \
-            [extract_nested_patches_position(imgs, offsets_xy, fmt= 'channel',
-                    **kwargs)
-                for imgs in [Y_I, Y_phi]]
-
-    assert Y_I.shape[-1] == get('gridsize')**2
-    norm_Y_I = tf.math.reduce_max(Y_I, axis = (1, 2, 3))[:, None, None, None]
-    norm_Y_I = tf.math.reduce_mean(norm_Y_I)
-    Y_I /= norm_Y_I
-
-    Y_I, Y_phi =\
-        channel_to_flat(Y_I, Y_phi)
-    return Y_I, Y_phi, _Y_I_full / norm_Y_I, norm_Y_I
-
-#@debug
-def reassemble_nested_average(output_tensor: tf.Tensor, cropN: Optional[int] = None, M: Optional[int] = None, n_imgs: int = 1,
-        offset: int = 4) -> tf.Tensor:
-    """
-    Stitch reconstruction patches from (first) model output into full
-    reconstructed images, averaging the overlaps
-    """
-    assert len(output_tensor.shape) == 4
-    bsize = int(output_tensor.shape[0] / n_imgs)
-    output_tensor = output_tensor[:bsize, ...]
-    if M is None:
-        M = int(np.sqrt(bsize))
-    if cropN is None:
-        cropN = params.params()['cropN']
-    patches = _togrid(trim_reconstruction(output_tensor, cropN), gridsize = M,
-        N = cropN)
-    patches = tf.reshape(patches, (-1, M, M, cropN**2))
-    obj_recon = complexify_function(extract_patches_inverse)(patches, cropN,
-        True, gridsize = M, offset = offset)
-    return obj_recon
-
-
-#@debug
-def gram_matrix(input_tensor: tf.Tensor) -> tf.Tensor:
-    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
-    input_shape = tf.shape(input_tensor)
-    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
-    return result/(num_locations)
-
-#@debug
-def high_pass_x_y(image: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
-    x_var = image[:,:,1:,:] - image[:,:,:-1,:]
-    y_var = image[:,1:,:,:] - image[:,:-1,:,:]
-    return x_var, y_var
-
-pp = tfk.Sequential([
-    Lambda(lambda x: tf.image.grayscale_to_rgb(x)),
-])
-#@debug
-def perceptual_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    """
-    target = pp(target)
-    pred = pp(pred)
-
-    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-    vgg.trainable = False
-
-    outputs = [vgg.get_layer('block2_conv2').output]
-    feat_model = Model(vgg.input, outputs)
-    activatedModelVal = feat_model(pred)
-    actualModelVal = feat_model(target)
-    return meanSquaredLoss(gram_matrix(actualModelVal),gram_matrix(activatedModelVal))
-
-#@debug
-def meanSquaredLoss(y_true: tf.Tensor, y_pred: tf.Tensor, center_target: bool = True) -> tf.Tensor:
-    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))
-
-#@debug
-def masked_MAE_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    bigN
-    """
-    mae = tf.keras.metrics.mean_absolute_error
-    mask = params()['probe_mask']
-    pred = trim_reconstruction(
-            reassemble_patches(mask * pred))
-    target = trim_reconstruction(
-            reassemble_patches(tf.math.abs(mask) * target))
-    return mae(target, pred)
-
-
-@complexify_sum_real_imag
-#@debug
-def total_variation_complex(obj: tf.Tensor) -> tf.Tensor:
-    """ calculate summed total variation of the real and imaginary components
-        of a tensor
-    """
-    x_deltas, y_deltas = high_pass_x_y(obj)
-    return tf.reduce_sum(x_deltas**2) + tf.reduce_sum(y_deltas**2)
-
-#@debug
-def total_variation(obj: tf.Tensor, amp_only: bool = False) -> tf.Tensor:
-    if amp_only:
-        obj = Lambda(lambda x: tf.math.abs(x))(obj)
-    return total_variation_complex(obj)
-
-@complexify_sum_amp_phase
-#@debug
-def complex_mae(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    mae = tf.keras.metrics.mean_absolute_error
-    return mae(target, pred)
-
-#@debug
-def masked_mae(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    mae = tf.keras.metrics.mean_absolute_error
-    pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-    return mae(target, pred)
-
-#@debug
-def realspace_loss(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    if not get('probe.big'):
-        pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-
-    if get('tv_weight') > 0:
-        tv_loss = total_variation(pred) * get('tv_weight')
-    else:
-        tv_loss = 0.
-
-    if get('realspace_mae_weight') > 0:
-        mae_loss = complex_mae(target, pred) * get('realspace_mae_weight')
-    else:
-        mae_loss = 0.
-    return tv_loss + mae_loss
diff --git a/build/lib/build/lib/build/lib/ptycho/train.py b/build/lib/build/lib/build/lib/ptycho/train.py
deleted file mode 100644
index 7f93781..0000000
--- a/build/lib/build/lib/build/lib/ptycho/train.py
+++ /dev/null
@@ -1,121 +0,0 @@
-# train.py
-
-import os
-from ptycho.model_manager import ModelManager
-from ptycho import model_manager
-from ptycho.export import save_recons
-from datetime import datetime
-import matplotlib
-import matplotlib.pyplot as plt
-import dill
-import argparse
-from ptycho import params
-from ptycho import misc
-import numpy as np
-import h5py
-
-plt.rcParams["figure.figsize"] = (10, 10)
-matplotlib.rcParams['font.size'] = 12
-
-save_model = True
-save_data = False
-
-parser = argparse.ArgumentParser(description='Script to set attributes for ptycho program')
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(
-                        prog = 'PtychoPINN',
-                        description = 'Generate / load data and train the model',
-                        )
-    parser.add_argument('--model_type', type=str, default='pinn', help='model type (pinn or supervised)')
-    parser.add_argument('--output_prefix', type=str, default='lines2', help='output directory prefix')
-    parser.add_argument('--data_source', type=str, default='lines', help='Dataset specification')
-    parser.add_argument('--set_phi', action='store_true', default=False, help='If true, simulated objects are given non-zero phase')
-    parser.add_argument('--nepochs', type=int, default=60, help='Number of epochs')
-    parser.add_argument('--offset', type=int, default=4, help='Scan point spacing for simulated (grid-sampled) data')
-    parser.add_argument('--gridsize', type=int, default=2, help='Solution region grid size (e.g. 2 -> 2x2, etc.)')
-    parser.add_argument('--object_big', type=bool, default=True, help='If true, reconstruct the entire solution region for each set of patterns, instead of just the central N x N region.')
-    parser.add_argument('--nll_weight', type=float, default=1., help='Diffraction reconstruction NLL loss weight')
-    parser.add_argument('--mae_weight', type=float, default=0., help='Diffraction reconstruction MAE loss weight')
-    parser.add_argument('--nimgs_train', type=int, default=params.cfg['nimgs_train'], help='Number of generated training images')
-    parser.add_argument('--nimgs_test', type=int, default=params.cfg['nimgs_test'], help='Number of generated testing images')
-    parser.add_argument('--outer_offset_train', type=int, default=None, help='Scan point grid offset for (generated) training datasets')
-    parser.add_argument('--outer_offset_test', type=int, default=None, help='Scan point grid offset for (generated) testing datasets')
-    parser.add_argument('--n_filters_scale', type=int, default=2, help='Number of filters scale')
-    parser.add_argument('--max_position_jitter', type=int, default=10, help='Solution region is expanded around the edges by this amount')
-    parser.add_argument('--intensity_scale_trainable', type=bool, default=True, help='If true, sets the model-internal normalization of diffraction amplitudes to trainable')
-    parser.add_argument('--positions_provided', type=bool, default=False, help='[deprecated] Whether nominal or true (nominal + jitter) positions are provided in simulation runs')
-    parser.add_argument('--label', type=str, default='', help='[deprecated] Name of this run')
-    args = parser.parse_args()
-
-    model_type = params.cfg['model_type'] = args.model_type
-    label = params.cfg['label'] = args.label
-    params.cfg['positions.provided'] = args.positions_provided
-    params.cfg['data_source'] = args.data_source
-    params.cfg['set_phi'] = args.set_phi
-    params.cfg['nepochs'] = args.nepochs
-    offset = params.cfg['offset'] = args.offset
-    params.cfg['max_position_jitter'] = args.max_position_jitter
-    params.cfg['output_prefix'] = args.output_prefix
-    params.cfg['gridsize'] = args.gridsize
-    params.cfg['n_filters_scale'] = args.n_filters_scale
-    params.cfg['object.big'] = args.object_big
-    params.cfg['intensity_scale.trainable'] = args.intensity_scale_trainable
-    params.cfg['nll_weight'] = args.nll_weight
-    params.cfg['mae_weight'] = args.mae_weight
-    params.cfg['nimgs_train'] = args.nimgs_train
-    params.cfg['nimgs_test'] = args.nimgs_test
-    params.cfg['outer_offset_train'] = args.outer_offset_train
-    params.cfg['outer_offset_test'] = args.outer_offset_test
-else:
-    model_type = params.cfg['model_type']
-    label = params.cfg['label']
-    offset = params.cfg['offset']
-params.cfg['output_prefix'] = misc.get_path_prefix()
-
-out_prefix = params.get('output_prefix')
-os.makedirs(out_prefix, exist_ok=True)
-
-from ptycho import generate_data
-ptycho_dataset = generate_data.ptycho_dataset
-YY_ground_truth = generate_data.YY_ground_truth
-YY_test_full = generate_data.YY_test_full
-Y_I_test = generate_data.Y_I_test
-Y_phi_test = generate_data.Y_phi_test
-X_test = generate_data.X_test
-norm_Y_I_test = generate_data.norm_Y_I_test
-from ptycho import model
-from ptycho.evaluation import save_metrics
-
-if model_type == 'pinn':
-    from ptycho import train_pinn
-    print("DEBUG: generate_data diff norm {}".format(np.mean(np.abs(ptycho_dataset.train_data.X))))
-    train_output = train_pinn.train_eval(ptycho_dataset)
-    pred_amp = train_output['pred_amp']
-    history = train_output['history']
-    reconstructed_obj = train_output['reconstructed_obj']
-    stitched_obj = train_output['stitched_obj']
-
-elif model_type == 'supervised':
-    from ptycho.train_supervised import stitched_obj
-    from ptycho import train_supervised
-    history = train_supervised.history
-    reconstructed_obj = train_supervised.reconstructed_obj
-else:
-    raise ValueError
-
-d = save_recons(model_type, stitched_obj)
-
-with open(out_prefix + '/history.dill', 'wb') as file_pi:
-    dill.dump(history.history, file_pi)
-
-if save_model:
-    model_manager.save(out_prefix)
-
-if save_data:
-    with open(out_prefix + '/test_data.dill', 'wb') as f:
-        dill.dump(
-            {'YY_test_full': YY_test_full,
-             'Y_I_test': Y_I_test,
-             'Y_phi_test': Y_phi_test,
-             'X_test': X_test}, f)
diff --git a/build/lib/build/lib/build/lib/ptycho/train_pinn.py b/build/lib/build/lib/build/lib/ptycho/train_pinn.py
deleted file mode 100644
index 05fbd5b..0000000
--- a/build/lib/build/lib/build/lib/ptycho/train_pinn.py
+++ /dev/null
@@ -1,121 +0,0 @@
-from ptycho import params
-from .loader import PtychoDataContainer
-from .image import reassemble_patches
-
-def train(train_data: PtychoDataContainer, intensity_scale=None, model_instance=None):
-    from . import params as p
-    # Model requires intensity_scale to be defined to set the initial
-    # value of the corresponding model parameter
-    if intensity_scale is None:
-        intensity_scale = calculate_intensity_scale(train_data)
-    p.set('intensity_scale', intensity_scale)
-
-    from ptycho import probe
-    probe.set_probe_guess(None, train_data.probe)
-
-    from ptycho import model
-    if model_instance is None:
-        model_instance = model.autoencoder
-    nepochs = params.cfg['nepochs']
-    params.print_params()
-    return model_instance, model.train(nepochs, train_data)
-
-def train_eval(ptycho_dataset):
-    ## TODO reconstructed_obj -> pred_Y or something
-    model_instance, history = train(ptycho_dataset.train_data)
-    results = {
-        'history': history,
-        'model_instance': model_instance
-    }
-    if ptycho_dataset.test_data is not None:
-        eval_results = eval(ptycho_dataset.test_data, history, trained_model=model_instance)
-        # Get config from the dataset
-        config = ptycho_dataset.test_data.config if hasattr(ptycho_dataset.test_data, 'config') else params.cfg
-        try:
-            stitched_obj = reassemble_patches(eval_results['reconstructed_obj'], config, part='complex')
-        except ValueError as e:
-            print(e)
-            stitched_obj = None
-
-        results.update({
-            'reconstructed_obj': eval_results['reconstructed_obj'],
-            'pred_amp': eval_results['pred_amp'],
-            'reconstructed_obj_cdi': eval_results['reconstructed_obj_cdi'],
-            'stitched_obj': stitched_obj,
-        })
-    return results
-
-from tensorflow.keras.models import load_model
-# Enhance the existing eval function to optionally load a model for inference
-def eval(test_data, history=None, trained_model=None, model_path=None):
-    """
-    Evaluate the model on test data. Optionally load a model if a path is provided.
-
-    Parameters:
-    - test_data: The test data for evaluation.
-    - history: Training history, if available.
-    - trained_model: An already trained model instance, if available.
-    - model_path: Path to a saved model, if loading is required.
-
-    Returns:
-    - Evaluation results including reconstructed objects and prediction amplitudes.
-    """
-    from ptycho.data_preprocessing import reassemble
-
-    from ptycho import probe
-    probe.set_probe_guess(None, test_data.probe)
-    # TODO enforce that the train and test probes are the same
-    print('INFO:', 'setting probe from test data container. It MUST be consistent with the training probe')
-
-    from ptycho import model
-    if model_path is not None:
-        print(f"Loading model from {model_path}")
-        trained_model = load_model(model_path)
-    elif trained_model is None:
-        raise ValueError("Either a trained model instance or a model path must be provided.")
-
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = trained_model.predict(
-        [test_data.X * model.params()['intensity_scale'], test_data.coords_nominal]
-    )
-    try:
-        stitched_obj = reassemble(reconstructed_obj, part='complex')
-    except (ValueError, TypeError) as e:
-        stitched_obj = None
-        print('Object stitching failed:', e)
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi,
-        'stitched_obj': stitched_obj
-    }
-
-def calculate_intensity_scale(ptycho_data_container: PtychoDataContainer) -> float:
-    import tensorflow as tf
-    import numpy as np
-    from . import params as p
-    def count_photons(obj):
-        pcount = np.mean(tf.math.reduce_sum(obj**2, (1, 2)))
-        return pcount
-
-    def scale_nphotons(X):
-        # TODO assumes X is already normalized. this should be enforced
-        return tf.math.sqrt(p.get('nphotons')) / (p.get('N') / 2)
-
-    # Calculate the intensity scale using the adapted scale_nphotons function
-    intensity_scale = scale_nphotons(ptycho_data_container.X).numpy()
-
-    return intensity_scale
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_eval_result(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/ptycho/train_supervised.py b/build/lib/build/lib/build/lib/ptycho/train_supervised.py
deleted file mode 100644
index 3ab4e9f..0000000
--- a/build/lib/build/lib/build/lib/ptycho/train_supervised.py
+++ /dev/null
@@ -1,73 +0,0 @@
-from ptycho.generate_data import *
-from ptycho import tf_helper as hh
-from ptycho import baselines as bl
-from ptycho import params as p
-from ptycho.image import reassemble_patches
-
-offset = p.get('offset')
-
-# For comparison to the 'baseline' model (PtychoNN) we need to crop/shift in a different way
-def xyshift(arr4d, dx, dy):
-    assert len(arr4d.shape) == 4
-    from scipy.ndimage.interpolation import shift
-    arr4d = np.roll(arr4d, dx, axis = 1)
-    arr4d = np.roll(arr4d, dy, axis = 2)
-    return arr4d
-
-def get_recon_patches_single_channel(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0] * bl.params.params()['intensity_scale']])
-    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-#    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0]])
-#    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-
-def get_recon_patches_grid(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_overlap_pred_I, baseline_overlap_pred_phi = model.predict(
-        [X_test[:, :, :, :4]  * bl.params.params()['intensity_scale']])
-    obj_stitched = hh.combine_complex(baseline_overlap_pred_I[:, :, :, :1], baseline_overlap_pred_phi[:, :, :, :1])
-    return xyshift(obj_stitched, -offset // 2, -offset // 2)
-
-if p.cfg['gridsize'] == 2:
-    model, history = bl.train((X_train[:, :, :, :4]),
-                              Y_I_train[:, :, :, :4], Y_phi_train[:, :, :, :4])
-
-    reconstructed_obj = get_recon_patches_grid(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-elif p.cfg['gridsize'] == 1:
-    model, history = bl.train((X_train[:, :, :, :1]), Y_I_train[:, :, :, :1], Y_phi_train[:, :, :, :1])
-
-    # TODO match above
-    reconstructed_obj = get_recon_patches_single_channel(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-    reconstructed_obj_train = get_recon_patches_single_channel(X_train)
-
-else:
-    raise ValueError
-
-try:
-    stitched_obj = reassemble_patches(reconstructed_obj, config, part='complex')
-except (ValueError, TypeError) as e:
-    print('object stitching failed:', e)
-
-# New alternative implementation 
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_reconstruction(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/build/lib/ptycho/trash/model2.py b/build/lib/build/lib/build/lib/ptycho/trash/model2.py
deleted file mode 100644
index fde7a52..0000000
--- a/build/lib/build/lib/build/lib/ptycho/trash/model2.py
+++ /dev/null
@@ -1,148 +0,0 @@
-from . import tf_helper as hh
-from .params import params
-
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras import Sequential
-from tensorflow.keras.activations import sigmoid, tanh
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras.layers import Lambda
-import glob
-import math
-import numpy as np
-import os
-import tensorflow as tf
-import tensorflow_probability as tfp
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-
-N = params()['N']
-w = params()['w']
-h = params()['h']
-gridsize = params()['gridsize']
-offset = params()['offset']
-tprobe = params()['probe']
-batch_size = params()['batch_size']
-# TODO don't rely on this
-intensity_scale = params()['intensity_scale']
-
-# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N // 2,N // 2,3))
-vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-vgg.trainable = False
-
-outputs = [vgg.get_layer('block2_conv2').output]
-feat_model = Model(vgg.input, outputs)
-# feat_model.trainable = False
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-input_img = Input(shape=(h, w, gridsize**2), name = 'input')
-
-x = hh.Conv_Pool_block(input_img,32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-
-encoded=x
-
-#Decoding arm for amplitude
-x1=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x1=hh.Conv_Up_block(x1,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-decoded1 = Conv2D(gridsize**2, (3, 3), padding='same')(x1)
-decoded1 = Lambda(lambda x: sigmoid(x), name='amp')(decoded1)
-
-#Decoding arm for phase
-x2=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x2=hh.Conv_Up_block(x2,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-#x2=Conv_Up_block(x2,32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-
-decoded2 = Conv2D(gridsize**2, (3, 3), padding='same')(x2)
-decoded2 = Lambda(lambda x: math.pi * tanh(x), name='phi')(decoded2)
-
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]),
-                     name='obj')([decoded1, decoded2])
-
-padded_obj = tfkl.ZeroPadding2D(((h // 4), (w // 4)), name = 'padded_obj')(obj)
-padded_obj_2 = Lambda(lambda x:
-    hh.reassemble_patches(x), name = 'padded_obj_2',
-    )(padded_obj)
-#padded_obj_2 = tfkl.ZeroPadding2D((offset // 2 , offset // 2), name = 'padded_obj_2')(padded_obj)
-
-trimmed_obj = Lambda(lambda x: x[:, (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        :], name = 'trimmed_obj')(padded_obj_2)
-
-# TODO average?
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x: hh.flatten_overlaps(x, fmt = 'flat'), name = 'padded_objs_with_offsets')(padded_obj_2)
-# Apply the probe
-padded_objs_with_offsets = Lambda(lambda x: tf.cast(tprobe, tf.complex64) * x,
-                                  name = 'padded_objs_with_offsets_illuminated')(padded_objs_with_offsets)
-
-# TODO refactor
-# Diffracted amplitude
-padded_objs_with_offsets, pred_diff = hh.pad_and_diffract(padded_objs_with_offsets, h, w, pad=False)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-pred_intensity = tfpl.DistributionLambda(lambda t:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               ((t * intensity_scale)**2))
-                                       )))(pred_diff)
-
-#def mul_gaussian_noise(image):
-#    # image must be scaled in [0, 1]
-#    with tf.name_scope('Add_gaussian_noise'):
-#        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=1, dtype=tf.float32)
-#        noise_img = image * noise
-#    return noise_img
-
-negloglik = lambda x, rv_x: -rv_x.log_prob((x))
-
-# The first output exposes the real space object reconstruction and
-# though it does not contribute to the training loss, it's used to
-# calculate reconstruction errors for evaluation
-autoencoder = Model([input_img], [trimmed_obj, pred_diff, pred_intensity, pred_diff])
-#autoencoder = Model([input_img], [padded_obj, pred_diff, pred_intensity, pred_diff])
-
-encode_obj_to_diffraction = tf.keras.Model(inputs=[padded_obj],
-                           outputs=[pred_diff])
-
-diffraction_to_obj = tf.keras.Model(inputs=[input_img],
-                           outputs=[obj])
-
-autoencoder.compile(optimizer='adam',
-     loss=['mean_absolute_error', 'mean_absolute_error', negloglik, hh.total_variation_loss],
-     loss_weights = [0., 0., 1., 0.])
-
-print (autoencoder.summary())
-#plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-def train(epochs, X_train, Y_I_train):
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.h5' %wt_path,
-                                                monitor='val_loss', verbose=1, save_best_only=True,
-                                                save_weights_only=False, mode='auto', period=1)
-
-
-    history=autoencoder.fit([X_train], [Y_I_train, X_train, (intensity_scale * X_train)**2,
-                                       X_train], shuffle=True, batch_size=batch_size, verbose=1,
-                               epochs=epochs, validation_split = 0.05, callbacks=[reduce_lr, earlystop, checkpoints])
-    return history
diff --git a/build/lib/build/lib/build/lib/ptycho/visualization.py b/build/lib/build/lib/build/lib/ptycho/visualization.py
deleted file mode 100644
index 91f038e..0000000
--- a/build/lib/build/lib/build/lib/ptycho/visualization.py
+++ /dev/null
@@ -1,22 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-
-def display_imgs(x, y=None, log = False, cbar = False, figsize=(10, 2), **kwargs):
-  if not isinstance(x, (np.ndarray, np.generic)):
-    x = np.array(x)
-  #plt.ioff()
-  n = x.shape[0]
-  fig, axs = plt.subplots(1, n, figsize = figsize)
-  if y is not None:
-    fig.suptitle(np.argmax(y, axis=1))
-  for i in range(n):
-    if log:
-        axs.flat[i].imshow(np.log(.01 + x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    else:
-        axs.flat[i].imshow((x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    axs.flat[i].axis('off')
-  if cbar:
-    plt.colorbar()
-  plt.show()
-  plt.close()
-  plt.ion()
diff --git a/build/lib/build/lib/build/lib/ptycho/workflows/__init__.py b/build/lib/build/lib/build/lib/ptycho/workflows/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/build/lib/ptycho/workflows/components.py b/build/lib/build/lib/build/lib/ptycho/workflows/components.py
deleted file mode 100644
index b030f63..0000000
--- a/build/lib/build/lib/build/lib/ptycho/workflows/components.py
+++ /dev/null
@@ -1,455 +0,0 @@
-import argparse
-import yaml
-import os
-import numpy as np
-import tensorflow as tf
-from ptycho import params as p
-from ptycho import probe
-from ptycho.loader import RawData, PtychoDataContainer
-import logging
-import matplotlib.pyplot as plt
-from typing import Union, Optional, Dict, Any, Tuple, Literal
-from pathlib import Path
-from ptycho.config.config import TrainingConfig, ModelConfig, dataclass_to_legacy_dict
-from dataclasses import fields
-from ptycho import loader, probe
-from typing import Union, Optional, Tuple, Dict, Any
-from ptycho.raw_data import RawData
-from ptycho.loader import PtychoDataContainer
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import params
-from ptycho.image import reassemble_patches
-
-# Set up logging
-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
-logger = logging.getLogger(__name__)
-
-from dataclasses import fields
-from ptycho.config.config import ModelConfig, TrainingConfig
-
-def update_config_from_dict(config_updates: dict):
-    """
-    Updates the application's configuration from a dictionary, ideal for notebook workflows.
-
-    Args:
-        config_updates (dict): A dictionary of parameters to update.
-    """
-    # 1. Create a mutable dictionary from the default dataclass values
-    model_defaults = {f.name: f.default for f in fields(ModelConfig)}
-    training_defaults = {f.name: f.default for f in fields(TrainingConfig) if f.name != 'model'}
-    
-    # Merge them
-    full_config_dict = {**model_defaults, **training_defaults}
-
-    # 2. Update with the user's dictionary
-    for key, value in config_updates.items():
-        if key in full_config_dict:
-            full_config_dict[key] = value
-        else:
-            # Optionally warn about unused keys
-            logger.warning(f"Configuration key '{key}' is not a recognized parameter.")
-
-    # 3. Re-construct the dataclasses
-    model_args = {k: v for k, v in full_config_dict.items() if k in model_defaults}
-    training_args = {k: v for k, v in full_config_dict.items() if k in training_defaults}
-
-    # Handle required Path objects if they are not set
-    if training_args.get('train_data_file') is None:
-        # Assign a dummy path or handle as an error if it's essential for all workflows
-        training_args['train_data_file'] = Path("dummy_path.npz")
-
-    final_model_config = ModelConfig(**model_args)
-    final_training_config = TrainingConfig(model=final_model_config, **training_args)
-    
-    # 4. Update the legacy global params dictionary
-    update_legacy_dict(params.cfg, final_training_config)
-    
-    logger.info("Configuration updated programmatically for interactive session.")
-    params.print_params()
-
-def load_data(file_path, n_images=None, flip_x=False, flip_y=False, swap_xy=False, n_samples=1, coord_scale=1.0):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        n_images (int, optional): Number of data points to include in the training set. Defaults to 512.
-        flip_x (bool, optional): If True, flip the sign of x coordinates. Defaults to False.
-        flip_y (bool, optional): If True, flip the sign of y coordinates. Defaults to False.
-        swap_xy (bool, optional): If True, swap x and y coordinates. Defaults to False.
-        n_samples (int, optional): Number of samples to generate. Defaults to 1.
-        coord_scale (float, optional): Scale factor for x and y coordinates. Defaults to 1.0.
-
-    Returns:
-        RawData: RawData object containing the dataset.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Apply coordinate transformations
-    if flip_x:
-        xcoords = -xcoords
-        xcoords_start = -xcoords_start
-        #probeGuess = probeGuess[::-1, :]
-    if flip_y:
-        ycoords = -ycoords
-        ycoords_start = -ycoords_start
-        #probeGuess = probeGuess[:, ::-1]
-    if swap_xy:
-        xcoords, ycoords = ycoords, xcoords
-        xcoords_start, ycoords_start = ycoords_start, xcoords_start
-        #probeGuess = np.transpose(probeGuess)
-
-    # Apply coordinate scaling
-    xcoords *= coord_scale
-    ycoords *= coord_scale
-    xcoords_start *= coord_scale
-    ycoords_start *= coord_scale
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    if n_images is None:
-        n_images = xcoords.shape[0]
-
-    # Create RawData object for the training subset
-    ptycho_data = RawData(xcoords[:n_images], ycoords[:n_images],
-                          xcoords_start[:n_images], ycoords_start[:n_images],
-                          diff3d[:n_images], probeGuess,
-                          scan_index[:n_images], objectGuess=objectGuess)
-
-    return ptycho_data
-
-def parse_arguments():
-    """Parse command-line arguments based on TrainingConfig fields."""
-    logger = logging.getLogger(__name__)
-    parser = argparse.ArgumentParser(description="Non-grid CDI Example Script")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    
-    # Add arguments based on TrainingConfig fields
-    for field in fields(TrainingConfig):
-        if field.name == 'model':
-            # Handle ModelConfig fields
-            for model_field in fields(ModelConfig):
-                # Special handling for Literal types
-                if hasattr(model_field.type, "__origin__") and model_field.type.__origin__ is Literal:
-                    choices = list(model_field.type.__args__)
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=str,
-                        choices=choices,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}, choices: {choices}"
-                    )
-                else:
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=model_field.type,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}"
-                    )
-        else:
-            # Handle path fields specially
-            if field.type == Path or str(field.type).startswith("typing.Optional[pathlib.Path"):
-                logger.debug(f"Field: {field.name}")
-                logger.debug(f"Field type: {field.type}")
-                logger.debug(f"Field default: {field.default}")
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=lambda x: (logger.debug(f"Converting path value: {x}"), Path(x) if x is not None else None)[1],
-                    default=None if field.default == None else str(field.default),
-                    help=f"Path for {field.name}"
-                )
-            else:
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=field.type,
-                    default=field.default,
-                    help=f"Training parameter: {field.name}"
-                )
-    
-    return parser.parse_args()
-
-def load_yaml_config(file_path: str) -> Dict[str, Any]:
-    """Load configuration from a YAML file."""
-    try:
-        with open(file_path, 'r') as file:
-            return yaml.safe_load(file)
-    except (yaml.YAMLError, IOError) as e:
-        logger.error(f"Error loading YAML config: {e}")
-        raise
-
-
-#def validate_config(config: Dict[str, Any]) -> None:
-#    """Validate the configuration."""
-#    if 'train_data_file_path' not in config or config['train_data_file_path'] is None:
-#        raise ValueError("train_data_file_path is a required parameter and must be provided")
-
-def setup_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> TrainingConfig:
-    """Set up the configuration by merging defaults, YAML file, and command-line arguments."""
-    try:
-        yaml_config = load_yaml_config(yaml_path) if yaml_path else None
-        args_config = vars(args)
-        
-        # Convert string paths to Path objects
-        for key in ['train_data_file', 'test_data_file', 'output_dir']:
-            if key in args_config and args_config[key] is not None:
-                args_config[key] = Path(args_config[key])
-        
-        # Create ModelConfig from args
-        model_fields = {f.name for f in fields(ModelConfig)}
-        model_args = {k: v for k, v in args_config.items() if k in model_fields}
-        model_config = ModelConfig(**model_args)
-        
-        # Create TrainingConfig
-        training_fields = {f.name for f in fields(TrainingConfig)}
-        training_args = {k: v for k, v in args_config.items() 
-                        if k in training_fields and k != 'model'}
-        config = TrainingConfig(model=model_config, **training_args)
-        
-        # Update the global configuration
-        update_legacy_dict(params.cfg, config)
-        
-        logger.info("Configuration setup complete")
-        logger.info(f"Final configuration: {config}")
-        
-        return config
-    except (yaml.YAMLError, IOError, ValueError) as e:
-        logger.error(f"Error setting up configuration: {e}")
-        raise
-
-def load_and_prepare_data(data_file_path: str) -> Tuple[RawData, RawData, Any]:
-    """
-    Load and prepare the data from a single file path.
-
-    Args:
-        data_file_path (str): Path to the data file
-
-    Returns:
-        Tuple[RawData, RawData, Any]: A tuple containing the full dataset, training subset, and additional data
-    """
-    # TODO deprecated
-    from ptycho.loader import load_xpp_npz
-    if not os.path.exists(data_file_path):
-        raise FileNotFoundError(f"Data file not found: {data_file_path}")
-
-    try:
-        return load_xpp_npz(data_file_path)
-    except Exception as e:
-        logger.error(f"Error loading data from {data_file_path}: {str(e)}")
-        raise
-
-from typing import Union
-from ptycho.loader import RawData, PtychoDataContainer
-
-def create_ptycho_data_container(data: Union[RawData, PtychoDataContainer], config: TrainingConfig) -> PtychoDataContainer:
-    """
-    Factory function to create or return a PtychoDataContainer.
-
-    Args:
-        data (Union[RawData, PtychoDataContainer]): Input data, either RawData or PtychoDataContainer.
-        config (TrainingConfig): Training configuration object.
-
-    Returns:
-        PtychoDataContainer: The resulting PtychoDataContainer.
-
-    Raises:
-        TypeError: If the input data is neither RawData nor PtychoDataContainer.
-    """
-    if isinstance(data, PtychoDataContainer):
-        return data
-    elif isinstance(data, RawData):
-        dataset = data.generate_grouped_data(config.model.N, K=7, nsamples=1)
-        return loader.load(lambda: dataset, data.probeGuess, which=None, create_split=False)
-    else:
-        raise TypeError("data must be either RawData or PtychoDataContainer")
-
-def train_cdi_model(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig
-) -> Dict[str, Any]:
-    """
-    Train the CDI model.
-
-    Args:
-        train_data (Union[RawData, PtychoDataContainer]): Training data.
-        config (Dict[str, Any]): Configuration dictionary.
-
-    Returns:
-        Dict[str, Any]: Results dictionary containing training history.
-    """
-    from ptycho.loader import PtychoDataset
-    from ptycho import train_pinn
-    # Convert input data to PtychoDataContainer
-    train_container = create_ptycho_data_container(train_data, config)
-    if test_data is not None:
-        test_container = create_ptycho_data_container(test_data, config)
-    else:
-        test_container = None
-
-    # Initialize probe
-    probe.set_probe_guess(None, train_container.probe)
-
-#    # Calculate intensity scale
-#    intensity_scale = train_pinn.calculate_intensity_scale(train_container)
-
-    # Train the model
-    results = train_pinn.train_eval(PtychoDataset(train_container, test_container))
-    results['train_container'] = train_container
-    results['test_container'] = test_container
-    #history = train_pinn.train(train_container)
-    
-    return results
-
-def reassemble_cdi_image(
-    test_data: Union[RawData, PtychoDataContainer],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20,
-    coord_scale: float = 1.0
-) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
-    """
-    Reassemble the CDI image using the trained model.
-
-    Args:
-        test_data (Union[RawData, PtychoDataContainer]): Test data.
-        config (Dict[str, Any]): Configuration dictionary.
-        flip_x (bool): Whether to flip the x coordinates. Default is False.
-        flip_y (bool): Whether to flip the y coordinates. Default is False.
-        transpose (bool): Whether to transpose the image by swapping the 1st and 2nd dimensions. Default is False.
-        M (int): Parameter for reassemble_position function. Default is 20.
-        coord_scale (float): Scale factor for x and y coordinates. Default is 1.0.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray, Dict[str, Any]]: 
-        Reconstructed amplitude, reconstructed phase, and results dictionary.
-    """
-    # TODO use train_pinn.eval to get reconstructed diffraction amplitude
-    test_container = create_ptycho_data_container(test_data, config)
-    
-    from ptycho import nbutils
-    obj_tensor_full, global_offsets = nbutils.reconstruct_image(test_container)
-    
-    # Log the shape of global_offsets
-    logger.info(f"Shape of global_offsets: {global_offsets.shape}")
-
-    # Assert that obj_tensor_full is a 4D tensor
-    assert obj_tensor_full.ndim == 4, f"Expected obj_tensor_full to be a 4D tensor, but got shape {obj_tensor_full.shape}"
-
-    # Transpose the image if requested
-    if transpose:
-        obj_tensor_full = np.transpose(obj_tensor_full, (0, 2, 1, 3))
-
-    # Flip coordinates if requested
-    if flip_x:
-        global_offsets[:, 0, 0, :] = -global_offsets[:, 0, 0, :]
-    if flip_y:
-        global_offsets[:, 0, 1, :] = -global_offsets[:, 0, 1, :]
-    
-    # Scale coordinates
-    global_offsets *= coord_scale
-    
-    from ptycho import tf_helper as hh
-    obj_image = hh.reassemble_position(obj_tensor_full, global_offsets, M=M)
-    
-    recon_amp = np.absolute(obj_image)
-    recon_phase = np.angle(obj_image)
-    
-    results = {
-        "obj_tensor_full": obj_tensor_full,
-        "global_offsets": global_offsets,
-        "recon_amp": recon_amp,
-        "recon_phase": recon_phase
-    }
-    
-    return recon_amp, recon_phase, results
-
-def run_cdi_example(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20
-) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Dict[str, Any]]:
-    """
-    Run the main CDI example execution flow.
-
-    Args:
-        train_data: Training data
-        test_data: Optional test data
-        config: Training configuration parameters
-        flip_x: Whether to flip the x coordinates
-        flip_y: Whether to flip the y coordinates
-        transpose: Whether to transpose the image by swapping dimensions
-        M: Parameter for reassemble_position function
-
-    Returns:
-        Tuple containing:
-        - reconstructed amplitude (or None)
-        - reconstructed phase (or None)
-        - results dictionary
-    """
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    # Train the model
-    train_results = train_cdi_model(train_data, test_data, config)
-    
-    recon_amp, recon_phase = None, None
-    
-    # Reassemble test image if test data is provided and reconstructed_obj is available
-    if test_data is not None and 'reconstructed_obj' in train_results:
-        recon_amp, recon_phase, reassemble_results = reassemble_cdi_image(
-            test_data, config, flip_x, flip_y, transpose, M=M
-        )
-        train_results.update(reassemble_results)
-    
-    return recon_amp, recon_phase, train_results
-
-
-def save_outputs(amplitude: Optional[np.ndarray], phase: Optional[np.ndarray], results: Dict[str, Any], output_prefix: str) -> None:
-    """Save the generated images and results."""
-    os.makedirs(output_prefix, exist_ok=True)
-    
-    # TODO Save training history with tensorboard / mlflow
-    
-    # Save test results if available
-    if amplitude is not None and phase is not None:
-        logger.info(f"Amplitude array shape: {amplitude.shape}")
-        logger.info(f"Phase array shape: {phase.shape}")
-        
-        # Squeeze any extra dimensions
-        amplitude = np.squeeze(amplitude)
-        phase = np.squeeze(phase)
-        
-        logger.info(f"Squeezed amplitude shape: {amplitude.shape}")
-        logger.info(f"Squeezed phase shape: {phase.shape}")
-        
-        # Save as PNG files using plt.figure() to handle 2D arrays properly
-        plt.figure(figsize=(8,8))
-        plt.imshow(amplitude, cmap='gray')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_amplitude.png"))
-        plt.close()
-        
-        plt.figure(figsize=(8,8))
-        plt.imshow(phase, cmap='viridis')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_phase.png"))
-        plt.close()
-        
-    logger.info(f"Outputs saved to {output_prefix}")
diff --git a/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py b/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py
deleted file mode 100644
index 5d1f9ad..0000000
--- a/build/lib/build/lib/build/lib/ptycho/workflows/visualize_results.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho import evaluation, params
-from typing import Dict, Any
-
-def visualize_results(results: Dict[str, Any], test_data, i: int = 200, output_prefix: str = 'output'):
-    """
-    Visualize the results using the evaluation.summarize function.
-
-    Args:
-    results (Dict[str, Any]): Dictionary containing the results from the CDI process.
-    test_data: The test data used for evaluation.
-    i (int): Index of the sample to visualize. Default is 200.
-    output_prefix (str): Directory to save the output files. Default is 'output'.
-    """
-    # Extract necessary data from results and test_data
-    pred_amp = results['pred_amp']
-    reconstructed_obj = results['reconstructed_obj']
-    X_test = test_data.X
-    Y_I_test = test_data.Y_I
-    Y_phi_test = test_data.Y_phi
-    probe = np.absolute(params.get('probe')[:, :, 0, 0])
-
-    # Call the summarize function
-    heatmaps = evaluation.summarize(i, results['pred_amp'] + 1, results['reconstructed_obj'], 
-                                    X_test, Y_I_test, Y_phi_test,
-                                    probe, channel=0, crop=False)
-
-    # Save the heatmaps
-    for name, heatmap in heatmaps.items():
-        plt.figure(figsize=(10, 10))
-        plt.imshow(heatmap, cmap='jet')
-        plt.colorbar()
-        plt.title(name)
-        plt.savefig(f"{output_prefix}/{name}.png")
-        plt.close()
-
-    print(f"Heatmaps saved to {output_prefix}")
-
-if __name__ == "__main__":
-    # This is where you would load your results and test_data
-    # For example:
-    # from ptycho.workflows.components import load_and_prepare_data
-    # test_data = load_and_prepare_data("path_to_test_data.npz")
-    # results = ... # Load your results here
-
-    # visualize_results(results, test_data)
-    pass  # Remove this line when uncommenting the code above
diff --git a/build/lib/build/lib/build/lib/ptycho/xpp.py b/build/lib/build/lib/build/lib/ptycho/xpp.py
deleted file mode 100644
index 15c881b..0000000
--- a/build/lib/build/lib/build/lib/ptycho/xpp.py
+++ /dev/null
@@ -1,23 +0,0 @@
-import numpy as np
-import pkg_resources
-
-from .loader import load_xpp_npz as load_ptycho_data
-
-train_frac = .5
-N = 64
-gridh, gridw = 32, 32
-
-np.random.seed(7)
-
-def get_data(**kwargs):
-    return dset, train_frac
-
-
-data_file_path = pkg_resources.resource_filename(__name__, 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-ptycho_data, ptycho_data_train, obj = load_ptycho_data(data_file_path)
-print('raw diffraction shape', obj['diffraction'].shape)
-# TODO cast to complex64?
-probeGuess = obj['probeGuess']
-objectGuess = obj['objectGuess']
-
-## TODO refactor actual / nominal positions
diff --git a/build/lib/build/lib/build/lib/scripts/inference/inference.py b/build/lib/build/lib/build/lib/scripts/inference/inference.py
deleted file mode 100644
index 41951e8..0000000
--- a/build/lib/build/lib/build/lib/scripts/inference/inference.py
+++ /dev/null
@@ -1,384 +0,0 @@
-#!/usr/bin/env python
-# coding: utf-8
-# TODO needs to be updated to use the new-style config dataclasses
-# MAYBE only generate the comparison plot when ground truth object is provided
-# MAYBE save output to npz file, not just image
-
-"""
-Inference script for ptychography reconstruction.
-
-This script loads a trained model and test data, performs inference,
-and saves the reconstructed image comparison and optionally a probe visualization.
-
-Usage:
-    python inference_script.py --model_prefix <model_prefix> --test_data <test_data_file> [--output_path <output_path>]
-                               [--visualize_probe] [--K <K>] [--nsamples <nsamples>]
-
-Arguments:
-    --model_prefix: Path prefix for the saved model and its configuration
-    --test_data: Path to the .npz file containing test data
-    --output_path: Path prefix for saving output files and images (default: './')
-    --visualize_probe: Flag to generate and save probe visualization
-    --K: Number of nearest neighbors for grouped data generation (default: 7)
-    --nsamples: Number of samples for grouped data generation (default: 1)
-"""
-
-from typing import Optional
-import argparse
-import logging
-import os
-import sys
-import time
-import signal
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-from ptycho import probe, params, train_pinn
-from ptycho.model_manager import ModelManager
-from ptycho.raw_data import RawData
-from ptycho.workflows.components import load_data, setup_configuration, parse_arguments
-from ptycho.config.config import InferenceConfig, ModelConfig, validate_inference_config, update_legacy_dict
-
-# Set up logging
-logging.basicConfig(level=logging.INFO,
-                    format='%(asctime)s - %(levelname)s - %(message)s',
-                    handlers=[
-                        logging.StreamHandler(sys.stdout),
-                        logging.FileHandler('inference.log')
-                    ])
-logger = logging.getLogger(__name__)
-
-# Redirect print statements to logger
-print = logger.info
-
-# Global flag for graceful shutdown
-shutdown_requested = False
-
-def signal_handler(signum, frame):
-    global shutdown_requested
-    shutdown_requested = True
-    print(f"Received signal {signum}. Initiating graceful shutdown...")
-
-# Register signal handlers
-signal.signal(signal.SIGINT, signal_handler)
-signal.signal(signal.SIGTERM, signal_handler)
-
-def parse_arguments() -> argparse.Namespace:
-    """Parse command line arguments."""
-    parser = argparse.ArgumentParser(description="Ptychography Inference Script")
-    parser.add_argument("--model_path", type=str, required=True,
-                       help="Path to the saved model")
-    parser.add_argument("--test_data", type=str, required=True,
-                       help="Path to the test data file")
-    parser.add_argument("--config", type=str, required=False, default=None,
-                       help="Optional path to YAML configuration file to override defaults")
-    parser.add_argument("--output_dir", type=str, default='inference_outputs',
-                       help="Directory for saving output files and images")
-    parser.add_argument("--debug", action="store_true",
-                       help="Enable debug mode")
-    return parser.parse_args()
-
-def setup_inference_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> InferenceConfig:
-    """Setup inference configuration from arguments and YAML file."""
-    if yaml_path:
-        base_config = setup_configuration(args, yaml_path)
-        model_config = base_config.model
-    else:
-        # Use default ModelConfig when no YAML provided
-        model_config = ModelConfig()
-    
-    inference_config = InferenceConfig(
-        model=model_config,
-        model_path=Path(args.model_path),
-        test_data_file=Path(args.test_data),
-        debug=args.debug,
-        output_dir=Path(args.output_dir)
-    )
-    
-    validate_inference_config(inference_config)
-    return inference_config
-
-
-def load_model(model_path: Path) -> tuple:
-    """Load the saved model and its configuration."""
-    try:
-        print(f"Attempting to load model from: {model_path}")
-        print(f"Current working directory: {os.getcwd()}")
-        
-        # Check if the path is a directory and contains wts.h5.zip
-        model_zip = os.path.join(model_path, "wts.h5")
-        if not os.path.exists(f"{model_zip}.zip"):
-            raise ValueError(f"Model archive not found at: {model_zip}.zip")
-            
-        # Load multiple models
-        models_dict = ModelManager.load_multiple_models(model_zip)
-        
-        # Get the diffraction_to_obj model which is what we need for inference
-        if 'diffraction_to_obj' not in models_dict:
-            raise ValueError("No diffraction_to_obj model found in saved models")
-            
-        model = models_dict['diffraction_to_obj']
-        config = params.cfg  # ModelManager updates global config when loading
-
-        print(f"Successfully loaded model from {model_path}")
-        print(f"Model configuration: {config}")
-
-        return model, config
-
-    except Exception as e:
-        raise ValueError(f"Failed to load model: {str(e)}")
-
-def perform_inference(model: tf.keras.Model, test_data: RawData, config: dict, K: int, nsamples: int) -> tuple:
-    """
-    Perform inference using the loaded model and test data.
-
-    Args:
-        model (tf.keras.Model): The loaded TensorFlow model.
-        test_data (RawData): The RawData object containing test data.
-        config (dict): The model's configuration dictionary.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Returns:
-        tuple: (np.ndarray, np.ndarray, np.ndarray, np.ndarray) - Reconstructed amplitude, 
-               reconstructed phase, ePIE amplitude, and ePIE phase.
-
-    Raises:
-        ValueError: If there's an error during inference.
-    """
-    from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer
-    try:
-        # Set probe guess
-        probe.set_probe_guess(None, test_data.probeGuess)
-
-        # Set random seeds
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate grouped data
-        test_dataset = test_data.generate_grouped_data(config['N'], K=K, nsamples=nsamples)
-        
-        # Create PtychoDataContainer
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        start_time = time.time()
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        reconstruction_time = time.time() - start_time
-        print(f"Reconstruction completed in {reconstruction_time:.2f} seconds")
-
-        # Process the reconstructed image
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-
-#        # Process ePIE results for comparison
-#        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-#        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        epie_phase = np.angle(test_data.objectGuess)
-        epie_amplitude = np.abs(test_data.objectGuess)
-
-        print(f"Reconstructed amplitude shape: {reconstructed_amplitude.shape}")
-        print(f"Reconstructed phase shape: {reconstructed_phase.shape}")
-        print(f"ePIE amplitude shape: {epie_amplitude.shape}")
-        print(f"ePIE phase shape: {epie_phase.shape}")
-
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-
-    except Exception as e:
-        print(f"Error during inference: {str(e)}")
-        raise ValueError(f"Error during inference: {str(e)}")
-
-def save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_path):
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Create the comparison figure with a smaller size
-        fig, axs = plt.subplots(2, 2, figsize=(4, 4))
-        
-        # PtychoPINN phase
-        im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-        axs[0, 0].set_title('PtychoPINN Phase')
-        fig.colorbar(im_pinn_phase, ax=axs[0, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE phase
-        im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-        axs[0, 1].set_title('ePIE Phase')
-        fig.colorbar(im_epie_phase, ax=axs[0, 1], fraction=0.046, pad=0.04)
-        
-        # PtychoPINN amplitude
-        im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-        axs[1, 0].set_title('PtychoPINN Amplitude')
-        fig.colorbar(im_pinn_amp, ax=axs[1, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE amplitude
-        im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-        axs[1, 1].set_title('ePIE Amplitude')
-        fig.colorbar(im_epie_amp, ax=axs[1, 1], fraction=0.046, pad=0.04)
-        
-        # Remove axis ticks
-        for ax in axs.flat:
-            ax.set_xticks([])
-            ax.set_yticks([])
-        
-        # Adjust layout with specific padding
-        plt.tight_layout(pad=1.5)
-        
-        # Save the figure with adjusted DPI and ensuring the entire figure is saved
-        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.5)
-        plt.close(fig)
-
-        print(f"Comparison image saved to: {output_path}")
-
-    except Exception as e:
-        print(f"Error saving comparison image: {str(e)}")
-
-def save_probe_visualization(test_data: RawData, output_path: str):
-    """
-    Generate and save the probe visualization.
-
-    Args:
-        test_data (RawData): The RawData object containing test data.
-        output_path (str): Path to save the probe visualization.
-
-    Raises:
-        OSError: If there's an error creating the output directory or saving the image.
-    """
-    from ptycho.nbutils import probeshow
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Generate the probe visualization
-        fig = probeshow(test_data.probeGuess, test_data)
-        
-        # Save the figure
-        fig.savefig(output_path, dpi=300, bbox_inches='tight')
-        plt.close(fig)
-
-        print(f"Probe visualization saved to: {output_path}")
-
-    except OSError as e:
-        raise OSError(f"Error saving probe visualization: {str(e)}")
-
-def main(model_prefix: str, test_data_file: str, output_path: str, visualize_probe: bool, K: int, nsamples: int) -> None:
-    """
-    Main function to orchestrate the inference process.
-
-    Args:
-        model_prefix (str): Path prefix for the saved model and its configuration.
-        test_data_file (str): Path to the .npz file containing test data.
-        output_path (str): Path prefix for saving output files and images.
-        visualize_probe (bool): Flag to generate and save probe visualization.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Raises:
-        Exception: If any error occurs during the inference process.
-    """
-    print("Starting inference process...")
-    start_time = time.time()
-
-    try:
-        # Load model
-        print("Loading model...")
-        model, config = load_model(model_prefix)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(test_data_file)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping inference process.")
-            return
-
-        # Perform inference
-        print(f"Performing inference with K={K} and nsamples={nsamples}...")
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(model, test_data, config, K, nsamples)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping before saving results.")
-            return
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = os.path.join(output_path, "reconstruction_comparison.png")
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_image_path)
-
-        # Save probe visualization if requested
-        if visualize_probe:
-            print("Generating and saving probe visualization...")
-            probe_output_path = os.path.join(output_path, "probe_visualization.png")
-            save_probe_visualization(test_data, probe_output_path)
-
-        print("Inference process completed successfully.")
-
-    except FileNotFoundError as e:
-        print(f"File not found error: {str(e)}")
-        raise
-    except ValueError as e:
-        print(f"Value error: {str(e)}")
-        raise
-    except OSError as e:
-        print(f"OS error: {str(e)}")
-        raise
-    except Exception as e:
-        print(f"An unexpected error occurred: {str(e)}")
-        raise
-    finally:
-        # Perform any necessary cleanup
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-    end_time = time.time()
-    print(f"Total execution time: {end_time - start_time:.2f} seconds")
-
-def main():
-    """Main entry point for the ptychography inference script."""
-    try:
-        print("Starting ptychography inference script...")
-        args = parse_arguments()
-        config = setup_inference_configuration(args, args.config)
-        
-        # Update global params with new-style config
-        update_legacy_dict(params.cfg, config)
-
-        # Load model
-        print("Loading model...")
-        model, _ = load_model(config.model_path)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(args.test_data)
-
-        # Perform inference
-        print("Performing inference...")
-        # TODO might want to reduce K
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-            model, test_data, params.cfg, K=7, nsamples=1)
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = config.output_dir / "reconstruction_comparison.png"
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, 
-                            epie_amplitude, epie_phase, output_image_path)
-
-        print("Inference process completed successfully.")
-        sys.exit(0)
-    except Exception as e:
-        print(f"Script execution failed: {str(e)}")
-        sys.exit(1)
-    finally:
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py b/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py
deleted file mode 100644
index 008d7f5..0000000
--- a/build/lib/build/lib/build/lib/scripts/inspect_ptycho_data.py
+++ /dev/null
@@ -1,73 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho.loader import PtychoDataContainer
-
-def load_ptycho_data(file_path: str) -> PtychoDataContainer:
-    """
-    Load the npz-serialized ptycho data.
-
-    Args:
-        file_path (str): Path to the npz file.
-
-    Returns:
-        PtychoDataContainer: Loaded ptycho data.
-    """
-    data = np.load(file_path, allow_pickle=True)
-    return PtychoDataContainer(
-        X=data['X'],
-        Y_I=data['Y_I'],
-        Y_phi=data['Y_phi'],
-        norm_Y_I=data['norm_Y_I'],
-        YY_full=data['YY_full'],
-        coords_nominal=data['coords_nominal'],
-        coords_true=data['coords_true'],
-        nn_indices=data['nn_indices'],
-        global_offsets=data['global_offsets'],
-        local_offsets=data['local_offsets'],
-        probeGuess=data['probe']
-    )
-
-def inspect_ptycho_frames(data: PtychoDataContainer, num_frames: int = 2):
-    """
-    Visually inspect a couple of frames from X, Y_I, and Y_phi.
-
-    Args:
-        data (PtychoDataContainer): Loaded ptycho data.
-        num_frames (int): Number of frames to display. Defaults to 2.
-    """
-    fig, axes = plt.subplots(3, num_frames, figsize=(5*num_frames, 15))
-    
-    for i in range(num_frames):
-        axes[0, i].imshow(data.X[i, ..., 0], cmap='viridis')
-        axes[0, i].set_title(f'X - Frame {i}')
-        axes[0, i].axis('off')
-        
-        axes[1, i].imshow(data.Y_I[i, ..., 0], cmap='viridis')
-        axes[1, i].set_title(f'Y_I - Frame {i}')
-        axes[1, i].axis('off')
-        
-        axes[2, i].imshow(data.Y_phi[i, ..., 0], cmap='viridis')
-        axes[2, i].set_title(f'Y_phi - Frame {i}')
-        axes[2, i].axis('off')
-    
-    plt.tight_layout()
-    plt.show()
-
-if __name__ == "__main__":
-    import sys
-
-    if len(sys.argv) < 2:
-        print("Usage: python inspect_ptycho_data.py <path_to_npz_file>")
-        sys.exit(1)
-
-    file_path = sys.argv[1]
-    
-    try:
-        # Load the data
-        ptycho_data = load_ptycho_data(file_path)
-        
-        # Inspect the frames
-        inspect_ptycho_frames(ptycho_data)
-    except Exception as e:
-        print(f"An error occurred: {e}")
-        sys.exit(1)
diff --git a/build/lib/build/lib/build/lib/scripts/simulation/simulation.py b/build/lib/build/lib/build/lib/scripts/simulation/simulation.py
deleted file mode 100644
index 3dbea64..0000000
--- a/build/lib/build/lib/build/lib/scripts/simulation/simulation.py
+++ /dev/null
@@ -1,276 +0,0 @@
-#!/usr/bin/env python3
-# ptycho_simulate_cli.py
-
-import argparse
-import os
-import sys
-import matplotlib.pyplot as plt
-from ptycho.workflows.components import (
-    setup_configuration,
-    run_cdi_example,
-    update_params,
-)
-
-def save_plot_to_file(fig, filename):
-    fig.savefig(filename, dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-def generate_html_report(output_dir, image_files, args, params):
-    import base64
-
-    html_content = """
-    <!DOCTYPE html>
-    <html lang="en">
-    <head>
-        <meta charset="UTF-8">
-        <meta name="viewport" content="width=device-width, initial-scale=1.0">
-        <title>Ptychography Simulation Report</title>
-        <style>
-            body {
-                font-family: Arial, sans-serif;
-                line-height: 1.6;
-                color: #333;
-                max-width: 1000px;
-                margin: 0 auto;
-                padding: 20px;
-            }
-            h1, h2 {
-                color: #2c3e50;
-                text-align: center;
-            }
-            .image-container {
-                margin-bottom: 30px;
-            }
-            img {
-                max-width: 100%;
-                height: auto;
-                display: block;
-                margin: 0 auto;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 5px;
-            }
-            .image-title {
-                font-weight: bold;
-                margin-top: 10px;
-                text-align: center;
-            }
-            .command, .parameters {
-                background-color: #f4f4f4;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 10px;
-                margin-bottom: 20px;
-                white-space: pre-wrap;
-                word-wrap: break-word;
-            }
-            .parameter-name {
-                font-weight: bold;
-            }
-            .parameter-description {
-                margin-left: 20px;
-                margin-bottom: 10px;
-            }
-        </style>
-    </head>
-    <body>
-        <h1>Ptychography Simulation Report</h1>
-        
-        <h2>Launch Command</h2>
-        <div class="command">
-        {' '.join(sys.argv)}
-        </div>
-        
-        <h2>Model Parameters</h2>
-        <div class="parameters">
-    """
-
-    for key, value in params.items():
-        html_content += f'<p><span class="parameter-name">{key}:</span> {value}</p>\n'
-        if key == "N":
-            html_content += '<p class="parameter-description">Size of the simulation grid.</p>\n'
-        elif key == "probe_scale":
-            html_content += '<p class="parameter-description">Probe scale factor.</p>\n'
-        elif key == "nphotons":
-            html_content += '<p class="parameter-description">Number of photons.</p>\n'
-        elif key == "mae_weight":
-            html_content += '<p class="parameter-description">Weight for MAE loss.</p>\n'
-        elif key == "nll_weight":
-            html_content += '<p class="parameter-description">Weight for NLL loss.</p>\n'
-        elif key == "nepochs":
-            html_content += '<p class="parameter-description">Number of epochs for training.</p>\n'
-        elif key == "intensity_scale.trainable":
-            html_content += '<p class="parameter-description">Whether intensity scale is trainable.</p>\n'
-        elif key == "positions.provided":
-            html_content += '<p class="parameter-description">Whether positions are provided.</p>\n'
-        elif key == "probe.big":
-            html_content += '<p class="parameter-description">Whether to use a big probe.</p>\n'
-        elif key == "probe.mask":
-            html_content += '<p class="parameter-description">Whether to use a probe mask.</p>\n'
-        elif key == "data_source":
-            html_content += '<p class="parameter-description">Type of data source.</p>\n'
-        elif key == "gridsize":
-            html_content += '<p class="parameter-description">Grid size for simulation.</p>\n'
-
-    html_content += """
-        </div>
-        
-        <h2>Visualizations</h2>
-    """
-
-    for image_file in image_files:
-        image_name = os.path.basename(image_file)
-        image_title = image_name.replace('_', ' ').replace('.png', '').title()
-        
-        # Read the image file and encode it in base64
-        with open(image_file, 'rb') as img_f:
-            image_data = img_f.read()
-            encoded_image = base64.b64encode(image_data).decode('utf-8')
-        
-        # Determine the image's MIME type
-        mime_type = 'image/png'  # Adjust if using other image formats
-        
-        # Embed the image in the HTML using a data URI
-        html_content += f"""
-        <div class="image-container">
-            <img src="data:{mime_type};base64,{encoded_image}" alt="{image_title}">
-            <p class="image-title">{image_title}</p>
-        </div>
-        """
-
-    html_content += """
-    </body>
-    </html>
-    """
-
-    with open(os.path.join(output_dir, 'report.html'), 'w') as f:
-        f.write(html_content)
-
-def main():
-    parser = argparse.ArgumentParser(description="Simulate ptychography data and generate visualizations.")
-    parser.add_argument("input_file", help="Path to the input .npz file containing probe and object guesses.")
-    parser.add_argument("output_dir", help="Directory to save output visualizations.")
-    parser.add_argument("--nimages", type=int, default=2000, help="Number of images to simulate.")
-    parser.add_argument("--seed", type=int, default=None, help="Random seed for reproducibility.")
-    parser.add_argument("--nepochs", type=int, default=50, help="Number of epochs for training.")
-    parser.add_argument("--output_prefix", default="tmp", help="Prefix for output files.")
-    parser.add_argument("--intensity_scale_trainable", action="store_true", default=False, help="Make intensity scale trainable.")
-    parser.add_argument("--positions_provided", action="store_true", default=True, help="Positions are provided.")
-    parser.add_argument("--probe_big", action="store_true", default=True, help="Use big probe.")
-    parser.add_argument("--probe_mask", action="store_true", default=False, help="Use probe mask.")
-    parser.add_argument("--data_source", default="generic", help="Data source type.")
-    parser.add_argument("--gridsize", type=int, default=1, help="Grid size.")
-    parser.add_argument("--train_data_file_path", default=None, help="Path to train data file.")
-    parser.add_argument("--test_data_file_path", default=None, help="Path to test data file.")
-    parser.add_argument("--N", type=int, default=128, help="Size of the simulation grid.")
-    parser.add_argument("--probe_scale", type=int, default=4, help="Probe scale factor.")
-    parser.add_argument("--nphotons", type=float, default=1e9, help="Number of photons.")
-    parser.add_argument("--mae_weight", type=float, default=1, help="Weight for MAE loss.")
-    parser.add_argument("--nll_weight", type=float, default=0, help="Weight for NLL loss.")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    args = parser.parse_args()
-
-    os.makedirs(args.output_dir, exist_ok=True)
-
-    params = {
-        "nepochs": args.nepochs,
-        "output_prefix": args.output_prefix,
-        "intensity_scale.trainable": args.intensity_scale_trainable,
-        "positions.provided": args.positions_provided,
-        "probe.big": args.probe_big,
-        "probe.mask": args.probe_mask,
-        "data_source": args.data_source,
-        "gridsize": args.gridsize,
-        "train_data_file_path": args.train_data_file_path,
-        "test_data_file_path": args.test_data_file_path,
-        "N": args.N,
-        "probe_scale": args.probe_scale,
-        "nphotons": args.nphotons,
-        "mae_weight": args.mae_weight,
-        "nll_weight": args.nll_weight,
-    }
-    
-
-    update_params(params)
-    config = setup_configuration(args, args.config)
-
-    from ptycho import probe
-    from ptycho.nongrid_simulation import (
-        simulate_from_npz,
-        visualize_simulated_data,
-        plot_random_groups,
-        compare_reconstructions,
-    )
-    from ptycho import tf_helper as hh
-    from ptycho import baselines as bl
-    from ptycho.workflows.components import create_ptycho_data_container
-
-    # Simulate data
-    simulated_data, ground_truth_patches = simulate_from_npz(
-        args.input_file, args.nimages, random_seed=args.seed
-    )
-
-    # Set the probe
-    probe.set_probe_guess(None, simulated_data.probeGuess)
-
-    # Prepare data for visualization
-    data_for_vis = {
-        'diffraction_patterns': simulated_data.diff3d,
-        'ground_truth_patches': ground_truth_patches,
-        'probe_guess': simulated_data.probeGuess,
-        'object': simulated_data.objectGuess,
-        'x_coordinates': simulated_data.xcoords,
-        'y_coordinates': simulated_data.ycoords,
-    }
-
-    # Generate and save visualizations
-    image_files = []
-
-    # Visualize simulated data
-    #plt.figure(figsize=(20, 20))
-    visualize_simulated_data(data_for_vis, args.output_dir)
-    filename = os.path.join(args.output_dir, "simulated_data_visualization.png")
-    #plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    #plt.close()
-
-    # Plot random groups
-    for i in range(3):  # Generate 3 sets of random groups
-        plt.figure(figsize=(15, 15))
-        plot_random_groups(simulated_data, K=5, seed=args.seed)
-        filename = os.path.join(args.output_dir, f'random_groups_{i+1}.png')
-        plt.savefig(filename, dpi=300, bbox_inches='tight')
-        image_files.append(filename)
-        plt.close()
-
-    # Run CDI example and compare reconstructions
-    config = setup_configuration(args, None)
-    train_data = create_ptycho_data_container(simulated_data, config)
-    recon_amp, recon_phase, results = run_cdi_example(train_data, train_data, config)
-
-    # Train baseline model
-    baseline_model = bl.train(train_data.X[:, :, :, :1], train_data.Y_I[:, :, :, :1], train_data.Y_phi[:, :, :, :1])
-    baseline_pred_I, baseline_pred_phi = baseline_model[0].predict([train_data.X[:, :, :, 0]])
-
-    # Compare reconstructions
-    plt.figure(figsize=(20, 20))
-    compare_reconstructions(
-        results['obj_tensor_full'],
-        results['global_offsets'],
-        simulated_data.objectGuess,
-        hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-    )
-    filename = os.path.join(args.output_dir, 'reconstruction_comparison.png')
-    plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    plt.close()
-
-    # Generate HTML report with embedded images, launch command, and model parameters
-    generate_html_report(args.output_dir, image_files, args, params)
-
-    print(f"Simulation and visualization complete. Results saved in {args.output_dir}")
-    print(f"Open {os.path.join(args.output_dir, 'report.html')} to view the visualizations.")
-
-if __name__ == "__main__":
-    main()
-
diff --git a/build/lib/build/lib/build/lib/scripts/stitch_patches.py b/build/lib/build/lib/build/lib/scripts/stitch_patches.py
deleted file mode 100644
index 4f88936..0000000
--- a/build/lib/build/lib/build/lib/scripts/stitch_patches.py
+++ /dev/null
@@ -1,93 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, *, 
-                  N: int,
-                  gridsize: int,
-                  offset: int,
-                  nimgs_test: int,
-                  outer_offset_test: int = None,
-                  norm_Y_I_test: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        N: Size of each square patch
-        gridsize: Grid size for patch arrangement  
-        offset: Spacing between patches
-        nimgs_test: Number of test images
-        outer_offset_test: Offset between outer patches
-        norm_Y_I_test: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # if the channel dimension exists, its size must be 1
-    if patches.shape[-1] != 1:
-        assert patches.shape[-1] == N
-
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    # Handle optional parameters
-    nimgs = nimgs_test
-    outer_offset = outer_offset_test if outer_offset_test is not None else offset
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / nimgs) / (N**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-
-# Usage example
-#stitched = stitch_patches(ptycho_dataset.test_data.Y[:, :, :, :1],
-#              N=64,
-#              gridsize=2,
-#              offset=4,
-#              nimgs_test=1,
-#              outer_offset_test=20,
-#              norm_Y_I_test=ptycho_dataset.test_data.norm_Y_I,
-#              norm=True, 
-#              part='complex')
-#plt.imshow(np.abs(stitched[0, :, :, 0]))
diff --git a/build/lib/build/lib/build/lib/scripts/training/train.py b/build/lib/build/lib/build/lib/scripts/training/train.py
deleted file mode 100644
index 983f262..0000000
--- a/build/lib/build/lib/build/lib/scripts/training/train.py
+++ /dev/null
@@ -1,62 +0,0 @@
-#!/usr/bin/env python
-
-import logging
-import sys
-
-# Set up file handler for debug logging
-file_handler = logging.FileHandler('train_debug.log')
-file_handler.setLevel(logging.DEBUG)
-file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Set up console handler for info logging
-console_handler = logging.StreamHandler(sys.stdout)
-console_handler.setLevel(logging.INFO)
-console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Configure root logger
-logging.getLogger().setLevel(logging.DEBUG)
-logging.getLogger().addHandler(file_handler)
-logging.getLogger().addHandler(console_handler)
-
-from ptycho.workflows.components import (
-    parse_arguments,
-    setup_configuration,
-    load_data,
-    run_cdi_example,
-    save_outputs,
-    logger
-)
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import model_manager, params
-def main() -> None:
-    """Main function to orchestrate the CDI example script execution."""
-    args = parse_arguments()
-    
-    # Handle legacy argument name
-    if hasattr(args, 'train_data_file_path'):
-        args.train_data_file = args.train_data_file_path
-        delattr(args, 'train_data_file_path')
-        
-    config = setup_configuration(args, args.config)
-    
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    try:
-
-        #ptycho_data, ptycho_data_train, obj = load_and_prepare_data(config['train_data_file_path'])
-        ptycho_data = load_data(str(config.train_data_file), n_images = 512)
-        
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-    except Exception as e:
-        logger.error(f"An error occurred during execution: {e}")
-        raise
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py b/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py
deleted file mode 100644
index 8e729d2..0000000
--- a/build/lib/build/lib/build/lib/tests/old_test_tf_helper.py
+++ /dev/null
@@ -1,49 +0,0 @@
-from ptycho.tf_helper import complexify_function, complexify_amp_phase, combine_complex
-import tensorflow as tf
-import numpy as np
-
-
-# Sample function to be complexified
-def sample_fn(tensor, *args, **kwargs):
-    return tensor * 2
-
-# Complexify the sample function
-complexified_fn = complexify_function(sample_fn)
-complexified_amp_phase_fn = complexify_amp_phase(sample_fn)
-
-def test_complexify_function():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    expected_output = tf.constant([2.0 + 4.0j, 6.0 + 8.0j], dtype=tf.complex64)
-    assert tf.math.reduce_all(complexified_fn(complex_tensor) == expected_output), "Failed on complex tensor"
-
-def test_complexify_amp_phase():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    # Doubling the amplitude
-    expected_amplitude = tf.math.abs(complex_tensor) * 2
-    # Doubling the phase (modulus to keep it within -pi to pi)
-    expected_phase = tf.math.angle(complex_tensor) * 2 % (2 * tf.constant(np.pi))
-    # Construct the expected tensor
-    expected_tensor = combine_complex(expected_amplitude, expected_phase)
-    # Compare the reconstructed tensor to the expected tensor
-    error = tf.math.abs(complexified_amp_phase_fn(complex_tensor) - expected_tensor)
-    assert tf.math.reduce_max(error) < 1e-6, "Failed on complex tensor"
-
-
-# Execute the tests
-test_complexify_function()
-
-with tf.device('/CPU:0'):
-    # Force CPU execution because one of the first two tests fails on GPU
-    test_complexify_amp_phase()
-
-print("All tests passed!")
diff --git a/build/lib/build/lib/build/lib/tests/test_generate_data.py b/build/lib/build/lib/build/lib/tests/test_generate_data.py
deleted file mode 100644
index 405bef0..0000000
--- a/build/lib/build/lib/build/lib/tests/test_generate_data.py
+++ /dev/null
@@ -1,7 +0,0 @@
-# Test for generate_data module in the ptycho package
-
-from ptycho import generate_data as init
-
-def test_placeholder():
-    # Placeholder test to ensure the import works
-    assert hasattr(init, 'PtychoData'), "generate_data module should have PtychoData class"
diff --git a/build/lib/build/lib/build/lib/tests/test_generic_loader.py b/build/lib/build/lib/build/lib/tests/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/build/lib/tests/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/build/lib/tests/test_tf_helper.py b/build/lib/build/lib/build/lib/tests/test_tf_helper.py
deleted file mode 100644
index 337e29e..0000000
--- a/build/lib/build/lib/build/lib/tests/test_tf_helper.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import unittest
-import tensorflow as tf
-import numpy as np
-from ptycho.tf_helper import get_mask, combine_complex, pad_obj
-
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import tensorflow as tf
-from ptycho.tf_helper import get_mask, _fromgrid, params
-
-class TestFromGrid(unittest.TestCase):
-
-    def test_fromgrid(self):
-        print("Debug: Starting test_fromgrid")
-        # Set up parameters for the test
-        gridsize = params()['gridsize']
-        N = params()['N']
-        print(f"Debug: Test parameters - gridsize = {gridsize}, N = {N}")
-        # Create a sample input tensor in grid format
-        input_tensor = tf.random.uniform((1, gridsize, gridsize, N, N), dtype=tf.float32)
-        print(f"Debug: Input tensor shape = {input_tensor.shape}")
-        # Calculate the expected output shape
-        expected_shape = (1, N, N, 1)
-        print(f"Debug: Expected output shape = {expected_shape}")
-        # Run the _fromgrid function
-        output_tensor = _fromgrid(input_tensor)
-        print(f"Debug: Output tensor shape = {output_tensor.shape}")
-        # Check if the output shape matches the expected shape
-        self.assertEqual(output_tensor.shape, expected_shape)
-
-with tf.device('/CPU:0'):
-    def test_complexify_amp_phase():
-        # Test with real tensor
-        real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-        assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-    def test_get_mask():
-        input_tensor = tf.constant([[0.1, 0.5], [0.9, 0.0]], dtype=tf.float32)
-        expected_output = tf.constant([[0, 1], [1, 0]], dtype=tf.float32)
-        threshold = 0.2
-        output = get_mask(input_tensor, threshold)
-        self.assertTrue(tf.reduce_all(tf.equal(output, expected_output)))
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import numpy as np
-import tensorflow as tf
-from ptycho.tf_helper import combine_complex
-
-class TestCombineComplex(unittest.TestCase):
-
-def test_combine_complex():
-    amp = tf.constant([1.0, 2.0], dtype=tf.float32)
-    phi = tf.constant([0.0, np.pi], dtype=tf.float32)
-    expected_output = tf.constant([1.0 + 0j, -2.0 + 0j], dtype=tf.complex64)
-    output_complex = combine_complex(amp, phi)
-    # Use a tolerance when comparing complex numbers
-    tolerance = 1e-5
-    self.assertTrue(tf.reduce_all(tf.math.abs(output_complex - expected_output) < tolerance))
-
-def test_pad_and_diffract():
-    # Create a sample input tensor
-    input_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
-    input_tensor = tf.reshape(input_tensor, (1, 2, 2, 1))  # Reshape to (batch, height, width, channels)
-    # Define the desired output height and width
-    desired_height = 4
-    desired_width = 4
-    # Expected output tensor values based on provided output
-    expected_output_values = [0.0, 0.70710677, 1.0, 0.70710677, 0.35355338, 1.4577379, 1.9039432, 1.2747549, 0.5, 1.8027756]
-    # Run pad_and_diffract function
-    _, output_tensor = pad_and_diffract(input_tensor, desired_height, desired_width)
-    # Flatten the output tensor and slice the first 10 values for comparison
-    output_values = output_tensor.numpy().flatten()[:10]
-    # Check if the output values match the expected values within a tolerance
-    for expected, actual in zip(expected_output_values, output_values):
-        self.assertAlmostEqual(expected, actual, places=5)
-
-# Execute the tests
-if __name__ == "__main__":
-    test_complexify_function()
-    with tf.device('/CPU:0'):
-        # Force CPU execution because one of the first two tests fails on GPU
-        test_complexify_amp_phase()
-        test_get_mask()
-        test_combine_complex()
-        test_pad_and_diffract()
-
-if __name__ == '__main__':
-    unittest.main()
-
diff --git a/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py b/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py
deleted file mode 100644
index 20e2574..0000000
--- a/build/lib/build/lib/build/lib/torch/tests/test_tf_helper.py
+++ /dev/null
@@ -1,326 +0,0 @@
-import torch
-import numpy as np
-from .tf_helper import *
-
-def test_get_mask():
-    input_tensor = torch.tensor([[1.0, 0.5, 0.8], [0.3, 0.9, 0.2]])
-    support_threshold = 0.6
-    expected_output = torch.tensor([[1.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
-    assert torch.all(torch.eq(get_mask(input_tensor, support_threshold), expected_output))
-
-def test_combine_complex():
-    amp = torch.tensor([[1.0, 0.5], [0.8, 0.3]])
-    phi = torch.tensor([[0.0, np.pi/2], [np.pi/4, np.pi]])
-    expected_output = torch.view_as_complex(torch.tensor([[[1.0, 0.0], [0.0, 0.5]], [[0.5657, 0.5657], [-0.3, 0.0]]]))
-    assert torch.allclose(combine_complex(amp, phi), expected_output)
-
-def test_pad_obj():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_obj(input_tensor, h, w), expected_output))
-
-def test__fromgrid():
-    params()['N'] = 2
-    img = torch.ones((1, 2, 2, 2, 2, 1))
-    expected_output = torch.ones((4, 2, 2, 1))
-    assert torch.all(torch.eq(_fromgrid(img), expected_output))
-
-def test__togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img = torch.ones((4, 2, 2, 1))
-    expected_output = torch.ones((1, 2, 2, 2, 2, 1))
-    assert torch.all(torch.eq(_togrid(img), expected_output))
-
-def test_togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img1 = torch.ones((4, 2, 2, 1))
-    img2 = torch.ones((4, 2, 2, 1))
-    expected_output = (torch.ones((1, 2, 2, 2, 2, 1)), torch.ones((1, 2, 2, 2, 2, 1)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(togrid(img1, img2), expected_output))
-
-def test__grid_to_channel():
-    params()['gridsize'] = 2
-    grid = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_grid_to_channel(grid), expected_output))
-
-def test_grid_to_channel():
-    params()['gridsize'] = 2
-    grid1 = torch.ones((1, 2, 2, 3, 3, 1))
-    grid2 = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = (torch.ones((1, 3, 3, 4)), torch.ones((1, 3, 3, 4)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(grid_to_channel(grid1, grid2), expected_output))
-
-def test__flat_to_channel():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    img = torch.ones((4, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_flat_to_channel(img), expected_output))
-
-def test__flat_to_channel_2():
-    params()['gridsize'] = 2
-    img = torch.ones((1, 3, 4, 1))
-    expected_output = torch.ones((1, 3, 4, 4))
-    assert torch.all(torch.eq(_flat_to_channel_2(img), expected_output))
-
-def test__channel_to_flat():
-    img = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3, 3, 1))
-    assert torch.all(torch.eq(_channel_to_flat(img), expected_output))
-
-def test__channel_to_patches():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    channel = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((1, 2, 2, 9))
-    assert torch.all(torch.eq(_channel_to_patches(channel), expected_output))
-
-def test_pad_patches():
-    imgs = torch.ones((1, 4, 4, 1))
-    padded_size = 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_patches(imgs, padded_size), expected_output))
-
-def test_pad():
-    imgs = torch.ones((1, 4, 4, 1))
-    size = 2
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad(imgs, size), expected_output))
-
-def test_trim_reconstruction():
-    x = torch.ones((1, 8, 8, 1))
-    N = 4
-    expected_output = torch.ones((1, 4, 4, 1))
-    assert torch.all(torch.eq(trim_reconstruction(x, N), expected_output))
-
-def test_flatten_offsets():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3))
-    assert torch.all(torch.eq(flatten_offsets(channels), expected_output))
-
-def test_pad_reconstruction():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 7, 7, 1))
-    assert torch.all(torch.eq(pad_reconstruction(channels), expected_output))
-
-def test_pad_and_diffract():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    padded_expected = torch.ones((1, 8, 8, 1))
-    input_expected = torch.ones((1, 8, 8, 1))
-    padded, input = pad_and_diffract(input_tensor, h, w)
-    assert torch.all(torch.eq(padded, padded_expected))
-    assert torch.allclose(input, input_expected, atol=1e-6)
-
-import torch
-from typing import Callable
-
-def test_mk_centermask():
-    inputs = torch.ones((2, 8, 8, 3))
-    N = 4
-    c = 3
-
-    # Test case 1: Check if the function returns the correct center mask when kind='center'
-    expected_center_mask = torch.zeros((2, 8, 8, 3))
-    expected_center_mask[:, 2:6, 2:6, :] = 1
-    center_mask = mk_centermask(inputs, N, c, kind='center')
-    assert torch.allclose(center_mask, expected_center_mask)
-
-    # Test case 2: Check if the function returns the correct border mask when kind='border'
-    expected_border_mask = torch.ones((2, 8, 8, 3))
-    expected_border_mask[:, 2:6, 2:6, :] = 0
-    border_mask = mk_centermask(inputs, N, c, kind='border')
-    assert torch.allclose(border_mask, expected_border_mask)
-
-    # Test case 3: Check if the function raises a ValueError when kind is not 'center' or 'border'
-    try:
-        mk_centermask(inputs, N, c, kind='invalid')
-        assert False, "Expected ValueError was not raised"
-    except ValueError:
-        pass
-
-def test_mk_norm():
-    channels = torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function returns the correct norm values
-    expected_norm = torch.ones((2, 8, 8, 4)) * 2 + 0.001
-    norm = mk_norm(channels, mock_fn_reassemble_real)
-    assert torch.allclose(norm, expected_norm)
-
-    # Test case 2: Check if the function handles different input shapes correctly
-    channels_2 = torch.ones((4, 16, 16, 8))
-    expected_norm_2 = torch.ones((4, 16, 16, 8)) * 2 + 0.001
-    norm_2 = mk_norm(channels_2, mock_fn_reassemble_real)
-    assert torch.allclose(norm_2, expected_norm_2)
-
-def test_reassemble_patches():
-    channels = torch.ones((2, 8, 8, 4)) + 1j * torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function correctly reassembles patches when average=False
-    expected_output = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output = reassemble_patches(channels, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the function correctly reassembles patches when average=True
-    expected_output_avg = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output_avg = reassemble_patches(channels, mock_fn_reassemble_real, average=True)
-    assert torch.allclose(output_avg, expected_output_avg)
-
-    # Test case 3: Check if the function handles complex input channels correctly
-    channels_real = torch.ones((2, 8, 8, 4))
-    channels_imag = torch.ones((2, 8, 8, 4)) * 2
-    channels_complex = torch.complex(channels_real, channels_imag)
-    expected_output_complex = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 4
-    output_complex = reassemble_patches(channels_complex, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output_complex, expected_output_complex)
-
-def test__reassemble_patches_position_real():
-    imgs = torch.ones((2, 8, 8, 4))
-    offsets_xy = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-    padded_size = 16
-
-    # Mock Translation class
-    class MockTranslation:
-        def __call__(self, inputs):
-            return inputs[0] + inputs[1].unsqueeze(-1).unsqueeze(-1)
-
-    # Mock helper functions
-    def mock_flatten_offsets(offsets_xy):
-        return offsets_xy.view(-1, 2)
-
-    def mock__channel_to_flat(imgs):
-        return imgs.view(-1, 8, 8, 1)
-
-    def mock_pad_patches(imgs_flat, padded_size):
-        return torch.ones((8, padded_size, padded_size, 1))
-
-    def mock__flat_to_channel(imgs_flat_bigN_translated, N):
-        return imgs_flat_bigN_translated.view(2, N, N, 4)
-
-    # Test case 1: Check if the function correctly reassembles patches when agg=True
-    expected_output_agg = torch.ones((2, padded_size, padded_size, 1)) * 4
-    output_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=True, padded_size=padded_size,
-                                                   flatten_offsets=mock_flatten_offsets,
-                                                   _channel_to_flat=mock__channel_to_flat,
-                                                   pad_patches=mock_pad_patches,
-                                                   Translation=MockTranslation(),
-                                                   _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg, expected_output_agg)
-
-    # Test case 2: Check if the function correctly reassembles patches when agg=False
-    expected_output_no_agg = torch.ones((2, padded_size, padded_size, 4))
-    output_no_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=False, padded_size=padded_size,
-                                                      flatten_offsets=mock_flatten_offsets,
-                                                      _channel_to_flat=mock__channel_to_flat,
-                                                      pad_patches=mock_pad_patches,
-                                                      Translation=MockTranslation(),
-                                                      _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_no_agg, expected_output_no_agg)
-
-    # Test case 3: Check if the function handles different input shapes and offsets correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    offsets_xy_2 = torch.tensor([[[1, 1], [2, 2], [3, 3], [4, 4]], [[5, 5], [6, 6], [7, 7], [8, 8]]])
-    padded_size_2 = 32
-    expected_output_agg_2 = torch.ones((4, padded_size_2, padded_size_2, 1)) * 8
-    output_agg_2 = _reassemble_patches_position_real(imgs_2, offsets_xy_2, agg=True, padded_size=padded_size_2,
-                                                     flatten_offsets=mock_flatten_offsets,
-                                                     _channel_to_flat=mock__channel_to_flat,
-                                                     pad_patches=mock_pad_patches,
-                                                     Translation=MockTranslation(),
-                                                     _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg_2, expected_output_agg_2)
-
-def test_mk_reassemble_position_real():
-    input_positions = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-
-    # Mock _reassemble_patches_position_real function
-    def mock__reassemble_patches_position_real(imgs, offsets_xy, **kwargs):
-        return imgs + offsets_xy.sum()
-
-    # Test case 1: Check if the function returns a callable that correctly reassembles patches
-    imgs = torch.ones((2, 8, 8, 4))
-    expected_output = imgs + 10
-    reassemble_fn = mk_reassemble_position_real(input_positions)
-    output = reassemble_fn(imgs)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the returned callable handles different input shapes and keyword arguments correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    expected_output_2 = imgs_2 + 10
-    output_2 = reassemble_fn(imgs_2)
-    assert torch.allclose(output_2, expected_output_2)
-
-    import torch
-import numpy as np
-
-def test_translate():
-    # Test case 1: Single input tensor
-    tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    output = translate(tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
-    # Test case 2: Batched input tensors
-    batch_size = 2
-    channels = 3
-    height = 4
-    width = 5
-    imgs = torch.randn(batch_size, channels, height, width)
-    offsets = torch.tensor([[1.0, -1.0], [-2.0, 2.0]], dtype=torch.float32)
-    expected_output = torch.tensor([
-        [
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.1132, 0.1562, 0.1697],
-             [0.0000, 0.7470, 0.8155, 0.1878, 0.4034],
-             [0.0000, 1.3378, 0.9931, 0.2400, 0.2372]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.6398, 0.8829, 0.9593],
-             [0.0000, 1.0086, 1.1025, 0.2537, 0.5450],
-             [0.0000, 0.8617, 0.6401, 0.1547, 0.1529]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.2566, 0.3541, 0.3848],
-             [0.0000, 0.5297, 0.5783, 0.1331, 0.2861],
-             [0.0000, 0.6287, 0.4674, 0.1129, 0.1117]]
-        ],
-        [
-            [[0.0000, 0.9102, 0.8985, 0.0256, 0.1092],
-             [0.0000, 0.0082, 0.1560, 0.1651, 0.1176],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.6713, 0.6630, 0.0189, 0.0806],
-             [0.0000, 0.0118, 0.2246, 0.2374, 0.1691],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.5032, 0.4970, 0.0142, 0.0604],
-             [0.0000, 0.0117, 0.2213, 0.2342, 0.1667],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]
-        ]
-    ], dtype=torch.float32)
-    output = translate(imgs, offsets)
-    assert torch.allclose(output, expected_output, atol=1e-4)
-
-    # Test case 3: Complex input tensor
-    real_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    imag_tensor = torch.tensor([[0.5, 1.0, 1.5], [2.0, 2.5, 3.0]], dtype=torch.float32)
-    complex_tensor = torch.complex(real_tensor, imag_tensor)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_real_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    expected_imag_output = torch.tensor([[2.5, 3.0, 0.0], [1.0, 1.5, 0.0]], dtype=torch.float32)
-    expected_output = torch.complex(expected_real_output, expected_imag_output)
-    output = translate(complex_tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
diff --git a/build/lib/build/lib/build/lib/torch/tests/tf_helper.py b/build/lib/build/lib/build/lib/torch/tests/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/build/lib/torch/tests/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/build/lib/build/lib/torch/tf_helper.py b/build/lib/build/lib/build/lib/torch/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/build/lib/torch/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/build/lib/diagram/pinn.py b/build/lib/build/lib/diagram/pinn.py
deleted file mode 100644
index 2e5d21a..0000000
--- a/build/lib/build/lib/diagram/pinn.py
+++ /dev/null
@@ -1,293 +0,0 @@
-
-import numpy as np
-import sys
-sys.path.append('../')
-from pycore.tikzeng import *
-
-offset = -1.5
-scale = .3
-decoder_offset = 0
-def ppos(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    nums = np.array([float(n) for n in nums])
-    nums[0] += decoder_offset
-    new = str(tuple(n * scale for n in nums))
-    print(new)
-    return new
-
-def ppos_encoder(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    new = str(tuple(float(n) * scale for n in nums))
-    print(new)
-    return new
-
-## vim macro
-"""/\dcw{}jk?codek$a"jkpa", jk/\a\d"""
-patch_size = 26
-# size of the probe-illuminated patches
-probe_scale = 1.2
-zoff = -10 #* scale
-xext = 31
-xpatch = 31.2
-patch_width = .5
-diff_width = .5
-diff_spacing = 7 * probe_scale
-xdiff = 37
-xdiff2 = 44
-probe_size = 32
-
-diff2_spacing = .2
-diff2_dx = 2
-diff2_dy = .5
-diff2_dz = 0.5
-diff2_width = 3
-amp_suffix = '_1'
-phase_suffix = '_2'
-
-legend_offset_y = -20
-legend_boxsize = 8
-legend_width = 0
-legend_spacing_x = 6 / (2 * scale)
-legend_offset_x = -7
-legend_spacing_y = -4 / (2 * scale)
-legend_patch_width = .1
-offset2 = offset * (legend_boxsize / 32)
-
-img_path_fmt = '../../notebooks/images/{}'
-
-input1 = img_path_fmt.format('in1.png')
-input2 = img_path_fmt.format('in2.png')
-input3 = img_path_fmt.format('in3.png')
-input4 = img_path_fmt.format('in4.png')
-
-output1 = img_path_fmt.format('out1.png')
-output2 = img_path_fmt.format('out2.png')
-output3 = img_path_fmt.format('out3.png')
-output4 = img_path_fmt.format('out4.png')
-
-patch1_path = img_path_fmt.format('patch1.png')
-patch2_path = img_path_fmt.format('patch2.png')
-patch3_path = img_path_fmt.format('patch3.png')
-patch4_path = img_path_fmt.format('patch4.png')
-
-phase_path = img_path_fmt.format('phase.png')
-amp_path = img_path_fmt.format('amp.png')
-full_obj_path = img_path_fmt.format('full_obj.png')
-
-im_size = 13 * scale
-inp_x = -7
-outp_x = 50
-
-encoder = [
-    to_input(input1, to=ppos("({},{},{})".format(inp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(input2, to=ppos("({},{},{})".format(inp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(input3, to=ppos("({},{},{})".format(inp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(input4, to=ppos("({},{},{})".format(inp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-    to_ConvRelu("conv11", '', 64, offset=ppos_encoder("(0,0,0)"), to=ppos_encoder("(0,0,0)"),
-        height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_ConvRelu("conv12", '', '', offset=ppos_encoder("(.4,0,0)"), to=ppos_encoder("(0,0,0)"), height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_Pool("pool1", offset=ppos_encoder("(0,0,0)"), to="(conv12-east)", height=32* scale, depth=32* scale),
-
-    to_ConvRelu("conv21", '', '', offset=ppos_encoder("(5,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_ConvRelu("conv22", '', 128, offset=ppos_encoder("(5.8,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_Pool("pool2", offset=ppos_encoder("(0,0,0)"), to="(conv22-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool1", "conv21"),
-
-    to_ConvRelu("conv31", '', 256, offset=ppos_encoder("(10,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_ConvRelu("conv32", '', '', offset=ppos_encoder("(11.6,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_Pool("pool3", offset=ppos_encoder("(0,0,0)"), to="(conv32-east)", height=8* scale, depth=8* scale),
-    to_connection( "pool2", "conv31"),
-]
-
-def last_decoder(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_Sigmoid("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = 'A(r)')
-    elif pos_sign == -1:
-        return to_Tanh("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = r'$\bm{\phi(r)}$')
-    else:
-        raise ValueError
-
-def last_decoder_img(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_input(amp_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    elif pos_sign == -1:
-        return to_input(phase_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    else:
-        raise ValueError
-
-def mk_decoder(name_suffix = '0', pos_sign = 1):
-    return [
-    to_ConvRelu("up11" + name_suffix, '', 256, offset=ppos("(12,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_ConvRelu("up12" + name_suffix, '', '', offset=ppos("(13.6,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_UnPool("unpool1" + name_suffix, offset=ppos("(0,0,0)"), to="(up12" + name_suffix + "-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool3", "up11" + name_suffix),
-
-    to_ConvRelu("up21" + name_suffix, '', 128, offset=ppos("(18,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_ConvRelu("up22" + name_suffix, '', '', offset=ppos("(18.8,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_UnPool("unpool2" + name_suffix, offset=ppos("(0,0,0)"), to="(up22" + name_suffix + "-east)", height=32* scale, depth=32* scale),
-    to_connection( "unpool1" + name_suffix, "up21" + name_suffix),
-
-#    to_Conv("up31" + name_suffix, '', 1, offset=ppos("(23,0,0)"),
-#        to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-#        depth=32* scale, width=2 * scale),
-    last_decoder(pos_sign, name_suffix),
-    last_decoder_img(pos_sign, name_suffix),
-    to_connection( "unpool2" + name_suffix, last + name_suffix)
-    #to_connection( "unpool2" + name_suffix, "up31" + name_suffix)
-    ]
-#last = "up31"
-last = "last"
-
-forward_map =\
-[
-    to_Sum("sum1", offset=ppos("(27.5,0,0)"), to=ppos("(0, 0, 0)"), radius=2.5 * scale, opacity=0.6),
-    to_connection(last+ amp_suffix, "sum1"),
-    to_connection(last+ phase_suffix, "sum1"),
-    to_Extract("extract1", '', 4, offset=ppos("({},0,0)".format(xext)),
-        to=ppos("(0,0,0)"), height=64* scale / 2, depth=64* scale / 2, width=2* scale,
-        caption = ''),
-    to_input(full_obj_path, to = ppos("({},0,0)".format(xext)), width = im_size,
-        height = im_size),
-    to_connection("sum1", "extract1"),
-    to_Patch("patch1", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch4", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch2", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch3", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale)] +\
-    to_Illumination("probe2", patch2_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * 1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch2", "probe2")] +\
-    to_Illumination("probe3", patch3_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * .5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch3", "probe3")] +\
-    to_Illumination("probe1", patch1_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch1", "probe1")] +\
-    to_Illumination("probe4", patch4_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2,
-        caption = r'$\bm{\times}$ Probe${(\bm{r - r_i})}$') +\
-    [to_connection( "patch4", "probe4")] +\
-    [
-#        to_Diffraction("diff1", '', 4, offset=ppos("({},0,0)".format(xdiff2)),
-#        to=ppos("({},{},{})".format(diff2_dx * 1.5, diff2_dy * 1.5, diff2_dz * 1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-#    to_Diffraction("diff2", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing)),
-#        to=ppos("({},{},{})".format(diff2_dx * .5, diff2_dy * .5, diff2_dz * .5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_Diffraction("diff3", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 2)),
-        to=ppos("({},{},{})".format(diff2_dx * -.5, diff2_dy * -.5, diff2_dz * -.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-        caption = ''),
-#    to_Diffraction("diff4", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 3)),
-#        to=ppos("({},{},{})".format(diff2_dx * -1.5, diff2_dy * -1.5, diff2_dz * -1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_connection("probe2", "diff3"),#top
-    to_connection("probe1", "diff3"),
-    to_connection("probe3", "diff3"),
-    to_connection("probe4", "diff3"),# bottom
-#    to_connection("probe2", "diff1"),#top
-#    to_connection("probe1", "diff3"),
-#    to_connection("probe3", "diff2"),
-#    to_connection("probe4", "diff4"),# bottom
-
-    to_input(output1, to=ppos("({},{},{})".format(outp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(output2, to=ppos("({},{},{})".format(outp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(output3, to=ppos("({},{},{})".format(outp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(output4, to=ppos("({},{},{})".format(outp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-
-    to_ConvRelu("conv_relu_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~ReLU($\cdot$)""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~ReLU($\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Pool("pool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""AvgPool2D($\cdot$)"""),
-
-    to_UnPool("unpool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-        legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Upsample($\cdot$)"""),
-
-    to_Tanh("tanh_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 0,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~$i \bm{\pi \tanh(\cdot)}$""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~$i \pi \tanh(\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Sigmoid("sigmoid_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 1,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~Sigmoid$(\cdot)$""",
-        s_filer = '', n_filer = ''),
-
-    to_Patch("patch1_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch4_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch2_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch3_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale,
-        caption = r"""Crop$(\cdot)$\linebreak Shift$(\cdot)$""",),
-        #caption = r"""Illuminate$(\cdot)$""",),
-
-    to_Diffraction("diff_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 3,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Diffract$(\bm{\cdot})$ \linebreak $\sim $Poisson$(\bm{\cdot}^2)$""",
-        s_filer = '', n_filer = ''),
-
-]
-
-arch = [to_head( '..' ),
-    to_cor(),
-    to_begin()] +\
-    encoder + mk_decoder(amp_suffix, pos_sign = 1) +\
-    mk_decoder(phase_suffix, pos_sign = -1) + forward_map +\
-    [to_end()]
-
-def main():
-    namefile = str(sys.argv[0]).split('.')[0]
-    to_generate(arch, namefile + '.tex' )
-
-if __name__ == '__main__':
-    main()
diff --git a/build/lib/build/lib/diagram/tikzeng.py b/build/lib/build/lib/diagram/tikzeng.py
deleted file mode 100644
index 4de56da..0000000
--- a/build/lib/build/lib/diagram/tikzeng.py
+++ /dev/null
@@ -1,374 +0,0 @@
-
-import os
-
-def to_head( projectpath ):
-    pathlayers = os.path.join( projectpath, 'layers/' ).replace('\\', '/')
-    return r"""
-\documentclass[border=8pt, multi, tikz]{standalone}
-\usepackage{import}
-\usepackage{bm}
-\usepackage{transparent}
-\subimport{"""+ pathlayers + r"""}{init}
-\usetikzlibrary{positioning}
-\usetikzlibrary{3d} %for including external image
-"""
-
-def to_cor():
-    return r"""
-\def\ConvColor{rgb:yellow,5;red,2.5;white,5}
-\def\ConvReluColor{rgb:yellow,5;red,5;white,5}
-\def\PoolColor{rgb:red,1;black,0.3}
-\def\UnpoolColor{rgb:blue,2;green,1;black,0.3}
-\def\FcColor{rgb:blue,5;red,2.5;white,5}
-\def\FcReluColor{rgb:blue,5;red,5;white,4}
-\def\SoftmaxColor{rgb:magenta,5;black,7}
-\def\SumColor{rgb:blue,5;green,15}
-\def\DcnvColor{rgb:blue,5;green,2.5;white,5}
-"""
-
-def to_begin():
-    return r"""
-\newcommand{\copymidarrow}{\tikz \draw[-Stealth,line width=0.8mm,draw={rgb:blue,4;red,1;green,1;black,3}] (-0.3,0) -- ++(0.3,0);}
-
-\begin{document}
-\begin{tikzpicture}
-\tikzstyle{connection}=[ultra thick,every node/.style={sloped,allow upside down},draw=\edgecolor,opacity=0.7]
-\tikzstyle{copyconnection}=[ultra thick,every node/.style={sloped,allow upside down},draw={rgb:blue,4;red,1;green,1;black,3},opacity=0.7]
-"""
-
-# layers definition
-
-def to_input( pathfile, to='(-3,0,0)', width=8, height=8, name="temp" ):
-    return r"""
-\node[canvas is zy plane at x=0] (""" + name + """) at """+ to +""" {\includegraphics[width="""+ str(width)+"cm"+""",height="""+ str(height)+"cm"+"""]{"""+ pathfile +"""}};
-"""
-
-# Conv
-def to_Conv( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_ConvRelu( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# Conv,Conv,relu
-# Bottleneck
-def to_ConvConvRelu( name, s_filer=256, n_filer=(64,64), offset="(0,0,0)", to="(0,0,0)", width=(2,2), height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name +""",
-        caption="""+ caption +""",
-        xlabel={{ """+ str(n_filer[0]) +""", """+ str(n_filer[1]) +""" }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        bandfill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width={ """+ str(width[0]) +""" , """+ str(width[1]) +""" },
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# Pool
-def to_Pool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+name+""",
-        caption="""+ caption +r""",
-        fill=\PoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# unpool4,
-def to_UnPool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+ name +r""",
-        caption="""+ caption +r""",
-        fill=\UnpoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_ConvRes( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Pad( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sigmoid( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:violet,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Tanh( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Patch( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.1, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        bandopacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-# bandfill={rgb:blue,1;red,2},
-
-def to_Extract( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)",
-        width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;green,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_Illumination( name, filepath, s_filer=256, n_filer=64,
-    offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-    opacity=0.2, caption=" " , im_size = 4):
-    return [r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;blue,3},
-        bandfill={rgb:black,1;blue,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-""",
-    to_input(filepath, to = to, width = im_size, height = im_size)]
-
-def to_Diffraction( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.4, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:violet,1;red,3},
-        bandfill={rgb:white,1;red,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# ConvSoftMax
-def to_ConvSoftMax( name, s_filer=40, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# SoftMax
-def to_SoftMax( name, s_filer=10, offset="(0,0,0)", to="(0,0,0)", width=1.5, height=3, depth=25, opacity=0.8, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        xlabel={{" ","dummy"}},
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sum( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=""" + r'$\times$' + """
-        }
-    };
-"""
-
-def to_Prod( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=$x$
-        }
-    };
-"""
-
-# \times?
-
-def to_connection( of, to):
-    return r"""
-\draw [connection]  ("""+of+"""-east)    -- node {\midarrow} ("""+to+"""-west);
-"""
-
-def to_skip( of, to, pos=1.25):
-    return r"""
-\path ("""+ of +"""-southeast) -- ("""+ of +"""-northeast) coordinate[pos="""+ str(pos) +"""] ("""+ of +"""-top) ;
-\path ("""+ to +"""-south)  -- ("""+ to +"""-north)  coordinate[pos="""+ str(pos) +"""] ("""+ to +"""-top) ;
-\draw [copyconnection]  ("""+of+"""-northeast)
--- node {\copymidarrow}("""+of+"""-top)
--- node {\copymidarrow}("""+to+"""-top)
--- node {\copymidarrow} ("""+to+"""-north);
-"""
-
-def to_end():
-    return r"""
-\end{tikzpicture}
-\end{document}
-"""
-
-def to_generate( arch, pathname="file.tex" ):
-    with open(pathname, "w") as f:
-        for c in arch:
-            print(c)
-            f.write( c )
-
diff --git a/build/lib/build/lib/loaders/__init__.py b/build/lib/build/lib/loaders/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/loaders/als.py b/build/lib/build/lib/loaders/als.py
deleted file mode 100644
index d1b9b0a..0000000
--- a/build/lib/build/lib/loaders/als.py
+++ /dev/null
@@ -1,47 +0,0 @@
-import numpy as np
-from ptycho.raw_data import RawData
-
-import pkg_resources
-
-def load_single_object(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects. We ASSUME we're processing
-    a single object. The first train_size samples will be used for training and the entire dataset 
-    will be used for evaluation.
-
-    Args:
-        file_path: Path to the data file.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = data['diffraction']
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                          diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                xcoords_start[:train_size], ycoords_start[:train_size],
-                                diff3d[:train_size], probeGuess,
-                                scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
-
diff --git a/build/lib/build/lib/loaders/xpp.py b/build/lib/build/lib/loaders/xpp.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/notebooks/dose.py b/build/lib/build/lib/notebooks/dose.py
deleted file mode 100644
index f98380e..0000000
--- a/build/lib/build/lib/notebooks/dose.py
+++ /dev/null
@@ -1,235 +0,0 @@
-import argparse
-
-def init(nphotons, loss_fn='nll'):
-    from ptycho.params import cfg
-    cfg['positions.provided'] = False
-    cfg['data_source'] = 'lines'
-    cfg['set_phi'] = False
-    cfg['nepochs'] = 60 
-
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 3
-    cfg['output_prefix'] = 'lines3'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-    cfg['probe.trainable'] = False
-
-    cfg['outer_offset_train'] = 8
-    cfg['outer_offset_test'] = 20
-    cfg['nimgs_train'] = 2
-    cfg['nimgs_test'] = 2
-
-    cfg['nphotons'] = nphotons
-
-    if loss_fn == 'mae':
-        cfg['mae_weight'] = 1.
-        cfg['nll_weight'] = 0.
-    elif loss_fn == 'nll':
-        pass  # Keep the current behavior
-    else:
-        raise ValueError(f"Invalid loss_fn: {loss_fn}. Must be 'mae' or 'nll'.")
-
-def plot_results(stitched_obj, YY_ground_truth, d):
-    import matplotlib.pyplot as plt
-    import numpy as np
-
-    fig, axs = plt.subplots(1, 1, figsize=(5, 5))
-
-    # reconstructed amplitude images
-    img1 = axs.imshow(np.absolute(stitched_obj)[0], cmap='jet', interpolation='none')
-    axs.set_title(f'Reconstructed amplitude - FRC50: {d["frc50"][0]:.2f}')
-
-    fig.colorbar(img1, ax=axs)
-
-def execute(nphotons, reload_modules=False):
-    from ptycho.tf_helper import pad
-    from ptycho.evaluation import save_metrics, trim
-    from ptycho.tf_helper import pad
-    from ptycho.params import cfg
-    cfg['nphotons'] = nphotons
-
-    cfg['data_source'] = 'lines'
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 10
-    cfg['output_prefix'] = 'lines2'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-
-    from ptycho import train
-    if reload_modules:
-        reload(train.generate_data)
-        reload(train.train_pinn.model)
-        reload(train.train_pinn)
-        reload(train)
-
-    stitched_obj, YY_ground_truth = train.stitched_obj, train.YY_ground_truth
-
-    from ptycho.train_pinn import train as train_pinn, eval as eval_pinn
-    from ptycho import misc
-
-    plot_results(stitched_obj, YY_ground_truth, train.d)
-    # Corrected the indentation and scope of the return statement
-    return train.d, YY_ground_truth, stitched_obj, train.train_output
-
-def parse_arguments():
-    parser = argparse.ArgumentParser(description='Ptychographic reconstruction script.')
-    parser.add_argument('nphotons', type=float, help='Number of photons')
-    args = parser.parse_args()
-    return args.nphotons
-
-if __name__ == '__main__':
-    nphotons = parse_arguments()
-    init(nphotons)
-
-    d, YY_ground_truth, stitched_obj = execute(nphotons)
-
-from importlib import reload
-def run_experiment_with_photons(photons_list, loss_fn='nll'):
-    print("DEBUG: Starting run_experiment_with_photons")
-    results = {}
-    first_iteration = True
-    for nphotons in photons_list:
-        init(nphotons, loss_fn=loss_fn)
-        print("DEBUG: nphotons set to", nphotons, "in run_experiment_with_photons")
-        if  first_iteration:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=False)
-        else:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=True)
-        first_iteration = False
-        results[nphotons] = {'d': d, 'YY_ground_truth': YY_ground_truth, 'stitched_obj': stitched_obj, 'train_output': train_output}
-    return results
-import os
-import dill
-import pandas as pd
-import numpy as np
-from matplotlib.image import imread
-
-def has_amp_recon(subdir):
-    return os.path.exists(os.path.join(subdir, 'amp_recon.png'))
-
-def load_recent_experiment_data(directory, N):
-    subdirs = [os.path.join(directory, d) for d in os.listdir(directory) if is_valid_run(os.path.join(directory, d)) and has_amp_recon(os.path.join(directory, d))]
-    print(subdirs)
-    recent_subdirs = subdirs[:N]
-    subdirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)
-
-    data = {}
-    for subdir in recent_subdirs:
-        params_path = os.path.join(subdir, 'params.dill')
-        metrics_path = os.path.join(subdir, 'metrics.csv')
-
-        with open(params_path, 'rb') as f:
-            params = dill.load(f)
-        metrics = pd.read_csv(metrics_path)
-
-        nphotons = (np.log10(params['nphotons']))
-        print('NPOHOT {}'.format(nphotons))
-        #if nphotons not in data or os.path.getmtime(params_path) > os.path.getmtime(os.path.join(data[nphotons]['dir'], 'params.dill')):
-        amp_recon_path = os.path.join(subdir, 'amp_recon.png')
-        amp_recon = imread(amp_recon_path)
-        data[nphotons] = {'params': params, 'metrics': metrics, 'amp_recon': amp_recon, 'dir': subdir}
-
-    return {k: {'params': v['params'], 'metrics': v['metrics']} for k, v in data.items()}
-def is_valid_run(subdir):
-    return os.path.exists(os.path.join(subdir, 'params.dill'))
-import matplotlib.pyplot as plt
-
-def generate_and_save_heatmap(experiment_entry, ax=None, photon_dose=None):
-    if ax is None:
-        fig, ax = plt.subplots()
-    stitched_obj = experiment_entry['stitched_obj'][0, :, :, 0]
-    metrics = experiment_entry['d']
-    frc50 = metrics.get('frc50', [None])[0]
-    psnr = metrics.get('psnr', [None])[0]
-
-    ax.imshow(np.abs(stitched_obj), cmap='jet', interpolation='nearest')
-    title = f'FRC50: {frc50:.2f}, PSNR: {psnr:.2f}'
-    if photon_dose is not None:
-        title = f'Photons: {photon_dose:.0e}, ' + title
-    ax.set_title(title)
-    ax.axis('off')
-
-def generate_2x2_heatmap_plots(res, layout=(1, 4), filename='heatmap_plots.png', axs=None,
-                               fig = None):
-#    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 4*layout[0]))
-#    axs = axs.flatten()
-    for i, (photon_dose, experiment_entry) in enumerate(res.items()):
-        generate_and_save_heatmap(experiment_entry, axs[i], photon_dose)
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.close(fig)
-
-def plot_heatmap_from_experiment(res, nphot, index):
-    import matplotlib.pyplot as plt
-    c = res[nphot]['train_output']['dataset']
-    plt.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    #plt.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    plt.title(f'{nphot:.0e} photons', fontsize = 10)
-    plt.savefig(f'heatmap_photon_dose_{nphot:.0e}_index_{index}.png')
-    #plt.show()
-def plot_heatmaps_for_all_photons(res, index):
-    for nphot in res.keys():
-        plot_heatmap_from_experiment(res, nphot, index)
-    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0]))
-
-def generate_2x2_heatmap_plots_using_function(res, index, layout=(1, 4), filename='heatmap_plots_2x2.png', border_color='black', border_width=2, axs=None):
-    a, b = layout
-    #fig, axs = plt.subplots(1, b, figsize=(24, 3))
-    #fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0])) if axs is None else (None, axs)
-    axs = axs.flatten()
-    photon_doses = list(res.keys())[: b]  # Select the first 4 photon doses for the 2x2 grid
-    for i, nphot in enumerate(photon_doses):
-        ax = axs[i]
-        c = res[nphot]['train_output']['dataset']
-        heatmap = ax.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        for spine in ax.spines.values():
-            spine.set_edgecolor(border_color)
-            spine.set_linewidth(border_width)
-        #ax.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        #ax.set_title(f'{nphot:.0e} photons', fontsize=16)
-        ax.axis('off')
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.show()
-
-def stack_and_display_horizontal_plots(res, index, layout=(1, 4), figsize=(24, 8), crop_size=None):
-    from matplotlib import pyplot as plt
-    import numpy as np
-
-    a, b = layout
-    fig, axs = plt.subplots(2, b, figsize=figsize)
-
-    if crop_size is not None:
-        def crop_center(img, cropx, cropy):
-            y, x = img.shape
-            startx = x // 2 - (cropx // 2)
-            starty = y // 2 - (cropy // 2)
-            return img[starty:starty + cropy, startx:startx + cropx]
-
-        cropped_res = {}
-        for dose, entry in res.items():
-            stitched_obj = entry['stitched_obj'][0, :, :, 0]
-            cropped_obj = crop_center(stitched_obj, crop_size, crop_size)
-            padded_obj = np.pad(cropped_obj, ((0, crop_size - cropped_obj.shape[0]), (0, crop_size - cropped_obj.shape[1])), mode='constant')
-            cropped_res[dose] = {'stitched_obj': np.expand_dims(np.expand_dims(padded_obj, axis=0), axis=-1), **{k: v for k, v in entry.items() if k != 'stitched_obj'}}
-
-        generate_2x2_heatmap_plots(cropped_res, layout=layout, axs=axs[0])
-    else:
-        generate_2x2_heatmap_plots(res, layout=layout, axs=axs[0])
-
-    generate_2x2_heatmap_plots_using_function(res, index, layout=layout, axs=axs[1], border_color='black', border_width=2)
-    plt.tight_layout()
-    fig.savefig(f'stacked_dose_progression_index_{index}.png')
-    plt.show()
diff --git a/build/lib/build/lib/notebooks/test_generic_loader.py b/build/lib/build/lib/notebooks/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/notebooks/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/notebooks/train_and_infer.py b/build/lib/build/lib/notebooks/train_and_infer.py
deleted file mode 100644
index 6a33f16..0000000
--- a/build/lib/build/lib/notebooks/train_and_infer.py
+++ /dev/null
@@ -1,159 +0,0 @@
-import logging
-import sys
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-
-from ptycho.workflows.components import (
-    load_data,
-    run_cdi_example,
-    save_outputs
-)
-from ptycho.config.config import TrainingConfig, InferenceConfig, ModelConfig, update_legacy_dict
-from ptycho import model_manager, params, probe
-from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer, probeshow
-
-# Configure logging
-logging.basicConfig(level=logging.INFO,
-                   format='%(asctime)s - %(levelname)s - %(message)s',
-                   handlers=[
-                       logging.StreamHandler(sys.stdout),
-                       logging.FileHandler('train_and_infer.log')
-                   ])
-logger = logging.getLogger(__name__)
-
-def train_model(config: TrainingConfig):
-    """Train the model using provided configuration."""
-    logger.info("Starting training process...")
-    
-    try:
-        # Load training data
-        ptycho_data = load_data(str(config.train_data_file), n_images=512)
-        
-        # Load test data if provided
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        # Run training
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        
-        # Save model and outputs
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-        
-        return recon_amp, recon_phase, results
-    
-    except Exception as e:
-        logger.error(f"Training failed: {e}")
-        raise
-
-def perform_inference(model: tf.keras.Model, test_data, K: int = 7, nsamples: int = 1):
-    """Perform inference using trained model."""
-    logger.info("Starting inference process...")
-    
-    try:
-        # Set probe guess and random seeds
-        probe.set_probe_guess(None, test_data.probeGuess)
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate test dataset
-        test_dataset = test_data.generate_grouped_data(params.cfg['N'], K=K, nsamples=nsamples)
-        
-        # Create data container
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        
-        # Reassemble position
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-        
-        # Process ePIE results
-        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-    
-    except Exception as e:
-        logger.error(f"Inference failed: {e}")
-        raise
-
-def plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase):
-    """Plot comparison between reconstructed and ePIE results."""
-    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
-    
-    # Plot phases
-    im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    fig.colorbar(im_pinn_phase, ax=axs[0, 0])
-    
-    im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    fig.colorbar(im_epie_phase, ax=axs[0, 1])
-    
-    # Plot amplitudes
-    im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    fig.colorbar(im_pinn_amp, ax=axs[1, 0])
-    
-    im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-    axs[1, 1].set_title('ePIE Amplitude')
-    fig.colorbar(im_epie_amp, ax=axs[1, 1])
-    
-    # Remove ticks
-    for ax in axs.flat:
-        ax.set_xticks([])
-        ax.set_yticks([])
-    
-    plt.tight_layout()
-    return fig
-
-def plot_probe(test_data):
-    """Generate probe visualization."""
-    return probeshow(test_data.probeGuess, test_data)
-
-# Example usage in notebook:
-"""
-# Configuration
-train_config = TrainingConfig(
-    model=ModelConfig(),
-    train_data_file=Path('path/to/train_data.npz'),
-    test_data_file=Path('path/to/test_data.npz'),
-    output_dir=Path('output_directory'),
-    debug=False
-)
-
-# Update global params
-update_legacy_dict(params.cfg, train_config)
-
-# Train model
-recon_amp, recon_phase, results = train_model(train_config)
-
-# Load model for inference
-model, _ = model_manager.ModelManager.load_model(train_config.output_dir)
-
-# Load test data
-test_data = load_data('path/to/test_data.npz')
-
-# Perform inference
-reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-    model, test_data, K=7, nsamples=1
-)
-
-# Plot results
-fig = plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase)
-plt.show()
-
-# Plot probe visualization
-probe_fig = plot_probe(test_data)
-plt.show()
-"""
diff --git a/build/lib/build/lib/ptycho/__init__.py b/build/lib/build/lib/ptycho/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/autotest/__init__.py b/build/lib/build/lib/ptycho/autotest/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/autotest/configuration.py b/build/lib/build/lib/ptycho/autotest/configuration.py
deleted file mode 100644
index 2d66523..0000000
--- a/build/lib/build/lib/ptycho/autotest/configuration.py
+++ /dev/null
@@ -1,13 +0,0 @@
-import os
-
-class Configuration:
-    def __init__(self, debug: bool = False, log_file_prefix: str = "logs"):
-        self.debug = debug
-        self.log_file_prefix = log_file_prefix
-
-    def getDebugFlag(self) -> bool:
-        return self.debug
-
-    def getLogFilePrefix(self) -> str:
-        return self.log_file_prefix
-
diff --git a/build/lib/build/lib/ptycho/autotest/debug.py b/build/lib/build/lib/ptycho/autotest/debug.py
deleted file mode 100644
index a5bf044..0000000
--- a/build/lib/build/lib/ptycho/autotest/debug.py
+++ /dev/null
@@ -1,174 +0,0 @@
-from .serializer import Serializer
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-
-# spec
-#    @depends_on(Logger, Configuration, FunctionMapping)
-#    interface Debug {
-#        """
-#        Applies the debugging process to the function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - Configuration must allow debugging.
-#
-#        Postconditions:
-#        - If debugging is allowed by the Configuration:
-#          - Returns a new function that wraps the original function with debugging functionality.
-#          - The returned function, when called, performs two forms of logging:
-#            1. Prints function call and return information to the console, surrounded by XML tags
-#               containing the callable's module path and name. The console log messages are in the
-#               format `<module.function>CALL/RETURN args/result</module.function>`. For all array
-#               or tensor types (i.e., objects with a .shape and/or .dtype attribute), the shapes
-#               and data types are also printed.
-#            2. Serializes function inputs and outputs to a log file using the `logCall` and `logReturn`
-#               methods of the Logger interface. The serialized data can be loaded using the `LoadLog`
-#               method. If serialization fails, the console logging still occurs, but no log file is
-#               generated for that invocation.
-#          - Logs only the first two invocations of the function.
-#        - If debugging is not allowed by the Configuration:
-#          - Returns the original function unchanged, without any debugging functionality.
-#        """
-#        Callable decorate(Callable func);
-#    };
-
-## implementation
-import time
-import os
-import pickle
-import json
-from typing import Callable, Any, List, Union, Optional
-import re
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-class Debug:
-    def __init__(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-
-    def decorate(self, func: Callable) -> Callable:
-        increment_count = make_invocation_counter()
-        if not self.configuration.getDebugFlag():
-            return func
-
-        else:
-            module_path = self.function_mapping.get_module_path(func)
-            function_name = func.__name__
-
-            def wrapper(*args: Any, **kwargs: Any) -> Any:
-                invocation_count = increment_count()
-                if invocation_count > 2:
-                    return func(*args, **kwargs)
-                
-                log_file_path = self.function_mapping.get_log_file_path(func)
-                os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
-
-                try:
-                    serialized_args = self.serializer.serialize(args)
-                    serialized_kwargs = self.serializer.serialize(kwargs)
-                    self.logger.logCall(serialized_args, serialized_kwargs, log_file_path)
-                except ValueError:
-                    pass  # If serialization fails, just proceed with console logging
-
-                console_log_start = f"<{module_path}.{function_name}>CALL"
-                console_log_args = self._formatConsoleLog(args)
-                console_log_kwargs = self._formatConsoleLog(kwargs)
-                print(console_log_start)
-                print(console_log_args)
-                print(console_log_kwargs)
-
-                start_time = time.time()
-
-                result = func(*args, **kwargs)
-                try:
-                    serialized_result = self.serializer.serialize(result)
-                    self.logger.logReturn(serialized_result, time.time() - start_time, log_file_path)
-
-                    console_log_end = f"</{module_path}.{function_name}>RETURN"
-                    console_log_result = self._formatConsoleLog(result)
-                    print(console_log_end + " " + console_log_result)
-
-                except Exception as e:
-                    self.logger.logError(str(e), log_file_path)
-                    print(f"<{module_path}.{function_name}>ERROR {str(e)}")
-                return result
-
-            return wrapper
-
-    def _formatConsoleLog(self, data: Any) -> str:
-        if not isinstance(data, tuple):
-            data = (data,)
-
-        formatted_data = []
-        for item in data:
-            if hasattr(item, 'shape') and hasattr(item, 'dtype'):
-                formatted_data.append(f"type={type(item)}, shape={item.shape}, dtype={item.dtype}")
-            elif isinstance(item, (int, float, str, bool)):
-                formatted_data.append(f"type={type(item)}, {item}")
-            else:
-                formatted_data.append(f"type={type(item)}")
-        return ", ".join(formatted_data)
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-import unittest
-
-class TestDebug(unittest.TestCase):
-    def setUp(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.debug = Debug(self.configuration, self.serializer, self.logger, self.function_mapping)
-
-    def test_decorate_call(self):
-        @self.debug.decorate
-        def add(x, y):
-            return x + y
-
-        result = add(3, 4)
-        self.assertEqual(result, 7)
-
-    def test_decorate_return(self):
-        @self.debug.decorate
-        def multiply(x, y):
-            return x * y
-
-        result = multiply(2, 3)
-        self.assertEqual(result, 6)
-        result = multiply(4, 5)
-        self.assertEqual(result, 20)
-        result = multiply(6, 7)  # This call should not be logged
-        self.assertEqual(result, 42)
-
-    def test_decorate_error(self):
-        @self.debug.decorate
-        def divide(x, y):
-            return x / y
-
-        with self.assertRaises(ZeroDivisionError):
-            divide(1, 0)
-
-#    def test_format_console_log(self):
-#        data = (3, "hello")
-#        formatted_log = self.debug._formatConsoleLog(data)
-#        self.assertEqual(formatted_log, "3, hello")
-
-obj = Debug()
-debug = obj.decorate
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
-
diff --git a/build/lib/build/lib/ptycho/autotest/functionmapping.py b/build/lib/build/lib/ptycho/autotest/functionmapping.py
deleted file mode 100644
index a9be5de..0000000
--- a/build/lib/build/lib/ptycho/autotest/functionmapping.py
+++ /dev/null
@@ -1,185 +0,0 @@
-# spec
-#    interface FunctionMapping {
-#        """
-#        Retrieves the log file path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - `log_directory` must be a valid directory path.
-#        - Expected JSON format: { "log_directory": "string" }
-#
-#        Postconditions:
-#        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-#        - If `log_directory` is not provided or is an empty string, returns an empty string.
-#        """
-#        string getLogFilePath(Callable func, string log_directory);
-#
-#        """
-#        Loads a function given its log file path or module path.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid log file path or empty string.
-#        - `module_path` must be a valid module path or empty string.
-#        - Expected JSON format: { "log_file_path": "string", "module_path": "string" }
-#
-#        Postconditions:
-#        - Returns the function object if successfully loaded.
-#        - If the function cannot be found or imported, returns None.
-#        """
-#        Union[Callable, None] loadFunction(string log_file_path, string module_path);
-#
-#        """
-#        Retrieves the module path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#
-#        Postconditions:
-#        - Returns the module path for the given function, formatted as `module.fname`.
-#        - If `func` is a built-in function or does not have a valid module path, returns an empty string.
-#        """
-#        string getModulePath(Callable func);
-#    };
-
-# implementation
-import os
-import shutil
-import importlib
-from typing import Callable, Optional
-
-def dprint(*args):
-    pass
-
-class FunctionMapping:
-    def __init__(self, log_directory: str = "logs"):
-        self.log_directory = log_directory
-
-    def get_log_file_path(self, func: Callable) -> str:
-        """
-        Retrieves the log file path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_log_file_path(sample_function)
-        'test_logs/__main__.sample_function.log'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        log_file_path = f"{self.log_directory}/{module_name}.{func_name}.log"
-        return log_file_path
-
-    def save_function(self, log_file_path: str, func: Callable) -> None:
-        module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-        module = importlib.import_module(module_path)
-        setattr(module, func_name, func)
-
-    def load_function_from_path(self, log_file_path: str) -> Optional[Callable]:
-        try:
-            dprint(f"log_file_path: {log_file_path}")
-            module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-            dprint(f"module_path: {module_path}")
-            dprint(f"func_name: {func_name}")
-            dprint(f"Importing module: {module_path}")
-            module = importlib.import_module(module_path)
-            dprint(f"Imported module: {module}")
-            dprint(f"Retrieving function: {func_name}")
-            func = getattr(module, func_name, None)
-            dprint(f"Retrieved function: {func}")
-            return func
-        except Exception as e:
-            dprint(f"Error loading function: {e}")
-            return None
-
-    def get_module_and_function_from_log_path(self, log_file_path: str) -> tuple:
-        dprint(f"log_file_path: {log_file_path}")
-        log_file_path = log_file_path.replace(f"{self.log_directory}/", "")
-        dprint(f"log_file_path after removing log_directory: {log_file_path}")
-        log_file_path = log_file_path.replace(".log", "")
-        dprint(f"log_file_path after removing .log: {log_file_path}")
-        parts = log_file_path.rsplit(".", 1)
-        print(parts)
-        dprint(f"parts: {parts}")
-        module_path = parts[0]
-        dprint(f"module_path: {module_path}")
-        func_name = parts[1]
-        dprint(f"func_name: {func_name}")
-        return module_path, func_name
-
-    def load_function(self, log_file_path: str) -> Optional[Callable]:
-        """
-        Loads a function given its log file path.
-        
-        Preconditions:
-        - `log_file_path` must be valid.
-        
-        Postconditions:
-        - Returns the function object if successfully loaded.
-        - If the function cannot be found or imported, returns None.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> log_file_path = function_mapping.get_log_file_path(sample_function)
-        >>> loaded_func = function_mapping.load_function(log_file_path)
-        """
-        return self.load_function_from_path(log_file_path)
-
-    def get_module_path(self, func: Callable) -> str:
-        """
-        Retrieves the module path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the module path for the given function, formatted as `module.fname`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_module_path(sample_function)
-        '__main__.sample_function'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        module_path = f"{module_name}.{func_name}"
-        return module_path
-
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-def sample_function():
-    return "sample function executed"
-
-def another_function():
-    return "another function executed"
-
-def test_get_log_file_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_log_file_path(sample_function)
-    assert path == 'test_logs/__main__.sample_function.log', f"Expected 'test_logs/__main__.sample_function.log', got '{path}'"
-
-def test_load_function():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    log_file_path = function_mapping.get_log_file_path(sample_function)
-    
-    loaded_func = function_mapping.load_function(log_file_path=log_file_path)
-    assert loaded_func is not None, "Expected function to be loaded, but got None"
-    assert loaded_func.__name__ == 'sample_function', f"Expected 'sample_function', got '{loaded_func.__name__}'"
-
-def test_get_module_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_module_path(sample_function)
-    assert path == '__main__.sample_function', f"Expected '__main__.sample_function', got '{path}'"
-
-if __name__ == "__main__":
-    test_get_log_file_path()
-    test_load_function()
-    test_get_module_path()
-    print("All tests passed!")
diff --git a/build/lib/build/lib/ptycho/autotest/logger.py b/build/lib/build/lib/ptycho/autotest/logger.py
deleted file mode 100644
index 8def564..0000000
--- a/build/lib/build/lib/ptycho/autotest/logger.py
+++ /dev/null
@@ -1,242 +0,0 @@
-from .serializer import Serializer
-# spec
-#    @depends_on(Serializer)
-#    interface Logger {
-#        """
-#        Logs function call details to a specified log file.
-#
-#        Preconditions:
-#        - `args` and `kwargs` are serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized function arguments and keyword arguments are written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logCall(bytes args, bytes kwargs, string log_file_path);
-#
-#        """
-#        Logs function return details to the specified log file.
-#
-#        Preconditions:
-#        - `result` is serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized `result` and `execution_time` are appended to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logReturn(bytes result, float execution_time, string log_file_path);
-#
-#        """
-#        Logs an error message to the specified log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The `error` message is written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logError(string error, string log_file_path);
-#
-#        """
-#        Loads a logged dataset from a log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with read permissions.
-#          The file must contain valid JSON-formatted log entries.
-#
-#        Postconditions:
-#        - Returns a list or tuple containing the logged inputs and output.
-#        - If there is an error during loading, returns an empty list or tuple.
-#        """
-#        Union[list, tuple] loadLog(Configuration configuration);
-#
-#        """
-#        Searches the log directory and returns all valid log file paths.
-#
-#        Preconditions:
-#        - `log_directory` must be a valid directory path with read permissions.
-#
-#        Postconditions:
-#        - Returns a list of valid log file paths adhering to the format ^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.?
-#        - Invalid log file paths are filtered out using the validateLogFilePath method.
-#        - If there are no valid log files or an error occurs during searching, returns an empty list.
-#        """
-#        list[str] searchLogDirectory(string log_directory);
-#
-#        """
-#        Validates a log file path against the expected format.
-#
-#        Preconditions:
-#        - `log_file_path` must be a string representing a file path.
-#
-#        Postconditions:
-#        - Returns True if the `log_file_path` adheres to the format '^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.', False otherwise.
-#        """
-#        bool validateLogFilePath(string log_file_path);
-#    };
-
-import json
-import os
-import sys
-import pickle
-from typing import Any, Union, List
-import re
-
-class Logger:
-    def __init__(self):
-        self.serializer = Serializer()
-
-    def logCall(self, args: bytes, kwargs: bytes, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "args": args.hex(),
-                    "kwargs": kwargs.hex()
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function call: {e}", file=sys.stderr)
-
-    def logReturn(self, result: bytes, execution_time: float, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "result": result.hex(),
-                    "execution_time": execution_time
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function return: {e}", file=sys.stderr)
-
-    def logError(self, error: str, log_file_path: str) -> None:
-        pass
-#        try:
-#            with open(log_file_path, 'a') as log_file:
-#                log_entry = json.dumps({
-#                    "error": error
-#                })
-#                log_file.write(log_entry + "\n")
-#        except Exception as e:
-#            print(f"Error logging error: {e}", file=sys.stderr)
-
-    def loadLog(self, log_file_path: str) -> Union[List, tuple]:
-        logs = []
-        try:
-            with open(log_file_path, 'r') as log_file:
-                for line in log_file:
-                    log_entry = json.loads(line)
-                    if "args" in log_entry:
-                        log_entry["args"] = bytes.fromhex(log_entry["args"])
-                    if "kwargs" in log_entry:
-                        log_entry["kwargs"] = bytes.fromhex(log_entry["kwargs"])
-                    if "result" in log_entry:
-                        log_entry["result"] = bytes.fromhex(log_entry["result"])
-                    logs.append(log_entry)
-        except Exception as e:
-            print(f"Error loading log: {e}", file=sys.stderr)
-        return logs
-
-    def searchLogDirectory(self, log_directory: str) -> List[str]:
-        valid_log_files = []
-        try:
-            for root, _, files in os.walk(log_directory):
-                for file in files:
-                    file_path = os.path.relpath(os.path.join(root, file), start=log_directory)
-                    if self.validateLogFilePath(file_path):
-                        valid_log_files.append(os.path.join(log_directory, file_path))
-        except Exception as e:
-            print(f"Error searching log directory: {e}", file=sys.stderr)
-        return valid_log_files
-
-    def validateLogFilePath(self, log_file_path: str) -> bool:
-        return True
-        pattern = r'^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$'
-        return re.match(pattern, log_file_path) is not None
-
-import unittest
-import tempfile
-
-class TestLogger(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.test_dir = tempfile.TemporaryDirectory()
-        self.test_file = os.path.join(self.test_dir.name, 'test.log')
-        
-    def tearDown(self):
-        self.test_dir.cleanup()
-
-    def test_logCall(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        self.logger.logCall(args, kwargs, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["args"], args.hex())
-            self.assertEqual(log_entry["kwargs"], kwargs.hex())
-
-    def test_logReturn(self):
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["result"], result.hex())
-            self.assertEqual(log_entry["execution_time"], execution_time)
-
-    def test_logError(self):
-        error = "Test error message"
-        self.logger.logError(error, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["error"], error)
-
-    def test_loadLog(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        
-        self.logger.logCall(args, kwargs, self.test_file)
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        logs = self.logger.loadLog(self.test_file)
-        self.assertEqual(len(logs), 2)
-        self.assertEqual(logs[0]["args"], args)
-        self.assertEqual(logs[0]["kwargs"], kwargs)
-        self.assertEqual(logs[1]["result"], result)
-        self.assertEqual(logs[1]["execution_time"], execution_time)
-
-    def test_searchLogDirectory(self):
-        valid_file = os.path.join(self.test_dir.name, 'logs/module.samplefunc.log')
-        invalid_file = os.path.join(self.test_dir.name, 'invalid.log')
-        
-        os.makedirs(os.path.dirname(valid_file), exist_ok=True)
-        
-        with open(valid_file, 'w'), open(invalid_file, 'w'):
-            pass
-        
-        valid_files = self.logger.searchLogDirectory(self.test_dir.name)
-        self.assertIn(valid_file, valid_files)
-        self.assertNotIn(invalid_file, valid_files)
-
-    def test_validateLogFilePath(self):
-        valid_path = 'logs/module.samplefunc.log'
-        invalid_path = 'invalid.log'
-        
-        self.assertTrue(self.logger.validateLogFilePath(valid_path))
-        self.assertFalse(self.logger.validateLogFilePath(invalid_path))
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/ptycho/autotest/serializer.py b/build/lib/build/lib/ptycho/autotest/serializer.py
deleted file mode 100644
index bbf4035..0000000
--- a/build/lib/build/lib/ptycho/autotest/serializer.py
+++ /dev/null
@@ -1,92 +0,0 @@
-# spec
-#module DebuggingSystem {
-#
-#    interface Serializer {
-#        """
-#        Serializes Python objects to a binary format using pickle.
-#
-#        Preconditions:
-#        - `input_data` must be a picklable Python object.
-#
-#        Postconditions:
-#        - Returns the serialized binary data of the input object.
-#        - Raises ValueError if the input data is not picklable.
-#        """
-#        bytes serialize(Any input_data);
-#
-#        """
-#        Deserializes Python objects from a binary format using pickle.
-#
-#        Preconditions:
-#        - `serialized_data` must be a valid pickle-serialized binary string.
-#
-#        Postconditions:
-#        - Returns the deserialized Python object.
-#        - Raises ValueError if the binary data could not be deserialized.
-#        """
-#        Any deserialize(bytes serialized_data);
-#    };
-
-import doctest
-import pickle
-from typing import Any, List
-
-class Serializer:
-    def serialize(self, input_data: Any) -> bytes:
-        """
-        Serializes Python objects to a binary format using pickle.
-
-        Preconditions:
-        - `input_data` must be a picklable Python object.
-
-        Postconditions:
-        - Returns the serialized binary data of the input object.
-        - Raises ValueError if the input data is not picklable.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> type(serialized_data)
-        <class 'bytes'>
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.serialize(lambda x: x)  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Input data is not picklable
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.dumps(input_data)
-        except (pickle.PicklingError, AttributeError, TypeError):
-            raise ValueError("Input data is not picklable")
-
-    def deserialize(self, serialized_data: bytes) -> Any:
-        """
-        Deserializes Python objects from a binary format using pickle.
-
-        Preconditions:
-        - `serialized_data` must be a valid pickle-serialized binary string.
-
-        Postconditions:
-        - Returns the deserialized Python object.
-        - Raises ValueError if the binary data could not be deserialized.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.loads(serialized_data)
-        except (pickle.UnpicklingError, EOFError, AttributeError, ImportError, IndexError):
-            raise ValueError("Could not deserialize the binary data")
-doctest.testmod(verbose=True)
-
diff --git a/build/lib/build/lib/ptycho/autotest/testing.py b/build/lib/build/lib/ptycho/autotest/testing.py
deleted file mode 100644
index 079233e..0000000
--- a/build/lib/build/lib/ptycho/autotest/testing.py
+++ /dev/null
@@ -1,163 +0,0 @@
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-import unittest
-from logger import Logger
-from functionmapping import FunctionMapping
-
-from typing import List, Tuple, Any, Optional, Callable, Union
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-    def testCallable(self, log_path_prefix: str, func: Callable) -> bool:
-        print(f"Debug: testCallable called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            for i in range(len(logs) // 2):
-                args = logs[2 * i]['args']
-                kwargs = logs[2 * i]['kwargs']
-                expected_output = logs[2 * i + 1]['result']
-                try:
-                    deserialized_args = self.logger.serializer.deserialize(args)
-                    deserialized_kwargs = self.logger.serializer.deserialize(kwargs)
-                    deserialized_expected_output = self.logger.serializer.deserialize(expected_output)
-                    actual_output = func(*deserialized_args, **deserialized_kwargs)
-                    #print(f"Debug: Actual output: {actual_output}")
-                    if actual_output != deserialized_expected_output:
-                        print("Debug: Test failed")
-                        return False
-                except Exception as e:
-                    print(f"Error testing function: {e}")
-                    return False
-        print("Debug: Test passed")
-        return True
-
-    def createTestCase(self, log_path_prefix: str) -> Union[tuple, None]:
-        print(f"Debug: createTestCase called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            if logs:
-                log = logs[0]
-                inputs = log['args']
-                expected_output = log['result']
-                func = self.function_mapping.load_function(log_file)
-                print(f"Debug: Loaded function: {func}")
-                if func is not None:
-                    return (inputs, expected_output, func)
-        print("Debug: No test case found")
-        return None
-
-    def runTestSuite(self, log_path_prefix: str) -> TestSummary:
-        print(f"Debug: runTestSuite called with log_path_prefix: {log_path_prefix}")
-        summary = TestSummary()
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            test_case = self.createTestCase(log_path_prefix)
-            if test_case is not None:
-                inputs, expected_output, func = test_case
-                if self.testCallable(log_path_prefix, func):
-                    summary.increment_passed()
-                else:
-                    summary.increment_failed()
-            else:
-                summary.increment_skipped()
-        print(f"Debug: Test summary: {summary}")
-        return summary
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-
-def add(x, y):
-    return x + y
-
-def multiply(x, y):
-    return x * y
-
-def divide(x, y):
-    return x / y
-
-class TestTesting(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.testing = Testing(self.logger, self.function_mapping)
-
-    def test_testCallable(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.assertTrue(self.testing.testCallable(log_path_prefix, add))
-
-    def test_createTestCase(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        test_case = self.testing.createTestCase(log_path_prefix)
-        self.assertIsNotNone(test_case)
-        inputs, expected_output, func = test_case
-        self.assertEqual(self.logger.serializer.deserialize(inputs), (3, 4))
-        self.assertEqual(self.logger.serializer.deserialize(expected_output), 7)
-        self.assertEqual(func, add)
-
-    def test_runTestSuite(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.logger.logReturn(log_path_prefix + '/multiply', (3, 4), 12)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        self.function_mapping.save_function(log_path_prefix + '/multiply', multiply)
-        summary = self.testing.runTestSuite(log_path_prefix)
-        self.assertIsInstance(summary, TestSummary)
-        self.assertEqual(summary.passed, 2)
-        self.assertEqual(summary.failed, 0)
-        self.assertEqual(summary.skipped, 0)
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/build/lib/ptycho/baselines.py b/build/lib/build/lib/ptycho/baselines.py
deleted file mode 100644
index 7511803..0000000
--- a/build/lib/build/lib/ptycho/baselines.py
+++ /dev/null
@@ -1,93 +0,0 @@
-# based on https://github.com/mcherukara/PtychoNN/tree/master/TF2
-# with minor changes to make comparison to PtychoPINN easier
-from .tf_helper import *
-from . import params
-import tensorflow as tf
-import numpy as np
-
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras import Sequential
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-
-tf.keras.backend.clear_session()
-np.random.seed(123)
-
-h,w=params.get('N'), params.get('N')
-nepochs=params.get('nepochs')
-wt_path = 'wts4' #Where to store network weights
-batch_size = 32
-
-n_filters_scale = params.params()['n_filters_scale']
-
-#Keras modules
-from tensorflow.keras.layers import UpSampling2D
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-
-#checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.hdf5' %wt_path,
-#                                            monitor='val_loss', verbose=1, save_best_only=True,
-#                                            save_weights_only=False, mode='auto', period=1)
-
-def build_model(X_train, Y_I_train, Y_phi_train):
-    tf.keras.backend.clear_session()
-    c = X_train.shape[-1]
-    input_img = Input(shape=(h, w, c))
-
-    x = Conv_Pool_block(input_img,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    #Activations are all ReLu
-
-    encoded=x
-
-    #Decoding arm 1
-    x1=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded1 = Conv2D(c, (3, 3), padding='same')(x1)
-
-    #Decoding arm 2
-    x2=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded2 = Conv2D(c, (3, 3), padding='same')(x2)
-    #Put together
-    autoencoder = Model(input_img, [decoded1, decoded2])
-    # Masked MAE creates a more apples-to-apples comparison with the main
-    # model, but it doesn't seem to affect the image quality
-    #autoencoder.compile(optimizer='adam', loss=masked_mae)
-    autoencoder.compile(optimizer='adam', loss='mean_absolute_error')
-    return autoencoder
-
-def train(X_train, Y_I_train, Y_phi_train, autoencoder = None):
-    if autoencoder is None:
-        autoencoder = build_model(X_train, Y_I_train, Y_phi_train)
-
-    print (autoencoder.summary())
-    #plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-
-    #history=autoencoder.fit(X_train * params.params()['intensity_scale'],
-    history=autoencoder.fit(X_train,
-        [Y_I_train, Y_phi_train], shuffle=True,
-        batch_size=batch_size, verbose=1, epochs=nepochs,
-        validation_split = 0.05, callbacks=[reduce_lr, earlystop])
-    return autoencoder, history
diff --git a/build/lib/build/lib/ptycho/classes.py b/build/lib/build/lib/ptycho/classes.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/config/__init__.py b/build/lib/build/lib/ptycho/config/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/config/config.py b/build/lib/build/lib/ptycho/config/config.py
deleted file mode 100644
index c49e74c..0000000
--- a/build/lib/build/lib/ptycho/config/config.py
+++ /dev/null
@@ -1,149 +0,0 @@
-from dataclasses import dataclass, asdict
-from pathlib import Path
-from typing import Dict, Any, Optional, Literal
-import yaml
-
-@dataclass(frozen=True)
-class ModelConfig:
-    """Core model architecture parameters."""
-    N: Literal[64, 128, 256] = 64
-    gridsize: int = 1
-    n_filters_scale: int = 2
-    model_type: Literal['pinn', 'supervised'] = 'pinn'
-    amp_activation: Literal['sigmoid', 'swish', 'softplus', 'relu'] = 'sigmoid'
-    object_big: bool = True
-    probe_big: bool = True  # Changed default
-    probe_mask: bool = False  # Changed default
-    pad_object: bool = True
-    probe_scale: float = 4.
-    gaussian_smoothing_sigma: float = 0.0
-
-@dataclass(frozen=True)
-class TrainingConfig:
-    """Training specific configuration."""
-    model: ModelConfig
-    train_data_file: Path  # Added
-    test_data_file: Optional[Path] = None  # Added
-    batch_size: int = 16
-    nepochs: int = 50
-    mae_weight: float = 0.0
-    nll_weight: float = 1.0
-    realspace_mae_weight: float = 0.0
-    realspace_weight: float = 0.0
-    nphotons: float = 1e9
-    positions_provided: bool = True  
-    probe_trainable: bool = False
-    intensity_scale_trainable: bool = True  # Changed default
-    output_dir: Path = Path("training_outputs")
-
-@dataclass(frozen=True)
-class InferenceConfig:
-    """Inference specific configuration."""
-    model: ModelConfig
-    model_path: Path
-    test_data_file: Path
-    debug: bool = False
-    output_dir: Path = Path("inference_outputs")
-
-def validate_model_config(config: ModelConfig) -> None:
-    """Validate model configuration."""
-    if config.gridsize <= 0:
-        raise ValueError(f"gridsize must be positive, got {config.gridsize}")
-    if config.n_filters_scale <= 0:
-        raise ValueError(f"n_filters_scale must be positive, got {config.n_filters_scale}")
-    if config.probe_scale <= 0:
-        raise ValueError(f"probe_scale must be positive, got {config.probe_scale}")
-    if config.gaussian_smoothing_sigma < 0:
-        raise ValueError(f"gaussian_smoothing_sigma must be non-negative, got {config.gaussian_smoothing_sigma}")
-
-def validate_training_config(config: TrainingConfig) -> None:
-    """Validate training configuration."""
-    validate_model_config(config.model)
-    if config.batch_size <= 0 or (config.batch_size & (config.batch_size - 1)):
-        raise ValueError(f"batch_size must be positive power of 2, got {config.batch_size}")
-    if config.nepochs <= 0:
-        raise ValueError(f"nepochs must be positive, got {config.nepochs}")
-    if not (0 <= config.mae_weight <= 1):
-        raise ValueError(f"mae_weight must be in [0,1], got {config.mae_weight}")
-    if not (0 <= config.nll_weight <= 1):
-        raise ValueError(f"nll_weight must be in [0,1], got {config.nll_weight}")
-    if config.nphotons <= 0:
-        raise ValueError(f"nphotons must be positive, got {config.nphotons}")
-
-def validate_inference_config(config: InferenceConfig) -> None:
-    """Validate inference configuration."""
-    validate_model_config(config.model)
-    if not config.model_path.exists():
-        raise ValueError(f"model_path does not exist: {config.model_path}")
-
-def load_yaml_config(path: Path) -> Dict[str, Any]:
-    """Load YAML configuration file.
-    
-    Args:
-        path: Path to YAML config file
-        
-    Returns:
-        Dictionary containing configuration values
-        
-    Raises:
-        OSError: If file cannot be read
-        yaml.YAMLError: If YAML is invalid
-    """
-    try:
-        with open(path) as f:
-            return yaml.safe_load(f)
-    except (OSError, yaml.YAMLError) as e:
-        raise type(e)(f"Failed to load config from {path}: {str(e)}")
-
-def dataclass_to_legacy_dict(obj: Any) -> Dict[str, Any]:
-    """Convert dataclass to legacy dictionary format with key mappings.
-    
-    Args:
-        obj: Dataclass instance to convert
-        
-    Returns:
-        Dictionary with legacy parameter names and values
-    """
-    # Key mappings from dataclass field names to legacy param names
-    KEY_MAPPINGS = {
-        'object_big': 'object.big',
-        'probe_big': 'probe.big', 
-        'probe_mask': 'probe.mask',
-        'probe_trainable': 'probe.trainable',
-        'intensity_scale_trainable': 'intensity_scale.trainable',
-        'positions_provided': 'positions.provided',
-        'output_dir': 'output_prefix'
-    }
-
-    # Convert dataclass to dict
-    d = asdict(obj)
-
-    # Handle nested ModelConfig
-    if 'model' in d:
-        model_dict = d.pop('model')
-        d.update(model_dict)
-
-    # Apply key mappings
-    for old_key, new_key in KEY_MAPPINGS.items():
-        if old_key in d:
-            d[new_key] = d.pop(old_key)
-
-    # Convert Path to string
-    if 'output_dir' in d:
-        d['output_prefix'] = str(d.pop('output_dir'))
-
-    return d
-
-def update_legacy_dict(cfg: Dict[str, Any], dataclass_obj: Any) -> None:
-    """Update legacy dictionary with dataclass values.
-    
-    Updates all values from the dataclass, adding new keys if needed.
-    
-    Args:
-        cfg: Legacy dictionary to update
-        dataclass_obj: Dataclass instance containing new values
-    """
-    new_values = dataclass_to_legacy_dict(dataclass_obj)
-    
-    # Update all values from dataclass
-    cfg.update(new_values)
diff --git a/build/lib/build/lib/ptycho/data_preprocessing.py b/build/lib/build/lib/ptycho/data_preprocessing.py
deleted file mode 100644
index 6a49d58..0000000
--- a/build/lib/build/lib/ptycho/data_preprocessing.py
+++ /dev/null
@@ -1,189 +0,0 @@
-from sklearn.utils import shuffle
-import numpy as np
-
-from ptycho import params
-from ptycho import diffsim as datasets
-import tensorflow as tf
-
-from .loader import PtychoDataset, PtychoDataContainer
-from ptycho import loader
-from ptycho import probe
-
-if params.get('outer_offset_train') is None or params.get('outer_offset_test') is None:
-    assert params.get('data_source') == 'generic'
-
-def load_simulated_data(size, probe, outer_offset_train, outer_offset_test, jitter_scale, intensity_scale=None):
-    np.random.seed(1)
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), size, probe, outer_offset_train, jitter_scale=jitter_scale, which = 'train')
-    params.cfg['intensity_scale'] = intensity_scale
-
-    np.random.seed(2)
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, which = 'test')
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_experimental_data(probe, outer_offset_train, outer_offset_test, jitter_scale):
-    from ptycho import experimental
-    YY_I, YY_phi = experimental.get_full_experimental('train')
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), experimental.train_size, probe, outer_offset_train, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    YY_I, YY_phi = experimental.get_full_experimental('test')
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), experimental.test_size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_xpp_data(probeGuess):
-    from ptycho import xpp
-    train_data_container = loader.load(xpp.get_data, probeGuess, which='train')
-    test_data_container = loader.load(xpp.get_data, probeGuess, which='test')
-    return train_data_container, test_data_container
-
-def load_generic_data(probeGuess, N):
-    from ptycho.raw_data import RawData
-    train_data_file_path = params.get('train_data_file_path')
-    test_data_file_path = params.get('test_data_file_path')
-
-    train_raw = RawData.from_file(train_data_file_path)
-    test_raw = RawData.from_file(test_data_file_path)
-
-    dset_train = train_raw.generate_grouped_data(N, K=7, nsamples=1)
-    dset_test = test_raw.generate_grouped_data(N, K=7, nsamples=1)
-
-    train_data_container = loader.load(lambda: dset_train, probeGuess, which=None, create_split=False)
-    test_data_container = loader.load(lambda: dset_test, probeGuess, which=None, create_split=False)
-    return train_data_container, test_data_container
-
-def shuffle_data(X, Y_I, Y_phi, random_state=0):
-    indices = np.arange(len(Y_I))
-    indices_shuffled = shuffle(indices, random_state=random_state)
-
-    X_shuffled = X[indices_shuffled]
-    Y_I_shuffled = Y_I[indices_shuffled]
-    Y_phi_shuffled = Y_phi[indices_shuffled]
-
-    return X_shuffled, Y_I_shuffled, Y_phi_shuffled, indices_shuffled
-
-def get_clipped_object(YY_full, outer_offset):
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-
-    extra_size = (YY_full.shape[1] - (params.cfg['N'] + (params.cfg['gridsize'] - 1) * params.cfg['offset'])) % (outer_offset // 2)
-    if extra_size > 0:
-        YY_ground_truth = YY_full[:, :-extra_size, :-extra_size]
-    else:
-        print('discarding length {} from test image'.format(extra_size))
-        YY_ground_truth = YY_full
-    YY_ground_truth = YY_ground_truth[:, clipleft:-clipright, clipleft:-clipright]
-    return YY_ground_truth
-
-def get_clip_sizes(outer_offset):
-    N = params.cfg['N']
-    gridsize = params.cfg['gridsize']
-    offset = params.cfg['offset']
-    bordersize = (N - outer_offset / 2) / 2
-    borderleft = int(np.ceil(bordersize))
-    borderright = int(np.floor(bordersize))
-    clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-    clipleft = int(np.ceil(clipsize))
-    clipright = int(np.floor(clipsize))
-    return borderleft, borderright, clipleft, clipright
-
-def stitch_data(b, norm_Y_I_test=1, norm=True, part='amp', outer_offset=None, nimgs=None):
-    # channel size must be 1, or not present
-    if b.shape[-1] != 1:
-        assert b.shape[-1] == params.get(['N'])
-    if nimgs is None:
-        nimgs = params.get('nimgs_test')
-    if outer_offset is None:
-        outer_offset = params.get('outer_offset_test')
-    nsegments = int(np.sqrt((int(tf.size(b)) / nimgs) / (params.cfg['N']**2)))
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    else:
-        img_recon = np.reshape((getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    return stitched
-
-def reassemble(b, norm_Y_I = 1., part='amp', **kwargs):
-    stitched = stitch_data(b, norm_Y_I, norm=False, part=part, **kwargs)
-    return stitched
-
-def process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test):
-    X_train, Y_I_train, Y_phi_train, indices_shuffled = shuffle_data(np.array(X_train), np.array(Y_I_train), np.array(Y_phi_train))
-    if params.get('outer_offset_train') is not None:
-        YY_ground_truth_all = get_clipped_object(YY_test_full, outer_offset_test)
-        YY_ground_truth = YY_ground_truth_all[0, ...]
-        print('DEBUG: generating grid-mode ground truth image')
-    else:
-        YY_ground_truth = None
-        print('DEBUG: No ground truth image in non-grid mode')
-    return X_train, Y_I_train, Y_phi_train, YY_ground_truth
-
-def create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                          X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true):
-    return PtychoDataset(
-        PtychoDataContainer(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true, None, None, None, probe.get_probe(params)),
-        PtychoDataContainer(X_test, Y_I_test, Y_phi_test, intensity_scale, YY_test_full, coords_test_nominal, coords_test_true, None, None, None, probe.get_probe(params)),
-    )
-
-def generate_data(probeGuess = None):
-    # TODO handle probeGuess None case
-    data_source = params.params()['data_source']
-    probe_np = probe.get_probe(params)
-    outer_offset_train = params.cfg['outer_offset_train']
-    outer_offset_test = params.cfg['outer_offset_test']
-    YY_test_full = None
-    norm_Y_I_test = None
-
-    if data_source in ['lines', 'grf', 'points', 'testimg', 'diagonals', 'V']:
-        size = params.cfg['size']
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_simulated_data(size, probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'experimental':
-        # Ensure nimgs parameters are 1 for experimental data
-        assert params.get('nimgs_train') == 1, "nimgs_train must be 1 for experimental data"
-        assert params.get('nimgs_test') == 1, "nimgs_test must be 1 for experimental data"
-        
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_experimental_data(probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'xpp':
-        test_data_container, train_data_container = load_xpp_data(probeGuess)
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        YY_test_full = None
-    elif data_source == 'generic':
-        train_data_container, test_data_container = load_generic_data(probeGuess, params.cfg['N'])
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        print('INFO: train data:')
-        print(train_data_container)
-        print('INFO: test data:')
-        print(test_data_container)
-    else:
-        raise ValueError("Invalid data source")
-
-    params.cfg['intensity_scale'] = intensity_scale
-    return ptycho_dataset.train_data.X, ptycho_dataset.train_data.Y_I, ptycho_dataset.train_data.Y_phi, ptycho_dataset.test_data.X, ptycho_dataset.test_data.Y_I, ptycho_dataset.test_data.Y_phi, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
diff --git a/build/lib/build/lib/ptycho/datagen/__init__.py b/build/lib/build/lib/ptycho/datagen/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/datagen/diagonals.py b/build/lib/build/lib/ptycho/datagen/diagonals.py
deleted file mode 100644
index 1c4bac9..0000000
--- a/build/lib/build/lib/ptycho/datagen/diagonals.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import numpy as np
-
-def draw_lines(shape, num):
-    num_vertical = num_horizontal = num_diagonal = num
-    # Create a 2D NumPy array with zeros
-    arr = np.zeros(shape)
-    n, m = shape
-
-    # Draw vertical lines
-    for i in range(num_vertical):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        arr[:, x] = 1
-
-    # Draw horizontal lines
-    for i in range(num_horizontal):
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        arr[y, :] = 1
-
-    # Draw diagonal lines
-    for i in range(num_diagonal):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        off = min(x, y)
-        x = x - off
-        y = y - off
-        ix = np.arange(x, n - y)
-        iy = np.arange(y, m - x)
-        arr[ix, iy] = 1
-        arr[ix, -iy] = 1
-
-    return arr
-
-
-from scipy.ndimage import gaussian_filter as gf
-def mk_diags(N, sigma = .75):
-    img = draw_lines((N, N), 40)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/ptycho/datagen/grf.py b/build/lib/build/lib/ptycho/datagen/grf.py
deleted file mode 100644
index 8ab01fd..0000000
--- a/build/lib/build/lib/ptycho/datagen/grf.py
+++ /dev/null
@@ -1,73 +0,0 @@
-# credit https://github.com/PabloVD/MapGenerator
-
-import matplotlib.pyplot as plt
-import numpy as np
-import powerbox as pbox
-from scipy import interpolate, ndimage
-
-#--- Parameters for GRF---#
-
-
-# Number of bins per dimension
-boxsize = 100#(max(xx.shape) + 1) // 2#xx.shape[0] // 2
-# Number of bins per dimension in the high resolution  box
-
-# Define power spectrum as a power law with an spectral index indexlaw
-# With lower the spectral indexes, small structures are removed
-def powerspec(k,indexlaw):
-    return k**indexlaw
-
-# Filter the field with a gaussian window
-def smooth_field(field,sigmagauss,gridsize=boxsize):
-
-    x, y = np.linspace(0,field.shape[0],num=field.shape[0]), np.linspace(0,field.shape[1],num=field.shape[1])
-
-    # Interpolation
-    f = interpolate.interp2d(x,y,field,kind="linear")
-
-    qx = np.linspace(x[0],x[-1], num = gridsize)
-    qy = np.linspace(y[0],y[-1], num = gridsize)
-
-    # Filtering
-    smooth = ndimage.filters.gaussian_filter(f(qx,qy),sigmagauss)
-    return smooth
-
-# Remove regions below sea level
-def mainland(field,threshold):
-    for i, row in enumerate(field):
-        for j, el in enumerate(row):
-            if el<threshold:   field[i,j]=0.
-    return field
-
-# Normalize the values of the field between 0 and 1
-def normalize_field(field):
-    min, max = np.amin(field), np.amax(field)
-    newfield = (field-min)/(max-min)
-    return newfield
-
-# Generate a map of islands applying different processes:
-# 1. Generate a random gaussian field given a power spectrum
-# 2. Normalize the field between 0 and 1
-# 3. Smooth the field with a gaussian filter
-# 4. Retain only the mainland above a certain threshold
-def generate_map(indexlaw,sigma,threshold, boxsize):
-    # Number of bins per dimension in the high resolution  box
-    highboxsize = 2*boxsize
-    field = pbox.powerbox.PowerBox(boxsize, lambda k: powerspec(k,indexlaw), dim=2, boxlength=100.).delta_x()
-    field = normalize_field(field)
-    field = smooth_field(field,sigma,gridsize=highboxsize)
-    return field
-
-def mk_grf(N):
-    assert not N % 2
-    boxsize = N // 2
-    # Threshold for the sea level
-    threshold = 0.4
-    # Sigma for the gaussian smoothing
-    sigma = 1
-    # Spectral index for the power spectrum
-    indexlaw = -.4
-    res = np.zeros((N, N, 1))
-    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-    return res
-
diff --git a/build/lib/build/lib/ptycho/datagen/points.py b/build/lib/build/lib/ptycho/datagen/points.py
deleted file mode 100644
index eb415e4..0000000
--- a/build/lib/build/lib/ptycho/datagen/points.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def randones(N, pct = .1):
-    """
-    Return array whose entries are randomly either 0 or 1.
-    """
-    rows, cols = N, N
-
-    # define the percentage of entries to increment
-    pct = 0.1
-
-    # create a 2D numpy array of all 0s
-    arr = np.zeros((rows, cols))
-
-    # determine the number of entries to increment
-    num_entries = int(rows * cols * pct)
-
-    # randomly select indices to increment with replacement
-    indices = np.random.choice(rows * cols, num_entries)
-
-    # increment the values at the selected indices by 1
-    np.add.at(arr, np.unravel_index(indices, (rows, cols)), 1)
-
-    # print the resulting array
-    return arr
-
-
-def mk_points(N, sigma = 1, pct = .15):
-    img = randones(N, pct = pct)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/build/lib/ptycho/datagen/testimg.py b/build/lib/build/lib/ptycho/datagen/testimg.py
deleted file mode 100644
index 5f49b13..0000000
--- a/build/lib/build/lib/ptycho/datagen/testimg.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-import os
-from scipy import misc
-from imageio import imread
-from ptycho import tf_helper as hh
-from ptycho import params
-import tensorflow as tf
-
-def first_and_last(it):
-    it = iter(it)  # Ensure it's an iterator
-    try:
-        first = next(it)  # Get the first item
-    except StopIteration:
-        return  # If the iterator is empty, return an empty iterator
-    last = None
-    for last in it:  # Traverse the rest of the iterator to find the last item
-        pass
-    if last is None:
-        yield first
-    else:
-        yield first
-        yield last
-
-path = './'
-image = imread(os.path.join(path,'williamson.jpeg')).astype(float)
-image /= image.mean()
-image = image[None, 100:, :, :1]
-
-N = params.get('size')
-imgs = hh.extract_patches(image, N, N)
-imgs = tf.reshape(imgs, (-1,) + (N, N))
-
-# Convert TensorFlow tensor to NumPy array for reversible operations
-imgs_np = imgs.numpy()
-rev = imgs_np[::-1]  # Reversing using NumPy slicing
-
-# Convert back to TensorFlow tensor if needed
-rev_tensor = tf.convert_to_tensor(rev, dtype=tf.float32)
-it = iter(imgs_np)  # Iterator for original order
-rev_it = iter(rev_tensor)  # Iterator for reversed order
-
-def get_block(reverse = False):
-    if reverse:
-        return np.array(next(rev_it))
-    return np.array(next(it))
-
-def get_img(N = None, sigma = .5, reverse = False):
-    img = get_block(reverse = reverse)
-    # Anti-aliasing
-    img = gf(img, sigma)
-    img = img[:, :, None]
-    return img
-
diff --git a/build/lib/build/lib/ptycho/datagen/vendetta.py b/build/lib/build/lib/ptycho/datagen/vendetta.py
deleted file mode 100644
index 5676c59..0000000
--- a/build/lib/build/lib/ptycho/datagen/vendetta.py
+++ /dev/null
@@ -1,78 +0,0 @@
-import numpy as np
-import scipy.ndimage
-import matplotlib.pyplot as plt
-
-from scipy.ndimage import zoom
-import numpy as np
-
-from PIL import Image, ImageDraw, ImageFont
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def letter_to_array(letter, font_path, font_size, image_size):
-    # Create a blank image
-    img = Image.new('L', image_size, 255)  # 'L' stands for 8-bit pixels, black and white
-
-    # Get drawing context
-    d = ImageDraw.Draw(img)
-
-    # Define font
-    font = ImageFont.truetype(font_path, font_size)
-
-    # Get text width and height
-    text_width, text_height = d.textsize(letter, font=font)
-
-    # Calculate X, Y position of the text
-    x = (image_size[0] - text_width) / 2
-    y = (image_size[1] - text_height) / 2
-
-    # Draw the text onto the image
-    d.text((x, y), letter, font=font, fill=(0))
-
-    # Convert the image data to a numpy array
-    data = np.array(img)
-
-    # Convert to binary (0 and 1)
-    binary_data = np.where(data < 128, 1, 0)
-
-    return binary_data
-
-# Use a font available on your system (this path is for demonstration; adjust accordingly)
-font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
-sprite = letter_to_array('V', font_path, font_size=50, image_size=(60, 60))
-
-def create_canvas(size):
-    return np.zeros((size, size))
-
-def create_sprite():
-    return sprite
-
-def add_sprite_to_canvas(canvas, sprite, repetitions):
-    for _ in range(repetitions):
-        scale = 0.05 + .4 * np.random.rand()
-        scaled_sprite = scipy.ndimage.zoom(sprite, scale)
-
-        tx = np.random.randint(0, canvas.shape[0] - scaled_sprite.shape[0])
-        ty = np.random.randint(0, canvas.shape[1] - scaled_sprite.shape[1])
-
-        x_end = min(tx + scaled_sprite.shape[0], canvas.shape[0])
-        y_end = min(ty + scaled_sprite.shape[1], canvas.shape[1])
-
-        canvas[tx:x_end, ty:y_end] += scaled_sprite[:x_end-tx, :y_end-ty]
-
-#def visualize_canvas(canvas):
-#    plt.imshow(canvas, cmap='gray')
-#    plt.show()
-
-def mk_vs(N, nfeats = 1000):
-    from . import fourier as f
-    assert not N % 2
-    canvas = create_canvas(N)
-    sprite = create_sprite()
-    add_sprite_to_canvas(canvas, sprite, nfeats)
-    res = canvas[..., None]
-    res = f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-    return res / res.max()
-#    res = np.zeros((N, N, 1))
-#    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-#    return res
diff --git a/build/lib/build/lib/ptycho/diffsim.py b/build/lib/build/lib/ptycho/diffsim.py
deleted file mode 100644
index be005a6..0000000
--- a/build/lib/build/lib/ptycho/diffsim.py
+++ /dev/null
@@ -1,234 +0,0 @@
-from skimage import draw, morphology
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import matplotlib.pyplot as plt
-import numpy as np
-import tensorflow as tf
-
-from . import fourier as f
-from . import tf_helper as hh
-from . import params as p
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-
-N = 64
-
-def observe_amplitude(amplitude):
-    """
-    Sample photons from wave amplitudes by drwaing from the corresponding Poisson distributions
-    """
-    return tf.sqrt((hh.tfd.Independent(hh.tfd.Poisson(amplitude**2))).sample())# + 0.5
-
-def count_photons(obj):
-    return tf.math.reduce_sum(obj**2, (1, 2))
-
-def scale_nphotons(padded_obj):
-    """
-    Calculate the object amplitude normalization factor that gives the desired
-    *expected* number of observed photons, averaged over an entire dataset.
-
-    Returns a single scalar.
-    """
-    mean_photons = tf.math.reduce_mean(count_photons(padded_obj))
-    norm = tf.math.sqrt(p.get('nphotons') / mean_photons)
-    return norm
-
-def diffract_obj(sample, draw_poisson = True):
-    N = p.get('N')
-    amplitude = hh.pad_and_diffract(sample, N, N, pad=False)[1]
-    if draw_poisson:
-        observed_amp = observe_amplitude(amplitude)
-        return observed_amp
-    else:
-        return amplitude
-
-def illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = None):
-    """
-    Illuminate object with real or complex probe, then apply diffraction map.
-
-    Returned Y_I and Y_phi are amplitude and phase *after* illumination with the
-    probe.
-    """
-    # ensure probe is broadcastable
-    if len(probe.shape) == 2:
-        assert probe.shape[0] == probe.shape[1]
-        probe = probe[..., None]
-    elif len(probe.shape) == 3:
-        assert probe.shape[-1] == 1
-    if intensity_scale is None:
-        probe_amplitude = tf.cast(tf.abs(probe), Y_I.dtype)
-        intensity_scale = scale_nphotons(Y_I * probe_amplitude[None, ...]).numpy()
-    batch_size = p.get('batch_size')
-    obj = intensity_scale * hh.combine_complex(Y_I, Y_phi)
-    obj = obj * tf.cast(probe[None, ...], obj.dtype)
-    Y_I = tf.math.abs(obj)
-
-    X = (tf.data.Dataset.from_tensor_slices(obj)
-               .batch(batch_size)
-               .prefetch(tf.data.AUTOTUNE)
-               .map(diffract_obj)
-               .cache())
-    X = np.vstack(list(iter(X)))
-    X, Y_I, Y_phi =\
-        X / intensity_scale, Y_I / intensity_scale, Y_phi
-
-    X, Y_I, Y_phi =\
-        hh.togrid(X, Y_I, Y_phi)
-
-    X, Y_I, Y_phi =\
-        hh.grid_to_channel(X, Y_I, Y_phi)
-
-    return X, Y_I, Y_phi, intensity_scale
-
-def mk_rand(N):
-    return int(N * np.random.uniform())
-
-def mk_lines_img(N = 64, nlines = 10):
-    image = np.zeros((N, N))
-    for _ in range(nlines):
-        rr, cc = draw.line(mk_rand(N), mk_rand(N), mk_rand(N), mk_rand(N))
-        image[rr, cc] = 1
-    res = np.zeros((N, N, 3))
-    res[:, :, :] = image[..., None]
-    return f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-
-def mk_noise(N = 64, nlines = 10):
-    return np.random.uniform(size = N * N).reshape((N, N, 1))
-
-from ptycho.misc import memoize_disk_and_memory
-
-def extract_coords(size, repeats = 1, coord_type = 'offsets',
-        outer_offset = None, **kwargs):
-    """
-    Return nominal offset coords in channel format. x and y offsets are
-    stacked in the third dimension.
-
-    offset coordinates are r - r', where
-        r' is the patch center of mass
-        r is the center of mass of that patch's solution region / grid,
-            which contains gridsize**2 patches
-    """
-    x = tf.range(size, dtype = tf.float32)
-    y = tf.range(size, dtype = tf.float32)
-    xx, yy = tf.meshgrid(x, y)
-    xx = xx[None, ..., None]
-    yy = yy[None, ..., None]
-    def _extract_coords(zz, fn):
-        ix = fn(zz)
-        ix = tf.reduce_mean(ix, axis = (1, 2))
-        return tf.repeat(ix, repeats, axis = 0)[:, None, None, :]
-    def outer(img):
-        return hh.extract_outer(img, fmt = 'grid', outer_offset = outer_offset)
-    def inner(img):
-        return hh.extract_nested_patches(img, fmt = 'channel',
-            outer_offset = outer_offset)
-    def get_patch_offsets(coords):
-        offsets_x = coords[1][0] - coords[0][0]
-        offsets_y = coords[1][1] - coords[0][1]
-        return tf.stack([offsets_x, offsets_y], axis = 2)[:, :, :, 0, :]
-    ix = _extract_coords(xx, inner)
-    iy = _extract_coords(yy, inner)
-    ix_offsets = _extract_coords(xx, outer)
-    iy_offsets = _extract_coords(yy, outer)
-    coords = ((ix, iy), (ix_offsets, iy_offsets))
-    if coord_type == 'offsets':
-        return get_patch_offsets(coords)
-    elif coord_type == 'global':
-        return (ix, iy)
-    else:
-        raise ValueError
-
-def add_position_jitter(coords, jitter_scale):
-    shape = coords.shape
-    jitter = jitter_scale * tf.random.normal(shape)
-    return jitter + coords
-
-def scan_and_normalize(jitter_scale = None, YY_I = None, YY_phi = None,
-        **kwargs):
-    """
-    Inputs:
-    4d tensors of full (arbitrary-sized) object phase and amplitude.
-
-    Returns (normalized) amplitude and phase and scan point offsets.
-
-    coords: tuple of two tuples. First gives center coords for each
-    small image patch. Second gives offset coords for each solution
-    region.
-    """
-    size = YY_I.shape[1]
-    n = YY_I.shape[0]
-    coords = true_coords = extract_coords(size, n, **kwargs)
-    if jitter_scale is not None:
-        print('simulating gaussian position jitter, scale', jitter_scale)
-        true_coords = add_position_jitter(coords, jitter_scale)
-
-    Y_I, Y_phi, _Y_I_full, norm_Y_I = hh.preprocess_objects(YY_I,
-        offsets_xy = true_coords, Y_phi = YY_phi, **kwargs)
-    return Y_I, Y_phi, _Y_I_full, norm_Y_I, (coords, true_coords)
-
-import math
-def dummy_phi(Y_I):
-    return tf.cast(tf.constant(math.pi), tf.float32) *\
-        tf.cast(tf.math.tanh( (Y_I - tf.math.reduce_max(Y_I) / 2) /
-            (3 * tf.math.reduce_mean(Y_I))), tf.float32)
-
-def sim_object_image(size, which = 'train'):
-    if p.get('data_source') == 'lines':
-        return mk_lines_img(2 * size, nlines = 400)[size // 2: -size // 2, size // 2: -size // 2, :1]
-    elif p.get('data_source') == 'grf':
-        from .datagen import grf
-        return grf.mk_grf(size)
-    elif p.get('data_source') == 'points':
-        from .datagen import points
-        return points.mk_points(size)
-    elif p.get('data_source') == 'testimg':
-        from .datagen import testimg
-        if which == 'train':
-            return testimg.get_img(size)
-        elif which == 'test':
-            return testimg.get_img(size, reverse = True)
-        else:
-            raise ValueError
-    elif p.get('data_source') == 'testimg_reverse':
-        from .datagen import testimg
-        return testimg.get_img(size, reverse = True)
-    elif p.get('data_source') == 'diagonals':
-        from .datagen import diagonals
-        return diagonals.mk_diags(size)
-    elif p.get('data_source') == 'V':
-        from .datagen import vendetta
-        return vendetta.mk_vs(size)
-    else:
-        raise ValueError
-
-@memoize_disk_and_memory
-def mk_simdata(n, size, probe, outer_offset, intensity_scale = None,
-        YY_I = None, YY_phi = None, dict_fmt = False,  which = 'train', **kwargs):
-    if YY_I is None:
-        YY_I = np.array([sim_object_image(size, which = which)
-              for _ in range(n)])
-    if p.get('set_phi') and YY_phi is None:
-        YY_phi = dummy_phi(YY_I)
-    Y_I, Y_phi, _, norm_Y_I, coords = scan_and_normalize(YY_I = YY_I,
-        YY_phi = YY_phi, outer_offset = outer_offset, **kwargs)
-    if dict_fmt:
-        d = dict()
-        d['I_pre_probe'] = Y_I
-        d['phi_pre_probe'] = Y_phi
-    X, Y_I, Y_phi, intensity_scale =\
-        illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = intensity_scale)
-    if YY_phi is None:
-        YY_full = hh.combine_complex(YY_I, tf.zeros_like(YY_I))
-    else:
-        YY_full = hh.combine_complex(YY_I, YY_phi)
-    if dict_fmt:
-        d['X'] = X
-        d['Y_I'] = Y_I
-        d['Y_phi'] = Y_phi
-        d['intensity_scale'] = intensity_scale
-        d['norm_Y_I'] = norm_Y_I
-        d['coords'] = coords
-        return d
-    return X, Y_I, Y_phi, intensity_scale, YY_full,\
-        norm_Y_I, coords
diff --git a/build/lib/build/lib/ptycho/evaluation.py b/build/lib/build/lib/ptycho/evaluation.py
deleted file mode 100644
index 51274e4..0000000
--- a/build/lib/build/lib/ptycho/evaluation.py
+++ /dev/null
@@ -1,275 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib
-import tensorflow as tf
-
-from ptycho import params
-from ptycho import misc
-
-def recon_patches(patches):
-    """
-    chop channel dimension size to 1, then patch together a single image
-    """
-    from ptycho import generate_data as data
-    return data.reassemble(patches[:, :, :, :1])[0]
-
-def symmetrize(arr):
-    return (arr + arr[::-1, ::-1]) / 2
-
-def symmetrize_3d(arr):
-    return (arr + arr[:, ::-1, ::-1]) / 2
-
-def cropshow(arr, *args, crop = True, **kwargs):
-    if crop:
-        arr = arr[16:-16, 16:-16]
-    plt.imshow(arr, *args, **kwargs)
-
-from scipy.ndimage import gaussian_filter as gf
-
-def summarize(i, a, b, X_test, Y_I_test, Y_phi_test, probe, channel = 0, **kwargs):
-    from . import params as cfg
-    plt.rcParams["figure.figsize"] = (10, 10)
-    vmin = 0
-    vmax = np.absolute(b)[i].max()
-
-    heatmaps = {}  # initialize the dictionary to store the heatmaps
-    probe = np.absolute(probe)
-    aa, bb = 3, 3
-    plt.subplot(aa, bb, 1)
-    plt.title('True amp.\n(illuminated)')
-    true_amp_illuminated = (Y_I_test[i, :, :, channel])
-    cropshow(true_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_illuminated'] = true_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 2)
-    plt.title('Reconstructed amp.\n(illuminated)')
-    rec_amp_illuminated = (np.absolute(b))[i] * probe[..., None]
-    cropshow(rec_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_illuminated'] = rec_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 3)
-    plt.title('True phase')
-    true_phase = ((Y_phi_test * (probe > .01)[..., None]))[i, :, :, channel]
-    cropshow(true_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['true_phase'] = true_phase  # add to the dictionary
-
-    plt.subplot(aa, bb, 4)
-    plt.title('True amp.\n(full)')
-    true_amp_full = (Y_I_test[i, :, :, channel] / (probe + 1e-9))
-    cropshow(true_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_full'] = true_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 5)
-    plt.title('Reconstructed amp. (full)')
-    rec_amp_full = (np.absolute(b))[i]
-    cropshow(rec_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_full'] = rec_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 6)
-    plt.title('Reconstructed phase')
-    rec_phase = (np.angle(b) * (probe > .01)[..., None])[i]
-    rec_phase[np.isclose(rec_phase,  0)] = np.nan
-    cropshow(rec_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['rec_phase'] = rec_phase  # add to the dictionary
-    print('phase min:', np.min((np.angle(b) * (probe > .01)[..., None])),
-        'phase max:', np.max((np.angle(b) * (probe > .01)[..., None])))
-
-    plt.subplot(aa, bb, 7)
-    plt.title('True diffraction')
-    true_diffraction = np.log(cfg.get('intensity_scale') * X_test)[i, :, :, channel]
-    plt.imshow(true_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['true_diffraction'] = true_diffraction  # add to the dictionary
-
-    plt.subplot(aa, bb, 8)
-    plt.title('Recon diffraction')
-    rec_diffraction = np.log(a)[i, :, :, channel]
-    plt.imshow(rec_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['rec_diffraction'] = rec_diffraction  # add to the dictionary
-
-    return heatmaps
-
-def plt_metrics(history, loss_type = 'MAE', metric2 = 'padded_obj_loss'):
-    hist=history
-    epochs=np.asarray(history.epoch)+1
-
-    plt.style.use('seaborn-white')
-    matplotlib.rc('font',family='Times New Roman')
-    matplotlib.rcParams['font.size'] = 12
-
-    f, axarr = plt.subplots(2, sharex=True, figsize=(12, 8))
-
-    axarr[0].set(ylabel='Loss')
-    axarr[0].plot(epochs,hist.history['loss'], 'C3o', label='Diffraction {} Training'.format(loss_type))
-    axarr[0].plot(epochs,hist.history['val_loss'], 'C3-', label='Diffraction {} Validation'.format(loss_type))
-    axarr[0].grid()
-    axarr[0].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-
-    axarr[1].set(ylabel='Loss')
-    axarr[1].plot(epochs,hist.history[metric2], 'C0o', label='Object {} Training'.format(loss_type))
-    axarr[1].plot(epochs,hist.history['val_' + metric2], 'C0-', label='Object {} Validation'.format(loss_type))
-    axarr[1].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-    plt.xlabel('Epochs')
-    plt.tight_layout()
-    #plt.semilogy()
-    axarr[1].grid()
-
-import scipy.fftpack as fftpack
-fp = fftpack
-
-def trim(arr2d):
-    offset = params.get('offset')
-    assert not (offset % 2)
-    return arr2d[offset // 2:-offset // 2, offset // 2:-offset // 2]
-
-def mae(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean(np.absolute(target - scale * pred))
-
-def mse(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean((target - scale * pred)**2)
-
-def psnr(target, pred, normalize = True, shift = False):
-    """
-    for phase inputs, assume that global shift has already been taken care off
-    """
-    import cv2
-    target = np.array(target)
-    pred = np.array(pred)
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    if shift:
-        offset = min(np.min(target), np.min(pred))
-        target = target - offset
-        pred = pred - offset
-    pred = scale * pred
-    return cv2.PSNR(target, pred)
-
-def fft2d(aphi):
-    F1 = fftpack.fft2((aphi).astype(float))
-    F2 = fftpack.fftshift(F1)
-    return F2
-
-def highpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-
-    F2[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 0
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def lowpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-    mask = np.zeros_like(F2)
-    mask[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 1.
-    F2 = F2 * mask
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def frc50(target, pred, sigma = 1):
-    if np.isnan(pred).all():
-        raise ValueError
-    if np.max(target) == np.min(target) == 0:
-        return None, np.nan
-    from FRC import fourier_ring_corr as frc
-    shellcorr = frc.FSC(np.array(target), np.array(pred))
-    shellcorr = gf(shellcorr, sigma)
-    return shellcorr, np.where(shellcorr < .5)[0][0]
-
-
-
-def eval_reconstruction(stitched_obj, ground_truth_obj, lowpass_n = 1,
-        label = ''):
-    # TODO consistent shapes
-    assert stitched_obj.shape[1] == ground_truth_obj.shape[1]
-    assert np.ndim(ground_truth_obj) == 3
-    assert int(np.ndim(stitched_obj)) in [3, 4]
-    if np.ndim(stitched_obj) == 4:
-        stitched_obj = stitched_obj[0]
-    YY_ground_truth = np.absolute(ground_truth_obj)
-    YY_phi_ground_truth = np.angle(ground_truth_obj)
-
-    phi_pred = trim(
-        highpass2d(
-            np.squeeze(np.angle(stitched_obj)), n = lowpass_n
-        )
-    )
-    phi_target = trim(
-        highpass2d(
-            np.squeeze(YY_phi_ground_truth), n = lowpass_n
-        )
-    )
-    amp_target = tf.cast(trim(YY_ground_truth), tf.float32)
-    amp_pred = trim(np.absolute(stitched_obj))
-
-    # TODO complex FRC?
-    mae_amp = mae(amp_target, amp_pred) # PINN
-    mse_amp = mse(amp_target, amp_pred) # PINN
-    psnr_amp = psnr(amp_target[:, :, 0], amp_pred[:, :, 0], normalize = True,
-        shift = False)
-    frc_amp, frc50_amp = frc50(amp_target[:, :, 0], amp_pred[:, :, 0])
-
-    mae_phi = mae(phi_target, phi_pred, normalize=False) # PINN
-    mse_phi = mse(phi_target, phi_pred, normalize=False) # PINN
-    psnr_phi = psnr(phi_target, phi_pred, normalize = False, shift = True)
-    frc_phi, frc50_phi = frc50(phi_target, phi_pred)
-
-    return {'mae': (mae_amp, mae_phi),
-        'mse': (mse_amp, mse_phi),
-        'psnr': (psnr_amp, psnr_phi),
-        'frc50': (frc50_amp, frc50_phi),
-        'frc': (frc_amp, frc_phi)}
-
-
-import pandas as pd
-import os
-import dill
-def save_metrics(stitched_obj, YY_ground_truth,  label = ''):
-    """
-    evaluate reconstruction and save the result to disk.
-    """
-    out_prefix = misc.get_path_prefix()
-    os.makedirs(out_prefix, exist_ok=True)
-    metrics = eval_reconstruction(stitched_obj, YY_ground_truth, label = label)
-    metrics['label'] = label
-    d = {**params.cfg, **metrics}
-    with open(out_prefix + '/params.dill', 'wb') as f:
-        dill.dump(d, f)
-    df = pd.DataFrame({k: d[k] for k in ['mae', 'mse', 'psnr', 'frc50']})
-    df.to_csv(out_prefix + '/metrics.csv')
-    return {k: metrics[k] for k in ['mae', 'mse', 'psnr', 'frc50', 'frc']}
diff --git a/build/lib/build/lib/ptycho/experimental.py b/build/lib/build/lib/ptycho/experimental.py
deleted file mode 100644
index adbb619..0000000
--- a/build/lib/build/lib/ptycho/experimental.py
+++ /dev/null
@@ -1,116 +0,0 @@
-from skimage.transform import resize
-from tqdm.notebook import tqdm as tqdm
-import matplotlib.pyplot as plt
-import numpy as np
-import scipy.signal
-import sys
-
-from . import tf_helper as hh
-
-path = '.'
-
-sys.path.append(path)
-sys.path.append('PtychoNN/TF2/')
-
-N = 64
-### Read experimental diffraction data and reconstructed images
-
-data_diffr = np.load(path+'/PtychoNN/data/20191008_39_diff.npz')['arr_0']
-data_diffr.shape
-
-data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)
-for i in tqdm(range(data_diffr.shape[0])):
-    for j in range(data_diffr.shape[1]):
-        data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)
-        data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])
-
-real_space = np.load(path+'/PtychoNN/data/20191008_39_amp_pha_10nm_full.npy')
-amp = np.abs(real_space)
-ph = np.angle(real_space)
-amp.shape
-
-### Split data and then shuffle
-
-nlines = 100 #How many lines of data to use for training?
-nltest = 60 #How many lines for the test set?
-tst_strt = amp.shape[0]-nltest #Where to index from
-print(tst_strt)
-train_size = 272
-test_size = 248
-
-def stack(a1, a2):
-    return np.array((a1, a2)).reshape((-1, N, N, 1))
-
-def augment_inversion(Y_I_train, Y_phi_train):
-    phi = stack(Y_phi_train, -Y_phi_train)
-    return stack(Y_I_train, Y_I_train[:, ::-1, ::-1, :]), stack(Y_phi_train, -Y_phi_train)
-
-def reconstruct_object(data4d, scan_grid_offset):
-    """
-    Given a 4d object patches, reconstruct the whole object
-    """
-    return hh.extract_patches_inverse(
-       data4d.reshape((data4d.shape[0], data4d.shape[1], -1))[None, ...],
-       N, True, gridsize = data4d.shape[0],
-       offset = scan_grid_offset)
-
-from ptycho.misc import memoize_disk_and_memory
-@memoize_disk_and_memory
-def get_full_experimental(which):
-    """
-    Returns (normalized) amplitude and phase for n generated objects
-    """
-    inverted_patches_I = reconstruct_object(amp, offset_experimental)
-    inverted_patches_phi = reconstruct_object(ph, offset_experimental)
-    print('GROUND TRUTH FULL SHAPE:', inverted_patches_I.shape)
-    if which == 'train':
-        YY_I = inverted_patches_I[:, :train_size, :train_size, :]
-        YY_phi = inverted_patches_phi[:, :train_size, :train_size, :]
-    elif which == 'test':
-        YY_I = inverted_patches_I[:, -test_size:, -test_size:, :]
-        YY_phi = inverted_patches_phi[:, -test_size:, -test_size:, :]
-    else:
-        raise ValueError
-    return YY_I, YY_phi
-
-
-X_train = data_diffr_red[:nlines,:].reshape(-1,N,N)[:,:,:,np.newaxis]
-X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,N,N)[:,:,:,np.newaxis]
-Y_I_train = amp[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_I_test = amp[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_train = ph[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_test = ph[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-
-ntrain = X_train.shape[0]*X_train.shape[1]
-ntest = X_test.shape[0]*X_test.shape[1]
-
-print(X_train.shape, X_test.shape)
-
-
-tmp1, tmp2 = Y_I_train, Y_I_test
-
-img = np.zeros((544, 544), dtype = 'float32')[None, ..., None]
-offset_experimental = 3
-
-## Recover shift between scan points
-def cross_image(im1, im2):
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
-
-cross = cross_image(amp[0, 0], amp[1, 0])
-ref = cross_image(amp[0, 0], amp[0, 0])
-
-cmax = lambda cross: np.array(np.where(cross.ravel()[np.argmax(cross)] == cross))
-
-plt.imshow(cross)
-
-cmax(cross), cmax(cross) - cmax(ref)
diff --git a/build/lib/build/lib/ptycho/export.py b/build/lib/build/lib/ptycho/export.py
deleted file mode 100644
index ba05094..0000000
--- a/build/lib/build/lib/ptycho/export.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import dill
-import matplotlib.pyplot as plt
-import numpy as np
-from ptycho.misc import get_path_prefix
-from ptycho.params import get
-
-def save_recons(model_type, stitched_obj):
-    from ptycho.generate_data import YY_ground_truth
-    from ptycho.evaluation import save_metrics
-    try:
-        out_prefix = get('output_prefix')
-        if YY_ground_truth is not None:
-            plt.imsave(out_prefix + 'amp_orig.png',
-                       np.absolute(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-            plt.imsave(out_prefix + 'phi_orig.png',
-                       np.angle(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-        if stitched_obj is not None:
-            plt.imsave(out_prefix + 'amp_recon.png', np.absolute(stitched_obj[0][:, :, 0]), cmap='jet')
-            plt.imsave(out_prefix + 'phi_recon.png', np.angle(stitched_obj[0][:, :, 0]), cmap='jet')
-
-        with open(out_prefix + '/recon.dill', 'wb') as f:
-            dump_data = {'stitched_obj_amp': np.absolute(stitched_obj[0][:, :, 0] if stitched_obj is not None else np.array([])),
-                         'stitched_obj_phase': np.angle(stitched_obj[0][:, :, 0]) if stitched_obj is not None else np.array([])}
-            if YY_ground_truth is not None:
-                dump_data.update({'YY_ground_truth_amp': np.absolute(YY_ground_truth[:, :, 0]),
-                                  'YY_ground_truth_phi': np.angle(YY_ground_truth[:, :, 0])})
-            dill.dump(dump_data, f)
-        if YY_ground_truth is not None and stitched_obj is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth or stitched_obj is None, metrics cannot be calculated.'}
-
-        if YY_ground_truth is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth is None, metrics cannot be calculated.'}
-        return d
-    except ImportError as e:
-        print('object stitching failed. No images will be saved.')
diff --git a/build/lib/build/lib/ptycho/fourier.py b/build/lib/build/lib/ptycho/fourier.py
deleted file mode 100644
index 1cf06f5..0000000
--- a/build/lib/build/lib/ptycho/fourier.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import pandas as pd
-import numpy as np
-
-from scipy.fft import fft, fftfreq, ifft, fft2, ifft2, ifftshift
-import matplotlib.pyplot as plt
-from scipy.fftpack import fft, fftshift
-from scipy.signal import butter
-from scipy import signal
-from scipy.signal import convolve2d as conv2
-
-from skimage import color, data, restoration
-from scipy.ndimage import gaussian_filter as gf
-
-def plot_df(*args):
-    df = pd.DataFrame([p for p, _ in args]).T
-    df.columns = [l for _, l in args ]
-    return df.plot()
-
-def lowpass_g(size, y, sym = False):
-    from scipy.signal.windows import gaussian
-    L = gaussian(len(y), std = len(y) / (size * np.pi**2), sym = sym)
-    L /= L.max()
-    return L
-
-def highpass_g(size, y):
-    return 1 - lowpass_g(size, y)
-
-def bandpass_g(L, H, y):
-    L = lowpass_g(L, y)
-    H = highpass_g(H, y)
-    return L * H
-
-def clip_high(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    x2[(N - nz) // 2 : (N + nz) // 2] = 0
-    #x2[(-nz) // 2:] = 0
-    return x2
-
-def clip_low(x, frac_zero, invert = False):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    mask = np.ones_like(x)
-    mask[:( nz) // 2 ] = 0
-    mask[(-nz) // 2:] = 0
-    if invert:
-        mask = 1 - mask
-    x2 = x2 * mask
-
-#     x2[:( nz) // 2 ] = 0
-#     x2[(-nz) // 2:] = 0
-    return x2, mask
-
-def clip_low_window(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = np.ones_like(x)
-    x2[:( nz) // 2 ] = 0
-    x2[(-nz) // 2:] = 0
-    return x2
-
-def if_mag(arr, phase = 0, truncate = False, toreal = 'psd', **kwargs):
-    #print("arr shape", arr.shape)
-    #trunc = len(arr) - unpadded_length
-    phase = np.exp(1j * phase)
-    tmp = ifft(arr)
-    if toreal == 'psd':
-        real = np.real(np.sqrt(np.conjugate(tmp) * tmp))
-    elif toreal == 'real':
-        real = np.real(tmp)
-    else:
-        raise ValueError
-    if truncate:
-        raise NotImplementedError
-        #return real[trunc // 2: -trunc // 2]
-    return real
-
-def power(arr):
-    ampsq = arr * np.conjugate(arr)
-    return np.real(ampsq)
-
-def mag(x):
-    return np.sqrt(power(x))
-
-def lorenz(gamma, x, x0):
-    return ( 1. / (np.pi * gamma)) * (gamma**2) / ((x - x0)**2 + gamma**2)
-
diff --git a/build/lib/build/lib/ptycho/generate_data.py b/build/lib/build/lib/ptycho/generate_data.py
deleted file mode 100644
index 21c4079..0000000
--- a/build/lib/build/lib/ptycho/generate_data.py
+++ /dev/null
@@ -1,11 +0,0 @@
-import numpy as np
-from .data_preprocessing import generate_data
-from . import params as p
-
-# TODO passing the probe should be mandatory, to enforce side-effect free behavior.
-def main(probeGuess = None):
-    X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = generate_data(probeGuess)
-    print(np.linalg.norm(ptycho_dataset.train_data.X[0]) / np.linalg.norm(np.abs(ptycho_dataset.train_data.Y[0])))
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
-X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = main(probeGuess = p.get('probe'))
diff --git a/build/lib/build/lib/ptycho/image/__init__.py b/build/lib/build/lib/ptycho/image/__init__.py
deleted file mode 100644
index 48b86dc..0000000
--- a/build/lib/build/lib/ptycho/image/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .stitching import stitch_patches, reassemble_patches
diff --git a/build/lib/build/lib/ptycho/image/stitching.py b/build/lib/build/lib/ptycho/image/stitching.py
deleted file mode 100644
index 9b26c64..0000000
--- a/build/lib/build/lib/ptycho/image/stitching.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, config, *, 
-                  norm_Y_I: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # Get N from config at the start
-    N = config['N']
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        N = config['N']
-        gridsize = config['gridsize']
-        offset = config['offset']
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    outer_offset = config.get('outer_offset_test', config['offset'])
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / config['nimgs_test']) / (config['N']**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-def reassemble_patches(patches, config, *, norm_Y_I=1., part='amp', norm=False):
-    """
-    High-level convenience function for stitching patches using config parameters.
-    
-    Args:
-        patches: Patches to reassemble
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        part: Which part to extract (default: 'amp')
-        norm: Whether to normalize (default: False)
-    """
-    return stitch_patches(
-        patches,
-        config,
-        norm_Y_I=norm_Y_I,
-        norm=norm,
-        part=part
-    )
diff --git a/build/lib/build/lib/ptycho/inference.py b/build/lib/build/lib/ptycho/inference.py
deleted file mode 100644
index be7ef91..0000000
--- a/build/lib/build/lib/ptycho/inference.py
+++ /dev/null
@@ -1,63 +0,0 @@
-from ptycho.model_manager import ModelManager
-from tensorflow.keras.models import Model
-from ptycho import params
-from ptycho.loader import PtychoDataContainer
-import numpy as np
-
-# TODO this module is for inference-only workflows. it needs to be consolidated with train_pinn
-
-def load_pretrained_model(model_path: str) -> Model:
-    """
-    Load a pre-trained model from an H5 file.
-    """
-    model = ModelManager.load_model(model_path)
-    return model
-
-def prepare_data(data_container: PtychoDataContainer) -> tuple:
-    """
-    Prepare data for inference.
-    """
-    from ptycho import model
-    X = data_container.X * model.params()['intensity_scale']
-    coords_nominal = data_container.coords_nominal
-    return X, coords_nominal
-
-def perform_inference(model: Model, X: np.ndarray, coords_nominal: np.ndarray) -> dict:
-    """
-    Perform inference using the pre-trained model and prepared data.
-    """
-    from ptycho import model
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = model.predict([X, coords_nominal])
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi
-    }
-
-def inference_flow(model_path: str, data_container: PtychoDataContainer) -> dict:
-    """
-    The main flow for model inference, integrating the steps.
-    """
-    pre_trained_model = load_pretrained_model(model_path or params.get('h5_path'))
-    X, coords_nominal = prepare_data(data_container)
-    inference_results = perform_inference(pre_trained_model, X, coords_nominal)
-    return inference_results
-
-# Example usage
-# model_path = 'path/to/model.h5'
-# data_container = PtychoDataContainer(...)
-# results = inference_flow(model_path, data_container)
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def reassemble_with_config(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/ptycho/loader.py b/build/lib/build/lib/ptycho/loader.py
deleted file mode 100644
index b1421e4..0000000
--- a/build/lib/build/lib/ptycho/loader.py
+++ /dev/null
@@ -1,318 +0,0 @@
-"""Generic loader for datasets with non-rectangular scan point patterns."""
-
-import numpy as np
-import tensorflow as tf
-from typing import Callable
-
-from .params import params, get
-from .autotest.debug import debug
-from . import diffsim as datasets
-from . import tf_helper as hh
-from .raw_data import RawData, key_coords_offsets, key_coords_relative 
-
-class PtychoDataset:
-    @debug
-    def __init__(self, train_data, test_data):
-        self.train_data = train_data
-        self.test_data = test_data
-
-class PtychoDataContainer:
-    """
-    A class to contain ptycho data attributes for easy access and manipulation.
-    """
-    @debug
-    def __init__(self, X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, nn_indices, global_offsets, local_offsets, probeGuess):
-        self.X = X
-        self.Y_I = Y_I
-        self.Y_phi = Y_phi
-        self.norm_Y_I = norm_Y_I
-        self.YY_full = YY_full
-        self.coords_nominal = coords_nominal
-        self.coords = coords_nominal
-        self.coords_true = coords_true
-        self.nn_indices = nn_indices
-        self.global_offsets = global_offsets
-        self.local_offsets = local_offsets
-        self.probe = probeGuess
-
-        from .tf_helper import combine_complex
-        self.Y = combine_complex(Y_I, Y_phi)
-
-    @debug
-    def __repr__(self):
-        repr_str = '<PtychoDataContainer'
-        for attr_name in ['X', 'Y_I', 'Y_phi', 'norm_Y_I', 'YY_full', 'coords_nominal', 'coords_true', 'nn_indices', 'global_offsets', 'local_offsets', 'probe']:
-            attr = getattr(self, attr_name)
-            if attr is not None:
-                if isinstance(attr, np.ndarray):
-                    if np.iscomplexobj(attr):
-                        repr_str += f' {attr_name}={attr.shape} mean_amplitude={np.mean(np.abs(attr)):.3f}'
-                    else:
-                        repr_str += f' {attr_name}={attr.shape} mean={attr.mean():.3f}'
-                else:
-                    repr_str += f' {attr_name}={attr.shape}'
-        repr_str += '>'
-        return repr_str
-
-    @staticmethod
-    @debug
-    def from_raw_data_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess=None, N=None, K=7, nsamples=1):
-        """
-        Static method constructor that composes a call to RawData.from_coords_without_pc() and loader.load,
-        then initializes attributes.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-            N (int, optional): The size of the image. Defaults to None.
-            K (int, optional): The number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): The number of samples. Defaults to 1.
-
-        Returns:
-            PtychoDataContainer: An instance of the PtychoDataContainer class.
-        """
-        from . import params as cfg
-        if N is None:
-            N = cfg.get('N')
-        train_raw = RawData.from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-        
-        dset_train = train_raw.generate_grouped_data(N, K=K, nsamples=nsamples)
-
-        # Use loader.load() to handle the conversion to PtychoData
-        return load(lambda: dset_train, probeGuess, which=None, create_split=False)
-
-    #@debug
-    def to_npz(self, file_path: str) -> None:
-        """
-        Write the underlying arrays to an npz file.
-
-        Args:
-            file_path (str): Path to the output npz file.
-        """
-        np.savez(
-            file_path,
-            X=self.X.numpy() if tf.is_tensor(self.X) else self.X,
-            Y_I=self.Y_I.numpy() if tf.is_tensor(self.Y_I) else self.Y_I,
-            Y_phi=self.Y_phi.numpy() if tf.is_tensor(self.Y_phi) else self.Y_phi,
-            norm_Y_I=self.norm_Y_I,
-            YY_full=self.YY_full,
-            coords_nominal=self.coords_nominal.numpy() if tf.is_tensor(self.coords_nominal) else self.coords_nominal,
-            coords_true=self.coords_true.numpy() if tf.is_tensor(self.coords_true) else self.coords_true,
-            nn_indices=self.nn_indices,
-            global_offsets=self.global_offsets,
-            local_offsets=self.local_offsets,
-            probe=self.probe.numpy() if tf.is_tensor(self.probe) else self.probe
-        )
-
-    # TODO is this deprecated, given the above method to_npz()?
-
-@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset['coords_offsets']
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset['coords_relative']
-    coords_true = dset['coords_relative']
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    Y = tf.ones_like(X)
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-@debug
-def split_data(X_full, coords_nominal, coords_true, train_frac, which):
-    """
-    Splits the data into training and testing sets based on the specified fraction.
-
-    Args:
-        X_full (np.ndarray): The full dataset to be split.
-        coords_nominal (np.ndarray): The nominal coordinates associated with the dataset.
-        coords_true (np.ndarray): The true coordinates associated with the dataset.
-        train_frac (float): The fraction of the dataset to be used for training.
-        which (str): A string indicating whether to return the 'train' or 'test' split.
-
-    Returns:
-        tuple: A tuple containing the split data and coordinates.
-    """
-    n_train = int(len(X_full) * train_frac)
-    if which == 'train':
-        return X_full[:n_train], coords_nominal[:n_train], coords_true[:n_train]
-    elif which == 'test':
-        return X_full[n_train:], coords_nominal[n_train:], coords_true[n_train:]
-    else:
-        raise ValueError("Invalid split type specified: must be 'train' or 'test'.")
-
-@debug
-def split_tensor(tensor, frac, which='test'):
-    """
-    Splits a tensor into training and test portions based on the specified fraction.
-
-    :param tensor: The tensor to split.
-    :param frac: Fraction of the data to be used for training.
-    :param which: Specifies whether to return the training ('train') or test ('test') portion.
-    :return: The appropriate portion of the tensor based on the specified fraction and 'which' parameter.
-    """
-    n_train = int(len(tensor) * frac)
-    return tensor[:n_train] if which == 'train' else tensor[n_train:]
-
-# TODO this should be a method of PtychoDataContainer
-#@debug
-def load(cb: Callable, probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset[key_coords_offsets]
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset[key_coords_relative]
-    coords_true = dset[key_coords_relative]
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-#    try:
-#        Y = get_image_patches(gt_image, global_offsets, coords_true) * cfg.get('probe_mask')[..., 0]
-#    except:
-#        Y = tf.zeros_like(X)
-
-    norm_Y_I = datasets.scale_nphotons(X)
-
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-    # TODO we shouldn't be nuking the ground truth
-##    try:
-#    if dset['Y'] is None:
-#        Y = get_image_patches(gt_image,
-#            global_offsets, coords_true) * probe.get_probe_mask_real(cfg.get('N'))
-#        print("loader: generating ground truth patches from image and offsets")
-#    else:
-#        Y = dset['Y']
-#        print("loader: using provided ground truth patches")
-    if dset['Y'] is None:
-        Y = tf.ones_like(X)
-        print("loader: setting dummy Y ground truth")
-    else:
-        Y = dset['Y']
-        print("loader: using provided ground truth patches")
-    Y_I = tf.math.abs(Y)
-    Y_phi = tf.math.angle(Y)
-
-    # TODO get rid of?
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    # TODO this should be baked into the model pipeline. If we can
-    # assume consistent normalization, we can get rid of intensity_scale
-    # as a model parameter since the post normalization average L2 norm
-    # will be fixed. Normalizing in the model's dataloader will make
-    # things more self-contained and avoid the need for separately
-    # scaling simulated datasets. While we're at it we should get rid of
-    # all the unecessary multiiplying and dividing by intensity_scale.
-    # As long as nphotons is a dataset-level attribute (i.e. an attribute of RawData 
-    # and PtychoDataContainer), nothing is lost
-    # by keeping the diffraction in normalized format everywhere except
-    # before the Poisson NLL calculation in model.py.
-
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    #print('X NORM', X_full_norm)
-    return X_full_norm * X_full
-
-#@debug
-def crop(arr2d, size):
-    N, M = arr2d.shape
-    return arr2d[N // 2 - (size) // 2: N // 2+ (size) // 2, N // 2 - (size) // 2: N // 2 + (size) // 2]
-
-@debug
-def get_gt_patch(offset, N, gt_image):
-    from . import tf_helper as hh
-    return crop(
-        hh.translate(gt_image, offset),
-        N // 2)
-
-def load_xpp_npz(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                                 diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                       xcoords_start[:train_size], ycoords_start[:train_size],
-                                       diff3d[:train_size], probeGuess,
-                                       scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
diff --git a/build/lib/build/lib/ptycho/logging.py b/build/lib/build/lib/ptycho/logging.py
deleted file mode 100644
index d9ca4fe..0000000
--- a/build/lib/build/lib/ptycho/logging.py
+++ /dev/null
@@ -1,315 +0,0 @@
-"""
-Module for logging and inspecting function inputs, outputs, and execution times.
-
-Provides the `debug` decorator to log function invocations, including serialized inputs,
-outputs, and execution times. Supports logging to console and disk files.
-
-Includes `load_logged_data` function to load logged data from disk for a specific invocation.
-
-Handles serialization of NumPy arrays, TensorFlow tensors, and custom objects.
-
-Logging controlled by `params.get('debug')` configuration.
-
-Key components:
-- `debug` decorator
-- `load_logged_data` function
-- Helper functions: `make_invocation_counter`, `serialize_input`
-- Custom exceptions: `SerializationError`, `LoggedDataNotFoundError`
-"""
-import functools
-import inspect
-import json
-import numpy as np
-import os
-import tensorflow as tf
-from datetime import datetime
-from typing import Any, Callable, Dict, List, Tuple
-
-import ptycho.params as params
-
-class SerializationError(Exception):
-    pass
-
-class LoggedDataNotFoundError(Exception):
-    pass
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-# TODO surround each function's output section in xml tags with the function / 
-# method path
-def debug(log_to_file: bool = True):
-    def decorator(func: Callable):
-        increment_count = make_invocation_counter()
-
-        @functools.wraps(func)
-        def wrapper(*args: Any, **kwargs: Any) -> Any:
-            if params.get('debug'):
-                invocation_count = increment_count()
-
-                if invocation_count <= 2:
-                    timestamp = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
-                    module_path = inspect.getmodule(func).__name__
-                    function_name = func.__name__
-
-                    def serialize_input(arg: Any) -> str:
-                        if isinstance(arg, np.ndarray):
-                            return f"NumPy array with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, tf.Tensor):
-                            return f"TensorFlow tensor with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, (int, float, str, bool)):
-                            return f"{type(arg).__name__} with value {arg}"
-                        else:
-                            return str(type(arg))
-
-                    serializable_inputs = {
-                        'args': [serialize_input(arg) for arg in args],
-                        'kwargs': {key: serialize_input(value) for key, value in kwargs.items()}
-                    }
-
-                    log_message = f"Calling function {function_name} in module {module_path} with inputs: {json.dumps(serializable_inputs, default=str)}"
-                    print(log_message)
-
-                    if log_to_file:
-                        log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-                        os.makedirs(log_directory, exist_ok=True)
-                        log_file_path = os.path.join(log_directory, f"{function_name}_{timestamp}.log")
-                        try:
-                            with open(log_file_path, 'w') as log_file:
-                                log_file.write(log_message + '\n')
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                    start_time = datetime.now()
-                    try:
-                        result = func(*args, **kwargs)
-                    except Exception as e:
-                        error_message = f"Error executing function {function_name} in module {module_path}: {str(e)}"
-                        print(error_message)
-                        raise e
-                    end_time = datetime.now()
-                    execution_time = end_time - start_time
-
-                    serializable_result = serialize_input(result)
-
-                    log_message = f"Function {function_name} in module {module_path} returned: {serializable_result}"
-                    print(log_message)
-                    print(f"Execution time: {execution_time}")
-
-                    if log_to_file:
-                        try:
-                            with open(log_file_path, 'a') as log_file:
-                                log_file.write(log_message + '\n')
-                                log_file.write(f"Execution time: {execution_time}\n")
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                else:
-                    result = func(*args, **kwargs)
-
-            else:
-                result = func(*args, **kwargs)
-
-            return result
-
-        return wrapper
-
-    return decorator
-
-def load_logged_data(module_path: str, function_name: str, invocation_index: int = 0) -> Tuple[Dict[str, Any], Any]:
-    log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-    log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-    log_files.sort()
-
-    if invocation_index >= len(log_files):
-        raise LoggedDataNotFoundError(f"Invocation index {invocation_index} not found for function {function_name} in module {module_path}")
-
-    log_file_path = os.path.join(log_directory, log_files[invocation_index])
-
-    try:
-        with open(log_file_path, 'r') as log_file:
-            lines = log_file.readlines()
-            inputs_line = lines[0].strip()
-            outputs_line = lines[1].strip()
-
-            inputs_start = inputs_line.find(': ') + 2
-            outputs_start = outputs_line.find(': ') + 2
-
-            inputs_json = inputs_line[inputs_start:]
-            outputs_str = outputs_line[outputs_start:]
-
-            inputs = json.loads(inputs_json)
-            outputs = outputs_str
-
-            return inputs, outputs
-    except (IOError, json.JSONDecodeError) as e:
-        raise LoggedDataNotFoundError(f"Error loading logged data for function {function_name} in module {module_path}: {str(e)}")
-
-import os
-import json
-from typing import List, Tuple, Union
-from ptycho.logging import LoggedDataNotFoundError, load_logged_data
-
-def get_type_and_dim(serialized_data: str) -> str:
-    if serialized_data.startswith("NumPy array"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"NumPy array, shape: {shape}, dtype: {dtype}"
-    elif serialized_data.startswith("TensorFlow tensor"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"TensorFlow tensor, shape: {shape}, dtype: {dtype}"
-    else:
-        return serialized_data.split(" ")[0]
-
-def process_log_file(module_path: str, function_name: str) -> None:
-    if function_name.startswith("__init__"):
-        return
-
-    invocation_index = 0
-    try:
-        inputs, outputs = load_logged_data(module_path, function_name, invocation_index)
-    except LoggedDataNotFoundError:
-        return
-
-    input_types_dims = []
-    for input_data in inputs["args"]:
-        input_types_dims.append(get_type_and_dim(input_data))
-    for input_name, input_data in inputs["kwargs"].items():
-        input_types_dims.append(f"{input_name}: {get_type_and_dim(input_data)}")
-
-    output_type_dim = get_type_and_dim(outputs)
-
-    print(f"Module: {module_path}, Function: {function_name}")
-    print("Input types and dimensionalities:")
-    for input_type_dim in input_types_dims:
-        print(f"  - {input_type_dim}")
-    print(f"Output type and dimensionality: {output_type_dim}")
-    print()
-
-def extract_logged_data(log_directory: str) -> None:
-    for module_name in os.listdir(log_directory):
-        module_directory = os.path.join(log_directory, module_name)
-        for log_file in os.listdir(module_directory):
-            function_name = log_file.split("_")[0]
-            process_log_file(module_name, function_name)
-
-# TODO this function belongs among the tests
-def main() -> None:
-    log_directory = "logs/"
-    extract_logged_data(log_directory)
-
-####
-# tests
-####
-# Test case 1: Function with serializable inputs and output
-@debug()
-def add_numbers(a: int, b: int) -> int:
-    return a + b
-
-# Test case 2: Function with NumPy array input and output
-@debug()
-def multiply_array(arr: np.ndarray) -> np.ndarray:
-    return arr * 2
-
-# Test case 3: Function with TensorFlow tensor input and output
-@debug()
-def add_tensors(t1: tf.Tensor, t2: tf.Tensor) -> tf.Tensor:
-    return t1 + t2
-
-# Test case 4: Function with mixed input types and custom object output
-class CustomResult:
-    def __init__(self, value: str):
-        self.value = value
-
-@debug()
-def process_data(data: Any, flag: bool) -> CustomResult:
-    if flag:
-        return CustomResult("Processed: " + str(data))
-    else:
-        return CustomResult("Skipped: " + str(data))
-
-# Test case 5: Function with exception
-@debug()
-def divide_numbers(a: int, b: int) -> float:
-    return a / b
-
-# Test case 6: Loading logged data from disk
-@debug(log_to_file=True)
-def multiply_numbers(a: int, b: int) -> int:
-    return a * b
-
-## Set the debug parameter to True
-#params.cfg['debug'] = True
-#
-## Running the tests
-#add_numbers(3, 5)
-#add_numbers(4, 6)
-#add_numbers(5, 7)  # This invocation will not be logged
-#multiply_array(np.array([1, 2, 3]))
-#multiply_array(np.array([4, 5, 6]))
-#multiply_array(np.array([7, 8, 9]))  # This invocation will not be logged
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#add_tensors(tf.constant([[1.0, 2.0], [3.0, 4.0]]), tf.constant([[5.0, 6.0], [7.0, 8.0]]))
-#add_tensors(tf.constant([1.0, 2.0, 3.0]), tf.constant([4.0, 5.0, 6.0]))  # This invocation will not be logged
-#process_data({"key": "value"}, True)
-#process_data({"key": "value"}, False)
-#process_data([1, 2, 3], True)  # This invocation will not be logged
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(20, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(30, 0)  # This invocation will not be logged
-#except ZeroDivisionError:
-#    pass
-#
-#multiply_numbers(2, 3)
-#multiply_numbers(4, 5)
-#multiply_numbers(6, 7)  # This invocation will not be logged
-#
-## Loading logged data from disk
-#module_path = "__main__"
-#function_name = "multiply_numbers"
-#invocation_index = 0
-#
-#inputs, output = load_logged_data(module_path, function_name, invocation_index)
-#
-#print(f"Loaded inputs: {inputs}")
-#print(f"Loaded output: {output}")
-#
-## Cleanup: Remove the logged data files
-#log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-#log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-#for log_file in log_files:
-#    log_file_path = os.path.join(log_directory, log_file)
-#    os.remove(log_file_path)
-#
-## Set the debug parameter to False
-#params.cfg['debug'] = False
-#
-## Running the tests again (no logging should occur)
-#add_numbers(3, 5)
-#multiply_array(np.array([1, 2, 3]))
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#process_data({"key": "value"}, True)
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#multiply_numbers(2, 3)
-#
-#
diff --git a/build/lib/build/lib/ptycho/losses.py b/build/lib/build/lib/ptycho/losses.py
deleted file mode 100644
index 1efd8b0..0000000
--- a/build/lib/build/lib/ptycho/losses.py
+++ /dev/null
@@ -1,17 +0,0 @@
-#def I_channel_MAE(y_true,y_pred, center_target = True):
-#    if center_target:
-#        y_true = center_channels(y_true
-#    return tf.reduce_mean(tf.keras.losses.MeanAbsoluteError(y_true,y_pred))
-
-#def symmetrized_loss(target, pred, loss_fn):
-#    """
-#    Calculate loss function on an image, taking into account that the
-#    prediction may be coordinate-inverted relative to the target
-#    """
-#    abs1 = (target)
-#    abs2 = (pred)
-#    abs3 = abs2[:, ::-1, ::-1, :]
-#    target_sym = (symmetrize_3d(target))
-#    a, b, c = loss_fn(abs1, abs2), loss_fn(abs1, abs3), loss_fn(target_sym, pred)
-#    return tf.minimum(a,
-#                      tf.minimum(b, c))
diff --git a/build/lib/build/lib/ptycho/misc.py b/build/lib/build/lib/ptycho/misc.py
deleted file mode 100644
index 003189f..0000000
--- a/build/lib/build/lib/ptycho/misc.py
+++ /dev/null
@@ -1,330 +0,0 @@
-import numpy as np
-import matplotlib.cm as cm
-import scipy.cluster.vq as scv
-from ptycho import params
-from datetime import datetime
-
-# TODO multiple creations of this directory
-def get_path_prefix():
-    label = params.cfg['label']
-    prefix = params.params()['output_prefix']
-    now = datetime.now() # current date and time
-    try:
-        date_time = params.get('timestamp')
-    except KeyError:
-        date_time = now.strftime("%m/%d/%Y, %H:%M:%S")
-        params.set('timestamp', date_time)
-    date_time = date_time.replace('/', '-').replace(':', '.').replace(', ', '-')
-
-    #print('offset', offset)
-    out_prefix = '{}/{}_{}/'.format(prefix, date_time, label)
-    return out_prefix
-
-# Convert RGB colormap images to grayscale
-def colormap2arr(arr,cmap):
-    # http://stackoverflow.com/questions/3720840/how-to-reverse-color-map-image-to-scalar-values/3722674#3722674
-    gradient=cmap(np.linspace(0.0,1.0,1000))
-
-    # Reshape arr to something like (240*240, 4), all the 4-tuples in a long list...
-    arr2=arr.reshape((arr.shape[0]*arr.shape[1],arr.shape[2]))
-
-    # Use vector quantization to shift the values in arr2 to the nearest point in
-    # the code book (gradient).
-    code,dist=scv.vq(arr2,gradient)
-
-    # code is an array of length arr2 (240*240), holding the code book index for
-    # each observation. (arr2 are the "observations".)
-    # Scale the values so they are from 0 to 1.
-    values=code.astype('float')/gradient.shape[0]
-
-    # Reshape values back to (240,240)
-    values=values.reshape(arr.shape[0],arr.shape[1])
-    values=values[::-1]
-    return values
-
-import functools
-import hashlib
-import json
-import os
-import tensorflow as tf
-
-#https://chat.openai.com/c/8273412b-f3fb-405c-a7a4-c0466bb43b04
-import os
-import functools
-import hashlib
-import json
-import numpy as np
-import tensorflow as tf
-
-def memoize_disk_and_memory(func):
-    from ptycho.params import cfg
-    from ptycho import probe
-    memory_cache = {}
-    disk_cache_dir = 'memoized_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def process_dict(d):
-        processed = {}
-        for k, v in d.items():
-            if isinstance(v, tf.Tensor):
-                processed[k] = ('tensor', v.numpy())
-            elif isinstance(v, np.ndarray):
-                processed[k] = ('array', v)
-            elif isinstance(v, dict):
-                processed[k] = ('dict', process_dict(v))
-            else:
-                processed[k] = ('primitive', v)
-        return processed
-
-    def reconstruct_dict(d):
-        reconstructed = {}
-        for k, (type_, value) in d.items():
-            if type_ == 'tensor' or type_ == 'array':
-                reconstructed[k] = value
-            elif type_ == 'dict':
-                reconstructed[k] = reconstruct_dict(value)
-            else:  # primitive
-                reconstructed[k] = value
-        return reconstructed
-
-    @functools.wraps(func)
-    def wrapper(*args, **kwargs):
-        cfg_keys = ['offset', 'N', 'outer_offset_train', 'outer_offset_test',
-                    'nphotons', 'nimgs_train', 'nimgs_test', 'set_phi',
-                    'data_source', 'gridsize', 'big_gridsize', 'default_probe_scale']
-        hash_input = {k: cfg[k] for k in cfg_keys if k in cfg}
-        hash_input.update({f'arg_{i}': json.dumps(arg, default=str) for i, arg in enumerate(args)})
-        hash_input.update({f'kwarg_{k}': json.dumps(v, default=str) for k, v in kwargs.items()})
-        hash_input_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha1(hash_input_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-        else:
-            disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-            if os.path.exists(disk_cache_file):
-                print("Loading result from disk cache.")
-                loaded_data = np.load(disk_cache_file, allow_pickle=True)
-                if 'dict_data' in loaded_data:
-                    result = reconstruct_dict(loaded_data['dict_data'].item())
-                elif 'result' in loaded_data:
-                    result = loaded_data['result']
-                else:
-                    result = tuple(loaded_data[key] for key in loaded_data.keys())
-                    if len(result) == 1:
-                        result = result[0]
-            else:
-                print("No cached result found. Calculating and caching the result.")
-                result = func(*args, **kwargs)
-                if isinstance(result, (np.ndarray, tf.Tensor)):
-                    np.savez(disk_cache_file, result=result.numpy() if isinstance(result, tf.Tensor) else result)
-                elif isinstance(result, tuple):
-                    np.savez(disk_cache_file, **{f'arr_{i}': arr.numpy() if isinstance(arr, tf.Tensor) else arr for i, arr in enumerate(result)})
-                elif isinstance(result, dict):
-                    processed_dict = process_dict(result)
-                    np.savez(disk_cache_file, dict_data=processed_dict)
-                else:
-                    raise ValueError("Invalid function output. Expected numpy array, TensorFlow tensor, tuple, or dictionary with values as arrays/tensors/primitives.")
-                memory_cache[hash_hex] = result
-        return result
-    return wrapper
-
-
-##########
-# unit test
-##########
-#
-#import numpy as np
-#import tensorflow as tf
-#
-## Define test functions
-#@memoize_disk_and_memory
-#def test_function1(x):
-#    return np.random.rand(x, x)
-#
-#@memoize_disk_and_memory
-#def test_function2(x):
-#    return tf.random.uniform((x, x))
-#
-#@memoize_disk_and_memory
-#def test_function3(x):
-#    return np.random.rand(x, x), tf.random.uniform((x, x))
-#
-## First run - cache miss
-#result1_first = test_function1(5)
-#result2_first = test_function2(5)
-#result3_first = test_function3(5)
-#
-## Second run - cache hit
-#result1_second = test_function1(5)
-#result2_second = test_function2(5)
-#result3_second = test_function3(5)
-#
-## Test if the memoized results match the first run results
-#np.testing.assert_array_equal(result1_first, result1_second)
-#np.testing.assert_array_equal(result2_first, result2_second)
-#
-#np.testing.assert_array_equal(result3_first[0], result3_second[0])
-#np.testing.assert_array_equal(result3_first[1], result3_second[1])
-#
-## Test if memoization works with different function arguments
-#result1_diff_arg = test_function1(6)
-#np.testing.assert_raises(AssertionError, np.testing.assert_array_equal, result1_first, result1_diff_arg)
-#
-
-import functools
-import numpy as np
-import tensorflow as tf
-
-def make_invocation_counter():
-    count = 0
-
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-
-    return increment
-
-######
-## logging decorator
-######
-# TODO deprecated, moved to logging.py
-#def g(h):
-#    increment_count = make_invocation_counter()
-#
-#    def wrapper(f):
-#        @functools.wraps(f)
-#        def inner(*args, **kwargs):
-#            invocation_count = increment_count()
-#            if invocation_count <= 2:
-#                return h(f)(*args, **kwargs)
-#            else:
-#                return f(*args, **kwargs)
-#
-#        return inner
-#
-#    return wrapper
-#
-#@g
-#def debug(func):
-#    def wrapper(*args, **kwargs):
-#        def get_type_and_shape(x):
-#            if isinstance(x, np.ndarray):
-#                return f"{type(x)} with shape {x.shape}"
-#            elif isinstance(x, tf.Tensor):
-#                return f"{type(x)} with shape {x.shape}"
-#            else:
-#                return str(type(x))
-#
-#        args_types = [get_type_and_shape(arg) for arg in args]
-#        kwargs_types = {k: get_type_and_shape(v) for k, v in kwargs.items()}
-#
-#        print(f"Calling {func.__name__} with args types: {args_types}, kwargs types: {kwargs_types}")
-#        result = func(*args, **kwargs)
-#        
-#        result_type = get_type_and_shape(result)
-#        print(f"{func.__name__} returned {result_type}")
-#        
-#        return result
-#    return wrapper
-
-import scipy.signal
-import functools
-import hashlib
-import json
-import os
-import numpy as np
-
-def memoize_simulated_data(func):
-    memory_cache = {}
-    disk_cache_dir = 'memoized_simulated_data'
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    def array_to_bytes(arr):
-        return arr.tobytes(), arr.dtype.str, arr.shape
-
-    def bytes_to_array(data, dtype, shape):
-        return np.frombuffer(data, dtype=np.dtype(dtype)).reshape(shape)
-
-    @functools.wraps(func)
-    def wrapper(objectGuess, probeGuess, nimages, buffer, random_seed=None, return_patches=True):
-        from ptycho.loader import RawData
-        # Create a unique hash for the input parameters
-        hash_input = {
-            'objectGuess': array_to_bytes(objectGuess),
-            'probeGuess': array_to_bytes(probeGuess),
-            'nimages': nimages,
-            'buffer': buffer,
-            'random_seed': random_seed,
-            'return_patches': return_patches
-        }
-        hash_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha256(hash_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-
-        disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-        if os.path.exists(disk_cache_file):
-            print("Loading result from disk cache.")
-            with np.load(disk_cache_file, allow_pickle=True) as data:
-                raw_data_dict = data['raw_data'].item()
-                raw_data = RawData(
-                    xcoords=raw_data_dict['xcoords'],
-                    ycoords=raw_data_dict['ycoords'],
-                    xcoords_start=raw_data_dict['xcoords_start'],
-                    ycoords_start=raw_data_dict['ycoords_start'],
-                    diff3d=raw_data_dict['diff3d'],
-                    probeGuess=raw_data_dict['probeGuess']
-                )
-                if return_patches:
-                    patches = data['patches']
-                    result = (raw_data, patches)
-                else:
-                    result = raw_data
-        else:
-            print("No cached result found. Calculating and caching the result.")
-            result = func(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches)
-            
-            if isinstance(result, tuple):
-                raw_data, patches = result
-            else:
-                raw_data = result
-                patches = None
-
-            raw_data_dict = {
-                'xcoords': raw_data.xcoords,
-                'ycoords': raw_data.ycoords,
-                'xcoords_start': raw_data.xcoords_start,
-                'ycoords_start': raw_data.ycoords_start,
-                'diff3d': raw_data.diff3d,
-                'probeGuess': raw_data.probeGuess
-            }
-
-            np.savez(disk_cache_file, raw_data=raw_data_dict, patches=patches)
-
-        memory_cache[hash_hex] = result
-        return result
-
-    return wrapper
-
-def cross_image(im1, im2):
-    """
-    Find offsets through 2d autocorrelation
-    """
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
diff --git a/build/lib/build/lib/ptycho/model.py b/build/lib/build/lib/ptycho/model.py
deleted file mode 100644
index a182376..0000000
--- a/build/lib/build/lib/ptycho/model.py
+++ /dev/null
@@ -1,477 +0,0 @@
-# TODO s
-# - complex convolution
-# - Use tensor views:
-#     https://chat.openai.com/c/e6d5e400-daf9-44b7-8ef9-d49f21a634a3
-# -difference maps?
-# -double -> float32
-# Apply real space loss to both amplitude and phase of the object
-
-from datetime import datetime
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras.activations import relu, sigmoid, tanh, swish, softplus
-from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, InputLayer, Lambda, Dense
-from tensorflow.keras.layers import Layer
-from tensorflow.keras import layers
-import glob
-import math
-import numpy as np
-import os
-import tensorflow.compat.v2 as tf
-import tensorflow_probability as tfp
-
-from .loader import PtychoDataContainer
-from . import tf_helper as hh
-from . import params as cfg
-params = cfg.params
-
-import tensorflow_addons as tfa
-gaussian_filter2d = tfa.image.gaussian_filter2d
-
-def complex_gaussian_filter2d(input_tensor, filter_shape, sigma):
-    """
-    Apply Gaussian filter to complex-valued tensor.
-    
-    Args:
-    input_tensor: Complex-valued input tensor
-    filter_shape: Tuple of integers specifying the filter shape
-    sigma: Float or tuple of floats for the Gaussian kernel standard deviation
-    
-    Returns:
-    Complex-valued tensor after applying Gaussian filter
-    """
-    real_part = tf.math.real(input_tensor)
-    imag_part = tf.math.imag(input_tensor)
-    
-    filtered_real = gaussian_filter2d(real_part, filter_shape=filter_shape, sigma=sigma)
-    filtered_imag = gaussian_filter2d(imag_part, filter_shape=filter_shape, sigma=sigma)
-    
-    return tf.complex(filtered_real, filtered_imag)
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-# sets the number of convolutional filters
-
-n_filters_scale =  cfg.get('n_filters_scale')
-N = cfg.get('N')
-gridsize = cfg.get('gridsize')
-offset = cfg.get('offset')
-
-from . import probe
-tprobe = params()['probe']
-
-probe_mask = probe.get_probe_mask(N)
-#probe_mask = cfg.get('probe_mask')[:, :, :, 0]
-
-if len(tprobe.shape) == 3:
-    initial_probe_guess = tprobe[None, ...]
-    #probe_mask = probe_mask[None, ...]
-elif len(tprobe.shape) == 4:
-    initial_probe_guess = tprobe
-else:
-    raise ValueError
-
-initial_probe_guess = tf.Variable(
-            initial_value=tf.cast(initial_probe_guess, tf.complex64),
-            trainable=params()['probe.trainable'],
-        )
-
-# TODO hyperparameters:
-# TODO total variation loss
-# -probe smoothing scale(?)
-class ProbeIllumination(tf.keras.layers.Layer):
-    def __init__(self, name = None):
-        super(ProbeIllumination, self).__init__(name = name)
-        self.w = initial_probe_guess
-        self.sigma = cfg.get('gaussian_smoothing_sigma')
-
-    def call(self, inputs):
-        # x is expected to have shape (batch_size, N, N, gridsize**2)
-        # where N is the size of each patch and gridsize**2 is the number of patches
-        x = inputs[0]
-        
-        # self.w has shape (1, N, N, 1) or (1, N, N, gridsize**2) if probe.big is True
-        # probe_mask has shape (N, N, 1)
-        
-        # Apply multiplication first
-        illuminated = self.w * x
-        
-        # Apply Gaussian smoothing only if sigma is not 0
-        if self.sigma != 0:
-            smoothed = complex_gaussian_filter2d(illuminated, filter_shape=(3, 3), sigma=self.sigma)
-        else:
-            smoothed = illuminated
-        
-        if cfg.get('probe.mask'):
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed * tf.cast(probe_mask, tf.complex64), (self.w * tf.cast(probe_mask, tf.complex64))[None, ...]
-        else:
-            # Output shape: (batch_size, N, N, gridsize**2)
-            return smoothed, (self.w)[None, ...]
-
-probe_illumination = ProbeIllumination()
-
-nphotons = cfg.get('nphotons')
-
-# TODO scaling could be done on a shot-by-shot basis, but IIRC I tried this
-# and there were issues
-log_scale_guess = np.log(cfg.get('intensity_scale'))
-log_scale = tf.Variable(
-            initial_value=tf.constant(float(log_scale_guess)),
-            trainable = params()['intensity_scale.trainable'],
-        )
-
-class IntensityScaler(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return x / tf.math.exp(self.w)
-
-# TODO use a bijector instead of separately defining the transform and its
-# inverse
-class IntensityScaler_inv(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler_inv, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return tf.math.exp(self.w) * x
-
-def scale(inputs):
-    x, = inputs
-    res = x / tf.math.exp(log_scale)
-    return res
-
-def inv_scale(inputs):
-    x, = inputs
-    return tf.math.exp(log_scale) * x
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-lambda_norm = Lambda(lambda x: tf.math.reduce_sum(x**2, axis = [1, 2]))
-input_img = Input(shape=(N, N, gridsize**2), name = 'input')
-input_positions = Input(shape=(1, 2, gridsize**2), name = 'input_positions')
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-def create_encoder(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 128:
-        filters = [n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 256:
-        filters = [n_filters_scale * 8, n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Pool_block(x, num_filters)
-    
-    return x
-
-def create_decoder_base(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    return x
-
-def get_resolution_scale_factor(N):
-    """
-    Calculate the resolution-dependent filter count programmatically.
-    
-    Args:
-    N (int): The input resolution (must be a power of 2)
-    
-    Returns:
-    int: The scale factor for the given resolution
-    
-    Raises:
-    ValueError: If the input size is not a power of 2 or is outside the supported range
-    """
-    if N < 64 or N > 1024:
-        raise ValueError(f"Input size {N} is outside the supported range (64 to 1024)")
-    
-    if not (N & (N - 1) == 0) or N == 0:
-        raise ValueError(f"Input size {N} is not a power of 2")
-    
-    # Calculate the scale factor
-    # For N=64, we want 32; for N=128, we want 16; for N=256, we want 8, etc.
-    # This can be achieved by dividing 2048 by N
-    return 2048 // N
-
-def create_decoder_last(input_tensor, n_filters_scale, conv1, conv2, act=tf.keras.activations.sigmoid, name=''):
-    N = cfg.get('N')
-    gridsize = cfg.get('gridsize')
-
-    scale_factor = get_resolution_scale_factor(N)
-    if cfg.get('pad_object'):
-        c_outer = 4
-        x1 = conv1(input_tensor[..., :-c_outer])
-        x1 = act(x1)
-        x1 = tf.keras.layers.ZeroPadding2D(((N // 4), (N // 4)), name=name + '_padded')(x1)
-        
-        if not cfg.get('probe.big'):
-            return x1
-        
-        x2 = Conv_Up_block(input_tensor[..., -c_outer:], n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = swish(x2)
-        
-        # Drop the central region of x2
-        center_mask = hh.mk_centermask(x2, N, 1, kind='border')
-        x2_masked = x2 * center_mask
-        
-        outputs = x1 + x2_masked
-        return outputs
-
-    else:
-        x2 = Conv_Up_block(input_tensor, n_filters_scale * scale_factor)
-        x2 = conv2(x2)
-        x2 = act(x2)
-        return x2
-
-
-def create_decoder_phase(input_tensor, n_filters_scale, gridsize, big):
-    num_filters = gridsize**2 if big else 1
-    conv1 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    act = tf.keras.layers.Lambda(lambda x: math.pi * tf.keras.activations.tanh(x), name='phi')
-    
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act, name='phase')
-    return outputs
-
-
-def create_autoencoder(input_tensor, n_filters_scale, gridsize, big):
-    encoded = create_encoder(input_tensor, n_filters_scale)
-    decoded_amp = create_decoder_amp(encoded, n_filters_scale)
-    decoded_phase = create_decoder_phase(encoded, n_filters_scale, gridsize, big)
-    
-    return decoded_amp, decoded_phase
-
-
-def get_amp_activation():
-    if cfg.get('amp_activation') == 'sigmoid':
-        return lambda x: sigmoid(x)
-    elif cfg.get('amp_activation') == 'swish':
-        return lambda x: swish(x)
-    elif cfg.get('amp_activation') == 'softplus':
-        return lambda x: softplus(x)
-    elif cfg.get('amp_activation') == 'relu':
-        return lambda x: relu(x)
-    else:
-        return ValueError
-
-def create_decoder_amp(input_tensor, n_filters_scale):
-    # Placeholder convolution layers and activation as defined in the original DecoderAmp class
-    conv1 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    act = Lambda(get_amp_activation(), name='amp')
-
-    x = create_decoder_base(input_tensor, n_filters_scale)
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act,
-        name = 'amp')
-    return outputs
-
-normed_input = scale([input_img])
-decoded1, decoded2 = create_autoencoder(normed_input, n_filters_scale, gridsize,
-    cfg.get('object.big'))
-
-# Combine the two decoded outputs
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]), name='obj')([decoded1, decoded2])
-
-if cfg.get('object.big'):
-    # If 'object.big' is true, reassemble the patches
-    padded_obj_2 = Lambda(lambda x: hh.reassemble_patches(x[0], fn_reassemble_real=hh.mk_reassemble_position_real(x[1])), name = 'padded_obj_2')([obj, input_positions])
-else:
-    # If 'object.big' is not true, pad the reconstruction
-    padded_obj_2 = Lambda(lambda x: hh.pad_reconstruction(x), name = 'padded_obj_2')(obj)
-
-# TODO rename?
-# Trim the object reconstruction to N x N
-trimmed_obj = Lambda(hh.trim_reconstruction, name = 'trimmed_obj')(padded_obj_2)
-
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x:
-    hh.extract_patches_position(x[0], x[1], 0.),
-    name = 'padded_objs_with_offsets')([padded_obj_2, input_positions])
-
-# Apply the probe illumination
-padded_objs_with_offsets, probe = probe_illumination([padded_objs_with_offsets])
-flat_illuminated = padded_objs_with_offsets
-
-# Apply pad and diffract operation
-padded_objs_with_offsets, pred_diff = Lambda(lambda x: hh.pad_and_diffract(x, N, N, pad=False), name = 'pred_amplitude')(padded_objs_with_offsets)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-# Scale the amplitude
-pred_amp_scaled = inv_scale([pred_diff])
-
-
-# TODO Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
-dist_poisson_intensity = tfpl.DistributionLambda(lambda amplitude:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               (amplitude**2)))))
-pred_intensity_sampled = dist_poisson_intensity(pred_amp_scaled)
-
-# Poisson distribution over expected diffraction intensity (i.e. photons per
-# pixel)
-def negloglik(x, rv_x):
-    return -rv_x.log_prob(x)
-fn_poisson_nll = lambda A_target, A_pred: negloglik(A_target**2, dist_poisson_intensity(A_pred))
-
-autoencoder = Model([input_img, input_positions], [trimmed_obj, pred_amp_scaled, pred_intensity_sampled])
-
-autoencoder_no_nll = Model(inputs = [input_img, input_positions],
-        outputs = [pred_amp_scaled])
-
-#encode_obj_to_diffraction = tf.keras.Model(inputs=[obj, input_positions],
-#                           outputs=[pred_diff, flat_illuminated])
-diffraction_to_obj = tf.keras.Model(inputs=[input_img, input_positions],
-                           outputs=[trimmed_obj])
-
-mae_weight = cfg.get('mae_weight') # should normally be 0
-nll_weight = cfg.get('nll_weight') # should normally be 1
-# Total variation regularization on real space amplitude
-realspace_weight = cfg.get('realspace_weight')#1e2
-optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
-
-autoencoder.compile(optimizer= optimizer,
-     #loss=[lambda target, pred: hh.total_variation(pred),
-     loss=[hh.realspace_loss,
-        'mean_absolute_error', negloglik, 'mean_absolute_error'],
-     loss_weights = [realspace_weight, mae_weight, nll_weight, 0.])
-
-print (autoencoder.summary())
-
-# Create a TensorBoard callback
-logs = "logs/" + datetime.now().strftime("%Y%m%d-%H%M%S")
-
-tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,
-                                                 histogram_freq=1,
-                                                 profile_batch='500,520')
-
-def prepare_inputs(train_data: PtychoDataContainer):
-    """training inputs"""
-    return [train_data.X * cfg.get('intensity_scale'), train_data.coords]
-
-def prepare_outputs(train_data: PtychoDataContainer):
-    """training outputs"""
-    return [hh.center_channels(train_data.Y_I, train_data.coords)[:, :, :, :1],
-                (cfg.get('intensity_scale') * train_data.X),
-                (cfg.get('intensity_scale') * train_data.X)**2]
-
-#def train(epochs, X_train, coords_train, Y_obj_train):
-def train(epochs, trainset: PtychoDataContainer):
-    assert type(trainset) == PtychoDataContainer
-    coords_train = trainset.coords
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint(
-                            '%s/weights.{epoch:02d}.h5' %wt_path,
-                            monitor='val_loss', verbose=1, save_best_only=True,
-                            save_weights_only=False, mode='auto', period=1)
-
-    batch_size = params()['batch_size']
-    history=autoencoder.fit(
-#        prepare_inputs(X_train, coords_train),
-#        prepare_outputs(Y_obj_train, coords_train, X_train),
-        prepare_inputs(trainset),
-        prepare_outputs(trainset),
-        shuffle=True, batch_size=batch_size, verbose=1,
-        epochs=epochs, validation_split = 0.05,
-        callbacks=[reduce_lr, earlystop])
-        #callbacks=[reduce_lr, earlystop, tboard_callback])
-    return history
-import numpy as np
-
-def print_model_diagnostics(model):
-    """
-    Prints diagnostic information for a given TensorFlow/Keras model.
-
-    Parameters:
-    - model: A TensorFlow/Keras model object.
-    """
-    # Print the model summary to get the architecture, layer types, output shapes, and parameter counts.
-    model.summary()
-
-    # Print input shape
-    print("Model Input Shape(s):")
-    for input_layer in model.inputs:
-        print(input_layer.shape)
-
-    # Print output shape
-    print("Model Output Shape(s):")
-    for output_layer in model.outputs:
-        print(output_layer.shape)
-
-    # Print total number of parameters
-    print("Total Parameters:", model.count_params())
-
-    # Print trainable and non-trainable parameter counts
-    trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
-    non_trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])
-    print("Trainable Parameters:", trainable_count)
-    print("Non-trainable Parameters:", non_trainable_count)
-
-    # If the model uses any custom layers, print their names and configurations
-    print("Custom Layers (if any):")
-    for layer in model.layers:
-        if hasattr(layer, 'custom_objects'):
-            print(f"{layer.name}: {layer.custom_objects}")
diff --git a/build/lib/build/lib/ptycho/model_manager.py b/build/lib/build/lib/ptycho/model_manager.py
deleted file mode 100644
index 2ee4937..0000000
--- a/build/lib/build/lib/ptycho/model_manager.py
+++ /dev/null
@@ -1,202 +0,0 @@
-# model_manager.py
-
-import os
-import h5py
-import dill
-import tempfile
-import zipfile
-import shutil
-import tensorflow as tf
-from typing import Dict, List, Any, Optional
-from ptycho import params
-
-class ModelManager:
-    @staticmethod
-    def save_model(model: tf.keras.Model, model_dir: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model (tf.keras.Model): The model to save.
-            model_dir (str): Directory path for saving the model.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the model.
-            intensity_scale (float): The intensity scale used in the model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            os.makedirs(model_dir, exist_ok=True)
-            
-            # Save the model
-            model.save(model_dir, save_format="tf")
-            
-            # Save custom objects
-            with open(custom_objects_path, 'wb') as f:
-                dill.dump(custom_objects, f)
-            
-            # Save parameters including intensity_scale
-            params_dict = params.cfg.copy()
-            params_dict['intensity_scale'] = intensity_scale
-            params_dict['_version'] = '1.0'  # Add version information
-            with open(params_path, 'wb') as f:
-                dill.dump(params_dict, f)
-            
-            # Save intensity_scale as an attribute in the HDF5 file
-            with h5py.File(model_file, 'a') as hf:
-                hf.attrs['intensity_scale'] = intensity_scale
-        
-        except Exception as e:
-            print(f"Error saving model to {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def load_model(model_dir: str) -> tf.keras.Model:
-        """
-        Load a single model along with its custom objects, parameters, and intensity scale.
-
-        Args:
-            model_dir (str): Directory containing the model files.
-
-        Returns:
-            tf.keras.Model: The loaded model.
-        """
-        model_file = os.path.join(model_dir, "model.h5")
-        custom_objects_path = os.path.join(model_dir, "custom_objects.dill")
-        params_path = os.path.join(model_dir, "params.dill")
-        
-        try:
-            
-            # Load parameters
-            with open(params_path, 'rb') as f:
-                loaded_params = dill.load(f)
-            
-            # Check version and handle any necessary migrations
-            version = loaded_params.pop('_version', '1.0')
-            # Here you could add logic to handle different versions if needed
-            
-            # Update params.cfg with loaded parameters
-            params.cfg.update(loaded_params)
-            
-            # Load custom objects
-            with open(custom_objects_path, 'rb') as f:
-                custom_objects = dill.load(f)
-            
-            # Load intensity scale
-            with h5py.File(model_file, 'r') as hf:
-                intensity_scale = hf.attrs['intensity_scale']
-            
-            # Set intensity scale in params
-            params.set('intensity_scale', intensity_scale)
-
-            # Load and return the model
-            return tf.keras.models.load_model(model_dir, custom_objects=custom_objects)
-        
-        except Exception as e:
-            print(f"Error loading model from {model_dir}: {str(e)}")
-            raise
-
-    @staticmethod
-    def save_multiple_models(models_dict: Dict[str, tf.keras.Model], base_path: str, custom_objects: Dict[str, Any], intensity_scale: float) -> None:
-        """
-        Save multiple models into a single zip archive.
-
-        Args:
-            models_dict (Dict[str, tf.keras.Model]): Dictionary of models to save.
-            base_path (str): Base path for saving the zip archive.
-            custom_objects (Dict[str, Any]): Dictionary of custom objects used in the models.
-            intensity_scale (float): The intensity scale used in the models.
-        """
-        zip_path = f"{base_path}.zip"
-        os.makedirs(os.path.dirname(zip_path), exist_ok=True)
-        
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Save manifest of included models
-            manifest = {'models': list(models_dict.keys()), 'version': '1.0'}
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'wb') as f:
-                dill.dump(manifest, f)
-            
-            # Save each model to temp directory
-            for model_name, model in models_dict.items():
-                model_subdir = os.path.join(temp_dir, model_name)
-                os.makedirs(model_subdir, exist_ok=True)
-                ModelManager.save_model(model, model_subdir, custom_objects, intensity_scale)
-            
-            # Create zip archive
-            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
-                for root, _, files in os.walk(temp_dir):
-                    for file in files:
-                        full_path = os.path.join(root, file)
-                        arc_path = os.path.relpath(full_path, temp_dir)
-                        zf.write(full_path, arc_path)
-
-    @staticmethod
-    def load_multiple_models(base_path: str, model_names: Optional[List[str]] = None) -> Dict[str, tf.keras.Model]:
-        """
-        Load multiple models from a zip archive.
-
-        Args:
-            base_path (str): Base path of the zip archive.
-            model_names (Optional[List[str]]): List of model names to load. If None, loads all models.
-
-        Returns:
-            Dict[str, tf.keras.Model]: Dictionary of loaded models.
-        """
-        zip_path = f"{base_path}.zip"
-        if not os.path.exists(zip_path):
-            raise FileNotFoundError(f"Model archive not found: {zip_path}")
-            
-        with tempfile.TemporaryDirectory() as temp_dir:
-            # Extract zip archive
-            with zipfile.ZipFile(zip_path, 'r') as zf:
-                zf.extractall(temp_dir)
-            
-            # Load manifest
-            manifest_path = os.path.join(temp_dir, 'manifest.dill')
-            with open(manifest_path, 'rb') as f:
-                manifest = dill.load(f)
-            
-            # Determine which models to load
-            available_models = manifest['models']
-            if model_names is None:
-                model_names = available_models
-            else:
-                # Validate requested models exist
-                missing = set(model_names) - set(available_models)
-                if missing:
-                    raise ValueError(f"Requested models not found in archive: {missing}")
-            
-            # Load each requested model
-            loaded_models = {}
-            for model_name in model_names:
-                model_subdir = os.path.join(temp_dir, model_name)
-                loaded_models[model_name] = ModelManager.load_model(model_subdir)
-            
-            return loaded_models
-
-
-def save(out_prefix: str) -> None:
-    """Save models to a zip archive."""
-    from ptycho import model
-    from ptycho.model import ProbeIllumination, IntensityScaler, IntensityScaler_inv, negloglik
-    from ptycho.tf_helper import Translation
-    from ptycho.tf_helper import realspace_loss as hh_realspace_loss
-
-    model_path = os.path.join(out_prefix, params.get('h5_path'))
-    custom_objects = {
-        'ProbeIllumination': ProbeIllumination,
-        'IntensityScaler': IntensityScaler,
-        'IntensityScaler_inv': IntensityScaler_inv,
-        'Translation': Translation,
-        'negloglik': negloglik,
-        'realspace_loss': hh_realspace_loss
-    }
-    
-    models_to_save = {
-        'autoencoder': model.autoencoder,
-        'diffraction_to_obj': model.diffraction_to_obj
-    }
-    
-    ModelManager.save_multiple_models(models_to_save, model_path, custom_objects, params.get('intensity_scale'))
diff --git a/build/lib/build/lib/ptycho/nbutils.py b/build/lib/build/lib/ptycho/nbutils.py
deleted file mode 100644
index fe53aab..0000000
--- a/build/lib/build/lib/ptycho/nbutils.py
+++ /dev/null
@@ -1,217 +0,0 @@
-import matplotlib.pyplot as plt
-from ptycho import model
-import numpy as np
-
-def crop_to_non_uniform_region_with_buffer(img_array, buffer=0):
-    """
-    Crop the image to the non-uniform region with an additional buffer in each direction.
-
-    Parameters:
-    - img_array: The numpy array of the image.
-    - buffer: The number of pixels to expand the cropped region in each direction.
-
-    Returns:
-    - cropped_img_array: The numpy array of the cropped image.
-    """
-
-    # Convert to grayscale if it is not already
-    if len(img_array.shape) == 3:
-        gray_img_array = img_array[:, :, 0]
-    else:
-        gray_img_array = img_array
-
-    # Find the background pixel value, assuming it is the mode of the corner pixels
-    corner_pixels = [gray_img_array[0, 0], gray_img_array[0, -1], gray_img_array[-1, 0], gray_img_array[-1, -1]]
-    background_pixel = max(set(corner_pixels), key=corner_pixels.count)
-
-    # Detect the non-uniform region
-    rows, cols = np.where(gray_img_array != background_pixel)
-    if rows.size > 0 and cols.size > 0:
-        row_min, row_max, col_min, col_max = rows.min(), rows.max(), cols.min(), cols.max()
-        # Apply the buffer, ensuring we don't go out of the image bounds
-        row_min = max(row_min - buffer, 0)
-        row_max = min(row_max + buffer, gray_img_array.shape[0] - 1)
-        col_min = max(col_min - buffer, 0)
-        col_max = min(col_max + buffer, gray_img_array.shape[1] - 1)
-    else:
-        raise ValueError("No non-uniform region found")
-
-    # Crop the image to the non-uniform region with the buffer
-    cropped_img_array = gray_img_array[row_min:row_max+1, col_min:col_max+1]
-
-    return cropped_img_array
-
-import matplotlib.pyplot as plt
-
-def mk_comparison(method1, method2, method1_name='PtychoNN', method2_name='ground truth', method0=None, method0_name='ePIE', phase_vmin=None, phase_vmax=None):
-    """
-    Create a comparison plot of phase and amplitude images for 2 or 3 methods.
-
-    Parameters:
-    - method1: Complex 2D array of method1 data
-    - method2: Complex 2D array of method2 data
-    - method1_name: Name of the first method (default: 'PtychoNN')
-    - method2_name: Name of the second method (default: 'ground truth')
-    - method0: Complex 2D array of method0 data (optional)
-    - method0_name: Name of the optional third method (default: 'ePIE')
-    - phase_vmin: Minimum data value for phase plots (optional)
-    - phase_vmax: Maximum data value for phase plots (optional)
-    """
-    num_methods = 3 if method0 is not None else 2
-    fig, axs = plt.subplots(2, num_methods, figsize=(5*num_methods, 10))
-
-    methods = [method0, method1, method2] if num_methods == 3 else [method1, method2]
-    method_names = [method0_name, method1_name, method2_name] if num_methods == 3 else [method1_name, method2_name]
-
-    for i, (method, name) in enumerate(zip(methods, method_names)):
-        # Phase plot
-        phase_img = axs[0, i].imshow(np.angle(method), cmap='gray', vmin=phase_vmin, vmax=phase_vmax)
-        axs[0, i].set_title(f'{name} Phase')
-        axs[0, i].axis('off')
-        fig.colorbar(phase_img, ax=axs[0, i], orientation='vertical')
-
-        # Amplitude plot
-        amp_img = axs[1, i].imshow(np.abs(method), cmap='viridis')
-        axs[1, i].set_title(f'{name} Amplitude')
-        axs[1, i].axis('off')
-        fig.colorbar(amp_img, ax=axs[1, i], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-    plt.show()
-
-def compare(obj_tensor_full, global_offsets, objectGuess, ptychonn_tensor=None):
-    from ptycho import loader
-
-    # Process PtychoPINN data
-    ptychopinn_image = loader.reassemble_position(obj_tensor_full, global_offsets[:, :, :, :], M=20)
-    ptychopinn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychopinn_image[..., 0]), buffer=-20)
-    ptychopinn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychopinn_image[..., 0]), buffer=-20)
-
-    # Process ground truth data
-    gt_phase = crop_to_non_uniform_region_with_buffer(np.angle(objectGuess), buffer=-20)
-    gt_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(objectGuess), buffer=-20)
-
-    # Process PtychoNN data if provided
-    if ptychonn_tensor is not None:
-        ptychonn_image = loader.reassemble_position(ptychonn_tensor, global_offsets[:, :, :, :], M=20)
-        ptychonn_phase = crop_to_non_uniform_region_with_buffer(np.angle(ptychonn_image[..., 0]), buffer=-20)
-        ptychonn_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(ptychonn_image[..., 0]), buffer=-20)
-        
-        # Create comparison with all three methods
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth',
-                      method0=ptychonn_phase + 1j * ptychonn_amplitude, 
-                      method0_name='PtychoNN')
-    else:
-        # Create comparison with only PtychoPINN and ground truth
-        mk_comparison(ptychopinn_phase + 1j * ptychopinn_amplitude, 
-                      gt_phase + 1j * gt_amplitude, 
-                      method1_name='PtychoPINN', 
-                      method2_name='ground truth')
-
-# TODO type annotation
-def reconstruct_image(test_data, diffraction_to_obj = None):
-    global_offsets = test_data.global_offsets
-    local_offsets = test_data.local_offsets
-
-    if diffraction_to_obj is None:
-        diffraction_to_obj = model.diffraction_to_obj
-    obj_tensor_full = diffraction_to_obj.predict(
-                    [test_data.X * model.params()['intensity_scale'],
-                    local_offsets])
-    return obj_tensor_full, global_offsets
-
-def print_shapes(test_data):
-    for key, value in test_data.items():
-        if value is not None:
-            if isinstance(value, tuple):
-                print(f"{key}\t")
-                for i, array in enumerate(value):
-                    print(f"  Array {i+1}{array.shape}, \t {array.dtype}")
-            else:
-                print(f"{key}\t{value.shape}, {value.dtype}")
-
-def probeshow(probeGuess, test_data):
-    # Creating a figure with three subplots
-    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
-
-    # Plotting the magnitude of the complex array
-    img1 = ax1.imshow(np.abs(probeGuess), cmap='viridis')
-    ax1.set_title('probe amplitude')
-    fig.colorbar(img1, ax=ax1, orientation='vertical')
-
-    # Plotting the phase of the complex array
-    img2 = ax2.imshow(np.angle(probeGuess), cmap='jet')
-    ax2.set_title('probe phase')
-    fig.colorbar(img2, ax=ax2, orientation='vertical')
-
-    # Plotting the scan point positions
-    ax3.scatter(*(test_data.global_offsets.squeeze().T))
-    ax3.set_title('scan point positions')
-
-    # Improving layout
-    plt.tight_layout()
-    plt.show()
-
-
-def track_dict_changes(input_dict, callback):
-    # Copy the original dictionary to track changes
-    original_dict = input_dict.copy()
-    # Execute the callback function
-    callback(input_dict)
-    # Determine which keys have changed or added
-    changed_or_added_keys = [key for key in input_dict if input_dict.get(key) != original_dict.get(key)]
-    return changed_or_added_keys
-
-def mk_epie_comparison2x2(ptycho_pinn_phase, epie_phase, ptycho_pinn_amplitude,epie_amplitude):
-    # Create a 2x2 subplot
-    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
-
-    # PtychoPINN phase with color bar
-    ptycho_pinn_phase_img = axs[0, 0].imshow(ptycho_pinn_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    axs[0, 0].axis('off')
-    fig.colorbar(ptycho_pinn_phase_img, ax=axs[0, 0], orientation='vertical')
-
-    # ePIE phase with color bar
-    epie_phase_img = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    axs[0, 1].axis('off')
-    fig.colorbar(epie_phase_img, ax=axs[0, 1], orientation='vertical')
-
-    # PtychoPINN amplitude with color bar
-    ptycho_pinn_amplitude_img = axs[1, 0].imshow(ptycho_pinn_amplitude, cmap='gray')#,
-                                               # vmin = .2
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    axs[1, 0].axis('off')
-    fig.colorbar(ptycho_pinn_amplitude_img, ax=axs[1, 0], orientation='vertical')
-
-    # ePIE amplitude with color bar
-    epie_amplitude_img = axs[1, 1].imshow(epie_amplitude, cmap='gray')
-    axs[1, 1].set_title('ePIE Amplitude')
-    axs[1, 1].axis('off')
-    fig.colorbar(epie_amplitude_img, ax=axs[1, 1], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-
-    plt.show()
-
-# object heatmaps
-## Creating a figure and two subplots
-#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
-#
-## Plotting the amplitude of the complex object
-#ax1.imshow(np.absolute(objectGuess), cmap='viridis')
-#ax1.set_title('Amplitude')
-#
-## Plotting the phase of the complex object
-#ax2.imshow(np.angle(objectGuess), cmap='viridis')
-#ax2.set_title('Phase')
-#
-## Adjust layout
-#plt.tight_layout()
-#plt.show()
diff --git a/build/lib/build/lib/ptycho/nongrid_simulation.py b/build/lib/build/lib/ptycho/nongrid_simulation.py
deleted file mode 100644
index 9c653ea..0000000
--- a/build/lib/build/lib/ptycho/nongrid_simulation.py
+++ /dev/null
@@ -1,266 +0,0 @@
-# ptycho_simulation.py
-
-import numpy as np
-import matplotlib.pyplot as plt
-from mpl_toolkits.axes_grid1 import make_axes_locatable
-from typing import Union, Tuple, Dict
-from ptycho.loader import RawData
-from ptycho import tf_helper as hh
-from ptycho import probe
-from ptycho import baselines as bl
-
-def load_probe_object(file_path: str) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Load object and probe guesses from a .npz file.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-
-    Returns:
-        tuple: A tuple containing (objectGuess, probeGuess)
-
-    Raises:
-        ValueError: If required data is missing from the .npz file or if data is invalid.
-        RuntimeError: If an error occurs during file loading.
-    """
-    try:
-        with np.load(file_path) as data:
-            if 'objectGuess' not in data or 'probeGuess' not in data:
-                raise ValueError("The .npz file must contain 'objectGuess' and 'probeGuess'")
-            
-            objectGuess = data['objectGuess']
-            probeGuess = data['probeGuess']
-
-        # Validate extracted data
-        if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-            raise ValueError("objectGuess and probeGuess must be 2D arrays")
-        if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-            raise ValueError("objectGuess and probeGuess must be complex-valued")
-
-        return objectGuess, probeGuess
-
-    except Exception as e:
-        raise RuntimeError(f"Error loading data from {file_path}: {str(e)}")
-
-from ptycho.misc import memoize_simulated_data
-
-#@memoize_simulated_data
-def generate_simulated_data(objectGuess: np.ndarray, probeGuess: np.ndarray, nimages: int, buffer: float, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    Args:
-        objectGuess (np.ndarray): Complex-valued 2D array representing the object.
-        probeGuess (np.ndarray): Complex-valued 2D array representing the probe.
-        nimages (int): Number of scan positions to generate.
-        buffer (float): Border size to avoid when generating coordinates.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation.
-    """
-    # Input validation
-    if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-        raise ValueError("objectGuess and probeGuess must be 2D arrays")
-    if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-        raise ValueError("objectGuess and probeGuess must be complex-valued")
-    if nimages <= 0 or buffer < 0:
-        raise ValueError("nimages must be positive and buffer must be non-negative")
-
-    # Get object dimensions
-    height, width = objectGuess.shape
-
-    # Ensure buffer doesn't exceed image dimensions
-    buffer = min(buffer, min(height, width) / 2 - 1)
-
-    # Set random seed if provided
-    if random_seed is not None:
-        np.random.seed(random_seed)
-
-    # Generate random coordinates (floats)
-    xcoords = np.random.uniform(buffer, width - buffer, nimages)
-    ycoords = np.random.uniform(buffer, height - buffer, nimages)
-
-    # Create scan_index
-    scan_index = np.zeros(nimages, dtype=int)
-
-    # Generate simulated data
-    return RawData.from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index, return_patches=return_patches)
-
-def simulate_from_npz(file_path: str, nimages: int, buffer: float = None, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Load object and probe guesses from a .npz file and generate simulated ptychography data.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-        nimages (int): Number of scan positions to generate.
-        buffer (float, optional): Border size to avoid when generating coordinates. 
-                                  If None, defaults to 35% of the smaller dimension of objectGuess.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation or file loading.
-    """
-    # Load guesses from file
-    objectGuess, probeGuess = load_probe_object(file_path)
-
-    # Set default buffer if not provided
-    if buffer is None:
-        buffer = min(objectGuess.shape) * 0.35  # 35% of the smaller dimension
-
-    # Generate simulated data
-    return generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches=return_patches)
-
-def plot_complex_image(ax: plt.Axes, data: np.ndarray, title: str) -> None:
-    """Helper function to plot complex-valued images."""
-    im = ax.imshow(np.abs(data), cmap='viridis')
-    ax.set_title(f"{title} (Magnitude)")
-    divider = make_axes_locatable(ax)
-    cax = divider.append_axes("right", size="5%", pad=0.05)
-    plt.colorbar(im, cax=cax)
-
-    ax_phase = divider.append_axes("bottom", size="100%", pad=0.2, sharex=ax)
-    im_phase = ax_phase.imshow(np.angle(data), cmap='hsv')
-    ax_phase.set_title(f"{title} (Phase)")
-    cax_phase = divider.append_axes("bottom", size="5%", pad=0.5)
-    plt.colorbar(im_phase, cax=cax_phase, orientation="horizontal")
-
-def visualize_simulated_data(data: Dict[str, np.ndarray], output_dir: str) -> None:
-    """
-    Visualize the simulated ptychography data and save all plots in a single image file.
-
-    Args:
-        data (dict): Dictionary containing the loaded simulated data.
-        output_dir (str): Directory to save the output plot.
-    """
-    import os
-
-    # Create output directory if it doesn't exist
-    os.makedirs(output_dir, exist_ok=True)
-
-    # Create a large figure with multiple subplots
-    fig = plt.figure(figsize=(24, 30))
-    gs = fig.add_gridspec(5, 3, height_ratios=[1, 0.2, 1, 0.2, 1])
-
-    # Plot probe guess
-    ax_probe = fig.add_subplot(gs[0, 0])
-    plot_complex_image(ax_probe, data['probe_guess'], "Probe Guess")
-
-    # Plot object guess
-    ax_object = fig.add_subplot(gs[0, 1])
-    plot_complex_image(ax_object, data['object'], "Object Guess")
-
-    # Plot scan positions
-    ax_scan = fig.add_subplot(gs[0, 2])
-    ax_scan.scatter(data['x_coordinates'], data['y_coordinates'], alpha=0.5)
-    ax_scan.set_title("Scan Positions")
-    ax_scan.set_xlabel("X Coordinate")
-    ax_scan.set_ylabel("Y Coordinate")
-    ax_scan.set_aspect('equal')
-
-    # Add title for diffraction patterns
-    fig.text(0.5, 0.62, "Sample Diffraction Patterns", ha='center', va='center', fontsize=16)
-
-    # Plot a sample of diffraction patterns
-    for i in range(3):
-        if i < min(3, data['diffraction_patterns'].shape[0]):
-            ax = fig.add_subplot(gs[2, i])
-            im = ax.imshow(np.log(data['diffraction_patterns'][i]), cmap='viridis')
-            ax.set_title(f"Pattern {i}")
-            plt.colorbar(im, ax=ax)
-
-    # Add title for ground truth patches
-    fig.text(0.5, 0.22, "Sample Ground Truth Patches", ha='center', va='center', fontsize=16)
-
-    # Plot ground truth patches
-    for i in range(3):
-        if i < min(3, data['ground_truth_patches'].shape[0]):
-            ax = fig.add_subplot(gs[4, i])
-            plot_complex_image(ax, data['ground_truth_patches'][i], f"Patch {i}")
-
-    plt.tight_layout()
-    plt.savefig(os.path.join(output_dir, "simulated_data_visualization.png"), dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-    print(f"All plots have been saved to: {os.path.join(output_dir, 'simulated_data_visualization.png')}")
-
-def plot_random_groups(tmp: RawData, K: int, figsize: Tuple[int, int] = (15, 5), seed: int = None) -> None:
-    """
-    Plot a random selection of K groups of (diffraction image, Y amplitude, Y phase) from a RawData object.
-
-    Args:
-        tmp (RawData): The RawData object containing the ptychography data.
-        K (int): Number of groups to plot.
-        figsize (tuple): Figure size for each group plot. Default is (15, 5).
-        seed (int): Random seed for reproducibility. Default is None.
-
-    Raises:
-        ValueError: If K is greater than the number of available diffraction patterns.
-    """
-    if K > tmp.diff3d.shape[0]:
-        raise ValueError(f"K ({K}) cannot be greater than the number of diffraction patterns ({tmp.diff3d.shape[0]})")
-
-    # Set random seed if provided
-    if seed is not None:
-        np.random.seed(seed)
-
-    # Randomly select K indices
-    indices = np.random.choice(tmp.diff3d.shape[0], K, replace=False)
-
-    for idx in indices:
-        fig, axes = plt.subplots(1, 3, figsize=figsize)
-        fig.suptitle(f"Group {idx}")
-
-        # Plot diffraction image (log scale for better visibility)
-        diff_img = axes[0].imshow(np.log1p(1 + 100 * tmp.diff3d[idx]), cmap='jet')
-        axes[0].set_title("Diffraction (log scale)")
-        plt.colorbar(diff_img, ax=axes[0])
-
-        # Plot Y amplitude
-        amp_img = axes[1].imshow(np.abs(tmp.Y[idx]), cmap='viridis')
-        axes[1].set_title("Y Amplitude")
-        plt.colorbar(amp_img, ax=axes[1])
-
-        # Plot Y phase
-        phase_img = axes[2].imshow(np.angle(tmp.Y[idx]), cmap='twilight')
-        axes[2].set_title("Y Phase")
-        plt.colorbar(phase_img, ax=axes[2])
-
-        # Remove axis ticks for cleaner look
-        for ax in axes:
-            ax.set_xticks([])
-            ax.set_yticks([])
-
-        plt.tight_layout()
-        plt.show()
-
-def compare_reconstructions(obj_tensor_full: np.ndarray, global_offsets: np.ndarray, ground_truth: np.ndarray, ptychonn_tensor: np.ndarray) -> None:
-    """
-    Compare the reconstructed object with the ground truth and PtychoNN prediction.
-
-    Args:
-        obj_tensor_full (np.ndarray): Full reconstructed object tensor.
-        global_offsets (np.ndarray): Global offsets for positioning.
-        ground_truth (np.ndarray): Ground truth object.
-        ptychonn_tensor (np.ndarray): PtychoNN predicted object tensor.
-    """
-    from ptycho import nbutils
-    irange = int(np.max(global_offsets[:, 0, 1, 0]) - np.min(global_offsets[:, 0, 1, 0]))
-    trimmed_ground_truth = hh.trim_reconstruction(ground_truth[None, ..., None], irange)[0, :, :, 0]
-    
-    nbutils.compare(obj_tensor_full, global_offsets, trimmed_ground_truth, ptychonn_tensor=ptychonn_tensor)
-
-# Add any additional helper functions or classes as needed
-
diff --git a/build/lib/build/lib/ptycho/params.py b/build/lib/build/lib/ptycho/params.py
deleted file mode 100644
index 3215103..0000000
--- a/build/lib/build/lib/ptycho/params.py
+++ /dev/null
@@ -1,86 +0,0 @@
-"""
-Stores global variables for data generation and model configuration
-"""
-import numpy as np
-import tensorflow as tf
-# TODO naming convention for different types of parameters
-# TODO what default value and initialization for the probe scale?
-cfg = {
-    'N': 64, 'offset': 4, 'gridsize': 2,
-    'outer_offset_train': None, 'outer_offset_test': None, 'batch_size': 16,
-    'nepochs': 60, 'n_filters_scale': 2, 'output_prefix': 'outputs',
-    'big_gridsize': 10, 'max_position_jitter': 10, 'sim_jitter_scale': 0.,
-    'default_probe_scale': 0.7, 'mae_weight': 0., 'nll_weight': 1., 'tv_weight': 0.,
-    'realspace_mae_weight': 0., 'realspace_weight': 0., 'nphotons': 1e9,
-    'nimgs_train': 9, 'nimgs_test': 3,
-    'data_source': 'generic', 'probe.trainable': False,
-    'intensity_scale.trainable': False, 'positions.provided': False,
-    'object.big': True, 'probe.big': False, 'probe_scale': 10., 'set_phi': False,
-    'probe.mask': True, 'pad_object': True, 'model_type': 'pinn', 'label': '', 'size': 392,
-    'amp_activation': 'sigmoid', 'h5_path': 'wts.h5', 'npseed': 42,
-    'debug': True,
-    'gaussian_smoothing_sigma': 0.0  # New parameter for Gaussian smoothing sigma
-    }
-
-# TODO parameter description
-# probe.big: if True, increase the real space solution from 32x32 to 64x64
-
-# TODO bigoffset should be a derived quantity, at least for simulation
-def get_bigN():
-    N = cfg['N']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return N + (gridsize - 1) * offset
-
-def get_padding_size():
-    buffer = cfg['max_position_jitter']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return (gridsize - 1) * offset + buffer
-
-def get_padded_size():
-    bigN = get_bigN()
-    buffer = cfg['max_position_jitter']
-    return bigN + buffer
-
-def params():
-    d = {k:v for k, v in cfg.items()}
-    d['bigN'] = get_bigN()
-    return d
-
-# TODO refactor
-def validate():
-    valid_data_sources = ['lines', 'grf', 'experimental', 'points',
-        'testimg', 'diagonals', 'xpp', 'V', 'generic']
-    assert cfg['data_source'] in valid_data_sources, \
-        f"Invalid data source: {cfg['data_source']}. Must be one of {valid_data_sources}."
-    if cfg['realspace_mae_weight'] > 0.:
-        assert cfg['realspace_weight'] > 0
-    return True
-
-def set(key, value):
-    print("DEBUG: Setting", key, "to", value, "in params")
-    cfg[key] = value
-    assert validate()
-
-def get(key):
-    if key == 'bigN':
-        cfg['bigN'] = get_bigN()
-        return cfg['bigN']
-    return cfg[key]
-
-def print_params():
-    """Print all parameters with special handling for arrays/tensors"""
-    all_params = params()
-    print("Current Parameters:")
-    print("-" * 20)
-    for key, value in sorted(all_params.items()):
-        if isinstance(value, (np.ndarray, tf.Tensor)):
-            print(f"{key}:")
-            print(f"  shape: {value.shape}")
-            print(f"  mean: {np.mean(value):.3f}")
-            print(f"  std: {np.std(value):.3f}")
-            print(f"  min: {np.min(value):.3f}")
-            print(f"  max: {np.max(value):.3f}")
-        else:
-            print(f"{key}: {value}")
diff --git a/build/lib/build/lib/ptycho/physics.py b/build/lib/build/lib/ptycho/physics.py
deleted file mode 100644
index a19c0e5..0000000
--- a/build/lib/build/lib/ptycho/physics.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from . import params as p
-from . import tf_helper as hh
-import tensorflow as tf
-import numpy as np
-import pdb
diff --git a/build/lib/build/lib/ptycho/plotting.py b/build/lib/build/lib/ptycho/plotting.py
deleted file mode 100644
index f02404a..0000000
--- a/build/lib/build/lib/ptycho/plotting.py
+++ /dev/null
@@ -1,94 +0,0 @@
-import matplotlib.pyplot as plt
-from ipywidgets import interactive
-
-def ishow_imgs(*arrs_list, styles = None, labels = None,
-              log = False, height = '550px',
-              nested_label_callback = None):
-    """
-    Plot a series of curves interactively.
-    """
-    plt.rcParams["figure.figsize"]=(12, 9)
-    #labels = [label1, label2]
-    if labels is None:
-        labels = [''] * len(arrs_list)
-    def f(i):
-        for j, patterns in enumerate(arrs_list):
-            if styles is not None:
-                extra_args = (styles[j],)
-            else:
-                extra_args = ()
-            try:
-                for k in range(len(patterns[i])):
-                    len(patterns[i][k]) # TODO hack
-                    if nested_label_callback is not None:
-                        label = nested_label_callback(patterns[i], k)
-                    else:
-                        label = k
-                    plt.imshow(patterns[i][k], *extra_args, label = label)
-            except: # TODO except what?
-                if j < 2:
-                    plt.imshow(patterns[i], label = labels[j])
-                else:
-                    plt.imshow(patterns[i], *extra_args)
-
-    interactive_plot = interactive(f, i=(0, len(arrs_list[0]) - 1), step = 1)
-    output = interactive_plot.children[-1]
-    output.layout.height = height
-    return interactive_plot
-
-# Implementing actual plotting functions and the decorator for visual output
-
-import matplotlib.pyplot as plt
-import numpy as np
-
-from functools import wraps
-
-def plotting_function(func):
-    @wraps(func)
-    def wrapper(layout=(1, 1), display: bool = False, save: bool = False, save_path: str = "", *args, **kwargs):
-        standalone = 'ax' not in kwargs or kwargs['ax'] is None
-        if standalone:
-            fig, axs = plt.subplots(layout[0], layout[1], figsize=(layout[1]*3, layout[0]*3))
-            if layout == (1, 1):
-                axs = np.array([axs])
-            else:
-                axs = axs.reshape(layout[0], layout[1])
-            kwargs['ax'] = axs
-        result = func(*args, **kwargs)
-        if standalone:
-            plt.tight_layout()
-            if save:
-                plt.savefig(save_path if save_path else "/mnt/data/plot.png")
-            if display:
-                plt.show()
-        return result
-    return wrapper
-
-@plotting_function
-def plot_subfigure(ax=None, title: str = "Subfigure", *args, **kwargs):
-    rows, cols = ax.shape if isinstance(ax, np.ndarray) else (1, 1)
-    for i in range(rows):
-        for j in range(cols):
-            ax[i, j].plot([1, 2, 3], [1, 2, 3])
-            ax[i, j].set_title(f"{title} {i+1},{j+1}")
-
-def compose_and_save_figure():
-    fig = plt.figure(figsize=(10, 6))
-    gs = fig.add_gridspec(2, 2)
-
-    ax1 = fig.add_subplot(gs[0, 0])
-    ax2 = fig.add_subplot(gs[0, 1])
-    ax3 = fig.add_subplot(gs[1, :])
-
-    # Adjusting the plotting function to accept individual Axes
-    plot_subfigure(ax=np.array([[ax1]]), title="Plot 1")
-    plot_subfigure(ax=np.array([[ax2]]), title="Plot 2")
-    plot_subfigure(ax=np.array([[ax3]]), layout=(1, 1), title="Plot 3")
-
-    plt.tight_layout()
-    save_path = "/mnt/data/composed_figure.png"
-    plt.savefig(save_path)
-    plt.show()
-## To visually check, we'll call the plot_subfigure function directly with a layout parameter for standalone mode
-#plot_subfigure(layout=(2, 2), display=True, save=True, title="Standalone Plot", save_path="/mnt/data/standalone_plot.png")
-
diff --git a/build/lib/build/lib/ptycho/probe.py b/build/lib/build/lib/ptycho/probe.py
deleted file mode 100644
index 387fcf0..0000000
--- a/build/lib/build/lib/ptycho/probe.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import tensorflow as tf
-import numpy as np
-from . import fourier as f
-from . import params
-
-def get_lowpass_filter(scale, N):
-    return f.lowpass_g(scale, np.ones(N), sym=True)
-
-def get_default_probe(N, fmt='tf'):
-    scale = params.cfg['default_probe_scale']
-    filt = get_lowpass_filter(scale, N)
-    probe_np = f.gf(((np.einsum('i,j->ij', filt, filt)) > .5).astype(float), 1) + 1e-9
-    if fmt == 'np':
-        return probe_np
-    elif fmt == 'tf':
-        return tf.convert_to_tensor(probe_np, tf.complex64)[..., None]
-    else:
-        raise ValueError("Invalid format specified")
-
-def get_probe(params):
-    probe_tf = params.get('probe')
-    assert len(probe_tf.shape) == 3
-    return probe_tf
-
-def to_np(probe):
-    assert len(probe.shape) == 3
-    return np.array(probe[:, :, 0])
-
-def get_squared_distance(N):
-    centered_indices = np.arange(N) - N // 2 + .5
-    x, y = np.meshgrid(centered_indices, centered_indices)
-    return np.sqrt(x*x+y*y)
-
-def get_probe_mask_real(N):
-    return (get_squared_distance(N) < N // 4)[..., None]
-
-def get_probe_mask(N):
-    probe_mask_real = get_probe_mask_real(N)
-    probe_mask = tf.convert_to_tensor(probe_mask_real, tf.complex64)
-    #return tf.convert_to_tensor(probe_mask, tf.complex64)[..., None]
-    return tf.convert_to_tensor(probe_mask, tf.complex64)
-
-def set_probe(probe):
-    assert len(probe.shape) == 3 or len(probe.shape) == 4
-    assert probe.shape[0] == probe.shape[1]
-    assert probe.shape[-1] == 1
-    if len(probe.shape) == 4:
-        assert probe.shape[-2] == 1
-        probe = probe[:, :, :]
-        print('coercing probe shape to 3d')
-
-    # This function still modifies global state
-    mask = tf.cast(get_probe_mask(params.get('N')), probe.dtype)
-    probe_scale = params.get('probe_scale')
-    tamped_probe = mask * probe
-    norm = float(probe_scale * tf.reduce_mean(tf.math.abs(tamped_probe)))
-    params.set('probe', probe / norm)
-
-def set_probe_guess(X_train = None, probe_guess = None):
-    N = params.get('N')
-    if probe_guess is None:
-        mu = 0.
-        tmp = X_train.mean(axis = (0, 3))
-        probe_fif = np.absolute(f.fftshift(f.ifft2(f.ifftshift(tmp))))[N // 2, :]
-
-        # variance increments of a slice down the middle
-        d_second_moment = (probe_fif / probe_fif.sum()) * ((np.arange(N) - N // 2)**2)
-        probe_sigma_guess = np.sqrt(d_second_moment.sum())
-        probe_guess = np.exp(-( (get_squared_distance(N) - mu)**2 / ( 2.0 * probe_sigma_guess**2 )))[..., None]\
-            + 1e-9
-        probe_guess *= get_probe_mask_real(N)
-        probe_guess *= (np.sum(get_default_probe(N)) / np.sum(probe_guess))
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.float32)
-    else:
-        if probe_guess.ndim not in [2, 3]:
-            raise ValueError("probe_guess must have 2 or 3 dimensions")
-        if probe_guess.ndim == 2:
-            probe_guess = probe_guess[..., None]
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.complex64)
-
-    #params.set('probe', t_probe_guess)
-    set_probe(t_probe_guess)
-    return t_probe_guess
-
-def set_default_probe():
-    """
-    use an idealized disk shaped probe. Only for simulated data workflows.
-    """
-    set_probe(get_default_probe(params.get('N'), fmt = 'tf'))
diff --git a/build/lib/build/lib/ptycho/raw_data.py b/build/lib/build/lib/ptycho/raw_data.py
deleted file mode 100644
index 16131a2..0000000
--- a/build/lib/build/lib/ptycho/raw_data.py
+++ /dev/null
@@ -1,474 +0,0 @@
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional
-from scipy.spatial import cKDTree
-from ptycho import params
-from ptycho.autotest.debug import debug
-from ptycho import diffsim as datasets
-from ptycho import tf_helper as hh
-
-# Constants, # TODO cleanup / refactor
-local_offset_sign = 1
-key_coords_offsets = 'coords_start_offsets'
-key_coords_relative = 'coords_start_relative'
-
-class RawData:
-    #@debug
-    def __init__(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess,
-             scan_index, objectGuess = None, Y = None, norm_Y_I = None):
-        # Sanity checks
-        self._check_data_validity(xcoords, ycoords, xcoords_start, ycoords_start, diff3d,
-                    probeGuess, scan_index)
-
-        # TODO these should go in the data validation method
-        assert len(xcoords.shape) == 1, f"Expected xcoords to be 1D, got shape {xcoords.shape}"
-        assert len(ycoords.shape) == 1, f"Expected ycoords to be 1D, got shape {ycoords.shape}"
-        assert len(xcoords_start.shape) == 1, f"Expected xcoords_start to be 1D, got shape {xcoords_start.shape}"
-        assert len(ycoords_start.shape) == 1, f"Expected ycoords_start to be 1D, got shape {ycoords_start.shape}"
-        if diff3d is not None:
-            assert len(diff3d.shape) == 3, f"Expected diff3d to be 3D, got shape {diff3d.shape}"
-            print(f"diff3d shape: {diff3d.shape}")
-            assert diff3d.shape[1] == diff3d.shape[2]
-        if probeGuess is not None:
-            assert len(probeGuess.shape) == 2, f"Expected probeGuess to be 2D, got shape {probeGuess.shape}"
-            print(f"probeGuess shape: {probeGuess.shape}")
-        if scan_index is not None:
-            assert len(scan_index.shape) == 1, f"Expected scan_index to be 1D, got shape {scan_index.shape}"
-            print(f"scan_index shape: {scan_index.shape}")
-        if objectGuess is not None:
-            print(f"objectGuess shape: {objectGuess.shape}")
-            assert len(objectGuess.shape) == 2
-
-        print(f"xcoords shape: {xcoords.shape}")
-        print(f"ycoords shape: {ycoords.shape}")
-        print(f"xcoords_start shape: {xcoords_start.shape}")
-        print(f"ycoords_start shape: {ycoords_start.shape}")
-
-        # Assigning values if checks pass
-        self.xcoords = xcoords
-        self.ycoords = ycoords
-        self.xcoords_start = xcoords_start
-        self.ycoords_start = ycoords_start
-        self.diff3d = diff3d
-        self.probeGuess = probeGuess
-        self.scan_index = scan_index
-        self.objectGuess = objectGuess
-        # TODO validity checks
-        self.Y = Y
-        self.norm_Y_I = norm_Y_I
-
-    @staticmethod
-    #@debug
-    def from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index,
-                               objectGuess=None):
-        """
-        Static method to create a RawData instance without separate start coordinates.
-        The start coordinates are set to be the same as the xcoords and ycoords.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        return RawData(xcoords, ycoords, xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-
-    @staticmethod
-    def from_simulation(xcoords, ycoords, probeGuess,
-                 objectGuess, scan_index = None):
-        """
-        Create a RawData instance from simulation data.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            objectGuess (np.ndarray): initial guess of the object.
-            scan_index (np.ndarray, optional): array indicating the scan index for each diffraction pattern.
-
-        Returns:
-            RawData: An instance of the RawData class with simulated data.
-        """
-        from ptycho.diffsim import illuminate_and_diffract
-        xcoords_start = xcoords
-        ycoords_start = ycoords
-        global_offsets, local_offsets, nn_indices = calculate_relative_coords(
-                    xcoords, ycoords)
-
-        Y_obj = get_image_patches(objectGuess, global_offsets, local_offsets) 
-        Y_I = tf.math.abs(Y_obj)
-        Y_phi = tf.math.angle(Y_obj)
-        X, Y_I_xprobe, Y_phi_xprobe, intensity_scale = illuminate_and_diffract(Y_I, Y_phi, probeGuess)
-        norm_Y_I = datasets.scale_nphotons(X)
-        assert X.shape[-1] == 1, "gridsize must be set to one when simulating in this mode"
-        # TODO RawData should have a method for generating the illuminated ground truth object
-        return RawData(xcoords, ycoords, xcoords_start, ycoords_start, tf.squeeze(X).numpy(),
-                       probeGuess, scan_index, objectGuess,
-                       Y = tf.squeeze(hh.combine_complex( Y_I_xprobe, Y_phi_xprobe)).numpy(),
-                       norm_Y_I = norm_Y_I)
-
-    #@debug
-    def __str__(self):
-        parts = [
-            "RawData:",
-            f"  xcoords: {self.xcoords.shape if self.xcoords is not None else 'None'}",
-            f"  ycoords: {self.ycoords.shape if self.ycoords is not None else 'None'}",
-            f"  xcoords_start: {self.xcoords_start.shape if self.xcoords_start is not None else 'None'}",
-            f"  ycoords_start: {self.ycoords_start.shape if self.ycoords_start is not None else 'None'}",
-            f"  diff3d: {self.diff3d.shape if self.diff3d is not None else 'None'}",
-            f"  probeGuess: {self.probeGuess.shape if self.probeGuess is not None else 'None'}",
-            f"  scan_index: {self.scan_index.shape if self.scan_index is not None else 'None'}",
-            f"  objectGuess: {self.objectGuess.shape if self.objectGuess is not None else 'None'}"
-        ]
-        return "\n".join(parts)
-
-    #@debug
-    def to_file(self, file_path: str) -> None:
-        """
-        Method to write the RawData object to a file using numpy.savez.
-
-        Args:
-            file_path (str): Path to the file where the data will be saved.
-        """
-        np.savez(file_path,
-                 xcoords=self.xcoords,
-                 ycoords=self.ycoords,
-                 xcoords_start=self.xcoords_start,
-                 ycoords_start=self.ycoords_start,
-                 diff3d=self.diff3d,
-                 probeGuess=self.probeGuess,
-                 objectGuess=self.objectGuess,
-                 scan_index=self.scan_index)
-
-    @staticmethod
-    #@debug
-    def from_file(train_data_file_path: str) -> 'RawData':
-        """
-        Static method to create a RawData instance from a file.
-
-        Args:
-            train_data_file_path (str): Path to the file containing the data.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        # Load training data
-        train_data = np.load(train_data_file_path)
-        train_raw_data = RawData(
-            xcoords=train_data['xcoords'],
-            ycoords=train_data['ycoords'],
-            xcoords_start=train_data['xcoords_start'],
-            ycoords_start=train_data['ycoords_start'],
-            diff3d=train_data['diff3d'],
-            probeGuess=train_data['probeGuess'],
-            objectGuess=train_data['objectGuess'],
-            scan_index=train_data['scan_index']
-        )
-        return train_raw_data
-
-    @staticmethod
-    #@debug
-    def from_files(train_data_file_path, test_data_file_path):
-        """
-        Static method to instantiate RawData objects from training and test data files.
-
-        The data files should be NumPy .npz files with the following keys:
-        - 'xcoords': x coordinates of the scan points
-        - 'ycoords': y coordinates of the scan points
-        - 'xcoords_start': starting x coordinates for the scan
-        - 'ycoords_start': starting y coordinates for the scan
-        - 'diff3d': diffraction patterns
-        - 'probeGuess': initial guess of the probe function
-        - 'scan_index': array indicating the scan index for each diffraction pattern
-
-        Args:
-            train_data_file_path (str): Path to the training data file.
-            test_data_file_path (str): Path to the test data file.
-
-        Returns:
-            tuple: A tuple containing the instantiated RawData objects for training and test data.
-        """
-        # Load training data
-        train_raw_data = RawData.from_file(train_data_file_path)
-
-        # Load test data
-        test_raw_data = RawData.from_file(test_data_file_path)
-
-        return train_raw_data, test_raw_data
-
-    #@debug
-    def generate_grouped_data(self, N, K = 7, nsamples = 1):
-        """
-        Generate nearest-neighbor solution region grouping.
-
-        Args:
-            N (int): Size of the solution region.
-            K (int, optional): Number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): Number of samples. Defaults to 1.
-
-        Returns:
-            dict: Dictionary containing grouped data.
-        """
-        print('DEBUG:', 'nsamples:', nsamples)
-        return get_neighbor_diffraction_and_positions(self, N, K=K, nsamples=nsamples)
-
-    #@debug
-    def _check_data_validity(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-        """
-        Check if the input data is valid.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            xcoords_start (np.ndarray): starting x coordinates for the scan.
-            ycoords_start (np.ndarray): starting y coordinates for the scan.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-
-        Raises:
-            ValueError: If coordinate arrays don't have matching shapes.
-        """
-        # Check if coordinate arrays have matching shapes
-        if not (xcoords.shape == ycoords.shape == xcoords_start.shape == ycoords_start.shape):
-            raise ValueError("Coordinate arrays must have matching shapes.")
-
-#@debug
-def calculate_relative_coords(xcoords, ycoords, K = 6, C = None, nsamples = 10):
-    """
-    Group scan indices and coordinates into solution regions, then
-    calculate coords_offsets (global solution region coordinates) and
-    coords_relative (local solution patch coords) from ptycho_data using
-    the provided index_grouping_cb callback function.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        tuple: A tuple containing coords_offsets, coords_relative, and nn_indices.
-    """
-    nn_indices, coords_nn = group_coords(xcoords, ycoords, K = K, C = C, nsamples = nsamples)
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-    return coords_offsets, coords_relative, nn_indices
-
-#@debug
-def get_image_patches(gt_image, global_offsets, local_offsets):
-    """
-    Generate and return image patches in channel format using a single canvas.
-
-    Args:
-        gt_image (tensor): Ground truth image tensor.
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Image patches in channel format.
-    """
-    # Get necessary parameters
-    gridsize = params.get('gridsize')
-    N = params.get('N')
-    B = global_offsets.shape[0]
-    c = gridsize**2
-
-    # Pad the ground truth image once
-    gt_padded = hh.pad(gt_image[None, ..., None], N // 2)
-
-    # Calculate the combined offsets by adding global and local offsets
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    offsets_f = hh._channel_to_flat(offsets_c)
-
-    # Create a canvas to store the extracted patches
-    canvas = np.zeros((B, N, N, c))
-
-    # Iterate over the combined offsets and extract patches one by one
-    for i in range(B * c):
-        offset = -offsets_f[i, :, :, 0]
-        translated_patch = hh.translate(gt_padded, offset)
-        canvas[i // c, :, :, i % c] = np.array(translated_patch)[0, :N, :N, 0]
-
-    # Convert the canvas to a TensorFlow tensor and return it
-    return tf.convert_to_tensor(canvas)
-
-#@debug
-def group_coords(xcoords: np.ndarray, ycoords: np.ndarray, K: int, C: Optional[int], nsamples: int) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int): Number of nearest neighbors to consider.
-        C (Optional[int]): Number of coordinates per solution region. If None, uses gridsize^2.
-        nsamples (int): Number of samples to generate.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray]: A tuple containing:
-            - nn_indices: shape (M, C)
-            - coords_nn: shape (M, 1, 2, C)
-    """
-    gridsize = params.get('gridsize')
-    if C is None:
-        C = gridsize**2
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords, ycoords)
-    else:
-        nn_indices = get_neighbor_indices(xcoords, ycoords, K=K)
-        nn_indices = sample_rows(nn_indices, C, nsamples).reshape(-1, C)
-
-    coords_nn = np.transpose(np.array([xcoords[nn_indices],
-                            ycoords[nn_indices]]),
-                            [1, 0, 2])[:, None, :, :]
-    return nn_indices, coords_nn[:, :, :, :]
-
-#@debug
-def get_relative_coords(coords_nn):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, 1, 2, C).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    assert len(coords_nn.shape) == 4
-    coords_offsets = np.mean(coords_nn, axis=3)[..., None]
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-    return coords_offsets, coords_relative
-
-#@debug
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    Assign each pattern index to itself.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-
-    Returns:
-        np.ndarray: Array of self-indices.
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-#@debug
-def get_neighbor_indices(xcoords, ycoords, K = 3):
-    """
-    Get K nearest neighbor indices for each point.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors to find. Defaults to 3.
-
-    Returns:
-        np.ndarray: Array of nearest neighbor indices.
-    """
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-#@debug
-def sample_rows(indices, n, m):
-    """
-    Sample rows from the given indices.
-
-    Args:
-        indices (np.ndarray): Array of indices to sample from.
-        n (int): Number of samples per row.
-        m (int): Number of rows to generate.
-
-    Returns:
-        np.ndarray: Sampled indices array.
-    """
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-#@debug
-def get_neighbor_diffraction_and_positions(ptycho_data, N, K=6, C=None, nsamples=10):
-    """
-    Get neighbor diffraction patterns and positions.
-
-    Args:
-        ptycho_data (RawData): An instance of the RawData class.
-        N (int): Size of the solution region.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        dict: A dictionary containing grouped data and metadata.
-    """
-    nn_indices, coords_nn = group_coords(ptycho_data.xcoords, ptycho_data.ycoords,
-                                         K = K, C = C, nsamples = nsamples)
-
-    diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-    if ptycho_data.Y is not None:
-        Y4d_nn = np.transpose(ptycho_data.Y[nn_indices], [0, 2, 3, 1])
-    else:
-        Y4d_nn = None
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if ptycho_data.xcoords_start is not None:
-        coords_start_nn = np.transpose(np.array([ptycho_data.xcoords_start[nn_indices], ptycho_data.ycoords_start[nn_indices]]),
-                                       [1, 0, 2])[:, None, :, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'Y': Y4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    """
-    Normalize the diffraction data.
-
-    Args:
-        dset (dict): Dictionary containing the dataset.
-        N (int): Size of the solution region.
-
-    Returns:
-        np.ndarray: Normalized diffraction data.
-    """
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    return X_full_norm * X_full
-
diff --git a/build/lib/build/lib/ptycho/test_memoize_simulated_data.py b/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
deleted file mode 100644
index e283054..0000000
--- a/build/lib/build/lib/ptycho/test_memoize_simulated_data.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import numpy as np
-from ptycho.nongrid_simulation import generate_simulated_data
-from ptycho.loader import RawData
-import os
-import shutil
-
-def test_memoize_simulated_data():
-    # Create sample input data
-    objectGuess = np.random.rand(128, 128) + 1j * np.random.rand(128, 128)
-    probeGuess = np.random.rand(32, 32) + 1j * np.random.rand(32, 32)
-    nimages = 100
-    buffer = 10
-    random_seed = 42
-
-    # Clear the cache directory before starting the test
-    cache_dir = 'memoized_simulated_data'
-    if os.path.exists(cache_dir):
-        shutil.rmtree(cache_dir)
-
-    # First call, should compute the result and cache it
-    result1 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result1, tuple), "Result should be a tuple"
-    assert len(result1) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result1[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result1[1], np.ndarray), "Second element should be a numpy array"
-
-    # Second call, should load the result from the cache
-    result2 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result2, tuple), "Result should be a tuple"
-    assert len(result2) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result2[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result2[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are identical
-    assert np.array_equal(result1[0].diff3d, result2[0].diff3d), "Cached result differs from original"
-    assert np.array_equal(result1[1], result2[1]), "Cached patches differ from original"
-
-    # Third call with different random seed, should compute a new result
-    result3 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed=123)
-    assert isinstance(result3, tuple), "Result should be a tuple"
-    assert len(result3) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result3[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result3[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are different
-    assert not np.array_equal(result1[0].diff3d, result3[0].diff3d), "Results with different seeds should differ"
-
-    print("All tests passed successfully!")
-
-if __name__ == "__main__":
-    test_memoize_simulated_data()
diff --git a/build/lib/build/lib/ptycho/tests/test_model_manager.py b/build/lib/build/lib/ptycho/tests/test_model_manager.py
deleted file mode 100644
index e56140a..0000000
--- a/build/lib/build/lib/ptycho/tests/test_model_manager.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from tensorflow.keras.models import Sequential
-from tensorflow.keras.layers import Dense
-from ptycho.model_manager import ModelManager
-
-def test_save_and_load_model():
-    # Create a simple model for testing
-    model = Sequential([
-        Dense(64, activation='relu', input_shape=(32,)),
-        Dense(10, activation='softmax')
-    ])
-    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
-
-    # Define custom objects and intensity scale for testing
-    custom_objects = {'custom_activation': tf.nn.relu}
-    intensity_scale = 2.5
-
-    # Save the model
-    model_path = 'test_model.h5'
-    ModelManager.save_model(model, model_path, custom_objects, intensity_scale)
-
-    # Ensure the .dill file is created
-    assert os.path.exists(model_path + ".dill")
-
-    # Load the model
-    loaded_model = ModelManager.load_model(model_path)
-
-    # Check if the loaded model has the same architecture
-    assert np.array_equal(model.get_weights()[0], loaded_model.get_weights()[0])
-
-    # Clean up
-    os.remove(model_path)
-    os.remove(model_path + ".dill")
diff --git a/build/lib/build/lib/ptycho/tf_helper.py b/build/lib/build/lib/ptycho/tf_helper.py
deleted file mode 100644
index fc1233f..0000000
--- a/build/lib/build/lib/ptycho/tf_helper.py
+++ /dev/null
@@ -1,707 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional, Union, Callable, Any
-
-# Check if there are any GPUs available and set memory growth accordingly
-physical_devices = tf.config.list_physical_devices('GPU')
-if physical_devices:
-    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
-    tf.config.experimental.set_memory_growth(physical_devices[0], True)
-else:
-    print("No GPU found, using CPU instead.")
-
-
-import tensorflow.compat.v2 as tf
-tf.enable_v2_behavior()
-
-from tensorflow.keras import Model
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, UpSampling2D
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import tensorflow_probability as tfp
-
-from .params import params, cfg, get, get_padded_size
-#from .logging import debug
-from .autotest.debug import debug
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-support_threshold = .0
-#@debug
-def get_mask(input: tf.Tensor, support_threshold: float) -> tf.Tensor:
-    mask = tf.where(input > support_threshold, tf.ones_like(input),
-                    tf.zeros_like(input))
-    return mask
-
-#@debug
-def combine_complex(amp: tf.Tensor, phi: tf.Tensor) -> tf.Tensor:
-    output = tf.cast(amp, tf.complex64) * tf.exp(
-        1j * tf.cast(phi, tf.complex64))
-    return output
-
-#@debug
-def pad_obj(input: tf.Tensor, h: int, w: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((h // 4, w // 4), name = 'padded_obj')(input)
-
-#@debug
-def pad_and_diffract(input: tf.Tensor, h: int, w: int, pad: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses sysmmetric FT - L2 norm is conserved
-    """
-    input = tf.ensure_shape(input, (None, h, w, 1))
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = (((fft2d(
-        (tf.cast((input), tf.complex64))[..., 0]
-        ))))
-    input = (( tf.math.real(tf.math.conj((input)) * input) / (h * w)))
-    input = (( tf.expand_dims(
-                              tf.math.sqrt(
-            fftshift(input, (-2, -1))), 3)
-        ))
-    return padded, input
-
-#@debug
-def _fromgrid(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return tf.reshape(img, (-1, N, N, 1))
-
-#@debug
-def _togrid(img: tf.Tensor, gridsize: Optional[int] = None, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e. from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return tf.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-#@debug
-def togrid(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return [_togrid(img) for img in imgs]
-
-#@debug
-def _grid_to_channel(grid: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = tf.transpose(grid, [0, 3, 4, 1, 2, 5], conjugate=False)
-    _, ww, hh = img.shape[:3]
-    img = tf.reshape(img, (-1, ww, hh, gridsize**2))
-    return img
-
-#@debug
-def grid_to_channel(*grids: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_grid_to_channel(g) for g in grids]
-
-#@debug
-def _flat_to_channel(img: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = tf.reshape(img, (-1, gridsize**2, N, N))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _flat_to_channel_2(img: tf.Tensor) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = tf.reshape(img, (-1, gridsize**2, N, M))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-#@debug
-def _channel_to_flat(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    shape = tf.shape(img)
-    b, h, w, c = shape[0], shape[1], shape[2], shape[3]
-    #_, h, w, c = img.shape
-    img = tf.transpose(img, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, h, w, 1))
-    return img
-
-#@debug
-def _channel_to_patches(channel: tf.Tensor) -> tf.Tensor:
-    """
-    reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = tf.transpose(channel, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-#@debug
-def channel_to_flat(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_channel_to_flat(g) for g in imgs]
-
-#@debug
-def extract_patches(x: tf.Tensor, N: int, offset: int) -> tf.Tensor:
-    return tf.image.extract_patches(
-        x,
-        [1, N, N, 1],
-        [1, offset,offset, 1],
-        [1, 1, 1, 1],
-        padding="VALID"
-    )
-
-#@debug
-def extract_outer(img: tf.Tensor, fmt: str = 'grid',
-        bigN: Optional[int] = None, outer_offset: Optional[int] = None) -> tf.Tensor:#,
-    """
-        Extract big patches (overlapping bigN x bigN regions over an
-        entire input img)
-    """
-    if bigN is None:
-        bigN = get('bigN')
-    assert img.shape[-1] == 1
-    grid = tf.reshape(
-        extract_patches(img, bigN, outer_offset // 2),
-        (-1, bigN, bigN, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)
-    else:
-        raise ValueError
-
-#@debug
-def extract_inner_grid(grid: tf.Tensor) -> tf.Tensor:
-    N = cfg['N']
-    offset = params()['offset']
-    return extract_patches(grid, N, offset)
-
-#@debug
-def extract_nested_patches(img: tf.Tensor, fmt: str = 'flat',
-        extract_inner_fn: Callable[[tf.Tensor], tf.Tensor] = extract_inner_grid,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-
-    This function and extract_outer are only used to extract nominal
-    coordinates, so it is not necessary for them to use jitter padding
-    """
-    N = cfg['N']
-    offset = params()['offset']
-    gridsize = params()['gridsize']
-    assert img.shape[-1] == 1
-    outer_grid = extract_outer(img, fmt = 'grid', **kwargs)
-    grid = tf.reshape(
-        extract_inner_fn(outer_grid),
-        (-1, gridsize, gridsize, N, N, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)#, outer_grid # TODO second output is for debugging
-    else:
-        raise ValueError
-
-#@debug
-def mk_extract_inner_position(offsets_xy: tf.Tensor) -> Callable[[tf.Tensor], Tuple[tf.Tensor]]:
-    #@debug
-    def inner(grid: tf.Tensor) -> Tuple[tf.Tensor]:
-        return extract_patches_position(grid, offsets_xy),
-    return inner
-
-#@debug
-def extract_nested_patches_position(img: tf.Tensor, offsets_xy: tf.Tensor, fmt: str = 'flat',
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-    """
-    return extract_nested_patches(img, fmt = fmt,
-        extract_inner_fn = mk_extract_inner_position(offsets_xy),
-        **kwargs)
-
-@tf.function
-#@debug
-def extract_patches_inverse(y: tf.Tensor, N: int, average: bool, gridsize: Optional[int] = None, offset: Optional[int] = None) -> tf.Tensor:
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if offset is None:
-        offset = params()['offset']
-    target_size = N + (gridsize - 1) * offset
-    b = tf.shape(y)[0]
-
-    _x = tf.zeros((b, target_size, target_size, 1), dtype = y.dtype)
-    _y = extract_patches(_x, N, offset)
-    if average:
-        grad = tf.gradients(_y, _x)[0]
-        return tf.gradients(_y, _x, grad_ys=y)[0] / grad
-    else:
-        return tf.gradients(_y, _x, grad_ys=y)[0]
-
-#@debug
-def reassemble_patches_real(channels: tf.Tensor, average: bool = True, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = _channel_to_patches(channels)
-    N = params()['N']
-    return extract_patches_inverse(real, N, average, **kwargs)
-
-#@debug
-def pad_patches(imgs: tf.Tensor, padded_size: Optional[int] = None) -> tf.Tensor:
-    N = params()['N']
-    if padded_size is None:
-        padded_size = get_padded_size()
-    return tfkl.ZeroPadding2D(((padded_size - N) // 2, (padded_size - N) // 2))(imgs)
-
-#@debug
-def pad(imgs: tf.Tensor, size: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((size, size))(imgs)
-
-#@debug
-def trim_reconstruction(x: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert int(shape[1]) == int(shape[2])
-    try:
-        clipsize = (int(shape[1]) - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize: -clipsize,
-            clipsize: -clipsize, :]
-
-#@debug
-def extract_patches_position(imgs: tf.Tensor, offsets_xy: tf.Tensor, jitter: float = 0.) -> tf.Tensor:
-    """
-    Expects offsets_xy in channel format.
-
-    imgs must be in flat format with a single image per solution region, i.e.
-    (batch size, M, M, 1) where M = N + some padding size.
-
-    Returns shifted images in channel format, cropped symmetrically
-
-    no negative sign
-    """
-    if  imgs.get_shape()[0] is not None:
-        assert int(imgs.get_shape()[0]) == int(offsets_xy.get_shape()[0])
-    assert int(imgs.get_shape()[3]) == 1
-    assert int(offsets_xy.get_shape()[2]) == 2
-    assert int(imgs.get_shape()[3]) == 1
-    gridsize = params()['gridsize']
-    assert int(offsets_xy.get_shape()[3]) == gridsize**2
-    offsets_flat = flatten_offsets(offsets_xy)
-    stacked = tf.repeat(imgs, gridsize**2, axis = 3)
-    flat_padded = _channel_to_flat(stacked)
-    channels_translated = trim_reconstruction(
-        Translation()([flat_padded, offsets_flat, jitter]))
-    return channels_translated
-
-#@debug
-def center_channels(channels: tf.Tensor, offsets_xy: tf.Tensor) -> tf.Tensor:
-    """
-    Undo image patch offsets
-    """
-    ct = Translation()([_channel_to_flat(channels), flatten_offsets(-offsets_xy), 0.])
-    channels_centered = _flat_to_channel(ct)
-    return channels_centered
-
-#@debug
-def is_complex_tensor(tensor: tf.Tensor) -> bool:
-    """Check if the tensor is of complex dtype."""
-    return tensor.dtype in [tf.complex64, tf.complex128]
-
-#@debug
-def complexify_helper(separate: Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]], combine: Callable[[tf.Tensor, tf.Tensor], tf.Tensor]) -> Callable:
-    """
-    Create a "complexify" function based on the provided separation and combination methods.
-    """
-    #@debug
-    def complexify(fn: Callable[..., tf.Tensor]) -> Callable[..., tf.Tensor]:
-        #@debug
-        def newf(*args: Any, **kwargs: Any) -> tf.Tensor:
-            channels = args[0]
-            if is_complex_tensor(channels):
-                part1, part2 = separate(channels)
-                assembled_part1 = fn(part1, *args[1:], **kwargs)
-                assembled_part2 = fn(part2, *args[1:], **kwargs)
-                return combine(assembled_part1, assembled_part2)
-            else:
-                return fn(*args, **kwargs)
-        return newf
-    return complexify
-
-#@debug
-def separate_real_imag(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.real(channels), tf.math.imag(channels)
-
-#@debug
-def combine_real_imag(real: Union[tf.Tensor, np.ndarray], imag: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:
-    return tf.cast(tf.dtypes.complex(real, imag), tf.complex64)
-
-#@debug
-def separate_amp_phase(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.abs(channels), tf.math.angle(channels)
-
-complexify_function = complexify_helper(separate_real_imag, combine_real_imag)
-complexify_amp_phase = complexify_helper(separate_amp_phase, combine_complex)
-complexify_sum_amp_phase = complexify_helper(separate_amp_phase, lambda a, b: a + b)
-complexify_sum_real_imag = complexify_helper(separate_real_imag, lambda a, b: a + b)
-
-
-from tensorflow_addons.image import translate as _translate
-
-#from ptycho.misc import debug
-@complexify_function
-#@debug
-def translate(imgs: tf.Tensor, offsets: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    # TODO assert dimensionality of translations is 2; i.e. B, 2
-    return _translate(imgs, offsets, **kwargs)
-
-# TODO consolidate this and translate()
-class Translation(tf.keras.layers.Layer):
-    def __init__(self) -> None:
-        super(Translation, self).__init__()
-    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor, float]) -> tf.Tensor:
-        imgs, offsets, jitter = inputs
-        jitter = tf.random.normal(tf.shape(offsets), stddev = jitter)
-        return translate(imgs, offsets + jitter, interpolation = 'bilinear')
-
-#@debug
-def flatten_offsets(channels: tf.Tensor) -> tf.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-#@debug
-def pad_reconstruction(channels: tf.Tensor) -> tf.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-#@debug
-def _reassemble_patches_position_real(imgs: tf.Tensor, offsets_xy: tf.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, 0.])
-    if agg:
-        imgs_merged = tf.reduce_sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N = padded_size),
-                    axis = 3)[..., None]
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N = padded_size)
-
-#@debug
-def mk_centermask(inputs: tf.Tensor, N: int, c: int, kind: str = 'center') -> tf.Tensor:
-    b = tf.shape(inputs)[0]
-#    if get('probe.big'):
-#        ones = tf.ones((b, N, N, c), dtype = inputs.dtype)
-#    else:
-#        ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-#        ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-    ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-#@debug
-def mk_norm(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor]) -> tf.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    # TODO if probe.big is True, shouldn't the ones fill the full N x N region?
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average = False)
-    norm = assembled_ones + .001
-    return norm
-
-#@debug
-def reassemble_patches(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = tf.math.real(channels)
-    imag = tf.math.imag(channels)
-    assembled_real = fn_reassemble_real(real, average = average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average = average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return tf.dtypes.complex(assembled_real, assembled_imag)
-
-#@debug
-def shift_and_sum(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    from . import tf_helper as hh
-    assert len(obj_tensor.shape) == 4
-    assert obj_tensor.dtype == np.complex64
-    assert len(global_offsets.shape) == 4
-    assert global_offsets.dtype == np.float64
-    # Extract necessary parameters
-    N = params()['N']
-    # Select the central part of the object tensor
-    obj_tensor = obj_tensor[:, N // 2 - M // 2: N // 2 + M // 2, N // 2 - M // 2: N // 2 + M // 2, :]
-    # Calculate the center of mass of global_offsets
-    center_of_mass = tf.reduce_mean(tf.cast(global_offsets, tf.float32), axis=0)
-    # Adjust global_offsets by subtracting the center of mass
-    adjusted_offsets = tf.cast(global_offsets, tf.float32) - center_of_mass
-    # Calculate dynamic padding based on maximum adjusted offset
-    max_offset = tf.reduce_max(tf.abs(adjusted_offsets))
-    dynamic_pad = int(tf.cast(tf.math.ceil(max_offset), tf.int32))
-    print('PADDING SIZE:', dynamic_pad)
-    
-    # Create a canvas to store the shifted and summed object tensors
-    result = tf.zeros_like(hh.pad(obj_tensor[0:1], dynamic_pad))
-    
-    # Iterate over the adjusted offsets and perform shift-and-sum
-    for i in range(len(adjusted_offsets)):
-        # Apply dynamic padding to the current object tensor
-        padded_obj_tensor = hh.pad(obj_tensor[i:i+1], dynamic_pad)
-        # Squeeze and cast adjusted offset to 2D float for translation
-        offset_2d = tf.cast(tf.squeeze(adjusted_offsets[i]), tf.float32)
-        # Translate the padded object tensor
-        translated_obj = hh.translate(padded_obj_tensor, offset_2d, interpolation='bilinear')
-        # Accumulate the translated object tensor
-        result += translated_obj[0]
-    
-    # TODO: how could we support multiple scans?
-    return result[0]
-
-#@debug
-def reassemble_whole_object(patches: tf.Tensor, offsets: tf.Tensor, size: int = 226, norm: bool = False) -> tf.Tensor:
-    """
-    patches: tensor of shape (B, N, N, gridsize**2) containing reconstruction patches
-
-    reassembles the NxN patches into a single size x size x 1 mage, given the
-        provided offsets
-
-    This function inverts the offsets, so it's not necessary to multiply by -1
-    """
-    img = tf.reduce_sum(
-        reassemble_patches(patches, fn_reassemble_real=mk_reassemble_position_real(
-        offsets, padded_size = size)),
-        axis = 0)
-    if norm:
-        return img / reassemble_whole_object(tf.ones_like(patches), offsets, size = size, norm = False)
-    return img
-
-def reassemble_position(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    ones = tf.ones_like(obj_tensor)
-    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
-        (1e-9 + shift_and_sum(ones, global_offsets, M = M))
-
-#@debug
-def mk_reassemble_position_real(input_positions: tf.Tensor, **outer_kwargs: Any) -> Callable[[tf.Tensor], tf.Tensor]:
-    #@debug
-    def reassemble_patches_position_real(imgs: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-#@debug
-def preprocess_objects(Y_I: np.ndarray, Y_phi: Optional[np.ndarray] = None,
-        offsets_xy: Optional[tf.Tensor] = None, **kwargs: Any) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
-    """
-    Extracts normalized object patches from full real-space images, using the
-    nested grid format.
-    """
-    _Y_I_full = Y_I
-    if Y_phi is None:
-        Y_phi = np.zeros_like(Y_I)
-
-    if offsets_xy is None or tf.math.reduce_all(offsets_xy == 0):
-        print('Sampling on regular grid')
-        Y_I, Y_phi = \
-            [extract_nested_patches(imgs, fmt= 'channel', **kwargs)
-                for imgs in [Y_I, Y_phi]]
-    else:
-        print('Using provided scan point offsets')
-        Y_I, Y_phi = \
-            [extract_nested_patches_position(imgs, offsets_xy, fmt= 'channel',
-                    **kwargs)
-                for imgs in [Y_I, Y_phi]]
-
-    assert Y_I.shape[-1] == get('gridsize')**2
-    norm_Y_I = tf.math.reduce_max(Y_I, axis = (1, 2, 3))[:, None, None, None]
-    norm_Y_I = tf.math.reduce_mean(norm_Y_I)
-    Y_I /= norm_Y_I
-
-    Y_I, Y_phi =\
-        channel_to_flat(Y_I, Y_phi)
-    return Y_I, Y_phi, _Y_I_full / norm_Y_I, norm_Y_I
-
-#@debug
-def reassemble_nested_average(output_tensor: tf.Tensor, cropN: Optional[int] = None, M: Optional[int] = None, n_imgs: int = 1,
-        offset: int = 4) -> tf.Tensor:
-    """
-    Stitch reconstruction patches from (first) model output into full
-    reconstructed images, averaging the overlaps
-    """
-    assert len(output_tensor.shape) == 4
-    bsize = int(output_tensor.shape[0] / n_imgs)
-    output_tensor = output_tensor[:bsize, ...]
-    if M is None:
-        M = int(np.sqrt(bsize))
-    if cropN is None:
-        cropN = params.params()['cropN']
-    patches = _togrid(trim_reconstruction(output_tensor, cropN), gridsize = M,
-        N = cropN)
-    patches = tf.reshape(patches, (-1, M, M, cropN**2))
-    obj_recon = complexify_function(extract_patches_inverse)(patches, cropN,
-        True, gridsize = M, offset = offset)
-    return obj_recon
-
-
-#@debug
-def gram_matrix(input_tensor: tf.Tensor) -> tf.Tensor:
-    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
-    input_shape = tf.shape(input_tensor)
-    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
-    return result/(num_locations)
-
-#@debug
-def high_pass_x_y(image: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
-    x_var = image[:,:,1:,:] - image[:,:,:-1,:]
-    y_var = image[:,1:,:,:] - image[:,:-1,:,:]
-    return x_var, y_var
-
-pp = tfk.Sequential([
-    Lambda(lambda x: tf.image.grayscale_to_rgb(x)),
-])
-#@debug
-def perceptual_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    """
-    target = pp(target)
-    pred = pp(pred)
-
-    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-    vgg.trainable = False
-
-    outputs = [vgg.get_layer('block2_conv2').output]
-    feat_model = Model(vgg.input, outputs)
-    activatedModelVal = feat_model(pred)
-    actualModelVal = feat_model(target)
-    return meanSquaredLoss(gram_matrix(actualModelVal),gram_matrix(activatedModelVal))
-
-#@debug
-def meanSquaredLoss(y_true: tf.Tensor, y_pred: tf.Tensor, center_target: bool = True) -> tf.Tensor:
-    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))
-
-#@debug
-def masked_MAE_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    bigN
-    """
-    mae = tf.keras.metrics.mean_absolute_error
-    mask = params()['probe_mask']
-    pred = trim_reconstruction(
-            reassemble_patches(mask * pred))
-    target = trim_reconstruction(
-            reassemble_patches(tf.math.abs(mask) * target))
-    return mae(target, pred)
-
-
-@complexify_sum_real_imag
-#@debug
-def total_variation_complex(obj: tf.Tensor) -> tf.Tensor:
-    """ calculate summed total variation of the real and imaginary components
-        of a tensor
-    """
-    x_deltas, y_deltas = high_pass_x_y(obj)
-    return tf.reduce_sum(x_deltas**2) + tf.reduce_sum(y_deltas**2)
-
-#@debug
-def total_variation(obj: tf.Tensor, amp_only: bool = False) -> tf.Tensor:
-    if amp_only:
-        obj = Lambda(lambda x: tf.math.abs(x))(obj)
-    return total_variation_complex(obj)
-
-@complexify_sum_amp_phase
-#@debug
-def complex_mae(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    mae = tf.keras.metrics.mean_absolute_error
-    return mae(target, pred)
-
-#@debug
-def masked_mae(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    mae = tf.keras.metrics.mean_absolute_error
-    pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-    return mae(target, pred)
-
-#@debug
-def realspace_loss(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    N = params()['N']
-    if not get('probe.big'):
-        pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-
-    if get('tv_weight') > 0:
-        tv_loss = total_variation(pred) * get('tv_weight')
-    else:
-        tv_loss = 0.
-
-    if get('realspace_mae_weight') > 0:
-        mae_loss = complex_mae(target, pred) * get('realspace_mae_weight')
-    else:
-        mae_loss = 0.
-    return tv_loss + mae_loss
diff --git a/build/lib/build/lib/ptycho/train.py b/build/lib/build/lib/ptycho/train.py
deleted file mode 100644
index 7f93781..0000000
--- a/build/lib/build/lib/ptycho/train.py
+++ /dev/null
@@ -1,121 +0,0 @@
-# train.py
-
-import os
-from ptycho.model_manager import ModelManager
-from ptycho import model_manager
-from ptycho.export import save_recons
-from datetime import datetime
-import matplotlib
-import matplotlib.pyplot as plt
-import dill
-import argparse
-from ptycho import params
-from ptycho import misc
-import numpy as np
-import h5py
-
-plt.rcParams["figure.figsize"] = (10, 10)
-matplotlib.rcParams['font.size'] = 12
-
-save_model = True
-save_data = False
-
-parser = argparse.ArgumentParser(description='Script to set attributes for ptycho program')
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(
-                        prog = 'PtychoPINN',
-                        description = 'Generate / load data and train the model',
-                        )
-    parser.add_argument('--model_type', type=str, default='pinn', help='model type (pinn or supervised)')
-    parser.add_argument('--output_prefix', type=str, default='lines2', help='output directory prefix')
-    parser.add_argument('--data_source', type=str, default='lines', help='Dataset specification')
-    parser.add_argument('--set_phi', action='store_true', default=False, help='If true, simulated objects are given non-zero phase')
-    parser.add_argument('--nepochs', type=int, default=60, help='Number of epochs')
-    parser.add_argument('--offset', type=int, default=4, help='Scan point spacing for simulated (grid-sampled) data')
-    parser.add_argument('--gridsize', type=int, default=2, help='Solution region grid size (e.g. 2 -> 2x2, etc.)')
-    parser.add_argument('--object_big', type=bool, default=True, help='If true, reconstruct the entire solution region for each set of patterns, instead of just the central N x N region.')
-    parser.add_argument('--nll_weight', type=float, default=1., help='Diffraction reconstruction NLL loss weight')
-    parser.add_argument('--mae_weight', type=float, default=0., help='Diffraction reconstruction MAE loss weight')
-    parser.add_argument('--nimgs_train', type=int, default=params.cfg['nimgs_train'], help='Number of generated training images')
-    parser.add_argument('--nimgs_test', type=int, default=params.cfg['nimgs_test'], help='Number of generated testing images')
-    parser.add_argument('--outer_offset_train', type=int, default=None, help='Scan point grid offset for (generated) training datasets')
-    parser.add_argument('--outer_offset_test', type=int, default=None, help='Scan point grid offset for (generated) testing datasets')
-    parser.add_argument('--n_filters_scale', type=int, default=2, help='Number of filters scale')
-    parser.add_argument('--max_position_jitter', type=int, default=10, help='Solution region is expanded around the edges by this amount')
-    parser.add_argument('--intensity_scale_trainable', type=bool, default=True, help='If true, sets the model-internal normalization of diffraction amplitudes to trainable')
-    parser.add_argument('--positions_provided', type=bool, default=False, help='[deprecated] Whether nominal or true (nominal + jitter) positions are provided in simulation runs')
-    parser.add_argument('--label', type=str, default='', help='[deprecated] Name of this run')
-    args = parser.parse_args()
-
-    model_type = params.cfg['model_type'] = args.model_type
-    label = params.cfg['label'] = args.label
-    params.cfg['positions.provided'] = args.positions_provided
-    params.cfg['data_source'] = args.data_source
-    params.cfg['set_phi'] = args.set_phi
-    params.cfg['nepochs'] = args.nepochs
-    offset = params.cfg['offset'] = args.offset
-    params.cfg['max_position_jitter'] = args.max_position_jitter
-    params.cfg['output_prefix'] = args.output_prefix
-    params.cfg['gridsize'] = args.gridsize
-    params.cfg['n_filters_scale'] = args.n_filters_scale
-    params.cfg['object.big'] = args.object_big
-    params.cfg['intensity_scale.trainable'] = args.intensity_scale_trainable
-    params.cfg['nll_weight'] = args.nll_weight
-    params.cfg['mae_weight'] = args.mae_weight
-    params.cfg['nimgs_train'] = args.nimgs_train
-    params.cfg['nimgs_test'] = args.nimgs_test
-    params.cfg['outer_offset_train'] = args.outer_offset_train
-    params.cfg['outer_offset_test'] = args.outer_offset_test
-else:
-    model_type = params.cfg['model_type']
-    label = params.cfg['label']
-    offset = params.cfg['offset']
-params.cfg['output_prefix'] = misc.get_path_prefix()
-
-out_prefix = params.get('output_prefix')
-os.makedirs(out_prefix, exist_ok=True)
-
-from ptycho import generate_data
-ptycho_dataset = generate_data.ptycho_dataset
-YY_ground_truth = generate_data.YY_ground_truth
-YY_test_full = generate_data.YY_test_full
-Y_I_test = generate_data.Y_I_test
-Y_phi_test = generate_data.Y_phi_test
-X_test = generate_data.X_test
-norm_Y_I_test = generate_data.norm_Y_I_test
-from ptycho import model
-from ptycho.evaluation import save_metrics
-
-if model_type == 'pinn':
-    from ptycho import train_pinn
-    print("DEBUG: generate_data diff norm {}".format(np.mean(np.abs(ptycho_dataset.train_data.X))))
-    train_output = train_pinn.train_eval(ptycho_dataset)
-    pred_amp = train_output['pred_amp']
-    history = train_output['history']
-    reconstructed_obj = train_output['reconstructed_obj']
-    stitched_obj = train_output['stitched_obj']
-
-elif model_type == 'supervised':
-    from ptycho.train_supervised import stitched_obj
-    from ptycho import train_supervised
-    history = train_supervised.history
-    reconstructed_obj = train_supervised.reconstructed_obj
-else:
-    raise ValueError
-
-d = save_recons(model_type, stitched_obj)
-
-with open(out_prefix + '/history.dill', 'wb') as file_pi:
-    dill.dump(history.history, file_pi)
-
-if save_model:
-    model_manager.save(out_prefix)
-
-if save_data:
-    with open(out_prefix + '/test_data.dill', 'wb') as f:
-        dill.dump(
-            {'YY_test_full': YY_test_full,
-             'Y_I_test': Y_I_test,
-             'Y_phi_test': Y_phi_test,
-             'X_test': X_test}, f)
diff --git a/build/lib/build/lib/ptycho/train_pinn.py b/build/lib/build/lib/ptycho/train_pinn.py
deleted file mode 100644
index 05fbd5b..0000000
--- a/build/lib/build/lib/ptycho/train_pinn.py
+++ /dev/null
@@ -1,121 +0,0 @@
-from ptycho import params
-from .loader import PtychoDataContainer
-from .image import reassemble_patches
-
-def train(train_data: PtychoDataContainer, intensity_scale=None, model_instance=None):
-    from . import params as p
-    # Model requires intensity_scale to be defined to set the initial
-    # value of the corresponding model parameter
-    if intensity_scale is None:
-        intensity_scale = calculate_intensity_scale(train_data)
-    p.set('intensity_scale', intensity_scale)
-
-    from ptycho import probe
-    probe.set_probe_guess(None, train_data.probe)
-
-    from ptycho import model
-    if model_instance is None:
-        model_instance = model.autoencoder
-    nepochs = params.cfg['nepochs']
-    params.print_params()
-    return model_instance, model.train(nepochs, train_data)
-
-def train_eval(ptycho_dataset):
-    ## TODO reconstructed_obj -> pred_Y or something
-    model_instance, history = train(ptycho_dataset.train_data)
-    results = {
-        'history': history,
-        'model_instance': model_instance
-    }
-    if ptycho_dataset.test_data is not None:
-        eval_results = eval(ptycho_dataset.test_data, history, trained_model=model_instance)
-        # Get config from the dataset
-        config = ptycho_dataset.test_data.config if hasattr(ptycho_dataset.test_data, 'config') else params.cfg
-        try:
-            stitched_obj = reassemble_patches(eval_results['reconstructed_obj'], config, part='complex')
-        except ValueError as e:
-            print(e)
-            stitched_obj = None
-
-        results.update({
-            'reconstructed_obj': eval_results['reconstructed_obj'],
-            'pred_amp': eval_results['pred_amp'],
-            'reconstructed_obj_cdi': eval_results['reconstructed_obj_cdi'],
-            'stitched_obj': stitched_obj,
-        })
-    return results
-
-from tensorflow.keras.models import load_model
-# Enhance the existing eval function to optionally load a model for inference
-def eval(test_data, history=None, trained_model=None, model_path=None):
-    """
-    Evaluate the model on test data. Optionally load a model if a path is provided.
-
-    Parameters:
-    - test_data: The test data for evaluation.
-    - history: Training history, if available.
-    - trained_model: An already trained model instance, if available.
-    - model_path: Path to a saved model, if loading is required.
-
-    Returns:
-    - Evaluation results including reconstructed objects and prediction amplitudes.
-    """
-    from ptycho.data_preprocessing import reassemble
-
-    from ptycho import probe
-    probe.set_probe_guess(None, test_data.probe)
-    # TODO enforce that the train and test probes are the same
-    print('INFO:', 'setting probe from test data container. It MUST be consistent with the training probe')
-
-    from ptycho import model
-    if model_path is not None:
-        print(f"Loading model from {model_path}")
-        trained_model = load_model(model_path)
-    elif trained_model is None:
-        raise ValueError("Either a trained model instance or a model path must be provided.")
-
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = trained_model.predict(
-        [test_data.X * model.params()['intensity_scale'], test_data.coords_nominal]
-    )
-    try:
-        stitched_obj = reassemble(reconstructed_obj, part='complex')
-    except (ValueError, TypeError) as e:
-        stitched_obj = None
-        print('Object stitching failed:', e)
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi,
-        'stitched_obj': stitched_obj
-    }
-
-def calculate_intensity_scale(ptycho_data_container: PtychoDataContainer) -> float:
-    import tensorflow as tf
-    import numpy as np
-    from . import params as p
-    def count_photons(obj):
-        pcount = np.mean(tf.math.reduce_sum(obj**2, (1, 2)))
-        return pcount
-
-    def scale_nphotons(X):
-        # TODO assumes X is already normalized. this should be enforced
-        return tf.math.sqrt(p.get('nphotons')) / (p.get('N') / 2)
-
-    # Calculate the intensity scale using the adapted scale_nphotons function
-    intensity_scale = scale_nphotons(ptycho_data_container.X).numpy()
-
-    return intensity_scale
-
-# New alternative implementation
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_eval_result(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('Object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/ptycho/train_supervised.py b/build/lib/build/lib/ptycho/train_supervised.py
deleted file mode 100644
index 3ab4e9f..0000000
--- a/build/lib/build/lib/ptycho/train_supervised.py
+++ /dev/null
@@ -1,73 +0,0 @@
-from ptycho.generate_data import *
-from ptycho import tf_helper as hh
-from ptycho import baselines as bl
-from ptycho import params as p
-from ptycho.image import reassemble_patches
-
-offset = p.get('offset')
-
-# For comparison to the 'baseline' model (PtychoNN) we need to crop/shift in a different way
-def xyshift(arr4d, dx, dy):
-    assert len(arr4d.shape) == 4
-    from scipy.ndimage.interpolation import shift
-    arr4d = np.roll(arr4d, dx, axis = 1)
-    arr4d = np.roll(arr4d, dy, axis = 2)
-    return arr4d
-
-def get_recon_patches_single_channel(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0] * bl.params.params()['intensity_scale']])
-    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-#    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0]])
-#    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-
-def get_recon_patches_grid(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_overlap_pred_I, baseline_overlap_pred_phi = model.predict(
-        [X_test[:, :, :, :4]  * bl.params.params()['intensity_scale']])
-    obj_stitched = hh.combine_complex(baseline_overlap_pred_I[:, :, :, :1], baseline_overlap_pred_phi[:, :, :, :1])
-    return xyshift(obj_stitched, -offset // 2, -offset // 2)
-
-if p.cfg['gridsize'] == 2:
-    model, history = bl.train((X_train[:, :, :, :4]),
-                              Y_I_train[:, :, :, :4], Y_phi_train[:, :, :, :4])
-
-    reconstructed_obj = get_recon_patches_grid(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-elif p.cfg['gridsize'] == 1:
-    model, history = bl.train((X_train[:, :, :, :1]), Y_I_train[:, :, :, :1], Y_phi_train[:, :, :, :1])
-
-    # TODO match above
-    reconstructed_obj = get_recon_patches_single_channel(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-    reconstructed_obj_train = get_recon_patches_single_channel(X_train)
-
-else:
-    raise ValueError
-
-try:
-    stitched_obj = reassemble_patches(reconstructed_obj, config, part='complex')
-except (ValueError, TypeError) as e:
-    print('object stitching failed:', e)
-
-# New alternative implementation 
-from ptycho.image import reassemble_patches as _reassemble_patches
-
-def stitch_reconstruction(reconstructed_obj, config, **kwargs):
-    """
-    Alternative implementation using new stitching module.
-    Preserves existing behavior while allowing transition to new API.
-    """
-    try:
-        return _reassemble_patches(reconstructed_obj, config, part='complex', **kwargs)
-    except (ValueError, TypeError) as e:
-        print('object stitching failed:', e)
-        return None
diff --git a/build/lib/build/lib/ptycho/trash/model2.py b/build/lib/build/lib/ptycho/trash/model2.py
deleted file mode 100644
index fde7a52..0000000
--- a/build/lib/build/lib/ptycho/trash/model2.py
+++ /dev/null
@@ -1,148 +0,0 @@
-from . import tf_helper as hh
-from .params import params
-
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras import Sequential
-from tensorflow.keras.activations import sigmoid, tanh
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras.layers import Lambda
-import glob
-import math
-import numpy as np
-import os
-import tensorflow as tf
-import tensorflow_probability as tfp
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-
-N = params()['N']
-w = params()['w']
-h = params()['h']
-gridsize = params()['gridsize']
-offset = params()['offset']
-tprobe = params()['probe']
-batch_size = params()['batch_size']
-# TODO don't rely on this
-intensity_scale = params()['intensity_scale']
-
-# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N // 2,N // 2,3))
-vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-vgg.trainable = False
-
-outputs = [vgg.get_layer('block2_conv2').output]
-feat_model = Model(vgg.input, outputs)
-# feat_model.trainable = False
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-input_img = Input(shape=(h, w, gridsize**2), name = 'input')
-
-x = hh.Conv_Pool_block(input_img,32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-
-encoded=x
-
-#Decoding arm for amplitude
-x1=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x1=hh.Conv_Up_block(x1,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-decoded1 = Conv2D(gridsize**2, (3, 3), padding='same')(x1)
-decoded1 = Lambda(lambda x: sigmoid(x), name='amp')(decoded1)
-
-#Decoding arm for phase
-x2=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x2=hh.Conv_Up_block(x2,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-#x2=Conv_Up_block(x2,32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-
-decoded2 = Conv2D(gridsize**2, (3, 3), padding='same')(x2)
-decoded2 = Lambda(lambda x: math.pi * tanh(x), name='phi')(decoded2)
-
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]),
-                     name='obj')([decoded1, decoded2])
-
-padded_obj = tfkl.ZeroPadding2D(((h // 4), (w // 4)), name = 'padded_obj')(obj)
-padded_obj_2 = Lambda(lambda x:
-    hh.reassemble_patches(x), name = 'padded_obj_2',
-    )(padded_obj)
-#padded_obj_2 = tfkl.ZeroPadding2D((offset // 2 , offset // 2), name = 'padded_obj_2')(padded_obj)
-
-trimmed_obj = Lambda(lambda x: x[:, (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        :], name = 'trimmed_obj')(padded_obj_2)
-
-# TODO average?
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x: hh.flatten_overlaps(x, fmt = 'flat'), name = 'padded_objs_with_offsets')(padded_obj_2)
-# Apply the probe
-padded_objs_with_offsets = Lambda(lambda x: tf.cast(tprobe, tf.complex64) * x,
-                                  name = 'padded_objs_with_offsets_illuminated')(padded_objs_with_offsets)
-
-# TODO refactor
-# Diffracted amplitude
-padded_objs_with_offsets, pred_diff = hh.pad_and_diffract(padded_objs_with_offsets, h, w, pad=False)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-pred_intensity = tfpl.DistributionLambda(lambda t:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               ((t * intensity_scale)**2))
-                                       )))(pred_diff)
-
-#def mul_gaussian_noise(image):
-#    # image must be scaled in [0, 1]
-#    with tf.name_scope('Add_gaussian_noise'):
-#        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=1, dtype=tf.float32)
-#        noise_img = image * noise
-#    return noise_img
-
-negloglik = lambda x, rv_x: -rv_x.log_prob((x))
-
-# The first output exposes the real space object reconstruction and
-# though it does not contribute to the training loss, it's used to
-# calculate reconstruction errors for evaluation
-autoencoder = Model([input_img], [trimmed_obj, pred_diff, pred_intensity, pred_diff])
-#autoencoder = Model([input_img], [padded_obj, pred_diff, pred_intensity, pred_diff])
-
-encode_obj_to_diffraction = tf.keras.Model(inputs=[padded_obj],
-                           outputs=[pred_diff])
-
-diffraction_to_obj = tf.keras.Model(inputs=[input_img],
-                           outputs=[obj])
-
-autoencoder.compile(optimizer='adam',
-     loss=['mean_absolute_error', 'mean_absolute_error', negloglik, hh.total_variation_loss],
-     loss_weights = [0., 0., 1., 0.])
-
-print (autoencoder.summary())
-#plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-def train(epochs, X_train, Y_I_train):
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.h5' %wt_path,
-                                                monitor='val_loss', verbose=1, save_best_only=True,
-                                                save_weights_only=False, mode='auto', period=1)
-
-
-    history=autoencoder.fit([X_train], [Y_I_train, X_train, (intensity_scale * X_train)**2,
-                                       X_train], shuffle=True, batch_size=batch_size, verbose=1,
-                               epochs=epochs, validation_split = 0.05, callbacks=[reduce_lr, earlystop, checkpoints])
-    return history
diff --git a/build/lib/build/lib/ptycho/visualization.py b/build/lib/build/lib/ptycho/visualization.py
deleted file mode 100644
index 91f038e..0000000
--- a/build/lib/build/lib/ptycho/visualization.py
+++ /dev/null
@@ -1,22 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-
-def display_imgs(x, y=None, log = False, cbar = False, figsize=(10, 2), **kwargs):
-  if not isinstance(x, (np.ndarray, np.generic)):
-    x = np.array(x)
-  #plt.ioff()
-  n = x.shape[0]
-  fig, axs = plt.subplots(1, n, figsize = figsize)
-  if y is not None:
-    fig.suptitle(np.argmax(y, axis=1))
-  for i in range(n):
-    if log:
-        axs.flat[i].imshow(np.log(.01 + x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    else:
-        axs.flat[i].imshow((x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    axs.flat[i].axis('off')
-  if cbar:
-    plt.colorbar()
-  plt.show()
-  plt.close()
-  plt.ion()
diff --git a/build/lib/build/lib/ptycho/workflows/__init__.py b/build/lib/build/lib/ptycho/workflows/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/build/lib/ptycho/workflows/components.py b/build/lib/build/lib/ptycho/workflows/components.py
deleted file mode 100644
index b030f63..0000000
--- a/build/lib/build/lib/ptycho/workflows/components.py
+++ /dev/null
@@ -1,455 +0,0 @@
-import argparse
-import yaml
-import os
-import numpy as np
-import tensorflow as tf
-from ptycho import params as p
-from ptycho import probe
-from ptycho.loader import RawData, PtychoDataContainer
-import logging
-import matplotlib.pyplot as plt
-from typing import Union, Optional, Dict, Any, Tuple, Literal
-from pathlib import Path
-from ptycho.config.config import TrainingConfig, ModelConfig, dataclass_to_legacy_dict
-from dataclasses import fields
-from ptycho import loader, probe
-from typing import Union, Optional, Tuple, Dict, Any
-from ptycho.raw_data import RawData
-from ptycho.loader import PtychoDataContainer
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import params
-from ptycho.image import reassemble_patches
-
-# Set up logging
-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
-logger = logging.getLogger(__name__)
-
-from dataclasses import fields
-from ptycho.config.config import ModelConfig, TrainingConfig
-
-def update_config_from_dict(config_updates: dict):
-    """
-    Updates the application's configuration from a dictionary, ideal for notebook workflows.
-
-    Args:
-        config_updates (dict): A dictionary of parameters to update.
-    """
-    # 1. Create a mutable dictionary from the default dataclass values
-    model_defaults = {f.name: f.default for f in fields(ModelConfig)}
-    training_defaults = {f.name: f.default for f in fields(TrainingConfig) if f.name != 'model'}
-    
-    # Merge them
-    full_config_dict = {**model_defaults, **training_defaults}
-
-    # 2. Update with the user's dictionary
-    for key, value in config_updates.items():
-        if key in full_config_dict:
-            full_config_dict[key] = value
-        else:
-            # Optionally warn about unused keys
-            logger.warning(f"Configuration key '{key}' is not a recognized parameter.")
-
-    # 3. Re-construct the dataclasses
-    model_args = {k: v for k, v in full_config_dict.items() if k in model_defaults}
-    training_args = {k: v for k, v in full_config_dict.items() if k in training_defaults}
-
-    # Handle required Path objects if they are not set
-    if training_args.get('train_data_file') is None:
-        # Assign a dummy path or handle as an error if it's essential for all workflows
-        training_args['train_data_file'] = Path("dummy_path.npz")
-
-    final_model_config = ModelConfig(**model_args)
-    final_training_config = TrainingConfig(model=final_model_config, **training_args)
-    
-    # 4. Update the legacy global params dictionary
-    update_legacy_dict(params.cfg, final_training_config)
-    
-    logger.info("Configuration updated programmatically for interactive session.")
-    params.print_params()
-
-def load_data(file_path, n_images=None, flip_x=False, flip_y=False, swap_xy=False, n_samples=1, coord_scale=1.0):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        n_images (int, optional): Number of data points to include in the training set. Defaults to 512.
-        flip_x (bool, optional): If True, flip the sign of x coordinates. Defaults to False.
-        flip_y (bool, optional): If True, flip the sign of y coordinates. Defaults to False.
-        swap_xy (bool, optional): If True, swap x and y coordinates. Defaults to False.
-        n_samples (int, optional): Number of samples to generate. Defaults to 1.
-        coord_scale (float, optional): Scale factor for x and y coordinates. Defaults to 1.0.
-
-    Returns:
-        RawData: RawData object containing the dataset.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Apply coordinate transformations
-    if flip_x:
-        xcoords = -xcoords
-        xcoords_start = -xcoords_start
-        #probeGuess = probeGuess[::-1, :]
-    if flip_y:
-        ycoords = -ycoords
-        ycoords_start = -ycoords_start
-        #probeGuess = probeGuess[:, ::-1]
-    if swap_xy:
-        xcoords, ycoords = ycoords, xcoords
-        xcoords_start, ycoords_start = ycoords_start, xcoords_start
-        #probeGuess = np.transpose(probeGuess)
-
-    # Apply coordinate scaling
-    xcoords *= coord_scale
-    ycoords *= coord_scale
-    xcoords_start *= coord_scale
-    ycoords_start *= coord_scale
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    if n_images is None:
-        n_images = xcoords.shape[0]
-
-    # Create RawData object for the training subset
-    ptycho_data = RawData(xcoords[:n_images], ycoords[:n_images],
-                          xcoords_start[:n_images], ycoords_start[:n_images],
-                          diff3d[:n_images], probeGuess,
-                          scan_index[:n_images], objectGuess=objectGuess)
-
-    return ptycho_data
-
-def parse_arguments():
-    """Parse command-line arguments based on TrainingConfig fields."""
-    logger = logging.getLogger(__name__)
-    parser = argparse.ArgumentParser(description="Non-grid CDI Example Script")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    
-    # Add arguments based on TrainingConfig fields
-    for field in fields(TrainingConfig):
-        if field.name == 'model':
-            # Handle ModelConfig fields
-            for model_field in fields(ModelConfig):
-                # Special handling for Literal types
-                if hasattr(model_field.type, "__origin__") and model_field.type.__origin__ is Literal:
-                    choices = list(model_field.type.__args__)
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=str,
-                        choices=choices,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}, choices: {choices}"
-                    )
-                else:
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=model_field.type,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}"
-                    )
-        else:
-            # Handle path fields specially
-            if field.type == Path or str(field.type).startswith("typing.Optional[pathlib.Path"):
-                logger.debug(f"Field: {field.name}")
-                logger.debug(f"Field type: {field.type}")
-                logger.debug(f"Field default: {field.default}")
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=lambda x: (logger.debug(f"Converting path value: {x}"), Path(x) if x is not None else None)[1],
-                    default=None if field.default == None else str(field.default),
-                    help=f"Path for {field.name}"
-                )
-            else:
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=field.type,
-                    default=field.default,
-                    help=f"Training parameter: {field.name}"
-                )
-    
-    return parser.parse_args()
-
-def load_yaml_config(file_path: str) -> Dict[str, Any]:
-    """Load configuration from a YAML file."""
-    try:
-        with open(file_path, 'r') as file:
-            return yaml.safe_load(file)
-    except (yaml.YAMLError, IOError) as e:
-        logger.error(f"Error loading YAML config: {e}")
-        raise
-
-
-#def validate_config(config: Dict[str, Any]) -> None:
-#    """Validate the configuration."""
-#    if 'train_data_file_path' not in config or config['train_data_file_path'] is None:
-#        raise ValueError("train_data_file_path is a required parameter and must be provided")
-
-def setup_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> TrainingConfig:
-    """Set up the configuration by merging defaults, YAML file, and command-line arguments."""
-    try:
-        yaml_config = load_yaml_config(yaml_path) if yaml_path else None
-        args_config = vars(args)
-        
-        # Convert string paths to Path objects
-        for key in ['train_data_file', 'test_data_file', 'output_dir']:
-            if key in args_config and args_config[key] is not None:
-                args_config[key] = Path(args_config[key])
-        
-        # Create ModelConfig from args
-        model_fields = {f.name for f in fields(ModelConfig)}
-        model_args = {k: v for k, v in args_config.items() if k in model_fields}
-        model_config = ModelConfig(**model_args)
-        
-        # Create TrainingConfig
-        training_fields = {f.name for f in fields(TrainingConfig)}
-        training_args = {k: v for k, v in args_config.items() 
-                        if k in training_fields and k != 'model'}
-        config = TrainingConfig(model=model_config, **training_args)
-        
-        # Update the global configuration
-        update_legacy_dict(params.cfg, config)
-        
-        logger.info("Configuration setup complete")
-        logger.info(f"Final configuration: {config}")
-        
-        return config
-    except (yaml.YAMLError, IOError, ValueError) as e:
-        logger.error(f"Error setting up configuration: {e}")
-        raise
-
-def load_and_prepare_data(data_file_path: str) -> Tuple[RawData, RawData, Any]:
-    """
-    Load and prepare the data from a single file path.
-
-    Args:
-        data_file_path (str): Path to the data file
-
-    Returns:
-        Tuple[RawData, RawData, Any]: A tuple containing the full dataset, training subset, and additional data
-    """
-    # TODO deprecated
-    from ptycho.loader import load_xpp_npz
-    if not os.path.exists(data_file_path):
-        raise FileNotFoundError(f"Data file not found: {data_file_path}")
-
-    try:
-        return load_xpp_npz(data_file_path)
-    except Exception as e:
-        logger.error(f"Error loading data from {data_file_path}: {str(e)}")
-        raise
-
-from typing import Union
-from ptycho.loader import RawData, PtychoDataContainer
-
-def create_ptycho_data_container(data: Union[RawData, PtychoDataContainer], config: TrainingConfig) -> PtychoDataContainer:
-    """
-    Factory function to create or return a PtychoDataContainer.
-
-    Args:
-        data (Union[RawData, PtychoDataContainer]): Input data, either RawData or PtychoDataContainer.
-        config (TrainingConfig): Training configuration object.
-
-    Returns:
-        PtychoDataContainer: The resulting PtychoDataContainer.
-
-    Raises:
-        TypeError: If the input data is neither RawData nor PtychoDataContainer.
-    """
-    if isinstance(data, PtychoDataContainer):
-        return data
-    elif isinstance(data, RawData):
-        dataset = data.generate_grouped_data(config.model.N, K=7, nsamples=1)
-        return loader.load(lambda: dataset, data.probeGuess, which=None, create_split=False)
-    else:
-        raise TypeError("data must be either RawData or PtychoDataContainer")
-
-def train_cdi_model(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig
-) -> Dict[str, Any]:
-    """
-    Train the CDI model.
-
-    Args:
-        train_data (Union[RawData, PtychoDataContainer]): Training data.
-        config (Dict[str, Any]): Configuration dictionary.
-
-    Returns:
-        Dict[str, Any]: Results dictionary containing training history.
-    """
-    from ptycho.loader import PtychoDataset
-    from ptycho import train_pinn
-    # Convert input data to PtychoDataContainer
-    train_container = create_ptycho_data_container(train_data, config)
-    if test_data is not None:
-        test_container = create_ptycho_data_container(test_data, config)
-    else:
-        test_container = None
-
-    # Initialize probe
-    probe.set_probe_guess(None, train_container.probe)
-
-#    # Calculate intensity scale
-#    intensity_scale = train_pinn.calculate_intensity_scale(train_container)
-
-    # Train the model
-    results = train_pinn.train_eval(PtychoDataset(train_container, test_container))
-    results['train_container'] = train_container
-    results['test_container'] = test_container
-    #history = train_pinn.train(train_container)
-    
-    return results
-
-def reassemble_cdi_image(
-    test_data: Union[RawData, PtychoDataContainer],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20,
-    coord_scale: float = 1.0
-) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
-    """
-    Reassemble the CDI image using the trained model.
-
-    Args:
-        test_data (Union[RawData, PtychoDataContainer]): Test data.
-        config (Dict[str, Any]): Configuration dictionary.
-        flip_x (bool): Whether to flip the x coordinates. Default is False.
-        flip_y (bool): Whether to flip the y coordinates. Default is False.
-        transpose (bool): Whether to transpose the image by swapping the 1st and 2nd dimensions. Default is False.
-        M (int): Parameter for reassemble_position function. Default is 20.
-        coord_scale (float): Scale factor for x and y coordinates. Default is 1.0.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray, Dict[str, Any]]: 
-        Reconstructed amplitude, reconstructed phase, and results dictionary.
-    """
-    # TODO use train_pinn.eval to get reconstructed diffraction amplitude
-    test_container = create_ptycho_data_container(test_data, config)
-    
-    from ptycho import nbutils
-    obj_tensor_full, global_offsets = nbutils.reconstruct_image(test_container)
-    
-    # Log the shape of global_offsets
-    logger.info(f"Shape of global_offsets: {global_offsets.shape}")
-
-    # Assert that obj_tensor_full is a 4D tensor
-    assert obj_tensor_full.ndim == 4, f"Expected obj_tensor_full to be a 4D tensor, but got shape {obj_tensor_full.shape}"
-
-    # Transpose the image if requested
-    if transpose:
-        obj_tensor_full = np.transpose(obj_tensor_full, (0, 2, 1, 3))
-
-    # Flip coordinates if requested
-    if flip_x:
-        global_offsets[:, 0, 0, :] = -global_offsets[:, 0, 0, :]
-    if flip_y:
-        global_offsets[:, 0, 1, :] = -global_offsets[:, 0, 1, :]
-    
-    # Scale coordinates
-    global_offsets *= coord_scale
-    
-    from ptycho import tf_helper as hh
-    obj_image = hh.reassemble_position(obj_tensor_full, global_offsets, M=M)
-    
-    recon_amp = np.absolute(obj_image)
-    recon_phase = np.angle(obj_image)
-    
-    results = {
-        "obj_tensor_full": obj_tensor_full,
-        "global_offsets": global_offsets,
-        "recon_amp": recon_amp,
-        "recon_phase": recon_phase
-    }
-    
-    return recon_amp, recon_phase, results
-
-def run_cdi_example(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20
-) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Dict[str, Any]]:
-    """
-    Run the main CDI example execution flow.
-
-    Args:
-        train_data: Training data
-        test_data: Optional test data
-        config: Training configuration parameters
-        flip_x: Whether to flip the x coordinates
-        flip_y: Whether to flip the y coordinates
-        transpose: Whether to transpose the image by swapping dimensions
-        M: Parameter for reassemble_position function
-
-    Returns:
-        Tuple containing:
-        - reconstructed amplitude (or None)
-        - reconstructed phase (or None)
-        - results dictionary
-    """
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    # Train the model
-    train_results = train_cdi_model(train_data, test_data, config)
-    
-    recon_amp, recon_phase = None, None
-    
-    # Reassemble test image if test data is provided and reconstructed_obj is available
-    if test_data is not None and 'reconstructed_obj' in train_results:
-        recon_amp, recon_phase, reassemble_results = reassemble_cdi_image(
-            test_data, config, flip_x, flip_y, transpose, M=M
-        )
-        train_results.update(reassemble_results)
-    
-    return recon_amp, recon_phase, train_results
-
-
-def save_outputs(amplitude: Optional[np.ndarray], phase: Optional[np.ndarray], results: Dict[str, Any], output_prefix: str) -> None:
-    """Save the generated images and results."""
-    os.makedirs(output_prefix, exist_ok=True)
-    
-    # TODO Save training history with tensorboard / mlflow
-    
-    # Save test results if available
-    if amplitude is not None and phase is not None:
-        logger.info(f"Amplitude array shape: {amplitude.shape}")
-        logger.info(f"Phase array shape: {phase.shape}")
-        
-        # Squeeze any extra dimensions
-        amplitude = np.squeeze(amplitude)
-        phase = np.squeeze(phase)
-        
-        logger.info(f"Squeezed amplitude shape: {amplitude.shape}")
-        logger.info(f"Squeezed phase shape: {phase.shape}")
-        
-        # Save as PNG files using plt.figure() to handle 2D arrays properly
-        plt.figure(figsize=(8,8))
-        plt.imshow(amplitude, cmap='gray')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_amplitude.png"))
-        plt.close()
-        
-        plt.figure(figsize=(8,8))
-        plt.imshow(phase, cmap='viridis')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_phase.png"))
-        plt.close()
-        
-    logger.info(f"Outputs saved to {output_prefix}")
diff --git a/build/lib/build/lib/ptycho/workflows/visualize_results.py b/build/lib/build/lib/ptycho/workflows/visualize_results.py
deleted file mode 100644
index 5d1f9ad..0000000
--- a/build/lib/build/lib/ptycho/workflows/visualize_results.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho import evaluation, params
-from typing import Dict, Any
-
-def visualize_results(results: Dict[str, Any], test_data, i: int = 200, output_prefix: str = 'output'):
-    """
-    Visualize the results using the evaluation.summarize function.
-
-    Args:
-    results (Dict[str, Any]): Dictionary containing the results from the CDI process.
-    test_data: The test data used for evaluation.
-    i (int): Index of the sample to visualize. Default is 200.
-    output_prefix (str): Directory to save the output files. Default is 'output'.
-    """
-    # Extract necessary data from results and test_data
-    pred_amp = results['pred_amp']
-    reconstructed_obj = results['reconstructed_obj']
-    X_test = test_data.X
-    Y_I_test = test_data.Y_I
-    Y_phi_test = test_data.Y_phi
-    probe = np.absolute(params.get('probe')[:, :, 0, 0])
-
-    # Call the summarize function
-    heatmaps = evaluation.summarize(i, results['pred_amp'] + 1, results['reconstructed_obj'], 
-                                    X_test, Y_I_test, Y_phi_test,
-                                    probe, channel=0, crop=False)
-
-    # Save the heatmaps
-    for name, heatmap in heatmaps.items():
-        plt.figure(figsize=(10, 10))
-        plt.imshow(heatmap, cmap='jet')
-        plt.colorbar()
-        plt.title(name)
-        plt.savefig(f"{output_prefix}/{name}.png")
-        plt.close()
-
-    print(f"Heatmaps saved to {output_prefix}")
-
-if __name__ == "__main__":
-    # This is where you would load your results and test_data
-    # For example:
-    # from ptycho.workflows.components import load_and_prepare_data
-    # test_data = load_and_prepare_data("path_to_test_data.npz")
-    # results = ... # Load your results here
-
-    # visualize_results(results, test_data)
-    pass  # Remove this line when uncommenting the code above
diff --git a/build/lib/build/lib/ptycho/xpp.py b/build/lib/build/lib/ptycho/xpp.py
deleted file mode 100644
index 15c881b..0000000
--- a/build/lib/build/lib/ptycho/xpp.py
+++ /dev/null
@@ -1,23 +0,0 @@
-import numpy as np
-import pkg_resources
-
-from .loader import load_xpp_npz as load_ptycho_data
-
-train_frac = .5
-N = 64
-gridh, gridw = 32, 32
-
-np.random.seed(7)
-
-def get_data(**kwargs):
-    return dset, train_frac
-
-
-data_file_path = pkg_resources.resource_filename(__name__, 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-ptycho_data, ptycho_data_train, obj = load_ptycho_data(data_file_path)
-print('raw diffraction shape', obj['diffraction'].shape)
-# TODO cast to complex64?
-probeGuess = obj['probeGuess']
-objectGuess = obj['objectGuess']
-
-## TODO refactor actual / nominal positions
diff --git a/build/lib/build/lib/scripts/inference/inference.py b/build/lib/build/lib/scripts/inference/inference.py
deleted file mode 100644
index 41951e8..0000000
--- a/build/lib/build/lib/scripts/inference/inference.py
+++ /dev/null
@@ -1,384 +0,0 @@
-#!/usr/bin/env python
-# coding: utf-8
-# TODO needs to be updated to use the new-style config dataclasses
-# MAYBE only generate the comparison plot when ground truth object is provided
-# MAYBE save output to npz file, not just image
-
-"""
-Inference script for ptychography reconstruction.
-
-This script loads a trained model and test data, performs inference,
-and saves the reconstructed image comparison and optionally a probe visualization.
-
-Usage:
-    python inference_script.py --model_prefix <model_prefix> --test_data <test_data_file> [--output_path <output_path>]
-                               [--visualize_probe] [--K <K>] [--nsamples <nsamples>]
-
-Arguments:
-    --model_prefix: Path prefix for the saved model and its configuration
-    --test_data: Path to the .npz file containing test data
-    --output_path: Path prefix for saving output files and images (default: './')
-    --visualize_probe: Flag to generate and save probe visualization
-    --K: Number of nearest neighbors for grouped data generation (default: 7)
-    --nsamples: Number of samples for grouped data generation (default: 1)
-"""
-
-from typing import Optional
-import argparse
-import logging
-import os
-import sys
-import time
-import signal
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-from ptycho import probe, params, train_pinn
-from ptycho.model_manager import ModelManager
-from ptycho.raw_data import RawData
-from ptycho.workflows.components import load_data, setup_configuration, parse_arguments
-from ptycho.config.config import InferenceConfig, ModelConfig, validate_inference_config, update_legacy_dict
-
-# Set up logging
-logging.basicConfig(level=logging.INFO,
-                    format='%(asctime)s - %(levelname)s - %(message)s',
-                    handlers=[
-                        logging.StreamHandler(sys.stdout),
-                        logging.FileHandler('inference.log')
-                    ])
-logger = logging.getLogger(__name__)
-
-# Redirect print statements to logger
-print = logger.info
-
-# Global flag for graceful shutdown
-shutdown_requested = False
-
-def signal_handler(signum, frame):
-    global shutdown_requested
-    shutdown_requested = True
-    print(f"Received signal {signum}. Initiating graceful shutdown...")
-
-# Register signal handlers
-signal.signal(signal.SIGINT, signal_handler)
-signal.signal(signal.SIGTERM, signal_handler)
-
-def parse_arguments() -> argparse.Namespace:
-    """Parse command line arguments."""
-    parser = argparse.ArgumentParser(description="Ptychography Inference Script")
-    parser.add_argument("--model_path", type=str, required=True,
-                       help="Path to the saved model")
-    parser.add_argument("--test_data", type=str, required=True,
-                       help="Path to the test data file")
-    parser.add_argument("--config", type=str, required=False, default=None,
-                       help="Optional path to YAML configuration file to override defaults")
-    parser.add_argument("--output_dir", type=str, default='inference_outputs',
-                       help="Directory for saving output files and images")
-    parser.add_argument("--debug", action="store_true",
-                       help="Enable debug mode")
-    return parser.parse_args()
-
-def setup_inference_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> InferenceConfig:
-    """Setup inference configuration from arguments and YAML file."""
-    if yaml_path:
-        base_config = setup_configuration(args, yaml_path)
-        model_config = base_config.model
-    else:
-        # Use default ModelConfig when no YAML provided
-        model_config = ModelConfig()
-    
-    inference_config = InferenceConfig(
-        model=model_config,
-        model_path=Path(args.model_path),
-        test_data_file=Path(args.test_data),
-        debug=args.debug,
-        output_dir=Path(args.output_dir)
-    )
-    
-    validate_inference_config(inference_config)
-    return inference_config
-
-
-def load_model(model_path: Path) -> tuple:
-    """Load the saved model and its configuration."""
-    try:
-        print(f"Attempting to load model from: {model_path}")
-        print(f"Current working directory: {os.getcwd()}")
-        
-        # Check if the path is a directory and contains wts.h5.zip
-        model_zip = os.path.join(model_path, "wts.h5")
-        if not os.path.exists(f"{model_zip}.zip"):
-            raise ValueError(f"Model archive not found at: {model_zip}.zip")
-            
-        # Load multiple models
-        models_dict = ModelManager.load_multiple_models(model_zip)
-        
-        # Get the diffraction_to_obj model which is what we need for inference
-        if 'diffraction_to_obj' not in models_dict:
-            raise ValueError("No diffraction_to_obj model found in saved models")
-            
-        model = models_dict['diffraction_to_obj']
-        config = params.cfg  # ModelManager updates global config when loading
-
-        print(f"Successfully loaded model from {model_path}")
-        print(f"Model configuration: {config}")
-
-        return model, config
-
-    except Exception as e:
-        raise ValueError(f"Failed to load model: {str(e)}")
-
-def perform_inference(model: tf.keras.Model, test_data: RawData, config: dict, K: int, nsamples: int) -> tuple:
-    """
-    Perform inference using the loaded model and test data.
-
-    Args:
-        model (tf.keras.Model): The loaded TensorFlow model.
-        test_data (RawData): The RawData object containing test data.
-        config (dict): The model's configuration dictionary.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Returns:
-        tuple: (np.ndarray, np.ndarray, np.ndarray, np.ndarray) - Reconstructed amplitude, 
-               reconstructed phase, ePIE amplitude, and ePIE phase.
-
-    Raises:
-        ValueError: If there's an error during inference.
-    """
-    from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer
-    try:
-        # Set probe guess
-        probe.set_probe_guess(None, test_data.probeGuess)
-
-        # Set random seeds
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate grouped data
-        test_dataset = test_data.generate_grouped_data(config['N'], K=K, nsamples=nsamples)
-        
-        # Create PtychoDataContainer
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        start_time = time.time()
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        reconstruction_time = time.time() - start_time
-        print(f"Reconstruction completed in {reconstruction_time:.2f} seconds")
-
-        # Process the reconstructed image
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-
-#        # Process ePIE results for comparison
-#        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-#        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        epie_phase = np.angle(test_data.objectGuess)
-        epie_amplitude = np.abs(test_data.objectGuess)
-
-        print(f"Reconstructed amplitude shape: {reconstructed_amplitude.shape}")
-        print(f"Reconstructed phase shape: {reconstructed_phase.shape}")
-        print(f"ePIE amplitude shape: {epie_amplitude.shape}")
-        print(f"ePIE phase shape: {epie_phase.shape}")
-
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-
-    except Exception as e:
-        print(f"Error during inference: {str(e)}")
-        raise ValueError(f"Error during inference: {str(e)}")
-
-def save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_path):
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Create the comparison figure with a smaller size
-        fig, axs = plt.subplots(2, 2, figsize=(4, 4))
-        
-        # PtychoPINN phase
-        im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-        axs[0, 0].set_title('PtychoPINN Phase')
-        fig.colorbar(im_pinn_phase, ax=axs[0, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE phase
-        im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-        axs[0, 1].set_title('ePIE Phase')
-        fig.colorbar(im_epie_phase, ax=axs[0, 1], fraction=0.046, pad=0.04)
-        
-        # PtychoPINN amplitude
-        im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-        axs[1, 0].set_title('PtychoPINN Amplitude')
-        fig.colorbar(im_pinn_amp, ax=axs[1, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE amplitude
-        im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-        axs[1, 1].set_title('ePIE Amplitude')
-        fig.colorbar(im_epie_amp, ax=axs[1, 1], fraction=0.046, pad=0.04)
-        
-        # Remove axis ticks
-        for ax in axs.flat:
-            ax.set_xticks([])
-            ax.set_yticks([])
-        
-        # Adjust layout with specific padding
-        plt.tight_layout(pad=1.5)
-        
-        # Save the figure with adjusted DPI and ensuring the entire figure is saved
-        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.5)
-        plt.close(fig)
-
-        print(f"Comparison image saved to: {output_path}")
-
-    except Exception as e:
-        print(f"Error saving comparison image: {str(e)}")
-
-def save_probe_visualization(test_data: RawData, output_path: str):
-    """
-    Generate and save the probe visualization.
-
-    Args:
-        test_data (RawData): The RawData object containing test data.
-        output_path (str): Path to save the probe visualization.
-
-    Raises:
-        OSError: If there's an error creating the output directory or saving the image.
-    """
-    from ptycho.nbutils import probeshow
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Generate the probe visualization
-        fig = probeshow(test_data.probeGuess, test_data)
-        
-        # Save the figure
-        fig.savefig(output_path, dpi=300, bbox_inches='tight')
-        plt.close(fig)
-
-        print(f"Probe visualization saved to: {output_path}")
-
-    except OSError as e:
-        raise OSError(f"Error saving probe visualization: {str(e)}")
-
-def main(model_prefix: str, test_data_file: str, output_path: str, visualize_probe: bool, K: int, nsamples: int) -> None:
-    """
-    Main function to orchestrate the inference process.
-
-    Args:
-        model_prefix (str): Path prefix for the saved model and its configuration.
-        test_data_file (str): Path to the .npz file containing test data.
-        output_path (str): Path prefix for saving output files and images.
-        visualize_probe (bool): Flag to generate and save probe visualization.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Raises:
-        Exception: If any error occurs during the inference process.
-    """
-    print("Starting inference process...")
-    start_time = time.time()
-
-    try:
-        # Load model
-        print("Loading model...")
-        model, config = load_model(model_prefix)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(test_data_file)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping inference process.")
-            return
-
-        # Perform inference
-        print(f"Performing inference with K={K} and nsamples={nsamples}...")
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(model, test_data, config, K, nsamples)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping before saving results.")
-            return
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = os.path.join(output_path, "reconstruction_comparison.png")
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_image_path)
-
-        # Save probe visualization if requested
-        if visualize_probe:
-            print("Generating and saving probe visualization...")
-            probe_output_path = os.path.join(output_path, "probe_visualization.png")
-            save_probe_visualization(test_data, probe_output_path)
-
-        print("Inference process completed successfully.")
-
-    except FileNotFoundError as e:
-        print(f"File not found error: {str(e)}")
-        raise
-    except ValueError as e:
-        print(f"Value error: {str(e)}")
-        raise
-    except OSError as e:
-        print(f"OS error: {str(e)}")
-        raise
-    except Exception as e:
-        print(f"An unexpected error occurred: {str(e)}")
-        raise
-    finally:
-        # Perform any necessary cleanup
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-    end_time = time.time()
-    print(f"Total execution time: {end_time - start_time:.2f} seconds")
-
-def main():
-    """Main entry point for the ptychography inference script."""
-    try:
-        print("Starting ptychography inference script...")
-        args = parse_arguments()
-        config = setup_inference_configuration(args, args.config)
-        
-        # Update global params with new-style config
-        update_legacy_dict(params.cfg, config)
-
-        # Load model
-        print("Loading model...")
-        model, _ = load_model(config.model_path)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(args.test_data)
-
-        # Perform inference
-        print("Performing inference...")
-        # TODO might want to reduce K
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-            model, test_data, params.cfg, K=7, nsamples=1)
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = config.output_dir / "reconstruction_comparison.png"
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, 
-                            epie_amplitude, epie_phase, output_image_path)
-
-        print("Inference process completed successfully.")
-        sys.exit(0)
-    except Exception as e:
-        print(f"Script execution failed: {str(e)}")
-        sys.exit(1)
-    finally:
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/scripts/inspect_ptycho_data.py b/build/lib/build/lib/scripts/inspect_ptycho_data.py
deleted file mode 100644
index 008d7f5..0000000
--- a/build/lib/build/lib/scripts/inspect_ptycho_data.py
+++ /dev/null
@@ -1,73 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho.loader import PtychoDataContainer
-
-def load_ptycho_data(file_path: str) -> PtychoDataContainer:
-    """
-    Load the npz-serialized ptycho data.
-
-    Args:
-        file_path (str): Path to the npz file.
-
-    Returns:
-        PtychoDataContainer: Loaded ptycho data.
-    """
-    data = np.load(file_path, allow_pickle=True)
-    return PtychoDataContainer(
-        X=data['X'],
-        Y_I=data['Y_I'],
-        Y_phi=data['Y_phi'],
-        norm_Y_I=data['norm_Y_I'],
-        YY_full=data['YY_full'],
-        coords_nominal=data['coords_nominal'],
-        coords_true=data['coords_true'],
-        nn_indices=data['nn_indices'],
-        global_offsets=data['global_offsets'],
-        local_offsets=data['local_offsets'],
-        probeGuess=data['probe']
-    )
-
-def inspect_ptycho_frames(data: PtychoDataContainer, num_frames: int = 2):
-    """
-    Visually inspect a couple of frames from X, Y_I, and Y_phi.
-
-    Args:
-        data (PtychoDataContainer): Loaded ptycho data.
-        num_frames (int): Number of frames to display. Defaults to 2.
-    """
-    fig, axes = plt.subplots(3, num_frames, figsize=(5*num_frames, 15))
-    
-    for i in range(num_frames):
-        axes[0, i].imshow(data.X[i, ..., 0], cmap='viridis')
-        axes[0, i].set_title(f'X - Frame {i}')
-        axes[0, i].axis('off')
-        
-        axes[1, i].imshow(data.Y_I[i, ..., 0], cmap='viridis')
-        axes[1, i].set_title(f'Y_I - Frame {i}')
-        axes[1, i].axis('off')
-        
-        axes[2, i].imshow(data.Y_phi[i, ..., 0], cmap='viridis')
-        axes[2, i].set_title(f'Y_phi - Frame {i}')
-        axes[2, i].axis('off')
-    
-    plt.tight_layout()
-    plt.show()
-
-if __name__ == "__main__":
-    import sys
-
-    if len(sys.argv) < 2:
-        print("Usage: python inspect_ptycho_data.py <path_to_npz_file>")
-        sys.exit(1)
-
-    file_path = sys.argv[1]
-    
-    try:
-        # Load the data
-        ptycho_data = load_ptycho_data(file_path)
-        
-        # Inspect the frames
-        inspect_ptycho_frames(ptycho_data)
-    except Exception as e:
-        print(f"An error occurred: {e}")
-        sys.exit(1)
diff --git a/build/lib/build/lib/scripts/simulation/simulation.py b/build/lib/build/lib/scripts/simulation/simulation.py
deleted file mode 100644
index 3dbea64..0000000
--- a/build/lib/build/lib/scripts/simulation/simulation.py
+++ /dev/null
@@ -1,276 +0,0 @@
-#!/usr/bin/env python3
-# ptycho_simulate_cli.py
-
-import argparse
-import os
-import sys
-import matplotlib.pyplot as plt
-from ptycho.workflows.components import (
-    setup_configuration,
-    run_cdi_example,
-    update_params,
-)
-
-def save_plot_to_file(fig, filename):
-    fig.savefig(filename, dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-def generate_html_report(output_dir, image_files, args, params):
-    import base64
-
-    html_content = """
-    <!DOCTYPE html>
-    <html lang="en">
-    <head>
-        <meta charset="UTF-8">
-        <meta name="viewport" content="width=device-width, initial-scale=1.0">
-        <title>Ptychography Simulation Report</title>
-        <style>
-            body {
-                font-family: Arial, sans-serif;
-                line-height: 1.6;
-                color: #333;
-                max-width: 1000px;
-                margin: 0 auto;
-                padding: 20px;
-            }
-            h1, h2 {
-                color: #2c3e50;
-                text-align: center;
-            }
-            .image-container {
-                margin-bottom: 30px;
-            }
-            img {
-                max-width: 100%;
-                height: auto;
-                display: block;
-                margin: 0 auto;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 5px;
-            }
-            .image-title {
-                font-weight: bold;
-                margin-top: 10px;
-                text-align: center;
-            }
-            .command, .parameters {
-                background-color: #f4f4f4;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 10px;
-                margin-bottom: 20px;
-                white-space: pre-wrap;
-                word-wrap: break-word;
-            }
-            .parameter-name {
-                font-weight: bold;
-            }
-            .parameter-description {
-                margin-left: 20px;
-                margin-bottom: 10px;
-            }
-        </style>
-    </head>
-    <body>
-        <h1>Ptychography Simulation Report</h1>
-        
-        <h2>Launch Command</h2>
-        <div class="command">
-        {' '.join(sys.argv)}
-        </div>
-        
-        <h2>Model Parameters</h2>
-        <div class="parameters">
-    """
-
-    for key, value in params.items():
-        html_content += f'<p><span class="parameter-name">{key}:</span> {value}</p>\n'
-        if key == "N":
-            html_content += '<p class="parameter-description">Size of the simulation grid.</p>\n'
-        elif key == "probe_scale":
-            html_content += '<p class="parameter-description">Probe scale factor.</p>\n'
-        elif key == "nphotons":
-            html_content += '<p class="parameter-description">Number of photons.</p>\n'
-        elif key == "mae_weight":
-            html_content += '<p class="parameter-description">Weight for MAE loss.</p>\n'
-        elif key == "nll_weight":
-            html_content += '<p class="parameter-description">Weight for NLL loss.</p>\n'
-        elif key == "nepochs":
-            html_content += '<p class="parameter-description">Number of epochs for training.</p>\n'
-        elif key == "intensity_scale.trainable":
-            html_content += '<p class="parameter-description">Whether intensity scale is trainable.</p>\n'
-        elif key == "positions.provided":
-            html_content += '<p class="parameter-description">Whether positions are provided.</p>\n'
-        elif key == "probe.big":
-            html_content += '<p class="parameter-description">Whether to use a big probe.</p>\n'
-        elif key == "probe.mask":
-            html_content += '<p class="parameter-description">Whether to use a probe mask.</p>\n'
-        elif key == "data_source":
-            html_content += '<p class="parameter-description">Type of data source.</p>\n'
-        elif key == "gridsize":
-            html_content += '<p class="parameter-description">Grid size for simulation.</p>\n'
-
-    html_content += """
-        </div>
-        
-        <h2>Visualizations</h2>
-    """
-
-    for image_file in image_files:
-        image_name = os.path.basename(image_file)
-        image_title = image_name.replace('_', ' ').replace('.png', '').title()
-        
-        # Read the image file and encode it in base64
-        with open(image_file, 'rb') as img_f:
-            image_data = img_f.read()
-            encoded_image = base64.b64encode(image_data).decode('utf-8')
-        
-        # Determine the image's MIME type
-        mime_type = 'image/png'  # Adjust if using other image formats
-        
-        # Embed the image in the HTML using a data URI
-        html_content += f"""
-        <div class="image-container">
-            <img src="data:{mime_type};base64,{encoded_image}" alt="{image_title}">
-            <p class="image-title">{image_title}</p>
-        </div>
-        """
-
-    html_content += """
-    </body>
-    </html>
-    """
-
-    with open(os.path.join(output_dir, 'report.html'), 'w') as f:
-        f.write(html_content)
-
-def main():
-    parser = argparse.ArgumentParser(description="Simulate ptychography data and generate visualizations.")
-    parser.add_argument("input_file", help="Path to the input .npz file containing probe and object guesses.")
-    parser.add_argument("output_dir", help="Directory to save output visualizations.")
-    parser.add_argument("--nimages", type=int, default=2000, help="Number of images to simulate.")
-    parser.add_argument("--seed", type=int, default=None, help="Random seed for reproducibility.")
-    parser.add_argument("--nepochs", type=int, default=50, help="Number of epochs for training.")
-    parser.add_argument("--output_prefix", default="tmp", help="Prefix for output files.")
-    parser.add_argument("--intensity_scale_trainable", action="store_true", default=False, help="Make intensity scale trainable.")
-    parser.add_argument("--positions_provided", action="store_true", default=True, help="Positions are provided.")
-    parser.add_argument("--probe_big", action="store_true", default=True, help="Use big probe.")
-    parser.add_argument("--probe_mask", action="store_true", default=False, help="Use probe mask.")
-    parser.add_argument("--data_source", default="generic", help="Data source type.")
-    parser.add_argument("--gridsize", type=int, default=1, help="Grid size.")
-    parser.add_argument("--train_data_file_path", default=None, help="Path to train data file.")
-    parser.add_argument("--test_data_file_path", default=None, help="Path to test data file.")
-    parser.add_argument("--N", type=int, default=128, help="Size of the simulation grid.")
-    parser.add_argument("--probe_scale", type=int, default=4, help="Probe scale factor.")
-    parser.add_argument("--nphotons", type=float, default=1e9, help="Number of photons.")
-    parser.add_argument("--mae_weight", type=float, default=1, help="Weight for MAE loss.")
-    parser.add_argument("--nll_weight", type=float, default=0, help="Weight for NLL loss.")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    args = parser.parse_args()
-
-    os.makedirs(args.output_dir, exist_ok=True)
-
-    params = {
-        "nepochs": args.nepochs,
-        "output_prefix": args.output_prefix,
-        "intensity_scale.trainable": args.intensity_scale_trainable,
-        "positions.provided": args.positions_provided,
-        "probe.big": args.probe_big,
-        "probe.mask": args.probe_mask,
-        "data_source": args.data_source,
-        "gridsize": args.gridsize,
-        "train_data_file_path": args.train_data_file_path,
-        "test_data_file_path": args.test_data_file_path,
-        "N": args.N,
-        "probe_scale": args.probe_scale,
-        "nphotons": args.nphotons,
-        "mae_weight": args.mae_weight,
-        "nll_weight": args.nll_weight,
-    }
-    
-
-    update_params(params)
-    config = setup_configuration(args, args.config)
-
-    from ptycho import probe
-    from ptycho.nongrid_simulation import (
-        simulate_from_npz,
-        visualize_simulated_data,
-        plot_random_groups,
-        compare_reconstructions,
-    )
-    from ptycho import tf_helper as hh
-    from ptycho import baselines as bl
-    from ptycho.workflows.components import create_ptycho_data_container
-
-    # Simulate data
-    simulated_data, ground_truth_patches = simulate_from_npz(
-        args.input_file, args.nimages, random_seed=args.seed
-    )
-
-    # Set the probe
-    probe.set_probe_guess(None, simulated_data.probeGuess)
-
-    # Prepare data for visualization
-    data_for_vis = {
-        'diffraction_patterns': simulated_data.diff3d,
-        'ground_truth_patches': ground_truth_patches,
-        'probe_guess': simulated_data.probeGuess,
-        'object': simulated_data.objectGuess,
-        'x_coordinates': simulated_data.xcoords,
-        'y_coordinates': simulated_data.ycoords,
-    }
-
-    # Generate and save visualizations
-    image_files = []
-
-    # Visualize simulated data
-    #plt.figure(figsize=(20, 20))
-    visualize_simulated_data(data_for_vis, args.output_dir)
-    filename = os.path.join(args.output_dir, "simulated_data_visualization.png")
-    #plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    #plt.close()
-
-    # Plot random groups
-    for i in range(3):  # Generate 3 sets of random groups
-        plt.figure(figsize=(15, 15))
-        plot_random_groups(simulated_data, K=5, seed=args.seed)
-        filename = os.path.join(args.output_dir, f'random_groups_{i+1}.png')
-        plt.savefig(filename, dpi=300, bbox_inches='tight')
-        image_files.append(filename)
-        plt.close()
-
-    # Run CDI example and compare reconstructions
-    config = setup_configuration(args, None)
-    train_data = create_ptycho_data_container(simulated_data, config)
-    recon_amp, recon_phase, results = run_cdi_example(train_data, train_data, config)
-
-    # Train baseline model
-    baseline_model = bl.train(train_data.X[:, :, :, :1], train_data.Y_I[:, :, :, :1], train_data.Y_phi[:, :, :, :1])
-    baseline_pred_I, baseline_pred_phi = baseline_model[0].predict([train_data.X[:, :, :, 0]])
-
-    # Compare reconstructions
-    plt.figure(figsize=(20, 20))
-    compare_reconstructions(
-        results['obj_tensor_full'],
-        results['global_offsets'],
-        simulated_data.objectGuess,
-        hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-    )
-    filename = os.path.join(args.output_dir, 'reconstruction_comparison.png')
-    plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    plt.close()
-
-    # Generate HTML report with embedded images, launch command, and model parameters
-    generate_html_report(args.output_dir, image_files, args, params)
-
-    print(f"Simulation and visualization complete. Results saved in {args.output_dir}")
-    print(f"Open {os.path.join(args.output_dir, 'report.html')} to view the visualizations.")
-
-if __name__ == "__main__":
-    main()
-
diff --git a/build/lib/build/lib/scripts/stitch_patches.py b/build/lib/build/lib/scripts/stitch_patches.py
deleted file mode 100644
index 4f88936..0000000
--- a/build/lib/build/lib/scripts/stitch_patches.py
+++ /dev/null
@@ -1,93 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, *, 
-                  N: int,
-                  gridsize: int,
-                  offset: int,
-                  nimgs_test: int,
-                  outer_offset_test: int = None,
-                  norm_Y_I_test: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        N: Size of each square patch
-        gridsize: Grid size for patch arrangement  
-        offset: Spacing between patches
-        nimgs_test: Number of test images
-        outer_offset_test: Offset between outer patches
-        norm_Y_I_test: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # if the channel dimension exists, its size must be 1
-    if patches.shape[-1] != 1:
-        assert patches.shape[-1] == N
-
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    # Handle optional parameters
-    nimgs = nimgs_test
-    outer_offset = outer_offset_test if outer_offset_test is not None else offset
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / nimgs) / (N**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-
-# Usage example
-#stitched = stitch_patches(ptycho_dataset.test_data.Y[:, :, :, :1],
-#              N=64,
-#              gridsize=2,
-#              offset=4,
-#              nimgs_test=1,
-#              outer_offset_test=20,
-#              norm_Y_I_test=ptycho_dataset.test_data.norm_Y_I,
-#              norm=True, 
-#              part='complex')
-#plt.imshow(np.abs(stitched[0, :, :, 0]))
diff --git a/build/lib/build/lib/scripts/training/train.py b/build/lib/build/lib/scripts/training/train.py
deleted file mode 100644
index 983f262..0000000
--- a/build/lib/build/lib/scripts/training/train.py
+++ /dev/null
@@ -1,62 +0,0 @@
-#!/usr/bin/env python
-
-import logging
-import sys
-
-# Set up file handler for debug logging
-file_handler = logging.FileHandler('train_debug.log')
-file_handler.setLevel(logging.DEBUG)
-file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Set up console handler for info logging
-console_handler = logging.StreamHandler(sys.stdout)
-console_handler.setLevel(logging.INFO)
-console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Configure root logger
-logging.getLogger().setLevel(logging.DEBUG)
-logging.getLogger().addHandler(file_handler)
-logging.getLogger().addHandler(console_handler)
-
-from ptycho.workflows.components import (
-    parse_arguments,
-    setup_configuration,
-    load_data,
-    run_cdi_example,
-    save_outputs,
-    logger
-)
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import model_manager, params
-def main() -> None:
-    """Main function to orchestrate the CDI example script execution."""
-    args = parse_arguments()
-    
-    # Handle legacy argument name
-    if hasattr(args, 'train_data_file_path'):
-        args.train_data_file = args.train_data_file_path
-        delattr(args, 'train_data_file_path')
-        
-    config = setup_configuration(args, args.config)
-    
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    try:
-
-        #ptycho_data, ptycho_data_train, obj = load_and_prepare_data(config['train_data_file_path'])
-        ptycho_data = load_data(str(config.train_data_file), n_images = 512)
-        
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-    except Exception as e:
-        logger.error(f"An error occurred during execution: {e}")
-        raise
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/build/lib/tests/old_test_tf_helper.py b/build/lib/build/lib/tests/old_test_tf_helper.py
deleted file mode 100644
index 8e729d2..0000000
--- a/build/lib/build/lib/tests/old_test_tf_helper.py
+++ /dev/null
@@ -1,49 +0,0 @@
-from ptycho.tf_helper import complexify_function, complexify_amp_phase, combine_complex
-import tensorflow as tf
-import numpy as np
-
-
-# Sample function to be complexified
-def sample_fn(tensor, *args, **kwargs):
-    return tensor * 2
-
-# Complexify the sample function
-complexified_fn = complexify_function(sample_fn)
-complexified_amp_phase_fn = complexify_amp_phase(sample_fn)
-
-def test_complexify_function():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    expected_output = tf.constant([2.0 + 4.0j, 6.0 + 8.0j], dtype=tf.complex64)
-    assert tf.math.reduce_all(complexified_fn(complex_tensor) == expected_output), "Failed on complex tensor"
-
-def test_complexify_amp_phase():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    # Doubling the amplitude
-    expected_amplitude = tf.math.abs(complex_tensor) * 2
-    # Doubling the phase (modulus to keep it within -pi to pi)
-    expected_phase = tf.math.angle(complex_tensor) * 2 % (2 * tf.constant(np.pi))
-    # Construct the expected tensor
-    expected_tensor = combine_complex(expected_amplitude, expected_phase)
-    # Compare the reconstructed tensor to the expected tensor
-    error = tf.math.abs(complexified_amp_phase_fn(complex_tensor) - expected_tensor)
-    assert tf.math.reduce_max(error) < 1e-6, "Failed on complex tensor"
-
-
-# Execute the tests
-test_complexify_function()
-
-with tf.device('/CPU:0'):
-    # Force CPU execution because one of the first two tests fails on GPU
-    test_complexify_amp_phase()
-
-print("All tests passed!")
diff --git a/build/lib/build/lib/tests/test_generate_data.py b/build/lib/build/lib/tests/test_generate_data.py
deleted file mode 100644
index 405bef0..0000000
--- a/build/lib/build/lib/tests/test_generate_data.py
+++ /dev/null
@@ -1,7 +0,0 @@
-# Test for generate_data module in the ptycho package
-
-from ptycho import generate_data as init
-
-def test_placeholder():
-    # Placeholder test to ensure the import works
-    assert hasattr(init, 'PtychoData'), "generate_data module should have PtychoData class"
diff --git a/build/lib/build/lib/tests/test_generic_loader.py b/build/lib/build/lib/tests/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/build/lib/tests/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/build/lib/tests/test_tf_helper.py b/build/lib/build/lib/tests/test_tf_helper.py
deleted file mode 100644
index 337e29e..0000000
--- a/build/lib/build/lib/tests/test_tf_helper.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import unittest
-import tensorflow as tf
-import numpy as np
-from ptycho.tf_helper import get_mask, combine_complex, pad_obj
-
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import tensorflow as tf
-from ptycho.tf_helper import get_mask, _fromgrid, params
-
-class TestFromGrid(unittest.TestCase):
-
-    def test_fromgrid(self):
-        print("Debug: Starting test_fromgrid")
-        # Set up parameters for the test
-        gridsize = params()['gridsize']
-        N = params()['N']
-        print(f"Debug: Test parameters - gridsize = {gridsize}, N = {N}")
-        # Create a sample input tensor in grid format
-        input_tensor = tf.random.uniform((1, gridsize, gridsize, N, N), dtype=tf.float32)
-        print(f"Debug: Input tensor shape = {input_tensor.shape}")
-        # Calculate the expected output shape
-        expected_shape = (1, N, N, 1)
-        print(f"Debug: Expected output shape = {expected_shape}")
-        # Run the _fromgrid function
-        output_tensor = _fromgrid(input_tensor)
-        print(f"Debug: Output tensor shape = {output_tensor.shape}")
-        # Check if the output shape matches the expected shape
-        self.assertEqual(output_tensor.shape, expected_shape)
-
-with tf.device('/CPU:0'):
-    def test_complexify_amp_phase():
-        # Test with real tensor
-        real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-        assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-    def test_get_mask():
-        input_tensor = tf.constant([[0.1, 0.5], [0.9, 0.0]], dtype=tf.float32)
-        expected_output = tf.constant([[0, 1], [1, 0]], dtype=tf.float32)
-        threshold = 0.2
-        output = get_mask(input_tensor, threshold)
-        self.assertTrue(tf.reduce_all(tf.equal(output, expected_output)))
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import numpy as np
-import tensorflow as tf
-from ptycho.tf_helper import combine_complex
-
-class TestCombineComplex(unittest.TestCase):
-
-def test_combine_complex():
-    amp = tf.constant([1.0, 2.0], dtype=tf.float32)
-    phi = tf.constant([0.0, np.pi], dtype=tf.float32)
-    expected_output = tf.constant([1.0 + 0j, -2.0 + 0j], dtype=tf.complex64)
-    output_complex = combine_complex(amp, phi)
-    # Use a tolerance when comparing complex numbers
-    tolerance = 1e-5
-    self.assertTrue(tf.reduce_all(tf.math.abs(output_complex - expected_output) < tolerance))
-
-def test_pad_and_diffract():
-    # Create a sample input tensor
-    input_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
-    input_tensor = tf.reshape(input_tensor, (1, 2, 2, 1))  # Reshape to (batch, height, width, channels)
-    # Define the desired output height and width
-    desired_height = 4
-    desired_width = 4
-    # Expected output tensor values based on provided output
-    expected_output_values = [0.0, 0.70710677, 1.0, 0.70710677, 0.35355338, 1.4577379, 1.9039432, 1.2747549, 0.5, 1.8027756]
-    # Run pad_and_diffract function
-    _, output_tensor = pad_and_diffract(input_tensor, desired_height, desired_width)
-    # Flatten the output tensor and slice the first 10 values for comparison
-    output_values = output_tensor.numpy().flatten()[:10]
-    # Check if the output values match the expected values within a tolerance
-    for expected, actual in zip(expected_output_values, output_values):
-        self.assertAlmostEqual(expected, actual, places=5)
-
-# Execute the tests
-if __name__ == "__main__":
-    test_complexify_function()
-    with tf.device('/CPU:0'):
-        # Force CPU execution because one of the first two tests fails on GPU
-        test_complexify_amp_phase()
-        test_get_mask()
-        test_combine_complex()
-        test_pad_and_diffract()
-
-if __name__ == '__main__':
-    unittest.main()
-
diff --git a/build/lib/build/lib/torch/tests/test_tf_helper.py b/build/lib/build/lib/torch/tests/test_tf_helper.py
deleted file mode 100644
index 20e2574..0000000
--- a/build/lib/build/lib/torch/tests/test_tf_helper.py
+++ /dev/null
@@ -1,326 +0,0 @@
-import torch
-import numpy as np
-from .tf_helper import *
-
-def test_get_mask():
-    input_tensor = torch.tensor([[1.0, 0.5, 0.8], [0.3, 0.9, 0.2]])
-    support_threshold = 0.6
-    expected_output = torch.tensor([[1.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
-    assert torch.all(torch.eq(get_mask(input_tensor, support_threshold), expected_output))
-
-def test_combine_complex():
-    amp = torch.tensor([[1.0, 0.5], [0.8, 0.3]])
-    phi = torch.tensor([[0.0, np.pi/2], [np.pi/4, np.pi]])
-    expected_output = torch.view_as_complex(torch.tensor([[[1.0, 0.0], [0.0, 0.5]], [[0.5657, 0.5657], [-0.3, 0.0]]]))
-    assert torch.allclose(combine_complex(amp, phi), expected_output)
-
-def test_pad_obj():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_obj(input_tensor, h, w), expected_output))
-
-def test__fromgrid():
-    params()['N'] = 2
-    img = torch.ones((1, 2, 2, 2, 2, 1))
-    expected_output = torch.ones((4, 2, 2, 1))
-    assert torch.all(torch.eq(_fromgrid(img), expected_output))
-
-def test__togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img = torch.ones((4, 2, 2, 1))
-    expected_output = torch.ones((1, 2, 2, 2, 2, 1))
-    assert torch.all(torch.eq(_togrid(img), expected_output))
-
-def test_togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img1 = torch.ones((4, 2, 2, 1))
-    img2 = torch.ones((4, 2, 2, 1))
-    expected_output = (torch.ones((1, 2, 2, 2, 2, 1)), torch.ones((1, 2, 2, 2, 2, 1)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(togrid(img1, img2), expected_output))
-
-def test__grid_to_channel():
-    params()['gridsize'] = 2
-    grid = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_grid_to_channel(grid), expected_output))
-
-def test_grid_to_channel():
-    params()['gridsize'] = 2
-    grid1 = torch.ones((1, 2, 2, 3, 3, 1))
-    grid2 = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = (torch.ones((1, 3, 3, 4)), torch.ones((1, 3, 3, 4)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(grid_to_channel(grid1, grid2), expected_output))
-
-def test__flat_to_channel():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    img = torch.ones((4, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_flat_to_channel(img), expected_output))
-
-def test__flat_to_channel_2():
-    params()['gridsize'] = 2
-    img = torch.ones((1, 3, 4, 1))
-    expected_output = torch.ones((1, 3, 4, 4))
-    assert torch.all(torch.eq(_flat_to_channel_2(img), expected_output))
-
-def test__channel_to_flat():
-    img = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3, 3, 1))
-    assert torch.all(torch.eq(_channel_to_flat(img), expected_output))
-
-def test__channel_to_patches():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    channel = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((1, 2, 2, 9))
-    assert torch.all(torch.eq(_channel_to_patches(channel), expected_output))
-
-def test_pad_patches():
-    imgs = torch.ones((1, 4, 4, 1))
-    padded_size = 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_patches(imgs, padded_size), expected_output))
-
-def test_pad():
-    imgs = torch.ones((1, 4, 4, 1))
-    size = 2
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad(imgs, size), expected_output))
-
-def test_trim_reconstruction():
-    x = torch.ones((1, 8, 8, 1))
-    N = 4
-    expected_output = torch.ones((1, 4, 4, 1))
-    assert torch.all(torch.eq(trim_reconstruction(x, N), expected_output))
-
-def test_flatten_offsets():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3))
-    assert torch.all(torch.eq(flatten_offsets(channels), expected_output))
-
-def test_pad_reconstruction():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 7, 7, 1))
-    assert torch.all(torch.eq(pad_reconstruction(channels), expected_output))
-
-def test_pad_and_diffract():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    padded_expected = torch.ones((1, 8, 8, 1))
-    input_expected = torch.ones((1, 8, 8, 1))
-    padded, input = pad_and_diffract(input_tensor, h, w)
-    assert torch.all(torch.eq(padded, padded_expected))
-    assert torch.allclose(input, input_expected, atol=1e-6)
-
-import torch
-from typing import Callable
-
-def test_mk_centermask():
-    inputs = torch.ones((2, 8, 8, 3))
-    N = 4
-    c = 3
-
-    # Test case 1: Check if the function returns the correct center mask when kind='center'
-    expected_center_mask = torch.zeros((2, 8, 8, 3))
-    expected_center_mask[:, 2:6, 2:6, :] = 1
-    center_mask = mk_centermask(inputs, N, c, kind='center')
-    assert torch.allclose(center_mask, expected_center_mask)
-
-    # Test case 2: Check if the function returns the correct border mask when kind='border'
-    expected_border_mask = torch.ones((2, 8, 8, 3))
-    expected_border_mask[:, 2:6, 2:6, :] = 0
-    border_mask = mk_centermask(inputs, N, c, kind='border')
-    assert torch.allclose(border_mask, expected_border_mask)
-
-    # Test case 3: Check if the function raises a ValueError when kind is not 'center' or 'border'
-    try:
-        mk_centermask(inputs, N, c, kind='invalid')
-        assert False, "Expected ValueError was not raised"
-    except ValueError:
-        pass
-
-def test_mk_norm():
-    channels = torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function returns the correct norm values
-    expected_norm = torch.ones((2, 8, 8, 4)) * 2 + 0.001
-    norm = mk_norm(channels, mock_fn_reassemble_real)
-    assert torch.allclose(norm, expected_norm)
-
-    # Test case 2: Check if the function handles different input shapes correctly
-    channels_2 = torch.ones((4, 16, 16, 8))
-    expected_norm_2 = torch.ones((4, 16, 16, 8)) * 2 + 0.001
-    norm_2 = mk_norm(channels_2, mock_fn_reassemble_real)
-    assert torch.allclose(norm_2, expected_norm_2)
-
-def test_reassemble_patches():
-    channels = torch.ones((2, 8, 8, 4)) + 1j * torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function correctly reassembles patches when average=False
-    expected_output = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output = reassemble_patches(channels, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the function correctly reassembles patches when average=True
-    expected_output_avg = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output_avg = reassemble_patches(channels, mock_fn_reassemble_real, average=True)
-    assert torch.allclose(output_avg, expected_output_avg)
-
-    # Test case 3: Check if the function handles complex input channels correctly
-    channels_real = torch.ones((2, 8, 8, 4))
-    channels_imag = torch.ones((2, 8, 8, 4)) * 2
-    channels_complex = torch.complex(channels_real, channels_imag)
-    expected_output_complex = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 4
-    output_complex = reassemble_patches(channels_complex, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output_complex, expected_output_complex)
-
-def test__reassemble_patches_position_real():
-    imgs = torch.ones((2, 8, 8, 4))
-    offsets_xy = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-    padded_size = 16
-
-    # Mock Translation class
-    class MockTranslation:
-        def __call__(self, inputs):
-            return inputs[0] + inputs[1].unsqueeze(-1).unsqueeze(-1)
-
-    # Mock helper functions
-    def mock_flatten_offsets(offsets_xy):
-        return offsets_xy.view(-1, 2)
-
-    def mock__channel_to_flat(imgs):
-        return imgs.view(-1, 8, 8, 1)
-
-    def mock_pad_patches(imgs_flat, padded_size):
-        return torch.ones((8, padded_size, padded_size, 1))
-
-    def mock__flat_to_channel(imgs_flat_bigN_translated, N):
-        return imgs_flat_bigN_translated.view(2, N, N, 4)
-
-    # Test case 1: Check if the function correctly reassembles patches when agg=True
-    expected_output_agg = torch.ones((2, padded_size, padded_size, 1)) * 4
-    output_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=True, padded_size=padded_size,
-                                                   flatten_offsets=mock_flatten_offsets,
-                                                   _channel_to_flat=mock__channel_to_flat,
-                                                   pad_patches=mock_pad_patches,
-                                                   Translation=MockTranslation(),
-                                                   _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg, expected_output_agg)
-
-    # Test case 2: Check if the function correctly reassembles patches when agg=False
-    expected_output_no_agg = torch.ones((2, padded_size, padded_size, 4))
-    output_no_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=False, padded_size=padded_size,
-                                                      flatten_offsets=mock_flatten_offsets,
-                                                      _channel_to_flat=mock__channel_to_flat,
-                                                      pad_patches=mock_pad_patches,
-                                                      Translation=MockTranslation(),
-                                                      _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_no_agg, expected_output_no_agg)
-
-    # Test case 3: Check if the function handles different input shapes and offsets correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    offsets_xy_2 = torch.tensor([[[1, 1], [2, 2], [3, 3], [4, 4]], [[5, 5], [6, 6], [7, 7], [8, 8]]])
-    padded_size_2 = 32
-    expected_output_agg_2 = torch.ones((4, padded_size_2, padded_size_2, 1)) * 8
-    output_agg_2 = _reassemble_patches_position_real(imgs_2, offsets_xy_2, agg=True, padded_size=padded_size_2,
-                                                     flatten_offsets=mock_flatten_offsets,
-                                                     _channel_to_flat=mock__channel_to_flat,
-                                                     pad_patches=mock_pad_patches,
-                                                     Translation=MockTranslation(),
-                                                     _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg_2, expected_output_agg_2)
-
-def test_mk_reassemble_position_real():
-    input_positions = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-
-    # Mock _reassemble_patches_position_real function
-    def mock__reassemble_patches_position_real(imgs, offsets_xy, **kwargs):
-        return imgs + offsets_xy.sum()
-
-    # Test case 1: Check if the function returns a callable that correctly reassembles patches
-    imgs = torch.ones((2, 8, 8, 4))
-    expected_output = imgs + 10
-    reassemble_fn = mk_reassemble_position_real(input_positions)
-    output = reassemble_fn(imgs)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the returned callable handles different input shapes and keyword arguments correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    expected_output_2 = imgs_2 + 10
-    output_2 = reassemble_fn(imgs_2)
-    assert torch.allclose(output_2, expected_output_2)
-
-    import torch
-import numpy as np
-
-def test_translate():
-    # Test case 1: Single input tensor
-    tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    output = translate(tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
-    # Test case 2: Batched input tensors
-    batch_size = 2
-    channels = 3
-    height = 4
-    width = 5
-    imgs = torch.randn(batch_size, channels, height, width)
-    offsets = torch.tensor([[1.0, -1.0], [-2.0, 2.0]], dtype=torch.float32)
-    expected_output = torch.tensor([
-        [
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.1132, 0.1562, 0.1697],
-             [0.0000, 0.7470, 0.8155, 0.1878, 0.4034],
-             [0.0000, 1.3378, 0.9931, 0.2400, 0.2372]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.6398, 0.8829, 0.9593],
-             [0.0000, 1.0086, 1.1025, 0.2537, 0.5450],
-             [0.0000, 0.8617, 0.6401, 0.1547, 0.1529]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.2566, 0.3541, 0.3848],
-             [0.0000, 0.5297, 0.5783, 0.1331, 0.2861],
-             [0.0000, 0.6287, 0.4674, 0.1129, 0.1117]]
-        ],
-        [
-            [[0.0000, 0.9102, 0.8985, 0.0256, 0.1092],
-             [0.0000, 0.0082, 0.1560, 0.1651, 0.1176],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.6713, 0.6630, 0.0189, 0.0806],
-             [0.0000, 0.0118, 0.2246, 0.2374, 0.1691],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.5032, 0.4970, 0.0142, 0.0604],
-             [0.0000, 0.0117, 0.2213, 0.2342, 0.1667],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]
-        ]
-    ], dtype=torch.float32)
-    output = translate(imgs, offsets)
-    assert torch.allclose(output, expected_output, atol=1e-4)
-
-    # Test case 3: Complex input tensor
-    real_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    imag_tensor = torch.tensor([[0.5, 1.0, 1.5], [2.0, 2.5, 3.0]], dtype=torch.float32)
-    complex_tensor = torch.complex(real_tensor, imag_tensor)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_real_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    expected_imag_output = torch.tensor([[2.5, 3.0, 0.0], [1.0, 1.5, 0.0]], dtype=torch.float32)
-    expected_output = torch.complex(expected_real_output, expected_imag_output)
-    output = translate(complex_tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
diff --git a/build/lib/build/lib/torch/tests/tf_helper.py b/build/lib/build/lib/torch/tests/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/torch/tests/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/build/lib/torch/tf_helper.py b/build/lib/build/lib/torch/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/build/lib/torch/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/diagram/lett.png b/build/lib/diagram/lett.png
deleted file mode 100644
index 4dc18aa..0000000
Binary files a/build/lib/diagram/lett.png and /dev/null differ
diff --git a/build/lib/diagram/pinn.py b/build/lib/diagram/pinn.py
deleted file mode 100644
index 2e5d21a..0000000
--- a/build/lib/diagram/pinn.py
+++ /dev/null
@@ -1,293 +0,0 @@
-
-import numpy as np
-import sys
-sys.path.append('../')
-from pycore.tikzeng import *
-
-offset = -1.5
-scale = .3
-decoder_offset = 0
-def ppos(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    nums = np.array([float(n) for n in nums])
-    nums[0] += decoder_offset
-    new = str(tuple(n * scale for n in nums))
-    print(new)
-    return new
-
-def ppos_encoder(num_tuple_s):
-    nums = num_tuple_s.replace(' ', '').replace('(', '').replace(')', '')
-    nums = nums.split(',')
-    new = str(tuple(float(n) * scale for n in nums))
-    print(new)
-    return new
-
-## vim macro
-"""/\dcw{}jk?codek$a"jkpa", jk/\a\d"""
-patch_size = 26
-# size of the probe-illuminated patches
-probe_scale = 1.2
-zoff = -10 #* scale
-xext = 31
-xpatch = 31.2
-patch_width = .5
-diff_width = .5
-diff_spacing = 7 * probe_scale
-xdiff = 37
-xdiff2 = 44
-probe_size = 32
-
-diff2_spacing = .2
-diff2_dx = 2
-diff2_dy = .5
-diff2_dz = 0.5
-diff2_width = 3
-amp_suffix = '_1'
-phase_suffix = '_2'
-
-legend_offset_y = -20
-legend_boxsize = 8
-legend_width = 0
-legend_spacing_x = 6 / (2 * scale)
-legend_offset_x = -7
-legend_spacing_y = -4 / (2 * scale)
-legend_patch_width = .1
-offset2 = offset * (legend_boxsize / 32)
-
-img_path_fmt = '../../notebooks/images/{}'
-
-input1 = img_path_fmt.format('in1.png')
-input2 = img_path_fmt.format('in2.png')
-input3 = img_path_fmt.format('in3.png')
-input4 = img_path_fmt.format('in4.png')
-
-output1 = img_path_fmt.format('out1.png')
-output2 = img_path_fmt.format('out2.png')
-output3 = img_path_fmt.format('out3.png')
-output4 = img_path_fmt.format('out4.png')
-
-patch1_path = img_path_fmt.format('patch1.png')
-patch2_path = img_path_fmt.format('patch2.png')
-patch3_path = img_path_fmt.format('patch3.png')
-patch4_path = img_path_fmt.format('patch4.png')
-
-phase_path = img_path_fmt.format('phase.png')
-amp_path = img_path_fmt.format('amp.png')
-full_obj_path = img_path_fmt.format('full_obj.png')
-
-im_size = 13 * scale
-inp_x = -7
-outp_x = 50
-
-encoder = [
-    to_input(input1, to=ppos("({},{},{})".format(inp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(input2, to=ppos("({},{},{})".format(inp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(input3, to=ppos("({},{},{})".format(inp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(input4, to=ppos("({},{},{})".format(inp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-    to_ConvRelu("conv11", '', 64, offset=ppos_encoder("(0,0,0)"), to=ppos_encoder("(0,0,0)"),
-        height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_ConvRelu("conv12", '', '', offset=ppos_encoder("(.4,0,0)"), to=ppos_encoder("(0,0,0)"), height=64 * scale, depth=64 * scale, width=2 * scale),
-    to_Pool("pool1", offset=ppos_encoder("(0,0,0)"), to="(conv12-east)", height=32* scale, depth=32* scale),
-
-    to_ConvRelu("conv21", '', '', offset=ppos_encoder("(5,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_ConvRelu("conv22", '', 128, offset=ppos_encoder("(5.8,0,0)"), to=ppos_encoder("(0,0,0)"), height=32* scale, depth=32* scale, width=4 * scale),
-    to_Pool("pool2", offset=ppos_encoder("(0,0,0)"), to="(conv22-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool1", "conv21"),
-
-    to_ConvRelu("conv31", '', 256, offset=ppos_encoder("(10,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_ConvRelu("conv32", '', '', offset=ppos_encoder("(11.6,0,0)"), to=ppos_encoder("(0,0,0)"), height=16* scale, depth=16* scale, width=8 * scale),
-    to_Pool("pool3", offset=ppos_encoder("(0,0,0)"), to="(conv32-east)", height=8* scale, depth=8* scale),
-    to_connection( "pool2", "conv31"),
-]
-
-def last_decoder(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_Sigmoid("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = 'A(r)')
-    elif pos_sign == -1:
-        return to_Tanh("last" + name_suffix, '', '1', offset=ppos("(23.2,0,0)"),
-            to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-            depth=32* scale, width=2 * scale,
-            caption = r'$\bm{\phi(r)}$')
-    else:
-        raise ValueError
-
-def last_decoder_img(pos_sign, name_suffix):
-    if pos_sign == 1:
-        return to_input(amp_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    elif pos_sign == -1:
-        return to_input(phase_path,
-            to=ppos("(24.2,{},0)".format(pos_sign * zoff)), width = im_size / 2,
-            height = im_size / 2)
-    else:
-        raise ValueError
-
-def mk_decoder(name_suffix = '0', pos_sign = 1):
-    return [
-    to_ConvRelu("up11" + name_suffix, '', 256, offset=ppos("(12,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_ConvRelu("up12" + name_suffix, '', '', offset=ppos("(13.6,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=8* scale, depth=8* scale, width=8 * scale),
-    to_UnPool("unpool1" + name_suffix, offset=ppos("(0,0,0)"), to="(up12" + name_suffix + "-east)", height=16* scale, depth=16* scale),
-    to_connection( "pool3", "up11" + name_suffix),
-
-    to_ConvRelu("up21" + name_suffix, '', 128, offset=ppos("(18,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_ConvRelu("up22" + name_suffix, '', '', offset=ppos("(18.8,0,0)"), to=ppos("(0,{},0)".format(pos_sign * zoff)), height=16* scale, depth=16* scale, width=4 * scale),
-    to_UnPool("unpool2" + name_suffix, offset=ppos("(0,0,0)"), to="(up22" + name_suffix + "-east)", height=32* scale, depth=32* scale),
-    to_connection( "unpool1" + name_suffix, "up21" + name_suffix),
-
-#    to_Conv("up31" + name_suffix, '', 1, offset=ppos("(23,0,0)"),
-#        to=ppos("(0,{},0)".format(pos_sign * zoff)), height=32* scale,
-#        depth=32* scale, width=2 * scale),
-    last_decoder(pos_sign, name_suffix),
-    last_decoder_img(pos_sign, name_suffix),
-    to_connection( "unpool2" + name_suffix, last + name_suffix)
-    #to_connection( "unpool2" + name_suffix, "up31" + name_suffix)
-    ]
-#last = "up31"
-last = "last"
-
-forward_map =\
-[
-    to_Sum("sum1", offset=ppos("(27.5,0,0)"), to=ppos("(0, 0, 0)"), radius=2.5 * scale, opacity=0.6),
-    to_connection(last+ amp_suffix, "sum1"),
-    to_connection(last+ phase_suffix, "sum1"),
-    to_Extract("extract1", '', 4, offset=ppos("({},0,0)".format(xext)),
-        to=ppos("(0,0,0)"), height=64* scale / 2, depth=64* scale / 2, width=2* scale,
-        caption = ''),
-    to_input(full_obj_path, to = ppos("({},0,0)".format(xext)), width = im_size,
-        height = im_size),
-    to_connection("sum1", "extract1"),
-    to_Patch("patch1", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch4", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch2", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale),
-    to_Patch("patch3", '', '', offset=ppos("({},0,0)".format(xpatch)),
-        to=ppos("(0,{},{})".format(-offset, -offset)), height=patch_size * scale, depth=patch_size * scale,
-        width=patch_width * scale)] +\
-    to_Illumination("probe2", patch2_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * 1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch2", "probe2")] +\
-    to_Illumination("probe3", patch3_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * .5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch3", "probe3")] +\
-    to_Illumination("probe1", patch1_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2) +\
-    [to_connection( "patch1", "probe1")] +\
-    to_Illumination("probe4", patch4_path, '', '', offset=ppos("(0,0,0)"),
-        to=ppos("({},{},0)".format(xdiff, diff_spacing * -1.5)), height=probe_size * scale, depth=probe_size * scale,
-        width=diff_width * scale, im_size = probe_scale * im_size / 2,
-        caption = r'$\bm{\times}$ Probe${(\bm{r - r_i})}$') +\
-    [to_connection( "patch4", "probe4")] +\
-    [
-#        to_Diffraction("diff1", '', 4, offset=ppos("({},0,0)".format(xdiff2)),
-#        to=ppos("({},{},{})".format(diff2_dx * 1.5, diff2_dy * 1.5, diff2_dz * 1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-#    to_Diffraction("diff2", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing)),
-#        to=ppos("({},{},{})".format(diff2_dx * .5, diff2_dy * .5, diff2_dz * .5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_Diffraction("diff3", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 2)),
-        to=ppos("({},{},{})".format(diff2_dx * -.5, diff2_dy * -.5, diff2_dz * -.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-        caption = ''),
-#    to_Diffraction("diff4", '', 4, offset=ppos("({},0,0)".format(xdiff2 + diff2_spacing * 3)),
-#        to=ppos("({},{},{})".format(diff2_dx * -1.5, diff2_dy * -1.5, diff2_dz * -1.5)), height=64* scale, depth=64* scale, width=diff2_width* scale,
-#        caption = ''),
-    to_connection("probe2", "diff3"),#top
-    to_connection("probe1", "diff3"),
-    to_connection("probe3", "diff3"),
-    to_connection("probe4", "diff3"),# bottom
-#    to_connection("probe2", "diff1"),#top
-#    to_connection("probe1", "diff3"),
-#    to_connection("probe3", "diff2"),
-#    to_connection("probe4", "diff4"),# bottom
-
-    to_input(output1, to=ppos("({},{},{})".format(outp_x, diff2_dy * 1.5, diff2_dz * 1.5)), width = im_size, height = im_size),
-    to_input(output2, to=ppos("({},{},{})".format(outp_x, diff2_dy * .5, diff2_dz * .5)), width = im_size, height = im_size),
-    to_input(output3, to=ppos("({},{},{})".format(outp_x, diff2_dy * -.5, diff2_dz * -.5)), width = im_size, height = im_size),
-    to_input(output4, to=ppos("({},{},{})".format(outp_x, diff2_dy * -1.5, diff2_dz * -1.5)), width = im_size, height = im_size),
-
-    to_ConvRelu("conv_relu_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~ReLU($\cdot$)""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~ReLU($\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Pool("pool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x, legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""AvgPool2D($\cdot$)"""),
-
-    to_UnPool("unpool_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-        legend_offset_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Upsample($\cdot$)"""),
-
-    to_Tanh("tanh_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 0,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~$i \bm{\pi \tanh(\cdot)}$""",
-        #caption = r"""Conv2D($\cdot$)$\linebreak\rightarrow$~$i \pi \tanh(\cdot$)""",
-        s_filer = '', n_filer = ''),
-
-    to_Sigmoid("sigmoid_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 1,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Conv2D($\cdot$)$\linebreak$~Sigmoid$(\cdot)$""",
-        s_filer = '', n_filer = ''),
-
-    to_Patch("patch1_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch4_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch2_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale),
-    to_Patch("patch3_legend", '', '', offset=ppos("({},{},0)".format(legend_offset_x + legend_spacing_x * 2,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos("(0,{},{})".format(-offset2, -offset2)), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_patch_width * scale,
-        caption = r"""Crop$(\cdot)$\linebreak Shift$(\cdot)$""",),
-        #caption = r"""Illuminate$(\cdot)$""",),
-
-    to_Diffraction("diff_legend", offset=ppos_encoder("({},{},0)".format(legend_offset_x + legend_spacing_x * 3,
-            legend_offset_y + legend_spacing_y)),
-        to=ppos_encoder("(0,0,0)"), height=legend_boxsize * scale, depth=legend_boxsize * scale,
-        width=legend_width * scale,
-        caption = r"""Diffract$(\bm{\cdot})$ \linebreak $\sim $Poisson$(\bm{\cdot}^2)$""",
-        s_filer = '', n_filer = ''),
-
-]
-
-arch = [to_head( '..' ),
-    to_cor(),
-    to_begin()] +\
-    encoder + mk_decoder(amp_suffix, pos_sign = 1) +\
-    mk_decoder(phase_suffix, pos_sign = -1) + forward_map +\
-    [to_end()]
-
-def main():
-    namefile = str(sys.argv[0]).split('.')[0]
-    to_generate(arch, namefile + '.tex' )
-
-if __name__ == '__main__':
-    main()
diff --git a/build/lib/diagram/pinn_letters.pdf b/build/lib/diagram/pinn_letters.pdf
deleted file mode 100644
index ed004b4..0000000
Binary files a/build/lib/diagram/pinn_letters.pdf and /dev/null differ
diff --git a/build/lib/diagram/pinn_squidward.pdf b/build/lib/diagram/pinn_squidward.pdf
deleted file mode 100644
index 45f6876..0000000
Binary files a/build/lib/diagram/pinn_squidward.pdf and /dev/null differ
diff --git a/build/lib/diagram/tikzeng.py b/build/lib/diagram/tikzeng.py
deleted file mode 100644
index 4de56da..0000000
--- a/build/lib/diagram/tikzeng.py
+++ /dev/null
@@ -1,374 +0,0 @@
-
-import os
-
-def to_head( projectpath ):
-    pathlayers = os.path.join( projectpath, 'layers/' ).replace('\\', '/')
-    return r"""
-\documentclass[border=8pt, multi, tikz]{standalone}
-\usepackage{import}
-\usepackage{bm}
-\usepackage{transparent}
-\subimport{"""+ pathlayers + r"""}{init}
-\usetikzlibrary{positioning}
-\usetikzlibrary{3d} %for including external image
-"""
-
-def to_cor():
-    return r"""
-\def\ConvColor{rgb:yellow,5;red,2.5;white,5}
-\def\ConvReluColor{rgb:yellow,5;red,5;white,5}
-\def\PoolColor{rgb:red,1;black,0.3}
-\def\UnpoolColor{rgb:blue,2;green,1;black,0.3}
-\def\FcColor{rgb:blue,5;red,2.5;white,5}
-\def\FcReluColor{rgb:blue,5;red,5;white,4}
-\def\SoftmaxColor{rgb:magenta,5;black,7}
-\def\SumColor{rgb:blue,5;green,15}
-\def\DcnvColor{rgb:blue,5;green,2.5;white,5}
-"""
-
-def to_begin():
-    return r"""
-\newcommand{\copymidarrow}{\tikz \draw[-Stealth,line width=0.8mm,draw={rgb:blue,4;red,1;green,1;black,3}] (-0.3,0) -- ++(0.3,0);}
-
-\begin{document}
-\begin{tikzpicture}
-\tikzstyle{connection}=[ultra thick,every node/.style={sloped,allow upside down},draw=\edgecolor,opacity=0.7]
-\tikzstyle{copyconnection}=[ultra thick,every node/.style={sloped,allow upside down},draw={rgb:blue,4;red,1;green,1;black,3},opacity=0.7]
-"""
-
-# layers definition
-
-def to_input( pathfile, to='(-3,0,0)', width=8, height=8, name="temp" ):
-    return r"""
-\node[canvas is zy plane at x=0] (""" + name + """) at """+ to +""" {\includegraphics[width="""+ str(width)+"cm"+""",height="""+ str(height)+"cm"+"""]{"""+ pathfile +"""}};
-"""
-
-# Conv
-def to_Conv( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_ConvRelu( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +r""",
-        xlabel={{"""+ str(n_filer) +""", }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# Conv,Conv,relu
-# Bottleneck
-def to_ConvConvRelu( name, s_filer=256, n_filer=(64,64), offset="(0,0,0)", to="(0,0,0)", width=(2,2), height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name +""",
-        caption="""+ caption +""",
-        xlabel={{ """+ str(n_filer[0]) +""", """+ str(n_filer[1]) +""" }},
-        zlabel="""+ str(s_filer) +""",
-        fill=\ConvColor,
-        bandfill=\ConvReluColor,
-        height="""+ str(height) +""",
-        width={ """+ str(width[0]) +""" , """+ str(width[1]) +""" },
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# Pool
-def to_Pool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+name+""",
-        caption="""+ caption +r""",
-        fill=\PoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# unpool4,
-def to_UnPool(name, offset="(0,0,0)", to="(0,0,0)", width=1, height=32, depth=32, opacity=0.5, caption=" "):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {Box={
-        name="""+ name +r""",
-        caption="""+ caption +r""",
-        fill=\UnpoolColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_ConvRes( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Pad( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sigmoid( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:violet,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Tanh( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Patch( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.1, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:black,2},
-        opacity="""+ str(opacity) +""",
-        bandopacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-# bandfill={rgb:blue,1;red,2},
-
-def to_Extract( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)",
-        width=6, height=40, depth=40, opacity=0.2, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;black,3},
-        bandfill={rgb:white,1;green,2},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-def to_Illumination( name, filepath, s_filer=256, n_filer=64,
-    offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-    opacity=0.2, caption=" " , im_size = 4):
-    return [r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:white,1;blue,3},
-        bandfill={rgb:black,1;blue,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-""",
-    to_input(filepath, to = to, width = im_size, height = im_size)]
-
-def to_Diffraction( name, s_filer=256, n_filer=64, offset="(0,0,0)", to="(0,0,0)", width=6, height=40, depth=40,
-        opacity=0.4, caption=" " ):
-    return r"""
-\pic[shift={ """+ offset +""" }] at """+ to +"""
-    {RightBandedBox={
-        name="""+ name + """,
-        caption="""+ caption + """,
-        xlabel={{ """+ str(n_filer) + """, }},
-        zlabel="""+ str(s_filer) +r""",
-        fill={rgb:violet,1;red,3},
-        bandfill={rgb:white,1;red,3},
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-
-# ConvSoftMax
-def to_ConvSoftMax( name, s_filer=40, offset="(0,0,0)", to="(0,0,0)", width=1, height=40, depth=40, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-# SoftMax
-def to_SoftMax( name, s_filer=10, offset="(0,0,0)", to="(0,0,0)", width=1.5, height=3, depth=25, opacity=0.8, caption=" " ):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Box={
-        name=""" + name +""",
-        caption="""+ caption +""",
-        xlabel={{" ","dummy"}},
-        zlabel="""+ str(s_filer) +""",
-        fill=\SoftmaxColor,
-        opacity="""+ str(opacity) +""",
-        height="""+ str(height) +""",
-        width="""+ str(width) +""",
-        depth="""+ str(depth) +"""
-        }
-    };
-"""
-
-def to_Sum( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=""" + r'$\times$' + """
-        }
-    };
-"""
-
-def to_Prod( name, offset="(0,0,0)", to="(0,0,0)", radius=2.5, opacity=0.6):
-    return r"""
-\pic[shift={"""+ offset +"""}] at """+ to +"""
-    {Ball={
-        name=""" + name +""",
-        fill=\SumColor,
-        opacity="""+ str(opacity) +""",
-        radius="""+ str(radius) +""",
-        logo=$x$
-        }
-    };
-"""
-
-# \times?
-
-def to_connection( of, to):
-    return r"""
-\draw [connection]  ("""+of+"""-east)    -- node {\midarrow} ("""+to+"""-west);
-"""
-
-def to_skip( of, to, pos=1.25):
-    return r"""
-\path ("""+ of +"""-southeast) -- ("""+ of +"""-northeast) coordinate[pos="""+ str(pos) +"""] ("""+ of +"""-top) ;
-\path ("""+ to +"""-south)  -- ("""+ to +"""-north)  coordinate[pos="""+ str(pos) +"""] ("""+ to +"""-top) ;
-\draw [copyconnection]  ("""+of+"""-northeast)
--- node {\copymidarrow}("""+of+"""-top)
--- node {\copymidarrow}("""+to+"""-top)
--- node {\copymidarrow} ("""+to+"""-north);
-"""
-
-def to_end():
-    return r"""
-\end{tikzpicture}
-\end{document}
-"""
-
-def to_generate( arch, pathname="file.tex" ):
-    with open(pathname, "w") as f:
-        for c in arch:
-            print(c)
-            f.write( c )
-
diff --git a/build/lib/docs/mermaid.txt b/build/lib/docs/mermaid.txt
deleted file mode 100644
index 51d334f..0000000
--- a/build/lib/docs/mermaid.txt
+++ /dev/null
@@ -1,1251 +0,0 @@
-%% Consolidated module-level mermaid diagrams
-
-graph TD
-    %% model.py
-    subgraph model[model.py]
-        ProbeIllumination_init[ProbeIllumination.__init__()]
-        ProbeIllumination_call[ProbeIllumination.call()]
-        IntensityScaler_init[IntensityScaler.__init__()]
-        IntensityScaler_call[IntensityScaler.call()]
-        IntensityScaler_inv_init[IntensityScaler_inv.__init__()]
-        IntensityScaler_inv_call[IntensityScaler_inv.call()]
-        scale[scale()]
-        inv_scale[inv_scale()]
-        Conv_Pool_block[Conv_Pool_block()]
-        Conv_Up_block[Conv_Up_block()]
-        create_encoder[create_encoder()]
-        create_decoder_base[create_decoder_base()]
-        get_resolution_scale_factor[get_resolution_scale_factor()]
-        create_decoder_last[create_decoder_last()]
-        create_decoder_phase[create_decoder_phase()]
-        create_decoder_amp[create_decoder_amp()]
-        create_autoencoder[create_autoencoder()]
-        get_amp_activation[get_amp_activation()]
-        prepare_inputs[prepare_inputs()]
-        prepare_outputs[prepare_outputs()]
-        train[train()]
-        print_model_diagnostics[print_model_diagnostics()]
-
-        %% Internal dependencies
-        create_encoder --> Conv_Pool_block
-        create_decoder_base --> Conv_Up_block
-        create_decoder_phase --> create_decoder_base
-        create_decoder_phase --> create_decoder_last
-        create_decoder_amp --> create_decoder_base
-        create_decoder_amp --> create_decoder_last
-        create_decoder_amp --> get_amp_activation
-        create_autoencoder --> create_encoder
-        create_autoencoder --> create_decoder_amp
-        create_autoencoder --> create_decoder_phase
-        train --> prepare_inputs
-        train --> prepare_outputs
-
-        %% External dependencies
-        ProbeIllumination_init -.-> ".params: cfg.get()"
-        ProbeIllumination_call -.-> ".tf_helper: hh.combine_complex"
-        ProbeIllumination_call -.-> ".params: cfg.get()"
-        create_encoder -.-> ".params: cfg.get()"
-        create_decoder_base -.-> ".params: cfg.get()"
-        create_decoder_last -.-> ".params: cfg.get()"
-        create_decoder_last -.-> ".tf_helper: hh.mk_centermask"
-        create_decoder_phase -.-> ".params: cfg.get()"
-        create_decoder_amp -.-> ".params: cfg.get()"
-        get_amp_activation -.-> ".params: cfg.get()"
-        prepare_inputs -.-> ".params: cfg.get()"
-        prepare_outputs -.-> ".tf_helper: hh.center_channels"
-        prepare_outputs -.-> ".params: cfg.get()"
-        train -.-> ".params: params()"
-    end
-
-    %% train_pinn.py
-    subgraph train_pinn[train_pinn.py]
-        train_pinn_train[train()]
-        train_eval[train_eval()]
-        eval[eval()]
-        calculate_intensity_scale[calculate_intensity_scale()]
-
-        %% Internal dependencies
-        train_eval --> train_pinn_train
-        train_eval --> eval
-        train_pinn_train --> calculate_intensity_scale
-
-        %% External dependencies
-        train_pinn_train -.-> ".params: params.set()"
-        train_pinn_train -.-> ".probe: probe.set_probe_guess()"
-        train_pinn_train -.-> ".model: model.train()"
-        eval -.-> ".probe: probe.set_probe_guess()"
-        eval -.-> ".model: model.predict()"
-        eval -.-> ".data_preprocessing: reassemble()"
-        calculate_intensity_scale -.-> ".params: params.get()"
-    end
-
-%% loader.py
-subgraph loader[loader.py]
-    PtychoDataset_init[PtychoDataset.__init__()]
-    PtychoDataContainer_init[PtychoDataContainer.__init__()]
-    PtychoDataContainer_repr[PtychoDataContainer.__repr__()]
-    PtychoDataContainer_from_raw_data_without_pc[PtychoDataContainer.from_raw_data_without_pc()]
-    split_data[split_data()]
-    split_tensor[split_tensor()]
-    load[load()]
-    crop[crop()]
-    get_gt_patch[get_gt_patch()]
-    load_xpp_npz[load_xpp_npz()]
-
-    %% Internal dependencies
-    PtychoDataContainer_from_raw_data_without_pc --> load
-    load --> split_tensor
-    load --> split_data
-    get_gt_patch --> crop
-
-    %% External dependencies
-    PtychoDataContainer_init -.-> ".tf_helper: hh.combine_complex"
-    PtychoDataContainer_from_raw_data_without_pc -.-> ".params: cfg.get()"
-    PtychoDataContainer_from_raw_data_without_pc -.-> ".raw_data: RawData.from_coords_without_pc"
-    load -.-> ".diffsim: datasets.scale_nphotons"
-    load -.-> ".probe: probe.get_probe_mask_real"
-    get_gt_patch -.-> ".tf_helper: hh.translate"
-    load_xpp_npz -.-> ".raw_data: RawData"
-end
-
-%% raw_data.py
-subgraph raw_data[raw_data.py]
-    RawData_init[RawData.__init__()]
-    RawData_str[RawData.__str__()]
-    RawData_to_file[RawData.to_file()]
-    RawData_from_file[RawData.from_file()]
-    RawData_from_files[RawData.from_files()]
-    RawData_generate_grouped_data[RawData.generate_grouped_data()]
-    RawData_check_data_validity[RawData._check_data_validity()]
-    RawData_from_coords_without_pc[RawData.from_coords_without_pc()]
-    RawData_from_simulation[RawData.from_simulation()]
-    get_neighbor_self_indices[get_neighbor_self_indices()]
-    get_neighbor_indices[get_neighbor_indices()]
-    sample_rows[sample_rows()]
-    get_relative_coords[get_relative_coords()]
-    calculate_relative_coords[calculate_relative_coords()]
-    group_coords[group_coords()]
-    get_neighbor_diffraction_and_positions[get_neighbor_diffraction_and_positions()]
-    get_image_patches[get_image_patches()]
-    normalize_data[normalize_data()]
-
-    %% Internal dependencies
-    RawData_init --> RawData_check_data_validity
-    RawData_from_file --> RawData_init
-    RawData_from_files --> RawData_from_file
-    RawData_generate_grouped_data --> get_neighbor_diffraction_and_positions
-    RawData_from_coords_without_pc --> RawData_init
-    calculate_relative_coords --> group_coords
-    calculate_relative_coords --> get_relative_coords
-    group_coords --> get_neighbor_self_indices
-    group_coords --> get_neighbor_indices
-    group_coords --> sample_rows
-    get_neighbor_diffraction_and_positions --> group_coords
-    get_neighbor_diffraction_and_positions --> get_relative_coords
-    get_neighbor_diffraction_and_positions --> normalize_data
-
-    %% External dependencies
-    RawData_generate_grouped_data -.-> ".params: params.get()"
-    RawData_from_simulation -.-> ".diffsim: datasets.illuminate_and_diffract"
-    RawData_from_simulation -.-> ".diffsim: datasets.scale_nphotons"
-    RawData_from_simulation -.-> ".tf_helper: hh.combine_complex"
-    get_image_patches -.-> ".params: params.get()"
-    get_image_patches -.-> ".tf_helper: hh.pad"
-    get_image_patches -.-> ".tf_helper: hh.translate"
-    group_coords -.-> ".params: params.get()"
-end
-
-    %% tf_helper.py
-    subgraph tf_helper[tf_helper.py]
-        get_mask[get_mask()]
-        combine_complex[combine_complex()]
-        pad_obj[pad_obj()]
-        pad_and_diffract[pad_and_diffract()]
-        _fromgrid[_fromgrid()]
-        _togrid[_togrid()]
-        togrid[togrid()]
-        _grid_to_channel[_grid_to_channel()]
-        grid_to_channel[grid_to_channel()]
-        _flat_to_channel[_flat_to_channel()]
-        _flat_to_channel_2[_flat_to_channel_2()]
-        _channel_to_flat[_channel_to_flat()]
-        _channel_to_patches[_channel_to_patches()]
-        channel_to_flat[channel_to_flat()]
-        extract_patches[extract_patches()]
-        extract_outer[extract_outer()]
-        extract_inner_grid[extract_inner_grid()]
-        extract_nested_patches[extract_nested_patches()]
-        mk_extract_inner_position[mk_extract_inner_position()]
-        extract_nested_patches_position[extract_nested_patches_position()]
-        extract_patches_inverse[extract_patches_inverse()]
-        reassemble_patches_real[reassemble_patches_real()]
-        pad_patches[pad_patches()]
-        pad[pad()]
-        trim_reconstruction[trim_reconstruction()]
-        extract_patches_position[extract_patches_position()]
-        center_channels[center_channels()]
-        is_complex_tensor[is_complex_tensor()]
-        complexify_helper[complexify_helper()]
-        separate_real_imag[separate_real_imag()]
-        combine_real_imag[combine_real_imag()]
-        separate_amp_phase[separate_amp_phase()]
-        translate[translate()]
-        Translation_call[Translation.call()]
-        flatten_offsets[flatten_offsets()]
-        pad_reconstruction[pad_reconstruction()]
-        _reassemble_patches_position_real[_reassemble_patches_position_real()]
-        mk_centermask[mk_centermask()]
-        mk_norm[mk_norm()]
-        reassemble_patches[reassemble_patches()]
-        reassemble_whole_object[reassemble_whole_object()]
-        mk_reassemble_position_real[mk_reassemble_position_real()]
-        preprocess_objects[preprocess_objects()]
-        reassemble_nested_average[reassemble_nested_average()]
-        gram_matrix[gram_matrix()]
-        high_pass_x_y[high_pass_x_y()]
-        perceptual_loss[perceptual_loss()]
-        meanSquaredLoss[meanSquaredLoss()]
-        masked_MAE_loss[masked_MAE_loss()]
-        total_variation_complex[total_variation_complex()]
-        total_variation[total_variation()]
-        complex_mae[complex_mae()]
-        masked_mae[masked_mae()]
-        realspace_loss[realspace_loss()]
-
-        %% Internal dependencies
-        pad_and_diffract --> pad_obj
-        togrid --> _togrid
-        grid_to_channel --> _grid_to_channel
-        channel_to_flat --> _channel_to_flat
-        extract_outer --> extract_patches
-        extract_outer --> _fromgrid
-        extract_outer --> _grid_to_channel
-        extract_inner_grid --> extract_patches
-        extract_nested_patches --> extract_outer
-        extract_nested_patches --> _fromgrid
-        extract_nested_patches --> _grid_to_channel
-        extract_nested_patches_position --> extract_nested_patches
-        extract_nested_patches_position --> mk_extract_inner_position
-        reassemble_patches_real --> _channel_to_patches
-        reassemble_patches_real --> extract_patches_inverse
-        extract_patches_position --> flatten_offsets
-        extract_patches_position --> _channel_to_flat
-        extract_patches_position --> trim_reconstruction
-        center_channels --> _channel_to_flat
-        center_channels --> flatten_offsets
-        center_channels --> _flat_to_channel
-        Translation_call --> translate
-        flatten_offsets --> _channel_to_flat
-        pad_reconstruction --> _channel_to_flat
-        pad_reconstruction --> pad_patches
-        _reassemble_patches_position_real --> flatten_offsets
-        _reassemble_patches_position_real --> _channel_to_flat
-        _reassemble_patches_position_real --> pad_patches
-        _reassemble_patches_position_real --> _flat_to_channel
-        mk_norm --> mk_centermask
-        reassemble_patches --> mk_norm
-        reassemble_whole_object --> reassemble_patches
-        mk_reassemble_position_real --> _reassemble_patches_position_real
-        preprocess_objects --> extract_nested_patches
-        preprocess_objects --> extract_nested_patches_position
-        preprocess_objects --> channel_to_flat
-        reassemble_nested_average --> _togrid
-        reassemble_nested_average --> trim_reconstruction
-        reassemble_nested_average --> extract_patches_inverse
-        perceptual_loss --> gram_matrix
-        perceptual_loss --> meanSquaredLoss
-        total_variation_complex --> high_pass_x_y
-        total_variation --> total_variation_complex
-        masked_MAE_loss --> trim_reconstruction
-        masked_MAE_loss --> reassemble_patches
-        masked_mae --> mk_centermask
-        realspace_loss --> mk_centermask
-        realspace_loss --> total_variation
-        realspace_loss --> complex_mae
-
-        %% External dependencies
-        _fromgrid -.-> ".params: params()"
-        _togrid -.-> ".params: params()"
-        _grid_to_channel -.-> ".params: params()"
-        _flat_to_channel -.-> ".params: params()"
-        _flat_to_channel_2 -.-> ".params: params()"
-        _channel_to_patches -.-> ".params: params()"
-        extract_outer -.-> ".params: get()"
-        extract_inner_grid -.-> ".params: cfg['N']"
-        extract_inner_grid -.-> ".params: params()"
-        extract_nested_patches -.-> ".params: cfg['N']"
-        extract_nested_patches -.-> ".params: params()"
-        extract_patches_inverse -.-> ".params: params()"
-        reassemble_patches_real -.-> ".params: params()"
-        pad_patches -.-> ".params: params()"
-        pad_patches -.-> ".params: get_padded_size()"
-        trim_reconstruction -.-> ".params: cfg['N']"
-        trim_reconstruction -.-> ".params: get_padded_size()"
-        extract_patches_position -.-> ".params: params()"
-        pad_reconstruction -.-> ".params: get_padded_size()"
-        _reassemble_patches_position_real -.-> ".params: get_padded_size()"
-        mk_norm -.-> ".params: params()"
-        reassemble_nested_average -.-> ".params: params.params()"
-        masked_MAE_loss -.-> ".params: params()"
-        masked_mae -.-> ".params: params()"
-        realspace_loss -.-> ".params: get()"
-    end
-
-subgraph params[params.py]
-        get_bigN[get_bigN()]
-        get_padding_size[get_padding_size()]
-        get_padded_size[get_padded_size()]
-        params[params()]
-        validate[validate()]
-        set[set()]
-        get[get()]
-        cfg[cfg]
-
-        %% Internal dependencies
-        get_padded_size --> get_bigN
-        get_padded_size --> get_padding_size
-        params --> get_bigN
-        set --> validate
-        get --> get_bigN
-
-        %% External dependencies
-        get_bigN -.-> cfg
-        get_padding_size -.-> cfg
-        validate -.-> cfg
-        set -.-> cfg
-        get -.-> cfg
-    end
-
-    %% probe.py
-    subgraph probe[probe.py]
-        get_lowpass_filter[get_lowpass_filter()]
-        get_default_probe[get_default_probe()]
-        get_probe[get_probe()]
-        to_np[to_np()]
-        get_squared_distance[get_squared_distance()]
-        get_probe_mask_real[get_probe_mask_real()]
-        get_probe_mask[get_probe_mask()]
-        set_probe[set_probe()]
-        set_probe_guess[set_probe_guess()]
-
-        %% Internal dependencies
-        get_default_probe --> get_lowpass_filter
-        get_probe_mask_real --> get_squared_distance
-        get_probe_mask --> get_probe_mask_real
-        set_probe_guess --> get_default_probe
-        set_probe_guess --> get_probe_mask_real
-
-        %% External dependencies
-        get_lowpass_filter -.-> ".fourier: f.lowpass_g()"
-        get_default_probe -.-> ".fourier: f.gf()"
-        get_default_probe -.-> ".params: params.cfg"
-        get_probe -.-> ".params: params.get()"
-        set_probe -.-> ".params: params.get()"
-        set_probe -.-> ".params: params.set()"
-        set_probe_guess -.-> ".fourier: f.fftshift()"
-        set_probe_guess -.-> ".fourier: f.ifft2()"
-        set_probe_guess -.-> ".fourier: f.ifftshift()"
-        set_probe_guess -.-> ".params: params.get()"
-        set_probe_guess -.-> ".params: params.set()"
-    end
-
-    %% evaluation.py
-    subgraph evaluation[evaluation.py]
-        recon_patches[recon_patches()]
-        symmetrize[symmetrize()]
-        symmetrize_3d[symmetrize_3d()]
-        cropshow[cropshow()]
-        summarize[summarize()]
-        plt_metrics[plt_metrics()]
-        trim[trim()]
-        mae[mae()]
-        mse[mse()]
-        psnr[psnr()]
-        fft2d[fft2d()]
-        highpass2d[highpass2d()]
-        lowpass2d[lowpass2d()]
-        frc50[frc50()]
-        eval_reconstruction[eval_reconstruction()]
-        save_metrics[save_metrics()]
-
-        %% Internal dependencies
-        summarize --> cropshow
-        highpass2d --> fft2d
-        lowpass2d --> fft2d
-        eval_reconstruction --> trim
-        eval_reconstruction --> highpass2d
-        eval_reconstruction --> mae
-        eval_reconstruction --> mse
-        eval_reconstruction --> psnr
-        eval_reconstruction --> frc50
-        save_metrics --> eval_reconstruction
-
-        %% External dependencies
-        recon_patches -.-> ".generate_data: data.reassemble()"
-        summarize -.-> ".params: cfg.get()"
-        trim -.-> ".params: params.get()"
-        frc50 -.-> ".FRC.fourier_ring_corr: frc.FSC()"
-        save_metrics -.-> ".misc: misc.get_path_prefix()"
-        save_metrics -.-> ".params: params.cfg"
-    end
-
-    %% data_preprocessing.py
-    subgraph data_preprocessing[data_preprocessing.py]
-        load_simulated_data[load_simulated_data()]
-        load_experimental_data[load_experimental_data()]
-        load_xpp_data[load_xpp_data()]
-        load_generic_data[load_generic_data()]
-        shuffle_data[shuffle_data()]
-        get_clipped_object[get_clipped_object()]
-        get_clip_sizes[get_clip_sizes()]
-        stitch_data[stitch_data()]
-        reassemble[reassemble()]
-        process_simulated_data[process_simulated_data()]
-        create_ptycho_dataset[create_ptycho_dataset()]
-        generate_data[generate_data()]
-
-        %% Internal dependencies
-        get_clipped_object --> get_clip_sizes
-        stitch_data --> get_clip_sizes
-        reassemble --> stitch_data
-        process_simulated_data --> shuffle_data
-        process_simulated_data --> get_clipped_object
-        generate_data --> load_simulated_data
-        generate_data --> load_experimental_data
-        generate_data --> load_xpp_data
-        generate_data --> load_generic_data
-        generate_data --> process_simulated_data
-        generate_data --> create_ptycho_dataset
-
-        %% External dependencies
-        load_simulated_data -.-> ".diffsim: datasets.mk_simdata"
-        load_experimental_data -.-> ".simulation.experimental: experimental.get_full_experimental"
-        load_experimental_data -.-> ".diffsim: datasets.mk_simdata"
-        load_xpp_data -.-> ".loader: loader.load"
-        load_xpp_data -.-> ".xpp: xpp.get_data"
-        load_generic_data -.-> ".loader: RawData.from_files"
-        load_generic_data -.-> ".loader: loader.load"
-        get_clipped_object -.-> ".params: params.cfg"
-        get_clip_sizes -.-> ".params: params.cfg"
-        stitch_data -.-> ".params: params.get()"
-        process_simulated_data -.-> ".params: params.get()"
-        create_ptycho_dataset -.-> ".probe: probe.get_probe"
-        generate_data -.-> ".params: params.params()"
-        generate_data -.-> ".params: params.cfg"
-        generate_data -.-> ".probe: probe.get_probe"
-    end
-
-    %% diffsim.py
-    subgraph diffsim[diffsim.py]
-        observe_amplitude[observe_amplitude()]
-        count_photons[count_photons()]
-        scale_nphotons[scale_nphotons()]
-        diffract_obj[diffract_obj()]
-        illuminate_and_diffract[illuminate_and_diffract()]
-        mk_rand[mk_rand()]
-        mk_lines_img[mk_lines_img()]
-        mk_noise[mk_noise()]
-        extract_coords[extract_coords()]
-        add_position_jitter[add_position_jitter()]
-        scan_and_normalize[scan_and_normalize()]
-        dummy_phi[dummy_phi()]
-        sim_object_image[sim_object_image()]
-        mk_simdata[mk_simdata()]
-
-        %% Internal dependencies
-        scale_nphotons --> count_photons
-        diffract_obj --> observe_amplitude
-        illuminate_and_diffract --> scale_nphotons
-        illuminate_and_diffract --> diffract_obj
-        mk_lines_img --> mk_rand
-        scan_and_normalize --> extract_coords
-        sim_object_image --> mk_lines_img
-        sim_object_image --> mk_noise
-        mk_simdata --> sim_object_image
-        mk_simdata --> scan_and_normalize
-        mk_simdata --> illuminate_and_diffract
-
-        %% External dependencies
-        observe_amplitude -.-> ".tf_helper: hh.tfd.Independent"
-        observe_amplitude -.-> ".tf_helper: hh.tfd.Poisson"
-        scale_nphotons -.-> ".params: p.get()"
-        diffract_obj -.-> ".tf_helper: hh.pad_and_diffract"
-        diffract_obj -.-> ".params: p.get()"
-        illuminate_and_diffract -.-> ".tf_helper: hh.combine_complex"
-        illuminate_and_diffract -.-> ".tf_helper: hh.togrid"
-        illuminate_and_diffract -.-> ".tf_helper: hh.grid_to_channel"
-        illuminate_and_diffract -.-> ".params: p.get()"
-        mk_lines_img -.-> ".fourier: f.gf"
-        extract_coords -.-> ".tf_helper: hh.extract_outer"
-        extract_coords -.-> ".tf_helper: hh.extract_nested_patches"
-        scan_and_normalize -.-> ".tf_helper: hh.preprocess_objects"
-        sim_object_image -.-> ".params: p.get()"
-        mk_simdata -.-> ".params: p.get()"
-    end
-
-    %% model_manager.py
-    subgraph model_manager[model_manager.py]
-        ModelManager_save_model[ModelManager.save_model()]
-        ModelManager_load_model[ModelManager.load_model()]
-        ModelManager_save_multiple_models[ModelManager.save_multiple_models()]
-        ModelManager_load_multiple_models[ModelManager.load_multiple_models()]
-        save[save()]
-
-        %% Internal dependencies
-        ModelManager_save_multiple_models --> ModelManager_save_model
-        ModelManager_load_multiple_models --> ModelManager_load_model
-        save --> ModelManager_save_multiple_models
-
-        %% External dependencies
-        ModelManager_load_model -.-> ".params: params.cfg.update()"
-        ModelManager_load_model -.-> ".params: params.set()"
-        save -.-> ".params: params.get()"
-    end
-
-    %% misc.py
-    subgraph misc[misc.py]
-        get_path_prefix[get_path_prefix()]
-        colormap2arr[colormap2arr()]
-        memoize_disk_and_memory[memoize_disk_and_memory()]
-        cross_image[cross_image()]
-
-        %% External dependencies
-        get_path_prefix -.-> ".params: params.cfg"
-        get_path_prefix -.-> ".params: params.params()"
-        get_path_prefix -.-> ".params: params.get()"
-        get_path_prefix -.-> ".params: params.set()"
-    end
-
-    %% inference.py
-    subgraph inference[inference.py]
-        load_pretrained_model[load_pretrained_model()]
-        prepare_data[prepare_data()]
-        perform_inference[perform_inference()]
-        inference_flow[inference_flow()]
-
-        %% Internal dependencies
-        inference_flow --> load_pretrained_model
-        inference_flow --> prepare_data
-        inference_flow --> perform_inference
-
-        %% External dependencies
-        load_pretrained_model -.-> ".model_manager: ModelManager.load_model()"
-        prepare_data -.-> ".model: model.params()"
-        perform_inference -.-> ".model: model.predict()"
-        perform_inference -.-> ".model: model.params()"
-        inference_flow -.-> ".params: params.get()"
-    end
-
-    %% generate_data.py
-    subgraph generate_data[generate_data.py]
-        main[main()]
-
-        %% External dependencies
-        main -.-> ".data_preprocessing: generate_data()"
-        main -.-> ".params: p.get()"
-    end
-
-    %% export.py
-    subgraph export[export.py]
-        save_recons[save_recons()]
-
-        %% External dependencies
-        save_recons -.-> ".misc: get_path_prefix()"
-        save_recons -.-> ".params: get()"
-        save_recons -.-> ".evaluation: save_metrics()"
-    end
-
-    %% logging.py
-    subgraph logging[logging.py]
-        SerializationError[SerializationError]
-        LoggedDataNotFoundError[LoggedDataNotFoundError]
-        make_invocation_counter[make_invocation_counter()]
-        debug[debug()]
-        load_logged_data[load_logged_data()]
-        get_type_and_dim[get_type_and_dim()]
-        process_log_file[process_log_file()]
-        extract_logged_data[extract_logged_data()]
-        main[main()]
-
-        %% Internal dependencies
-        debug --> make_invocation_counter
-        process_log_file --> load_logged_data
-        process_log_file --> get_type_and_dim
-        extract_logged_data --> process_log_file
-        main --> extract_logged_data
-
-        %% External dependencies
-        debug -.-> ".params: params.get()"
-    end
-
-    %% xpp.py
-    subgraph xpp[xpp.py]
-        get_data[get_data()]
-        cross_image[cross_image()]
-
-        %% External dependencies
-        ptycho_data -.-> ".loader: load_ptycho_data()"
-        ptycho_data_train -.-> ".loader: load_ptycho_data()"
-    end
-
-    %% cxiprocess.py
-    subgraph cxiprocess[cxiprocess.py]
-        load_diffraction_data[load_diffraction_data()]
-        bin_diffraction_data[bin_diffraction_data()]
-        crop_diffraction_data[crop_diffraction_data()]
-        preprocess_diffraction_data[preprocess_diffraction_data()]
-        load_probe_data[load_probe_data()]
-        load_scan_positions[load_scan_positions()]
-        load_scan_index[load_scan_index()]
-        load_object_guess[load_object_guess()]
-        save_preprocessed_data[save_preprocessed_data()]
-        preprocess_cxi_to_npy[preprocess_cxi_to_npy()]
-
-        %% Internal dependencies
-        preprocess_diffraction_data --> crop_diffraction_data
-        preprocess_diffraction_data --> bin_diffraction_data
-        preprocess_cxi_to_npy --> load_diffraction_data
-        preprocess_cxi_to_npy --> load_probe_data
-        preprocess_cxi_to_npy --> preprocess_diffraction_data
-        preprocess_cxi_to_npy --> load_scan_positions
-        preprocess_cxi_to_npy --> load_scan_index
-        preprocess_cxi_to_npy --> load_object_guess
-        preprocess_cxi_to_npy --> save_preprocessed_data
-
-        %% External dependencies
-        preprocess_cxi_to_npy -.-> ".probe_processor: process_probe()"
-    end
-
-    %% nbutils.py
-    subgraph nbutils[nbutils.py]
-        crop_to_non_uniform_region_with_buffer[crop_to_non_uniform_region_with_buffer()]
-        mk_epie_comparison2x2[mk_epie_comparison2x2()]
-        reconstruct_image[reconstruct_image()]
-        print_shapes[print_shapes()]
-        probeshow[probeshow()]
-        track_dict_changes[track_dict_changes()]
-
-        %% External dependencies
-        reconstruct_image -.-> ".model: model.diffraction_to_obj"
-        reconstruct_image -.-> ".model: model.params"
-    end
-
-    %% plotting.py
-    subgraph plotting[plotting.py]
-        ishow_imgs[ishow_imgs()]
-    end
-
-subgraph fourier[fourier.py]
-        plot_df[plot_df()]
-        lowpass_g[lowpass_g()]
-        highpass_g[highpass_g()]
-        bandpass_g[bandpass_g()]
-        clip_high[clip_high()]
-        clip_low[clip_low()]
-        clip_low_window[clip_low_window()]
-        if_mag[if_mag()]
-        power[power()]
-        mag[mag()]
-        lorenz[lorenz()]
-
-        %% Internal dependencies
-        highpass_g --> lowpass_g
-        bandpass_g --> lowpass_g
-        bandpass_g --> highpass_g
-        mag --> power
-    end
-
-    %% train_supervised.py
-    subgraph train_supervised[train_supervised.py]
-        xyshift[xyshift()]
-        get_recon_patches_single_channel[get_recon_patches_single_channel()]
-        get_recon_patches_grid[get_recon_patches_grid()]
-        offset[offset]
-        model[model]
-        history[history]
-        reconstructed_obj[reconstructed_obj]
-        reconstructed_obj_train[reconstructed_obj_train]
-        stitched_obj[stitched_obj]
-
-        %% Internal dependencies
-        get_recon_patches_grid --> xyshift
-
-        %% External dependencies
-        get_recon_patches_single_channel -.-> ".baselines: bl.params.params()"
-        get_recon_patches_single_channel -.-> ".tf_helper: hh.combine_complex()"
-        get_recon_patches_grid -.-> ".baselines: bl.params.params()"
-        get_recon_patches_grid -.-> ".tf_helper: hh.combine_complex()"
-        stitched_obj -.-> ".generate_data: reassemble()"
-    end
-
-    %% autotest/debug.py
-    subgraph debug[debug.py]
-        Debug_init[Debug.__init__()]
-        Debug_decorate[Debug.decorate()]
-        Debug_formatConsoleLog[Debug._formatConsoleLog()]
-        TestDebug_setUp[TestDebug.setUp()]
-        TestDebug_test_decorate_call[TestDebug.test_decorate_call()]
-        TestDebug_test_decorate_return[TestDebug.test_decorate_return()]
-        TestDebug_test_decorate_error[TestDebug.test_decorate_error()]
-        obj[obj]
-        debug[debug]
-
-        %% Internal dependencies
-        Debug_decorate --> Debug_formatConsoleLog
-
-        %% External dependencies
-        Debug_init -.-> ".configuration: Configuration()"
-        Debug_init -.-> ".serializer: Serializer()"
-        Debug_init -.-> ".logger: Logger()"
-        Debug_init -.-> ".functionmapping: FunctionMapping()"
-        TestDebug_setUp -.-> ".configuration: Configuration()"
-        TestDebug_setUp -.-> ".serializer: Serializer()"
-        TestDebug_setUp -.-> ".logger: Logger()"
-        TestDebug_setUp -.-> ".functionmapping: FunctionMapping()"
-        TestDebug_test_decorate_call -.-> "Debug.decorate()"
-        TestDebug_test_decorate_return -.-> "Debug.decorate()"
-        TestDebug_test_decorate_error -.-> "Debug.decorate()"
-    end
-
-    %% autotest/functionmapping.py
-    subgraph functionmapping[functionmapping.py]
-        FunctionMapping_init[FunctionMapping.__init__()]
-        FunctionMapping_get_log_file_path[FunctionMapping.get_log_file_path()]
-        FunctionMapping_save_function[FunctionMapping.save_function()]
-        FunctionMapping_load_function_from_path[FunctionMapping.load_function_from_path()]
-        FunctionMapping_get_module_and_function_from_log_path[FunctionMapping.get_module_and_function_from_log_path()]
-        FunctionMapping_load_function[FunctionMapping.load_function()]
-        FunctionMapping_get_module_path[FunctionMapping.get_module_path()]
-        sample_function[sample_function()]
-        another_function[another_function()]
-        test_get_log_file_path[test_get_log_file_path()]
-        test_load_function[test_load_function()]
-        test_get_module_path[test_get_module_path()]
-
-        %% Internal dependencies
-        FunctionMapping_save_function --> FunctionMapping_get_module_and_function_from_log_path
-        FunctionMapping_load_function_from_path --> FunctionMapping_get_module_and_function_from_log_path
-        FunctionMapping_load_function --> FunctionMapping_load_function_from_path
-        test_get_log_file_path --> FunctionMapping_get_log_file_path
-        test_load_function --> FunctionMapping_get_log_file_path
-        test_load_function --> FunctionMapping_load_function
-        test_get_module_path --> FunctionMapping_get_module_path
-    end
-
-    %% autotest/logger.py
-    subgraph logger[logger.py]
-        Logger_init[Logger.__init__()]
-        Logger_logCall[Logger.logCall()]
-        Logger_logReturn[Logger.logReturn()]
-        Logger_logError[Logger.logError()]
-        Logger_loadLog[Logger.loadLog()]
-        Logger_searchLogDirectory[Logger.searchLogDirectory()]
-        Logger_validateLogFilePath[Logger.validateLogFilePath()]
-        TestLogger_setUp[TestLogger.setUp()]
-        TestLogger_tearDown[TestLogger.tearDown()]
-        TestLogger_test_logCall[TestLogger.test_logCall()]
-        TestLogger_test_logReturn[TestLogger.test_logReturn()]
-        TestLogger_test_logError[TestLogger.test_logError()]
-        TestLogger_test_loadLog[TestLogger.test_loadLog()]
-        TestLogger_test_searchLogDirectory[TestLogger.test_searchLogDirectory()]
-        TestLogger_test_validateLogFilePath[TestLogger.test_validateLogFilePath()]
-
-        %% Internal dependencies
-        Logger_searchLogDirectory --> Logger_validateLogFilePath
-
-        %% External dependencies
-        Logger_init -.-> ".serializer: Serializer()"
-        TestLogger_setUp -.-> "Logger()"
-        TestLogger_test_logCall -.-> "Logger.logCall()"
-        TestLogger_test_logReturn -.-> "Logger.logReturn()"
-        TestLogger_test_logError -.-> "Logger.logError()"
-        TestLogger_test_loadLog -.-> "Logger.logCall()"
-        TestLogger_test_loadLog -.-> "Logger.logReturn()"
-        TestLogger_test_loadLog -.-> "Logger.loadLog()"
-        TestLogger_test_searchLogDirectory -.-> "Logger.searchLogDirectory()"
-        TestLogger_test_validateLogFilePath -.-> "Logger.validateLogFilePath()"
-    end
-
-    %% autotest/serializer.py
-    subgraph serializer[serializer.py]
-        Serializer_serialize[Serializer.serialize()]
-        Serializer_deserialize[Serializer.deserialize()]
-    end
-
-    %% autotest/testing.py
-    subgraph testing[testing.py]
-        TestSummary_init[TestSummary.__init__()]
-        TestSummary_increment_passed[TestSummary.increment_passed()]
-        TestSummary_increment_failed[TestSummary.increment_failed()]
-        TestSummary_increment_skipped[TestSummary.increment_skipped()]
-        TestSummary_repr[TestSummary.__repr__()]
-        Testing_init[Testing.__init__()]
-        Testing_testCallable[Testing.testCallable()]
-        Testing_createTestCase[Testing.createTestCase()]
-        Testing_runTestSuite[Testing.runTestSuite()]
-        TestTesting_setUp[TestTesting.setUp()]
-        TestTesting_test_testCallable[TestTesting.test_testCallable()]
-        TestTesting_test_createTestCase[TestTesting.test_createTestCase()]
-        TestTesting_test_runTestSuite[TestTesting.test_runTestSuite()]
-        add[add()]
-        multiply[multiply()]
-        divide[divide()]
-
-        %% Internal dependencies
-        Testing_runTestSuite --> Testing_createTestCase
-        Testing_runTestSuite --> Testing_testCallable
-        Testing_runTestSuite --> TestSummary_init
-
-        %% External dependencies
-        Testing_init -.-> ".logger: Logger()"
-        Testing_init -.-> ".functionmapping: FunctionMapping()"
-        Testing_testCallable -.-> ".logger: Logger.searchLogDirectory()"
-        Testing_testCallable -.-> ".logger: Logger.loadLog()"
-        Testing_testCallable -.-> ".logger: Logger.serializer.deserialize()"
-        Testing_createTestCase -.-> ".logger: Logger.searchLogDirectory()"
-        Testing_createTestCase -.-> ".logger: Logger.loadLog()"
-        Testing_createTestCase -.-> ".functionmapping: FunctionMapping.load_function()"
-        Testing_runTestSuite -.-> ".logger: Logger.searchLogDirectory()"
-        TestTesting_setUp -.-> ".logger: Logger()"
-        TestTesting_setUp -.-> ".functionmapping: FunctionMapping()"
-        TestTesting_test_testCallable -.-> "Testing.testCallable()"
-        TestTesting_test_testCallable -.-> ".logger: Logger.logReturn()"
-        TestTesting_test_createTestCase -.-> "Testing.createTestCase()"
-        TestTesting_test_createTestCase -.-> ".logger: Logger.logReturn()"
-        TestTesting_test_createTestCase -.-> ".functionmapping: FunctionMapping.save_function()"
-        TestTesting_test_runTestSuite -.-> "Testing.runTestSuite()"
-        TestTesting_test_runTestSuite -.-> ".logger: Logger.logReturn()"
-        TestTesting_test_runTestSuite -.-> ".functionmapping: FunctionMapping.save_function()"
-    end
-
-    %% autotest/configuration.py
-    subgraph configuration[configuration.py]
-        Configuration_init[Configuration.__init__()]
-        Configuration_getDebugFlag[Configuration.getDebugFlag()]
-        Configuration_getLogFilePrefix[Configuration.getLogFilePrefix()]
-    end
-
-    %% datagen/grf.py
-    subgraph grf[grf.py]
-        powerspec[powerspec()]
-        smooth_field[smooth_field()]
-        mainland[mainland()]
-        normalize_field[normalize_field()]
-        generate_map[generate_map()]
-        mk_grf[mk_grf()]
-
-        %% Internal dependencies
-        generate_map --> normalize_field
-        generate_map --> smooth_field
-        mk_grf --> generate_map
-
-        %% External dependencies
-        generate_map -.-> "pbox.powerbox.PowerBox()"
-    end
-
-    %% datagen/vendetta.py
-    subgraph vendetta[vendetta.py]
-        letter_to_array[letter_to_array()]
-        create_canvas[create_canvas()]
-        create_sprite[create_sprite()]
-        add_sprite_to_canvas[add_sprite_to_canvas()]
-        mk_vs[mk_vs()]
-        font_path[font_path]
-        sprite[sprite]
-
-        %% Internal dependencies
-        mk_vs --> create_canvas
-        mk_vs --> create_sprite
-        mk_vs --> add_sprite_to_canvas
-
-        %% External dependencies
-        mk_vs -.-> ".fourier: f.gf()"
-    end
-
-    %% datagen/testimg.py
-    subgraph testimg[testimg.py]
-        first_and_last[first_and_last()]
-        get_block[get_block()]
-        get_img[get_img()]
-        path[path]
-        image[image]
-        N[N]
-        imgs[imgs]
-        rev[rev]
-        it[it]
-        rev_it[rev_it]
-
-        %% Internal dependencies
-        get_img --> get_block
-
-        %% External dependencies
-        imgs -.-> ".tf_helper: hh.extract_patches()"
-        N -.-> ".params: params.get()"
-    end
-
-    %% datagen/diagonals.py
-    subgraph diagonals[diagonals.py]
-        draw_lines[draw_lines()]
-        mk_diags[mk_diags()]
-
-        %% Internal dependencies
-        mk_diags --> draw_lines
-
-        %% External dependencies
-        mk_diags -.-> "scipy.ndimage: gf"
-    end
-
-    %% datagen/points.py
-    subgraph points[points.py]
-        randones[randones()]
-        mk_points[mk_points()]
-
-        %% Internal dependencies
-        mk_points --> randones
-
-        %% External dependencies
-        mk_points -.-> "scipy.ndimage: gf"
-    end
-
-    %% FRC/fourier_ring_corr.py
-    subgraph fourier_ring_corr[fourier_ring_corr.py]
-        FSC[FSC()]
-
-        %% External dependencies
-        FSC -.-> ".spin_average: sa.spinavej()"
-    end
-
-    %% FRC/spin_average.py
-    subgraph spin_average[spin_average.py]
-        spinavej[spinavej()]
-    end
-
-    %% workflows/visualize_results.py
-    subgraph visualize_results[visualize_results.py]
-        visualize_results[visualize_results()]
-
-        %% External dependencies
-        visualize_results -.-> ".evaluation: evaluation.summarize()"
-    end
-
-    %% workflows/components.py
-    subgraph components[components.py]
-        load_data[load_data()]
-        update_params[update_params()]
-        parse_arguments[parse_arguments()]
-        load_yaml_config[load_yaml_config()]
-        merge_configs[merge_configs()]
-        validate_config[validate_config()]
-        setup_configuration[setup_configuration()]
-        load_and_prepare_data[load_and_prepare_data()]
-        create_ptycho_data_container[create_ptycho_data_container()]
-        train_cdi_model[train_cdi_model()]
-        reassemble_cdi_image[reassemble_cdi_image()]
-        run_cdi_example[run_cdi_example()]
-        save_outputs[save_outputs()]
-        ARG_TO_CONFIG_MAP[ARG_TO_CONFIG_MAP]
-
-        %% Internal dependencies
-        setup_configuration --> load_yaml_config
-        setup_configuration --> merge_configs
-        setup_configuration --> validate_config
-        train_cdi_model --> create_ptycho_data_container
-        reassemble_cdi_image --> create_ptycho_data_container
-        run_cdi_example --> train_cdi_model
-        run_cdi_example --> reassemble_cdi_image
-
-        %% External dependencies
-        update_params -.-> ".params: p.set()"
-        merge_configs -.-> ".params: p.cfg"
-        setup_configuration -.-> ".params: p.cfg.update()"
-        load_and_prepare_data -.-> ".loader: loader.load_xpp_npz()"
-        create_ptycho_data_container -.-> ".loader: loader.load()"
-        train_cdi_model -.-> ".probe: probe.set_probe_guess()"
-        train_cdi_model -.-> ".train_pinn: train_pinn.train_eval()"
-        reassemble_cdi_image -.-> ".loader: loader.reassemble_position()"
-    end
-
-%% scripts/training/train.py
-    subgraph train_script[train.py]
-        main[main()]
-
-        %% External dependencies
-        main -.-> ".workflows.components: parse_arguments()"
-        main -.-> ".workflows.components: setup_configuration()"
-        main -.-> ".workflows.components: load_data()"
-        main -.-> ".workflows.components: run_cdi_example()"
-        main -.-> ".model_manager: model_manager.save()"
-        main -.-> ".workflows.components: save_outputs()"
-    end
-
-    %% scripts/inference/inference.py
-    subgraph inference_script[inference.py]
-        parse_arguments[parse_arguments()]
-        load_model[load_model()]
-        perform_inference[perform_inference()]
-        save_comparison_image[save_comparison_image()]
-        save_probe_visualization[save_probe_visualization()]
-        main[main()]
-
-        %% Internal dependencies
-        main --> parse_arguments
-        main --> load_model
-        main --> perform_inference
-        main --> save_comparison_image
-        main --> save_probe_visualization
-
-        %% External dependencies
-        load_model -.-> ".model_manager: ModelManager.load_model()"
-        load_model -.-> ".params: params.cfg"
-        perform_inference -.-> ".probe: probe.set_probe_guess()"
-        perform_inference -.-> ".loader: loader.reassemble_position()"
-        main -.-> ".workflows.components: load_data()"
-    end
-
-    %% scripts/train.py
-    subgraph train_main[train.py]
-        parse_arguments[parse_arguments()]
-        load_yaml_config[load_yaml_config()]
-        merge_configs[merge_configs()]
-        validate_config[validate_config()]
-        setup_configuration[setup_configuration()]
-        load_and_prepare_data[load_and_prepare_data()]
-        run_cdi_example[run_cdi_example()]
-        save_outputs[save_outputs()]
-        main[main()]
-        ARG_TO_CONFIG_MAP[ARG_TO_CONFIG_MAP]
-
-        %% Internal dependencies
-        setup_configuration --> load_yaml_config
-        setup_configuration --> merge_configs
-        setup_configuration --> validate_config
-        main --> parse_arguments
-        main --> setup_configuration
-        main --> load_and_prepare_data
-        main --> run_cdi_example
-        main --> save_outputs
-
-        %% External dependencies
-        merge_configs -.-> ".params: params.cfg"
-        setup_configuration -.-> ".params: params.cfg.update()"
-        load_and_prepare_data -.-> ".xpp: xpp.load_ptycho_data()"
-        run_cdi_example -.-> ".probe: probe.set_probe_guess()"
-        run_cdi_example -.-> ".generate_data: generate_data.generate_data()"
-        run_cdi_example -.-> ".model: model.train()"
-        save_outputs -.-> ".evaluation: save_metrics()"
-    end
-
-
-%% project level
-graph TD
-    subgraph model[model.py]
-        model_ProbeIllumination[ProbeIllumination]
-        model_create_autoencoder[create_autoencoder]
-        model_train[train]
-    end
-
-    subgraph train_pinn[train_pinn.py]
-        train_pinn_train[train]
-        train_pinn_train_eval[train_eval]
-        train_pinn_eval[eval]
-    end
-
-    subgraph inference[inference.py]
-        inference_load_pretrained_model[load_pretrained_model]
-        inference_prepare_data[prepare_data]
-        inference_perform_inference[perform_inference]
-        inference_inference_flow[inference_flow]
-    end
-
-    subgraph loader[loader.py]
-        loader_RawData[RawData]
-        get_image_patches[get_image_patches]
-        loader_PtychoDataContainer[PtychoDataContainer]
-        loader_load[load]
-        loader_load -.-> "diffsim:scale_nphotons"
-    end
-
-    subgraph data_preprocessing[data_preprocessing.py]
-        data_preprocessing_create_ptycho_dataset[create_ptycho_dataset]
-        data_preprocessing_load_simulated_data_container[load_simulated_data_container]
-        data_preprocessing_generate_data[generate_data]
-        process_simulated_data[process_simulated_data]
-        data_preprocessing_generate_data -.-> "diffsim:mk_simdata"
-    end
-
-    subgraph evaluation[evaluation.py]
-        evaluation_eval_reconstruction[eval_reconstruction]
-        evaluation_save_metrics[save_metrics]
-    end
-
-    subgraph generate_data[generate_data.py]
-        generate_data_main[main]
-    end
-
-    subgraph tf_helper[tf_helper.py]
-        tf_helper_pad_and_diffract[pad_and_diffract]
-        tf_helper_reassemble_patches[reassemble_patches]
-        tf_helper_extract_patches_position[extract_patches_position]
-    end
-
-    subgraph probe[probe.py]
-        probe_get_probe[get_probe]
-        probe_set_probe_guess[set_probe_guess]
-        get_squared_distance[get_squared_distance]
-        get_probe_mask_real[get_probe_mask_real]
-        get_probe_mask[get_probe_mask]
-        set_probe[set_probe]
-    end
-
-    subgraph params[params.py]
-        params_cfg[cfg]
-        params_get[get]
-        params_set[set]
-    end
-
-    subgraph misc[misc.py]
-        misc_get_path_prefix[get_path_prefix]
-        misc_memoize_disk_and_memory[memoize_disk_and_memory]
-    end
-
-    subgraph diffsim[diffsim.py]
-        observe_amplitude[observe_amplitude]
-        count_photons[count_photons]
-        scale_nphotons[scale_nphotons]
-        diffract_obj[diffract_obj]
-        diffsim_illuminate_and_diffract[illuminate_and_diffract]
-        mk_rand[mk_rand]
-        mk_lines_img[mk_lines_img]
-        mk_noise[mk_noise]
-        extract_coords[extract_coords]
-        add_position_jitter[add_position_jitter]
-        scan_and_normalize[scan_and_normalize]
-        dummy_phi[dummy_phi]
-        sim_object_image[sim_object_image]
-        diffsim_mk_simdata[mk_simdata]
-    end
-
-    subgraph xpp[xpp.py]
-        xpp_get_data[get_data]
-    end
-
-    subgraph train[train.py]
-        train_main[main]
-    end
-
-    subgraph train_supervised[train_supervised.py]
-        train_supervised_get_recon_patches_single_channel[get_recon_patches_single_channel]
-        train_supervised_get_recon_patches_grid[get_recon_patches_grid]
-    end
-
-    subgraph plotting[plotting.py]
-        plotting_ishow_imgs[ishow_imgs]
-    end
-
-    subgraph nbutils[nbutils.py]
-        crop_to_non_uniform_region_with_buffer[crop_to_non_uniform_region_with_buffer]
-        mk_epie_comparison2x2[mk_epie_comparison2x2]
-        nbutils_reconstruct_image[reconstruct_image]
-        print_shapes[print_shapes]
-        nbutils_probeshow[probeshow]
-        track_dict_changes[track_dict_changes]
-    end
-
-    subgraph export[export.py]
-        export_save_recons[save_recons]
-    end
-
-    subgraph logging[logging.py]
-        make_invocation_counter[make_invocation_counter]
-        logging_debug[debug]
-        logging_load_logged_data[load_logged_data]
-        get_type_and_dim[get_type_and_dim]
-        process_log_file[process_log_file]
-        extract_logged_data[extract_logged_data]
-        main[main]
-        CustomResult[CustomResult]
-    end
-
-    subgraph cxiprocess[cxiprocess.py]
-        load_diffraction_data[load_diffraction_data]
-        bin_diffraction_data[bin_diffraction_data]
-        crop_diffraction_data[crop_diffraction_data]
-        preprocess_diffraction_data[preprocess_diffraction_data]
-        load_probe_data[load_probe_data]
-        load_scan_positions[load_scan_positions]
-        load_scan_index[load_scan_index]
-        load_object_guess[load_object_guess]
-        save_preprocessed_data[save_preprocessed_data]
-        cxiprocess_preprocess_cxi_to_npy[preprocess_cxi_to_npy]
-        cxiprocess_preprocess_cxi_to_npy -.-> "probe_processor:process_probe"
-    end
-
-    %% Inter-module dependencies
-    train_pinn_train --> model_train
-    train_pinn_eval --> model_ProbeIllumination
-    inference_prepare_data --> model.params
-    inference_perform_inference --> model.predict
-    loader_PtychoDataContainer --> model_ProbeIllumination
-
-    inference_inference_flow --> inference_load_pretrained_model
-    inference_inference_flow --> inference_prepare_data
-    inference_inference_flow --> inference_perform_inference
-
-    train_pinn_train --> loader_PtychoDataContainer
-    train_pinn_eval --> loader_PtychoDataContainer
-
-    data_preprocessing_create_ptycho_dataset --> loader_PtychoDataContainer
-    data_preprocessing_load_simulated_data_container --> loader_PtychoDataContainer
-
-    evaluation_eval_reconstruction --> model.params
-    evaluation_save_metrics --> data_preprocessing_generate_data
-
-    generate_data_main --> data_preprocessing_generate_data
-
-    model_ProbeIllumination --> probe_get_probe
-    model_train --> tf_helper_pad_and_diffract
-    model_train --> tf_helper_reassemble_patches
-    model_train --> tf_helper_extract_patches_position
-    model_train --> tf_helper_center_channels
-
-    loader_load --> params_get
-    loader_load --> diffsim_scale_nphotons
-    probe_set_probe_guess --> params_set
-
-    diffsim_illuminate_and_diffract --> tf_helper_pad_and_diffract
-    diffsim_illuminate_and_diffract --> tf_helper_togrid
-    diffsim_illuminate_and_diffract --> tf_helper_grid_to_channel
-
-    train_main --> data_preprocessing_generate_data
-    train_main --> model_manager_save
-
-    train_pinn_train --> probe_set_probe_guess
-    train_pinn_eval --> data_preprocessing_reassemble
-
-    evaluation_eval_reconstruction --> tf_helper_trim_reconstruction
-    evaluation_eval_reconstruction --> tf_helper_highpass2d
-
-    inference_load_pretrained_model --> model_manager_ModelManager_load_model
-    data_preprocessing_generate_data --> diffsim_mk_simdata
-    train_main --> train_pinn_train_eval
-    train_main --> evaluation_save_metrics
-    train_main --> misc_get_path_prefix
-
-    train_supervised_get_recon_patches_single_channel --> tf_helper_combine_complex
-    train_supervised_get_recon_patches_grid --> tf_helper_combine_complex
-
-    nbutils_reconstruct_image --> model.diffraction_to_obj
-    nbutils_reconstruct_image --> model.params
-
-    export_save_recons --> misc_get_path_prefix
-    export_save_recons --> params_get
-    export_save_recons --> evaluation_save_metrics
-
-    logging_debug --> params_get
-
-    cxiprocess_preprocess_cxi_to_npy --> probe.process_probe
-
-    %% Data flow
-    data_preprocessing_generate_data --> train_pinn_train
-    data_preprocessing_generate_data --> inference_prepare_data
-    data_preprocessing_generate_data --> evaluation_eval_reconstruction
diff --git a/build/lib/docs/tooltips.txt b/build/lib/docs/tooltips.txt
deleted file mode 100644
index cfa7a55..0000000
--- a/build/lib/docs/tooltips.txt
+++ /dev/null
@@ -1,45 +0,0 @@
-"""
-probe_trainable: bool = False
-    Optimizes the probe function during training. Experimental feature.
-
-intensity_scale_trainable: bool = True
-    Optimize the model's internal amplitude scaling factor during training. Typically 
-    left True.
-
-object_big: bool = True
-    Enables a separate real-space reconstruction for each input
-    diffraction image and an averaging / overlap constraint step. If
-    False, no explicit averaging is performed and the decoders return a
-    single real space image instead of `gridsize**2` images. Typically
-    left True.
-
-probe_mask: bool = False
-    Whether to apply circular mask to the probe function. If toggling
-    this changes the reconstruction, it's likely that there are edge /
-    real space truncation artifacts. Should be used with pad_object =
-    False.
-
-pad_object: bool = True
-    Whether to reconstruct the full real space grid (False) or restrict
-    to N/2 x N/2 (True). True strictly enforces the necessary reciprocal
-    space oversampling, but may cause truncation issues for probe
-    amplitudes with long tails. This truncation can be mitigated by
-    setting probe_big, which uses a small number of CNN filters to
-    generate a low-resolution reconstruction of the outer region.
-    Typically left True.
-
-probe_big: bool = True
-    if True, enables a low-resolution reconstruction of the outer
-    region of the NxN real-space grid. This technically violates the
-    zero-padding / oversampling condition, but may be needed if the
-    probe illumination has wide tails. Has no effect unless pad_object
-    is True.
-
-probe_scale: float = 4.0
-    Scaling factor for the probe amplitude. 
-
-gaussian_smoothing_sigma: float = 0.0
-    Standard deviation for Gaussian smoothing of probe illumination.
-    Increase from 0 to reduce noise / artifacts at cost of resolution.
-    Beware that abusing this can cause convergence issues.
-"""
diff --git a/build/lib/loaders/__init__.py b/build/lib/loaders/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/loaders/als.py b/build/lib/loaders/als.py
deleted file mode 100644
index d1b9b0a..0000000
--- a/build/lib/loaders/als.py
+++ /dev/null
@@ -1,47 +0,0 @@
-import numpy as np
-from ptycho.raw_data import RawData
-
-import pkg_resources
-
-def load_single_object(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects. We ASSUME we're processing
-    a single object. The first train_size samples will be used for training and the entire dataset 
-    will be used for evaluation.
-
-    Args:
-        file_path: Path to the data file.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = data['diffraction']
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                          diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = RawData(xcoords[:train_size], ycoords[:train_size],
-                                xcoords_start[:train_size], ycoords_start[:train_size],
-                                diff3d[:train_size], probeGuess,
-                                scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
-
diff --git a/build/lib/loaders/xpp.py b/build/lib/loaders/xpp.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/notebooks/archive/ablation.sh b/build/lib/notebooks/archive/ablation.sh
deleted file mode 100644
index e32feaa..0000000
--- a/build/lib/notebooks/archive/ablation.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-#!/bin/bash
-#dsource=grf
-#prefix=grf2
-dsource=$1
-prefix=$2
-nepochs=$3
-
-outer_offset_train=$4 # 8
-outer_offset_test=$5 # 20
-
-#outer_offset_train=8
-#outer_offset_test=20
-
-# Invocation 1
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 2 --n_filters_scale 2 --object_big True --intensity_scale_trainable True --label "PINN,NLL,overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
-
-# Invocation 2
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --nll_weight 0.0 --mae_weight 1.0 --intensity_scale_trainable True --object_big True --n_filters_scale 2 --label "PINN,overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
-
-# Invocation 3
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type supervised --n_filters_scale 1 --gridsize 2 --label "overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
-
-# Invocation 4
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 1 --nll_weight 1.0 --mae_weight 0.0 --label "PINN,NLL" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
-
-# Invocation 5
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 1 --nll_weight 0.0 --mae_weight 1.0 --label "PINN" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
-
-# Invocation 6
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type supervised --gridsize 1 --n_filters_scale 1 --label "none" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test --set_phi 
diff --git a/build/lib/notebooks/archive/ablation_nophi.sh b/build/lib/notebooks/archive/ablation_nophi.sh
deleted file mode 100644
index 6666769..0000000
--- a/build/lib/notebooks/archive/ablation_nophi.sh
+++ /dev/null
@@ -1,27 +0,0 @@
-#!/bin/bash
-#dsource=grf
-#prefix=grf2
-dsource=$1
-prefix=$2
-nepochs=$3
-
-outer_offset_train=8
-outer_offset_test=20
-
-# Invocation 1
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 2 --n_filters_scale 2 --object_big True --intensity_scale_trainable True --label "PINN,NLL,overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
-
-# Invocation 2
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --nll_weight 0.0 --mae_weight 1.0 --intensity_scale_trainable True --object_big True --n_filters_scale 2 --label "PINN,overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
-
-# Invocation 3
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type supervised --n_filters_scale 1 --gridsize 2 --label "overlaps" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
-
-# Invocation 4
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 1 --nll_weight 1.0 --mae_weight 0.0 --label "PINN,NLL" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
-
-# Invocation 5
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type pinn --gridsize 1 --nll_weight 0.0 --mae_weight 1.0 --label "PINN" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
-
-# Invocation 6
-python ptycho/train.py  --data_source $dsource --nepochs $nepochs --offset 4  --output_prefix $prefix --model_type supervised --gridsize 1 --n_filters_scale 1 --label "none" --nimgs_train 2 --nimgs_test 1 --outer_offset_train $outer_offset_train --outer_offset_test $outer_offset_test
diff --git a/build/lib/notebooks/archive/ablationtop.sh b/build/lib/notebooks/archive/ablationtop.sh
deleted file mode 100644
index 8d8d0e5..0000000
--- a/build/lib/notebooks/archive/ablationtop.sh
+++ /dev/null
@@ -1,15 +0,0 @@
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
- 
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
-
-bash ablation.sh experimental experimental3 50 4 20 && bash ablation_nophi.sh lines lines_nophi3 50 && bash ablation.sh grf grf3 50 8 20
diff --git a/build/lib/notebooks/archive/amp.jpeg b/build/lib/notebooks/archive/amp.jpeg
deleted file mode 100644
index 42b05bd..0000000
Binary files a/build/lib/notebooks/archive/amp.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/cameraman.bmp b/build/lib/notebooks/archive/cameraman.bmp
deleted file mode 100644
index 2cd57c1..0000000
Binary files a/build/lib/notebooks/archive/cameraman.bmp and /dev/null differ
diff --git a/build/lib/notebooks/archive/full_obj.jpeg b/build/lib/notebooks/archive/full_obj.jpeg
deleted file mode 100644
index bace2f2..0000000
Binary files a/build/lib/notebooks/archive/full_obj.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/in1.jpeg b/build/lib/notebooks/archive/in1.jpeg
deleted file mode 100644
index ee2294e..0000000
Binary files a/build/lib/notebooks/archive/in1.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/in2.jpeg b/build/lib/notebooks/archive/in2.jpeg
deleted file mode 100644
index 4b3faf0..0000000
Binary files a/build/lib/notebooks/archive/in2.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/in3.jpeg b/build/lib/notebooks/archive/in3.jpeg
deleted file mode 100644
index 6097e4b..0000000
Binary files a/build/lib/notebooks/archive/in3.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/in4.jpeg b/build/lib/notebooks/archive/in4.jpeg
deleted file mode 100644
index 96e32f6..0000000
Binary files a/build/lib/notebooks/archive/in4.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/letters.png b/build/lib/notebooks/archive/letters.png
deleted file mode 100644
index e8a2dad..0000000
Binary files a/build/lib/notebooks/archive/letters.png and /dev/null differ
diff --git a/build/lib/notebooks/archive/out1.jpeg b/build/lib/notebooks/archive/out1.jpeg
deleted file mode 100644
index ee2294e..0000000
Binary files a/build/lib/notebooks/archive/out1.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/out2.jpeg b/build/lib/notebooks/archive/out2.jpeg
deleted file mode 100644
index 4b3faf0..0000000
Binary files a/build/lib/notebooks/archive/out2.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/out3.jpeg b/build/lib/notebooks/archive/out3.jpeg
deleted file mode 100644
index 6097e4b..0000000
Binary files a/build/lib/notebooks/archive/out3.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/out4.jpeg b/build/lib/notebooks/archive/out4.jpeg
deleted file mode 100644
index 96e32f6..0000000
Binary files a/build/lib/notebooks/archive/out4.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/patch1.jpeg b/build/lib/notebooks/archive/patch1.jpeg
deleted file mode 100644
index 9d7a729..0000000
Binary files a/build/lib/notebooks/archive/patch1.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/patch2.jpeg b/build/lib/notebooks/archive/patch2.jpeg
deleted file mode 100644
index 9f9a988..0000000
Binary files a/build/lib/notebooks/archive/patch2.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/patch3.jpeg b/build/lib/notebooks/archive/patch3.jpeg
deleted file mode 100644
index 2bfac3b..0000000
Binary files a/build/lib/notebooks/archive/patch3.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/patch4.jpeg b/build/lib/notebooks/archive/patch4.jpeg
deleted file mode 100644
index 8b61a5c..0000000
Binary files a/build/lib/notebooks/archive/patch4.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/phase.jpeg b/build/lib/notebooks/archive/phase.jpeg
deleted file mode 100644
index 7d7e2d4..0000000
Binary files a/build/lib/notebooks/archive/phase.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/archive/squidward2.jpeg b/build/lib/notebooks/archive/squidward2.jpeg
deleted file mode 100644
index 4d7fd36..0000000
Binary files a/build/lib/notebooks/archive/squidward2.jpeg and /dev/null differ
diff --git a/build/lib/notebooks/dose.py b/build/lib/notebooks/dose.py
deleted file mode 100644
index f98380e..0000000
--- a/build/lib/notebooks/dose.py
+++ /dev/null
@@ -1,235 +0,0 @@
-import argparse
-
-def init(nphotons, loss_fn='nll'):
-    from ptycho.params import cfg
-    cfg['positions.provided'] = False
-    cfg['data_source'] = 'lines'
-    cfg['set_phi'] = False
-    cfg['nepochs'] = 60 
-
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 3
-    cfg['output_prefix'] = 'lines3'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-    cfg['probe.trainable'] = False
-
-    cfg['outer_offset_train'] = 8
-    cfg['outer_offset_test'] = 20
-    cfg['nimgs_train'] = 2
-    cfg['nimgs_test'] = 2
-
-    cfg['nphotons'] = nphotons
-
-    if loss_fn == 'mae':
-        cfg['mae_weight'] = 1.
-        cfg['nll_weight'] = 0.
-    elif loss_fn == 'nll':
-        pass  # Keep the current behavior
-    else:
-        raise ValueError(f"Invalid loss_fn: {loss_fn}. Must be 'mae' or 'nll'.")
-
-def plot_results(stitched_obj, YY_ground_truth, d):
-    import matplotlib.pyplot as plt
-    import numpy as np
-
-    fig, axs = plt.subplots(1, 1, figsize=(5, 5))
-
-    # reconstructed amplitude images
-    img1 = axs.imshow(np.absolute(stitched_obj)[0], cmap='jet', interpolation='none')
-    axs.set_title(f'Reconstructed amplitude - FRC50: {d["frc50"][0]:.2f}')
-
-    fig.colorbar(img1, ax=axs)
-
-def execute(nphotons, reload_modules=False):
-    from ptycho.tf_helper import pad
-    from ptycho.evaluation import save_metrics, trim
-    from ptycho.tf_helper import pad
-    from ptycho.params import cfg
-    cfg['nphotons'] = nphotons
-
-    cfg['data_source'] = 'lines'
-    cfg['offset'] = 4
-    cfg['max_position_jitter'] = 10
-    cfg['output_prefix'] = 'lines2'
-
-    cfg['gridsize'] = 2
-    cfg['n_filters_scale'] = 2
-    cfg['object.big'] = True
-    cfg['intensity_scale.trainable'] = True
-
-    from ptycho import train
-    if reload_modules:
-        reload(train.generate_data)
-        reload(train.train_pinn.model)
-        reload(train.train_pinn)
-        reload(train)
-
-    stitched_obj, YY_ground_truth = train.stitched_obj, train.YY_ground_truth
-
-    from ptycho.train_pinn import train as train_pinn, eval as eval_pinn
-    from ptycho import misc
-
-    plot_results(stitched_obj, YY_ground_truth, train.d)
-    # Corrected the indentation and scope of the return statement
-    return train.d, YY_ground_truth, stitched_obj, train.train_output
-
-def parse_arguments():
-    parser = argparse.ArgumentParser(description='Ptychographic reconstruction script.')
-    parser.add_argument('nphotons', type=float, help='Number of photons')
-    args = parser.parse_args()
-    return args.nphotons
-
-if __name__ == '__main__':
-    nphotons = parse_arguments()
-    init(nphotons)
-
-    d, YY_ground_truth, stitched_obj = execute(nphotons)
-
-from importlib import reload
-def run_experiment_with_photons(photons_list, loss_fn='nll'):
-    print("DEBUG: Starting run_experiment_with_photons")
-    results = {}
-    first_iteration = True
-    for nphotons in photons_list:
-        init(nphotons, loss_fn=loss_fn)
-        print("DEBUG: nphotons set to", nphotons, "in run_experiment_with_photons")
-        if  first_iteration:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=False)
-        else:
-            d, YY_ground_truth, stitched_obj, train_output = execute(nphotons, reload_modules=True)
-        first_iteration = False
-        results[nphotons] = {'d': d, 'YY_ground_truth': YY_ground_truth, 'stitched_obj': stitched_obj, 'train_output': train_output}
-    return results
-import os
-import dill
-import pandas as pd
-import numpy as np
-from matplotlib.image import imread
-
-def has_amp_recon(subdir):
-    return os.path.exists(os.path.join(subdir, 'amp_recon.png'))
-
-def load_recent_experiment_data(directory, N):
-    subdirs = [os.path.join(directory, d) for d in os.listdir(directory) if is_valid_run(os.path.join(directory, d)) and has_amp_recon(os.path.join(directory, d))]
-    print(subdirs)
-    recent_subdirs = subdirs[:N]
-    subdirs.sort(key=lambda x: os.path.getmtime(x), reverse=True)
-
-    data = {}
-    for subdir in recent_subdirs:
-        params_path = os.path.join(subdir, 'params.dill')
-        metrics_path = os.path.join(subdir, 'metrics.csv')
-
-        with open(params_path, 'rb') as f:
-            params = dill.load(f)
-        metrics = pd.read_csv(metrics_path)
-
-        nphotons = (np.log10(params['nphotons']))
-        print('NPOHOT {}'.format(nphotons))
-        #if nphotons not in data or os.path.getmtime(params_path) > os.path.getmtime(os.path.join(data[nphotons]['dir'], 'params.dill')):
-        amp_recon_path = os.path.join(subdir, 'amp_recon.png')
-        amp_recon = imread(amp_recon_path)
-        data[nphotons] = {'params': params, 'metrics': metrics, 'amp_recon': amp_recon, 'dir': subdir}
-
-    return {k: {'params': v['params'], 'metrics': v['metrics']} for k, v in data.items()}
-def is_valid_run(subdir):
-    return os.path.exists(os.path.join(subdir, 'params.dill'))
-import matplotlib.pyplot as plt
-
-def generate_and_save_heatmap(experiment_entry, ax=None, photon_dose=None):
-    if ax is None:
-        fig, ax = plt.subplots()
-    stitched_obj = experiment_entry['stitched_obj'][0, :, :, 0]
-    metrics = experiment_entry['d']
-    frc50 = metrics.get('frc50', [None])[0]
-    psnr = metrics.get('psnr', [None])[0]
-
-    ax.imshow(np.abs(stitched_obj), cmap='jet', interpolation='nearest')
-    title = f'FRC50: {frc50:.2f}, PSNR: {psnr:.2f}'
-    if photon_dose is not None:
-        title = f'Photons: {photon_dose:.0e}, ' + title
-    ax.set_title(title)
-    ax.axis('off')
-
-def generate_2x2_heatmap_plots(res, layout=(1, 4), filename='heatmap_plots.png', axs=None,
-                               fig = None):
-#    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 4*layout[0]))
-#    axs = axs.flatten()
-    for i, (photon_dose, experiment_entry) in enumerate(res.items()):
-        generate_and_save_heatmap(experiment_entry, axs[i], photon_dose)
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.close(fig)
-
-def plot_heatmap_from_experiment(res, nphot, index):
-    import matplotlib.pyplot as plt
-    c = res[nphot]['train_output']['dataset']
-    plt.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    #plt.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-    plt.title(f'{nphot:.0e} photons', fontsize = 10)
-    plt.savefig(f'heatmap_photon_dose_{nphot:.0e}_index_{index}.png')
-    #plt.show()
-def plot_heatmaps_for_all_photons(res, index):
-    for nphot in res.keys():
-        plot_heatmap_from_experiment(res, nphot, index)
-    fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0]))
-
-def generate_2x2_heatmap_plots_using_function(res, index, layout=(1, 4), filename='heatmap_plots_2x2.png', border_color='black', border_width=2, axs=None):
-    a, b = layout
-    #fig, axs = plt.subplots(1, b, figsize=(24, 3))
-    #fig, axs = plt.subplots(layout[0], layout[1], figsize=(12, 3*layout[0])) if axs is None else (None, axs)
-    axs = axs.flatten()
-    photon_doses = list(res.keys())[: b]  # Select the first 4 photon doses for the 2x2 grid
-    for i, nphot in enumerate(photon_doses):
-        ax = axs[i]
-        c = res[nphot]['train_output']['dataset']
-        heatmap = ax.imshow(np.log10(c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        for spine in ax.spines.values():
-            spine.set_edgecolor(border_color)
-            spine.set_linewidth(border_width)
-        #ax.imshow(np.log10(.5 + c.X[index][:, :, 0]), cmap='viridis', interpolation='nearest')
-        #ax.set_title(f'{nphot:.0e} photons', fontsize=16)
-        ax.axis('off')
-    plt.tight_layout()
-    plt.savefig(filename)
-    if axs is None:
-        plt.tight_layout()
-        plt.savefig(filename)
-        #plt.show()
-
-def stack_and_display_horizontal_plots(res, index, layout=(1, 4), figsize=(24, 8), crop_size=None):
-    from matplotlib import pyplot as plt
-    import numpy as np
-
-    a, b = layout
-    fig, axs = plt.subplots(2, b, figsize=figsize)
-
-    if crop_size is not None:
-        def crop_center(img, cropx, cropy):
-            y, x = img.shape
-            startx = x // 2 - (cropx // 2)
-            starty = y // 2 - (cropy // 2)
-            return img[starty:starty + cropy, startx:startx + cropx]
-
-        cropped_res = {}
-        for dose, entry in res.items():
-            stitched_obj = entry['stitched_obj'][0, :, :, 0]
-            cropped_obj = crop_center(stitched_obj, crop_size, crop_size)
-            padded_obj = np.pad(cropped_obj, ((0, crop_size - cropped_obj.shape[0]), (0, crop_size - cropped_obj.shape[1])), mode='constant')
-            cropped_res[dose] = {'stitched_obj': np.expand_dims(np.expand_dims(padded_obj, axis=0), axis=-1), **{k: v for k, v in entry.items() if k != 'stitched_obj'}}
-
-        generate_2x2_heatmap_plots(cropped_res, layout=layout, axs=axs[0])
-    else:
-        generate_2x2_heatmap_plots(res, layout=layout, axs=axs[0])
-
-    generate_2x2_heatmap_plots_using_function(res, index, layout=layout, axs=axs[1], border_color='black', border_width=2)
-    plt.tight_layout()
-    fig.savefig(f'stacked_dose_progression_index_{index}.png')
-    plt.show()
diff --git a/build/lib/notebooks/test_generic_loader.py b/build/lib/notebooks/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/notebooks/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/notebooks/train_and_infer.py b/build/lib/notebooks/train_and_infer.py
deleted file mode 100644
index 6a33f16..0000000
--- a/build/lib/notebooks/train_and_infer.py
+++ /dev/null
@@ -1,159 +0,0 @@
-import logging
-import sys
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-
-from ptycho.workflows.components import (
-    load_data,
-    run_cdi_example,
-    save_outputs
-)
-from ptycho.config.config import TrainingConfig, InferenceConfig, ModelConfig, update_legacy_dict
-from ptycho import model_manager, params, probe
-from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer, probeshow
-
-# Configure logging
-logging.basicConfig(level=logging.INFO,
-                   format='%(asctime)s - %(levelname)s - %(message)s',
-                   handlers=[
-                       logging.StreamHandler(sys.stdout),
-                       logging.FileHandler('train_and_infer.log')
-                   ])
-logger = logging.getLogger(__name__)
-
-def train_model(config: TrainingConfig):
-    """Train the model using provided configuration."""
-    logger.info("Starting training process...")
-    
-    try:
-        # Load training data
-        ptycho_data = load_data(str(config.train_data_file), n_images=512)
-        
-        # Load test data if provided
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        # Run training
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        
-        # Save model and outputs
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-        
-        return recon_amp, recon_phase, results
-    
-    except Exception as e:
-        logger.error(f"Training failed: {e}")
-        raise
-
-def perform_inference(model: tf.keras.Model, test_data, K: int = 7, nsamples: int = 1):
-    """Perform inference using trained model."""
-    logger.info("Starting inference process...")
-    
-    try:
-        # Set probe guess and random seeds
-        probe.set_probe_guess(None, test_data.probeGuess)
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate test dataset
-        test_dataset = test_data.generate_grouped_data(params.cfg['N'], K=K, nsamples=nsamples)
-        
-        # Create data container
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        
-        # Reassemble position
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-        
-        # Process ePIE results
-        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-    
-    except Exception as e:
-        logger.error(f"Inference failed: {e}")
-        raise
-
-def plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase):
-    """Plot comparison between reconstructed and ePIE results."""
-    fig, axs = plt.subplots(2, 2, figsize=(12, 12))
-    
-    # Plot phases
-    im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-    axs[0, 0].set_title('PtychoPINN Phase')
-    fig.colorbar(im_pinn_phase, ax=axs[0, 0])
-    
-    im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    fig.colorbar(im_epie_phase, ax=axs[0, 1])
-    
-    # Plot amplitudes
-    im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    fig.colorbar(im_pinn_amp, ax=axs[1, 0])
-    
-    im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-    axs[1, 1].set_title('ePIE Amplitude')
-    fig.colorbar(im_epie_amp, ax=axs[1, 1])
-    
-    # Remove ticks
-    for ax in axs.flat:
-        ax.set_xticks([])
-        ax.set_yticks([])
-    
-    plt.tight_layout()
-    return fig
-
-def plot_probe(test_data):
-    """Generate probe visualization."""
-    return probeshow(test_data.probeGuess, test_data)
-
-# Example usage in notebook:
-"""
-# Configuration
-train_config = TrainingConfig(
-    model=ModelConfig(),
-    train_data_file=Path('path/to/train_data.npz'),
-    test_data_file=Path('path/to/test_data.npz'),
-    output_dir=Path('output_directory'),
-    debug=False
-)
-
-# Update global params
-update_legacy_dict(params.cfg, train_config)
-
-# Train model
-recon_amp, recon_phase, results = train_model(train_config)
-
-# Load model for inference
-model, _ = model_manager.ModelManager.load_model(train_config.output_dir)
-
-# Load test data
-test_data = load_data('path/to/test_data.npz')
-
-# Perform inference
-reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-    model, test_data, K=7, nsamples=1
-)
-
-# Plot results
-fig = plot_comparison(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase)
-plt.show()
-
-# Plot probe visualization
-probe_fig = plot_probe(test_data)
-plt.show()
-"""
diff --git a/build/lib/notebooks/williamson.jpeg b/build/lib/notebooks/williamson.jpeg
deleted file mode 100644
index f5718cb..0000000
Binary files a/build/lib/notebooks/williamson.jpeg and /dev/null differ
diff --git a/build/lib/ptycho/__init__.py b/build/lib/ptycho/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/autotest/__init__.py b/build/lib/ptycho/autotest/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/autotest/configuration.py b/build/lib/ptycho/autotest/configuration.py
deleted file mode 100644
index 2d66523..0000000
--- a/build/lib/ptycho/autotest/configuration.py
+++ /dev/null
@@ -1,13 +0,0 @@
-import os
-
-class Configuration:
-    def __init__(self, debug: bool = False, log_file_prefix: str = "logs"):
-        self.debug = debug
-        self.log_file_prefix = log_file_prefix
-
-    def getDebugFlag(self) -> bool:
-        return self.debug
-
-    def getLogFilePrefix(self) -> str:
-        return self.log_file_prefix
-
diff --git a/build/lib/ptycho/autotest/debug.py b/build/lib/ptycho/autotest/debug.py
deleted file mode 100644
index cfcfdf3..0000000
--- a/build/lib/ptycho/autotest/debug.py
+++ /dev/null
@@ -1,170 +0,0 @@
-from .serializer import Serializer
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-
-# spec
-#    @depends_on(Logger, Configuration, FunctionMapping)
-#    interface Debug {
-#        """
-#        Applies the debugging process to the function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - Configuration must allow debugging.
-#
-#        Postconditions:
-#        - If debugging is allowed by the Configuration:
-#          - Returns a new function that wraps the original function with debugging functionality.
-#          - The returned function, when called, performs two forms of logging:
-#            1. Prints function call and return information to the console, surrounded by XML tags
-#               containing the callable's module path and name. The console log messages are in the
-#               format `<module.function>CALL/RETURN args/result</module.function>`. For all array
-#               or tensor types (i.e., objects with a .shape and/or .dtype attribute), the shapes
-#               and data types are also printed.
-#            2. Serializes function inputs and outputs to a log file using the `logCall` and `logReturn`
-#               methods of the Logger interface. The serialized data can be loaded using the `LoadLog`
-#               method. If serialization fails, the console logging still occurs, but no log file is
-#               generated for that invocation.
-#          - Logs only the first two invocations of the function.
-#        - If debugging is not allowed by the Configuration:
-#          - Returns the original function unchanged, without any debugging functionality.
-#        """
-#        Callable decorate(Callable func);
-#    };
-
-## implementation
-import time
-import os
-import pickle
-import json
-from typing import Callable, Any, List, Union, Optional
-import re
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-class Debug:
-    def __init__(self):
-        self.configuration = Configuration()
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-
-    def decorate(self, func: Callable) -> Callable:
-        increment_count = make_invocation_counter()
-        if not self.configuration.getDebugFlag():
-            return func
-
-        else:
-            module_path = self.function_mapping.get_module_path(func)
-            function_name = func.__name__
-
-            def wrapper(*args: Any, **kwargs: Any) -> Any:
-                invocation_count = increment_count()
-                if invocation_count > 2:
-                    return func(*args, **kwargs)
-                
-                log_file_path = self.function_mapping.get_log_file_path(func)
-                os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
-
-                try:
-                    serialized_args = self.serializer.serialize(args)
-                    serialized_kwargs = self.serializer.serialize(kwargs)
-                    self.logger.logCall(serialized_args, serialized_kwargs, log_file_path)
-                except ValueError:
-                    pass  # If serialization fails, just proceed with console logging
-
-                console_log_start = f"<{module_path}.{function_name}>CALL"
-                console_log_args = self._formatConsoleLog(args)
-                console_log_kwargs = self._formatConsoleLog(kwargs)
-                print(console_log_start)
-                print(console_log_args)
-                print(console_log_kwargs)
-
-                start_time = time.time()
-
-                result = func(*args, **kwargs)
-                try:
-                    serialized_result = self.serializer.serialize(result)
-                    self.logger.logReturn(serialized_result, time.time() - start_time, log_file_path)
-
-                    console_log_end = f"</{module_path}.{function_name}>RETURN"
-                    console_log_result = self._formatConsoleLog(result)
-                    print(console_log_end + " " + console_log_result)
-
-                except Exception as e:
-                    self.logger.logError(str(e), log_file_path)
-                    print(f"<{module_path}.{function_name}>ERROR {str(e)}")
-                return result
-
-            return wrapper
-
-    def _formatConsoleLog(self, data: Any) -> str:
-        if not isinstance(data, tuple):
-            data = (data,)
-
-        formatted_data = []
-        for item in data:
-            if hasattr(item, 'shape') and hasattr(item, 'dtype'):
-                formatted_data.append(f"type={type(item)}, shape={item.shape}, dtype={item.dtype}")
-            elif isinstance(item, (int, float, str, bool)):
-                formatted_data.append(f"type={type(item)}, {item}")
-            else:
-                formatted_data.append(f"type={type(item)}")
-        return ", ".join(formatted_data)
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-import unittest
-
-class TestDebug(unittest.TestCase):
-    def setUp(self):
-        self.configuration = Configuration(debug=True)
-        self.serializer = Serializer()
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.debug = Debug(self.configuration, self.serializer, self.logger, self.function_mapping)
-
-    def test_decorate_call(self):
-        @self.debug.decorate
-        def add(x, y):
-            return x + y
-
-        result = add(3, 4)
-        self.assertEqual(result, 7)
-
-    def test_decorate_return(self):
-        @self.debug.decorate
-        def multiply(x, y):
-            return x * y
-
-        result = multiply(2, 3)
-        self.assertEqual(result, 6)
-        result = multiply(4, 5)
-        self.assertEqual(result, 20)
-        result = multiply(6, 7)  # This call should not be logged
-        self.assertEqual(result, 42)
-
-    def test_decorate_error(self):
-        @self.debug.decorate
-        def divide(x, y):
-            return x / y
-
-        with self.assertRaises(ZeroDivisionError):
-            divide(1, 0)
-
-
-obj = Debug()
-debug = obj.decorate
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
-
diff --git a/build/lib/ptycho/autotest/functionmapping.py b/build/lib/ptycho/autotest/functionmapping.py
deleted file mode 100644
index a9be5de..0000000
--- a/build/lib/ptycho/autotest/functionmapping.py
+++ /dev/null
@@ -1,185 +0,0 @@
-# spec
-#    interface FunctionMapping {
-#        """
-#        Retrieves the log file path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#        - `log_directory` must be a valid directory path.
-#        - Expected JSON format: { "log_directory": "string" }
-#
-#        Postconditions:
-#        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-#        - If `log_directory` is not provided or is an empty string, returns an empty string.
-#        """
-#        string getLogFilePath(Callable func, string log_directory);
-#
-#        """
-#        Loads a function given its log file path or module path.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid log file path or empty string.
-#        - `module_path` must be a valid module path or empty string.
-#        - Expected JSON format: { "log_file_path": "string", "module_path": "string" }
-#
-#        Postconditions:
-#        - Returns the function object if successfully loaded.
-#        - If the function cannot be found or imported, returns None.
-#        """
-#        Union[Callable, None] loadFunction(string log_file_path, string module_path);
-#
-#        """
-#        Retrieves the module path for a given function.
-#
-#        Preconditions:
-#        - `func` must be a callable.
-#
-#        Postconditions:
-#        - Returns the module path for the given function, formatted as `module.fname`.
-#        - If `func` is a built-in function or does not have a valid module path, returns an empty string.
-#        """
-#        string getModulePath(Callable func);
-#    };
-
-# implementation
-import os
-import shutil
-import importlib
-from typing import Callable, Optional
-
-def dprint(*args):
-    pass
-
-class FunctionMapping:
-    def __init__(self, log_directory: str = "logs"):
-        self.log_directory = log_directory
-
-    def get_log_file_path(self, func: Callable) -> str:
-        """
-        Retrieves the log file path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the log file path for the given function, formatted as `prefix/module.fname<suffix>.log`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_log_file_path(sample_function)
-        'test_logs/__main__.sample_function.log'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        log_file_path = f"{self.log_directory}/{module_name}.{func_name}.log"
-        return log_file_path
-
-    def save_function(self, log_file_path: str, func: Callable) -> None:
-        module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-        module = importlib.import_module(module_path)
-        setattr(module, func_name, func)
-
-    def load_function_from_path(self, log_file_path: str) -> Optional[Callable]:
-        try:
-            dprint(f"log_file_path: {log_file_path}")
-            module_path, func_name = self.get_module_and_function_from_log_path(log_file_path)
-            dprint(f"module_path: {module_path}")
-            dprint(f"func_name: {func_name}")
-            dprint(f"Importing module: {module_path}")
-            module = importlib.import_module(module_path)
-            dprint(f"Imported module: {module}")
-            dprint(f"Retrieving function: {func_name}")
-            func = getattr(module, func_name, None)
-            dprint(f"Retrieved function: {func}")
-            return func
-        except Exception as e:
-            dprint(f"Error loading function: {e}")
-            return None
-
-    def get_module_and_function_from_log_path(self, log_file_path: str) -> tuple:
-        dprint(f"log_file_path: {log_file_path}")
-        log_file_path = log_file_path.replace(f"{self.log_directory}/", "")
-        dprint(f"log_file_path after removing log_directory: {log_file_path}")
-        log_file_path = log_file_path.replace(".log", "")
-        dprint(f"log_file_path after removing .log: {log_file_path}")
-        parts = log_file_path.rsplit(".", 1)
-        print(parts)
-        dprint(f"parts: {parts}")
-        module_path = parts[0]
-        dprint(f"module_path: {module_path}")
-        func_name = parts[1]
-        dprint(f"func_name: {func_name}")
-        return module_path, func_name
-
-    def load_function(self, log_file_path: str) -> Optional[Callable]:
-        """
-        Loads a function given its log file path.
-        
-        Preconditions:
-        - `log_file_path` must be valid.
-        
-        Postconditions:
-        - Returns the function object if successfully loaded.
-        - If the function cannot be found or imported, returns None.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> log_file_path = function_mapping.get_log_file_path(sample_function)
-        >>> loaded_func = function_mapping.load_function(log_file_path)
-        """
-        return self.load_function_from_path(log_file_path)
-
-    def get_module_path(self, func: Callable) -> str:
-        """
-        Retrieves the module path for a given function.
-        
-        Preconditions:
-        - `func` must be a callable.
-        
-        Postconditions:
-        - Returns the module path for the given function, formatted as `module.fname`.
-        >>> function_mapping = FunctionMapping(log_directory="test_logs")
-        >>> def sample_function():
-        ...     return "sample function executed"
-        >>> function_mapping.get_module_path(sample_function)
-        '__main__.sample_function'
-        """
-        module_name = func.__module__
-        func_name = func.__name__
-        module_path = f"{module_name}.{func_name}"
-        return module_path
-
-
-if __name__ == "__main__":
-    import doctest
-    doctest.testmod(verbose=True)
-
-def sample_function():
-    return "sample function executed"
-
-def another_function():
-    return "another function executed"
-
-def test_get_log_file_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_log_file_path(sample_function)
-    assert path == 'test_logs/__main__.sample_function.log', f"Expected 'test_logs/__main__.sample_function.log', got '{path}'"
-
-def test_load_function():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    log_file_path = function_mapping.get_log_file_path(sample_function)
-    
-    loaded_func = function_mapping.load_function(log_file_path=log_file_path)
-    assert loaded_func is not None, "Expected function to be loaded, but got None"
-    assert loaded_func.__name__ == 'sample_function', f"Expected 'sample_function', got '{loaded_func.__name__}'"
-
-def test_get_module_path():
-    function_mapping = FunctionMapping(log_directory="test_logs")
-    path = function_mapping.get_module_path(sample_function)
-    assert path == '__main__.sample_function', f"Expected '__main__.sample_function', got '{path}'"
-
-if __name__ == "__main__":
-    test_get_log_file_path()
-    test_load_function()
-    test_get_module_path()
-    print("All tests passed!")
diff --git a/build/lib/ptycho/autotest/logger.py b/build/lib/ptycho/autotest/logger.py
deleted file mode 100644
index 8def564..0000000
--- a/build/lib/ptycho/autotest/logger.py
+++ /dev/null
@@ -1,242 +0,0 @@
-from .serializer import Serializer
-# spec
-#    @depends_on(Serializer)
-#    interface Logger {
-#        """
-#        Logs function call details to a specified log file.
-#
-#        Preconditions:
-#        - `args` and `kwargs` are serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized function arguments and keyword arguments are written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logCall(bytes args, bytes kwargs, string log_file_path);
-#
-#        """
-#        Logs function return details to the specified log file.
-#
-#        Preconditions:
-#        - `result` is serialized using pickle.
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The serialized `result` and `execution_time` are appended to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logReturn(bytes result, float execution_time, string log_file_path);
-#
-#        """
-#        Logs an error message to the specified log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with write permissions.
-#          The directory containing the file must exist.
-#
-#        Postconditions:
-#        - The `error` message is written to the log file.
-#          The log entry is formatted as a single line JSON string.
-#        - If there is an error during logging, an error message is printed to stderr.
-#        """
-#        void logError(string error, string log_file_path);
-#
-#        """
-#        Loads a logged dataset from a log file.
-#
-#        Preconditions:
-#        - `log_file_path` must be a valid file path with read permissions.
-#          The file must contain valid JSON-formatted log entries.
-#
-#        Postconditions:
-#        - Returns a list or tuple containing the logged inputs and output.
-#        - If there is an error during loading, returns an empty list or tuple.
-#        """
-#        Union[list, tuple] loadLog(Configuration configuration);
-#
-#        """
-#        Searches the log directory and returns all valid log file paths.
-#
-#        Preconditions:
-#        - `log_directory` must be a valid directory path with read permissions.
-#
-#        Postconditions:
-#        - Returns a list of valid log file paths adhering to the format ^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.?
-#        - Invalid log file paths are filtered out using the validateLogFilePath method.
-#        - If there are no valid log files or an error occurs during searching, returns an empty list.
-#        """
-#        list[str] searchLogDirectory(string log_directory);
-#
-#        """
-#        Validates a log file path against the expected format.
-#
-#        Preconditions:
-#        - `log_file_path` must be a string representing a file path.
-#
-#        Postconditions:
-#        - Returns True if the `log_file_path` adheres to the format '^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$.', False otherwise.
-#        """
-#        bool validateLogFilePath(string log_file_path);
-#    };
-
-import json
-import os
-import sys
-import pickle
-from typing import Any, Union, List
-import re
-
-class Logger:
-    def __init__(self):
-        self.serializer = Serializer()
-
-    def logCall(self, args: bytes, kwargs: bytes, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "args": args.hex(),
-                    "kwargs": kwargs.hex()
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function call: {e}", file=sys.stderr)
-
-    def logReturn(self, result: bytes, execution_time: float, log_file_path: str) -> None:
-        try:
-            with open(log_file_path, 'a') as log_file:
-                log_entry = json.dumps({
-                    "result": result.hex(),
-                    "execution_time": execution_time
-                })
-                log_file.write(log_entry + "\n")
-        except Exception as e:
-            print(f"Error logging function return: {e}", file=sys.stderr)
-
-    def logError(self, error: str, log_file_path: str) -> None:
-        pass
-#        try:
-#            with open(log_file_path, 'a') as log_file:
-#                log_entry = json.dumps({
-#                    "error": error
-#                })
-#                log_file.write(log_entry + "\n")
-#        except Exception as e:
-#            print(f"Error logging error: {e}", file=sys.stderr)
-
-    def loadLog(self, log_file_path: str) -> Union[List, tuple]:
-        logs = []
-        try:
-            with open(log_file_path, 'r') as log_file:
-                for line in log_file:
-                    log_entry = json.loads(line)
-                    if "args" in log_entry:
-                        log_entry["args"] = bytes.fromhex(log_entry["args"])
-                    if "kwargs" in log_entry:
-                        log_entry["kwargs"] = bytes.fromhex(log_entry["kwargs"])
-                    if "result" in log_entry:
-                        log_entry["result"] = bytes.fromhex(log_entry["result"])
-                    logs.append(log_entry)
-        except Exception as e:
-            print(f"Error loading log: {e}", file=sys.stderr)
-        return logs
-
-    def searchLogDirectory(self, log_directory: str) -> List[str]:
-        valid_log_files = []
-        try:
-            for root, _, files in os.walk(log_directory):
-                for file in files:
-                    file_path = os.path.relpath(os.path.join(root, file), start=log_directory)
-                    if self.validateLogFilePath(file_path):
-                        valid_log_files.append(os.path.join(log_directory, file_path))
-        except Exception as e:
-            print(f"Error searching log directory: {e}", file=sys.stderr)
-        return valid_log_files
-
-    def validateLogFilePath(self, log_file_path: str) -> bool:
-        return True
-        pattern = r'^(?P<log_path_prefix>[a-z0-9]+)/(?P<python_namespace_path>([a-z0-9]+\.)+)log$'
-        return re.match(pattern, log_file_path) is not None
-
-import unittest
-import tempfile
-
-class TestLogger(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.test_dir = tempfile.TemporaryDirectory()
-        self.test_file = os.path.join(self.test_dir.name, 'test.log')
-        
-    def tearDown(self):
-        self.test_dir.cleanup()
-
-    def test_logCall(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        self.logger.logCall(args, kwargs, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["args"], args.hex())
-            self.assertEqual(log_entry["kwargs"], kwargs.hex())
-
-    def test_logReturn(self):
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["result"], result.hex())
-            self.assertEqual(log_entry["execution_time"], execution_time)
-
-    def test_logError(self):
-        error = "Test error message"
-        self.logger.logError(error, self.test_file)
-        
-        with open(self.test_file, 'r') as log_file:
-            log_entry = json.loads(log_file.readline())
-            self.assertEqual(log_entry["error"], error)
-
-    def test_loadLog(self):
-        args = self.logger.serializer.serialize(('arg1', 'arg2'))
-        kwargs = self.logger.serializer.serialize({'key': 'value'})
-        result = self.logger.serializer.serialize('result')
-        execution_time = 0.123
-        
-        self.logger.logCall(args, kwargs, self.test_file)
-        self.logger.logReturn(result, execution_time, self.test_file)
-        
-        logs = self.logger.loadLog(self.test_file)
-        self.assertEqual(len(logs), 2)
-        self.assertEqual(logs[0]["args"], args)
-        self.assertEqual(logs[0]["kwargs"], kwargs)
-        self.assertEqual(logs[1]["result"], result)
-        self.assertEqual(logs[1]["execution_time"], execution_time)
-
-    def test_searchLogDirectory(self):
-        valid_file = os.path.join(self.test_dir.name, 'logs/module.samplefunc.log')
-        invalid_file = os.path.join(self.test_dir.name, 'invalid.log')
-        
-        os.makedirs(os.path.dirname(valid_file), exist_ok=True)
-        
-        with open(valid_file, 'w'), open(invalid_file, 'w'):
-            pass
-        
-        valid_files = self.logger.searchLogDirectory(self.test_dir.name)
-        self.assertIn(valid_file, valid_files)
-        self.assertNotIn(invalid_file, valid_files)
-
-    def test_validateLogFilePath(self):
-        valid_path = 'logs/module.samplefunc.log'
-        invalid_path = 'invalid.log'
-        
-        self.assertTrue(self.logger.validateLogFilePath(valid_path))
-        self.assertFalse(self.logger.validateLogFilePath(invalid_path))
-
-if __name__ == '__main__':
-    unittest.main(argv=[''], verbosity=2, exit=False)
diff --git a/build/lib/ptycho/autotest/serializer.py b/build/lib/ptycho/autotest/serializer.py
deleted file mode 100644
index bbf4035..0000000
--- a/build/lib/ptycho/autotest/serializer.py
+++ /dev/null
@@ -1,92 +0,0 @@
-# spec
-#module DebuggingSystem {
-#
-#    interface Serializer {
-#        """
-#        Serializes Python objects to a binary format using pickle.
-#
-#        Preconditions:
-#        - `input_data` must be a picklable Python object.
-#
-#        Postconditions:
-#        - Returns the serialized binary data of the input object.
-#        - Raises ValueError if the input data is not picklable.
-#        """
-#        bytes serialize(Any input_data);
-#
-#        """
-#        Deserializes Python objects from a binary format using pickle.
-#
-#        Preconditions:
-#        - `serialized_data` must be a valid pickle-serialized binary string.
-#
-#        Postconditions:
-#        - Returns the deserialized Python object.
-#        - Raises ValueError if the binary data could not be deserialized.
-#        """
-#        Any deserialize(bytes serialized_data);
-#    };
-
-import doctest
-import pickle
-from typing import Any, List
-
-class Serializer:
-    def serialize(self, input_data: Any) -> bytes:
-        """
-        Serializes Python objects to a binary format using pickle.
-
-        Preconditions:
-        - `input_data` must be a picklable Python object.
-
-        Postconditions:
-        - Returns the serialized binary data of the input object.
-        - Raises ValueError if the input data is not picklable.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> type(serialized_data)
-        <class 'bytes'>
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.serialize(lambda x: x)  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Input data is not picklable
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.dumps(input_data)
-        except (pickle.PicklingError, AttributeError, TypeError):
-            raise ValueError("Input data is not picklable")
-
-    def deserialize(self, serialized_data: bytes) -> Any:
-        """
-        Deserializes Python objects from a binary format using pickle.
-
-        Preconditions:
-        - `serialized_data` must be a valid pickle-serialized binary string.
-
-        Postconditions:
-        - Returns the deserialized Python object.
-        - Raises ValueError if the binary data could not be deserialized.
-
-        >>> s = Serializer()
-        >>> data = {'key': 'value'}
-        >>> serialized_data = s.serialize(data)
-        >>> deserialized_data = s.deserialize(serialized_data)
-        >>> deserialized_data == data
-        True
-        >>> s.deserialize(b'not a pickle')  # doctest: +IGNORE_EXCEPTION_DETAIL
-        Traceback (most recent call last):
-        ValueError: Could not deserialize the binary data
-        """
-        try:
-            return pickle.loads(serialized_data)
-        except (pickle.UnpicklingError, EOFError, AttributeError, ImportError, IndexError):
-            raise ValueError("Could not deserialize the binary data")
-doctest.testmod(verbose=True)
-
diff --git a/build/lib/ptycho/autotest/testing.py b/build/lib/ptycho/autotest/testing.py
deleted file mode 100644
index 4b609fb..0000000
--- a/build/lib/ptycho/autotest/testing.py
+++ /dev/null
@@ -1,173 +0,0 @@
-from .logger import Logger
-from .functionmapping import FunctionMapping
-from .configuration import Configuration
-
-import unittest
-from unittest.mock import MagicMock
-
-# skipped_count
-
-from typing import List, Tuple, Any, Optional, Callable, Union
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-from logger import Logger
-from functionmapping import FunctionMapping
-from configuration import Configuration
-
-import unittest
-from unittest.mock import MagicMock
-
-# skipped_count
-
-from typing import List, Tuple, Any, Optional, Callable, Union
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-class Testing:
-    def __init__(self, logger: Logger, function_mapping: FunctionMapping):
-        self.logger = logger
-        self.function_mapping = function_mapping
-
-    def testCallable(self, log_path_prefix: str, func: Callable) -> bool:
-        print(f"Debug: testCallable called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            for i in range(len(logs) // 2):
-                args = logs[2 * i]['args']
-                kwargs = logs[2 * i]['kwargs']
-                expected_output = logs[2 * i + 1]['result']
-                try:
-                    deserialized_args = self.logger.serializer.deserialize(args)
-                    deserialized_kwargs = self.logger.serializer.deserialize(kwargs)
-                    deserialized_expected_output = self.logger.serializer.deserialize(expected_output)
-                    actual_output = func(*deserialized_args, **deserialized_kwargs)
-                    #print(f"Debug: Actual output: {actual_output}")
-                    if actual_output != deserialized_expected_output:
-                        print("Debug: Test failed")
-                        return False
-                except Exception as e:
-                    print(f"Error testing function: {e}")
-                    return False
-        print("Debug: Test passed")
-        return True
-
-    def createTestCase(self, log_path_prefix: str) -> Union[tuple, None]:
-        print(f"Debug: createTestCase called with log_path_prefix: {log_path_prefix}")
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            logs = self.logger.loadLog(log_file)
-            #print(f"Debug: Loaded logs: {logs}")
-            if logs:
-                log = logs[0]
-                inputs = log['args']
-                expected_output = log['result']
-                func = self.function_mapping.load_function(log_file)
-                print(f"Debug: Loaded function: {func}")
-                if func is not None:
-                    return (inputs, expected_output, func)
-        print("Debug: No test case found")
-        return None
-
-    def runTestSuite(self, log_path_prefix: str) -> TestSummary:
-        print(f"Debug: runTestSuite called with log_path_prefix: {log_path_prefix}")
-        summary = TestSummary()
-        log_files = self.logger.searchLogDirectory(log_path_prefix)
-        print(f"Debug: Found log files: {log_files}")
-        for log_file in log_files:
-            test_case = self.createTestCase(log_path_prefix)
-            if test_case is not None:
-                inputs, expected_output, func = test_case
-                if self.testCallable(log_path_prefix, func):
-                    summary.increment_passed()
-                else:
-                    summary.increment_failed()
-            else:
-                summary.increment_skipped()
-        print(f"Debug: Test summary: {summary}")
-        return summary
-
-class TestSummary:
-    def __init__(self):
-        self.passed = 0
-        self.failed = 0
-        self.skipped = 0
-
-    def increment_passed(self):
-        self.passed += 1
-
-    def increment_failed(self):
-        self.failed += 1
-
-    def increment_skipped(self):
-        self.skipped += 1
-
-    def __repr__(self):
-        return f"TestSummary(passed={self.passed}, failed={self.failed}, skipped={self.skipped})"
-
-
-def add(x, y):
-    return x + y
-
-def multiply(x, y):
-    return x * y
-
-def divide(x, y):
-    return x / y
-
-class TestTesting(unittest.TestCase):
-    def setUp(self):
-        self.logger = Logger()
-        self.function_mapping = FunctionMapping()
-        self.testing = Testing(self.logger, self.function_mapping)
-
-    def test_testCallable(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.assertTrue(self.testing.testCallable(log_path_prefix, add))
-
-    def test_createTestCase(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        test_case = self.testing.createTestCase(log_path_prefix)
-        self.assertIsNotNone(test_case)
-        inputs, expected_output, func = test_case
-        self.assertEqual(self.logger.serializer.deserialize(inputs), (3, 4))
-        self.assertEqual(self.logger.serializer.deserialize(expected_output), 7)
-        self.assertEqual(func, add)
-
-    def test_runTestSuite(self):
-        log_path_prefix = 'test_logs'
-        self.logger.logReturn(log_path_prefix + '/add', (3, 4), 7)
-        self.logger.logReturn(log_path_prefix + '/multiply', (3, 4), 12)
-        self.function_mapping.save_function(log_path_prefix + '/add', add)
-        self.function_mapping.save_function(log_path_prefix + '/multiply', multiply)
-        summary = self.testing.runTestSuite(log_path_prefix)
-        self.assertIsInstance(summary, TestSummary)
-        self.assertEqual(summary.passed, 2)
-        self.assertEqual(summary.failed, 0)
-        self.assertEqual(summary.skipped, 0)
-
diff --git a/build/lib/ptycho/baselines.py b/build/lib/ptycho/baselines.py
deleted file mode 100644
index d7d1ae6..0000000
--- a/build/lib/ptycho/baselines.py
+++ /dev/null
@@ -1,100 +0,0 @@
-# based on https://github.com/mcherukara/PtychoNN/tree/master/TF2
-# with minor changes to make comparison to PtychoPINN easier
-from .tf_helper import *
-from . import params
-import tensorflow as tf
-import numpy as np
-
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras import Sequential
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-
-from ptycho import generate_data as data
-from .evaluation import recon_patches
-
-tf.keras.backend.clear_session()
-np.random.seed(123)
-
-# files=glob.glob('%s/*' %wt_path)
-# for file in files:
-#     os.remove(file)
-
-h,w=64,64
-nepochs=params.get('nepochs')
-wt_path = 'wts4' #Where to store network weights
-batch_size = 32
-
-n_filters_scale = params.params()['n_filters_scale']
-
-#Keras modules
-from tensorflow.keras.layers import UpSampling2D
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-
-#checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.hdf5' %wt_path,
-#                                            monitor='val_loss', verbose=1, save_best_only=True,
-#                                            save_weights_only=False, mode='auto', period=1)
-
-def build_model(X_train, Y_I_train, Y_phi_train):
-    tf.keras.backend.clear_session()
-    c = X_train.shape[-1]
-    input_img = Input(shape=(h, w, c))
-
-    x = Conv_Pool_block(input_img,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    x = Conv_Pool_block(x,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-    #Activations are all ReLu
-
-    encoded=x
-
-    #Decoding arm 1
-    x1=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x1=Conv_Up_block(x1,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded1 = Conv2D(c, (3, 3), padding='same')(x1)
-
-    #Decoding arm 2
-    x2=Conv_Up_block(encoded,n_filters_scale * 128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-    x2=Conv_Up_block(x2,n_filters_scale * 32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-    decoded2 = Conv2D(c, (3, 3), padding='same')(x2)
-    #Put together
-    autoencoder = Model(input_img, [decoded1, decoded2])
-    # Masked MAE creates a more apples-to-apples comparison with the main
-    # model, but it doesn't seem to affect the image quality
-    #autoencoder.compile(optimizer='adam', loss=masked_mae)
-    autoencoder.compile(optimizer='adam', loss='mean_absolute_error')
-    return autoencoder
-
-def train(X_train, Y_I_train, Y_phi_train, autoencoder = None):
-    if autoencoder is None:
-        autoencoder = build_model(X_train, Y_I_train, Y_phi_train)
-
-    print (autoencoder.summary())
-    #plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-
-    #history=autoencoder.fit(X_train,
-    history=autoencoder.fit(X_train * params.params()['intensity_scale'],
-        [Y_I_train, Y_phi_train], shuffle=True,
-        batch_size=batch_size, verbose=1, epochs=nepochs,
-        validation_split = 0.05, callbacks=[reduce_lr, earlystop])
-    return autoencoder, history
diff --git a/build/lib/ptycho/classes.py b/build/lib/ptycho/classes.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/config/__init__.py b/build/lib/ptycho/config/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/config/config.py b/build/lib/ptycho/config/config.py
deleted file mode 100644
index c49e74c..0000000
--- a/build/lib/ptycho/config/config.py
+++ /dev/null
@@ -1,149 +0,0 @@
-from dataclasses import dataclass, asdict
-from pathlib import Path
-from typing import Dict, Any, Optional, Literal
-import yaml
-
-@dataclass(frozen=True)
-class ModelConfig:
-    """Core model architecture parameters."""
-    N: Literal[64, 128, 256] = 64
-    gridsize: int = 1
-    n_filters_scale: int = 2
-    model_type: Literal['pinn', 'supervised'] = 'pinn'
-    amp_activation: Literal['sigmoid', 'swish', 'softplus', 'relu'] = 'sigmoid'
-    object_big: bool = True
-    probe_big: bool = True  # Changed default
-    probe_mask: bool = False  # Changed default
-    pad_object: bool = True
-    probe_scale: float = 4.
-    gaussian_smoothing_sigma: float = 0.0
-
-@dataclass(frozen=True)
-class TrainingConfig:
-    """Training specific configuration."""
-    model: ModelConfig
-    train_data_file: Path  # Added
-    test_data_file: Optional[Path] = None  # Added
-    batch_size: int = 16
-    nepochs: int = 50
-    mae_weight: float = 0.0
-    nll_weight: float = 1.0
-    realspace_mae_weight: float = 0.0
-    realspace_weight: float = 0.0
-    nphotons: float = 1e9
-    positions_provided: bool = True  
-    probe_trainable: bool = False
-    intensity_scale_trainable: bool = True  # Changed default
-    output_dir: Path = Path("training_outputs")
-
-@dataclass(frozen=True)
-class InferenceConfig:
-    """Inference specific configuration."""
-    model: ModelConfig
-    model_path: Path
-    test_data_file: Path
-    debug: bool = False
-    output_dir: Path = Path("inference_outputs")
-
-def validate_model_config(config: ModelConfig) -> None:
-    """Validate model configuration."""
-    if config.gridsize <= 0:
-        raise ValueError(f"gridsize must be positive, got {config.gridsize}")
-    if config.n_filters_scale <= 0:
-        raise ValueError(f"n_filters_scale must be positive, got {config.n_filters_scale}")
-    if config.probe_scale <= 0:
-        raise ValueError(f"probe_scale must be positive, got {config.probe_scale}")
-    if config.gaussian_smoothing_sigma < 0:
-        raise ValueError(f"gaussian_smoothing_sigma must be non-negative, got {config.gaussian_smoothing_sigma}")
-
-def validate_training_config(config: TrainingConfig) -> None:
-    """Validate training configuration."""
-    validate_model_config(config.model)
-    if config.batch_size <= 0 or (config.batch_size & (config.batch_size - 1)):
-        raise ValueError(f"batch_size must be positive power of 2, got {config.batch_size}")
-    if config.nepochs <= 0:
-        raise ValueError(f"nepochs must be positive, got {config.nepochs}")
-    if not (0 <= config.mae_weight <= 1):
-        raise ValueError(f"mae_weight must be in [0,1], got {config.mae_weight}")
-    if not (0 <= config.nll_weight <= 1):
-        raise ValueError(f"nll_weight must be in [0,1], got {config.nll_weight}")
-    if config.nphotons <= 0:
-        raise ValueError(f"nphotons must be positive, got {config.nphotons}")
-
-def validate_inference_config(config: InferenceConfig) -> None:
-    """Validate inference configuration."""
-    validate_model_config(config.model)
-    if not config.model_path.exists():
-        raise ValueError(f"model_path does not exist: {config.model_path}")
-
-def load_yaml_config(path: Path) -> Dict[str, Any]:
-    """Load YAML configuration file.
-    
-    Args:
-        path: Path to YAML config file
-        
-    Returns:
-        Dictionary containing configuration values
-        
-    Raises:
-        OSError: If file cannot be read
-        yaml.YAMLError: If YAML is invalid
-    """
-    try:
-        with open(path) as f:
-            return yaml.safe_load(f)
-    except (OSError, yaml.YAMLError) as e:
-        raise type(e)(f"Failed to load config from {path}: {str(e)}")
-
-def dataclass_to_legacy_dict(obj: Any) -> Dict[str, Any]:
-    """Convert dataclass to legacy dictionary format with key mappings.
-    
-    Args:
-        obj: Dataclass instance to convert
-        
-    Returns:
-        Dictionary with legacy parameter names and values
-    """
-    # Key mappings from dataclass field names to legacy param names
-    KEY_MAPPINGS = {
-        'object_big': 'object.big',
-        'probe_big': 'probe.big', 
-        'probe_mask': 'probe.mask',
-        'probe_trainable': 'probe.trainable',
-        'intensity_scale_trainable': 'intensity_scale.trainable',
-        'positions_provided': 'positions.provided',
-        'output_dir': 'output_prefix'
-    }
-
-    # Convert dataclass to dict
-    d = asdict(obj)
-
-    # Handle nested ModelConfig
-    if 'model' in d:
-        model_dict = d.pop('model')
-        d.update(model_dict)
-
-    # Apply key mappings
-    for old_key, new_key in KEY_MAPPINGS.items():
-        if old_key in d:
-            d[new_key] = d.pop(old_key)
-
-    # Convert Path to string
-    if 'output_dir' in d:
-        d['output_prefix'] = str(d.pop('output_dir'))
-
-    return d
-
-def update_legacy_dict(cfg: Dict[str, Any], dataclass_obj: Any) -> None:
-    """Update legacy dictionary with dataclass values.
-    
-    Updates all values from the dataclass, adding new keys if needed.
-    
-    Args:
-        cfg: Legacy dictionary to update
-        dataclass_obj: Dataclass instance containing new values
-    """
-    new_values = dataclass_to_legacy_dict(dataclass_obj)
-    
-    # Update all values from dataclass
-    cfg.update(new_values)
diff --git a/build/lib/ptycho/data_preprocessing.py b/build/lib/ptycho/data_preprocessing.py
deleted file mode 100644
index 5d3ea10..0000000
--- a/build/lib/ptycho/data_preprocessing.py
+++ /dev/null
@@ -1,181 +0,0 @@
-from sklearn.utils import shuffle
-import numpy as np
-
-from ptycho import params
-from ptycho import diffsim as datasets
-import tensorflow as tf
-
-from .loader import PtychoDataset, PtychoDataContainer
-from ptycho import loader
-from ptycho import probe
-
-if params.get('outer_offset_train') is None or params.get('outer_offset_test') is None:
-    assert params.get('data_source') == 'generic'
-
-def load_simulated_data(size, probe, outer_offset_train, outer_offset_test, jitter_scale, intensity_scale=None):
-    np.random.seed(1)
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), size, probe, outer_offset_train, jitter_scale=jitter_scale, which = 'train')
-    params.cfg['intensity_scale'] = intensity_scale
-
-    np.random.seed(2)
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, which = 'test')
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_experimental_data(probe, outer_offset_train, outer_offset_test, jitter_scale):
-    from ptycho import experimental
-    YY_I, YY_phi = experimental.get_full_experimental('train')
-    X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, _, (coords_train_nominal, coords_train_true) = \
-        datasets.mk_simdata(params.get('nimgs_train'), experimental.train_size, probe, outer_offset_train, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    YY_I, YY_phi = experimental.get_full_experimental('test')
-    X_test, Y_I_test, Y_phi_test, _, YY_test_full, norm_Y_I_test, (coords_test_nominal, coords_test_true) = \
-        datasets.mk_simdata(params.get('nimgs_test'), experimental.test_size, probe, outer_offset_test, intensity_scale, jitter_scale=jitter_scale, YY_I=YY_I, YY_phi=YY_phi)
-
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true
-
-def load_xpp_data(probeGuess):
-    from ptycho import xpp
-    train_data_container = loader.load(xpp.get_data, probeGuess, which='train')
-    test_data_container = loader.load(xpp.get_data, probeGuess, which='test')
-    return train_data_container, test_data_container
-
-def load_generic_data(probeGuess, N):
-    from ptycho.loader import RawData
-    train_data_file_path = params.get('train_data_file_path')
-    test_data_file_path = params.get('test_data_file_path')
-
-    train_raw, test_raw = RawData.from_files(train_data_file_path, test_data_file_path)
-
-    dset_train = train_raw.generate_grouped_data(N, K=7, nsamples=1)
-    dset_test = test_raw.generate_grouped_data(N, K=7, nsamples=1)
-
-    train_data_container = loader.load(lambda: dset_train, probeGuess, which=None, create_split=False)
-    test_data_container = loader.load(lambda: dset_test, probeGuess, which=None, create_split=False)
-    return train_data_container, test_data_container
-
-def shuffle_data(X, Y_I, Y_phi, random_state=0):
-    indices = np.arange(len(Y_I))
-    indices_shuffled = shuffle(indices, random_state=random_state)
-
-    X_shuffled = X[indices_shuffled]
-    Y_I_shuffled = Y_I[indices_shuffled]
-    Y_phi_shuffled = Y_phi[indices_shuffled]
-
-    return X_shuffled, Y_I_shuffled, Y_phi_shuffled, indices_shuffled
-
-def get_clipped_object(YY_full, outer_offset):
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-
-    extra_size = (YY_full.shape[1] - (params.cfg['N'] + (params.cfg['gridsize'] - 1) * params.cfg['offset'])) % (outer_offset // 2)
-    if extra_size > 0:
-        YY_ground_truth = YY_full[:, :-extra_size, :-extra_size]
-    else:
-        print('discarding length {} from test image'.format(extra_size))
-        YY_ground_truth = YY_full
-    YY_ground_truth = YY_ground_truth[:, clipleft:-clipright, clipleft:-clipright]
-    return YY_ground_truth
-
-def get_clip_sizes(outer_offset):
-    N = params.cfg['N']
-    gridsize = params.cfg['gridsize']
-    offset = params.cfg['offset']
-    bordersize = (N - outer_offset / 2) / 2
-    borderleft = int(np.ceil(bordersize))
-    borderright = int(np.floor(bordersize))
-    clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-    clipleft = int(np.ceil(clipsize))
-    clipright = int(np.floor(clipsize))
-    return borderleft, borderright, clipleft, clipright
-
-def stitch_data(b, norm_Y_I_test=1, norm=True, part='amp', outer_offset=None, nimgs=None):
-    if nimgs is None:
-        nimgs = params.get('nimgs_test')
-    if outer_offset is None:
-        outer_offset = params.get('outer_offset_test')
-    nsegments = int(np.sqrt((int(tf.size(b)) / nimgs) / (params.cfg['N']**2)))
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    else:
-        img_recon = np.reshape((getpart(b)), (-1, nsegments, nsegments, params.cfg['N'], params.cfg['N'], 1))
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    return stitched
-
-def reassemble(b, norm_Y_I = 1., part='amp', **kwargs):
-    stitched = stitch_data(b, norm_Y_I, norm=False, part=part, **kwargs)
-    return stitched
-
-def process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test):
-    X_train, Y_I_train, Y_phi_train, indices_shuffled = shuffle_data(np.array(X_train), np.array(Y_I_train), np.array(Y_phi_train))
-    if params.get('outer_offset_train') is not None:
-        YY_ground_truth_all = get_clipped_object(YY_test_full, outer_offset_test)
-        YY_ground_truth = YY_ground_truth_all[0, ...]
-        print('DEBUG: generating grid-mode ground truth image')
-    else:
-        YY_ground_truth = None
-        print('DEBUG: No ground truth image in non-grid mode')
-    return X_train, Y_I_train, Y_phi_train, YY_ground_truth
-
-def create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                          X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true):
-    return PtychoDataset(
-        PtychoDataContainer(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true, None, None, None, probe.get_probe(fmt='np')),
-        PtychoDataContainer(X_test, Y_I_test, Y_phi_test, intensity_scale, YY_test_full, coords_test_nominal, coords_test_true, None, None, None, probe.get_probe(fmt='np')),
-    )
-
-def generate_data(probeGuess = None):
-    # TODO handle probeGuess None case
-    data_source = params.params()['data_source']
-    probe_np = probe.get_probe(fmt='np')
-    outer_offset_train = params.cfg['outer_offset_train']
-    outer_offset_test = params.cfg['outer_offset_test']
-    YY_test_full = None
-    norm_Y_I_test = None
-
-    if data_source in ['lines', 'grf', 'points', 'testimg', 'diagonals', 'V']:
-        size = params.cfg['size']
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_simulated_data(size, probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'experimental':
-        X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, intensity_scale, YY_train_full, YY_test_full, norm_Y_I_test, coords_train_nominal, coords_train_true, coords_test_nominal, coords_test_true = \
-            load_experimental_data(probe_np, outer_offset_train, outer_offset_test, params.params()['sim_jitter_scale'])
-        X_train, Y_I_train, Y_phi_train, YY_ground_truth = process_simulated_data(X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_test_full, outer_offset_test)
-        ptycho_dataset = create_ptycho_dataset(X_train, Y_I_train, Y_phi_train, intensity_scale, YY_train_full, coords_train_nominal, coords_train_true,
-                                               X_test, Y_I_test, Y_phi_test, YY_test_full, coords_test_nominal, coords_test_true)
-    elif data_source == 'xpp':
-        test_data_container, train_data_container = load_xpp_data(probeGuess)
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        YY_test_full = None
-    elif data_source == 'generic':
-        train_data_container, test_data_container = load_generic_data(probeGuess, params.cfg['N'])
-        intensity_scale = train_data_container.norm_Y_I
-        ptycho_dataset = PtychoDataset(train_data_container, test_data_container)
-        YY_ground_truth = None
-        print('INFO: train data:')
-        print(train_data_container)
-        print('INFO: test data:')
-        print(test_data_container)
-    else:
-        raise ValueError("Invalid data source")
-
-    params.cfg['intensity_scale'] = intensity_scale
-    return ptycho_dataset.train_data.X, ptycho_dataset.train_data.Y_I, ptycho_dataset.train_data.Y_phi, ptycho_dataset.test_data.X, ptycho_dataset.test_data.Y_I, ptycho_dataset.test_data.Y_phi, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
diff --git a/build/lib/ptycho/datagen/__init__.py b/build/lib/ptycho/datagen/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/datagen/diagonals.py b/build/lib/ptycho/datagen/diagonals.py
deleted file mode 100644
index 1c4bac9..0000000
--- a/build/lib/ptycho/datagen/diagonals.py
+++ /dev/null
@@ -1,40 +0,0 @@
-import numpy as np
-
-def draw_lines(shape, num):
-    num_vertical = num_horizontal = num_diagonal = num
-    # Create a 2D NumPy array with zeros
-    arr = np.zeros(shape)
-    n, m = shape
-
-    # Draw vertical lines
-    for i in range(num_vertical):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        arr[:, x] = 1
-
-    # Draw horizontal lines
-    for i in range(num_horizontal):
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        arr[y, :] = 1
-
-    # Draw diagonal lines
-    for i in range(num_diagonal):
-        x = np.random.randint(0, shape[1])  # Random x coordinate
-        y = np.random.randint(0, shape[0])  # Random y coordinate
-        off = min(x, y)
-        x = x - off
-        y = y - off
-        ix = np.arange(x, n - y)
-        iy = np.arange(y, m - x)
-        arr[ix, iy] = 1
-        arr[ix, -iy] = 1
-
-    return arr
-
-
-from scipy.ndimage import gaussian_filter as gf
-def mk_diags(N, sigma = .75):
-    img = draw_lines((N, N), 40)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/ptycho/datagen/grf.py b/build/lib/ptycho/datagen/grf.py
deleted file mode 100644
index 8ab01fd..0000000
--- a/build/lib/ptycho/datagen/grf.py
+++ /dev/null
@@ -1,73 +0,0 @@
-# credit https://github.com/PabloVD/MapGenerator
-
-import matplotlib.pyplot as plt
-import numpy as np
-import powerbox as pbox
-from scipy import interpolate, ndimage
-
-#--- Parameters for GRF---#
-
-
-# Number of bins per dimension
-boxsize = 100#(max(xx.shape) + 1) // 2#xx.shape[0] // 2
-# Number of bins per dimension in the high resolution  box
-
-# Define power spectrum as a power law with an spectral index indexlaw
-# With lower the spectral indexes, small structures are removed
-def powerspec(k,indexlaw):
-    return k**indexlaw
-
-# Filter the field with a gaussian window
-def smooth_field(field,sigmagauss,gridsize=boxsize):
-
-    x, y = np.linspace(0,field.shape[0],num=field.shape[0]), np.linspace(0,field.shape[1],num=field.shape[1])
-
-    # Interpolation
-    f = interpolate.interp2d(x,y,field,kind="linear")
-
-    qx = np.linspace(x[0],x[-1], num = gridsize)
-    qy = np.linspace(y[0],y[-1], num = gridsize)
-
-    # Filtering
-    smooth = ndimage.filters.gaussian_filter(f(qx,qy),sigmagauss)
-    return smooth
-
-# Remove regions below sea level
-def mainland(field,threshold):
-    for i, row in enumerate(field):
-        for j, el in enumerate(row):
-            if el<threshold:   field[i,j]=0.
-    return field
-
-# Normalize the values of the field between 0 and 1
-def normalize_field(field):
-    min, max = np.amin(field), np.amax(field)
-    newfield = (field-min)/(max-min)
-    return newfield
-
-# Generate a map of islands applying different processes:
-# 1. Generate a random gaussian field given a power spectrum
-# 2. Normalize the field between 0 and 1
-# 3. Smooth the field with a gaussian filter
-# 4. Retain only the mainland above a certain threshold
-def generate_map(indexlaw,sigma,threshold, boxsize):
-    # Number of bins per dimension in the high resolution  box
-    highboxsize = 2*boxsize
-    field = pbox.powerbox.PowerBox(boxsize, lambda k: powerspec(k,indexlaw), dim=2, boxlength=100.).delta_x()
-    field = normalize_field(field)
-    field = smooth_field(field,sigma,gridsize=highboxsize)
-    return field
-
-def mk_grf(N):
-    assert not N % 2
-    boxsize = N // 2
-    # Threshold for the sea level
-    threshold = 0.4
-    # Sigma for the gaussian smoothing
-    sigma = 1
-    # Spectral index for the power spectrum
-    indexlaw = -.4
-    res = np.zeros((N, N, 1))
-    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-    return res
-
diff --git a/build/lib/ptycho/datagen/points.py b/build/lib/ptycho/datagen/points.py
deleted file mode 100644
index eb415e4..0000000
--- a/build/lib/ptycho/datagen/points.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def randones(N, pct = .1):
-    """
-    Return array whose entries are randomly either 0 or 1.
-    """
-    rows, cols = N, N
-
-    # define the percentage of entries to increment
-    pct = 0.1
-
-    # create a 2D numpy array of all 0s
-    arr = np.zeros((rows, cols))
-
-    # determine the number of entries to increment
-    num_entries = int(rows * cols * pct)
-
-    # randomly select indices to increment with replacement
-    indices = np.random.choice(rows * cols, num_entries)
-
-    # increment the values at the selected indices by 1
-    np.add.at(arr, np.unravel_index(indices, (rows, cols)), 1)
-
-    # print the resulting array
-    return arr
-
-
-def mk_points(N, sigma = 1, pct = .15):
-    img = randones(N, pct = pct)
-    img = gf(img, sigma)
-    img = img + gf(img, 10 * sigma) * 5
-    img = img[:, :, None]
-    return img
diff --git a/build/lib/ptycho/datagen/testimg.py b/build/lib/ptycho/datagen/testimg.py
deleted file mode 100644
index 5f49b13..0000000
--- a/build/lib/ptycho/datagen/testimg.py
+++ /dev/null
@@ -1,55 +0,0 @@
-import matplotlib.pyplot as plt
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-import os
-from scipy import misc
-from imageio import imread
-from ptycho import tf_helper as hh
-from ptycho import params
-import tensorflow as tf
-
-def first_and_last(it):
-    it = iter(it)  # Ensure it's an iterator
-    try:
-        first = next(it)  # Get the first item
-    except StopIteration:
-        return  # If the iterator is empty, return an empty iterator
-    last = None
-    for last in it:  # Traverse the rest of the iterator to find the last item
-        pass
-    if last is None:
-        yield first
-    else:
-        yield first
-        yield last
-
-path = './'
-image = imread(os.path.join(path,'williamson.jpeg')).astype(float)
-image /= image.mean()
-image = image[None, 100:, :, :1]
-
-N = params.get('size')
-imgs = hh.extract_patches(image, N, N)
-imgs = tf.reshape(imgs, (-1,) + (N, N))
-
-# Convert TensorFlow tensor to NumPy array for reversible operations
-imgs_np = imgs.numpy()
-rev = imgs_np[::-1]  # Reversing using NumPy slicing
-
-# Convert back to TensorFlow tensor if needed
-rev_tensor = tf.convert_to_tensor(rev, dtype=tf.float32)
-it = iter(imgs_np)  # Iterator for original order
-rev_it = iter(rev_tensor)  # Iterator for reversed order
-
-def get_block(reverse = False):
-    if reverse:
-        return np.array(next(rev_it))
-    return np.array(next(it))
-
-def get_img(N = None, sigma = .5, reverse = False):
-    img = get_block(reverse = reverse)
-    # Anti-aliasing
-    img = gf(img, sigma)
-    img = img[:, :, None]
-    return img
-
diff --git a/build/lib/ptycho/datagen/vendetta.py b/build/lib/ptycho/datagen/vendetta.py
deleted file mode 100644
index 5676c59..0000000
--- a/build/lib/ptycho/datagen/vendetta.py
+++ /dev/null
@@ -1,78 +0,0 @@
-import numpy as np
-import scipy.ndimage
-import matplotlib.pyplot as plt
-
-from scipy.ndimage import zoom
-import numpy as np
-
-from PIL import Image, ImageDraw, ImageFont
-import numpy as np
-from scipy.ndimage import gaussian_filter as gf
-
-def letter_to_array(letter, font_path, font_size, image_size):
-    # Create a blank image
-    img = Image.new('L', image_size, 255)  # 'L' stands for 8-bit pixels, black and white
-
-    # Get drawing context
-    d = ImageDraw.Draw(img)
-
-    # Define font
-    font = ImageFont.truetype(font_path, font_size)
-
-    # Get text width and height
-    text_width, text_height = d.textsize(letter, font=font)
-
-    # Calculate X, Y position of the text
-    x = (image_size[0] - text_width) / 2
-    y = (image_size[1] - text_height) / 2
-
-    # Draw the text onto the image
-    d.text((x, y), letter, font=font, fill=(0))
-
-    # Convert the image data to a numpy array
-    data = np.array(img)
-
-    # Convert to binary (0 and 1)
-    binary_data = np.where(data < 128, 1, 0)
-
-    return binary_data
-
-# Use a font available on your system (this path is for demonstration; adjust accordingly)
-font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
-sprite = letter_to_array('V', font_path, font_size=50, image_size=(60, 60))
-
-def create_canvas(size):
-    return np.zeros((size, size))
-
-def create_sprite():
-    return sprite
-
-def add_sprite_to_canvas(canvas, sprite, repetitions):
-    for _ in range(repetitions):
-        scale = 0.05 + .4 * np.random.rand()
-        scaled_sprite = scipy.ndimage.zoom(sprite, scale)
-
-        tx = np.random.randint(0, canvas.shape[0] - scaled_sprite.shape[0])
-        ty = np.random.randint(0, canvas.shape[1] - scaled_sprite.shape[1])
-
-        x_end = min(tx + scaled_sprite.shape[0], canvas.shape[0])
-        y_end = min(ty + scaled_sprite.shape[1], canvas.shape[1])
-
-        canvas[tx:x_end, ty:y_end] += scaled_sprite[:x_end-tx, :y_end-ty]
-
-#def visualize_canvas(canvas):
-#    plt.imshow(canvas, cmap='gray')
-#    plt.show()
-
-def mk_vs(N, nfeats = 1000):
-    from . import fourier as f
-    assert not N % 2
-    canvas = create_canvas(N)
-    sprite = create_sprite()
-    add_sprite_to_canvas(canvas, sprite, nfeats)
-    res = canvas[..., None]
-    res = f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-    return res / res.max()
-#    res = np.zeros((N, N, 1))
-#    res[:, :, :] = generate_map(indexlaw, sigma, threshold, boxsize)[..., None]
-#    return res
diff --git a/build/lib/ptycho/diffsim.py b/build/lib/ptycho/diffsim.py
deleted file mode 100644
index 59c88fb..0000000
--- a/build/lib/ptycho/diffsim.py
+++ /dev/null
@@ -1,227 +0,0 @@
-from skimage import draw, morphology
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import matplotlib.pyplot as plt
-import numpy as np
-import tensorflow as tf
-
-from . import fourier as f
-from . import tf_helper as hh
-from . import params as p
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-
-N = 64
-
-def observe_amplitude(amplitude):
-    """
-    Sample photons from wave amplitudes by drwaing from the corresponding Poisson distributions
-    """
-    return tf.sqrt((hh.tfd.Independent(hh.tfd.Poisson(amplitude**2))).sample())# + 0.5
-
-def count_photons(obj):
-    return tf.math.reduce_sum(obj**2, (1, 2))
-
-def scale_nphotons(padded_obj):
-    """
-    Calculate the object amplitude normalization factor that gives the desired
-    *expected* number of observed photons, averaged over an entire dataset.
-
-    Returns a single scalar.
-    """
-    mean_photons = tf.math.reduce_mean(count_photons(padded_obj))
-    norm = tf.math.sqrt(p.get('nphotons') / mean_photons)
-    return norm
-
-def diffract_obj(sample, draw_poisson = True):
-    N = p.get('N')
-    amplitude = hh.pad_and_diffract(sample, N, N, pad=False)[1]
-    if draw_poisson:
-        observed_amp = observe_amplitude(amplitude)
-        return observed_amp
-    else:
-        return amplitude
-
-def illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = None):
-    """
-    Illuminate object with real or complex probe, then apply diffraction map.
-
-    Returned Y_I and Y_phi are amplitude and phase *after* illumination with the
-    probe.
-    """
-    if intensity_scale is None:
-        intensity_scale = scale_nphotons(Y_I * probe[None, ..., None]).numpy()
-    batch_size = p.get('batch_size')
-    obj = intensity_scale * hh.combine_complex(Y_I, Y_phi)
-    obj = obj * tf.cast(probe[None, ..., None], obj.dtype)
-    Y_I = tf.math.abs(obj)
-
-    X = (tf.data.Dataset.from_tensor_slices(obj)
-               .batch(batch_size)
-               .prefetch(tf.data.AUTOTUNE)
-               .map(diffract_obj)
-               .cache())
-    X = np.vstack(list(iter(X)))
-    X, Y_I, Y_phi =\
-        X / intensity_scale, Y_I / intensity_scale, Y_phi
-
-    X, Y_I, Y_phi =\
-        hh.togrid(X, Y_I, Y_phi)
-
-    X, Y_I, Y_phi =\
-        hh.grid_to_channel(X, Y_I, Y_phi)
-
-    return X, Y_I, Y_phi, intensity_scale
-
-def mk_rand(N):
-    return int(N * np.random.uniform())
-
-def mk_lines_img(N = 64, nlines = 10):
-    image = np.zeros((N, N))
-    for _ in range(nlines):
-        rr, cc = draw.line(mk_rand(N), mk_rand(N), mk_rand(N), mk_rand(N))
-        image[rr, cc] = 1
-    res = np.zeros((N, N, 3))
-    res[:, :, :] = image[..., None]
-    return f.gf(res, 1) + 2 * f.gf(res, 5) + 5 * f.gf(res, 10)
-
-def mk_noise(N = 64, nlines = 10):
-    return np.random.uniform(size = N * N).reshape((N, N, 1))
-
-from ptycho.misc import memoize_disk_and_memory
-
-def extract_coords(size, repeats = 1, coord_type = 'offsets',
-        outer_offset = None, **kwargs):
-    """
-    Return nominal offset coords in channel format. x and y offsets are
-    stacked in the third dimension.
-
-    offset coordinates are r - r', where
-        r' is the patch center of mass
-        r is the center of mass of that patch's solution region / grid,
-            which contains gridsize**2 patches
-    """
-    x = tf.range(size, dtype = tf.float32)
-    y = tf.range(size, dtype = tf.float32)
-    xx, yy = tf.meshgrid(x, y)
-    xx = xx[None, ..., None]
-    yy = yy[None, ..., None]
-    def _extract_coords(zz, fn):
-        ix = fn(zz)
-        ix = tf.reduce_mean(ix, axis = (1, 2))
-        return tf.repeat(ix, repeats, axis = 0)[:, None, None, :]
-    def outer(img):
-        return hh.extract_outer(img, fmt = 'grid', outer_offset = outer_offset)
-    def inner(img):
-        return hh.extract_nested_patches(img, fmt = 'channel',
-            outer_offset = outer_offset)
-    def get_patch_offsets(coords):
-        offsets_x = coords[1][0] - coords[0][0]
-        offsets_y = coords[1][1] - coords[0][1]
-        return tf.stack([offsets_x, offsets_y], axis = 2)[:, :, :, 0, :]
-    ix = _extract_coords(xx, inner)
-    iy = _extract_coords(yy, inner)
-    ix_offsets = _extract_coords(xx, outer)
-    iy_offsets = _extract_coords(yy, outer)
-    coords = ((ix, iy), (ix_offsets, iy_offsets))
-    if coord_type == 'offsets':
-        return get_patch_offsets(coords)
-    elif coord_type == 'global':
-        return (ix, iy)
-    else:
-        raise ValueError
-
-def add_position_jitter(coords, jitter_scale):
-    shape = coords.shape
-    jitter = jitter_scale * tf.random.normal(shape)
-    return jitter + coords
-
-def scan_and_normalize(jitter_scale = None, YY_I = None, YY_phi = None,
-        **kwargs):
-    """
-    Inputs:
-    4d tensors of full (arbitrary-sized) object phase and amplitude.
-
-    Returns (normalized) amplitude and phase and scan point offsets.
-
-    coords: tuple of two tuples. First gives center coords for each
-    small image patch. Second gives offset coords for each solution
-    region.
-    """
-    size = YY_I.shape[1]
-    n = YY_I.shape[0]
-    coords = true_coords = extract_coords(size, n, **kwargs)
-    if jitter_scale is not None:
-        print('simulating gaussian position jitter, scale', jitter_scale)
-        true_coords = add_position_jitter(coords, jitter_scale)
-
-    Y_I, Y_phi, _Y_I_full, norm_Y_I = hh.preprocess_objects(YY_I,
-        offsets_xy = true_coords, Y_phi = YY_phi, **kwargs)
-    return Y_I, Y_phi, _Y_I_full, norm_Y_I, (coords, true_coords)
-
-import math
-def dummy_phi(Y_I):
-    return tf.cast(tf.constant(math.pi), tf.float32) *\
-        tf.cast(tf.math.tanh( (Y_I - tf.math.reduce_max(Y_I) / 2) /
-            (3 * tf.math.reduce_mean(Y_I))), tf.float32)
-
-def sim_object_image(size, which = 'train'):
-    if p.get('data_source') == 'lines':
-        return mk_lines_img(2 * size, nlines = 400)[size // 2: -size // 2, size // 2: -size // 2, :1]
-    elif p.get('data_source') == 'grf':
-        from .datagen import grf
-        return grf.mk_grf(size)
-    elif p.get('data_source') == 'points':
-        from .datagen import points
-        return points.mk_points(size)
-    elif p.get('data_source') == 'testimg':
-        from .datagen import testimg
-        if which == 'train':
-            return testimg.get_img(size)
-        elif which == 'test':
-            return testimg.get_img(size, reverse = True)
-        else:
-            raise ValueError
-    elif p.get('data_source') == 'testimg_reverse':
-        from .datagen import testimg
-        return testimg.get_img(size, reverse = True)
-    elif p.get('data_source') == 'diagonals':
-        from .datagen import diagonals
-        return diagonals.mk_diags(size)
-    elif p.get('data_source') == 'V':
-        from .datagen import vendetta
-        return vendetta.mk_vs(size)
-    else:
-        raise ValueError
-
-@memoize_disk_and_memory
-def mk_simdata(n, size, probe, outer_offset, intensity_scale = None,
-        YY_I = None, YY_phi = None, dict_fmt = False,  which = 'train', **kwargs):
-    if YY_I is None:
-        YY_I = np.array([sim_object_image(size, which = which)
-              for _ in range(n)])
-    if p.get('set_phi') and YY_phi is None:
-        YY_phi = dummy_phi(YY_I)
-    Y_I, Y_phi, _, norm_Y_I, coords = scan_and_normalize(YY_I = YY_I,
-        YY_phi = YY_phi, outer_offset = outer_offset, **kwargs)
-    if dict_fmt:
-        d = dict()
-        d['I_pre_probe'] = Y_I
-        d['phi_pre_probe'] = Y_phi
-    X, Y_I, Y_phi, intensity_scale =\
-        illuminate_and_diffract(Y_I, Y_phi, probe, intensity_scale = intensity_scale)
-    if YY_phi is None:
-        YY_full = hh.combine_complex(YY_I, tf.zeros_like(YY_I))
-    else:
-        YY_full = hh.combine_complex(YY_I, YY_phi)
-    if dict_fmt:
-        d['X'] = X
-        d['Y_I'] = Y_I
-        d['Y_phi'] = Y_phi
-        d['intensity_scale'] = intensity_scale
-        d['norm_Y_I'] = norm_Y_I
-        d['coords'] = coords
-        return d
-    return X, Y_I, Y_phi, intensity_scale, YY_full,\
-        norm_Y_I, coords
diff --git a/build/lib/ptycho/evaluation.py b/build/lib/ptycho/evaluation.py
deleted file mode 100644
index 5844f4d..0000000
--- a/build/lib/ptycho/evaluation.py
+++ /dev/null
@@ -1,305 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib
-import tensorflow as tf
-
-from ptycho import params
-from ptycho import misc
-
-def recon_patches(patches):
-    """
-    chop channel dimension size to 1, then patch together a single image
-    """
-    from ptycho import generate_data as data
-    return data.reassemble(patches[:, :, :, :1])[0]
-
-def symmetrize(arr):
-    return (arr + arr[::-1, ::-1]) / 2
-
-def symmetrize_3d(arr):
-    return (arr + arr[:, ::-1, ::-1]) / 2
-
-def cropshow(arr, *args, crop = True, **kwargs):
-    if crop:
-        arr = arr[16:-16, 16:-16]
-    plt.imshow(arr, *args, **kwargs)
-
-from scipy.ndimage import gaussian_filter as gf
-
-def summarize(i, a, b, X_test, Y_I_test, Y_phi_test, probe, channel = 0, **kwargs):
-    plt.rcParams["figure.figsize"] = (10, 10)
-    vmin = 0
-    vmax = np.absolute(b)[i].max()
-
-    heatmaps = {}  # initialize the dictionary to store the heatmaps
-    probe = np.absolute(probe)
-    aa, bb = 3, 3
-    plt.subplot(aa, bb, 1)
-    plt.title('True amp.\n(illuminated)')
-    true_amp_illuminated = (Y_I_test[i, :, :, channel])
-    cropshow(true_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_illuminated'] = true_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 2)
-    plt.title('Reconstructed amp.\n(illuminated)')
-    rec_amp_illuminated = (np.absolute(b))[i] * probe[..., None]
-    cropshow(rec_amp_illuminated, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_illuminated'] = rec_amp_illuminated  # add to the dictionary
-
-    plt.subplot(aa, bb, 3)
-    plt.title('True phase')
-    true_phase = ((Y_phi_test * (probe > .01)[..., None]))[i, :, :, channel]
-    cropshow(true_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['true_phase'] = true_phase  # add to the dictionary
-
-    plt.subplot(aa, bb, 4)
-    plt.title('True amp.\n(full)')
-    true_amp_full = (Y_I_test[i, :, :, channel] / (probe + 1e-9))
-    cropshow(true_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['true_amp_full'] = true_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 5)
-    plt.title('Reconstructed amp. (full)')
-    rec_amp_full = (np.absolute(b))[i]
-    cropshow(rec_amp_full, cmap = 'jet', **kwargs)
-    heatmaps['rec_amp_full'] = rec_amp_full  # add to the dictionary
-
-    plt.subplot(aa, bb, 6)
-    plt.title('Reconstructed phase')
-    rec_phase = (np.angle(b) * (probe > .01)[..., None])[i]
-    rec_phase[np.isclose(rec_phase,  0)] = np.nan
-    cropshow(rec_phase, cmap = 'jet', **kwargs)
-    plt.colorbar()
-    heatmaps['rec_phase'] = rec_phase  # add to the dictionary
-    print('phase min:', np.min((np.angle(b) * (probe > .01)[..., None])),
-        'phase max:', np.max((np.angle(b) * (probe > .01)[..., None])))
-
-    plt.subplot(aa, bb, 7)
-    plt.title('True diffraction')
-    true_diffraction = np.log(X_test)[i, :, :, channel]
-    plt.imshow(true_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['true_diffraction'] = true_diffraction  # add to the dictionary
-
-    plt.subplot(aa, bb, 8)
-    plt.title('Recon diffraction')
-    rec_diffraction = np.log(a)[i, :, :, channel]
-    plt.imshow(rec_diffraction, cmap = 'jet')
-    plt.colorbar()
-    heatmaps['rec_diffraction'] = rec_diffraction  # add to the dictionary
-
-    return heatmaps
-
-
-def plt_metrics(history, loss_type = 'MAE', metric2 = 'padded_obj_loss'):
-    hist=history
-    epochs=np.asarray(history.epoch)+1
-
-    plt.style.use('seaborn-white')
-    matplotlib.rc('font',family='Times New Roman')
-    matplotlib.rcParams['font.size'] = 12
-
-    f, axarr = plt.subplots(2, sharex=True, figsize=(12, 8))
-
-    axarr[0].set(ylabel='Loss')
-    axarr[0].plot(epochs,hist.history['loss'], 'C3o', label='Diffraction {} Training'.format(loss_type))
-    axarr[0].plot(epochs,hist.history['val_loss'], 'C3-', label='Diffraction {} Validation'.format(loss_type))
-    axarr[0].grid()
-    axarr[0].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-
-    axarr[1].set(ylabel='Loss')
-    axarr[1].plot(epochs,hist.history[metric2], 'C0o', label='Object {} Training'.format(loss_type))
-    axarr[1].plot(epochs,hist.history['val_' + metric2], 'C0-', label='Object {} Validation'.format(loss_type))
-    axarr[1].legend(loc='center right', bbox_to_anchor=(1.5, 0.5))
-    plt.xlabel('Epochs')
-    plt.tight_layout()
-    #plt.semilogy()
-    axarr[1].grid()
-
-import scipy.fftpack as fftpack
-fp = fftpack
-
-def trim(arr2d):
-    offset = params.get('offset')
-    assert not (offset % 2)
-    return arr2d[offset // 2:-offset // 2, offset // 2:-offset // 2]
-
-def mae(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean(np.absolute(target - scale * pred))
-
-def mse(target, pred, normalize = True):
-    """
-    mae for an entire (stitched-together) reconstruction.
-    """
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    print('mean scale adjustment:', scale)
-    return np.mean((target - scale * pred)**2)
-
-def psnr(target, pred, normalize = True, shift = False):
-    """
-    for phase inputs, assume that global shift has already been taken care off
-    """
-    import cv2
-    target = np.array(target)
-    pred = np.array(pred)
-    if normalize:
-        scale = np.mean(target) / np.mean(pred)
-    else:
-        scale = 1
-    if shift:
-        offset = min(np.min(target), np.min(pred))
-        target = target - offset
-        pred = pred - offset
-    pred = scale * pred
-    return cv2.PSNR(target, pred)
-
-def fft2d(aphi):
-    F1 = fftpack.fft2((aphi).astype(float))
-    F2 = fftpack.fftshift(F1)
-    return F2
-
-def highpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-
-    F2[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 0
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def lowpass2d(aphi, n = 2):
-    if n == 1:
-        print('subtracting mean', np.mean(aphi))
-        return aphi - np.mean(aphi)
-    F2 = fft2d(aphi)
-    (w, h) = aphi.shape
-    half_w, half_h = int(w/2), int(h/2)
-
-    # high pass filter
-    mask = np.zeros_like(F2)
-    mask[half_w-n:half_w+n+1,half_h-n:half_h+n+1] = 1.
-    F2 = F2 * mask
-
-    im1 = fp.ifft2(fftpack.ifftshift(F2)).real
-    return im1
-
-def frc50(target, pred, sigma = 1):
-    if np.isnan(pred).all():
-        raise ValueError
-    if np.max(target) == np.min(target) == 0:
-        return None, np.nan
-    from FRC import fourier_ring_corr as frc
-    shellcorr = frc.FSC(np.array(target), np.array(pred))
-    shellcorr = gf(shellcorr, sigma)
-    return shellcorr, np.where(shellcorr < .5)[0][0]
-
-
-#def eval_reconstruction(stitched_obj, ground_truth_obj, lowpass_n = 1,
-#        label = ''):
-#    assert np.ndim(stitched_obj) == np.ndim(ground_truth_obj), \
-#        'stitched_obj and ground_truth_obj must have the same number of dimensions'
-#    assert stitched_obj.shape[1] == ground_truth_obj.shape[1]
-#
-#    YY_ground_truth = np.absolute(ground_truth_obj)
-#    YY_phi_ground_truth = np.angle(ground_truth_obj)
-#
-#    if np.ndim(stitched_obj) == 3:
-#        phi_pred = trim(
-#            highpass2d(
-#                np.squeeze(np.angle(stitched_obj)[0]), n = lowpass_n
-#            )
-#        )
-#        amp_pred = trim(np.absolute(stitched_obj)[0])
-#    else:  # If it's 2D
-#        phi_pred = trim(
-#            highpass2d(
-#                np.squeeze(np.angle(stitched_obj)), n = lowpass_n
-#            )
-#        )
-#        amp_pred = trim(np.absolute(stitched_obj))
-#
-#    phi_target = trim(
-#        highpass2d(
-#            np.squeeze(YY_phi_ground_truth), n = lowpass_n
-#        )
-#    )
-#    amp_target = tf.cast(trim(YY_ground_truth), tf.float32)
-
-def eval_reconstruction(stitched_obj, ground_truth_obj, lowpass_n = 1,
-        label = ''):
-    # TODO consistent shapes
-    assert stitched_obj.shape[1] == ground_truth_obj.shape[1]
-    assert np.ndim(ground_truth_obj) == 3
-    assert int(np.ndim(stitched_obj)) in [3, 4]
-    if np.ndim(stitched_obj) == 4:
-        stitched_obj = stitched_obj[0]
-    YY_ground_truth = np.absolute(ground_truth_obj)
-    YY_phi_ground_truth = np.angle(ground_truth_obj)
-
-    phi_pred = trim(
-        highpass2d(
-            np.squeeze(np.angle(stitched_obj)), n = lowpass_n
-        )
-    )
-    phi_target = trim(
-        highpass2d(
-            np.squeeze(YY_phi_ground_truth), n = lowpass_n
-        )
-    )
-    amp_target = tf.cast(trim(YY_ground_truth), tf.float32)
-    amp_pred = trim(np.absolute(stitched_obj))
-
-    # TODO complex FRC?
-    mae_amp = mae(amp_target, amp_pred) # PINN
-    mse_amp = mse(amp_target, amp_pred) # PINN
-    psnr_amp = psnr(amp_target[:, :, 0], amp_pred[:, :, 0], normalize = True,
-        shift = False)
-    frc_amp, frc50_amp = frc50(amp_target[:, :, 0], amp_pred[:, :, 0])
-
-    mae_phi = mae(phi_target, phi_pred, normalize=False) # PINN
-    mse_phi = mse(phi_target, phi_pred, normalize=False) # PINN
-    psnr_phi = psnr(phi_target, phi_pred, normalize = False, shift = True)
-    frc_phi, frc50_phi = frc50(phi_target, phi_pred)
-
-    return {'mae': (mae_amp, mae_phi),
-        'mse': (mse_amp, mse_phi),
-        'psnr': (psnr_amp, psnr_phi),
-        'frc50': (frc50_amp, frc50_phi),
-        'frc': (frc_amp, frc_phi)}
-
-
-import pandas as pd
-import os
-import dill
-def save_metrics(stitched_obj, YY_ground_truth,  label = ''):
-    """
-    evaluate reconstruction and save the result to disk.
-    """
-    out_prefix = misc.get_path_prefix()
-    os.makedirs(out_prefix, exist_ok=True)
-    metrics = eval_reconstruction(stitched_obj, YY_ground_truth, label = label)
-    metrics['label'] = label
-    d = {**params.cfg, **metrics}
-    with open(out_prefix + '/params.dill', 'wb') as f:
-        dill.dump(d, f)
-    df = pd.DataFrame({k: d[k] for k in ['mae', 'mse', 'psnr', 'frc50']})
-    df.to_csv(out_prefix + '/metrics.csv')
-    return {k: metrics[k] for k in ['mae', 'mse', 'psnr', 'frc50']}
diff --git a/build/lib/ptycho/experimental.py b/build/lib/ptycho/experimental.py
deleted file mode 100644
index cfefa4e..0000000
--- a/build/lib/ptycho/experimental.py
+++ /dev/null
@@ -1,116 +0,0 @@
-from skimage.transform import resize
-from tqdm.notebook import tqdm as tqdm
-import matplotlib.pyplot as plt
-import numpy as np
-import scipy.signal
-import sys
-
-from . import tf_helper as hh
-
-path = '.'
-
-sys.path.append(path)
-sys.path.append('PtychoNN/TF2/')
-
-N = 64
-### Read experimental diffraction data and reconstructed images
-
-data_diffr = np.load(path+'/PtychoNN/data/20191008_39_diff.npz')['arr_0']
-data_diffr.shape
-
-data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)
-for i in tqdm(range(data_diffr.shape[0])):
-    for j in range(data_diffr.shape[1]):
-        data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)
-        data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])
-
-real_space = np.load(path+'/PtychoNN/data/20191008_39_amp_pha_10nm_full.npy')
-amp = np.abs(real_space)
-ph = np.angle(real_space)
-amp.shape
-
-### Split data and then shuffle
-
-nlines = 100 #How many lines of data to use for training?
-nltest = 60 #How many lines for the test set?
-tst_strt = amp.shape[0]-nltest #Where to index from
-print(tst_strt)
-train_size = 272
-test_size = 248
-
-def stack(a1, a2):
-    return np.array((a1, a2)).reshape((-1, N, N, 1))
-
-def augment_inversion(Y_I_train, Y_phi_train):
-    phi = stack(Y_phi_train, -Y_phi_train)
-    return stack(Y_I_train, Y_I_train[:, ::-1, ::-1, :]), stack(Y_phi_train, -Y_phi_train)
-
-def reconstruct_object(data4d, scan_grid_offset):
-    """
-    Given a 4d object patches, reconstruct the whole object
-    """
-    hh.extract_patches_inverse(
-       data4d.reshape((data4d.shape[0], data4d.shape[1], -1))[None, ...],
-       N, True, gridsize = data4d.shape[0],
-       offset = scan_grid_offset)
-
-from ptycho.misc import memoize_disk_and_memory
-@memoize_disk_and_memory
-def get_full_experimental(which):
-    """
-    Returns (normalized) amplitude and phase for n generated objects
-    """
-    inverted_patches_I = reconstruct_object(amp, offset_experimental)
-    inverted_patches_phi = reconstruct_object(ph, offset_experimental)
-    if which == 'train':
-        YY_I = inverted_patches_I[:, :train_size, :train_size, :]
-        YY_phi = inverted_patches_phi[:, :train_size, :train_size, :]
-    elif which == 'test':
-        YY_I = inverted_patches_I[:, -test_size:, -test_size:, :]
-        YY_phi = inverted_patches_phi[:, -test_size:, -test_size:, :]
-    else:
-        raise ValueError
-    #pdb.set_trace()
-    return YY_I, YY_phi
-
-
-X_train = data_diffr_red[:nlines,:].reshape(-1,N,N)[:,:,:,np.newaxis]
-X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,N,N)[:,:,:,np.newaxis]
-Y_I_train = amp[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_I_test = amp[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_train = ph[:nlines,:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-Y_phi_test = ph[tst_strt:,tst_strt:]#.reshape(-1,h,w)[:,:,:,np.newaxis]
-
-ntrain = X_train.shape[0]*X_train.shape[1]
-ntest = X_test.shape[0]*X_test.shape[1]
-
-print(X_train.shape, X_test.shape)
-
-
-tmp1, tmp2 = Y_I_train, Y_I_test
-
-img = np.zeros((544, 544), dtype = 'float32')[None, ..., None]
-offset_experimental = 3
-
-## Recover shift between scan points
-def cross_image(im1, im2):
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
-
-cross = cross_image(amp[0, 0], amp[1, 0])
-ref = cross_image(amp[0, 0], amp[0, 0])
-
-cmax = lambda cross: np.array(np.where(cross.ravel()[np.argmax(cross)] == cross))
-
-plt.imshow(cross)
-
-cmax(cross), cmax(cross) - cmax(ref)
diff --git a/build/lib/ptycho/export.py b/build/lib/ptycho/export.py
deleted file mode 100644
index ba05094..0000000
--- a/build/lib/ptycho/export.py
+++ /dev/null
@@ -1,41 +0,0 @@
-import dill
-import matplotlib.pyplot as plt
-import numpy as np
-from ptycho.misc import get_path_prefix
-from ptycho.params import get
-
-def save_recons(model_type, stitched_obj):
-    from ptycho.generate_data import YY_ground_truth
-    from ptycho.evaluation import save_metrics
-    try:
-        out_prefix = get('output_prefix')
-        if YY_ground_truth is not None:
-            plt.imsave(out_prefix + 'amp_orig.png',
-                       np.absolute(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-            plt.imsave(out_prefix + 'phi_orig.png',
-                       np.angle(YY_ground_truth[:, :, 0]),
-                       cmap='jet')
-        if stitched_obj is not None:
-            plt.imsave(out_prefix + 'amp_recon.png', np.absolute(stitched_obj[0][:, :, 0]), cmap='jet')
-            plt.imsave(out_prefix + 'phi_recon.png', np.angle(stitched_obj[0][:, :, 0]), cmap='jet')
-
-        with open(out_prefix + '/recon.dill', 'wb') as f:
-            dump_data = {'stitched_obj_amp': np.absolute(stitched_obj[0][:, :, 0] if stitched_obj is not None else np.array([])),
-                         'stitched_obj_phase': np.angle(stitched_obj[0][:, :, 0]) if stitched_obj is not None else np.array([])}
-            if YY_ground_truth is not None:
-                dump_data.update({'YY_ground_truth_amp': np.absolute(YY_ground_truth[:, :, 0]),
-                                  'YY_ground_truth_phi': np.angle(YY_ground_truth[:, :, 0])})
-            dill.dump(dump_data, f)
-        if YY_ground_truth is not None and stitched_obj is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth or stitched_obj is None, metrics cannot be calculated.'}
-
-        if YY_ground_truth is not None:
-            d = save_metrics(stitched_obj, YY_ground_truth, label = get('label'))
-        else:
-            d = {'error': 'YY_ground_truth is None, metrics cannot be calculated.'}
-        return d
-    except ImportError as e:
-        print('object stitching failed. No images will be saved.')
diff --git a/build/lib/ptycho/fourier.py b/build/lib/ptycho/fourier.py
deleted file mode 100644
index 1cf06f5..0000000
--- a/build/lib/ptycho/fourier.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import pandas as pd
-import numpy as np
-
-from scipy.fft import fft, fftfreq, ifft, fft2, ifft2, ifftshift
-import matplotlib.pyplot as plt
-from scipy.fftpack import fft, fftshift
-from scipy.signal import butter
-from scipy import signal
-from scipy.signal import convolve2d as conv2
-
-from skimage import color, data, restoration
-from scipy.ndimage import gaussian_filter as gf
-
-def plot_df(*args):
-    df = pd.DataFrame([p for p, _ in args]).T
-    df.columns = [l for _, l in args ]
-    return df.plot()
-
-def lowpass_g(size, y, sym = False):
-    from scipy.signal.windows import gaussian
-    L = gaussian(len(y), std = len(y) / (size * np.pi**2), sym = sym)
-    L /= L.max()
-    return L
-
-def highpass_g(size, y):
-    return 1 - lowpass_g(size, y)
-
-def bandpass_g(L, H, y):
-    L = lowpass_g(L, y)
-    H = highpass_g(H, y)
-    return L * H
-
-def clip_high(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    x2[(N - nz) // 2 : (N + nz) // 2] = 0
-    #x2[(-nz) // 2:] = 0
-    return x2
-
-def clip_low(x, frac_zero, invert = False):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = x.copy()
-    mask = np.ones_like(x)
-    mask[:( nz) // 2 ] = 0
-    mask[(-nz) // 2:] = 0
-    if invert:
-        mask = 1 - mask
-    x2 = x2 * mask
-
-#     x2[:( nz) // 2 ] = 0
-#     x2[(-nz) // 2:] = 0
-    return x2, mask
-
-def clip_low_window(x, frac_zero):
-    N = len(x)
-    nz = int(frac_zero * N)
-    x2  = np.ones_like(x)
-    x2[:( nz) // 2 ] = 0
-    x2[(-nz) // 2:] = 0
-    return x2
-
-def if_mag(arr, phase = 0, truncate = False, toreal = 'psd', **kwargs):
-    #print("arr shape", arr.shape)
-    #trunc = len(arr) - unpadded_length
-    phase = np.exp(1j * phase)
-    tmp = ifft(arr)
-    if toreal == 'psd':
-        real = np.real(np.sqrt(np.conjugate(tmp) * tmp))
-    elif toreal == 'real':
-        real = np.real(tmp)
-    else:
-        raise ValueError
-    if truncate:
-        raise NotImplementedError
-        #return real[trunc // 2: -trunc // 2]
-    return real
-
-def power(arr):
-    ampsq = arr * np.conjugate(arr)
-    return np.real(ampsq)
-
-def mag(x):
-    return np.sqrt(power(x))
-
-def lorenz(gamma, x, x0):
-    return ( 1. / (np.pi * gamma)) * (gamma**2) / ((x - x0)**2 + gamma**2)
-
diff --git a/build/lib/ptycho/function_logger.py b/build/lib/ptycho/function_logger.py
deleted file mode 100644
index bd6ce7a..0000000
--- a/build/lib/ptycho/function_logger.py
+++ /dev/null
@@ -1,17 +0,0 @@
-import functools
-import logging
-
-# Set up logging configuration
-logging.basicConfig(
-    filename='function_calls.log',
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
-)
-
-def log_function_call(func):
-    @functools.wraps(func)
-    def wrapper(*args, **kwargs):
-        logging.info(f"Called function: {func.__name__}")
-        result = func(*args, **kwargs)
-        return result
-    return wrapper
\ No newline at end of file
diff --git a/build/lib/ptycho/generate_data.py b/build/lib/ptycho/generate_data.py
deleted file mode 100644
index 33d1c2a..0000000
--- a/build/lib/ptycho/generate_data.py
+++ /dev/null
@@ -1,10 +0,0 @@
-import numpy as np
-from .data_preprocessing import generate_data
-from . import params as p
-
-def main(probeGuess = None):
-    X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = generate_data(probeGuess)
-    print(np.linalg.norm(ptycho_dataset.train_data.X[0]) / np.linalg.norm(np.abs(ptycho_dataset.train_data.Y[0])))
-    return X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test
-
-X_train, Y_I_train, Y_phi_train, X_test, Y_I_test, Y_phi_test, YY_ground_truth, ptycho_dataset, YY_test_full, norm_Y_I_test = main(probeGuess = p.get('probe'))
diff --git a/build/lib/ptycho/image/__init__.py b/build/lib/ptycho/image/__init__.py
deleted file mode 100644
index 48b86dc..0000000
--- a/build/lib/ptycho/image/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .stitching import stitch_patches, reassemble_patches
diff --git a/build/lib/ptycho/image/stitching.py b/build/lib/ptycho/image/stitching.py
deleted file mode 100644
index 9b26c64..0000000
--- a/build/lib/ptycho/image/stitching.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, config, *, 
-                  norm_Y_I: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # Get N from config at the start
-    N = config['N']
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        N = config['N']
-        gridsize = config['gridsize']
-        offset = config['offset']
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    outer_offset = config.get('outer_offset_test', config['offset'])
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / config['nimgs_test']) / (config['N']**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-def reassemble_patches(patches, config, *, norm_Y_I=1., part='amp', norm=False):
-    """
-    High-level convenience function for stitching patches using config parameters.
-    
-    Args:
-        patches: Patches to reassemble
-        config: Configuration dictionary containing patch parameters
-        norm_Y_I: Normalization factor (default: 1.0)
-        part: Which part to extract (default: 'amp')
-        norm: Whether to normalize (default: False)
-    """
-    return stitch_patches(
-        patches,
-        config,
-        norm_Y_I=norm_Y_I,
-        norm=norm,
-        part=part
-    )
diff --git a/build/lib/ptycho/inference.py b/build/lib/ptycho/inference.py
deleted file mode 100644
index 1973407..0000000
--- a/build/lib/ptycho/inference.py
+++ /dev/null
@@ -1,49 +0,0 @@
-from ptycho.model_manager import ModelManager
-from tensorflow.keras.models import Model
-from ptycho import params
-from ptycho.loader import PtychoDataContainer
-import numpy as np
-
-# TODO this module is for inference-only workflows. it needs to be consolidated with train_pinn
-
-def load_pretrained_model(model_path: str) -> Model:
-    """
-    Load a pre-trained model from an H5 file.
-    """
-    model = ModelManager.load_model(model_path)
-    return model
-
-def prepare_data(data_container: PtychoDataContainer) -> tuple:
-    """
-    Prepare data for inference.
-    """
-    from ptycho import model
-    X = data_container.X * model.params()['intensity_scale']
-    coords_nominal = data_container.coords_nominal
-    return X, coords_nominal
-
-def perform_inference(model: Model, X: np.ndarray, coords_nominal: np.ndarray) -> dict:
-    """
-    Perform inference using the pre-trained model and prepared data.
-    """
-    from ptycho import model
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = model.predict([X, coords_nominal])
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi
-    }
-
-def inference_flow(model_path: str, data_container: PtychoDataContainer) -> dict:
-    """
-    The main flow for model inference, integrating the steps.
-    """
-    pre_trained_model = load_pretrained_model(model_path or params.get('h5_path'))
-    X, coords_nominal = prepare_data(data_container)
-    inference_results = perform_inference(pre_trained_model, X, coords_nominal)
-    return inference_results
-
-# Example usage
-# model_path = 'path/to/model.h5'
-# data_container = PtychoDataContainer(...)
-# results = inference_flow(model_path, data_container)
diff --git a/build/lib/ptycho/loader.py b/build/lib/ptycho/loader.py
deleted file mode 100644
index 2d3dd23..0000000
--- a/build/lib/ptycho/loader.py
+++ /dev/null
@@ -1,686 +0,0 @@
-""" 'Generic' loader for datasets with non-rectangular scan point patterns."""
-
-import numpy as np
-import tensorflow as tf
-from scipy.spatial import cKDTree
-from ptycho import diffsim as datasets
-from .params import params, get
-from .autotest.debug import debug
-
-from typing import Tuple, Optional, Callable
-
-# If == 1, relative coordinates are (patch CM coordinate - solution region CM
-# coordinate)
-local_offset_sign = 1
-
-key_coords_offsets = 'coords_start_offsets'
-key_coords_relative = 'coords_start_relative'
-
-class RawData:
-    @debug
-    def __init__(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess,
-                 scan_index, objectGuess = None):
-        # Sanity checks
-        self._check_data_validity(xcoords, ycoords, xcoords_start, ycoords_start, diff3d,
-                    probeGuess, scan_index)
-
-        # TODO these should go in the data validation method
-        assert len(xcoords.shape) == 1, f"Expected xcoords to be 1D, got shape {xcoords.shape}"
-        assert len(ycoords.shape) == 1, f"Expected ycoords to be 1D, got shape {ycoords.shape}"
-        assert len(xcoords_start.shape) == 1, f"Expected xcoords_start to be 1D, got shape {xcoords_start.shape}"
-        assert len(ycoords_start.shape) == 1, f"Expected ycoords_start to be 1D, got shape {ycoords_start.shape}"
-        if diff3d is not None:
-            assert len(diff3d.shape) == 3, f"Expected diff3d to be 3D, got shape {diff3d.shape}"
-            print(f"diff3d shape: {diff3d.shape}")
-        if probeGuess is not None:
-            assert len(probeGuess.shape) == 2, f"Expected probeGuess to be 2D, got shape {probeGuess.shape}"
-            print(f"probeGuess shape: {probeGuess.shape}")
-        if scan_index is not None:
-            assert len(scan_index.shape) == 1, f"Expected scan_index to be 1D, got shape {scan_index.shape}"
-            print(f"scan_index shape: {scan_index.shape}")
-        if objectGuess is not None:
-            print(f"objectGuess shape: {objectGuess.shape}")
-            assert len(objectGuess.shape) == 2
-
-        print(f"xcoords shape: {xcoords.shape}")
-        print(f"ycoords shape: {ycoords.shape}")
-        print(f"xcoords_start shape: {xcoords_start.shape}")
-        print(f"ycoords_start shape: {ycoords_start.shape}")
-
-        # Assigning values if checks pass
-        self.xcoords = xcoords
-        self.ycoords = ycoords
-        self.xcoords_start = xcoords_start
-        self.ycoords_start = ycoords_start
-        self.diff3d = diff3d
-        self.probeGuess = probeGuess
-        self.scan_index = scan_index
-        self.objectGuess = objectGuess
-
-    @staticmethod
-    @debug
-    def from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index,
-                               objectGuess=None):
-        """
-        Static method to create a RawData instance without separate start coordinates.
-        The start coordinates are set to be the same as the xcoords and ycoords.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        return RawData(xcoords, ycoords, xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-
-    @debug
-    def __str__(self):
-        parts = [
-            "RawData:",
-            f"  xcoords: {self.xcoords.shape if self.xcoords is not None else 'None'}",
-            f"  ycoords: {self.ycoords.shape if self.ycoords is not None else 'None'}",
-            f"  xcoords_start: {self.xcoords_start.shape if self.xcoords_start is not None else 'None'}",
-            f"  ycoords_start: {self.ycoords_start.shape if self.ycoords_start is not None else 'None'}",
-            f"  diff3d: {self.diff3d.shape if self.diff3d is not None else 'None'}",
-            f"  probeGuess: {self.probeGuess.shape if self.probeGuess is not None else 'None'}",
-            f"  scan_index: {self.scan_index.shape if self.scan_index is not None else 'None'}",
-            f"  objectGuess: {self.objectGuess.shape if self.objectGuess is not None else 'None'}"
-        ]
-        return "\n".join(parts)
-
-    @debug
-    def to_file(self, file_path: str) -> None:
-        """
-        Method to write the RawData object to a file using numpy.savez.
-
-        Args:
-            file_path (str): Path to the file where the data will be saved.
-        """
-        np.savez(file_path,
-                 xcoords=self.xcoords,
-                 ycoords=self.ycoords,
-                 xcoords_start=self.xcoords_start,
-                 ycoords_start=self.ycoords_start,
-                 diff3d=self.diff3d,
-                 probeGuess=self.probeGuess,
-                 objectGuess=self.objectGuess,
-                 scan_index=self.scan_index)
-
-    @staticmethod
-    @debug
-    def from_file(train_data_file_path: str) -> 'RawData':
-        """
-        """
-        # Load training data
-        train_data = np.load(train_data_file_path)
-        train_raw_data = RawData(
-            xcoords=train_data['xcoords'],
-            ycoords=train_data['ycoords'],
-            xcoords_start=train_data['xcoords_start'],
-            ycoords_start=train_data['ycoords_start'],
-            diff3d=train_data['diff3d'],
-            probeGuess=train_data['probeGuess'],
-            objectGuess=train_data['objectGuess'],
-            scan_index=train_data['scan_index']
-        )
-        return train_raw_data
-
-    @staticmethod
-    @debug
-    def from_files(train_data_file_path, test_data_file_path):
-        """
-        Static method to instantiate RawData objects from training and test data files.
-
-        The data files should be NumPy .npz files with the following keys:
-        - 'xcoords': x coordinates of the scan points
-        - 'ycoords': y coordinates of the scan points
-        - 'xcoords_start': starting x coordinates for the scan
-        - 'ycoords_start': starting y coordinates for the scan
-        - 'diff3d': diffraction patterns
-        - 'probeGuess': initial guess of the probe function
-        - 'scan_index': array indicating the scan index for each diffraction pattern
-
-        Args:
-            train_data_file_path (str): Path to the training data file.
-            test_data_file_path (str): Path to the test data file.
-
-        Returns:
-            tuple: A tuple containing the instantiated RawData objects for training and test data.
-        """
-        # Load training data
-        train_raw_data = RawData.from_file(train_data_file_path)
-
-        # Load test data
-        test_raw_data = RawData.from_file(test_data_file_path)
-
-        return train_raw_data, test_raw_data
-
-    @debug
-    def generate_grouped_data(self, N, K = 7, nsamples = 1):
-        """
-        Generate nearest-neighbor solution region grouping.
-        """
-#        np.random.seed(get('npseed'))
-#        print('DEBUG:', 'setting np seed in generate_grouped_data')
-        print('DEBUG:', 'nsamples:', nsamples)
-        return get_neighbor_diffraction_and_positions(self, N, K=K, nsamples=nsamples)
-
-
-    @debug
-    def _check_data_validity(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-        # Check if all inputs are numpy arrays
-#        if not all(isinstance(arr, np.ndarray) for arr in [xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index]):
-#            raise ValueError("All inputs must be numpy arrays.")
-
-        # Check if coordinate arrays have matching shapes
-        if not (xcoords.shape == ycoords.shape == xcoords_start.shape == ycoords_start.shape):
-            raise ValueError("Coordinate arrays must have matching shapes.")
-
-class PtychoDataset:
-    @debug
-    def __init__(self, train_data, test_data):
-        self.train_data = train_data
-        self.test_data = test_data
-
-
-class PtychoDataContainer:
-    """
-    A class to contain ptycho data attributes for easy access and manipulation.
-    """
-    @debug
-    def __init__(self, X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, nn_indices, global_offsets, local_offsets, probeGuess):
-        self.X = X
-        self.Y_I = Y_I
-        self.Y_phi = Y_phi
-        self.norm_Y_I = norm_Y_I
-        self.YY_full = YY_full
-        self.coords_nominal = coords_nominal
-        self.coords = coords_nominal
-        self.coords_true = coords_true
-        self.nn_indices = nn_indices
-        self.global_offsets = global_offsets
-        self.local_offsets = local_offsets
-        self.probe = probeGuess
-
-        from .tf_helper import combine_complex
-        self.Y = combine_complex(Y_I, Y_phi)
-
-    @debug
-    def __repr__(self):
-        repr_str = '<PtychoDataContainer'
-        for attr_name in ['X', 'Y_I', 'Y_phi', 'norm_Y_I', 'YY_full', 'coords_nominal', 'coords_true', 'nn_indices', 'global_offsets', 'local_offsets', 'probe']:
-            attr = getattr(self, attr_name)
-            if attr is not None:
-                if isinstance(attr, np.ndarray):
-                    if np.iscomplexobj(attr):
-                        repr_str += f' {attr_name}={attr.shape} mean_amplitude={np.mean(np.abs(attr)):.3f}'
-                    else:
-                        repr_str += f' {attr_name}={attr.shape} mean={attr.mean():.3f}'
-                else:
-                    repr_str += f' {attr_name}={attr.shape}'
-        repr_str += '>'
-        return repr_str
-    @staticmethod
-    @debug
-    def from_raw_data_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess=None, N=None, K=7, nsamples=1):
-        """
-        Static method constructor that composes a call to RawData.from_coords_without_pc() and loader.load,
-        then initializes attributes.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-            N (int, optional): The size of the image. Defaults to None.
-            K (int, optional): The number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): The number of samples. Defaults to 1.
-
-        Returns:
-            PtychoDataContainer: An instance of the PtychoDataContainer class.
-        """
-        # TODO this could be handled by a decorator
-        from . import params as cfg
-        if N is None:
-            N = cfg.get('N')
-        train_raw = RawData.from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-        
-        dset_train = train_raw.generate_grouped_data(N, K=K, nsamples=nsamples)
-
-        # Use loader.load() to handle the conversion to PtychoData
-        return load(lambda: dset_train, probeGuess, which=None, create_split=False)
-
-    # TODO currently this can only handle a single object image
-    @staticmethod
-    @debug
-    def from_simulation(xcoords, ycoords, xcoords_start, ycoords_start, probeGuess,
-                 objectGuess, scan_index = None):
-        """
-        """
-        from .diffsim import illuminate_and_diffract
-        ptycho_data = RawData(xcoords, ycoords, xcoords_start, ycoords_start, None,
-                              probeGuess, scan_index, objectGuess)
-
-        global_offsets, local_offsets, nn_indices = calculate_relative_coords(
-                    ptycho_data.xcoords, ptycho_data.ycoords)
-
-        # TODO get rid of separate nominal and real coordinates
-        _, coords_true, _ = calculate_relative_coords(ptycho_data.xcoords_start,
-                                                      ptycho_data.ycoords_start)
-        coords_nominal = coords_true
-
-        Y_obj = get_image_patches(objectGuess, global_offsets, local_offsets) 
-        Y_I = tf.math.abs(Y_obj)
-        Y_phi = tf.math.angle(Y_obj)
-        X, Y_I, Y_phi, intensity_scale = illuminate_and_diffract(Y_I, Y_phi, probeGuess)
-        norm_Y_I = datasets.scale_nphotons(X)
-        return PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, objectGuess, coords_nominal,
-                                   coords_true, nn_indices, global_offsets, local_offsets, probeGuess)
-
-####
-# two functions to organize flat coordinate arrays into 'solution region' format
-####
-@debug
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    assign each pattern index to itself
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-@debug
-def get_neighbor_indices(xcoords, ycoords, K = 3):
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-@debug
-def sample_rows(indices, n, m):
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-@debug
-def get_relative_coords(coords_nn):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, 1, 2, C).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    assert len(coords_nn.shape) == 4
-    coords_offsets = np.mean(coords_nn, axis=3)[..., None]
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-    return coords_offsets, coords_relative
-
-@debug
-def crop12(arr, size):
-    N, M = arr.shape[1:3]
-    return arr[:, N // 2 - (size) // 2: N // 2+ (size) // 2, N // 2 - (size) // 2: N // 2 + (size) // 2, ...]
-
-# TODO move to tf_helper, except the parts that are specific to xpp
-from .tf_helper import complexify_function
-import tensorflow as tf
-
-@debug
-def extract_and_translate_patch_np(image, offset, patch_size):
-    # Calculate the starting coordinates for cropping.
-    start_x = int(offset[0]) + image.shape[0] // 2 - patch_size // 2
-    start_y = int(offset[1]) + image.shape[1] // 2 - patch_size // 2
-
-    # Crop the patch from the image.
-    patch = image[start_x:start_x + patch_size, start_y:start_y + patch_size, :]
-
-    return patch
-
-@debug
-def unsqueeze_coords(tensor):
-    """
-    unsqueeze 2d coordinates to flat 4d tensor format
-    """
-    # TODO assert tensor dimensionality is 2
-    return tensor[:, None, :, None]
-
-from . import tf_helper as hh
-
-@debug
-def calculate_combined_offsets(global_offsets, local_offsets):
-    """
-    Calculate the combined offsets.
-
-    Args:
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Combined offset tensor.
-    """
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    return offsets_c
-
-# TODO move to tf_helper, except the parts that are specific to xpp
-# should be in xpp.py
-@debug
-def tile_gt_object(gt_image, shape):
-    from . import tf_helper as hh
-    gridsize = params()['gridsize']
-    N = params()['N']
-    B = shape[0] #* gridsize**2
-
-    gt_repeat = tf.repeat(
-        tf.repeat(gt_image[None, ...], B, axis = 0)[..., None],
-        gridsize**2, axis = 3)
-
-    gt_repeat = hh.pad(gt_repeat, N // 2)
-    return gt_repeat
-
-@debug
-def calculate_relative_coords(xcoords, ycoords, K = 6, C = None, nsamples = 10):
-    """
-    Group scan indices and coordinates in to solution regions, then
-    calculate coords_offsets (global solution region coordinates) and
-    coords_relative (local solution patch coords) from ptycho_data using
-    the provided index_grouping_cb callback function.
-
-    Args:
-        ptycho_data (RawData): An instance of the RawData class containing the dataset.
-        index_grouping_cb (callable): A callback function that defines how to group indices.
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    nn_indices, coords_nn = group_coords(xcoords, ycoords, K = K, C = C, nsamples = nsamples)
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-    return coords_offsets, coords_relative, nn_indices
-
-@debug
-def group_coords(xcoords: np.ndarray, ycoords: np.ndarray, K: int, C: Optional[int], nsamples: int) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-
-    Assumes ptycho_data.xcoords and ptycho_data.ycoords are of shape (M).
-    Returns:
-        nn_indices: shape (M, C)
-        coords_nn: shape (M, 1, 2, C)
-    """
-    gridsize = params()['gridsize']
-    if C is None:
-        C = gridsize**2
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords, ycoords)
-    else:
-        nn_indices = get_neighbor_indices(xcoords, ycoords, K=K)
-        nn_indices = sample_rows(nn_indices, C, nsamples).reshape(-1, C)
-
-    #diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-    coords_nn = np.transpose(np.array([xcoords[nn_indices],
-                            ycoords[nn_indices]]),
-                            [1, 0, 2])[:, None, :, :]
-    return nn_indices, coords_nn[:, :, :, :]
-
-@debug
-def get_neighbor_diffraction_and_positions(ptycho_data, N, K=6, C=None, nsamples=10):
-    """
-    ptycho_data: an instance of the RawData class
-    """
-    
-    nn_indices, coords_nn = group_coords(ptycho_data.xcoords, ptycho_data.ycoords,
-                                         K = K, C = C, nsamples = nsamples)
-
-    diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-
-    # IMPORTANT: coord swap
-    #coords_nn = coords_nn[:, :, ::-1, :]
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if ptycho_data.xcoords_start is not None:
-        coords_start_nn = np.transpose(np.array([ptycho_data.xcoords_start[nn_indices], ptycho_data.ycoords_start[nn_indices]]),
-                                       [1, 0, 2])[:, None, :, :]
-        #coords_start_nn = coords_start_nn[:, :, ::-1, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-@complexify_function
-@debug
-def get_image_patches(gt_image, global_offsets, local_offsets):
-    """
-    Generate and return image patches in channel format using a single canvas.
-
-    Args:
-        gt_image (tensor): Ground truth image tensor.
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Image patches in channel format.
-    """
-    # Get necessary parameters
-    gridsize = params()['gridsize']
-    N = params()['N']
-    B = global_offsets.shape[0]
-    c = gridsize**2
-
-    # Pad the ground truth image once
-    gt_padded = hh.pad(gt_image[None, ..., None], N // 2)
-
-    # Calculate the combined offsets by adding global and local offsets
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    offsets_f = hh._channel_to_flat(offsets_c)
-
-    # Create a canvas to store the extracted patches
-    canvas = np.zeros((B, N, N, c))
-
-    # Iterate over the combined offsets and extract patches one by one
-    for i in range(B * c):
-        offset = -offsets_f[i, :, :, 0]
-        translated_patch = hh.translate(gt_padded, offset)
-        canvas[i // c, :, :, i % c] = np.array(translated_patch)[0, :N, :N, 0]
-
-    # Convert the canvas to a TensorFlow tensor and return it
-    return tf.convert_to_tensor(canvas)
-
-@debug
-def shift_and_sum(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    from . import tf_helper as hh
-    assert len(obj_tensor.shape) == 4
-    assert obj_tensor.dtype == np.complex64
-    assert len(global_offsets.shape) == 4
-    assert global_offsets.dtype == np.float64
-    # Extract necessary parameters
-    N = params()['N']
-    # Select the central part of the object tensor
-    obj_tensor = obj_tensor[:, N // 2 - M // 2: N // 2 + M // 2, N // 2 - M // 2: N // 2 + M // 2, :]
-    # Calculate the center of mass of global_offsets
-    center_of_mass = tf.reduce_mean(tf.cast(global_offsets, tf.float32), axis=0)
-    # Adjust global_offsets by subtracting the center of mass
-    adjusted_offsets = tf.cast(global_offsets, tf.float32) - center_of_mass
-    # Calculate dynamic padding based on maximum adjusted offset
-    max_offset = tf.reduce_max(tf.abs(adjusted_offsets))
-    dynamic_pad = int(tf.cast(tf.math.ceil(max_offset), tf.int32))
-    print('PADDING SIZE:', dynamic_pad)
-    
-    # Create a canvas to store the shifted and summed object tensors
-    result = tf.zeros_like(hh.pad(obj_tensor[0:1], dynamic_pad))
-    
-    # Iterate over the adjusted offsets and perform shift-and-sum
-    for i in range(len(adjusted_offsets)):
-        # Apply dynamic padding to the current object tensor
-        padded_obj_tensor = hh.pad(obj_tensor[i:i+1], dynamic_pad)
-        # Squeeze and cast adjusted offset to 2D float for translation
-        offset_2d = tf.cast(tf.squeeze(adjusted_offsets[i]), tf.float32)
-        # Translate the padded object tensor
-        translated_obj = hh.translate(padded_obj_tensor, offset_2d, interpolation='bilinear')
-        # Accumulate the translated object tensor
-        result += translated_obj[0]
-    
-    # TODO: how could we support multiple scans?
-    return result[0]
-
-
-# TODO move to tf_helper?
-@debug
-def reassemble_position(obj_tensor: np.ndarray, global_offsets: np.ndarray, M: int = 10) -> tf.Tensor:
-    ones = tf.ones_like(obj_tensor)
-    return shift_and_sum(obj_tensor, global_offsets, M = M) /\
-        (1e-9 + shift_and_sum(ones, global_offsets, M = M))
-
-@debug
-def split_data(X_full, coords_nominal, coords_true, train_frac, which):
-    """
-    Splits the data into training and testing sets based on the specified fraction.
-
-    Args:
-        X_full (np.ndarray): The full dataset to be split.
-        coords_nominal (np.ndarray): The nominal coordinates associated with the dataset.
-        coords_true (np.ndarray): The true coordinates associated with the dataset.
-        train_frac (float): The fraction of the dataset to be used for training.
-        which (str): A string indicating whether to return the 'train' or 'test' split.
-
-    Returns:
-        tuple: A tuple containing the split data and coordinates.
-    """
-    n_train = int(len(X_full) * train_frac)
-    if which == 'train':
-        return X_full[:n_train], coords_nominal[:n_train], coords_true[:n_train]
-    elif which == 'test':
-        return X_full[n_train:], coords_nominal[n_train:], coords_true[n_train:]
-    else:
-        raise ValueError("Invalid split type specified: must be 'train' or 'test'.")
-
-@debug
-def split_tensor(tensor, frac, which='test'):
-    """
-    Splits a tensor into training and test portions based on the specified fraction.
-
-    :param tensor: The tensor to split.
-    :param frac: Fraction of the data to be used for training.
-    :param which: Specifies whether to return the training ('train') or test ('test') portion.
-    :return: The appropriate portion of the tensor based on the specified fraction and 'which' parameter.
-    """
-    n_train = int(len(tensor) * frac)
-    return tensor[:n_train] if which == 'train' else tensor[n_train:]
-
-# TODO this should be a method of PtychoDataContainer
-@debug
-def load(cb: Callable[[], RawData], probeGuess: tf.Tensor, which: str, create_split: bool) -> PtychoDataContainer:
-    from . import params as cfg
-    from . import probe
-    #probeGuess = probe.get_probe(fmt = 'np')
-    if create_split:
-        dset, train_frac = cb()
-    else:
-        dset = cb()
-    gt_image = dset['objectGuess']
-    X_full = dset['X_full'] # normalized diffraction
-    global_offsets = dset[key_coords_offsets]
-    # Define coords_nominal and coords_true before calling split_data
-    coords_nominal = dset[key_coords_relative]
-    coords_true = dset[key_coords_relative]
-    if create_split:
-        global_offsets = split_tensor(global_offsets, train_frac, which)
-        X, coords_nominal, coords_true = split_data(X_full, coords_nominal, coords_true, train_frac, which)
-    else:
-        X = X_full
-    norm_Y_I = datasets.scale_nphotons(X)
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-#    try:
-#        Y_obj = get_image_patches(gt_image, global_offsets, coords_true) * cfg.get('probe_mask')[..., 0]
-#    except:
-#        Y_obj = tf.zeros_like(X)
-
-    norm_Y_I = datasets.scale_nphotons(X)
-
-    X = tf.convert_to_tensor(X)
-    coords_nominal = tf.convert_to_tensor(coords_nominal)
-    coords_true = tf.convert_to_tensor(coords_true)
-
-#    try:
-    Y_obj = get_image_patches(gt_image,
-        global_offsets, coords_true) * cfg.get('probe_mask')[..., 0]
-    Y_I = tf.math.abs(Y_obj)
-    Y_phi = tf.math.angle(Y_obj)
-#    except: 
-#        Y_obj = None
-#        Y_I = tf.zeros_like(X)
-#        Y_phi = tf.zeros_like(X)
-#    Y_I = tf.ones_like(X)
-#    Y_phi = tf.ones_like(X)
-
-    YY_full = None
-    # TODO complex
-    container = PtychoDataContainer(X, Y_I, Y_phi, norm_Y_I, YY_full, coords_nominal, coords_true, dset['nn_indices'], dset['coords_offsets'], dset['coords_relative'], probeGuess)
-    print('INFO:', which)
-    print(container)
-    return container
-
-# Images are amplitude, not intensity
-@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    X_full = dset['diffraction']
-    X_full_norm = ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-    return X_full_norm * X_full
-
-@debug
-def crop(arr2d, size):
-    N, M = arr2d.shape
-    return arr2d[N // 2 - (size) // 2: N // 2+ (size) // 2, N // 2 - (size) // 2: N // 2 + (size) // 2]
-
-@debug
-def get_gt_patch(offset, N, gt_image):
-    from . import tf_helper as hh
-    return crop(
-        hh.translate(gt_image, offset),
-        N // 2)
-
-
-
-import sys
-
-from types import FunctionType
-from .function_logger import log_function_call
-#Import current module
-current_module = sys.modules[__name__]
-
-for name, func in list(vars(current_module).items()):
-    if isinstance(func, FunctionType): #Note: callable(func) doesn't work b/c classes are callable. Swapped to this method instead for functions only
-        setattr(current_module, name, log_function_call(func))
-
diff --git a/build/lib/ptycho/loader_structure.md b/build/lib/ptycho/loader_structure.md
deleted file mode 100644
index 8151800..0000000
--- a/build/lib/ptycho/loader_structure.md
+++ /dev/null
@@ -1,47 +0,0 @@
-graph TD
-    RawData[RawData]
-    PtychoDataset[PtychoDataset]
-    PtychoDataContainer[PtychoDataContainer]
-    load[load]
-    
-    RawData --> |uses| generate_grouped_data
-    RawData --> |uses| from_coords_without_pc
-    RawData --> |uses| from_simulation
-    RawData --> |uses| to_file
-    RawData --> |uses| from_file
-    RawData --> |uses| from_files
-    RawData --> |uses| _check_data_validity
-    
-    generate_grouped_data --> |calls| get_neighbor_diffraction_and_positions
-    
-    PtychoDataContainer --> |contains| X
-    PtychoDataContainer --> |contains| Y_I
-    PtychoDataContainer --> |contains| Y_phi
-    PtychoDataContainer --> |contains| norm_Y_I
-    PtychoDataContainer --> |contains| YY_full
-    PtychoDataContainer --> |contains| coords_nominal
-    PtychoDataContainer --> |contains| coords_true
-    
-    load --> |uses| normalize_data
-    load --> |uses| crop
-    load --> |uses| get_gt_patch
-    load --> |uses| get_image_patches
-    
-    subgraph Helper Functions
-        get_neighbor_self_indices
-        get_neighbor_indices
-        sample_rows
-        get_relative_coords
-        crop12
-        extract_and_translate_patch_np
-        unsqueeze_coords
-        calculate_combined_offsets
-    end
-    
-    shift_and_sum
-    reassemble_position --> |uses| shift_and_sum
-    
-    group_coords --> |uses| get_neighbor_self_indices
-    group_coords --> |uses| get_neighbor_indices
-    
-    calculate_relative_coords --> |uses| group_coords
diff --git a/build/lib/ptycho/logging.py b/build/lib/ptycho/logging.py
deleted file mode 100644
index 7f2433f..0000000
--- a/build/lib/ptycho/logging.py
+++ /dev/null
@@ -1,315 +0,0 @@
-"""
-Module for logging and inspecting function inputs, outputs, and execution times.
-
-Provides the `debug` decorator to log function invocations, including serialized inputs,
-outputs, and execution times. Supports logging to console and disk files.
-
-Includes `load_logged_data` function to load logged data from disk for a specific invocation.
-
-Handles serialization of NumPy arrays, TensorFlow tensors, and custom objects.
-
-Logging controlled by `params.get('debug')` configuration.
-
-Key components:
-- `debug` decorator
-- `load_logged_data` function
-- Helper functions: `make_invocation_counter`, `serialize_input`
-- Custom exceptions: `SerializationError`, `LoggedDataNotFoundError`
-"""
-import functools
-import inspect
-import json
-import numpy as np
-import os
-import tensorflow as tf
-from datetime import datetime
-from typing import Any, Callable, Dict, List, Tuple
-
-from . import params
-
-class SerializationError(Exception):
-    pass
-
-class LoggedDataNotFoundError(Exception):
-    pass
-
-def make_invocation_counter():
-    count = 0
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-    return increment
-
-# TODO surround each function's output section in xml tags with the function / 
-# method path
-def debug(log_to_file: bool = True):
-    def decorator(func: Callable):
-        increment_count = make_invocation_counter()
-
-        @functools.wraps(func)
-        def wrapper(*args: Any, **kwargs: Any) -> Any:
-            if params.get('debug'):
-                invocation_count = increment_count()
-
-                if invocation_count <= 2:
-                    timestamp = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
-                    module_path = inspect.getmodule(func).__name__
-                    function_name = func.__name__
-
-                    def serialize_input(arg: Any) -> str:
-                        if isinstance(arg, np.ndarray):
-                            return f"NumPy array with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, tf.Tensor):
-                            return f"TensorFlow tensor with shape {arg.shape} and data type {arg.dtype}"
-                        elif isinstance(arg, (int, float, str, bool)):
-                            return f"{type(arg).__name__} with value {arg}"
-                        else:
-                            return str(type(arg))
-
-                    serializable_inputs = {
-                        'args': [serialize_input(arg) for arg in args],
-                        'kwargs': {key: serialize_input(value) for key, value in kwargs.items()}
-                    }
-
-                    log_message = f"Calling function {function_name} in module {module_path} with inputs: {json.dumps(serializable_inputs, default=str)}"
-                    print(log_message)
-
-                    if log_to_file:
-                        log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-                        os.makedirs(log_directory, exist_ok=True)
-                        log_file_path = os.path.join(log_directory, f"{function_name}_{timestamp}.log")
-                        try:
-                            with open(log_file_path, 'w') as log_file:
-                                log_file.write(log_message + '\n')
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                    start_time = datetime.now()
-                    try:
-                        result = func(*args, **kwargs)
-                    except Exception as e:
-                        error_message = f"Error executing function {function_name} in module {module_path}: {str(e)}"
-                        print(error_message)
-                        raise e
-                    end_time = datetime.now()
-                    execution_time = end_time - start_time
-
-                    serializable_result = serialize_input(result)
-
-                    log_message = f"Function {function_name} in module {module_path} returned: {serializable_result}"
-                    print(log_message)
-                    print(f"Execution time: {execution_time}")
-
-                    if log_to_file:
-                        try:
-                            with open(log_file_path, 'a') as log_file:
-                                log_file.write(log_message + '\n')
-                                log_file.write(f"Execution time: {execution_time}\n")
-                        except IOError as e:
-                            print(f"Error writing log file: {e}")
-
-                else:
-                    result = func(*args, **kwargs)
-
-            else:
-                result = func(*args, **kwargs)
-
-            return result
-
-        return wrapper
-
-    return decorator
-
-def load_logged_data(module_path: str, function_name: str, invocation_index: int = 0) -> Tuple[Dict[str, Any], Any]:
-    log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-    log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-    log_files.sort()
-
-    if invocation_index >= len(log_files):
-        raise LoggedDataNotFoundError(f"Invocation index {invocation_index} not found for function {function_name} in module {module_path}")
-
-    log_file_path = os.path.join(log_directory, log_files[invocation_index])
-
-    try:
-        with open(log_file_path, 'r') as log_file:
-            lines = log_file.readlines()
-            inputs_line = lines[0].strip()
-            outputs_line = lines[1].strip()
-
-            inputs_start = inputs_line.find(': ') + 2
-            outputs_start = outputs_line.find(': ') + 2
-
-            inputs_json = inputs_line[inputs_start:]
-            outputs_str = outputs_line[outputs_start:]
-
-            inputs = json.loads(inputs_json)
-            outputs = outputs_str
-
-            return inputs, outputs
-    except (IOError, json.JSONDecodeError) as e:
-        raise LoggedDataNotFoundError(f"Error loading logged data for function {function_name} in module {module_path}: {str(e)}")
-
-import os
-import json
-from typing import List, Tuple, Union
-from ptycho.logging import LoggedDataNotFoundError, load_logged_data
-
-def get_type_and_dim(serialized_data: str) -> str:
-    if serialized_data.startswith("NumPy array"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"NumPy array, shape: {shape}, dtype: {dtype}"
-    elif serialized_data.startswith("TensorFlow tensor"):
-        shape_start = serialized_data.find("shape") + len("shape")
-        shape_end = serialized_data.find("and data type")
-        shape = eval(serialized_data[shape_start:shape_end].strip())
-        dtype = serialized_data[shape_end + len("and data type"):].strip()
-        return f"TensorFlow tensor, shape: {shape}, dtype: {dtype}"
-    else:
-        return serialized_data.split(" ")[0]
-
-def process_log_file(module_path: str, function_name: str) -> None:
-    if function_name.startswith("__init__"):
-        return
-
-    invocation_index = 0
-    try:
-        inputs, outputs = load_logged_data(module_path, function_name, invocation_index)
-    except LoggedDataNotFoundError:
-        return
-
-    input_types_dims = []
-    for input_data in inputs["args"]:
-        input_types_dims.append(get_type_and_dim(input_data))
-    for input_name, input_data in inputs["kwargs"].items():
-        input_types_dims.append(f"{input_name}: {get_type_and_dim(input_data)}")
-
-    output_type_dim = get_type_and_dim(outputs)
-
-    print(f"Module: {module_path}, Function: {function_name}")
-    print("Input types and dimensionalities:")
-    for input_type_dim in input_types_dims:
-        print(f"  - {input_type_dim}")
-    print(f"Output type and dimensionality: {output_type_dim}")
-    print()
-
-def extract_logged_data(log_directory: str) -> None:
-    for module_name in os.listdir(log_directory):
-        module_directory = os.path.join(log_directory, module_name)
-        for log_file in os.listdir(module_directory):
-            function_name = log_file.split("_")[0]
-            process_log_file(module_name, function_name)
-
-# TODO this function belongs among the tests
-def main() -> None:
-    log_directory = "logs/"
-    extract_logged_data(log_directory)
-
-####
-# tests
-####
-# Test case 1: Function with serializable inputs and output
-@debug()
-def add_numbers(a: int, b: int) -> int:
-    return a + b
-
-# Test case 2: Function with NumPy array input and output
-@debug()
-def multiply_array(arr: np.ndarray) -> np.ndarray:
-    return arr * 2
-
-# Test case 3: Function with TensorFlow tensor input and output
-@debug()
-def add_tensors(t1: tf.Tensor, t2: tf.Tensor) -> tf.Tensor:
-    return t1 + t2
-
-# Test case 4: Function with mixed input types and custom object output
-class CustomResult:
-    def __init__(self, value: str):
-        self.value = value
-
-@debug()
-def process_data(data: Any, flag: bool) -> CustomResult:
-    if flag:
-        return CustomResult("Processed: " + str(data))
-    else:
-        return CustomResult("Skipped: " + str(data))
-
-# Test case 5: Function with exception
-@debug()
-def divide_numbers(a: int, b: int) -> float:
-    return a / b
-
-# Test case 6: Loading logged data from disk
-@debug(log_to_file=True)
-def multiply_numbers(a: int, b: int) -> int:
-    return a * b
-
-## Set the debug parameter to True
-#params.cfg['debug'] = True
-#
-## Running the tests
-#add_numbers(3, 5)
-#add_numbers(4, 6)
-#add_numbers(5, 7)  # This invocation will not be logged
-#multiply_array(np.array([1, 2, 3]))
-#multiply_array(np.array([4, 5, 6]))
-#multiply_array(np.array([7, 8, 9]))  # This invocation will not be logged
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#add_tensors(tf.constant([[1.0, 2.0], [3.0, 4.0]]), tf.constant([[5.0, 6.0], [7.0, 8.0]]))
-#add_tensors(tf.constant([1.0, 2.0, 3.0]), tf.constant([4.0, 5.0, 6.0]))  # This invocation will not be logged
-#process_data({"key": "value"}, True)
-#process_data({"key": "value"}, False)
-#process_data([1, 2, 3], True)  # This invocation will not be logged
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(20, 0)
-#except ZeroDivisionError:
-#    pass
-#try:
-#    divide_numbers(30, 0)  # This invocation will not be logged
-#except ZeroDivisionError:
-#    pass
-#
-#multiply_numbers(2, 3)
-#multiply_numbers(4, 5)
-#multiply_numbers(6, 7)  # This invocation will not be logged
-#
-## Loading logged data from disk
-#module_path = "__main__"
-#function_name = "multiply_numbers"
-#invocation_index = 0
-#
-#inputs, output = load_logged_data(module_path, function_name, invocation_index)
-#
-#print(f"Loaded inputs: {inputs}")
-#print(f"Loaded output: {output}")
-#
-## Cleanup: Remove the logged data files
-#log_directory = os.path.join(os.getcwd(), 'logs', module_path)
-#log_files = [f for f in os.listdir(log_directory) if f.startswith(f"{function_name}_")]
-#for log_file in log_files:
-#    log_file_path = os.path.join(log_directory, log_file)
-#    os.remove(log_file_path)
-#
-## Set the debug parameter to False
-#params.cfg['debug'] = False
-#
-## Running the tests again (no logging should occur)
-#add_numbers(3, 5)
-#multiply_array(np.array([1, 2, 3]))
-#add_tensors(tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]), tf.constant([[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]))
-#process_data({"key": "value"}, True)
-#try:
-#    divide_numbers(10, 0)
-#except ZeroDivisionError:
-#    pass
-#multiply_numbers(2, 3)
-#
-#
diff --git a/build/lib/ptycho/losses.py b/build/lib/ptycho/losses.py
deleted file mode 100644
index 1efd8b0..0000000
--- a/build/lib/ptycho/losses.py
+++ /dev/null
@@ -1,17 +0,0 @@
-#def I_channel_MAE(y_true,y_pred, center_target = True):
-#    if center_target:
-#        y_true = center_channels(y_true
-#    return tf.reduce_mean(tf.keras.losses.MeanAbsoluteError(y_true,y_pred))
-
-#def symmetrized_loss(target, pred, loss_fn):
-#    """
-#    Calculate loss function on an image, taking into account that the
-#    prediction may be coordinate-inverted relative to the target
-#    """
-#    abs1 = (target)
-#    abs2 = (pred)
-#    abs3 = abs2[:, ::-1, ::-1, :]
-#    target_sym = (symmetrize_3d(target))
-#    a, b, c = loss_fn(abs1, abs2), loss_fn(abs1, abs3), loss_fn(target_sym, pred)
-#    return tf.minimum(a,
-#                      tf.minimum(b, c))
diff --git a/build/lib/ptycho/misc b/build/lib/ptycho/misc
deleted file mode 100644
index 222df9a..0000000
--- a/build/lib/ptycho/misc
+++ /dev/null
@@ -1,57 +0,0 @@
-#####
-## Utils for shifting and matching pieces of tensors
-#####
-
-# from scipy.spatial.distance import hamming
-
-# def mk_coords():
-#     for i in (0, 1):
-#         for j in (0, 1):
-#             yield (i, j)
-            
-# def get_pairs():
-#     for i, p1 in enumerate(mk_coords()):
-#         for p2 in list(mk_coords())[i:]:
-#             if hamming(np.array(p1), np.array(p2)) == .5:
-#                 yield (p1, p2)
-
-# def get_range(i, j, toggle_i, toggle_j):
-#     if toggle_i:
-#         DX = N - offset
-#         return (1 - i) * offset, (1 - i) * offset + DX, 0, offset + N
-#     elif toggle_j:
-#         DY = N - offset
-#         return 0, offset + N, (1 - j) * offset, (1 - j) * offset + DY
-#     else:
-#         raise ValueError
-
-# def toggle(coords1, coords2):
-#     return (coords1[0] ^ coords2[0], coords1[1] ^ coords2[1])
-
-# def get_overlap_pair(grid, coords1, coords2):
-#     """
-#     Get objects from neighboring scan points, cropping such that things line up properly.
-#     """
-#     i1start, i1end, j1start, j1end = get_range(*(coords1 + toggle(coords1, coords2)))
-#     i2start, i2end, j2start, j2end = get_range(*(coords2 + toggle(coords1, coords2)))
-#     return grid[:, coords1[0], coords1[1], i1start: i1end, j1start: j1end, :],\
-#         grid[:, coords2[0], coords2[1], i2start: i2end, j2start: j2end, :]
-
-# def get_overlap_pairs(grid):
-#     pairs = list(set(get_pairs()))
-#     return [get_overlap_pair(grid, p1, p2) for p1, p2 in pairs]
-
-# def overlap_penalty(grid):
-#     mae = tf.keras.losses.MeanAbsoluteError()
-#     penalties = [mae(a1, a2) for a1, a2 in get_overlap_pairs(grid)]
-#     return tf.math.reduce_mean(penalties)
-
-# overlap_penalty(Y_I_test)
-
-# pairs = list(set(get_pairs()))
-# it = iter(pairs)
-
-# a1, a2 = get_overlap_pair(Y_I_train, *next(it))
-# plt.imshow((a1 - a2)[0], cmap = 'jet')
-
-# overlap_penalty(Y_I_train)
diff --git a/build/lib/ptycho/misc.py b/build/lib/ptycho/misc.py
deleted file mode 100644
index eb0da43..0000000
--- a/build/lib/ptycho/misc.py
+++ /dev/null
@@ -1,217 +0,0 @@
-import numpy as np
-import matplotlib.cm as cm
-import scipy.cluster.vq as scv
-from ptycho import params
-from datetime import datetime
-
-# TODO multiple creations of this directory
-def get_path_prefix():
-    label = params.cfg['label']
-    prefix = params.params()['output_prefix']
-    now = datetime.now() # current date and time
-    try:
-        date_time = params.get('timestamp')
-    except KeyError:
-        date_time = now.strftime("%m/%d/%Y, %H:%M:%S")
-        params.set('timestamp', date_time)
-    date_time = date_time.replace('/', '-').replace(':', '.').replace(', ', '-')
-
-    #print('offset', offset)
-    out_prefix = '{}/{}_{}/'.format(prefix, date_time, label)
-    return out_prefix
-
-# Convert RGB colormap images to grayscale
-def colormap2arr(arr,cmap):
-    # http://stackoverflow.com/questions/3720840/how-to-reverse-color-map-image-to-scalar-values/3722674#3722674
-    gradient=cmap(np.linspace(0.0,1.0,1000))
-
-    # Reshape arr to something like (240*240, 4), all the 4-tuples in a long list...
-    arr2=arr.reshape((arr.shape[0]*arr.shape[1],arr.shape[2]))
-
-    # Use vector quantization to shift the values in arr2 to the nearest point in
-    # the code book (gradient).
-    code,dist=scv.vq(arr2,gradient)
-
-    # code is an array of length arr2 (240*240), holding the code book index for
-    # each observation. (arr2 are the "observations".)
-    # Scale the values so they are from 0 to 1.
-    values=code.astype('float')/gradient.shape[0]
-
-    # Reshape values back to (240,240)
-    values=values.reshape(arr.shape[0],arr.shape[1])
-    values=values[::-1]
-    return values
-
-import functools
-import hashlib
-import json
-import os
-import tensorflow as tf
-
-#https://chat.openai.com/c/8273412b-f3fb-405c-a7a4-c0466bb43b04
-def memoize_disk_and_memory(func):
-    from ptycho.params import cfg
-    from ptycho import probe
-    memory_cache = {}
-    disk_cache_dir = 'memoized_data'
-
-    if not os.path.exists(disk_cache_dir):
-        os.makedirs(disk_cache_dir)
-
-    @functools.wraps(func)
-    def wrapper(*args, **kwargs):
-        cfg_keys = ['offset', 'N', 'outer_offset_train', 'outer_offset_test',
-                     'nphotons', 'nimgs_train', 'nimgs_test', 'set_phi',
-                    'data_source', 'gridsize', 'big_gridsize', 'default_probe_scale']
-        hash_input = {k: cfg[k] for k in cfg_keys if k in cfg}
-        hash_input.update({f'arg_{i}': json.dumps(arg, default=str) for i, arg in enumerate(args)})
-        hash_input.update({f'kwarg_{k}': json.dumps(v, default=str) for k, v in kwargs.items()})
-
-        hash_input_str = json.dumps(hash_input, sort_keys=True).encode('utf-8')
-        hash_hex = hashlib.sha1(hash_input_str).hexdigest()
-
-        if hash_hex in memory_cache:
-            print("Loading result from memory cache.")
-            return memory_cache[hash_hex]
-        else:
-            disk_cache_file = os.path.join(disk_cache_dir, f'{hash_hex}.npz')
-
-            if os.path.exists(disk_cache_file):
-                print("Loading result from disk cache.")
-                loaded_data = np.load(disk_cache_file, allow_pickle=True)
-                result = tuple(loaded_data[key] for key in loaded_data.keys())
-                if len(result) == 1:
-                    result = result[0]
-            else:
-                print("No cached result found. Calculating and caching the result.")
-                result = func(*args, **kwargs)
-
-                if isinstance(result, (np.ndarray, tf.Tensor)):
-                    np.savez(disk_cache_file, result=result.numpy() if isinstance(result, tf.Tensor) else result)
-                elif isinstance(result, tuple):
-                    np.savez(disk_cache_file, **{f'arr_{i}': arr.numpy() if isinstance(arr, tf.Tensor) else arr for i, arr in enumerate(result)})
-                else:
-                    raise ValueError("Invalid function output. Expected numpy array, TensorFlow tensor, or tuple containing numpy arrays and/or TensorFlow tensors.")
-
-                memory_cache[hash_hex] = result
-
-        return result
-
-    return wrapper
-
-
-##########
-# unit test
-##########
-#
-#import numpy as np
-#import tensorflow as tf
-#
-## Define test functions
-#@memoize_disk_and_memory
-#def test_function1(x):
-#    return np.random.rand(x, x)
-#
-#@memoize_disk_and_memory
-#def test_function2(x):
-#    return tf.random.uniform((x, x))
-#
-#@memoize_disk_and_memory
-#def test_function3(x):
-#    return np.random.rand(x, x), tf.random.uniform((x, x))
-#
-## First run - cache miss
-#result1_first = test_function1(5)
-#result2_first = test_function2(5)
-#result3_first = test_function3(5)
-#
-## Second run - cache hit
-#result1_second = test_function1(5)
-#result2_second = test_function2(5)
-#result3_second = test_function3(5)
-#
-## Test if the memoized results match the first run results
-#np.testing.assert_array_equal(result1_first, result1_second)
-#np.testing.assert_array_equal(result2_first, result2_second)
-#
-#np.testing.assert_array_equal(result3_first[0], result3_second[0])
-#np.testing.assert_array_equal(result3_first[1], result3_second[1])
-#
-## Test if memoization works with different function arguments
-#result1_diff_arg = test_function1(6)
-#np.testing.assert_raises(AssertionError, np.testing.assert_array_equal, result1_first, result1_diff_arg)
-#
-
-import functools
-import numpy as np
-import tensorflow as tf
-
-def make_invocation_counter():
-    count = 0
-
-    def increment():
-        nonlocal count
-        count += 1
-        return count
-
-    return increment
-
-######
-## logging decorator
-######
-# TODO deprecated, moved to logging.py
-#def g(h):
-#    increment_count = make_invocation_counter()
-#
-#    def wrapper(f):
-#        @functools.wraps(f)
-#        def inner(*args, **kwargs):
-#            invocation_count = increment_count()
-#            if invocation_count <= 2:
-#                return h(f)(*args, **kwargs)
-#            else:
-#                return f(*args, **kwargs)
-#
-#        return inner
-#
-#    return wrapper
-#
-#@g
-#def debug(func):
-#    def wrapper(*args, **kwargs):
-#        def get_type_and_shape(x):
-#            if isinstance(x, np.ndarray):
-#                return f"{type(x)} with shape {x.shape}"
-#            elif isinstance(x, tf.Tensor):
-#                return f"{type(x)} with shape {x.shape}"
-#            else:
-#                return str(type(x))
-#
-#        args_types = [get_type_and_shape(arg) for arg in args]
-#        kwargs_types = {k: get_type_and_shape(v) for k, v in kwargs.items()}
-#
-#        print(f"Calling {func.__name__} with args types: {args_types}, kwargs types: {kwargs_types}")
-#        result = func(*args, **kwargs)
-#        
-#        result_type = get_type_and_shape(result)
-#        print(f"{func.__name__} returned {result_type}")
-#        
-#        return result
-#    return wrapper
-
-import scipy.signal
-def cross_image(im1, im2):
-    """
-    Find offsets through 2d autocorrelation
-    """
-    # get rid of the color channels by performing a grayscale transform
-    # the type cast into 'float' is to avoid overflows
-    im1_gray = im1#np.sum(im1.astype('float'), axis=2)
-    im2_gray = im2#np.sum(im2.astype('float'), axis=2)
-
-    # get rid of the averages, otherwise the results are not good
-    im1_gray -= np.mean(im1_gray)
-    im2_gray -= np.mean(im2_gray)
-
-    # calculate the correlation image; note the flipping of onw of the images
-    return scipy.signal.fftconvolve(im1_gray, im2_gray[::-1,::-1], mode='same')
diff --git a/build/lib/ptycho/model.py b/build/lib/ptycho/model.py
deleted file mode 100644
index c7b4bfe..0000000
--- a/build/lib/ptycho/model.py
+++ /dev/null
@@ -1,411 +0,0 @@
-# TODO s
-# - complex convolution
-# - Use tensor views:
-#     https://chat.openai.com/c/e6d5e400-daf9-44b7-8ef9-d49f21a634a3
-# -difference maps?
-# -double -> float32
-# Apply real space loss to both amplitude and phase of the object
-
-from datetime import datetime
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras.activations import relu, sigmoid, tanh, swish
-from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, UpSampling2D, InputLayer, Lambda, Dense
-from tensorflow.keras.layers import Layer
-from tensorflow.keras import layers
-import glob
-import math
-import numpy as np
-import os
-import tensorflow.compat.v2 as tf
-import tensorflow_probability as tfp
-
-from .loader import PtychoDataContainer
-from . import tf_helper as hh
-from . import params as cfg
-params = cfg.params
-
-import tensorflow_addons as tfa
-gaussian_filter2d = tfa.image.gaussian_filter2d
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-# sets the number of convolutional filters
-
-n_filters_scale =  cfg.get('n_filters_scale')
-N = cfg.get('N')
-gridsize = cfg.get('gridsize')
-offset = cfg.get('offset')
-
-from . import probe
-tprobe = params()['probe']
-# TODO
-#probe_mask = probe.probe_mask
-probe_mask = cfg.get('probe_mask')[:, :, :, 0]
-initial_probe_guess = tprobe
-initial_probe_guess = tf.Variable(
-            initial_value=tf.cast(initial_probe_guess, tf.complex64),
-            trainable=params()['probe.trainable'],
-        )
-
-# TODO hyperparameters:
-# TODO total variation loss
-# -probe smoothing scale(?)
-class ProbeIllumination(tf.keras.layers.Layer):
-    def __init__(self, name = None):
-        super(ProbeIllumination, self).__init__(name = name)
-        self.w = initial_probe_guess
-    #@tf.function
-    def call(self, inputs):
-        x = inputs[0]
-        if cfg.get('probe.mask'):
-            return self.w * x * probe_mask, (self.w * probe_mask)[None, ...]
-        else:
-            return self.w * x, (self.w)[None, ...]
-
-probe_illumination = ProbeIllumination()
-
-nphotons = cfg.get('nphotons')
-
-# TODO scaling could be done on a shot-by-shot basis, but IIRC I tried this
-# and there were issues
-log_scale_guess = np.log(cfg.get('intensity_scale'))
-log_scale = tf.Variable(
-            initial_value=tf.constant(float(log_scale_guess)),
-            trainable = params()['intensity_scale.trainable'],
-        )
-
-class IntensityScaler(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return x / tf.math.exp(self.w)
-
-# TODO use a bijector instead of separately defining the transform and its
-# inverse
-class IntensityScaler_inv(tf.keras.layers.Layer):
-    def __init__(self):
-        super(IntensityScaler_inv, self).__init__()
-        self.w = log_scale
-    def call(self, inputs):
-        x, = inputs
-        return tf.math.exp(self.w) * x
-
-def scale(inputs):
-    x, = inputs
-    res = x / tf.math.exp(log_scale)
-    return res
-
-def inv_scale(inputs):
-    x, = inputs
-    return tf.math.exp(log_scale) * x
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-lambda_norm = Lambda(lambda x: tf.math.reduce_sum(x**2, axis = [1, 2]))
-input_img = Input(shape=(N, N, gridsize**2), name = 'input')
-input_positions = Input(shape=(1, 2, gridsize**2), name = 'input_positions')
-
-def Conv_Pool_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = MaxPool2D((p1, p2), padding=padding, data_format=data_format)(x0)
-    return x0
-
-def Conv_Up_block(x0,nfilters,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last',
-        activation = 'relu'):
-    x0 = Conv2D(nfilters, (w1, w2), activation='relu', padding=padding, data_format=data_format)(x0)
-    x0 = Conv2D(nfilters, (w1, w2), activation=activation, padding=padding, data_format=data_format)(x0)
-    x0 = UpSampling2D((p1, p2), data_format=data_format)(x0)
-    return x0
-
-def create_encoder(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 128:
-        filters = [n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    elif N == 256:
-        filters = [n_filters_scale * 8, n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Pool_block(x, num_filters)
-    
-    return x
-
-def create_decoder_base(input_tensor, n_filters_scale):
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    return x
-
-def create_decoder_last(input_tensor, n_filters_scale, conv1, conv2, act=tf.keras.activations.sigmoid, name=''):
-    N = cfg.get('N')
-    gridsize = cfg.get('gridsize')
-    
-    c_outer = 4
-    x1 = conv1(input_tensor[..., :-c_outer])
-    x1 = act(x1)
-    x1 = tf.keras.layers.ZeroPadding2D(((N // 4), (N // 4)), name=name + '_padded')(x1)
-    
-    if not cfg.get('probe.big'):
-        return x1
-    
-    x2 = Conv_Up_block(input_tensor[..., -c_outer:], n_filters_scale * 32)
-    x2 = conv2(x2)
-    x2 = swish(x2)
-    
-    outputs = x1 + x2
-    return outputs
-
-def create_decoder_phase(input_tensor, n_filters_scale, gridsize, big):
-    num_filters = gridsize**2 if big else 1
-    conv1 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same')
-    act = tf.keras.layers.Lambda(lambda x: math.pi * tf.keras.activations.tanh(x), name='phi')
-    
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act, name='phase')
-    return outputs
-
-def create_decoder_amp(input_tensor, n_filters_scale):
-    conv1 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    act = Lambda(get_amp_activation(), name='amp')
-    
-    N = cfg.get('N')
-    
-    if N == 64:
-        filters = [n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 128:
-        filters = [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    elif N == 256:
-        filters = [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-    else:
-        raise ValueError(f"Unsupported input size: {N}")
-    
-    x = input_tensor
-    for num_filters in filters:
-        x = Conv_Up_block(x, num_filters)
-    
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act, name='amp')
-    return outputs
-
-def create_autoencoder(input_tensor, n_filters_scale, gridsize, big):
-    encoded = create_encoder(input_tensor, n_filters_scale)
-    decoded_amp = create_decoder_amp(encoded, n_filters_scale)
-    decoded_phase = create_decoder_phase(encoded, n_filters_scale, gridsize, big)
-    
-    return decoded_amp, decoded_phase
-
-
-def get_amp_activation():
-    if cfg.get('amp_activation') == 'sigmoid':
-        return lambda x: sigmoid(x)
-    elif cfg.get('amp_activation') == 'swish':
-        return lambda x: swish(x)
-    else:
-        return ValueError
-
-def create_decoder_amp(input_tensor, n_filters_scale):
-    # Placeholder convolution layers and activation as defined in the original DecoderAmp class
-    conv1 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same')
-    act = Lambda(get_amp_activation(), name='amp')
-
-    x = create_decoder_base(input_tensor, n_filters_scale)
-    outputs = create_decoder_last(x, n_filters_scale, conv1, conv2, act=act,
-        name = 'amp')
-    return outputs
-
-normed_input = scale([input_img])
-decoded1, decoded2 = create_autoencoder(normed_input, n_filters_scale, gridsize,
-    cfg.get('object.big'))
-
-# Combine the two decoded outputs
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]), name='obj')([decoded1, decoded2])
-
-if cfg.get('object.big'):
-    # If 'object.big' is true, reassemble the patches
-    padded_obj_2 = Lambda(lambda x: hh.reassemble_patches(x[0], fn_reassemble_real=hh.mk_reassemble_position_real(x[1])), name = 'padded_obj_2')([obj, input_positions])
-else:
-    # If 'object.big' is not true, pad the reconstruction
-    padded_obj_2 = Lambda(lambda x: hh.pad_reconstruction(x), name = 'padded_obj_2')(obj)
-
-# TODO rename?
-# Trim the object reconstruction to N x N
-trimmed_obj = Lambda(hh.trim_reconstruction, name = 'trimmed_obj')(padded_obj_2)
-
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x:
-    hh.extract_patches_position(x[0], x[1], 0.),
-    name = 'padded_objs_with_offsets')([padded_obj_2, input_positions])
-
-# Apply the probe illumination
-padded_objs_with_offsets, probe = probe_illumination([padded_objs_with_offsets])
-flat_illuminated = padded_objs_with_offsets
-
-# Apply pad and diffract operation
-padded_objs_with_offsets, pred_diff = Lambda(lambda x: hh.pad_and_diffract(x, N, N, pad=False), name = 'pred_amplitude')(padded_objs_with_offsets)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-# Scale the amplitude
-pred_amp_scaled = inv_scale([pred_diff])
-
-
-# TODO Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
-dist_poisson_intensity = tfpl.DistributionLambda(lambda amplitude:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               (amplitude**2)))))
-pred_intensity_sampled = dist_poisson_intensity(pred_amp_scaled)
-
-# Poisson distribution over expected diffraction intensity (i.e. photons per
-# pixel)
-negloglik = lambda x, rv_x: -rv_x.log_prob((x))
-fn_poisson_nll = lambda A_target, A_pred: negloglik(A_target**2, dist_poisson_intensity(A_pred))
-
-autoencoder = Model([input_img, input_positions], [trimmed_obj, pred_amp_scaled, pred_intensity_sampled])
-
-autoencoder_no_nll = Model(inputs = [input_img, input_positions],
-        outputs = [pred_amp_scaled])
-
-#encode_obj_to_diffraction = tf.keras.Model(inputs=[obj, input_positions],
-#                           outputs=[pred_diff, flat_illuminated])
-diffraction_to_obj = tf.keras.Model(inputs=[input_img, input_positions],
-                           outputs=[trimmed_obj])
-
-mae_weight = cfg.get('mae_weight') # should normally be 0
-nll_weight = cfg.get('nll_weight') # should normally be 1
-# Total variation regularization on real space amplitude
-realspace_weight = cfg.get('realspace_weight')#1e2
-optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
-
-autoencoder.compile(optimizer= optimizer,
-     #loss=[lambda target, pred: hh.total_variation(pred),
-     loss=[hh.realspace_loss,
-        'mean_absolute_error', negloglik, 'mean_absolute_error'],
-     loss_weights = [realspace_weight, mae_weight, nll_weight, 0.])
-
-print (autoencoder.summary())
-
-# Create a TensorBoard callback
-logs = "logs/" + datetime.now().strftime("%Y%m%d-%H%M%S")
-
-tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,
-                                                 histogram_freq=1,
-                                                 profile_batch='500,520')
-
-def prepare_inputs(train_data: PtychoDataContainer):
-    """training inputs"""
-    return [train_data.X * cfg.get('intensity_scale'), train_data.coords]
-
-def prepare_outputs(train_data: PtychoDataContainer):
-    """training outputs"""
-    return [hh.center_channels(train_data.Y_I, train_data.coords)[:, :, :, :1],
-                (cfg.get('intensity_scale') * train_data.X),
-                (cfg.get('intensity_scale') * train_data.X)**2]
-
-#def train(epochs, X_train, coords_train, Y_obj_train):
-def train(epochs, trainset: PtychoDataContainer):
-    assert type(trainset) == PtychoDataContainer
-    coords_train = trainset.coords
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint(
-                            '%s/weights.{epoch:02d}.h5' %wt_path,
-                            monitor='val_loss', verbose=1, save_best_only=True,
-                            save_weights_only=False, mode='auto', period=1)
-
-    batch_size = params()['batch_size']
-    history=autoencoder.fit(
-#        prepare_inputs(X_train, coords_train),
-#        prepare_outputs(Y_obj_train, coords_train, X_train),
-        prepare_inputs(trainset),
-        prepare_outputs(trainset),
-        shuffle=True, batch_size=batch_size, verbose=1,
-        epochs=epochs, validation_split = 0.05,
-        callbacks=[reduce_lr, earlystop])
-        #callbacks=[reduce_lr, earlystop, tboard_callback])
-    return history
-import numpy as np
-
-def print_model_diagnostics(model):
-    """
-    Prints diagnostic information for a given TensorFlow/Keras model.
-
-    Parameters:
-    - model: A TensorFlow/Keras model object.
-    """
-    # Print the model summary to get the architecture, layer types, output shapes, and parameter counts.
-    model.summary()
-
-    # Print input shape
-    print("Model Input Shape(s):")
-    for input_layer in model.inputs:
-        print(input_layer.shape)
-
-    # Print output shape
-    print("Model Output Shape(s):")
-    for output_layer in model.outputs:
-        print(output_layer.shape)
-
-    # Print total number of parameters
-    print("Total Parameters:", model.count_params())
-
-    # Print trainable and non-trainable parameter counts
-    trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])
-    non_trainable_count = np.sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])
-    print("Trainable Parameters:", trainable_count)
-    print("Non-trainable Parameters:", non_trainable_count)
-
-    # If the model uses any custom layers, print their names and configurations
-    print("Custom Layers (if any):")
-    for layer in model.layers:
-        if hasattr(layer, 'custom_objects'):
-            print(f"{layer.name}: {layer.custom_objects}")
diff --git a/build/lib/ptycho/model_manager.py b/build/lib/ptycho/model_manager.py
deleted file mode 100644
index 3ea0926..0000000
--- a/build/lib/ptycho/model_manager.py
+++ /dev/null
@@ -1,24 +0,0 @@
-import h5py
-import dill
-from tensorflow.keras.models import load_model as tf_load_model
-from ptycho import params
-
-class ModelManager:
-    @staticmethod
-    def save_model(model, model_path, custom_objects, intensity_scale):
-        custom_objects_path = model_path + ".dill"
-        model.save(model_path, save_format="tf")
-        with open(custom_objects_path, 'wb') as f:
-            dill.dump(custom_objects, f)
-        with h5py.File(model_path, 'a') as hf:
-            hf.attrs['intensity_scale'] = intensity_scale
-
-    @staticmethod
-    def load_model(model_path):
-        custom_objects_path = model_path + ".dill"
-        with open(custom_objects_path, 'rb') as f:
-            custom_objects = dill.load(f)
-        with h5py.File(model_path, 'r') as hf:
-            intensity_scale = hf.attrs['intensity_scale']
-        params.set('intensity_scale', intensity_scale)
-        return tf_load_model(model_path, custom_objects=custom_objects)
diff --git a/build/lib/ptycho/nbutils.py b/build/lib/ptycho/nbutils.py
deleted file mode 100644
index 3d71f13..0000000
--- a/build/lib/ptycho/nbutils.py
+++ /dev/null
@@ -1,159 +0,0 @@
-import matplotlib.pyplot as plt
-from ptycho import model
-import numpy as np
-
-def crop_to_non_uniform_region_with_buffer(img_array, buffer=0):
-    """
-    Crop the image to the non-uniform region with an additional buffer in each direction.
-
-    Parameters:
-    - img_array: The numpy array of the image.
-    - buffer: The number of pixels to expand the cropped region in each direction.
-
-    Returns:
-    - cropped_img_array: The numpy array of the cropped image.
-    """
-
-    # Convert to grayscale if it is not already
-    if len(img_array.shape) == 3:
-        gray_img_array = img_array[:, :, 0]
-    else:
-        gray_img_array = img_array
-
-    # Find the background pixel value, assuming it is the mode of the corner pixels
-    corner_pixels = [gray_img_array[0, 0], gray_img_array[0, -1], gray_img_array[-1, 0], gray_img_array[-1, -1]]
-    background_pixel = max(set(corner_pixels), key=corner_pixels.count)
-
-    # Detect the non-uniform region
-    rows, cols = np.where(gray_img_array != background_pixel)
-    if rows.size > 0 and cols.size > 0:
-        row_min, row_max, col_min, col_max = rows.min(), rows.max(), cols.min(), cols.max()
-        # Apply the buffer, ensuring we don't go out of the image bounds
-        row_min = max(row_min - buffer, 0)
-        row_max = min(row_max + buffer, gray_img_array.shape[0] - 1)
-        col_min = max(col_min - buffer, 0)
-        col_max = min(col_max + buffer, gray_img_array.shape[1] - 1)
-    else:
-        raise ValueError("No non-uniform region found")
-
-    # Crop the image to the non-uniform region with the buffer
-    cropped_img_array = gray_img_array[row_min:row_max+1, col_min:col_max+1]
-
-    return cropped_img_array
-
-import matplotlib.pyplot as plt
-
-def mk_epie_comparison2x2(ptycho_pinn_phase, epie_phase, ptycho_pinn_amplitude, epie_amplitude, phase_vmin=None, phase_vmax=None):
-    """
-    Create a 2x2 comparison plot of phase and amplitude images.
-
-    Parameters:
-    - ptycho_pinn_phase: 2D array of PtychoPINN phase data
-    - epie_phase: 2D array of ePIE phase data
-    - ptycho_pinn_amplitude: 2D array of PtychoPINN amplitude data
-    - epie_amplitude: 2D array of ePIE amplitude data
-    - phase_vmin: Minimum data value for phase plots (optional)
-    - phase_vmax: Maximum data value for phase plots (optional)
-    """
-    # Create a 2x2 subplot
-    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
-
-    # PtychoPINN phase with color bar
-    ptycho_pinn_phase_img = axs[0, 0].imshow(ptycho_pinn_phase, cmap='gray', vmin=phase_vmin, vmax=phase_vmax)
-    axs[0, 0].set_title('PtychoPINN Phase')
-    axs[0, 0].axis('off')
-    fig.colorbar(ptycho_pinn_phase_img, ax=axs[0, 0], orientation='vertical')
-
-    # ePIE phase with color bar
-    epie_phase_img = axs[0, 1].imshow(epie_phase, cmap='gray')
-    axs[0, 1].set_title('ePIE Phase')
-    axs[0, 1].axis('off')
-    fig.colorbar(epie_phase_img, ax=axs[0, 1], orientation='vertical')
-
-    # PtychoPINN amplitude with color bar
-    ptycho_pinn_amplitude_img = axs[1, 0].imshow(ptycho_pinn_amplitude, cmap='gray')
-    axs[1, 0].set_title('PtychoPINN Amplitude')
-    axs[1, 0].axis('off')
-    fig.colorbar(ptycho_pinn_amplitude_img, ax=axs[1, 0], orientation='vertical')
-
-    # ePIE amplitude with color bar
-    epie_amplitude_img = axs[1, 1].imshow(epie_amplitude, cmap='gray')
-    axs[1, 1].set_title('ePIE Amplitude')
-    axs[1, 1].axis('off')
-    fig.colorbar(epie_amplitude_img, ax=axs[1, 1], orientation='vertical')
-
-    # Adjust layout to prevent overlap
-    plt.tight_layout(pad=3.0)
-
-    plt.show()
-
-# TODO type annotation
-def reconstruct_image(test_data):
-    global_offsets = test_data.global_offsets
-    local_offsets = test_data.local_offsets
-
-#    obj_tensor_full, _, _ = model.autoencoder.predict(
-#                    [test_data['X'] * model.params()['intensity_scale'],
-#                                    local_offsets])
-    obj_tensor_full = model.diffraction_to_obj.predict(
-                    [test_data.X * model.params()['intensity_scale'],
-                    local_offsets])
-    return obj_tensor_full, global_offsets
-
-def print_shapes(test_data):
-    for key, value in test_data.items():
-        if value is not None:
-            if isinstance(value, tuple):
-                print(f"{key}\t")
-                for i, array in enumerate(value):
-                    print(f"  Array {i+1}{array.shape}, \t {array.dtype}")
-            else:
-                print(f"{key}\t{value.shape}, {value.dtype}")
-
-def probeshow(probeGuess, test_data):
-    # Creating a figure with three subplots
-    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
-
-    # Plotting the magnitude of the complex array
-    img1 = ax1.imshow(np.abs(probeGuess), cmap='viridis')
-    ax1.set_title('probe amplitude')
-    fig.colorbar(img1, ax=ax1, orientation='vertical')
-
-    # Plotting the phase of the complex array
-    img2 = ax2.imshow(np.angle(probeGuess), cmap='jet')
-    ax2.set_title('probe phase')
-    fig.colorbar(img2, ax=ax2, orientation='vertical')
-
-    # Plotting the scan point positions
-    ax3.scatter(*(test_data.global_offsets.squeeze().T))
-    ax3.set_title('scan point positions')
-
-    # Improving layout
-    plt.tight_layout()
-    plt.show()
-
-
-def track_dict_changes(input_dict, callback):
-    # Copy the original dictionary to track changes
-    original_dict = input_dict.copy()
-    # Execute the callback function
-    callback(input_dict)
-    # Determine which keys have changed or added
-    changed_or_added_keys = [key for key in input_dict if input_dict.get(key) != original_dict.get(key)]
-    return changed_or_added_keys
-
-# object heatmaps
-## Creating a figure and two subplots
-#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
-#
-## Plotting the amplitude of the complex object
-#ax1.imshow(np.absolute(objectGuess), cmap='viridis')
-#ax1.set_title('Amplitude')
-#
-## Plotting the phase of the complex object
-#ax2.imshow(np.angle(objectGuess), cmap='viridis')
-#ax2.set_title('Phase')
-#
-## Adjust layout
-#plt.tight_layout()
-#plt.show()
diff --git a/build/lib/ptycho/nongrid_simulation.py b/build/lib/ptycho/nongrid_simulation.py
deleted file mode 100644
index 9c653ea..0000000
--- a/build/lib/ptycho/nongrid_simulation.py
+++ /dev/null
@@ -1,266 +0,0 @@
-# ptycho_simulation.py
-
-import numpy as np
-import matplotlib.pyplot as plt
-from mpl_toolkits.axes_grid1 import make_axes_locatable
-from typing import Union, Tuple, Dict
-from ptycho.loader import RawData
-from ptycho import tf_helper as hh
-from ptycho import probe
-from ptycho import baselines as bl
-
-def load_probe_object(file_path: str) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Load object and probe guesses from a .npz file.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-
-    Returns:
-        tuple: A tuple containing (objectGuess, probeGuess)
-
-    Raises:
-        ValueError: If required data is missing from the .npz file or if data is invalid.
-        RuntimeError: If an error occurs during file loading.
-    """
-    try:
-        with np.load(file_path) as data:
-            if 'objectGuess' not in data or 'probeGuess' not in data:
-                raise ValueError("The .npz file must contain 'objectGuess' and 'probeGuess'")
-            
-            objectGuess = data['objectGuess']
-            probeGuess = data['probeGuess']
-
-        # Validate extracted data
-        if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-            raise ValueError("objectGuess and probeGuess must be 2D arrays")
-        if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-            raise ValueError("objectGuess and probeGuess must be complex-valued")
-
-        return objectGuess, probeGuess
-
-    except Exception as e:
-        raise RuntimeError(f"Error loading data from {file_path}: {str(e)}")
-
-from ptycho.misc import memoize_simulated_data
-
-#@memoize_simulated_data
-def generate_simulated_data(objectGuess: np.ndarray, probeGuess: np.ndarray, nimages: int, buffer: float, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    Args:
-        objectGuess (np.ndarray): Complex-valued 2D array representing the object.
-        probeGuess (np.ndarray): Complex-valued 2D array representing the probe.
-        nimages (int): Number of scan positions to generate.
-        buffer (float): Border size to avoid when generating coordinates.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation.
-    """
-    # Input validation
-    if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-        raise ValueError("objectGuess and probeGuess must be 2D arrays")
-    if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-        raise ValueError("objectGuess and probeGuess must be complex-valued")
-    if nimages <= 0 or buffer < 0:
-        raise ValueError("nimages must be positive and buffer must be non-negative")
-
-    # Get object dimensions
-    height, width = objectGuess.shape
-
-    # Ensure buffer doesn't exceed image dimensions
-    buffer = min(buffer, min(height, width) / 2 - 1)
-
-    # Set random seed if provided
-    if random_seed is not None:
-        np.random.seed(random_seed)
-
-    # Generate random coordinates (floats)
-    xcoords = np.random.uniform(buffer, width - buffer, nimages)
-    ycoords = np.random.uniform(buffer, height - buffer, nimages)
-
-    # Create scan_index
-    scan_index = np.zeros(nimages, dtype=int)
-
-    # Generate simulated data
-    return RawData.from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index, return_patches=return_patches)
-
-def simulate_from_npz(file_path: str, nimages: int, buffer: float = None, random_seed: int = None, return_patches: bool = True) -> Union[RawData, Tuple[RawData, np.ndarray]]:
-    """
-    Load object and probe guesses from a .npz file and generate simulated ptychography data.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-        nimages (int): Number of scan positions to generate.
-        buffer (float, optional): Border size to avoid when generating coordinates. 
-                                  If None, defaults to 35% of the smaller dimension of objectGuess.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-        return_patches (bool): If True, return ground truth patches along with simulated data.
-
-    Returns:
-        RawData or tuple: A RawData instance containing the simulated ptychography data,
-                          or a tuple of (RawData, ground_truth_patches) if return_patches is True.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation or file loading.
-    """
-    # Load guesses from file
-    objectGuess, probeGuess = load_probe_object(file_path)
-
-    # Set default buffer if not provided
-    if buffer is None:
-        buffer = min(objectGuess.shape) * 0.35  # 35% of the smaller dimension
-
-    # Generate simulated data
-    return generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed, return_patches=return_patches)
-
-def plot_complex_image(ax: plt.Axes, data: np.ndarray, title: str) -> None:
-    """Helper function to plot complex-valued images."""
-    im = ax.imshow(np.abs(data), cmap='viridis')
-    ax.set_title(f"{title} (Magnitude)")
-    divider = make_axes_locatable(ax)
-    cax = divider.append_axes("right", size="5%", pad=0.05)
-    plt.colorbar(im, cax=cax)
-
-    ax_phase = divider.append_axes("bottom", size="100%", pad=0.2, sharex=ax)
-    im_phase = ax_phase.imshow(np.angle(data), cmap='hsv')
-    ax_phase.set_title(f"{title} (Phase)")
-    cax_phase = divider.append_axes("bottom", size="5%", pad=0.5)
-    plt.colorbar(im_phase, cax=cax_phase, orientation="horizontal")
-
-def visualize_simulated_data(data: Dict[str, np.ndarray], output_dir: str) -> None:
-    """
-    Visualize the simulated ptychography data and save all plots in a single image file.
-
-    Args:
-        data (dict): Dictionary containing the loaded simulated data.
-        output_dir (str): Directory to save the output plot.
-    """
-    import os
-
-    # Create output directory if it doesn't exist
-    os.makedirs(output_dir, exist_ok=True)
-
-    # Create a large figure with multiple subplots
-    fig = plt.figure(figsize=(24, 30))
-    gs = fig.add_gridspec(5, 3, height_ratios=[1, 0.2, 1, 0.2, 1])
-
-    # Plot probe guess
-    ax_probe = fig.add_subplot(gs[0, 0])
-    plot_complex_image(ax_probe, data['probe_guess'], "Probe Guess")
-
-    # Plot object guess
-    ax_object = fig.add_subplot(gs[0, 1])
-    plot_complex_image(ax_object, data['object'], "Object Guess")
-
-    # Plot scan positions
-    ax_scan = fig.add_subplot(gs[0, 2])
-    ax_scan.scatter(data['x_coordinates'], data['y_coordinates'], alpha=0.5)
-    ax_scan.set_title("Scan Positions")
-    ax_scan.set_xlabel("X Coordinate")
-    ax_scan.set_ylabel("Y Coordinate")
-    ax_scan.set_aspect('equal')
-
-    # Add title for diffraction patterns
-    fig.text(0.5, 0.62, "Sample Diffraction Patterns", ha='center', va='center', fontsize=16)
-
-    # Plot a sample of diffraction patterns
-    for i in range(3):
-        if i < min(3, data['diffraction_patterns'].shape[0]):
-            ax = fig.add_subplot(gs[2, i])
-            im = ax.imshow(np.log(data['diffraction_patterns'][i]), cmap='viridis')
-            ax.set_title(f"Pattern {i}")
-            plt.colorbar(im, ax=ax)
-
-    # Add title for ground truth patches
-    fig.text(0.5, 0.22, "Sample Ground Truth Patches", ha='center', va='center', fontsize=16)
-
-    # Plot ground truth patches
-    for i in range(3):
-        if i < min(3, data['ground_truth_patches'].shape[0]):
-            ax = fig.add_subplot(gs[4, i])
-            plot_complex_image(ax, data['ground_truth_patches'][i], f"Patch {i}")
-
-    plt.tight_layout()
-    plt.savefig(os.path.join(output_dir, "simulated_data_visualization.png"), dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-    print(f"All plots have been saved to: {os.path.join(output_dir, 'simulated_data_visualization.png')}")
-
-def plot_random_groups(tmp: RawData, K: int, figsize: Tuple[int, int] = (15, 5), seed: int = None) -> None:
-    """
-    Plot a random selection of K groups of (diffraction image, Y amplitude, Y phase) from a RawData object.
-
-    Args:
-        tmp (RawData): The RawData object containing the ptychography data.
-        K (int): Number of groups to plot.
-        figsize (tuple): Figure size for each group plot. Default is (15, 5).
-        seed (int): Random seed for reproducibility. Default is None.
-
-    Raises:
-        ValueError: If K is greater than the number of available diffraction patterns.
-    """
-    if K > tmp.diff3d.shape[0]:
-        raise ValueError(f"K ({K}) cannot be greater than the number of diffraction patterns ({tmp.diff3d.shape[0]})")
-
-    # Set random seed if provided
-    if seed is not None:
-        np.random.seed(seed)
-
-    # Randomly select K indices
-    indices = np.random.choice(tmp.diff3d.shape[0], K, replace=False)
-
-    for idx in indices:
-        fig, axes = plt.subplots(1, 3, figsize=figsize)
-        fig.suptitle(f"Group {idx}")
-
-        # Plot diffraction image (log scale for better visibility)
-        diff_img = axes[0].imshow(np.log1p(1 + 100 * tmp.diff3d[idx]), cmap='jet')
-        axes[0].set_title("Diffraction (log scale)")
-        plt.colorbar(diff_img, ax=axes[0])
-
-        # Plot Y amplitude
-        amp_img = axes[1].imshow(np.abs(tmp.Y[idx]), cmap='viridis')
-        axes[1].set_title("Y Amplitude")
-        plt.colorbar(amp_img, ax=axes[1])
-
-        # Plot Y phase
-        phase_img = axes[2].imshow(np.angle(tmp.Y[idx]), cmap='twilight')
-        axes[2].set_title("Y Phase")
-        plt.colorbar(phase_img, ax=axes[2])
-
-        # Remove axis ticks for cleaner look
-        for ax in axes:
-            ax.set_xticks([])
-            ax.set_yticks([])
-
-        plt.tight_layout()
-        plt.show()
-
-def compare_reconstructions(obj_tensor_full: np.ndarray, global_offsets: np.ndarray, ground_truth: np.ndarray, ptychonn_tensor: np.ndarray) -> None:
-    """
-    Compare the reconstructed object with the ground truth and PtychoNN prediction.
-
-    Args:
-        obj_tensor_full (np.ndarray): Full reconstructed object tensor.
-        global_offsets (np.ndarray): Global offsets for positioning.
-        ground_truth (np.ndarray): Ground truth object.
-        ptychonn_tensor (np.ndarray): PtychoNN predicted object tensor.
-    """
-    from ptycho import nbutils
-    irange = int(np.max(global_offsets[:, 0, 1, 0]) - np.min(global_offsets[:, 0, 1, 0]))
-    trimmed_ground_truth = hh.trim_reconstruction(ground_truth[None, ..., None], irange)[0, :, :, 0]
-    
-    nbutils.compare(obj_tensor_full, global_offsets, trimmed_ground_truth, ptychonn_tensor=ptychonn_tensor)
-
-# Add any additional helper functions or classes as needed
-
diff --git a/build/lib/ptycho/params.py b/build/lib/ptycho/params.py
deleted file mode 100644
index 5d74708..0000000
--- a/build/lib/ptycho/params.py
+++ /dev/null
@@ -1,67 +0,0 @@
-"""
-Stores global variables for data generation and model configuration
-"""
-# TODO naming convention for different types of parameters
-# TODO what default value and initialization for the probe scale?
-cfg = {
-    'N': 128, 'offset': 4, 'gridsize': 2,
-    'outer_offset_train': None, 'outer_offset_test': None, 'batch_size': 16,
-    'nepochs': 60, 'n_filters_scale': 2, 'output_prefix': 'outputs',
-    'big_gridsize': 10, 'max_position_jitter': 10, 'sim_jitter_scale': 0.,
-    'default_probe_scale': 0.7, 'mae_weight': 0., 'nll_weight': 1., 'tv_weight': 0.,
-    'realspace_mae_weight': 0., 'realspace_weight': 0., 'nphotons': 1e9,
-    'nimgs_train': 9, 'nimgs_test': 3,
-    'data_source': 'lines', 'probe.trainable': False,
-    'intensity_scale.trainable': False, 'positions.provided': False,
-    'object.big': True, 'probe.big': False, 'probe_scale': 10., 'set_phi': False,
-    'probe.mask': True, 'model_type': 'pinn', 'label': '', 'size': 392,
-    'amp_activation': 'sigmoid', 'h5_path': 'wts.h5', 'npseed': 42,
-    'debug': True
-    }
-
-# TODO parameter description
-# probe.big: if True, increase the real space solution from 32x32 to 64x64
-
-# TODO bigoffset should be a derived quantity, at least for simulation
-def get_bigN():
-    N = cfg['N']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return N + (gridsize - 1) * offset
-
-def get_padding_size():
-    buffer = cfg['max_position_jitter']
-    gridsize = cfg['gridsize']
-    offset = cfg['offset']
-    return (gridsize - 1) * offset + buffer
-
-def get_padded_size():
-    bigN = get_bigN()
-    buffer = cfg['max_position_jitter']
-    return bigN + buffer
-
-def params():
-    d = {k:v for k, v in cfg.items()}
-    d['bigN'] = get_bigN()
-    return d
-
-# TODO refactor
-def validate():
-    valid_data_sources = ['lines', 'grf', 'experimental', 'points',
-        'testimg', 'diagonals', 'xpp', 'V', 'generic']
-    assert cfg['data_source'] in valid_data_sources, \
-        f"Invalid data source: {cfg['data_source']}. Must be one of {valid_data_sources}."
-    if cfg['realspace_mae_weight'] > 0.:
-        assert cfg['realspace_weight'] > 0
-    return True
-
-def set(key, value):
-    print("DEBUG: Setting", key, "to", value, "in params")
-    cfg[key] = value
-    assert validate()
-
-def get(key):
-    if key == 'bigN':
-        cfg['bigN'] = get_bigN()
-        return cfg['bigN']
-    return cfg[key]
diff --git a/build/lib/ptycho/physics.py b/build/lib/ptycho/physics.py
deleted file mode 100644
index a19c0e5..0000000
--- a/build/lib/ptycho/physics.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from . import params as p
-from . import tf_helper as hh
-import tensorflow as tf
-import numpy as np
-import pdb
diff --git a/build/lib/ptycho/plotting.py b/build/lib/ptycho/plotting.py
deleted file mode 100644
index f6992c2..0000000
--- a/build/lib/ptycho/plotting.py
+++ /dev/null
@@ -1,37 +0,0 @@
-import matplotlib.pyplot as plt
-from ipywidgets import interactive
-
-def ishow_imgs(*arrs_list, styles = None, labels = None,
-              log = False, height = '550px',
-              nested_label_callback = None):
-    """
-    Plot a series of curves interactively.
-    """
-    plt.rcParams["figure.figsize"]=(12, 9)
-    #labels = [label1, label2]
-    if labels is None:
-        labels = [''] * len(arrs_list)
-    def f(i):
-        for j, patterns in enumerate(arrs_list):
-            if styles is not None:
-                extra_args = (styles[j],)
-            else:
-                extra_args = ()
-            try:
-                for k in range(len(patterns[i])):
-                    len(patterns[i][k]) # TODO hack
-                    if nested_label_callback is not None:
-                        label = nested_label_callback(patterns[i], k)
-                    else:
-                        label = k
-                    plt.imshow(patterns[i][k], *extra_args, label = label)
-            except: # TODO except what?
-                if j < 2:
-                    plt.imshow(patterns[i], label = labels[j])
-                else:
-                    plt.imshow(patterns[i], *extra_args)
-
-    interactive_plot = interactive(f, i=(0, len(arrs_list[0]) - 1), step = 1)
-    output = interactive_plot.children[-1]
-    output.layout.height = height
-    return interactive_plot
diff --git a/build/lib/ptycho/probe.py b/build/lib/ptycho/probe.py
deleted file mode 100644
index 8f10f1b..0000000
--- a/build/lib/ptycho/probe.py
+++ /dev/null
@@ -1,86 +0,0 @@
-import tensorflow as tf
-import numpy as np
-from . import fourier as f
-from . import params
-
-N = params.cfg['N']
-
-# most common value in testing is .7. Sometimes also .55 or .9
-default_probe_scale = params.cfg['default_probe_scale']
-
-filt = f.lowpass_g(default_probe_scale, np.ones(N), sym = True)
-
-def get_default_probe(fmt = 'tf'):
-    probe_np = f.gf(((np.einsum('i,j->ij', filt, filt)) > .5).astype(float), 1) + 1e-9
-    if fmt == 'np':
-        return probe_np
-    elif fmt == 'tf':
-        return (tf.convert_to_tensor(probe_np, tf.float32)[..., None])
-    else:
-        raise ValueError
-
-def get_probe(fmt = 'tf'):
-    probe_tf = params.get('probe')
-    assert len(probe_tf.shape) == 3
-    if fmt == 'np':
-        return np.array(probe_tf)[:, :, 0]
-    elif fmt == 'tf':
-        return probe_tf
-    else:
-        raise ValueError
-
-def to_np(probe):
-    assert len(probe.shape) == 3
-    return np.array(probe[:, :, 0])
-
-def get_squared_distance():
-    """
-    Return array of distances from the center
-    """
-    centered_indices = np.arange(N) - N // 2 + .5
-    x, y = np.meshgrid(centered_indices, centered_indices)
-    d = np.sqrt(x*x+y*y)
-    return d
-
-probe_mask_real = (get_squared_distance() < N // 4)[..., None]
-# TODO adaptive probe mask?
-def get_probe_mask():
-    probe_mask = tf.convert_to_tensor(probe_mask_real, tf.complex64)
-    return tf.convert_to_tensor(probe_mask, tf.complex64)[..., None]
-
-def set_probe(probe):
-    # TODO optimize this scaling
-    mask = tf.cast(get_probe_mask(), probe.dtype)
-    probe_scale = params.get('probe_scale')
-    tamped_probe = mask * probe
-    norm = float(probe_scale * tf.reduce_mean(tf.math.abs(tamped_probe)))
-    params.set('probe', probe / norm)
-
-def set_probe_guess(X_train, probe_guess = None):
-    if probe_guess is None:
-        mu = 0.
-        tmp = X_train.mean(axis = (0, 3))
-        probe_fif = np.absolute(f.fftshift(f.ifft2(f.ifftshift(tmp))))[N // 2, :]
-
-        # variance increments of a slice down the middle
-        d_second_moment = (probe_fif / probe_fif.sum()) * ((np.arange(N) - N // 2)**2)
-        probe_sigma_guess = np.sqrt(d_second_moment.sum())
-        probe_guess = np.exp(-( (get_squared_distance() - mu)**2 / ( 2.0 * probe_sigma_guess**2 )))[..., None]\
-            + 1e-9
-        probe_guess *= probe_mask_real
-        probe_guess *= (np.sum(get_default_probe()) / np.sum(probe_guess))
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.float32)
-    else:
-        probe_guess = probe_guess[..., None]
-        t_probe_guess = tf.convert_to_tensor(probe_guess, tf.complex64)
-
-    #params.set('probe', t_probe_guess)
-    set_probe(t_probe_guess)
-    return t_probe_guess
-
-# This should be more explicit
-params.set('probe_mask', get_probe_mask())
-
-# TODO this needs to be called
-def set_default_probe():
-    set_probe(get_default_probe())
diff --git a/build/lib/ptycho/raw_data.py b/build/lib/ptycho/raw_data.py
deleted file mode 100644
index 16131a2..0000000
--- a/build/lib/ptycho/raw_data.py
+++ /dev/null
@@ -1,474 +0,0 @@
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional
-from scipy.spatial import cKDTree
-from ptycho import params
-from ptycho.autotest.debug import debug
-from ptycho import diffsim as datasets
-from ptycho import tf_helper as hh
-
-# Constants, # TODO cleanup / refactor
-local_offset_sign = 1
-key_coords_offsets = 'coords_start_offsets'
-key_coords_relative = 'coords_start_relative'
-
-class RawData:
-    #@debug
-    def __init__(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess,
-             scan_index, objectGuess = None, Y = None, norm_Y_I = None):
-        # Sanity checks
-        self._check_data_validity(xcoords, ycoords, xcoords_start, ycoords_start, diff3d,
-                    probeGuess, scan_index)
-
-        # TODO these should go in the data validation method
-        assert len(xcoords.shape) == 1, f"Expected xcoords to be 1D, got shape {xcoords.shape}"
-        assert len(ycoords.shape) == 1, f"Expected ycoords to be 1D, got shape {ycoords.shape}"
-        assert len(xcoords_start.shape) == 1, f"Expected xcoords_start to be 1D, got shape {xcoords_start.shape}"
-        assert len(ycoords_start.shape) == 1, f"Expected ycoords_start to be 1D, got shape {ycoords_start.shape}"
-        if diff3d is not None:
-            assert len(diff3d.shape) == 3, f"Expected diff3d to be 3D, got shape {diff3d.shape}"
-            print(f"diff3d shape: {diff3d.shape}")
-            assert diff3d.shape[1] == diff3d.shape[2]
-        if probeGuess is not None:
-            assert len(probeGuess.shape) == 2, f"Expected probeGuess to be 2D, got shape {probeGuess.shape}"
-            print(f"probeGuess shape: {probeGuess.shape}")
-        if scan_index is not None:
-            assert len(scan_index.shape) == 1, f"Expected scan_index to be 1D, got shape {scan_index.shape}"
-            print(f"scan_index shape: {scan_index.shape}")
-        if objectGuess is not None:
-            print(f"objectGuess shape: {objectGuess.shape}")
-            assert len(objectGuess.shape) == 2
-
-        print(f"xcoords shape: {xcoords.shape}")
-        print(f"ycoords shape: {ycoords.shape}")
-        print(f"xcoords_start shape: {xcoords_start.shape}")
-        print(f"ycoords_start shape: {ycoords_start.shape}")
-
-        # Assigning values if checks pass
-        self.xcoords = xcoords
-        self.ycoords = ycoords
-        self.xcoords_start = xcoords_start
-        self.ycoords_start = ycoords_start
-        self.diff3d = diff3d
-        self.probeGuess = probeGuess
-        self.scan_index = scan_index
-        self.objectGuess = objectGuess
-        # TODO validity checks
-        self.Y = Y
-        self.norm_Y_I = norm_Y_I
-
-    @staticmethod
-    #@debug
-    def from_coords_without_pc(xcoords, ycoords, diff3d, probeGuess, scan_index,
-                               objectGuess=None):
-        """
-        Static method to create a RawData instance without separate start coordinates.
-        The start coordinates are set to be the same as the xcoords and ycoords.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-            objectGuess (np.ndarray, optional): initial guess of the object. Defaults to None.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        return RawData(xcoords, ycoords, xcoords, ycoords, diff3d, probeGuess, scan_index, objectGuess)
-
-    @staticmethod
-    def from_simulation(xcoords, ycoords, probeGuess,
-                 objectGuess, scan_index = None):
-        """
-        Create a RawData instance from simulation data.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            objectGuess (np.ndarray): initial guess of the object.
-            scan_index (np.ndarray, optional): array indicating the scan index for each diffraction pattern.
-
-        Returns:
-            RawData: An instance of the RawData class with simulated data.
-        """
-        from ptycho.diffsim import illuminate_and_diffract
-        xcoords_start = xcoords
-        ycoords_start = ycoords
-        global_offsets, local_offsets, nn_indices = calculate_relative_coords(
-                    xcoords, ycoords)
-
-        Y_obj = get_image_patches(objectGuess, global_offsets, local_offsets) 
-        Y_I = tf.math.abs(Y_obj)
-        Y_phi = tf.math.angle(Y_obj)
-        X, Y_I_xprobe, Y_phi_xprobe, intensity_scale = illuminate_and_diffract(Y_I, Y_phi, probeGuess)
-        norm_Y_I = datasets.scale_nphotons(X)
-        assert X.shape[-1] == 1, "gridsize must be set to one when simulating in this mode"
-        # TODO RawData should have a method for generating the illuminated ground truth object
-        return RawData(xcoords, ycoords, xcoords_start, ycoords_start, tf.squeeze(X).numpy(),
-                       probeGuess, scan_index, objectGuess,
-                       Y = tf.squeeze(hh.combine_complex( Y_I_xprobe, Y_phi_xprobe)).numpy(),
-                       norm_Y_I = norm_Y_I)
-
-    #@debug
-    def __str__(self):
-        parts = [
-            "RawData:",
-            f"  xcoords: {self.xcoords.shape if self.xcoords is not None else 'None'}",
-            f"  ycoords: {self.ycoords.shape if self.ycoords is not None else 'None'}",
-            f"  xcoords_start: {self.xcoords_start.shape if self.xcoords_start is not None else 'None'}",
-            f"  ycoords_start: {self.ycoords_start.shape if self.ycoords_start is not None else 'None'}",
-            f"  diff3d: {self.diff3d.shape if self.diff3d is not None else 'None'}",
-            f"  probeGuess: {self.probeGuess.shape if self.probeGuess is not None else 'None'}",
-            f"  scan_index: {self.scan_index.shape if self.scan_index is not None else 'None'}",
-            f"  objectGuess: {self.objectGuess.shape if self.objectGuess is not None else 'None'}"
-        ]
-        return "\n".join(parts)
-
-    #@debug
-    def to_file(self, file_path: str) -> None:
-        """
-        Method to write the RawData object to a file using numpy.savez.
-
-        Args:
-            file_path (str): Path to the file where the data will be saved.
-        """
-        np.savez(file_path,
-                 xcoords=self.xcoords,
-                 ycoords=self.ycoords,
-                 xcoords_start=self.xcoords_start,
-                 ycoords_start=self.ycoords_start,
-                 diff3d=self.diff3d,
-                 probeGuess=self.probeGuess,
-                 objectGuess=self.objectGuess,
-                 scan_index=self.scan_index)
-
-    @staticmethod
-    #@debug
-    def from_file(train_data_file_path: str) -> 'RawData':
-        """
-        Static method to create a RawData instance from a file.
-
-        Args:
-            train_data_file_path (str): Path to the file containing the data.
-
-        Returns:
-            RawData: An instance of the RawData class.
-        """
-        # Load training data
-        train_data = np.load(train_data_file_path)
-        train_raw_data = RawData(
-            xcoords=train_data['xcoords'],
-            ycoords=train_data['ycoords'],
-            xcoords_start=train_data['xcoords_start'],
-            ycoords_start=train_data['ycoords_start'],
-            diff3d=train_data['diff3d'],
-            probeGuess=train_data['probeGuess'],
-            objectGuess=train_data['objectGuess'],
-            scan_index=train_data['scan_index']
-        )
-        return train_raw_data
-
-    @staticmethod
-    #@debug
-    def from_files(train_data_file_path, test_data_file_path):
-        """
-        Static method to instantiate RawData objects from training and test data files.
-
-        The data files should be NumPy .npz files with the following keys:
-        - 'xcoords': x coordinates of the scan points
-        - 'ycoords': y coordinates of the scan points
-        - 'xcoords_start': starting x coordinates for the scan
-        - 'ycoords_start': starting y coordinates for the scan
-        - 'diff3d': diffraction patterns
-        - 'probeGuess': initial guess of the probe function
-        - 'scan_index': array indicating the scan index for each diffraction pattern
-
-        Args:
-            train_data_file_path (str): Path to the training data file.
-            test_data_file_path (str): Path to the test data file.
-
-        Returns:
-            tuple: A tuple containing the instantiated RawData objects for training and test data.
-        """
-        # Load training data
-        train_raw_data = RawData.from_file(train_data_file_path)
-
-        # Load test data
-        test_raw_data = RawData.from_file(test_data_file_path)
-
-        return train_raw_data, test_raw_data
-
-    #@debug
-    def generate_grouped_data(self, N, K = 7, nsamples = 1):
-        """
-        Generate nearest-neighbor solution region grouping.
-
-        Args:
-            N (int): Size of the solution region.
-            K (int, optional): Number of nearest neighbors. Defaults to 7.
-            nsamples (int, optional): Number of samples. Defaults to 1.
-
-        Returns:
-            dict: Dictionary containing grouped data.
-        """
-        print('DEBUG:', 'nsamples:', nsamples)
-        return get_neighbor_diffraction_and_positions(self, N, K=K, nsamples=nsamples)
-
-    #@debug
-    def _check_data_validity(self, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-        """
-        Check if the input data is valid.
-
-        Args:
-            xcoords (np.ndarray): x coordinates of the scan points.
-            ycoords (np.ndarray): y coordinates of the scan points.
-            xcoords_start (np.ndarray): starting x coordinates for the scan.
-            ycoords_start (np.ndarray): starting y coordinates for the scan.
-            diff3d (np.ndarray): diffraction patterns.
-            probeGuess (np.ndarray): initial guess of the probe function.
-            scan_index (np.ndarray): array indicating the scan index for each diffraction pattern.
-
-        Raises:
-            ValueError: If coordinate arrays don't have matching shapes.
-        """
-        # Check if coordinate arrays have matching shapes
-        if not (xcoords.shape == ycoords.shape == xcoords_start.shape == ycoords_start.shape):
-            raise ValueError("Coordinate arrays must have matching shapes.")
-
-#@debug
-def calculate_relative_coords(xcoords, ycoords, K = 6, C = None, nsamples = 10):
-    """
-    Group scan indices and coordinates into solution regions, then
-    calculate coords_offsets (global solution region coordinates) and
-    coords_relative (local solution patch coords) from ptycho_data using
-    the provided index_grouping_cb callback function.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        tuple: A tuple containing coords_offsets, coords_relative, and nn_indices.
-    """
-    nn_indices, coords_nn = group_coords(xcoords, ycoords, K = K, C = C, nsamples = nsamples)
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-    return coords_offsets, coords_relative, nn_indices
-
-#@debug
-def get_image_patches(gt_image, global_offsets, local_offsets):
-    """
-    Generate and return image patches in channel format using a single canvas.
-
-    Args:
-        gt_image (tensor): Ground truth image tensor.
-        global_offsets (tensor): Global offset tensor.
-        local_offsets (tensor): Local offset tensor.
-
-    Returns:
-        tensor: Image patches in channel format.
-    """
-    # Get necessary parameters
-    gridsize = params.get('gridsize')
-    N = params.get('N')
-    B = global_offsets.shape[0]
-    c = gridsize**2
-
-    # Pad the ground truth image once
-    gt_padded = hh.pad(gt_image[None, ..., None], N // 2)
-
-    # Calculate the combined offsets by adding global and local offsets
-    offsets_c = tf.cast((global_offsets + local_offsets), tf.float32)
-    offsets_f = hh._channel_to_flat(offsets_c)
-
-    # Create a canvas to store the extracted patches
-    canvas = np.zeros((B, N, N, c))
-
-    # Iterate over the combined offsets and extract patches one by one
-    for i in range(B * c):
-        offset = -offsets_f[i, :, :, 0]
-        translated_patch = hh.translate(gt_padded, offset)
-        canvas[i // c, :, :, i % c] = np.array(translated_patch)[0, :N, :N, 0]
-
-    # Convert the canvas to a TensorFlow tensor and return it
-    return tf.convert_to_tensor(canvas)
-
-#@debug
-def group_coords(xcoords: np.ndarray, ycoords: np.ndarray, K: int, C: Optional[int], nsamples: int) -> Tuple[np.ndarray, np.ndarray]:
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int): Number of nearest neighbors to consider.
-        C (Optional[int]): Number of coordinates per solution region. If None, uses gridsize^2.
-        nsamples (int): Number of samples to generate.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray]: A tuple containing:
-            - nn_indices: shape (M, C)
-            - coords_nn: shape (M, 1, 2, C)
-    """
-    gridsize = params.get('gridsize')
-    if C is None:
-        C = gridsize**2
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords, ycoords)
-    else:
-        nn_indices = get_neighbor_indices(xcoords, ycoords, K=K)
-        nn_indices = sample_rows(nn_indices, C, nsamples).reshape(-1, C)
-
-    coords_nn = np.transpose(np.array([xcoords[nn_indices],
-                            ycoords[nn_indices]]),
-                            [1, 0, 2])[:, None, :, :]
-    return nn_indices, coords_nn[:, :, :, :]
-
-#@debug
-def get_relative_coords(coords_nn):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, 1, 2, C).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-    """
-    assert len(coords_nn.shape) == 4
-    coords_offsets = np.mean(coords_nn, axis=3)[..., None]
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-    return coords_offsets, coords_relative
-
-#@debug
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    Assign each pattern index to itself.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-
-    Returns:
-        np.ndarray: Array of self-indices.
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-#@debug
-def get_neighbor_indices(xcoords, ycoords, K = 3):
-    """
-    Get K nearest neighbor indices for each point.
-
-    Args:
-        xcoords (np.ndarray): x coordinates of the scan points.
-        ycoords (np.ndarray): y coordinates of the scan points.
-        K (int, optional): Number of nearest neighbors to find. Defaults to 3.
-
-    Returns:
-        np.ndarray: Array of nearest neighbor indices.
-    """
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-#@debug
-def sample_rows(indices, n, m):
-    """
-    Sample rows from the given indices.
-
-    Args:
-        indices (np.ndarray): Array of indices to sample from.
-        n (int): Number of samples per row.
-        m (int): Number of rows to generate.
-
-    Returns:
-        np.ndarray: Sampled indices array.
-    """
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-#@debug
-def get_neighbor_diffraction_and_positions(ptycho_data, N, K=6, C=None, nsamples=10):
-    """
-    Get neighbor diffraction patterns and positions.
-
-    Args:
-        ptycho_data (RawData): An instance of the RawData class.
-        N (int): Size of the solution region.
-        K (int, optional): Number of nearest neighbors. Defaults to 6.
-        C (int, optional): Number of coordinates per solution region. Defaults to None.
-        nsamples (int, optional): Number of samples. Defaults to 10.
-
-    Returns:
-        dict: A dictionary containing grouped data and metadata.
-    """
-    nn_indices, coords_nn = group_coords(ptycho_data.xcoords, ptycho_data.ycoords,
-                                         K = K, C = C, nsamples = nsamples)
-
-    diff4d_nn = np.transpose(ptycho_data.diff3d[nn_indices], [0, 2, 3, 1])
-    if ptycho_data.Y is not None:
-        Y4d_nn = np.transpose(ptycho_data.Y[nn_indices], [0, 2, 3, 1])
-    else:
-        Y4d_nn = None
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if ptycho_data.xcoords_start is not None:
-        coords_start_nn = np.transpose(np.array([ptycho_data.xcoords_start[nn_indices], ptycho_data.ycoords_start[nn_indices]]),
-                                       [1, 0, 2])[:, None, :, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'Y': Y4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-#@debug
-def normalize_data(dset: dict, N: int) -> np.ndarray:
-    """
-    Normalize the diffraction data.
-
-    Args:
-        dset (dict): Dictionary containing the dataset.
-        N (int): Size of the solution region.
-
-    Returns:
-        np.ndarray: Normalized diffraction data.
-    """
-    # Images are amplitude, not intensity
-    X_full = dset['diffraction']
-    X_full_norm = np.sqrt(
-            ((N / 2)**2) / np.mean(tf.reduce_sum(dset['diffraction']**2, axis=[1, 2]))
-            )
-    return X_full_norm * X_full
-
diff --git a/build/lib/ptycho/test_memoize_simulated_data.py b/build/lib/ptycho/test_memoize_simulated_data.py
deleted file mode 100644
index e283054..0000000
--- a/build/lib/ptycho/test_memoize_simulated_data.py
+++ /dev/null
@@ -1,51 +0,0 @@
-import numpy as np
-from ptycho.nongrid_simulation import generate_simulated_data
-from ptycho.loader import RawData
-import os
-import shutil
-
-def test_memoize_simulated_data():
-    # Create sample input data
-    objectGuess = np.random.rand(128, 128) + 1j * np.random.rand(128, 128)
-    probeGuess = np.random.rand(32, 32) + 1j * np.random.rand(32, 32)
-    nimages = 100
-    buffer = 10
-    random_seed = 42
-
-    # Clear the cache directory before starting the test
-    cache_dir = 'memoized_simulated_data'
-    if os.path.exists(cache_dir):
-        shutil.rmtree(cache_dir)
-
-    # First call, should compute the result and cache it
-    result1 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result1, tuple), "Result should be a tuple"
-    assert len(result1) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result1[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result1[1], np.ndarray), "Second element should be a numpy array"
-
-    # Second call, should load the result from the cache
-    result2 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed)
-    assert isinstance(result2, tuple), "Result should be a tuple"
-    assert len(result2) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result2[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result2[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are identical
-    assert np.array_equal(result1[0].diff3d, result2[0].diff3d), "Cached result differs from original"
-    assert np.array_equal(result1[1], result2[1]), "Cached patches differ from original"
-
-    # Third call with different random seed, should compute a new result
-    result3 = generate_simulated_data(objectGuess, probeGuess, nimages, buffer, random_seed=123)
-    assert isinstance(result3, tuple), "Result should be a tuple"
-    assert len(result3) == 2, "Result tuple should have 2 elements"
-    assert isinstance(result3[0], RawData), "First element should be a RawData instance"
-    assert isinstance(result3[1], np.ndarray), "Second element should be a numpy array"
-
-    # Check if results are different
-    assert not np.array_equal(result1[0].diff3d, result3[0].diff3d), "Results with different seeds should differ"
-
-    print("All tests passed successfully!")
-
-if __name__ == "__main__":
-    test_memoize_simulated_data()
diff --git a/build/lib/ptycho/tests/test_model_manager.py b/build/lib/ptycho/tests/test_model_manager.py
deleted file mode 100644
index e56140a..0000000
--- a/build/lib/ptycho/tests/test_model_manager.py
+++ /dev/null
@@ -1,35 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from tensorflow.keras.models import Sequential
-from tensorflow.keras.layers import Dense
-from ptycho.model_manager import ModelManager
-
-def test_save_and_load_model():
-    # Create a simple model for testing
-    model = Sequential([
-        Dense(64, activation='relu', input_shape=(32,)),
-        Dense(10, activation='softmax')
-    ])
-    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
-
-    # Define custom objects and intensity scale for testing
-    custom_objects = {'custom_activation': tf.nn.relu}
-    intensity_scale = 2.5
-
-    # Save the model
-    model_path = 'test_model.h5'
-    ModelManager.save_model(model, model_path, custom_objects, intensity_scale)
-
-    # Ensure the .dill file is created
-    assert os.path.exists(model_path + ".dill")
-
-    # Load the model
-    loaded_model = ModelManager.load_model(model_path)
-
-    # Check if the loaded model has the same architecture
-    assert np.array_equal(model.get_weights()[0], loaded_model.get_weights()[0])
-
-    # Clean up
-    os.remove(model_path)
-    os.remove(model_path + ".dill")
diff --git a/build/lib/ptycho/tf_helper.py b/build/lib/ptycho/tf_helper.py
deleted file mode 100644
index 3f35e76..0000000
--- a/build/lib/ptycho/tf_helper.py
+++ /dev/null
@@ -1,669 +0,0 @@
-import os
-import numpy as np
-import tensorflow as tf
-from typing import Tuple, Optional, Union, Callable, Any
-from .function_logger import log_function_call
-
-# Check if there are any GPUs available and set memory growth accordingly
-physical_devices = tf.config.list_physical_devices('GPU')
-if physical_devices:
-    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'
-    tf.config.experimental.set_memory_growth(physical_devices[0], True)
-else:
-    print("No GPU found, using CPU instead.")
-
-
-import tensorflow.compat.v2 as tf
-tf.enable_v2_behavior()
-
-from tensorflow.keras import Model
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, UpSampling2D
-from tensorflow.keras.layers import Lambda
-from tensorflow.signal import fft2d, fftshift
-import tensorflow_probability as tfp
-
-from .params import params, cfg, get, get_padded_size
-#from .logging import debug
-from .autotest.debug import debug
-
-tfk = tf.keras
-tfkl = tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-support_threshold = .0
-@debug
-def get_mask(input: tf.Tensor, support_threshold: float) -> tf.Tensor:
-    mask = tf.where(input > support_threshold, tf.ones_like(input),
-                    tf.zeros_like(input))
-    return mask
-
-@debug
-def combine_complex(amp: tf.Tensor, phi: tf.Tensor) -> tf.Tensor:
-    output = tf.cast(amp, tf.complex64) * tf.exp(
-        1j * tf.cast(phi, tf.complex64))
-    return output
-
-@debug
-def pad_obj(input: tf.Tensor, h: int, w: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((h // 4, w // 4), name = 'padded_obj')(input)
-
-@debug
-def pad_and_diffract(input: tf.Tensor, h: int, w: int, pad: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses sysmmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = (((fft2d(
-        (tf.cast((input), tf.complex64))[..., 0]
-        ))))
-    input = (( tf.math.real(tf.math.conj((input)) * input) / (h * w)))
-    input = (( tf.expand_dims(
-                              tf.math.sqrt(
-            fftshift(input, (-2, -1))), 3)
-        ))
-    return padded, input
-
-@debug
-def _fromgrid(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return tf.reshape(img, (-1, N, N, 1))
-
-@debug
-def _togrid(img: tf.Tensor, gridsize: Optional[int] = None, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e. from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return tf.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-@debug
-def togrid(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return [_togrid(img) for img in imgs]
-
-@debug
-def _grid_to_channel(grid: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = tf.transpose(grid, [0, 3, 4, 1, 2, 5], conjugate=False)
-    _, ww, hh = img.shape[:3]
-    img = tf.reshape(img, (-1, ww, hh, gridsize**2))
-    return img
-
-@debug
-def grid_to_channel(*grids: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_grid_to_channel(g) for g in grids]
-
-@debug
-def _flat_to_channel(img: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = tf.reshape(img, (-1, gridsize**2, N, N))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-@debug
-def _flat_to_channel_2(img: tf.Tensor) -> tf.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = tf.reshape(img, (-1, gridsize**2, N, M))
-    img = tf.transpose(img, [0, 2, 3, 1], conjugate=False)
-    return img
-
-@debug
-def _channel_to_flat(img: tf.Tensor) -> tf.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = tf.transpose(img, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, h, w, 1))
-    return img
-
-@debug
-def _channel_to_patches(channel: tf.Tensor) -> tf.Tensor:
-    """
-    reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = tf.transpose(channel, [0, 3, 1, 2], conjugate=False)
-    img = tf.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-@debug
-def channel_to_flat(*imgs: tf.Tensor) -> Tuple[tf.Tensor, ...]:
-    return [_channel_to_flat(g) for g in imgs]
-
-@debug
-def extract_patches(x: tf.Tensor, N: int, offset: int) -> tf.Tensor:
-    return tf.image.extract_patches(
-        x,
-        [1, N, N, 1],
-        [1, offset,offset, 1],
-        [1, 1, 1, 1],
-        padding="VALID"
-    )
-
-@debug
-def extract_outer(img: tf.Tensor, fmt: str = 'grid',
-        bigN: Optional[int] = None, outer_offset: Optional[int] = None) -> tf.Tensor:#,
-    """
-        Extract big patches (overlapping bigN x bigN regions over an
-        entire input img)
-    """
-    if bigN is None:
-        bigN = get('bigN')
-    assert img.shape[-1] == 1
-    grid = tf.reshape(
-        extract_patches(img, bigN, outer_offset // 2),
-        (-1, bigN, bigN, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)
-    else:
-        raise ValueError
-
-@debug
-def extract_inner_grid(grid: tf.Tensor) -> tf.Tensor:
-    N = cfg['N']
-    offset = params()['offset']
-    return extract_patches(grid, N, offset)
-
-@debug
-def extract_nested_patches(img: tf.Tensor, fmt: str = 'flat',
-        extract_inner_fn: Callable[[tf.Tensor], tf.Tensor] = extract_inner_grid,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-
-    This function and extract_outer are only used to extract nominal
-    coordinates, so it is not necessary for them to use jitter padding
-    """
-    N = cfg['N']
-    offset = params()['offset']
-    gridsize = params()['gridsize']
-    assert img.shape[-1] == 1
-    outer_grid = extract_outer(img, fmt = 'grid', **kwargs)
-    grid = tf.reshape(
-        extract_inner_fn(outer_grid),
-        (-1, gridsize, gridsize, N, N, 1))
-    if fmt == 'flat':
-        return _fromgrid(grid)
-    elif fmt == 'grid':
-        return grid
-    elif fmt == 'channel':
-        return _grid_to_channel(grid)#, 
-    else:
-        raise ValueError
-
-@debug
-def mk_extract_inner_position(offsets_xy: tf.Tensor) -> Callable[[tf.Tensor], Tuple[tf.Tensor]]:
-    @debug
-    def inner(grid: tf.Tensor) -> Tuple[tf.Tensor]:
-        return extract_patches_position(grid, offsets_xy),
-    return inner
-
-@debug
-def extract_nested_patches_position(img: tf.Tensor, offsets_xy: tf.Tensor, fmt: str = 'flat',
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Extract small patches (overlapping N x N regions on a gridsize x gridsize
-        grid) within big patches (overlapping bigN x bigN regions over the
-        entire input img)
-
-    fmt == 'channel': patches within a solution region go in the channel dimension
-    fmt == 'flat': patches within a solution go in the batch dimension; size of output
-        channel dimension is 1
-    fmt == 'grid': ...
-    """
-    return extract_nested_patches(img, fmt = fmt,
-        extract_inner_fn = mk_extract_inner_position(offsets_xy),
-        **kwargs)
-
-@tf.function
-@debug
-def extract_patches_inverse(y: tf.Tensor, N: int, average: bool, gridsize: Optional[int] = None, offset: Optional[int] = None) -> tf.Tensor:
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if offset is None:
-        offset = params()['offset']
-    target_size = N + (gridsize - 1) * offset
-    b = tf.shape(y)[0]
-
-    _x = tf.zeros((b, target_size, target_size, 1), dtype = y.dtype)
-    _y = extract_patches(_x, N, offset)
-    if average:
-        grad = tf.gradients(_y, _x)[0]
-        return tf.gradients(_y, _x, grad_ys=y)[0] / grad
-    else:
-        return tf.gradients(_y, _x, grad_ys=y)[0]
-
-@debug
-def reassemble_patches_real(channels: tf.Tensor, average: bool = True, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = _channel_to_patches(channels)
-    N = params()['N']
-    return extract_patches_inverse(real, N, average, **kwargs)
-
-@debug
-def pad_patches(imgs: tf.Tensor, padded_size: Optional[int] = None) -> tf.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    return tfkl.ZeroPadding2D(((padded_size - N) // 2, (padded_size - N) // 2))(imgs)
-
-@debug
-def pad(imgs: tf.Tensor, size: int) -> tf.Tensor:
-    return tfkl.ZeroPadding2D((size, size))(imgs)
-
-@debug
-def trim_reconstruction(x: tf.Tensor, N: Optional[int] = None) -> tf.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert int(shape[1]) == int(shape[2])
-    try:
-        clipsize = (int(shape[1]) - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize: -clipsize,
-            clipsize: -clipsize, :]
-
-@debug
-def extract_patches_position(imgs: tf.Tensor, offsets_xy: tf.Tensor, jitter: float = 0.) -> tf.Tensor:
-    """
-    Expects offsets_xy in channel format.
-
-    imgs must be in flat format with a single image per solution region, i.e.
-    (batch size, M, M, 1) where M = N + some padding size.
-
-    Returns shifted images in channel format, cropped symmetrically
-
-    no negative sign
-    """
-    if  imgs.get_shape()[0] is not None:
-        assert int(imgs.get_shape()[0]) == int(offsets_xy.get_shape()[0])
-    assert int(imgs.get_shape()[3]) == 1
-    assert int(offsets_xy.get_shape()[2]) == 2
-    assert int(imgs.get_shape()[3]) == 1
-    gridsize = params()['gridsize']
-    assert int(offsets_xy.get_shape()[3]) == gridsize**2
-    offsets_flat = flatten_offsets(offsets_xy)
-    stacked = tf.repeat(imgs, gridsize**2, axis = 3)
-    flat_padded = _channel_to_flat(stacked)
-    channels_translated = trim_reconstruction(
-        Translation()([flat_padded, offsets_flat, jitter]))
-    return channels_translated
-
-@debug
-def center_channels(channels: tf.Tensor, offsets_xy: tf.Tensor) -> tf.Tensor:
-    """
-    Undo image patch offsets
-    """
-    ct = Translation()([_channel_to_flat(channels), flatten_offsets(-offsets_xy), 0.])
-    channels_centered = _flat_to_channel(ct)
-    return channels_centered
-
-@debug
-def is_complex_tensor(tensor: tf.Tensor) -> bool:
-    """Check if the tensor is of complex dtype."""
-    return tensor.dtype in [tf.complex64, tf.complex128]
-
-@debug
-def complexify_helper(separate: Callable[[tf.Tensor], Tuple[tf.Tensor, tf.Tensor]], combine: Callable[[tf.Tensor, tf.Tensor], tf.Tensor]) -> Callable:
-    """
-    Create a "complexify" function based on the provided separation and combination methods.
-    """
-    @debug
-    def complexify(fn: Callable[..., tf.Tensor]) -> Callable[..., tf.Tensor]:
-        @debug
-        def newf(*args: Any, **kwargs: Any) -> tf.Tensor:
-            channels = args[0]
-            if is_complex_tensor(channels):
-                part1, part2 = separate(channels)
-                assembled_part1 = fn(part1, *args[1:], **kwargs)
-                assembled_part2 = fn(part2, *args[1:], **kwargs)
-                return combine(assembled_part1, assembled_part2)
-            else:
-                return fn(*args, **kwargs)
-        return newf
-    return complexify
-
-@debug
-def separate_real_imag(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.real(channels), tf.math.imag(channels)
-
-@debug
-def combine_real_imag(real: Union[tf.Tensor, np.ndarray], imag: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:
-    return tf.cast(tf.dtypes.complex(real, imag), tf.complex64)
-
-@debug
-def separate_amp_phase(channels: Union[tf.Tensor, np.ndarray]) -> Tuple[Union[tf.Tensor, np.ndarray], Union[tf.Tensor, np.ndarray]]:
-    return tf.math.abs(channels), tf.math.angle(channels)
-
-complexify_function = complexify_helper(separate_real_imag, combine_real_imag)
-complexify_amp_phase = complexify_helper(separate_amp_phase, combine_complex)
-complexify_sum_amp_phase = complexify_helper(separate_amp_phase, lambda a, b: a + b)
-complexify_sum_real_imag = complexify_helper(separate_real_imag, lambda a, b: a + b)
-
-
-from tensorflow_addons.image import translate as _translate
-
-#from ptycho.misc import debug
-@complexify_function
-@debug
-def translate(imgs: tf.Tensor, offsets: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    # TODO assert dimensionality of translations is 2; i.e. B, 2
-    return _translate(imgs, offsets, **kwargs)
-
-# TODO consolidate this and translate()
-class Translation(tf.keras.layers.Layer):
-    def __init__(self) -> None:
-        super(Translation, self).__init__()
-    def call(self, inputs: Tuple[tf.Tensor, tf.Tensor, float]) -> tf.Tensor:
-        imgs, offsets, jitter = inputs
-        jitter = tf.random.normal(tf.shape(offsets), stddev = jitter)
-        return translate(imgs, offsets + jitter, interpolation = 'bilinear')
-
-@debug
-def flatten_offsets(channels: tf.Tensor) -> tf.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-@debug
-def pad_reconstruction(channels: tf.Tensor) -> tf.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-@debug
-def _reassemble_patches_position_real(imgs: tf.Tensor, offsets_xy: tf.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> tf.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, 0.])
-    if agg:
-        imgs_merged = tf.reduce_sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N = padded_size),
-                    axis = 3)[..., None]
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N = padded_size)
-
-gridsize = params()['gridsize']
-N = params()['N']
-
-@debug
-def mk_centermask(inputs: tf.Tensor, N: int, c: int, kind: str = 'center') -> tf.Tensor:
-    b = tf.shape(inputs)[0]
-    ones = tf.ones((b, N // 2, N // 2, c), dtype = inputs.dtype)
-    ones =   tfkl.ZeroPadding2D((N // 4, N // 4))(ones)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-@debug
-def mk_norm(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor]) -> tf.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average = False)
-    norm = assembled_ones + .001
-    return norm
-
-@debug
-def reassemble_patches(channels: tf.Tensor, fn_reassemble_real: Callable[[tf.Tensor], tf.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> tf.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = tf.math.real(channels)
-    imag = tf.math.imag(channels)
-    assembled_real = fn_reassemble_real(real, average = average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average = average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return tf.dtypes.complex(assembled_real, assembled_imag)
-
-@debug
-def reassemble_whole_object(patches: tf.Tensor, offsets: tf.Tensor, size: int = 226, norm: bool = False) -> tf.Tensor:
-    """
-    patches: tensor of shape (B, N, N, gridsize**2) containing reconstruction patches
-
-    reassembles the NxN patches into a single size x size x 1 mage, given the
-        provided offsets
-
-    This function inverts the offsets, so it's not necessary to multiply by -1
-    """
-    img = tf.reduce_sum(
-        reassemble_patches(patches, fn_reassemble_real=mk_reassemble_position_real(
-        offsets, padded_size = size)),
-        axis = 0)
-    if norm:
-        return img / reassemble_whole_object(tf.ones_like(patches), offsets, size = size, norm = False)
-    return img
-
-@debug
-def mk_reassemble_position_real(input_positions: tf.Tensor, **outer_kwargs: Any) -> Callable[[tf.Tensor], tf.Tensor]:
-    @debug
-    def reassemble_patches_position_real(imgs: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-@debug
-def preprocess_objects(Y_I: np.ndarray, Y_phi: Optional[np.ndarray] = None,
-        offsets_xy: Optional[tf.Tensor] = None, **kwargs: Any) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
-    """
-    Extracts normalized object patches from full real-space images, using the
-    nested grid format.
-    """
-    _Y_I_full = Y_I
-    if Y_phi is None:
-        Y_phi = np.zeros_like(Y_I)
-
-    if offsets_xy is None or tf.math.reduce_all(offsets_xy == 0):
-        print('Sampling on regular grid')
-        Y_I, Y_phi = \
-            [extract_nested_patches(imgs, fmt= 'channel', **kwargs)
-                for imgs in [Y_I, Y_phi]]
-    else:
-        print('Using provided scan point offsets')
-        Y_I, Y_phi = \
-            [extract_nested_patches_position(imgs, offsets_xy, fmt= 'channel',
-                    **kwargs)
-                for imgs in [Y_I, Y_phi]]
-
-    assert Y_I.shape[-1] == get('gridsize')**2
-    norm_Y_I = tf.math.reduce_max(Y_I, axis = (1, 2, 3))[:, None, None, None]
-    norm_Y_I = tf.math.reduce_mean(norm_Y_I)
-    Y_I /= norm_Y_I
-
-    Y_I, Y_phi =\
-        channel_to_flat(Y_I, Y_phi)
-    return Y_I, Y_phi, _Y_I_full / norm_Y_I, norm_Y_I
-
-@debug
-def reassemble_nested_average(output_tensor: tf.Tensor, cropN: Optional[int] = None, M: Optional[int] = None, n_imgs: int = 1,
-        offset: int = 4) -> tf.Tensor:
-    """
-    Stitch reconstruction patches from (first) model output into full
-    reconstructed images, averaging the overlaps
-    """
-    assert len(output_tensor.shape) == 4
-    bsize = int(output_tensor.shape[0] / n_imgs)
-    output_tensor = output_tensor[:bsize, ...]
-    if M is None:
-        M = int(np.sqrt(bsize))
-    if cropN is None:
-        cropN = params.params()['cropN']
-    patches = _togrid(trim_reconstruction(output_tensor, cropN), gridsize = M,
-        N = cropN)
-    patches = tf.reshape(patches, (-1, M, M, cropN**2))
-    obj_recon = complexify_function(extract_patches_inverse)(patches, cropN,
-        True, gridsize = M, offset = offset)
-    return obj_recon
-
-
-@debug
-def gram_matrix(input_tensor: tf.Tensor) -> tf.Tensor:
-    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
-    input_shape = tf.shape(input_tensor)
-    num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
-    return result/(num_locations)
-
-@debug
-def high_pass_x_y(image: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
-    x_var = image[:,:,1:,:] - image[:,:,:-1,:]
-    y_var = image[:,1:,:,:] - image[:,:-1,:,:]
-    return x_var, y_var
-
-pp = tfk.Sequential([
-    Lambda(lambda x: tf.image.grayscale_to_rgb(x)),
-])
-@debug
-def perceptual_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    """
-    target = pp(target)
-    pred = pp(pred)
-
-    vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-    vgg.trainable = False
-
-    outputs = [vgg.get_layer('block2_conv2').output]
-    feat_model = Model(vgg.input, outputs)
-    activatedModelVal = feat_model(pred)
-    actualModelVal = feat_model(target)
-    return meanSquaredLoss(gram_matrix(actualModelVal),gram_matrix(activatedModelVal))
-
-@debug
-def meanSquaredLoss(y_true: tf.Tensor, y_pred: tf.Tensor, center_target: bool = True) -> tf.Tensor:
-    return tf.reduce_mean(tf.keras.losses.MSE(y_true,y_pred))
-
-@debug
-def masked_MAE_loss(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    """
-    bigN
-    """
-    mae = tf.keras.metrics.mean_absolute_error
-    mask = params()['probe_mask']
-    pred = trim_reconstruction(
-            reassemble_patches(mask * pred))
-    target = trim_reconstruction(
-            reassemble_patches(tf.math.abs(mask) * target))
-    return mae(target, pred)
-
-
-@complexify_sum_real_imag
-@debug
-def total_variation_complex(obj: tf.Tensor) -> tf.Tensor:
-    """ calculate summed total variation of the real and imaginary components
-        of a tensor
-    """
-    x_deltas, y_deltas = high_pass_x_y(obj)
-    return tf.reduce_sum(x_deltas**2) + tf.reduce_sum(y_deltas**2)
-
-@debug
-def total_variation(obj: tf.Tensor, amp_only: bool = False) -> tf.Tensor:
-    if amp_only:
-        obj = Lambda(lambda x: tf.math.abs(x))(obj)
-    return total_variation_complex(obj)
-
-@complexify_sum_amp_phase
-@debug
-def complex_mae(target: tf.Tensor, pred: tf.Tensor) -> tf.Tensor:
-    mae = tf.keras.metrics.mean_absolute_error
-    return mae(target, pred)
-
-@debug
-def masked_mae(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    mae = tf.keras.metrics.mean_absolute_error
-    pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-    return mae(target, pred)
-
-@debug
-def realspace_loss(target: tf.Tensor, pred: tf.Tensor, **kwargs: Any) -> tf.Tensor:
-    if not get('probe.big'):
-        pred = pred * mk_centermask(pred, N, 1, kind = 'center')
-
-    if get('tv_weight') > 0:
-        tv_loss = total_variation(pred) * get('tv_weight')
-    else:
-        tv_loss = 0.
-
-    if get('realspace_mae_weight') > 0:
-        mae_loss = complex_mae(target, pred) * get('realspace_mae_weight')
-    else:
-        mae_loss = 0.
-    return tv_loss + mae_loss
-
-
-#Code below is for function logging every call in tf_helper
-
-# TODO  should consolidate the logging method. right now we're doing it twice
-import sys
-from types import FunctionType
-#Import current module
-current_module = sys.modules[__name__]
-for name, func in list(vars(current_module).items()):
-    if isinstance(func, FunctionType): #Note: callable(func) doesn't work b/c classes are callable. Swapped to this method instead for functions only
-        setattr(current_module, name, log_function_call(func))
diff --git a/build/lib/ptycho/train.py b/build/lib/ptycho/train.py
deleted file mode 100644
index 8a0ec99..0000000
--- a/build/lib/ptycho/train.py
+++ /dev/null
@@ -1,148 +0,0 @@
-import os
-from ptycho.model_manager import ModelManager
-from ptycho.export import save_recons
-from datetime import datetime
-import matplotlib
-import matplotlib.pyplot as plt
-import dill
-import argparse
-from ptycho import params
-from ptycho import misc
-import numpy as np
-import h5py
-
-plt.rcParams["figure.figsize"] = (10, 10)
-matplotlib.rcParams['font.size'] = 12
-
-save_model = True
-save_data = False
-
-parser = argparse.ArgumentParser(description='Script to set attributes for ptycho program')
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(
-                        prog = 'PtychoPINN',
-                        description = 'Generate / load data and train the model',
-                        )
-    parser.add_argument('--model_type', type=str, default='pinn', help='model type (pinn or supervised)')
-    parser.add_argument('--output_prefix', type=str, default='lines2', help='output directory prefix')
-    parser.add_argument('--data_source', type=str, default='lines', help='Dataset specification')
-    parser.add_argument('--set_phi', action='store_true', default=False, help='If true, simulated objects are given non-zero phase')
-    parser.add_argument('--nepochs', type=int, default=60, help='Number of epochs')
-    parser.add_argument('--offset', type=int, default=4, help='Scan point spacing for simulated (grid-sampled) data')
-    parser.add_argument('--gridsize', type=int, default=2, help='Solution region grid size (e.g. 2 -> 2x2, etc.)')
-    parser.add_argument('--object_big', type=bool, default=True, help='If true, reconstruct the entire solution region for each set of patterns, instead of just the central N x N region.')
-    parser.add_argument('--nll_weight', type=float, default=1., help='Diffraction reconstruction NLL loss weight')
-    parser.add_argument('--mae_weight', type=float, default=0., help='Diffraction reconstruction MAE loss weight')
-
-    parser.add_argument('--nimgs_train', type=int, default=params.cfg['nimgs_train'], help='Number of generated training images')
-    parser.add_argument('--nimgs_test', type=int, default=params.cfg['nimgs_test'], help='Number of generated testing images')
-
-    parser.add_argument('--outer_offset_train', type=int, default=None, help='Scan point grid offset for (generated) training datasets')
-    parser.add_argument('--outer_offset_test', type=int, default=None, help='Scan point grid offset for (generated) testing datasets')
-
-    parser.add_argument('--n_filters_scale', type=int, default=2, help='Number of filters scale')
-    parser.add_argument('--max_position_jitter', type=int, default=10, help='Solution region is expanded around the edges by this amount')
-    parser.add_argument('--intensity_scale_trainable', type=bool, default=True, help='If true, sets the model-internal normalization of diffraction amplitudes to trainable')
-
-    parser.add_argument('--positions_provided', type=bool, default=False, help='[deprecated] Whether nominal or true (nominal + jitter) positions are provided in simulation runs')
-    parser.add_argument('--label', type=str, default='', help='[deprecated] Name of this run')
-    args = parser.parse_args()
-
-    # offset between neighboring scan points, in pixels
-    model_type = params.cfg['model_type'] = args.model_type
-    label = params.cfg['label'] = args.label
-    params.cfg['positions.provided'] = args.positions_provided
-    params.cfg['data_source'] = args.data_source
-    params.cfg['set_phi'] = args.set_phi
-    params.cfg['nepochs'] = args.nepochs
-    offset = params.cfg['offset'] = args.offset
-    params.cfg['max_position_jitter'] = args.max_position_jitter
-    params.cfg['output_prefix'] = args.output_prefix
-    params.cfg['gridsize'] = args.gridsize
-    params.cfg['n_filters_scale'] = args.n_filters_scale
-    params.cfg['object.big'] = args.object_big
-    params.cfg['intensity_scale.trainable'] = args.intensity_scale_trainable
-    params.cfg['nll_weight'] = args.nll_weight
-    params.cfg['mae_weight'] = args.mae_weight
-    params.cfg['nimgs_train'] = args.nimgs_train
-    params.cfg['nimgs_test'] = args.nimgs_test
-
-    params.cfg['outer_offset_train'] = args.outer_offset_train
-    params.cfg['outer_offset_test'] = args.outer_offset_test
-    # Update the output_prefix using get_path_prefix
-else:
-    model_type = params.cfg['model_type']
-    label = params.cfg['label']
-    offset = params.cfg['offset']
-params.cfg['output_prefix'] = misc.get_path_prefix()
-
-# TODO this should be a global parameter that's updated once per training and / or evaluation cycle
-out_prefix = params.get('output_prefix')
-os.makedirs(out_prefix, exist_ok=True)
-
-from ptycho import generate_data
-ptycho_dataset = generate_data.ptycho_dataset
-YY_ground_truth = generate_data.YY_ground_truth
-YY_test_full = generate_data.YY_test_full
-Y_I_test = generate_data.Y_I_test
-Y_phi_test = generate_data.Y_phi_test
-X_test = generate_data.X_test
-norm_Y_I_test = generate_data.norm_Y_I_test
-from ptycho import model
-from ptycho.evaluation import save_metrics
-
-if model_type == 'pinn':
-    from ptycho import train_pinn
-    print("DEBUG: generate_data diff norm {}".format(np.mean(np.abs(ptycho_dataset.train_data.X))))
-    train_output = train_pinn.train_eval(ptycho_dataset)
-#    reconstructed_obj_cdi = train_output['reconstructed_obj_cdi']
-#    stitched_obj = train_output['stitched_obj']
-    pred_amp = train_output['pred_amp']
-    history = train_output['history']
-    reconstructed_obj = train_output['reconstructed_obj']
-    stitched_obj = train_output['stitched_obj']
-
-elif model_type == 'supervised':
-    from ptycho.train_supervised import stitched_obj
-    from ptycho import train_supervised
-    history = train_supervised.history
-    reconstructed_obj = train_supervised.reconstructed_obj
-else:
-    raise ValueError
-
-d = save_recons(model_type, stitched_obj)
-
-with open(out_prefix + '/history.dill', 'wb') as file_pi:
-    dill.dump(history.history, file_pi)
-
-if save_model:
-    from ptycho.model import ProbeIllumination, IntensityScaler, IntensityScaler_inv, negloglik
-    from ptycho.tf_helper import Translation
-    from ptycho.tf_helper import realspace_loss as hh_realspace_loss
-    hh = {'realspace_loss': hh_realspace_loss}
-
-    model_path = '{}/{}'.format(out_prefix, params.get('h5_path'))
-    custom_objects = {
-        'ProbeIllumination': ProbeIllumination,
-        'IntensityScaler': IntensityScaler,
-        'IntensityScaler_inv': IntensityScaler_inv,
-        'Translation': Translation,
-        'negloglik': negloglik,
-        'realspace_loss': hh_realspace_loss
-    }
-    try:
-        ModelManager.save_model(model.autoencoder, model_path, custom_objects, params.get('intensity_scale'))
-    except Exception as e:
-        print("model saving failed") # @debug decorators will break this
-    with h5py.File(model_path, 'a') as f:
-        f.attrs['intensity_scale'] = params.get('intensity_scale')
-
-if save_data:
-    with open(out_prefix + '/test_data.dill', 'wb') as f:
-        dill.dump(
-            {'YY_test_full': YY_test_full,
-             'Y_I_test': Y_I_test,
-             'Y_phi_test': Y_phi_test,
-             'X_test': X_test}, f)
-
diff --git a/build/lib/ptycho/train_pinn.py b/build/lib/ptycho/train_pinn.py
deleted file mode 100644
index 418159a..0000000
--- a/build/lib/ptycho/train_pinn.py
+++ /dev/null
@@ -1,95 +0,0 @@
-from ptycho import params
-from .loader import PtychoDataContainer
-
-def train(train_data: PtychoDataContainer, intensity_scale=None, model_instance=None):
-    from . import params as p
-    # Model requires intensity_scale to be defined to set the initial
-    # value of the corresponding model parameter
-    if intensity_scale is None:
-        intensity_scale = calculate_intensity_scale(train_data)
-    p.set('intensity_scale', intensity_scale)
-
-    from ptycho import probe
-    probe.set_probe_guess(None, train_data.probe)
-
-    from ptycho import model
-    if model_instance is None:
-        model_instance = model.autoencoder
-    nepochs = params.cfg['nepochs']
-    return model_instance, model.train(nepochs, train_data)
-
-def train_eval(ptycho_dataset):
-    ## TODO reconstructed_obj -> pred_Y or something
-    model_instance, history = train(ptycho_dataset.train_data)
-    eval_results = eval(ptycho_dataset.test_data, history, trained_model = model_instance)
-    return {
-        'history': history,
-        'reconstructed_obj': eval_results['reconstructed_obj'],
-        'pred_amp': eval_results['pred_amp'],
-        'reconstructed_obj_cdi': eval_results['reconstructed_obj_cdi'],
-        'stitched_obj': eval_results['stitched_obj'],
-        'model_instance': model_instance
-    }
-
-from tensorflow.keras.models import load_model
-# Enhance the existing eval function to optionally load a model for inference
-def eval(test_data, history=None, trained_model=None, model_path=None):
-    """
-    Evaluate the model on test data. Optionally load a model if a path is provided.
-
-    Parameters:
-    - test_data: The test data for evaluation.
-    - history: Training history, if available.
-    - trained_model: An already trained model instance, if available.
-    - model_path: Path to a saved model, if loading is required.
-
-    Returns:
-    - Evaluation results including reconstructed objects and prediction amplitudes.
-    """
-    from ptycho.data_preprocessing import reassemble
-
-    from ptycho import probe
-    probe.set_probe_guess(None, test_data.probe)
-    # TODO enforce that the train and test probes are the same
-    print('INFO:', 'setting probe from test data container. It MUST be consistent with the training probe')
-
-    from ptycho import model
-    if model_path is not None:
-        print(f"Loading model from {model_path}")
-        trained_model = load_model(model_path)
-    elif trained_model is None:
-        raise ValueError("Either a trained model instance or a model path must be provided.")
-
-    reconstructed_obj, pred_amp, reconstructed_obj_cdi = trained_model.predict(
-        [test_data.X * model.params()['intensity_scale'], test_data.coords_nominal]
-    )
-    try:
-        stitched_obj = reassemble(reconstructed_obj, part='complex')
-    except (ValueError, TypeError) as e:
-        stitched_obj = None
-        print('Object stitching failed:', e)
-    return {
-        'reconstructed_obj': reconstructed_obj,
-        'pred_amp': pred_amp,
-        'reconstructed_obj_cdi': reconstructed_obj_cdi,
-        'stitched_obj': stitched_obj
-    }
-
-def calculate_intensity_scale(ptycho_data_container: PtychoDataContainer) -> float:
-    import tensorflow as tf
-    from . import params as p
-    def count_photons(obj):
-        return tf.math.reduce_sum(obj**2, (1, 2))
-
-    def scale_nphotons(padded_obj):
-        mean_photons = tf.math.reduce_mean(count_photons(padded_obj))
-        norm = tf.math.sqrt(p.get('nphotons') / mean_photons)
-        return norm
-
-    # Extract the object data from the PtychoDataContainer
-    obj_data = ptycho_data_container.Y_I  # Assuming Y_I contains the object data
-
-    # Calculate the intensity scale using the adapted scale_nphotons function
-    intensity_scale = scale_nphotons(obj_data).numpy()
-
-    return intensity_scale
diff --git a/build/lib/ptycho/train_supervised.py b/build/lib/ptycho/train_supervised.py
deleted file mode 100644
index 8f56994..0000000
--- a/build/lib/ptycho/train_supervised.py
+++ /dev/null
@@ -1,58 +0,0 @@
-from ptycho.generate_data import *
-from ptycho import tf_helper as hh
-from ptycho import baselines as bl
-from ptycho import params as p
-
-offset = p.get('offset')
-
-# For comparison to the 'baseline' model (PtychoNN) we need to crop/shift in a different way
-def xyshift(arr4d, dx, dy):
-    assert len(arr4d.shape) == 4
-    from scipy.ndimage.interpolation import shift
-    arr4d = np.roll(arr4d, dx, axis = 1)
-    arr4d = np.roll(arr4d, dy, axis = 2)
-    return arr4d
-
-def get_recon_patches_single_channel(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0] * bl.params.params()['intensity_scale']])
-    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-#    baseline_pred_I, baseline_pred_phi = model.predict([X[:, :, :, 0]])
-#    return hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-
-def get_recon_patches_grid(X):
-    """
-    Reconstructs obj patches using a single channel of X (assumes 'model' is the vanilla
-    supervised model)
-    """
-    baseline_overlap_pred_I, baseline_overlap_pred_phi = model.predict(
-        [X_test[:, :, :, :4]  * bl.params.params()['intensity_scale']])
-    obj_stitched = hh.combine_complex(baseline_overlap_pred_I[:, :, :, :1], baseline_overlap_pred_phi[:, :, :, :1])
-    return xyshift(obj_stitched, -offset // 2, -offset // 2)
-
-if p.cfg['gridsize'] == 2:
-    model, history = bl.train((X_train[:, :, :, :4]),
-                              Y_I_train[:, :, :, :4], Y_phi_train[:, :, :, :4])
-
-    reconstructed_obj = get_recon_patches_grid(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-elif p.cfg['gridsize'] == 1:
-    model, history = bl.train((X_train[:, :, :, :1]), Y_I_train[:, :, :, :1], Y_phi_train[:, :, :, :1])
-
-    # TODO match above
-    reconstructed_obj = get_recon_patches_single_channel(X_test)
-    #stitched_obj = reassemble(reconstructed_obj, part = 'complex')
-
-    reconstructed_obj_train = get_recon_patches_single_channel(X_train)
-
-else:
-    raise ValueError
-
-try:
-    stitched_obj = reassemble(reconstructed_obj, part='complex')
-except (ValueError, TypeError) as e:
-    print('object stitching failed:', e)
diff --git a/build/lib/ptycho/trash/model2.py b/build/lib/ptycho/trash/model2.py
deleted file mode 100644
index fde7a52..0000000
--- a/build/lib/ptycho/trash/model2.py
+++ /dev/null
@@ -1,148 +0,0 @@
-from . import tf_helper as hh
-from .params import params
-
-from tensorflow.keras import Input
-from tensorflow.keras import Model
-from tensorflow.keras import Sequential
-from tensorflow.keras.activations import sigmoid, tanh
-from tensorflow.keras.applications.vgg16 import VGG16
-from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense
-from tensorflow.keras.layers import Lambda
-import glob
-import math
-import numpy as np
-import os
-import tensorflow as tf
-import tensorflow_probability as tfp
-
-tfk = hh.tf.keras
-tfkl = hh.tf.keras.layers
-tfpl = tfp.layers
-tfd = tfp.distributions
-
-wt_path = 'wts4.1'
-
-N = params()['N']
-w = params()['w']
-h = params()['h']
-gridsize = params()['gridsize']
-offset = params()['offset']
-tprobe = params()['probe']
-batch_size = params()['batch_size']
-# TODO don't rely on this
-intensity_scale = params()['intensity_scale']
-
-# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N // 2,N // 2,3))
-vgg = VGG16(weights='imagenet', include_top=False, input_shape=(N, N, 3))
-vgg.trainable = False
-
-outputs = [vgg.get_layer('block2_conv2').output]
-feat_model = Model(vgg.input, outputs)
-# feat_model.trainable = False
-
-tf.keras.backend.clear_session()
-np.random.seed(2)
-
-files=glob.glob('%s/*' %wt_path)
-for file in files:
-    os.remove(file)
-
-input_img = Input(shape=(h, w, gridsize**2), name = 'input')
-
-x = hh.Conv_Pool_block(input_img,32,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,64,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-x = hh.Conv_Pool_block(x,128,w1=3,w2=3,p1=2,p2=2, padding='same', data_format='channels_last')
-
-encoded=x
-
-#Decoding arm for amplitude
-x1=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x1=hh.Conv_Up_block(x1,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-decoded1 = Conv2D(gridsize**2, (3, 3), padding='same')(x1)
-decoded1 = Lambda(lambda x: sigmoid(x), name='amp')(decoded1)
-
-#Decoding arm for phase
-x2=hh.Conv_Up_block(encoded,128,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-x2=hh.Conv_Up_block(x2,64,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-#x2=Conv_Up_block(x2,32,w1=3,w2=3,p1=2,p2=2,padding='same', data_format='channels_last')
-
-
-decoded2 = Conv2D(gridsize**2, (3, 3), padding='same')(x2)
-decoded2 = Lambda(lambda x: math.pi * tanh(x), name='phi')(decoded2)
-
-obj = Lambda(lambda x: hh.combine_complex(x[0], x[1]),
-                     name='obj')([decoded1, decoded2])
-
-padded_obj = tfkl.ZeroPadding2D(((h // 4), (w // 4)), name = 'padded_obj')(obj)
-padded_obj_2 = Lambda(lambda x:
-    hh.reassemble_patches(x), name = 'padded_obj_2',
-    )(padded_obj)
-#padded_obj_2 = tfkl.ZeroPadding2D((offset // 2 , offset // 2), name = 'padded_obj_2')(padded_obj)
-
-trimmed_obj = Lambda(lambda x: x[:, (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        (offset * (gridsize - 1)) // 2: -(offset * (gridsize - 1)) // 2,
-        :], name = 'trimmed_obj')(padded_obj_2)
-
-# TODO average?
-# Extract overlapping regions of the object
-padded_objs_with_offsets = Lambda(lambda x: hh.flatten_overlaps(x, fmt = 'flat'), name = 'padded_objs_with_offsets')(padded_obj_2)
-# Apply the probe
-padded_objs_with_offsets = Lambda(lambda x: tf.cast(tprobe, tf.complex64) * x,
-                                  name = 'padded_objs_with_offsets_illuminated')(padded_objs_with_offsets)
-
-# TODO refactor
-# Diffracted amplitude
-padded_objs_with_offsets, pred_diff = hh.pad_and_diffract(padded_objs_with_offsets, h, w, pad=False)
-
-# Reshape
-pred_diff = Lambda(lambda x: hh._flat_to_channel(x), name = 'pred_diff_channels')(pred_diff)
-
-pred_intensity = tfpl.DistributionLambda(lambda t:
-                                       (tfd.Independent(
-                                           tfd.Poisson(
-                                               ((t * intensity_scale)**2))
-                                       )))(pred_diff)
-
-#def mul_gaussian_noise(image):
-#    # image must be scaled in [0, 1]
-#    with tf.name_scope('Add_gaussian_noise'):
-#        noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=1, dtype=tf.float32)
-#        noise_img = image * noise
-#    return noise_img
-
-negloglik = lambda x, rv_x: -rv_x.log_prob((x))
-
-# The first output exposes the real space object reconstruction and
-# though it does not contribute to the training loss, it's used to
-# calculate reconstruction errors for evaluation
-autoencoder = Model([input_img], [trimmed_obj, pred_diff, pred_intensity, pred_diff])
-#autoencoder = Model([input_img], [padded_obj, pred_diff, pred_intensity, pred_diff])
-
-encode_obj_to_diffraction = tf.keras.Model(inputs=[padded_obj],
-                           outputs=[pred_diff])
-
-diffraction_to_obj = tf.keras.Model(inputs=[input_img],
-                           outputs=[obj])
-
-autoencoder.compile(optimizer='adam',
-     loss=['mean_absolute_error', 'mean_absolute_error', negloglik, hh.total_variation_loss],
-     loss_weights = [0., 0., 1., 0.])
-
-print (autoencoder.summary())
-#plot_model(autoencoder, to_file='paper_data/str_model.png')
-
-def train(epochs, X_train, Y_I_train):
-    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,
-                                  patience=2, min_lr=0.0001, verbose=1)
-    earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)
-
-    checkpoints= tf.keras.callbacks.ModelCheckpoint('%s/weights.{epoch:02d}.h5' %wt_path,
-                                                monitor='val_loss', verbose=1, save_best_only=True,
-                                                save_weights_only=False, mode='auto', period=1)
-
-
-    history=autoencoder.fit([X_train], [Y_I_train, X_train, (intensity_scale * X_train)**2,
-                                       X_train], shuffle=True, batch_size=batch_size, verbose=1,
-                               epochs=epochs, validation_split = 0.05, callbacks=[reduce_lr, earlystop, checkpoints])
-    return history
diff --git a/build/lib/ptycho/visualization.py b/build/lib/ptycho/visualization.py
deleted file mode 100644
index 91f038e..0000000
--- a/build/lib/ptycho/visualization.py
+++ /dev/null
@@ -1,22 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-
-def display_imgs(x, y=None, log = False, cbar = False, figsize=(10, 2), **kwargs):
-  if not isinstance(x, (np.ndarray, np.generic)):
-    x = np.array(x)
-  #plt.ioff()
-  n = x.shape[0]
-  fig, axs = plt.subplots(1, n, figsize = figsize)
-  if y is not None:
-    fig.suptitle(np.argmax(y, axis=1))
-  for i in range(n):
-    if log:
-        axs.flat[i].imshow(np.log(.01 + x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    else:
-        axs.flat[i].imshow((x[i].squeeze()), interpolation='none', cmap='jet', **kwargs)
-    axs.flat[i].axis('off')
-  if cbar:
-    plt.colorbar()
-  plt.show()
-  plt.close()
-  plt.ion()
diff --git a/build/lib/ptycho/workflows/__init__.py b/build/lib/ptycho/workflows/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho/workflows/components.py b/build/lib/ptycho/workflows/components.py
deleted file mode 100644
index b030f63..0000000
--- a/build/lib/ptycho/workflows/components.py
+++ /dev/null
@@ -1,455 +0,0 @@
-import argparse
-import yaml
-import os
-import numpy as np
-import tensorflow as tf
-from ptycho import params as p
-from ptycho import probe
-from ptycho.loader import RawData, PtychoDataContainer
-import logging
-import matplotlib.pyplot as plt
-from typing import Union, Optional, Dict, Any, Tuple, Literal
-from pathlib import Path
-from ptycho.config.config import TrainingConfig, ModelConfig, dataclass_to_legacy_dict
-from dataclasses import fields
-from ptycho import loader, probe
-from typing import Union, Optional, Tuple, Dict, Any
-from ptycho.raw_data import RawData
-from ptycho.loader import PtychoDataContainer
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import params
-from ptycho.image import reassemble_patches
-
-# Set up logging
-logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
-logger = logging.getLogger(__name__)
-
-from dataclasses import fields
-from ptycho.config.config import ModelConfig, TrainingConfig
-
-def update_config_from_dict(config_updates: dict):
-    """
-    Updates the application's configuration from a dictionary, ideal for notebook workflows.
-
-    Args:
-        config_updates (dict): A dictionary of parameters to update.
-    """
-    # 1. Create a mutable dictionary from the default dataclass values
-    model_defaults = {f.name: f.default for f in fields(ModelConfig)}
-    training_defaults = {f.name: f.default for f in fields(TrainingConfig) if f.name != 'model'}
-    
-    # Merge them
-    full_config_dict = {**model_defaults, **training_defaults}
-
-    # 2. Update with the user's dictionary
-    for key, value in config_updates.items():
-        if key in full_config_dict:
-            full_config_dict[key] = value
-        else:
-            # Optionally warn about unused keys
-            logger.warning(f"Configuration key '{key}' is not a recognized parameter.")
-
-    # 3. Re-construct the dataclasses
-    model_args = {k: v for k, v in full_config_dict.items() if k in model_defaults}
-    training_args = {k: v for k, v in full_config_dict.items() if k in training_defaults}
-
-    # Handle required Path objects if they are not set
-    if training_args.get('train_data_file') is None:
-        # Assign a dummy path or handle as an error if it's essential for all workflows
-        training_args['train_data_file'] = Path("dummy_path.npz")
-
-    final_model_config = ModelConfig(**model_args)
-    final_training_config = TrainingConfig(model=final_model_config, **training_args)
-    
-    # 4. Update the legacy global params dictionary
-    update_legacy_dict(params.cfg, final_training_config)
-    
-    logger.info("Configuration updated programmatically for interactive session.")
-    params.print_params()
-
-def load_data(file_path, n_images=None, flip_x=False, flip_y=False, swap_xy=False, n_samples=1, coord_scale=1.0):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        n_images (int, optional): Number of data points to include in the training set. Defaults to 512.
-        flip_x (bool, optional): If True, flip the sign of x coordinates. Defaults to False.
-        flip_y (bool, optional): If True, flip the sign of y coordinates. Defaults to False.
-        swap_xy (bool, optional): If True, swap x and y coordinates. Defaults to False.
-        n_samples (int, optional): Number of samples to generate. Defaults to 1.
-        coord_scale (float, optional): Scale factor for x and y coordinates. Defaults to 1.0.
-
-    Returns:
-        RawData: RawData object containing the dataset.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Apply coordinate transformations
-    if flip_x:
-        xcoords = -xcoords
-        xcoords_start = -xcoords_start
-        #probeGuess = probeGuess[::-1, :]
-    if flip_y:
-        ycoords = -ycoords
-        ycoords_start = -ycoords_start
-        #probeGuess = probeGuess[:, ::-1]
-    if swap_xy:
-        xcoords, ycoords = ycoords, xcoords
-        xcoords_start, ycoords_start = ycoords_start, xcoords_start
-        #probeGuess = np.transpose(probeGuess)
-
-    # Apply coordinate scaling
-    xcoords *= coord_scale
-    ycoords *= coord_scale
-    xcoords_start *= coord_scale
-    ycoords_start *= coord_scale
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    if n_images is None:
-        n_images = xcoords.shape[0]
-
-    # Create RawData object for the training subset
-    ptycho_data = RawData(xcoords[:n_images], ycoords[:n_images],
-                          xcoords_start[:n_images], ycoords_start[:n_images],
-                          diff3d[:n_images], probeGuess,
-                          scan_index[:n_images], objectGuess=objectGuess)
-
-    return ptycho_data
-
-def parse_arguments():
-    """Parse command-line arguments based on TrainingConfig fields."""
-    logger = logging.getLogger(__name__)
-    parser = argparse.ArgumentParser(description="Non-grid CDI Example Script")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    
-    # Add arguments based on TrainingConfig fields
-    for field in fields(TrainingConfig):
-        if field.name == 'model':
-            # Handle ModelConfig fields
-            for model_field in fields(ModelConfig):
-                # Special handling for Literal types
-                if hasattr(model_field.type, "__origin__") and model_field.type.__origin__ is Literal:
-                    choices = list(model_field.type.__args__)
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=str,
-                        choices=choices,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}, choices: {choices}"
-                    )
-                else:
-                    parser.add_argument(
-                        f"--{model_field.name}",
-                        type=model_field.type,
-                        default=model_field.default,
-                        help=f"Model parameter: {model_field.name}"
-                    )
-        else:
-            # Handle path fields specially
-            if field.type == Path or str(field.type).startswith("typing.Optional[pathlib.Path"):
-                logger.debug(f"Field: {field.name}")
-                logger.debug(f"Field type: {field.type}")
-                logger.debug(f"Field default: {field.default}")
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=lambda x: (logger.debug(f"Converting path value: {x}"), Path(x) if x is not None else None)[1],
-                    default=None if field.default == None else str(field.default),
-                    help=f"Path for {field.name}"
-                )
-            else:
-                parser.add_argument(
-                    f"--{field.name}",
-                    type=field.type,
-                    default=field.default,
-                    help=f"Training parameter: {field.name}"
-                )
-    
-    return parser.parse_args()
-
-def load_yaml_config(file_path: str) -> Dict[str, Any]:
-    """Load configuration from a YAML file."""
-    try:
-        with open(file_path, 'r') as file:
-            return yaml.safe_load(file)
-    except (yaml.YAMLError, IOError) as e:
-        logger.error(f"Error loading YAML config: {e}")
-        raise
-
-
-#def validate_config(config: Dict[str, Any]) -> None:
-#    """Validate the configuration."""
-#    if 'train_data_file_path' not in config or config['train_data_file_path'] is None:
-#        raise ValueError("train_data_file_path is a required parameter and must be provided")
-
-def setup_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> TrainingConfig:
-    """Set up the configuration by merging defaults, YAML file, and command-line arguments."""
-    try:
-        yaml_config = load_yaml_config(yaml_path) if yaml_path else None
-        args_config = vars(args)
-        
-        # Convert string paths to Path objects
-        for key in ['train_data_file', 'test_data_file', 'output_dir']:
-            if key in args_config and args_config[key] is not None:
-                args_config[key] = Path(args_config[key])
-        
-        # Create ModelConfig from args
-        model_fields = {f.name for f in fields(ModelConfig)}
-        model_args = {k: v for k, v in args_config.items() if k in model_fields}
-        model_config = ModelConfig(**model_args)
-        
-        # Create TrainingConfig
-        training_fields = {f.name for f in fields(TrainingConfig)}
-        training_args = {k: v for k, v in args_config.items() 
-                        if k in training_fields and k != 'model'}
-        config = TrainingConfig(model=model_config, **training_args)
-        
-        # Update the global configuration
-        update_legacy_dict(params.cfg, config)
-        
-        logger.info("Configuration setup complete")
-        logger.info(f"Final configuration: {config}")
-        
-        return config
-    except (yaml.YAMLError, IOError, ValueError) as e:
-        logger.error(f"Error setting up configuration: {e}")
-        raise
-
-def load_and_prepare_data(data_file_path: str) -> Tuple[RawData, RawData, Any]:
-    """
-    Load and prepare the data from a single file path.
-
-    Args:
-        data_file_path (str): Path to the data file
-
-    Returns:
-        Tuple[RawData, RawData, Any]: A tuple containing the full dataset, training subset, and additional data
-    """
-    # TODO deprecated
-    from ptycho.loader import load_xpp_npz
-    if not os.path.exists(data_file_path):
-        raise FileNotFoundError(f"Data file not found: {data_file_path}")
-
-    try:
-        return load_xpp_npz(data_file_path)
-    except Exception as e:
-        logger.error(f"Error loading data from {data_file_path}: {str(e)}")
-        raise
-
-from typing import Union
-from ptycho.loader import RawData, PtychoDataContainer
-
-def create_ptycho_data_container(data: Union[RawData, PtychoDataContainer], config: TrainingConfig) -> PtychoDataContainer:
-    """
-    Factory function to create or return a PtychoDataContainer.
-
-    Args:
-        data (Union[RawData, PtychoDataContainer]): Input data, either RawData or PtychoDataContainer.
-        config (TrainingConfig): Training configuration object.
-
-    Returns:
-        PtychoDataContainer: The resulting PtychoDataContainer.
-
-    Raises:
-        TypeError: If the input data is neither RawData nor PtychoDataContainer.
-    """
-    if isinstance(data, PtychoDataContainer):
-        return data
-    elif isinstance(data, RawData):
-        dataset = data.generate_grouped_data(config.model.N, K=7, nsamples=1)
-        return loader.load(lambda: dataset, data.probeGuess, which=None, create_split=False)
-    else:
-        raise TypeError("data must be either RawData or PtychoDataContainer")
-
-def train_cdi_model(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig
-) -> Dict[str, Any]:
-    """
-    Train the CDI model.
-
-    Args:
-        train_data (Union[RawData, PtychoDataContainer]): Training data.
-        config (Dict[str, Any]): Configuration dictionary.
-
-    Returns:
-        Dict[str, Any]: Results dictionary containing training history.
-    """
-    from ptycho.loader import PtychoDataset
-    from ptycho import train_pinn
-    # Convert input data to PtychoDataContainer
-    train_container = create_ptycho_data_container(train_data, config)
-    if test_data is not None:
-        test_container = create_ptycho_data_container(test_data, config)
-    else:
-        test_container = None
-
-    # Initialize probe
-    probe.set_probe_guess(None, train_container.probe)
-
-#    # Calculate intensity scale
-#    intensity_scale = train_pinn.calculate_intensity_scale(train_container)
-
-    # Train the model
-    results = train_pinn.train_eval(PtychoDataset(train_container, test_container))
-    results['train_container'] = train_container
-    results['test_container'] = test_container
-    #history = train_pinn.train(train_container)
-    
-    return results
-
-def reassemble_cdi_image(
-    test_data: Union[RawData, PtychoDataContainer],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20,
-    coord_scale: float = 1.0
-) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
-    """
-    Reassemble the CDI image using the trained model.
-
-    Args:
-        test_data (Union[RawData, PtychoDataContainer]): Test data.
-        config (Dict[str, Any]): Configuration dictionary.
-        flip_x (bool): Whether to flip the x coordinates. Default is False.
-        flip_y (bool): Whether to flip the y coordinates. Default is False.
-        transpose (bool): Whether to transpose the image by swapping the 1st and 2nd dimensions. Default is False.
-        M (int): Parameter for reassemble_position function. Default is 20.
-        coord_scale (float): Scale factor for x and y coordinates. Default is 1.0.
-
-    Returns:
-        Tuple[np.ndarray, np.ndarray, Dict[str, Any]]: 
-        Reconstructed amplitude, reconstructed phase, and results dictionary.
-    """
-    # TODO use train_pinn.eval to get reconstructed diffraction amplitude
-    test_container = create_ptycho_data_container(test_data, config)
-    
-    from ptycho import nbutils
-    obj_tensor_full, global_offsets = nbutils.reconstruct_image(test_container)
-    
-    # Log the shape of global_offsets
-    logger.info(f"Shape of global_offsets: {global_offsets.shape}")
-
-    # Assert that obj_tensor_full is a 4D tensor
-    assert obj_tensor_full.ndim == 4, f"Expected obj_tensor_full to be a 4D tensor, but got shape {obj_tensor_full.shape}"
-
-    # Transpose the image if requested
-    if transpose:
-        obj_tensor_full = np.transpose(obj_tensor_full, (0, 2, 1, 3))
-
-    # Flip coordinates if requested
-    if flip_x:
-        global_offsets[:, 0, 0, :] = -global_offsets[:, 0, 0, :]
-    if flip_y:
-        global_offsets[:, 0, 1, :] = -global_offsets[:, 0, 1, :]
-    
-    # Scale coordinates
-    global_offsets *= coord_scale
-    
-    from ptycho import tf_helper as hh
-    obj_image = hh.reassemble_position(obj_tensor_full, global_offsets, M=M)
-    
-    recon_amp = np.absolute(obj_image)
-    recon_phase = np.angle(obj_image)
-    
-    results = {
-        "obj_tensor_full": obj_tensor_full,
-        "global_offsets": global_offsets,
-        "recon_amp": recon_amp,
-        "recon_phase": recon_phase
-    }
-    
-    return recon_amp, recon_phase, results
-
-def run_cdi_example(
-    train_data: Union[RawData, PtychoDataContainer],
-    test_data: Optional[Union[RawData, PtychoDataContainer]],
-    config: TrainingConfig,
-    flip_x: bool = False,
-    flip_y: bool = False,
-    transpose: bool = False,
-    M: int = 20
-) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Dict[str, Any]]:
-    """
-    Run the main CDI example execution flow.
-
-    Args:
-        train_data: Training data
-        test_data: Optional test data
-        config: Training configuration parameters
-        flip_x: Whether to flip the x coordinates
-        flip_y: Whether to flip the y coordinates
-        transpose: Whether to transpose the image by swapping dimensions
-        M: Parameter for reassemble_position function
-
-    Returns:
-        Tuple containing:
-        - reconstructed amplitude (or None)
-        - reconstructed phase (or None)
-        - results dictionary
-    """
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    # Train the model
-    train_results = train_cdi_model(train_data, test_data, config)
-    
-    recon_amp, recon_phase = None, None
-    
-    # Reassemble test image if test data is provided and reconstructed_obj is available
-    if test_data is not None and 'reconstructed_obj' in train_results:
-        recon_amp, recon_phase, reassemble_results = reassemble_cdi_image(
-            test_data, config, flip_x, flip_y, transpose, M=M
-        )
-        train_results.update(reassemble_results)
-    
-    return recon_amp, recon_phase, train_results
-
-
-def save_outputs(amplitude: Optional[np.ndarray], phase: Optional[np.ndarray], results: Dict[str, Any], output_prefix: str) -> None:
-    """Save the generated images and results."""
-    os.makedirs(output_prefix, exist_ok=True)
-    
-    # TODO Save training history with tensorboard / mlflow
-    
-    # Save test results if available
-    if amplitude is not None and phase is not None:
-        logger.info(f"Amplitude array shape: {amplitude.shape}")
-        logger.info(f"Phase array shape: {phase.shape}")
-        
-        # Squeeze any extra dimensions
-        amplitude = np.squeeze(amplitude)
-        phase = np.squeeze(phase)
-        
-        logger.info(f"Squeezed amplitude shape: {amplitude.shape}")
-        logger.info(f"Squeezed phase shape: {phase.shape}")
-        
-        # Save as PNG files using plt.figure() to handle 2D arrays properly
-        plt.figure(figsize=(8,8))
-        plt.imshow(amplitude, cmap='gray')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_amplitude.png"))
-        plt.close()
-        
-        plt.figure(figsize=(8,8))
-        plt.imshow(phase, cmap='viridis')
-        plt.colorbar()
-        plt.savefig(os.path.join(output_prefix, "reconstructed_phase.png"))
-        plt.close()
-        
-    logger.info(f"Outputs saved to {output_prefix}")
diff --git a/build/lib/ptycho/workflows/visualize_results.py b/build/lib/ptycho/workflows/visualize_results.py
deleted file mode 100644
index 5d1f9ad..0000000
--- a/build/lib/ptycho/workflows/visualize_results.py
+++ /dev/null
@@ -1,48 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho import evaluation, params
-from typing import Dict, Any
-
-def visualize_results(results: Dict[str, Any], test_data, i: int = 200, output_prefix: str = 'output'):
-    """
-    Visualize the results using the evaluation.summarize function.
-
-    Args:
-    results (Dict[str, Any]): Dictionary containing the results from the CDI process.
-    test_data: The test data used for evaluation.
-    i (int): Index of the sample to visualize. Default is 200.
-    output_prefix (str): Directory to save the output files. Default is 'output'.
-    """
-    # Extract necessary data from results and test_data
-    pred_amp = results['pred_amp']
-    reconstructed_obj = results['reconstructed_obj']
-    X_test = test_data.X
-    Y_I_test = test_data.Y_I
-    Y_phi_test = test_data.Y_phi
-    probe = np.absolute(params.get('probe')[:, :, 0, 0])
-
-    # Call the summarize function
-    heatmaps = evaluation.summarize(i, results['pred_amp'] + 1, results['reconstructed_obj'], 
-                                    X_test, Y_I_test, Y_phi_test,
-                                    probe, channel=0, crop=False)
-
-    # Save the heatmaps
-    for name, heatmap in heatmaps.items():
-        plt.figure(figsize=(10, 10))
-        plt.imshow(heatmap, cmap='jet')
-        plt.colorbar()
-        plt.title(name)
-        plt.savefig(f"{output_prefix}/{name}.png")
-        plt.close()
-
-    print(f"Heatmaps saved to {output_prefix}")
-
-if __name__ == "__main__":
-    # This is where you would load your results and test_data
-    # For example:
-    # from ptycho.workflows.components import load_and_prepare_data
-    # test_data = load_and_prepare_data("path_to_test_data.npz")
-    # results = ... # Load your results here
-
-    # visualize_results(results, test_data)
-    pass  # Remove this line when uncommenting the code above
diff --git a/build/lib/ptycho/xpp.py b/build/lib/ptycho/xpp.py
deleted file mode 100644
index ec54375..0000000
--- a/build/lib/ptycho/xpp.py
+++ /dev/null
@@ -1,77 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-import tensorflow as tf
-import pkg_resources
-
-from . import loader
-from .loader import key_coords_offsets, key_coords_relative
-from ptycho import diffsim as datasets
-
-train_frac = .5
-N = 64
-gridh, gridw = 32, 32
-
-np.random.seed(7)
-
-
-def get_data(**kwargs):
-    return dset, train_frac
-
-import numpy as np
-from . import loader
-import pkg_resources
-
-def load_ptycho_data(file_path, train_size=512):
-    """
-    Load ptychography data from a file and return RawData objects.
-
-    Args:
-        file_path (str, optional): Path to the data file. Defaults to the package resource 'datasets/Run1084_recon3_postPC_shrunk_3.npz'.
-        train_size (int, optional): Number of data points to include in the training set. Defaults to 512.
-
-    Returns:
-        tuple: A tuple containing two RawData objects:
-            - ptycho_data: RawData object containing the full dataset.
-            - ptycho_data_train: RawData object containing a subset of the data for training.
-    """
-    # Load data from file
-    data = np.load(file_path)
-
-    # Extract required arrays from loaded data
-    xcoords = data['xcoords']
-    ycoords = data['ycoords']
-    xcoords_start = data['xcoords_start']
-    ycoords_start = data['ycoords_start']
-    diff3d = np.transpose(data['diffraction'], [2, 0, 1])
-    probeGuess = data['probeGuess']
-    objectGuess = data['objectGuess']
-
-    # Create scan_index array
-    scan_index = np.zeros(diff3d.shape[0], dtype=int)
-
-    # Create RawData object for the full dataset
-    ptycho_data = loader.RawData(xcoords, ycoords, xcoords_start, ycoords_start,
-                                 diff3d, probeGuess, scan_index, objectGuess=objectGuess)
-
-    # Create RawData object for the training subset
-    ptycho_data_train = loader.RawData(xcoords[:train_size], ycoords[:train_size],
-                                       xcoords_start[:train_size], ycoords_start[:train_size],
-                                       diff3d[:train_size], probeGuess,
-                                       scan_index[:train_size], objectGuess=objectGuess)
-
-    return ptycho_data, ptycho_data_train, data
-
-data_file_path = pkg_resources.resource_filename(__name__, 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-ptycho_data, ptycho_data_train, obj = load_ptycho_data(data_file_path)
-print('raw diffraction shape', obj['diffraction'].shape)
-# TODO cast to complex64?
-probeGuess = obj['probeGuess']
-objectGuess = obj['objectGuess']
-#dset = loader.get_neighbor_diffraction_and_positions(ptycho_data, N, K=6,
-#    nsamples=4)
-
-#dset = loader.get_neighbor_diffraction_and_positions(diff3d, xcoords, ycoords,
-#    xcoords_start, ycoords_start, K = 7, nsamples = 1)
-#X_full = dset['X_full']
-
-## TODO refactor actual / nominal positions
diff --git a/build/lib/ptycho_torch/__init__.py b/build/lib/ptycho_torch/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/build/lib/ptycho_torch/config_params.py b/build/lib/ptycho_torch/config_params.py
deleted file mode 100644
index ff48736..0000000
--- a/build/lib/ptycho_torch/config_params.py
+++ /dev/null
@@ -1,74 +0,0 @@
-#Configuration singleton class
-
-#Typical config values (need to be declared separately in __main__ or jupyter notebook)
-
-#The way you use this is:
-# 1. Defining a settings dictionary
-# 2. Declare specific class: ModelConfig(), TrainingConfig(), DataConfig()
-# 3. Call set_config or set_params methods using dictionary
-# 4. Now the respective class can be accessed globally
-
-#Configuration file for reference (this is not used within this file but used when configs are
-#declared in other files)
-
-data_config_default = {
-    'nphotons': 1e5,
-    'N': 128,
-    'C': 4,
-    'K': 6,
-    'n_subsample': 10,
-    'grid_size': (2,2),
-    'probe_dir_get': True,
-    'normalize': True
-}
-
-model_config_default = {
-    'intensity_scale_trainable': False,
-    'intensity_scale': 10000.0,
-    'max_position_jitter': 10, #Random jitter for translation (helps make model more robust)
-    'n_filters_scale': 2, #Shrinking factor for channels
-    'intensity_scale': 15000.0, #General intensity scale guess, this can be trainable. Needs to be float
-    'object.big': False, #True if need patch reassembly
-    'probe.big': True, #True if need patch reassembly
-    'offset': 4,
-    'loss_function': 'MAE'
-}
-
-training_config_default = {
-    'nll': True, #Negative log likelihood for loss function
-    'device': 'cuda',
-    'strategy': 'ddp'
-}
-
-class Settings:
-    _instance = None
-
-    def __new__(cls, *args, **kwargs):
-        if not cls._instance:
-            cls._instance = super(Settings, cls).__new__(cls, *args, **kwargs)
-            cls._instance.settings = {}
-        
-        return cls._instance
-    
-    def set_settings(self, settings):
-        self.settings = settings
-
-    def get(self, key, default_val = None):
-        if key not in self.settings:
-            return default_val
-        else:
-            return self.settings.get(key)
-    def add(self, key, value):
-        self.settings[key] = value
-
-
-class TrainingConfig(Settings):
-    _instance = None
-
-class ModelConfig(Settings):
-    _instance = None
-
-class DataConfig(Settings):
-    _instance = None
-
-#Creating dataclasses 
diff --git a/build/lib/ptycho_torch/datagen.py b/build/lib/ptycho_torch/datagen.py
deleted file mode 100644
index 450d4d4..0000000
--- a/build/lib/ptycho_torch/datagen.py
+++ /dev/null
@@ -1,215 +0,0 @@
-#This code is for generating "fake" data from a known ptychography dataset
-
-#Imports
-import numpy as np
-import torch
-from torch import nn
-import torch.nn.functional as F
-
-#Other functions
-import ptycho_torch.patch_generator as pg
-import ptycho_torch.helper as hh
-from ptycho_torch.config_params import TrainingConfig, DataConfig, ModelConfig
-
-
-
-def load_probe_object(file_path):
-    """
-    Load object and probe guesses from a .npz file.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-
-    Returns:
-        tuple: A tuple containing (objectGuess, probeGuess)
-
-    Raises:
-        ValueError: If required data is missing from the .npz file or if data is invalid.
-        RuntimeError: If an error occurs during file loading.
-    """
-    try:
-        with np.load(file_path) as data:
-            if 'objectGuess' not in data or 'probeGuess' not in data:
-                raise ValueError("The .npz file must contain 'objectGuess' and 'probeGuess'")
-            
-            objectGuess = data['objectGuess']
-            probeGuess = data['probeGuess']
-
-        # Validate extracted data
-        if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-            raise ValueError("objectGuess and probeGuess must be 2D arrays")
-        if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-            raise ValueError("objectGuess and probeGuess must be complex-valued")
-
-        return objectGuess, probeGuess
-
-    except Exception as e:
-        raise RuntimeError(f"Error loading data from {file_path}: {str(e)}")
-    
-def simulate_from_npz(file_path, nimages, buffer=None, random_seed=None):
-    """
-    Load object and probe guesses from a .npz file and generate simulated ptychography data.
-
-    Args:
-        file_path (str): Path to the .npz file containing objectGuess and probeGuess.
-        nimages (int): Number of scan positions to generate.
-        buffer (float, optional): Border size to avoid when generating coordinates. 
-                                  If None, defaults to 5% of the smaller dimension of objectGuess.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-
-    Returns:
-        RawData: A RawData instance containing the simulated ptychography data.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation or file loading.
-    """
-    # TODO there should be an option to use the same scan point coords as in the dataset for the simulation. This
-    # would be useful for consistency checks
-    # Load guesses from file
-    objectGuess, probeGuess = load_probe_object(file_path)
-
-    # Set default buffer if not provided
-    if buffer is None:
-        buffer = min(objectGuess.shape) * 0.05  # 5% of the smaller dimension
-
-    # Generate simulated data
-    return generate_simulated_data(objectGuess, probeGuess, nimages, random_seed)
-    
-
-def generate_simulated_data(objectGuess, probeGuess, nimages, random_seed=None):
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    Args:
-        objectGuess (np.ndarray): Complex-valued 2D array representing the object.
-        probeGuess (np.ndarray): Complex-valued 2D array representing the probe.
-        nimages (int): Number of scan positions to generate.
-        buffer (float): Border size to avoid when generating coordinates.
-        random_seed (int, optional): Seed for random number generation. If None, uses system time.
-
-    Returns:
-        RawData: A RawData instance containing the simulated ptychography data.
-
-    Raises:
-        ValueError: If input parameters are invalid.
-        RuntimeError: If an error occurs during simulation.
-    """
-    # Input validation
-    if objectGuess.ndim != 2 or probeGuess.ndim != 2:
-        raise ValueError("objectGuess and probeGuess must be 2D arrays")
-    if not np.iscomplexobj(objectGuess) or not np.iscomplexobj(probeGuess):
-        raise ValueError("objectGuess and probeGuess must be complex-valued")
-    if nimages <= 0:
-        raise ValueError("nimages must be positive and buffer must be non-negative")
-    
-    N = DataConfig().get('N')
-
-    # Get object dimensions
-    height, width = objectGuess.shape
-
-    # Ensure buffer doesn't exceed image dimensions
-    buffer = N//2
-
-    # Set random seed if provided
-    if random_seed is not None:
-        np.random.seed(random_seed)
-
-    # Generate random coordinates (floats)
-    xcoords = np.random.uniform(buffer, width - buffer, nimages)
-    ycoords = np.random.uniform(buffer, height - buffer, nimages)
-
-    # Create scan_index
-    scan_index = np.zeros(nimages, dtype = int)
-
-    # Generate simulated data
-    raw_data = from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index)
-
-    return raw_data
-
-def from_simulation(xcoords, ycoords, probeGuess, objectGuess, scan_index = None):
-    """
-    Generate simulated ptychography data using random scan positions.
-
-    """
-    #Convert all input vars to torch
-    xcoords = torch.from_numpy(xcoords)
-    ycoords = torch.from_numpy(ycoords)
-    probeGuess = torch.from_numpy(probeGuess)
-    objectGuess = torch.from_numpy(objectGuess)
-
-    sampled_obj_patches = get_image_patches(objectGuess, probeGuess, xcoords, ycoords)
-
-    diff_obj_patches, obj, scaling = hh.illuminate_and_diffract(sampled_obj_patches.squeeze(), probeGuess)
-    output_scaling_factor = hh.scale_nphotons(diff_obj_patches)
-
-    output_dict = {
-        'diff3d':  diff_obj_patches,
-        'original_object': sampled_obj_patches.squeeze(),
-        'object': obj,
-        'obj_scale_factor': output_scaling_factor,
-        'diff_scale_factor': scaling,
-        'xcoords': xcoords,
-        'ycoords': ycoords,
-        'xcoords_start': xcoords,
-        'ycoords_start': ycoords,
-        'scan_index': scan_index
-    }
-
-    return output_dict
-def get_image_patches(objectGuess, probeGuess, xcoords, ycoords):
-    """
-    Get and return image patches from single canvas
-
-    Input
-    -----
-    objectGuess: np.ndarray (H, W)
-    xcoords: np.darray (N)
-    ycoords: np.darray (N)
-
-    
-    """
-
-    #No need to pad canvas. We will never sample anywhere from outside the canvas
-    N = DataConfig().get('N')
-    n_images = len(xcoords)
-    #Need to add batch dimension to objectGuess
-    canvas = objectGuess[None].expand(n_images,-1,-1)
-
-    #All coordinates are in pixel units
-    #Remember that F.grid_sample needs coords in [-1, 1], so need to shift
-    h_obj, w_obj = objectGuess.shape
-    h_prob, w_prob = probeGuess.shape
-    x, y = torch.arange(h_prob), torch.arange(w_prob)
-    #Create "grid coordinates" at every xcoord location
-    x_shifted, y_shifted = ((xcoords - N/2)[:,None] + x)/ (h_obj-1), \
-                           ((ycoords - N/2)[:,None] + y)/ (w_obj-1) #map to [0,1]
-    
-    #Creating a meshgrid of size (H x W x 2)
-    grid = torch.stack([x_shifted.unsqueeze(-1).expand(n_images, -1, y_shifted.shape[1]),
-                        y_shifted.unsqueeze(1).expand(n_images, x_shifted.shape[1], -1)],
-                        dim = -1) * 2 - 1 #map to [-1,1]
-    #F.grid_sample behavior needs tranpose
-    grid = torch.transpose(grid, 1, 2)
-    grid = grid.to(torch.float32)
-
-    #F.grid_sample needs (N,C,H,W), so we put in 1 dummy C dimension
-    sampled_real = F.grid_sample(canvas.unsqueeze(1).real, grid,
-                                 mode = 'bilinear', align_corners = True)
-
-    sampled_imag = F.grid_sample(canvas.unsqueeze(1).imag, grid,
-                                 mode = 'bilinear', align_corners = True)
-    
-    sampled_complex = torch.view_as_complex(torch.stack([sampled_real, sampled_imag],
-                                                        dim = -1))
-    
-    return sampled_complex
-    #Note to albert:
-    #Continue developing get_image_patches adapated to pytorch.. shouldn't be too hard
-
-
-
-
-
-
-
diff --git a/build/lib/ptycho_torch/dset_loader_pt_mmap.py b/build/lib/ptycho_torch/dset_loader_pt_mmap.py
deleted file mode 100644
index a28c53a..0000000
--- a/build/lib/ptycho_torch/dset_loader_pt_mmap.py
+++ /dev/null
@@ -1,429 +0,0 @@
-import numpy as np
-from ptycho.params import params, get
-from torch.utils.data import Dataset, DataLoader
-from pathlib import Path
-import zipfile
-from collections import defaultdict
-import torch
-import time
-import os
-
-#Memory mapping
-from tensordict import MemoryMappedTensor, TensorDict
-
-#Patch generation
-from ptycho_torch.patch_generator import group_coords, get_relative_coords
-
-#Parameters
-from ptycho_torch.config_params import TrainingConfig, DataConfig, ModelConfig
-
-#Helper methods
-import ptycho_torch.helper as hh
-
-def npz_headers(npz):
-    """
-    Takes a path to an .npz file, which is a Zip archive of .npy files.
-    Generates a sequence of (name, shape).
-    We can use this to determin shape of npz constituents without loading them
-    This will be useful in the __len__ method for the dataset
-
-    Taken from: https://stackoverflow.com/questions/68224572/how-to-determine-the-shape-size-of-npz-file
-    Modified to quickly grab dimension we care about
-    """
-    with zipfile.ZipFile(npz) as archive:
-        for name in archive.namelist():
-            #If name starts with 'xcoords'
-            if name.startswith('diff3d'):
-
-                npy = archive.open(name)
-                version = np.lib.format.read_magic(npy)
-                shape, _, _ = np.lib.format._read_array_header(npy, version)
-                yield shape
-                break
-
-
-
-class PtychoDataset(Dataset):
-    """
-    Ptychography Dataset for PtychoPINN
-
-    Important: Some data is memory-mapped in order to provide fast loading for dynamic data
-    #Memory-mapped data: Diffraction images
-    #Non-memory-mapped data: Probe, ObjectGuess, scan_index, coords (x,y)
-
-    The layout of the data will be such that the first index is always the experiment #.
-    For example, diffraction[0] will return the entire image stack from the first experiment
-    coords[0] would return the stack of image coordinates from the first experiment
-
-    Inputs
-    -------
-    ptycho_dir: Directory containing individual ptychography scans as npz files. If non-npz, expected to be normalized or
-    rewritten via a data adapting software such as Ptychodus
-    probe_dir: Directory containing probe guesses as npz files. If non-npz, expected to be normalized or
-    rewritten via a data adapting software such as Ptychodus
-
-    Params
-    grid_size: tuple of image grid size (e.g. 2 x 2 is most used)
-                n_images = grid_size[0] * grid_size[1] (e.g. 2 x 2 = 4)
-    probe_map: list of probe indices assigned to each experiment
-                (e.g. [0, 1, 0] -> Exp 1, Probe 1. Exp 2, Probe 2. Exp 3, Probe 1)
-    probes: list of probes used in experiments. Will be h x w numpy tensors.
-    K: # of nearest neighbors to group together to select image patch from
-    n_subsample: # of patches to subsample from each group of size K
-        e.g. K = 6, n_subsample = 10, n_images = 4.  Then we subsample 10 patches from 6C4=15
-
-    """
-    def __init__(self, ptycho_dir, probe_dir, data_dir='data/memmap', remake_map = True):
-        #Directories
-        self.ptycho_dir = ptycho_dir
-        self.n_files = len(os.listdir(ptycho_dir))
-
-        #Putting all relevant information within accessible dictionary
-        self.data_dict = {}
-
-        #Either grab probes from directory or expect them to be provided in configs
-        if DataConfig().get('probe_dir_get'):
-            self.get_probes(probe_dir)
-        else:
-            self.data_dict['probes'] = DataConfig().get('probes')
-
-        #Calculate length for __len__ method and __get__
-        self.length, self.im_shape, self.cum_length = self.calculate_length(ptycho_dir)
-
-        #Image stack memory mapping
-        data_prefix = data_dir.split('/')[0]
-        state_path = data_prefix +'/' + 'state_files.npz'
-
-        #If memory map wasn't made or you want to remake it
-        if not os.path.exists(data_dir) or remake_map:
-            self.memory_map_data(Path(self.ptycho_dir).iterdir())
-            #Save self.data_dict and self.probes in npz file
-            np.savez(state_path,
-                     data_dict=self.data_dict)
-        #Otherwise, if path exists, load memory map and probe/other constants
-        else:
-            #THIS FUNCTIONALITY CURRENTLY DOESNT WORK
-            #I DONT EVEN KNOW IF YOU CAN LOAD A PREVIOUS MEMORY MAP
-            print('Existing map found. Loading memory-mapped data')
-            self.mmap_ptycho = TensorDict.load_memmap(data_dir)
-            temp = np.load(state_path, allow_pickle=True)
-
-            #Assign other important params
-            self.data_dict = temp['data_dict'].item()
-        
-    def calculate_length(self, ptycho_dir):
-        """
-        Calculates length from series of npz files without loading them using npz_header
-        Also calculates cumulative length for linear indexing, since we are creating "groups" of channels for ptychography training.
-        This means that the total length of image groups is equal to the # diffraction images * # of groupings.
-
-        """
-        total_length = 0
-        cumulative_length = [0]
-
-        for npz_file in Path(ptycho_dir).iterdir():
-            #Check whether object.big is checked
-            if ModelConfig().get('object.big'):
-                multiplier = DataConfig().get('n_subsample')
-            else:
-                multiplier = 1
-            tensor_shape = list(npz_headers(npz_file))
-
-            total_length += tensor_shape[0][0] * multiplier #Double indexing to access number inside nested list
-            im_shape = tensor_shape[0][1:]
-            cumulative_length.append(total_length)
-        
-        return total_length, im_shape, cumulative_length
-    
-    #Methods for diffraction data mapping
-    def memory_map_data(self, image_paths):
-        """
-        Creates memory mapped tensor dictionary containg diffraction images and relevant coordinate information
-        1.  Solves for solution patch indices using group_coords method
-        2.  Writes to respective memory maps. The diffraction map is populated in batches, while the other maps
-        are populated in full for every individual dataset
-            - "images" - (N x C x H x W), N = # of patterns, C = # of images per soln patch, H = height, W = width
-            - "coords_offsets" - (N x C x 1 x 2), N = # of patterns, C = # of images per soln patch, 2 = x,y
-            - "coords_relative" - (N x C x 1 x 2), N = # of patterns, C = # of images per soln patch, 2 = x,y
-            - "coords_start_offsets" - (N x C x 1 x 2), N = # of patterns, C = # of images per soln patch, 2 = x,y
-            - "coords_start_relative" - (N x C x 1 x 2), N = # of patterns, C = # of images per soln patch, 2 = x,y
-        Note: Probe is stored in memory for the dataset, not in the memory map.
-        ---
-        Args:
-            image_paths - list of paths to independent experiment npz files
-            grid_size - tuple of image grid size (e.g. 2 x 2 is most used)
-
-
-        """
-        if ModelConfig().get('object.big'):
-            n_channels = DataConfig().get('grid_size')[0] * DataConfig().get('grid_size')[1]
-        else:
-            n_channels = 1
-        DataConfig().add('n_images', n_channels)
-
-        #Create memory map for every tensor. We'll be populating the diffraction image in batches, and the
-        #other coordinate tensors in full for every individual dataset
-
-        mmap_length = self.length
-
-        #Time creation of tensordict with printed messages
-        print("Creating memory mapped tensor dictionary...")
-        print("Memory map length: {}".format(mmap_length))
-
-        #Start timer
-        start = time.time()
-
-        mmap_ptycho = TensorDict(
-            {   "images": MemoryMappedTensor.empty(
-                    (mmap_length, n_channels, *self.im_shape),
-                    dtype=torch.float32,
-                ),
-                "coords_center": MemoryMappedTensor.empty(
-                    (mmap_length, 1, 1, 2),
-                    dtype=torch.float32,
-                ),
-                "coords_relative": MemoryMappedTensor.empty(
-                    (mmap_length, n_channels, 1, 2),
-                    dtype=torch.float32,
-                ),
-                "coords_start_center": MemoryMappedTensor.empty(
-                    (mmap_length, 1, 1, 2),
-                    dtype=torch.float32,
-                ),
-                "coords_start_relative": MemoryMappedTensor.empty(
-                    (mmap_length, n_channels, 1, 2),
-                    dtype=torch.float32,
-                ),
-                "nn_indices": MemoryMappedTensor.empty(
-                    (mmap_length, n_channels),
-                    dtype=torch.int64
-                ),
-                "experiment_id": MemoryMappedTensor.empty(
-                    (mmap_length),
-                    dtype=torch.int32
-                )},
-            batch_size = mmap_length,
-        )
-
-        #End timer
-        end = time.time()
-        print("Memory map creation time: {}".format(end - start))
-
-        #Lock memory map
-        mmap_ptycho.memmap_like(prefix="data/memmap")
-
-        #Create normalization tensor for all experiments
-        self.data_dict["scaling_constant"] = torch.empty(self.n_files,
-                                                         dtype = torch.float32)
-
-        #Go through each npz file and populate mmap_diffraction
-        batch_size = 1024
-        #Keep track of memory map write indices
-        global_from, global_to = 0, 0
-
-        for i, npz_file in enumerate(image_paths):
-            print("Populating memory map for dataset {}".format(i))
-            #NON-DIFFRACTION IMAGE MAPPING
-            #----
-            #Assume: N = # of scans
-            start, end = self.cum_length[i], self.cum_length[i+1]
-
-            #Writing to non-diffraction memory maps in one go:
-            non_diff_timer_start = time.time()
-
-            #If solution patches are enforced, then must include alot more metadata
-            if ModelConfig().get('object.big'):
-                #Grabbing information from npz file
-                xcoords = np.load(npz_file)['xcoords']
-                ycoords = np.load(npz_file)['ycoords']
-                xcoords_start = np.load(npz_file)['xcoords_start']
-                ycoords_start = np.load(npz_file)['ycoords_start']
-                #Get indices for solution patches on current dataset
-                nn_indices, coords_nn = group_coords(xcoords, ycoords,
-                                        C=DataConfig().get('C'))
-                
-                #Coords_nn is (N x 4 x 1 x 2). Contains all 4 sets of (x,y) coords for an image patch
-                coords_start_nn = np.stack([xcoords_start[nn_indices],
-                                            ycoords_start[nn_indices]],axis=2)[:, :, None, :]
-                
-                #Get relative and center of mass coordinates
-                coords_com, coords_relative = get_relative_coords(coords_nn)
-                coords_start_com, coords_start_relative = get_relative_coords(coords_start_nn)
-
-                mmap_ptycho["coords_center"][start:end] = torch.from_numpy(coords_com)
-                mmap_ptycho["coords_relative"][start:end] = torch.from_numpy(coords_relative)
-                mmap_ptycho["coords_start_center"][start:end] = torch.from_numpy(coords_start_com)
-                mmap_ptycho["coords_start_relative"][start:end] = torch.from_numpy(coords_start_relative)
-                mmap_ptycho["nn_indices"][start:end] = torch.from_numpy(nn_indices)
-            else:
-                #Otherwise, the indices are just an arange from 0 to N-1
-                nn_indices = np.arange(end-start)
-                mmap_ptycho["nn_indices"][start:end] = torch.from_numpy(nn_indices)[:,None]
-
-            mmap_ptycho["experiment_id"][start:end] = torch.tensor(i)
-
-            non_diff_time = time.time() - non_diff_timer_start
-            print("Non-diffraction memory map write time: {}".format(non_diff_time))
-
-            #DIFFRACTION IMAGE MAPPING
-            #----
-            diff_timer_start = time.time()
-            curr_nn_index_length = len(nn_indices)
-            diff_stack = torch.from_numpy(np.load(npz_file)['diff3d'])
-
-            #Inserting dummy channel dimension if n_channels = 1
-            if not ModelConfig().get('object.big'):
-                diff_stack = diff_stack[:,None]
-
-            #Perform normalization on diffraction image stack
-            if DataConfig().get('normalize'):
-                diff_stack, norm_factor = hh.normalize_data(diff_stack)
-                self.data_dict["scaling_constant"][i] = norm_factor
-            else:
-                self.data_dict["scaling_constant"][i] = 1
-
-            #Write to memory mapped tensor in batches
-            for j in range(0, curr_nn_index_length, batch_size):
-                #Calculate end index (to not exceed length of list)
-                local_to = min(j + batch_size, curr_nn_index_length)
-                global_to += local_to - j
-
-                mmap_ptycho["images"][global_from:global_to] = diff_stack[nn_indices[j:local_to]]
-
-                #Writing everything simultaneously as a TensorDict
-                # mmap_ptycho[global_from:global_to] = TensorDict(
-                #     {
-                #         "images": torch.from_numpy(diff_stack[nn_indices[j:local_to]]),
-                #         "coords_center": torch.from_numpy(coords_com[j:local_to]),
-                #         "coords_relative": torch.from_numpy(coords_relative[j:local_to]),
-                #         "coords_start_center": torch.from_numpy(coords_start_com[j:local_to]),
-                #         "coords_start_relative": torch.from_numpy(coords_start_relative[j:local_to]),
-                #         "nn_indices": torch.from_numpy(nn_indices[j:local_to]),
-                #         "experiment_id": torch.from_numpy(np.full(local_to - j, i))
-                #     },
-                #     batch_size = (local_to - j)
-                # )
-
-                #Update global
-                global_from += global_to - global_from
-
-            diff_time = time.time() - diff_timer_start
-            print("Diffraction memory map write time: {}".format(diff_time))
-
-            #Calculate intensity scale for given experiment and add to 
-
-        
-
-        self.mmap_ptycho = mmap_ptycho
-
-        return 
-    
-    def get_probes(self, probe_dir):
-        '''
-        Retrieve all used experimental probes from probe directory. Expect a series of npz files with different probes.
-        Puts them all in the same tensor, self.probes, which will be indexed in __getitem__
-
-        '''
-        N = DataConfig().get('N')
-        n_probes = len(os.listdir(probe_dir))
-        self.data_dict['probes'] = torch.empty(size=(n_probes, N, N), dtype = torch.complex64)
-        print(os.listdir(probe_dir))
-        for i, probe_file in enumerate(os.listdir(probe_dir)):
-            probe_path = os.path.join(probe_dir, probe_file)
-            probe_data = np.load(probe_path)
-            probe_data = torch.from_numpy(probe_data['probe'])
-            self.data_dict['probes'][i] = probe_data
-
-    def load_diffraction_data(self, npz_file):
-        """
-        Loads diffraction image stack from npz file. Used for memory mapping only
-        (don't use for get_item)
-        ---
-        Input: npz_file - path to npz file
-        Output: diffraction - (N x H x W), N = # of patterns, H = height, W = width
-        """
-        diffraction = np.load(npz_file)['diff3d']
-        return diffraction
-
-    #Methods for mapping all other data 
-    def map_data(self, ptycho_dir):
-        """
-        Currently unused.
-
-        Maps all data from npzs to specific arrays held in memory
-        Data will be in format data_dict['parameter'][experiment #][image #]
-        """
-
-        #Take above code and instead use a for loop and unpack for each variable
-        for npz_file in Path(ptycho_dir).iterdir():
-            temp_file = np.load(npz_file)
-            #Append all relevant information
-            self.data_dict['xcoords'].append(temp_file['xcoords'])
-            self.data_dict['ycoords'].append(temp_file['ycoords'])
-            self.data_dict['xstart'].append(temp_file['xcoords_start'])
-            self.data_dict['ystart'].append(temp_file['ycoords_start'])
-            
-            self.data_dict['probeGuess_global'].append(temp_file['probeGuess']) #Note: this is a 2D array
-
-        return 
-
-    def __len__(self):
-        return self.length
-
-    def __getitem__(self, idx):
-        """
-        Returns memory mapped tensordict, alongside probe. Written to be batched
-        so you can return multiple instances.
-
-        Probe dimensionality is expanded to match the data channels. This is so multiplication operations are broadcast correctly.
-        
-        Output
-        -------
-        self.mmap_ptych[idx] - Batched TensorDict containing all relevant information for training. See
-            function memory_map_data for further details. Length is batch size
-        probes_indexed - (N,C,H,W) tensor, where N is batch size. C is number of channels, where the probe is duplicated
-            H and W are height and width of diffraction pattern. The dimensionality should be exactly the same as the output of the autoencoder.
-        scaling_constant - (N) tensor, scaling constants required for each diffraction image
-        
-        """
-        #Experimental index is used to find the probe corresponding to the right experiment
-        #exp_idx is a list of experiment indices that are then used to index probe/scaling constants
-        exp_idx = self.mmap_ptycho['experiment_id'][idx]
-
-        if ModelConfig().get('object.big'):
-            channels = DataConfig().get('C')
-        else:
-            channels = 1
-
-        #Expand probe to match number of channels for data.
-        probes_indexed = self.data_dict['probes'][exp_idx].unsqueeze(1).expand(-1,channels,-1,-1)
-
-        #Scaling constant
-        scaling_const = self.data_dict['scaling_constant'][exp_idx]
-
-        return self.mmap_ptycho[idx], probes_indexed, scaling_const
-        
-#Collation
-
-class TensorDictDataLoader(DataLoader):
-    '''
-    Modifiers dataloader class that allows for batch sampling exploiting the structure of TensorDicts
-    Given a set of indices, we can directly index all of them simultaneously from the TensorDict instead of calling
-    yield on a single index at a time.
-
-    This allows us to return a TensorDict object which already has indexing built in.
-    '''
-    def __iter__(self):
-        #Iterator over sampler
-        batch_sampler = self.batch_sampler
-        dataset = self.dataset
-
-        for batch_indices in batch_sampler:
-            yield dataset[batch_indices]
-
-
-
-#Tensor memory mapping has the advantage that it's already in shared memory so using multiple workers for the
-#dataloader on a single gpu is viable
-
-#Dataset will contain naive getitem methods
\ No newline at end of file
diff --git a/build/lib/ptycho_torch/helper.py b/build/lib/ptycho_torch/helper.py
deleted file mode 100644
index 1e05308..0000000
--- a/build/lib/ptycho_torch/helper.py
+++ /dev/null
@@ -1,509 +0,0 @@
-#Type helpers
-from typing import Tuple, Optional, Union, Callable, Any
-
-#Additional helper functions ported from original tensorflow lib
-import torch
-from torch import nn
-import torch.nn.functional as F
-from ptycho_torch.model import CombineComplex
-import numpy as np
-
-#Configurations
-from ptycho_torch.config_params import ModelConfig, TrainingConfig, DataConfig
-
-#Complex functions
-#---------------------
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    '''
-    Converts real number amplitude and phase into single complex number for FFT
-
-    Inputs
-    ------
-    amp: torch.Tensor
-        Amplitude of complex number
-    phi: torch.Tensor
-        Phase of complex number
-    
-    Outputs
-    -------
-    out: torch.Tensor
-        Complex number
-    '''
-
-    CC = CombineComplex()
-       
-    return CC(amp, phi)
-def is_complex(x: torch.Tensor) -> bool:
-    '''
-    Check if tensor is complex dtype.
-
-    Inputs
-    ------
-    x: torch.Tensor
-        Tensor to check
-
-    Outputs
-    -------
-    out: bool
-    '''
-
-    return x.is_complex()
-
-#Patch reassembly
-#---------------------
-def reassemble_patches_position_real(inputs: torch.Tensor, offsets_xy: torch.Tensor,
-                                      agg: bool = True,
-                                      padded_size: Optional[int] = None,
-                                      **kwargs: Any) -> torch.Tensor:
-    '''
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-
-    This function is passed as an argument (it is wrapped). This is because it is applied as a Lambda function
-    to every single image patch in the dataloader stack.
-
-    Inputs
-    ------
-    inputs: diffraction images from model -> (n_images, n_patches, N, N)
-    offsets_xy: offset patches in x, y -> (n_images, n_patches, 1, 2)
-    agg: aggregation boolean
-    padded_size: Amount of padding
-
-    Output
-    ------
-    out: torch.Tensor
-        Single tensor of shape (n_images, N, N) where N is summed object size. Everything has been merged here.
-    '''
-
-    assert inputs.dtype == torch.complex64, 'Input must be complex'
-
-    if padded_size is None:
-        padded_size = get_padded_size()
-
-    #Create ones mask for normaliziation, which cuts off half the image b/c Nyquist limit
-    norm = norm_mask(inputs)
-
-    #Flattening first two dimensions, adding singleton dimension to end
-    n_channels = inputs.shape[1]
-    offsets_flat = torch.flatten(offsets_xy, start_dim = 0, end_dim = 1)#[:,:,:,None]
-    imgs_flat = torch.flatten(inputs, start_dim = 0, end_dim = 1)#[:,:,:,None]
-    norm_flat = torch.flatten(norm, start_dim = 0, end_dim = 1)#[:,:,:,None]
-
-    #Pad patches and translate
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation(imgs_flat_bigN, offsets_flat, 0.)
-
-    #Same thing with norm
-    norm_flat_bigN = pad_patches(norm_flat, padded_size)
-    norm_flat_bigN_translated = Translation(norm_flat_bigN, offsets_flat, 0.)
-
-    if agg:
-        #First reshape batch * channel dim tensors to (batch, channel, size, size)
-        imgs_channel = torch.reshape(imgs_flat_bigN_translated,
-                                     (-1, n_channels, padded_size, padded_size))
-        norm_channel = torch.reshape(norm_flat_bigN_translated,
-                                     (-1, n_channels, padded_size, padded_size))
-        #Then decide which pixels you want to keep. We're getting rid of all pixels outside the N/2 x N/2 window
-        #due to nyquist sampling
-
-        #Boolean mask from N//2 sized masking
-        boolean_mask = torch.any(norm_channel, dim = 1).to(inputs.device) #(b, N, N)
-        #Count number of nonzeros from the ones mask, which has been modified by boolean_mask
-        non_zeros = torch.count_nonzero(norm_channel * boolean_mask[:,None,:,:], axis = 1).to(inputs.device)
-        #Change value of non_zeros from 0 to 1 in regions without any data. We'll be dividing
-        #by the number of non_zeros, so this is to avoid div by 0
-        non_zeros[non_zeros == 0] = 1
-
-        #Normalize merged image by number of summed channels
-        imgs_merged = (torch.sum(imgs_channel, axis = 1) * boolean_mask) / non_zeros
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N = padded_size)
-    
-def norm_mask(inputs):
-    '''
-    Creates normalization mask for patch reassembly. Simply returns a mask of ones which has reduced dimensionality
-    '''
-    B, C, N, _ = inputs.shape
-
-    #Mask with half-size
-    ones = torch.ones(B, C, N//2, N//2).to(inputs.device)
-    #Pad rest
-    ones = nn.ZeroPad2d(N//4)(ones)
-
-    return ones
-
-    
-def extract_channels_from_region(inputs: torch.Tensor,
-                                 offsets_xy: torch.Tensor,
-                                 jitter_amt: float = 0.0) -> torch.Tensor:
-    
-    '''
-    Extracts averaged objects from the summed M x M solution region.
-
-    Essentially we're translating the solution region in reverse; we reverse the offsets we used to translate
-    the original image, so that the image patch of interest (within the solution region) is
-    centered at the origin.
-
-    We can then use this modified translated solution region and do a simple crop extraction that's N x N about the origin.
-
-    Inputs
-    ------
-    inputs: torch.Tensor (batch_size, 1, M, M), M = N + some padding size
-    offsets: torch.Tensor (batch_size, C, 1, 2)
-    jitter_amt: float
-        Assuming zero jitter
-
-    Output
-    ------
-    output: torch.Tensor (batch_size, C, N, N)
-        - Shifted images, cropped symmetrically
-    
-    '''
-    offsets_flat = torch.flatten(offsets_xy, start_dim = 0, end_dim = 1)
-    #Check offset and input dimensions
-    #List of assertions
-    if inputs.shape[0] is not None:
-        assert int(inputs.shape[0]) == int(offsets_xy.shape[0])
-    assert int(inputs.shape[1]) == 1
-    assert int(offsets_xy.shape[3]) == 2
-
-    
-    #We need to repeat the solution patch C # of times, so we can perform unique translations
-    #for all C image patches.
-    #Steps: Repeat -> Flatten
-    n_channels = offsets_xy.shape[1]
-    stacked_inputs = inputs.expand(-1, n_channels, -1, -1)
-    flat_stacked_inputs = torch.flatten(stacked_inputs, start_dim = 0, end_dim = 1)
-
-    #Obtain translation of patches
-    #Note, offsets must be inverted in sign compared to Translation in: reassemble_patches_position_real
-    translated_patches = Translation(flat_stacked_inputs, -offsets_flat, 0.0)
-    cropped_patches = trim_reconstruction(translated_patches)
-    cropped_patches = torch.reshape(cropped_patches,
-                                    (-1, n_channels, DataConfig().get('N'), DataConfig().get('N')))
-
-    return cropped_patches
-
-    
-def trim_reconstruction(inputs: torch.Tensor, N: Optional[int] = None) -> torch.Tensor:
-    '''
-    Trim from shape (-1, 1, M, M) to (-1, 1, N, N) where M >= N
-    Second dimension is 1 because of Translation function always returning 4D tensor
-    M is the expanded solution region size
-    N is the exact size of the measured diffraction input image (e.g. 64 pixels)
-
-    Assume M = get_padded_size()
-
-    Inputs
-    ------
-    inputs: torch.Tensor (batch_size, 1, M, M)
-    N: int, size of last two dimensions
-    '''
-
-    if N is None:
-        N = DataConfig().get('N')
-
-    shape = inputs.shape
-
-    #Ensure dimension matching
-    if shape[2] is not None:
-        assert int(shape[2]) == int(shape[-1])
-    try:
-        clipsize = (int(shape[2]) - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    
-    #return clipped input
-    return inputs[:,:,
-                  clipsize:-clipsize,
-                  clipsize:-clipsize]
-
-
-
-#Masking/norm functions
-#---------------------
-#UNUSED
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    '''
-    Creates padded object mask to fulfill Nyquist criterion. This way, when we do FFT for
-    diffraction image, we don't oversample frequency.
-    (I.e. pad image on both sides with N/4 pixels, so total # of
-    padded pixels is N/2)).
-    The purpose of this mask is to find out how many images are overlapped
-    at a specific pixel, so we can normalize the sum of pixel values
-    by the number of images on that pixel (e.g. Pixel = 30, images = 3 -> normalized = 10)
-
-    Inputs
-    ------
-    inputs: torch.Tensor
-    N: Image dimension (x and y) in pixels
-    c: Number of images per patch (usually 4)
-    kind: 'center' or 'border'. Affects how mask is made
-
-    Outputs
-    -------
-    output: Padded mask
-    '''
-    n_images = inputs.shape[0]
-    count_mask = torch.ones((n_images, c, N, N),
-                              dtype = inputs.dtype)
-    #count_mask = F.pad(count_mask, (N//4, N//4, N//4, N//4), "constant", 0)
-
-    if kind == 'center':
-        return count_mask
-    elif kind == 'border':
-        return 1 - count_mask
-    else:
-        raise ValueError
-
-#UNUSED
-def mk_norm(inputs: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    '''
-    Create normalization tensor based on count_mask from mk_centermask
-    Adds .001 to deal with divide instablility from norm
-    '''
-    N = inputs.shape[-1]
-    images_per_patch = inputs.shape[1]
-    count_mask = mk_centermask(inputs, N, images_per_patch)
-    assembled_masks = fn_reassemble_real(count_mask, average = False)
-    norm = assembled_masks + 0.001
-
-    return norm
-
-#Pad functions
-#---------------------
-
-def pad_patches(input: torch.Tensor, padded_size: Optional[int] = None) -> torch.Tensor:
-    '''
-    Pad patches to be the same size as the original image
-    '''
-    if padded_size is None:
-        padded_size = get_padded_size()
-    pad_dim = (padded_size - input.shape[-1]) // 2
-
-    return F.pad(input, (pad_dim, pad_dim, pad_dim, pad_dim), "constant", 0)
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    '''
-    Pad object function for Nyquist criterion. An N x M image needs to be padded by N // 4
-    pixels on the top and bottom sides, and the M // 4 on the left and right sides
-    '''
-    return nn.ZeroPad2d((h // 4, h // 4, w // 4, w // 4))(input)
-
-def get_padded_size():
-    bigN = get_bigN()
-    buffer = ModelConfig().get('max_position_jitter')
-
-    return bigN + buffer
-
-def get_bigN():
-    N = DataConfig().get('N')
-    gridsize = DataConfig().get('grid_size')
-    offset = ModelConfig().get('offset')
-
-    return N + (gridsize[0] - 1) * offset
-
-#Translation functions
-#---------------------
-def Translation(img, offset, jitter_amt):
-    '''
-    Translation function with custom complex number support.
-    Uses torch.nn.functional.grid_sample to perform subpixel translation.
-    Meant to be performed on a flattened set of inputs.
-
-    Grid_sample takes an input of (N, C, H_in, W_in) and grid of (N, H_out, W_out, 2) to
-    output (N, C, H_out, W_out). In our case, C is 1 because we already flattened the channels from (N, C, H_in, W_in)
-    to (N * C, H_in, W_in). Offset is (N*C, 1, 2)
-
-    We transform the input solution region to (N, 1, H, W), and the grid to (N, H_out, W_out, 2).
-    The grid essentially contains all c possible translations of the input region.
-
-    The output in our case will be (N, 1, H_out, W_out)
-
-    Inputs
-    ------
-    img: torch.Tensor (N, H, W). Stack of images in a solution region. dtype complex, cfloat 
-    offset: torch.Tensor (N, 1, 2). Offset of each image in the solution region
-
-    Outputs
-    ------
-    out: torch.Tensor (N, 1, H_out, W_out)
-    '''
-    n, h, w = img.shape
-    #Create 2d grid to sample bilinear interpolation from
-    x, y = torch.arange(h).to(img.device), torch.arange(w).to(img.device)
-    #Add offset to x, y using broadcasting (H) -> (C, H)
-    jitter_x = torch.normal(torch.zeros(offset[:,:,0].shape).to(img.device), #offset: [n, 1]
-                          std=jitter_amt)
-    jitter_y = torch.normal(torch.zeros(offset[:,:,1].shape).to(img.device), #offset: [n, 1]
-                          std=jitter_amt)
-    
-    x_shifted, y_shifted = (x + offset[:, :, 0] + jitter_x)/(h-1), \
-                           (y + offset[:, :, 1] + jitter_y)/(w-1)
-       
-    #Create meshgrid using manual stacking method C x H x W x 2)
-    #Multiply by 2 and subtract 1 to shift to [-1, 1] range for use by grid_sample
-    grid = torch.stack([x_shifted.unsqueeze(-1).expand(n, -1, y_shifted.shape[1]),
-                    y_shifted.unsqueeze(1).expand(n, x_shifted.shape[1], -1)],
-                    dim = -1) * 2 - 1
-    
-    #Need to transpose grid due to some weird F.grid_sample behavior to make it align with tensorflow
-    grid = torch.transpose(grid, 1, 2)
-
-    #Apply F.grid_sample to translate real and imaginary parts separately.
-    #grid_sample does not have native complex tensor support
-    #Need to unsqueeze img to have it work with grid_sample (check documentation). 
-    #In our case, color channels are 1 (singleton) and so we just unsqueeze at 2nd dimension
-    
-    translated_real = F.grid_sample(img.unsqueeze(1).real, grid,
-                                    mode = 'bilinear', align_corners = True)
-
-    if img.dtype == torch.complex64:
-        translated_imag = F.grid_sample(img.unsqueeze(1).imag, grid,
-                                        mode = 'bilinear', align_corners = True)
-    else:
-        translated_imag = torch.zeros_like(translated_real).to(img.device)
-
-    #Combine real and imag
-    translated = torch.view_as_complex(torch.stack((translated_real, translated_imag),
-                                                   dim = -1))
-    
-    return translated
-
-#Flattening functions
-#---------------------
-def _flat_to_channel(img: torch.Tensor, channels: int = 4) -> torch.Tensor:
-    '''
-    Reshapes tensor from flat format to channel format. Useful to batch apply operations such as
-    translation on the flat tensor, then reshape back to channel format.
-
-    Inputs
-    ------
-    img: torch.Tensor (N, H, W)
-
-    Outputs
-    -------
-    out: torch.Tensor (M, C, H, W)
-    '''
-
-    _, H, W = img.shape
-
-    img = torch.reshape(img, (-1, channels, H, W))
-
-    return img
-    
-
-#Fourier functions for forward pass
-
-def pad_and_diffract(input: torch.Tensor, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    '''
-    Pads channel images and performs Fourier transform, going from real space (object) to
-    reciprocal space (diffraction pattern)
-
-    Input
-    --------
-    input: torch.Tensor (N, C, H, W). Does not need to be a flattened tensor.
-    pad: Boolean. Whether to pad the input before performing the Fourier transform.
-    
-    '''
-
-    h, w = input.shape[-2], input.shape[-1]
-
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    #assert input.shape[-1] == 1
-    input = torch.fft.fft2(input.to(torch.complex64))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1)))
-
-    return input, padded
-
-def illuminate_and_diffract(input: torch.Tensor, probe: torch.Tensor, intensity_scale = None) -> torch.Tensor:
-    '''
-    Performs illumination and diffraction of a single object.
-    Supports complex tensors
-
-    Inputs
-    --------
-    input: torch.Tensor (N, H, W)
-        - Channels are missing because we don't expect channels to show up here
-        - We are only illuminating a set of position-based patches from the object
-    probe: torch.Tensor (N, H, W)
-    '''
-    #Add batch dimension for single image
-    input_amp = torch.abs(input)
-    input_phase = torch.angle(input)
-
-    if intensity_scale is None:
-        intensity_scale = scale_nphotons(input_amp * torch.abs(probe))
-
-    input_scaled = intensity_scale * input
-
-    #Multiply by probe
-    probe_product = input_scaled * probe
-
-    #Get new intensity
-    input_amp = torch.abs(probe_product)
-
-    #Perform FFT
-    output = torch.fft.fft2(probe_product.to(torch.complex64))
-    output = torch.real(torch.conj(output) * output) / (input.shape[-2] * input.shape[-1])
-    output = torch.sqrt(torch.fft.fftshift(output, dim=(-2, -1)))
-
-    #Scale by intensity
-    output, input_amp, =\
-            output / intensity_scale, input_amp / intensity_scale
-    
-    input_scaled = combine_complex(input_amp, input_phase)
-    
-    return output, input_scaled, intensity_scale
-
-#Photon scaling functions
-
-def normalize_data(X: torch.Tensor) -> torch.Tensor:
-    """
-    Scale the photon counts in the diffraction image accounting for zero padding condition
-    and the fact that diffraction pixel values are the square root of the intensity, which we're
-    looking to scale to
-
-    Returns scaled data and scaling factor
-
-    Inputs
-    --------
-    input: torch.Tensor (N, H, W)
-
-    Outputs
-    --------
-    Tensor: torch.Tensor (N, H, W)
-    Scaling_factor: float
-
-    """
-    N = DataConfig().get('N')
-    scaling_factor = torch.sqrt(
-            ((N / 2) ** 2) / torch.mean(torch.sum(X**2, dim = (1, 2)))
-            )
-
-    return X * scaling_factor, scaling_factor
-
-
-def scale_nphotons(input: torch.Tensor) -> float:
-    """
-    Calculate the object amplitude normalization factor that gives the desired
-    *expected* number of observed photons, averaged over an entire dataset.
-
-    Returns a single scalar.
-
-    Inputs
-    --------
-    input: torch.Tensor (N, H, W)
-    """
-    #Find the mean photons PER image, first by summing all pixels per image, then averaging the sums from all images
-    mean_photons = torch.mean(torch.sum(input**2, dim = (1, 2)))
-    norm_factor = torch.sqrt(DataConfig().get('nphotons') / mean_photons)
-
-    return norm_factor
diff --git a/build/lib/ptycho_torch/model.py b/build/lib/ptycho_torch/model.py
deleted file mode 100644
index 894d7bf..0000000
--- a/build/lib/ptycho_torch/model.py
+++ /dev/null
@@ -1,592 +0,0 @@
-#Torch
-import torch
-from torch import nn
-import torch.nn.functional as F
-import torch.distributions as dist
-
-#Other math
-import numpy as np
-import math
-
-#Helper
-from ptycho_torch.config_params import ModelConfig, TrainingConfig, DataConfig
-import ptycho_torch.helper as hh
-
-#Ensuring 64float b/c of complex numbers
-torch.set_default_dtype(torch.float32)
-
-device = TrainingConfig().get('device')
-
-#Helping modules
-
-class Tanh_custom_act(nn.Module):
-    '''
-    Custom tanh activation module used in:
-        Decoder_phase
-    '''
-    def forward(self, x):
-        return math.pi * torch.tanh(x)
-
-#Conv blocks
-#Conv blocks
-class ConvBaseBlock(nn.Module):
-    '''
-    Convolutional base block for Pooling and Upscaling
-
-    If padding = same, padding is half of kernel size
-    '''
-    def __init__(self, in_channels, out_channels,
-                 w1 = 3, w2 = 3,
-                 padding = 'same',
-                 activation = 'relu'):
-        super(ConvBaseBlock, self).__init__()
-        padding_size = w1 // 2 if padding == 'same' else 0
-        #NN layers
-        self.conv1 = nn.Conv2d(in_channels = in_channels,
-                               out_channels = out_channels,
-                               kernel_size = (w1, w2),
-                               padding = padding_size)
-        self.conv2 = nn.Conv2d(in_channels = out_channels,
-                               out_channels = out_channels,
-                               kernel_size = (w1, w2),
-                               padding = padding_size)
-        #Activation used in upblock
-        self.activation = getattr(F, activation) if activation else None
-        
-    def forward(self, x):
-        x = F.relu(self.conv1(x))
-        x = self.activation(self.conv2(x)) if self.activation else F.relu(self.conv2(x))
-        x = self._pool_or_up(x)
-
-        return x
-    
-    def _pool_or_up(self, x):
-        raise NotImplementedError("Subclasses must implement pool or up")
-    
-class ConvPoolBlock(ConvBaseBlock):
-
-    def __init__(self, in_channels, out_channels,
-                 w1 = 3, w2 = 3, p1 = 2, p2 = 2,
-                 padding = 'same'):
-        super(ConvPoolBlock, self).__init__(in_channels, out_channels,
-                                            w1=w1, w2=w2, padding=padding)
-        #Pooling layer
-        self.pool = nn.MaxPool2d(kernel_size=(p1, p2),
-                                 padding = 0)
-        
-    def _pool_or_up(self, x):
-        return self.pool(x)
-    
-class ConvUpBlock(ConvBaseBlock):
-
-    def __init__(self, in_channels, out_channels,
-                 w1 = 3, w2 = 3, p1 = 2, p2 = 2,
-                 padding = 'same'):
-        
-        super(ConvUpBlock, self).__init__(in_channels, out_channels,
-                                            w1=w1, w2=w2, padding=padding)
-        padding_size = w1 // 2 if padding == 'same' else 0
-        #NN layers
-        self.up = nn.Upsample(scale_factor = (p1, p2),
-                              mode = 'nearest')
-
-    def _pool_or_up(self, x):
-        return self.up(x)
-
-#Encoder
-
-class Encoder(nn.Module):
-    def __init__(self, n_filters_scale):
-        super(Encoder, self).__init__()
-
-        self.N = DataConfig().get('N')
-        starting_coeff = 64 / (self.N / 32)
-        if ModelConfig().get('object.big'):
-            starting_filter_n = DataConfig().get('grid_size')[0] * DataConfig().get('grid_size')[1]
-        else:
-            starting_filter_n = 1
-        self.filters = [starting_filter_n]
-        #Starting output channels is 64. Last output size will always be n_filters_scale * 128. 
-        if self.N == 64:
-            self.filters = self.filters + [n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-        elif self.N == 128:
-            self.filters = self.filters + [n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-        elif self.N == 256:
-            self.filters = self.filters + [n_filters_scale * 8, n_filters_scale * 16, n_filters_scale * 32, n_filters_scale * 64, n_filters_scale * 128]
-
-
-
-        if starting_coeff < 3 or starting_coeff > 64:
-            raise ValueError(f"Unsupported input size: {self.N}")
-        
-        self.blocks = nn.ModuleList([ConvPoolBlock(in_channels = self.filters[i-1],
-                                                   out_channels = self.filters[i])
-                                    for i in range(1,len(self.filters))])
-        
-    def forward(self, x):
-        for block in self.blocks:
-            x = block(x)
-
-        return x
-    
-#Decoders
-
-class Decoder_filters(nn.Module):
-    '''
-    Base decoder class handling dynamic channel sizing in self.filters
-    '''
-    def __init__(self, n_filters_scale):
-        super(Decoder_filters, self).__init__()
-        self.N = DataConfig().get('N')
-
-        #Calculate number of channels for upscaling
-        #Start from self.N and divide by 2 until 32 for each layer
-        #E.g. 
-        #N == 64: [n_filters_scale * 64, n_filters_scale * 32]
-        #N == 128: [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-        self.filters = [n_filters_scale * 128]
-
-        if self.N == 64:
-            self.filters = self.filters + [n_filters_scale * 64, n_filters_scale * 32]
-        elif self.N == 128:
-            self.filters = self.filters + [n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-        elif self.N == 256:
-            self.filters = self.filters + [n_filters_scale * 256, n_filters_scale * 128, n_filters_scale * 64, n_filters_scale * 32]
-
-        if self.N < 64:
-            raise ValueError(f"Unsupported input size: {self.N}")
-        
-    def forward(self, x):
-        raise NotImplementedError("Subclasses must implement forward")
-    
-class Decoder_base(Decoder_filters):
-    def __init__(self, n_filters_scale):
-        super(Decoder_base, self).__init__(n_filters_scale)
-        #Layers
-        self.blocks = nn.ModuleList([ConvUpBlock(in_channels = self.filters[i-1],
-                                                   out_channels = self.filters[i]) 
-                                    for i in range(1,len(self.filters))])
-        
-    def forward(self, x):
-        for block in self.blocks:
-            x = block(x)
-
-        return x
-
-class Decoder_last(nn.Module):
-    '''
-    Decoder to get both amplitude and phase, combining to create full object function
-    '''
-    def __init__(self, in_channels, out_channels, n_filters_scale,
-                  activation = torch.sigmoid, name = ''):
-        super(Decoder_last, self).__init__()
-        #Grab parameters
-        self.N = DataConfig().get('N')
-        self.gridsize = DataConfig().get('grid_size')
-
-        #Channel splitting
-        if ModelConfig().get('object.big'):
-            self.c_outer = self.gridsize[0] * self.gridsize[1]
-        else:
-            self.c_outer = 1
-
-        #Layers
-        self.conv1 =  nn.Conv2d(in_channels = in_channels - self.c_outer,
-                                out_channels = out_channels,
-                                kernel_size = (3, 3),
-                                padding = 3//2)
-        
-        #conv_up_block and conv2 are separate to conv1
-        self.conv_up_block = ConvUpBlock(self.c_outer, n_filters_scale * 32)
-        self.conv2 =  nn.Conv2d(in_channels = n_filters_scale * 32,
-                                out_channels = out_channels,
-                                kernel_size = (3, 3),
-                                padding = 3//2)
-
-        #Additional
-        self.activation = activation
-        self.padding = nn.ConstantPad2d((self.N // 4, self.N // 4,
-                                         self.N // 4, self.N //4), 0)
-
-        
-    def forward(self,x):
-        x1 = self.conv1(x[:, :-self.c_outer, :, :])
-        x1 = self.activation(x1)
-        x1 = self.padding(x1)
-
-        if not ModelConfig().get('probe.big'):
-            return x1
-        
-        x2 = self.conv_up_block(x[:, -self.c_outer:, :, :])
-        x2 = self.conv2(x2)
-        x2 = F.silu(x2) #Same as swish
-
-        outputs = x1 + x2
-
-        return outputs
-
-class Decoder_phase(Decoder_base):
-    def __init__(self, n_filters_scale):
-        super(Decoder_phase, self).__init__(n_filters_scale)
-        grid_size = DataConfig().get('grid_size')
-        if ModelConfig().get('object.big'):
-            num_channels = grid_size[0] * grid_size[1]
-        else:
-            num_channels = 1
-        #Nn layers
-
-        #Custom nn layers with specific identifiable names
-        self.add_module('phase_activation', Tanh_custom_act())
-        self.add_module('phase', Decoder_last(n_filters_scale * 32, num_channels, n_filters_scale,
-                                         activation = self.phase_activation))
-            
-    def forward(self, x):
-        #Apply upscale block layers
-        for block in self.blocks:
-            x = block(x)
-
-        #Apply final layer
-        outputs = self.phase(x)
-
-        return outputs
-
-class Decoder_amp(Decoder_base):
-    def __init__(self, n_filters_scale):
-        super(Decoder_amp, self).__init__(n_filters_scale)
-
-        #Custom nn layers with specific identifiable names
-        self.add_module('amp_activation', Tanh_custom_act())
-        self.add_module('amp', Decoder_last(n_filters_scale * 32, 1, n_filters_scale,
-                                         activation = self.amp_activation))
-            
-    def forward(self, x):
-        #Apply upscale block layers
-        for block in self.blocks:
-            x = block(x)
-
-        #Apply final layer
-        outputs = self.amp(x)
-
-        return outputs
-    
-#Autoencoder
-
-class Autoencoder(nn.Module):
-    def __init__(self, n_filters_scale):
-        super(Autoencoder, self).__init__()
-        #Encoder
-        self.encoder = Encoder(n_filters_scale)
-        #Decoders (Amplitude/Phase)
-        self.decoder_amp = Decoder_amp(n_filters_scale)
-        self.decoder_phase = Decoder_phase(n_filters_scale)
-
-    def forward(self, x):
-        #Encoder
-        x = self.encoder(x)
-        #Decoders
-        x_amp = self.decoder_amp(x)
-        x_phase = self.decoder_phase(x)
-
-        return x_amp, x_phase
-
-#Probe modules
-class ProbeIllumination(nn.Module):
-    '''
-    Probe illumination done using hadamard product of object tensor and 2D probe function.
-    2D probe function should be supplised by the dataloader
-    '''
-    def __init__(self):
-        super(ProbeIllumination, self).__init__()
-        self.N = DataConfig().get('N')
-        self.mask = ModelConfig().get('probe_mask')
-    
-    def forward(self, x, probe):
-        
-        #Check if probe mask exists
-        #If not, probe mask is just a ones matrix
-        #If mask exists, save mask is class attribute
-        if not self.mask:
-            probe_mask = torch.ones((self.N, self.N)).to(x.device)
-        else:
-            probe_mask = ModelConfig().get('probe_mask')
-
-        return x * probe * probe_mask, probe * probe_mask
-
-
-#Other modules
-class CombineComplex(nn.Module):
-    '''
-    Converts real number amplitude and phase into single complex number for FFT
-
-    Inputs
-    ------
-    amp: torch.Tensor
-        Amplitude of complex number
-    phi: torch.Tensor
-        Phase of complex number
-    
-    Outputs
-    -------
-    out: torch.Tensor
-        Complex number
-    '''
-    def __init__(self):
-        super(CombineComplex, self).__init__()
-
-    def forward(self, amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-
-        out = amp.to(dtype=torch.complex64) * \
-                torch.exp(1j * phi.to(dtype=torch.complex64))
-        
-        return out
-    
-class LambdaLayer(nn.Module):
-    '''
-    Generic layer module for helper functions.
-
-    Mostly used for patch reconstruction
-
-    Note from 11/15/2024: Pytorch lightning really doesn't like LambdaLayers. 
-    Will treat them as if they were identity operations.
-    Replaced all LambdaLayers in the forward model with their respective helper functions
-    '''
-    def __init__(self, func):
-        super(LambdaLayer, self).__init__()
-        self.func = func
-    
-    def forward(self, *args, **kwargs):
-        return self.func(*args, **kwargs)
-    
-class PoissonIntensityLayer(nn.Module):
-    '''
-    Applies poisson intensity scaling using torch.distributions
-    Calculates the negative log likelihood of observing the raw data given the predicted intensities
-
-    '''
-    def __init__(self, amplitudes):
-        super(PoissonIntensityLayer, self).__init__()
-        #Poisson rate parameter (lambda)
-        Lambda = amplitudes ** 2
-        #Create Poisson distribution
-        #Second parameter (batch size) controls how many dimensions are summed over starting from the last
-        self.poisson_dist = dist.Independent(dist.Poisson(Lambda), 3)
-
-    def forward(self, x):
-        #Apply poisson distribution
-        return -self.poisson_dist.log_prob(x)
-    
-class ForwardModel(nn.Module):
-    '''
-    Forward model receiving complex object prediction, and applies physics-informed real space overlap
-    constraints to the solution space.
-
-    Inputs
-    ------
-    x: torch.Tensor (N, C, H, W), dtype = complex64
-    positions: torch.Tensor (N, C, 1, 2), dtype = float32
-        Positions of patches in real space
-    probe: torch.Tensor, dtype = complex64
-        Probe function
-    '''
-    def __init__(self):
-        super(ForwardModel, self).__init__()
-
-        #Configuration 
-        self.n_filters_scale = ModelConfig().get('n_filters_scale')
-        self.N = DataConfig().get('N')
-        self.gridsize = DataConfig().get('grid_size')
-        self.offset = ModelConfig().get('offset')
-        self.object_big = ModelConfig().get('object.big')
-
-        #Patch operations
-        #Lambdalayer here doesn't work for lightning module
-        self.reassemble_patches = LambdaLayer(hh.reassemble_patches_position_real)
-
-        self.pad_patches = LambdaLayer(hh.pad_patches)
-
-        self.trim_reconstruction = LambdaLayer(hh.trim_reconstruction)
-
-        self.extract_patches = LambdaLayer(hh.extract_channels_from_region)
-
-        #Probe Illumination
-        self.probe_illumination = ProbeIllumination()
-
-        #Pad/diffract
-        
-        self.pad_and_diffract = LambdaLayer(hh.pad_and_diffract)
-
-        #Intensity scaling
-        self.scaler = IntensityScalerModule()
-
-        
-    def forward(self, x, positions, probe, scale_factor):
-        #Reassemble patches
-        #Object_big: All patches are together in a solution region
-        if self.object_big:
-            reassembled_obj = hh.reassemble_patches_position_real(x, positions)
-            #Extract patches
-            extracted_patch_objs = hh.extract_channels_from_region(reassembled_obj[:,None,:,:], positions)
-        else:
-        #Single channel, no patch overlap
-            #NOTE for albert: Check transformation math
-            #Temporarily removed because it seemed superfluous
-            # reassembled_obj = self.pad_patches(
-            #     torch.flatten(x, start_dim = 0, end_dim = 1),
-            #     padded_size = hh.get_padded_size()
-            # )
-            extracted_patch_objs = x
-
-
-        #Apply probe illum
-        illuminated_objs, _ = self.probe_illumination(extracted_patch_objs,
-                                                    probe)
-        #Pad and diffract
-        pred_diffraction, _ = hh.pad_and_diffract(illuminated_objs,
-                                                    pad = False)
-        #Inverse scaling
-        pred_amp_scaled = self.scaler.inv_scale(pred_diffraction, scale_factor)
-
-        return pred_amp_scaled
-        
-        # #Performing inference
-        # else:
-        #     return extracted_patch_objs
-
-#Loss functions
-        
-class PoissonLoss(nn.Module):
-    def __init__(self):
-        super(PoissonLoss, self).__init__()
-    
-    def forward(self, pred, raw):
-        self.poisson = PoissonIntensityLayer(pred)
-        loss_likelihood = self.poisson(raw)
-
-        return loss_likelihood
-    
-class MAELoss(nn.Module):
-    def __init__(self):
-        super(MAELoss, self).__init__()
-        self.mae = nn.L1Loss(reduction = 'none')
-
-    def forward(self, pred, raw):
-        #Note: Prediction has not been squared yet, must be squared here
-        loss_mae = self.mae(pred**2, raw)
-
-        return loss_mae
-    
-#Scaling modules
-
-# # Example usage
-# # Assuming cfg is a dictionary with the key 'intensity_scale' and appropriate value
-# cfg = {'intensity_scale': 1.0}
-# params = lambda: {'intensity_scale.trainable': True}
-
-# # Initialize the module
-# scaler_module = IntensityScalerModule(cfg, params)
-
-# # Apply scaling and inverse scaling
-# scaled_tensor = scaler(input_tensor)
-# inv_scaled_tensor = inv_scaler(input_tensor)
-
-class IntensityScalerModule:
-    '''
-    Scaler module that works with single experiment data and multi-experiment data.
-
-    If single experiment data, ModelConfig will have an "intensity_scale" parameter that is determined
-    during the dataloading process. This is to set up log_scale as a learnable parameter.
-
-    If multi-experiment data, log_scale is no longer learnable since there are multiple different experiments
-    and different log_scales to learn.
-    '''
-    def __init__(self):
-        #Setting log scale values
-        if ModelConfig().get('intensity_scale_trainable'):
-            log_scale_guess = np.log(ModelConfig().get('intensity_scale'))
-            self.log_scale = nn.Parameter(torch.tensor(float(log_scale_guess)),
-                                      requires_grad = ModelConfig().get('intensity_scale_trainable'))
-        else:
-            self.log_scale = None
-    
-    #Intensity scaler as class
-    class IntensityScaler(nn.Module):
-        '''
-        Scales intensity with log scale factor. Supports inverse and regular scaling
-        '''
-        def __init__(self, log_scale, inv = False):
-            super(IntensityScalerModule.IntensityScaler, self).__init__()
-            self.scale_factor = torch.exp(log_scale)
-            if inv:
-                self.scale_factor = 1 / self.scale_factor
-
-        def forward(self, x):
-            return x / self.scale_factor
-        
-    #Standalone intensity scaling functions
-    def scale(self, x, scale_factor):
-        if self.log_scale:
-            log_scale = torch.exp(self.log_scale)
-        else:
-            log_scale = scale_factor
-        return x * log_scale
-
-    def inv_scale(self, x, scale_factor):
-        '''
-        Undoes the scaling operation, goes from normalized space -> experimental space
-        '''
-        if self.log_scale:
-            log_scale = torch.exp(self.log_scale)
-        else:
-            log_scale = scale_factor
-        return x / log_scale
-
-#Full module with everything
-class PtychoPINN(nn.Module):
-    '''
-    Full PtychoPINN module with all sub-modules.
-    If in training, outputs loss and reconstruction
-    If in inference, outputs object functions
-    
-    Note for forward call, because we're getting data from a memory-mapped tensor
-
-    Inputs
-    -------
-    x: torch.Tensor (N, C, H, W)
-    positions - Tensor input, comes from tensor['coords_relative']
-    probe - Tensor input, comes from dataset/dataloader __get__ function (returns x, probe)
-
-    '''
-    def __init__(self):
-        super(PtychoPINN, self).__init__()
-        self.n_filters_scale = ModelConfig().get('n_filters_scale')
-        self.device = TrainingConfig().get('device')
-        self.predict = False
-        #Autoencoder
-        self.autoencoder = Autoencoder(self.n_filters_scale)
-        self.combine_complex = CombineComplex()
-        #Adding named modules for forward operation
-        #Patch operations
-        self.forward_model = ForwardModel()
-        #Choose loss function
-        if ModelConfig().get('loss_function') == 'Poisson':
-            self.Loss = PoissonLoss()
-        elif ModelConfig().get('loss_function') == 'MAE':
-            self.Loss = MAELoss()
-
-    def forward(self, x, positions, probe, scale_factor):
-        #Autoencoder result
-        x_amp, x_phase = self.autoencoder(x)
-        #Combine amp and phase
-        x_combined = self.combine_complex(x_amp, x_phase)
-        if self.predict:
-            return x_combined
-        else:
-            #Run through forward model
-            scale_factor = scale_factor.view(-1, 1, 1, 1)
-            x_out = self.forward_model(x_combined, positions, probe, scale_factor)
-            #Get loss
-            if self.training:
-                return self.Loss(x_out, x)
-
-            return x_out
-            
diff --git a/build/lib/ptycho_torch/patch_generator.py b/build/lib/ptycho_torch/patch_generator.py
deleted file mode 100644
index 89cd842..0000000
--- a/build/lib/ptycho_torch/patch_generator.py
+++ /dev/null
@@ -1,152 +0,0 @@
-
-import numpy as np
-from scipy.spatial import cKDTree
-from ptycho_torch.config_params import TrainingConfig, DataConfig, ModelConfig
-#All methods for patch generation that used to be in loader will go here
-#Will be imported into dset_loader for generating patches of grid_size ** 2
-
-def get_neighbor_diffraction_and_positions(PtychoDataset, index, N, K=6, C=None, nsamples=10):
-    """
-    UNUSED CURENTLY
-    Returns, for a single experimental dataset, the relative offsets and coordinates for nearest neighboring groups of diffraction
-    images of stack size grid_size ** 2. Can be iteratively run to calculate for all experiments
-
-    Difference from PtychoPINN V1 (tf_helper):
-    diff4d_nn is not calculated in this function. We will be calculating diff4d_nn when writing
-    the memmap. 
-    ---
-    Inputs:
-    PtychoDataset - Dataset object from dset_loader. Contains all relevant dataset information
-        - image_map: shape (N x M* x H x W). M* is the number of diffraction patterns per
-          experiment. N is # of diffraction experiments
-    Index - Index of diffraction experiment to be used. First dimension of any tensor in dataset
-
-
-
-    """
-    
-    nn_indices, coords_nn = group_coords(PtychoDataset, index,
-                                         K = K, C = C, nsamples = nsamples)
-
-
-    #diff4d_nn = PtychoDataset.data_dict['diffraction'][index][nn_indices]
-
-    coords_offsets, coords_relative = get_relative_coords(coords_nn)
-
-    if PtychoDataset.data_dict['xstart'][index] is not None:
-        #Dimensions: M* x C x 1 x 2
-        coords_start_nn = np.stack(PtychoDataset[index].xcoords_start[nn_indices],
-                                   PtychoDataset[index].ycoords_start[nn_indices],
-                                   axis = 2)[:, :, None, :]
-        #coords_start_nn = coords_start_nn[:, :, ::-1, :]
-        coords_start_offsets, coords_start_relative = get_relative_coords(coords_start_nn)
-    else:
-        coords_start_offsets = coords_start_relative = None
-
-    #Adding other relevant parameters to data dict
-    PtychoDataset.data_dict['coords_offsets'] = coords_offsets
-    PtychoDataset.data_dict['coords_relative'] = coords_relative
-    PtychoDataset.data_dict['coords_start_offsets'] = coords_start_offsets
-    PtychoDataset.data_dict['coords_start_relative'] = coords_start_relative
-    PtychoDataset.data_dict['coords_nn'] = coords_nn
-    PtychoDataset.data_dict['coords_start_nn'] = coords_start_nn
-    PtychoDataset.data_dict['nn_indices'] = nn_indices
-
-    dset = {
-        'diffraction': diff4d_nn,
-        'coords_offsets': coords_offsets,
-        'coords_relative': coords_relative,
-        'coords_start_offsets': coords_start_offsets,
-        'coords_start_relative': coords_start_relative,
-        'coords_nn': coords_nn,
-        'coords_start_nn': coords_start_nn,
-        'nn_indices': nn_indices,
-        'objectGuess': ptycho_data.objectGuess
-    }
-    X_full = normalize_data(dset, N)
-    dset['X_full'] = X_full
-    print('neighbor-sampled diffraction shape', X_full.shape)
-    return dset
-
-def group_coords(xcoords, ycoords, C):
-    """
-    Assemble a flat dataset into solution regions using nearest-neighbor grouping.
-    ---
-    Inputs:
-    PtychoDataset - Dataset object from dset_loader. Contains all relevant dataset information
-    Index - Index of diffraction experiment to be used. First dimension of any tensor in dataset
-    K - Number of nearest neighbors to select from
-    C - Number of total images in a single solution region (i.e. K choose C for a single solution region)
-    nsamples - Number of distinct solution regions to sample from the K nearest neighbors
-               (e.g.) nsamples = 10, K = 6, C = 4. 6C4 = 15 but only 10 will be selected
-
-    Returns:
-        nn_indices: shape (M, C), M = total number of solution regions
-        coords_nn: shape (M, C, 1, 2)
-    """
-    if C is None:
-        C = DataConfig().get('C')
-    #No overlaps enforced
-    if C == 1:
-        nn_indices = get_neighbor_self_indices(xcoords,
-                                               ycoords)
-    #Yes overlaps enforced
-    else:
-        nn_indices = get_neighbor_indices(xcoords,
-                                          ycoords, K=DataConfig().get('K'))
-        nn_indices = sample_rows(nn_indices, C, DataConfig().get('n_subsample')).reshape(-1, C)
-
-    #Get final array of coordinates (M* x C x 1 x 2)
-    coords_nn = np.stack([xcoords[nn_indices],
-                          ycoords[nn_indices]],axis=2)[:, :, None, :]
-    
-    return nn_indices, coords_nn
-
-def get_neighbor_self_indices(xcoords, ycoords):
-    """
-    Assign each pattern index to itself
-    """
-    N = len(xcoords)
-    nn_indices = np.arange(N).reshape(N, 1) 
-    return nn_indices
-
-def get_neighbor_indices(xcoords, ycoords, K = 6):
-    # Combine x and y coordinates into a single array
-    points = np.column_stack((xcoords, ycoords))
-
-    # Create a KDTree
-    tree = cKDTree(points)
-
-    # Query for K nearest neighbors for each point
-    distances, nn_indices = tree.query(points, k=K+1)  # +1 because the point itself is included in the results
-    return nn_indices
-
-def sample_rows(indices, n, m):
-    N = indices.shape[0]
-    result = np.zeros((N, m, n), dtype=int)
-    for i in range(N):
-        result[i] = np.array([np.random.choice(indices[i], size=n, replace=False) for _ in range(m)])
-    return result
-
-def get_relative_coords(coords_nn, local_offset_sign=1):
-    """
-    Calculate the relative coordinates and offsets from the nearest neighbor coordinates.
-
-    Args:
-        coords_nn (np.ndarray): Array of nearest neighbor coordinates with shape (M, C, 1, 2).
-
-    Returns:
-        tuple: A tuple containing coords_offsets and coords_relative.
-        coords_relative: Array of relative coordinates with shape (M, C, 1, 2).
-        coords_offsets: Array of offsets with shape (M, 1, 1, 2).
-    """
-    assert len(coords_nn.shape) == 4
-    #Center of mass coordinate for every combination of coordinates
-    coords_offsets = np.mean(coords_nn, axis=1)[:, None, :, :]
-    #Subtract center of mass coordinate from every coordinate to get relative coordinate
-    #coords_offsets is broadcast to match second dimension of coords_nn
-    coords_relative = local_offset_sign * (coords_nn - coords_offsets)
-
-    return coords_offsets, coords_relative
-
-
diff --git a/build/lib/ptycho_torch/train.py b/build/lib/ptycho_torch/train.py
deleted file mode 100644
index 68cd83d..0000000
--- a/build/lib/ptycho_torch/train.py
+++ /dev/null
@@ -1,234 +0,0 @@
-#Most basic modules
-import sys
-import argparse
-import os
-
-#ML libraries
-import torch
-from torch import nn
-from torch.nn import functional as F
-from torch.utils.data import Subset
-
-#Automation modules
-#Lightning
-import lightning as L
-#MLFlow
-import mlflow.pytorch
-from mlflow import MlflowClient
-
-#Configs/Params
-from ptycho_torch.config_params import ModelConfig, TrainingConfig, DataConfig
-from ptycho_torch.config_params import data_config_default, model_config_default, training_config_default
-
-#Dataloader
-from ptycho_torch.dset_loader_pt_mmap import TensorDictDataLoader, PtychoDataset
-
-#Custom modules
-from ptycho_torch.model import Autoencoder, CombineComplex, ForwardModel, PoissonLoss, MAELoss
-
-#Helper function for mlflow
-def print_auto_logged_info(r):
-    tags = {k: v for k, v in r.data.tags.items() if not k.startswith("mlflow.")}
-    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, "model")]
-    print(f"run_id: {r.info.run_id}")
-    print(f"artifacts: {artifacts}")
-    print(f"params: {r.data.params}")
-    print(f"metrics: {r.data.metrics}")
-    print(f"tags: {tags}")
-
-# mlflow.set_tracking_uri("http://127.0.0.1:5000")
-# mlflow.set_experiment("PtychoPINN")
-
-
-class PtychoPINN(L.LightningModule):
-    '''
-    Lightning module equivalent of PtychoPINN module from ptycho_torch.model
-    We initialize all hyperparameters within here so that the Lightning trainer checkpoints it all
-    '''
-    def __init__(self):
-        super().__init__()
-        self.n_filters_scale = ModelConfig().get('n_filters_scale')
-        self.predict = False
-        #Autoencoder
-        self.autoencoder = Autoencoder(self.n_filters_scale)
-        self.combine_complex = CombineComplex()
-        #Adding named modules for forward operation
-        #Patch operations
-        self.forward_model = ForwardModel()
-
-        #Choose loss function
-        if ModelConfig().get('loss_function') == 'Poisson':
-            self.Loss = PoissonLoss()
-        elif ModelConfig().get('loss_function') == 'MAE':
-            self.Loss = MAELoss()
-    
-    def forward(self, x, positions, probe, scale_factor):
-        #Autoencoder result
-        x_amp, x_phase = self.autoencoder(x)
-        #Combine amp and phase
-        x_combined = self.combine_complex(x_amp, x_phase)
-        #Run through forward model
-        scale_factor = scale_factor.view(-1, 1, 1, 1)
-        x_out = self.forward_model.forward(x_combined, positions, probe * 2/3, scale_factor)
-
-        return x_out
-    
-    def forward_predict(self, x, positions, probe, scale_factor):
-        #Autoencoder result
-        x_amp, x_phase = self.autoencoder(x)
-        #Combine amp and phase
-        x_combined = self.combine_complex(x_amp, x_phase)
-
-        return x_combined
-    
-    def training_step(self, batch):
-        #Grab required data fields from TensorDict
-        x, positions, probe, scale = batch[0]['images'], \
-                                     batch[0]['coords_relative'], \
-                                     batch[1], \
-                                     batch[2]
-        #Run through forward model
-        pred = self(x, positions, probe, scale)
-
-        #Calculate loss
-        loss = self.Loss(pred, x).sum()
-
-        #Logging
-        if ModelConfig().get('loss_function') == 'Poisson':
-            self.log("poisson_train_loss", loss, on_epoch = True)
-        elif ModelConfig().get('loss_function') == 'MAE':
-            self.log("mae_train_loss", loss, on_epoch = True)
-        
-
-        return loss
-    
-    def predict_step(self, batch):
-        #Grab required data fields from TensorDict
-        x, positions, probe, scale = batch[0]['images'], \
-                                     batch[0]['coords_relative'], \
-                                     batch[1], \
-                                     batch[2]
-        
-        #Run through part of forward model
-        pred = self(x, positions, probe, scale)
-
-        return pred
-
-    def configure_optimizers(self):
-        optimizer = torch.optim.Adam(self.parameters(), lr = 2e-3)
-
-        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
-
-        return {
-                "optimizer": optimizer,
-                "lr_scheduler": scheduler
-                }
-
-#Training functions
-
-#Custom collation function which pins memory in order to transfer to gpu
-#Taken from: https://pytorch.org/tensordict/stable/tutorials/tensorclass_imagenet.html
-class Collate(nn.Module):
-    def __init__(self, device = None):
-        super().__init__()
-        self.device = torch.device(device)
-    def __call__(self, x):
-        '''
-        Moves tensor to RAM, and then to GPU.
-
-        Inputs
-        -------
-        x: TensorDict
-        '''
-        #Move data from memory map to RAM
-        if self.device.type == 'cuda':
-            out = x.pin_memory()
-        else: #cpu
-            out = x
-        #Then Ram to GPU
-        if self.device:
-            out = out.to(self.device)
-        return out
-
-def main(ptycho_dir, probe_dir):
-    #Define configs
-    print('Loading configs...')
-    modelconfig = ModelConfig()
-    trainingconfig = TrainingConfig()
-    dataconfig = DataConfig()
-
-    #Set configs
-    modelconfig.set_settings(model_config_default)
-    trainingconfig.set_settings(training_config_default)
-    dataconfig.set_settings(data_config_default)
-
-    #Modify specific settings here
-    dataconfig.add('N', 64)
-    dataconfig.add('normalize', False)
-
-    modelconfig.add('object.big', False)
-    modelconfig.add('probe.big', False)
-
-
-    #Creating dataset
-    print('Creating dataset...')
-    ptycho_dataset = PtychoDataset(ptycho_dir, probe_dir, remake_map=True)
-
-    #Dataloader
-    print('Creating dataloader...')
-    train_loader = TensorDictDataLoader(ptycho_dataset, batch_size = 64,
-                                        collate_fn = Collate(device = TrainingConfig().get('device')))
-
-    #Create model
-    print('Creating model...')
-    model = PtychoPINN()
-    model.training = True
-
-    #Create trainer
-    trainer = L.Trainer(max_epochs = 3,
-                        default_root_dir = os.path.dirname(os.getcwd()),
-                        devices = 'auto',
-                        accelerator = 'gpu',
-                        gradient_clip_val = 1,
-                        # strategy = TrainingConfig().get('strategy'),
-                        )#accumulate_grad_batches=3)
-
-    #Mlflow setup
-    # mlflow.set_tracking_uri("")
-    mlflow.set_experiment("PtychoPINN vanilla")
-
-    mlflow.pytorch.autolog(checkpoint_monitor = "mae_train_loss")
-
-    #Train the model
-    with mlflow.start_run() as run:
-        print('Training model...')
-        trainer.fit(model, train_loader)
-
-    print_auto_logged_info(mlflow.get_run(run_id = run.info.run_id))
-
-#Define main function
-if __name__ == '__main__':
-    #Parsing
-    parser = argparse.ArgumentParser(description = "Run training for ptycho_torch")
-    #Arguments
-    parser.add_argument('--ptycho_dir', type = str, help = 'Path to ptycho directory')
-    parser.add_argument('--probe_dir', type = str, help = 'Path to probe directory')
-    #Parse
-    args = parser.parse_args()
-
-    #Assign to vars
-    ptycho_dir = args.ptycho_dir
-    probe_dir = args.probe_dir
-
-    print(f"Probe: {probe_dir}")
-    print(f"Ptycho: {ptycho_dir}")
-
-    print(os.getcwd())
-
-    try:
-        main('datasets/lines_no_overlap_diff',
-             'datasets/probes_lines')
-
-    except Exception as e:
-        print(f"Training failed: {str(e)}")
-        sys.exit(1)
diff --git a/build/lib/ptycho_torch/train_dummy.py b/build/lib/ptycho_torch/train_dummy.py
deleted file mode 100644
index 68ceca0..0000000
--- a/build/lib/ptycho_torch/train_dummy.py
+++ /dev/null
@@ -1,76 +0,0 @@
-import os
-
-import lightning as L
-import torch
-from torch.nn import functional as F
-from torch.utils.data import DataLoader, Subset
-from torchmetrics import Accuracy
-from torchvision import transforms
-from torchvision.datasets import MNIST
-
-import mlflow.pytorch
-from mlflow import MlflowClient
-
-mlflow.set_tracking_uri("http://127.0.0.1:5000")
-mlflow.set_experiment("MNIST_test")
-
-
-class MNISTModel(L.LightningModule):
-    def __init__(self):
-        super().__init__()
-        self.l1 = torch.nn.Linear(28 * 28, 10)
-        self.accuracy = Accuracy("multiclass", num_classes=10)
-
-    def forward(self, x):
-        return torch.relu(self.l1(x.view(x.size(0), -1)))
-
-    def training_step(self, batch, batch_nb):
-        x, y = batch
-        logits = self(x)
-        loss = F.cross_entropy(logits, y)
-        pred = logits.argmax(dim=1)
-        acc = self.accuracy(pred, y)
-
-        # PyTorch `self.log` will be automatically captured by MLflow.
-        self.log("train_loss", loss, on_epoch=True)
-        self.log("acc", acc, on_epoch=True)
-        return loss
-
-    def configure_optimizers(self):
-        return torch.optim.Adam(self.parameters(), lr=0.02)
-
-
-def print_auto_logged_info(r):
-    tags = {k: v for k, v in r.data.tags.items() if not k.startswith("mlflow.")}
-    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, "model")]
-    print(f"run_id: {r.info.run_id}")
-    print(f"artifacts: {artifacts}")
-    print(f"params: {r.data.params}")
-    print(f"metrics: {r.data.metrics}")
-    print(f"tags: {tags}")
-
-
-# Initialize our model.
-mnist_model = MNISTModel()
-
-# Load MNIST dataset.
-train_ds = MNIST(
-    os.getcwd(), train=True, download=True, transform=transforms.ToTensor()
-)
-# Only take a subset of the data for faster training.
-indices = torch.arange(32)
-train_ds = Subset(train_ds, indices)
-train_loader = DataLoader(train_ds, batch_size=8)
-
-# Initialize a trainer.
-trainer = L.Trainer(max_epochs=10)
-
-# Auto log all MLflow entities
-mlflow.pytorch.autolog(checkpoint_monitor = "acc")
-
-# Train the model.
-with mlflow.start_run() as run:
-    trainer.fit(mnist_model, train_loader)
-
-# Fetch the auto logged parameters and metrics.
-print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))
\ No newline at end of file
diff --git a/build/lib/scripts/inference/README.md b/build/lib/scripts/inference/README.md
deleted file mode 100644
index 86d6ca4..0000000
--- a/build/lib/scripts/inference/README.md
+++ /dev/null
@@ -1,69 +0,0 @@
-# PtychoPINN Inference Script
-
-This script performs inference using a trained instance of PtychoPINN on test data and generates reconstruction results.
-
-## Prerequisites
-
-- PtychoPINN package
-
-## Usage
-
-```bash
-python inference_script.py --model_prefix <model_prefix> --test_data <test_data_file> [--output_path <output_path>] [--visualize_probe] [--K <K>] [--nsamples <nsamples>]
-```
-
-## Arguments
-
-- `--model_prefix`: (Required) Path prefix for the saved model and its configuration.
-- `--test_data`: (Required) Path to the .npz file containing test data.
-- `--output_path`: (Optional) Path prefix for saving output files and images. Default is './'.
-- `--visualize_probe`: (Optional) Flag to generate and save probe visualization.
-- `--K`: (Optional) Number of nearest neighbors for grouped data generation. Default is 7.
-- `--nsamples`: (Optional) Number of samples for grouped data generation. Default is 1.
-
-## Example
-
-```bash
-python inference_script.py --model_prefix models/my_model --test_data data/test_data.npz --output_path results/ --visualize_probe
-```
-
-## Input Data Format
-
-The script expects the test data to be in .npz format with the following arrays:
-
-- `xcoords`: x coordinates of the scan points
-- `ycoords`: y coordinates of the scan points
-- `xcoords_start`: starting x coordinates for the scan
-- `ycoords_start`: starting y coordinates for the scan
-- `diffraction`: diffraction patterns
-- `probeGuess`: initial guess of the probe function
-- `objectGuess`: initial guess of the object
-
-## Output
-
-The script generates the following outputs:
-
-1. A comparison image (`reconstruction_comparison.png`) showing:
-   - Reconstructed amplitude
-   - Reconstructed phase
-   - ePIE amplitude
-   - ePIE phase
-2. If `--visualize_probe` is used, a probe visualization image (`probe_visualization.png`)
-3. Log file (`inference.log`) with detailed information about the inference process
-
-All outputs are saved in the specified output directory.
-
-## Process
-
-1. The script first loads the trained model and its configuration.
-2. It then loads the test data from the provided .npz file.
-3. Inference is performed using the loaded model and test data.
-4. The results are processed to generate the comparison image.
-5. If requested, a probe visualization is generated.
-
-## Notes
-
-- The script uses logging to provide information about the process. Check the console output and log file for details.
-- Ensure that the model files (saved using the training script) are located at the path specified by `model_prefix`.
-- The `K` and `nsamples` parameters can be adjusted to experiment with different data grouping strategies.
-
diff --git a/build/lib/scripts/inference/inference.py b/build/lib/scripts/inference/inference.py
deleted file mode 100644
index 41951e8..0000000
--- a/build/lib/scripts/inference/inference.py
+++ /dev/null
@@ -1,384 +0,0 @@
-#!/usr/bin/env python
-# coding: utf-8
-# TODO needs to be updated to use the new-style config dataclasses
-# MAYBE only generate the comparison plot when ground truth object is provided
-# MAYBE save output to npz file, not just image
-
-"""
-Inference script for ptychography reconstruction.
-
-This script loads a trained model and test data, performs inference,
-and saves the reconstructed image comparison and optionally a probe visualization.
-
-Usage:
-    python inference_script.py --model_prefix <model_prefix> --test_data <test_data_file> [--output_path <output_path>]
-                               [--visualize_probe] [--K <K>] [--nsamples <nsamples>]
-
-Arguments:
-    --model_prefix: Path prefix for the saved model and its configuration
-    --test_data: Path to the .npz file containing test data
-    --output_path: Path prefix for saving output files and images (default: './')
-    --visualize_probe: Flag to generate and save probe visualization
-    --K: Number of nearest neighbors for grouped data generation (default: 7)
-    --nsamples: Number of samples for grouped data generation (default: 1)
-"""
-
-from typing import Optional
-import argparse
-import logging
-import os
-import sys
-import time
-import signal
-from pathlib import Path
-import numpy as np
-import tensorflow as tf
-import matplotlib.pyplot as plt
-from ptycho import probe, params, train_pinn
-from ptycho.model_manager import ModelManager
-from ptycho.raw_data import RawData
-from ptycho.workflows.components import load_data, setup_configuration, parse_arguments
-from ptycho.config.config import InferenceConfig, ModelConfig, validate_inference_config, update_legacy_dict
-
-# Set up logging
-logging.basicConfig(level=logging.INFO,
-                    format='%(asctime)s - %(levelname)s - %(message)s',
-                    handlers=[
-                        logging.StreamHandler(sys.stdout),
-                        logging.FileHandler('inference.log')
-                    ])
-logger = logging.getLogger(__name__)
-
-# Redirect print statements to logger
-print = logger.info
-
-# Global flag for graceful shutdown
-shutdown_requested = False
-
-def signal_handler(signum, frame):
-    global shutdown_requested
-    shutdown_requested = True
-    print(f"Received signal {signum}. Initiating graceful shutdown...")
-
-# Register signal handlers
-signal.signal(signal.SIGINT, signal_handler)
-signal.signal(signal.SIGTERM, signal_handler)
-
-def parse_arguments() -> argparse.Namespace:
-    """Parse command line arguments."""
-    parser = argparse.ArgumentParser(description="Ptychography Inference Script")
-    parser.add_argument("--model_path", type=str, required=True,
-                       help="Path to the saved model")
-    parser.add_argument("--test_data", type=str, required=True,
-                       help="Path to the test data file")
-    parser.add_argument("--config", type=str, required=False, default=None,
-                       help="Optional path to YAML configuration file to override defaults")
-    parser.add_argument("--output_dir", type=str, default='inference_outputs',
-                       help="Directory for saving output files and images")
-    parser.add_argument("--debug", action="store_true",
-                       help="Enable debug mode")
-    return parser.parse_args()
-
-def setup_inference_configuration(args: argparse.Namespace, yaml_path: Optional[str]) -> InferenceConfig:
-    """Setup inference configuration from arguments and YAML file."""
-    if yaml_path:
-        base_config = setup_configuration(args, yaml_path)
-        model_config = base_config.model
-    else:
-        # Use default ModelConfig when no YAML provided
-        model_config = ModelConfig()
-    
-    inference_config = InferenceConfig(
-        model=model_config,
-        model_path=Path(args.model_path),
-        test_data_file=Path(args.test_data),
-        debug=args.debug,
-        output_dir=Path(args.output_dir)
-    )
-    
-    validate_inference_config(inference_config)
-    return inference_config
-
-
-def load_model(model_path: Path) -> tuple:
-    """Load the saved model and its configuration."""
-    try:
-        print(f"Attempting to load model from: {model_path}")
-        print(f"Current working directory: {os.getcwd()}")
-        
-        # Check if the path is a directory and contains wts.h5.zip
-        model_zip = os.path.join(model_path, "wts.h5")
-        if not os.path.exists(f"{model_zip}.zip"):
-            raise ValueError(f"Model archive not found at: {model_zip}.zip")
-            
-        # Load multiple models
-        models_dict = ModelManager.load_multiple_models(model_zip)
-        
-        # Get the diffraction_to_obj model which is what we need for inference
-        if 'diffraction_to_obj' not in models_dict:
-            raise ValueError("No diffraction_to_obj model found in saved models")
-            
-        model = models_dict['diffraction_to_obj']
-        config = params.cfg  # ModelManager updates global config when loading
-
-        print(f"Successfully loaded model from {model_path}")
-        print(f"Model configuration: {config}")
-
-        return model, config
-
-    except Exception as e:
-        raise ValueError(f"Failed to load model: {str(e)}")
-
-def perform_inference(model: tf.keras.Model, test_data: RawData, config: dict, K: int, nsamples: int) -> tuple:
-    """
-    Perform inference using the loaded model and test data.
-
-    Args:
-        model (tf.keras.Model): The loaded TensorFlow model.
-        test_data (RawData): The RawData object containing test data.
-        config (dict): The model's configuration dictionary.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Returns:
-        tuple: (np.ndarray, np.ndarray, np.ndarray, np.ndarray) - Reconstructed amplitude, 
-               reconstructed phase, ePIE amplitude, and ePIE phase.
-
-    Raises:
-        ValueError: If there's an error during inference.
-    """
-    from ptycho.nbutils import reconstruct_image, crop_to_non_uniform_region_with_buffer
-    try:
-        # Set probe guess
-        probe.set_probe_guess(None, test_data.probeGuess)
-
-        # Set random seeds
-        tf.random.set_seed(45)
-        np.random.seed(45)
-
-        # Generate grouped data
-        test_dataset = test_data.generate_grouped_data(config['N'], K=K, nsamples=nsamples)
-        
-        # Create PtychoDataContainer
-        from ptycho import loader
-        test_data_container = loader.load(lambda: test_dataset, test_data.probeGuess, which=None, create_split=False)
-        
-        # Perform reconstruction
-        start_time = time.time()
-        obj_tensor_full, global_offsets = reconstruct_image(test_data_container, diffraction_to_obj=model)
-        reconstruction_time = time.time() - start_time
-        print(f"Reconstruction completed in {reconstruction_time:.2f} seconds")
-
-        # Process the reconstructed image
-        from ptycho.tf_helper import reassemble_position
-        obj_image = reassemble_position(obj_tensor_full, global_offsets, M=20)
-        
-        # Extract amplitude and phase
-        reconstructed_amplitude = np.abs(obj_image)
-        reconstructed_phase = np.angle(obj_image)
-
-#        # Process ePIE results for comparison
-#        epie_phase = crop_to_non_uniform_region_with_buffer(np.angle(test_data.objectGuess), buffer=-20)
-#        epie_amplitude = crop_to_non_uniform_region_with_buffer(np.abs(test_data.objectGuess), buffer=-20)
-        epie_phase = np.angle(test_data.objectGuess)
-        epie_amplitude = np.abs(test_data.objectGuess)
-
-        print(f"Reconstructed amplitude shape: {reconstructed_amplitude.shape}")
-        print(f"Reconstructed phase shape: {reconstructed_phase.shape}")
-        print(f"ePIE amplitude shape: {epie_amplitude.shape}")
-        print(f"ePIE phase shape: {epie_phase.shape}")
-
-        return reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase
-
-    except Exception as e:
-        print(f"Error during inference: {str(e)}")
-        raise ValueError(f"Error during inference: {str(e)}")
-
-def save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_path):
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Create the comparison figure with a smaller size
-        fig, axs = plt.subplots(2, 2, figsize=(4, 4))
-        
-        # PtychoPINN phase
-        im_pinn_phase = axs[0, 0].imshow(reconstructed_phase, cmap='gray')
-        axs[0, 0].set_title('PtychoPINN Phase')
-        fig.colorbar(im_pinn_phase, ax=axs[0, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE phase
-        im_epie_phase = axs[0, 1].imshow(epie_phase, cmap='gray')
-        axs[0, 1].set_title('ePIE Phase')
-        fig.colorbar(im_epie_phase, ax=axs[0, 1], fraction=0.046, pad=0.04)
-        
-        # PtychoPINN amplitude
-        im_pinn_amp = axs[1, 0].imshow(reconstructed_amplitude, cmap='viridis')
-        axs[1, 0].set_title('PtychoPINN Amplitude')
-        fig.colorbar(im_pinn_amp, ax=axs[1, 0], fraction=0.046, pad=0.04)
-        
-        # ePIE amplitude
-        im_epie_amp = axs[1, 1].imshow(epie_amplitude, cmap='viridis')
-        axs[1, 1].set_title('ePIE Amplitude')
-        fig.colorbar(im_epie_amp, ax=axs[1, 1], fraction=0.046, pad=0.04)
-        
-        # Remove axis ticks
-        for ax in axs.flat:
-            ax.set_xticks([])
-            ax.set_yticks([])
-        
-        # Adjust layout with specific padding
-        plt.tight_layout(pad=1.5)
-        
-        # Save the figure with adjusted DPI and ensuring the entire figure is saved
-        plt.savefig(output_path, dpi=300, bbox_inches='tight', pad_inches=0.5)
-        plt.close(fig)
-
-        print(f"Comparison image saved to: {output_path}")
-
-    except Exception as e:
-        print(f"Error saving comparison image: {str(e)}")
-
-def save_probe_visualization(test_data: RawData, output_path: str):
-    """
-    Generate and save the probe visualization.
-
-    Args:
-        test_data (RawData): The RawData object containing test data.
-        output_path (str): Path to save the probe visualization.
-
-    Raises:
-        OSError: If there's an error creating the output directory or saving the image.
-    """
-    from ptycho.nbutils import probeshow
-    try:
-        # Ensure output directory exists
-        os.makedirs(os.path.dirname(output_path), exist_ok=True)
-
-        # Generate the probe visualization
-        fig = probeshow(test_data.probeGuess, test_data)
-        
-        # Save the figure
-        fig.savefig(output_path, dpi=300, bbox_inches='tight')
-        plt.close(fig)
-
-        print(f"Probe visualization saved to: {output_path}")
-
-    except OSError as e:
-        raise OSError(f"Error saving probe visualization: {str(e)}")
-
-def main(model_prefix: str, test_data_file: str, output_path: str, visualize_probe: bool, K: int, nsamples: int) -> None:
-    """
-    Main function to orchestrate the inference process.
-
-    Args:
-        model_prefix (str): Path prefix for the saved model and its configuration.
-        test_data_file (str): Path to the .npz file containing test data.
-        output_path (str): Path prefix for saving output files and images.
-        visualize_probe (bool): Flag to generate and save probe visualization.
-        K (int): Number of nearest neighbors for grouped data generation.
-        nsamples (int): Number of samples for grouped data generation.
-
-    Raises:
-        Exception: If any error occurs during the inference process.
-    """
-    print("Starting inference process...")
-    start_time = time.time()
-
-    try:
-        # Load model
-        print("Loading model...")
-        model, config = load_model(model_prefix)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(test_data_file)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping inference process.")
-            return
-
-        # Perform inference
-        print(f"Performing inference with K={K} and nsamples={nsamples}...")
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(model, test_data, config, K, nsamples)
-
-        # Check for shutdown request
-        if shutdown_requested:
-            print("Shutdown requested. Stopping before saving results.")
-            return
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = os.path.join(output_path, "reconstruction_comparison.png")
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase, output_image_path)
-
-        # Save probe visualization if requested
-        if visualize_probe:
-            print("Generating and saving probe visualization...")
-            probe_output_path = os.path.join(output_path, "probe_visualization.png")
-            save_probe_visualization(test_data, probe_output_path)
-
-        print("Inference process completed successfully.")
-
-    except FileNotFoundError as e:
-        print(f"File not found error: {str(e)}")
-        raise
-    except ValueError as e:
-        print(f"Value error: {str(e)}")
-        raise
-    except OSError as e:
-        print(f"OS error: {str(e)}")
-        raise
-    except Exception as e:
-        print(f"An unexpected error occurred: {str(e)}")
-        raise
-    finally:
-        # Perform any necessary cleanup
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-    end_time = time.time()
-    print(f"Total execution time: {end_time - start_time:.2f} seconds")
-
-def main():
-    """Main entry point for the ptychography inference script."""
-    try:
-        print("Starting ptychography inference script...")
-        args = parse_arguments()
-        config = setup_inference_configuration(args, args.config)
-        
-        # Update global params with new-style config
-        update_legacy_dict(params.cfg, config)
-
-        # Load model
-        print("Loading model...")
-        model, _ = load_model(config.model_path)
-
-        # Load test data
-        print("Loading test data...")
-        test_data = load_data(args.test_data)
-
-        # Perform inference
-        print("Performing inference...")
-        # TODO might want to reduce K
-        reconstructed_amplitude, reconstructed_phase, epie_amplitude, epie_phase = perform_inference(
-            model, test_data, params.cfg, K=7, nsamples=1)
-
-        # Save comparison image
-        print("Saving comparison image...")
-        output_image_path = config.output_dir / "reconstruction_comparison.png"
-        save_comparison_image(reconstructed_amplitude, reconstructed_phase, 
-                            epie_amplitude, epie_phase, output_image_path)
-
-        print("Inference process completed successfully.")
-        sys.exit(0)
-    except Exception as e:
-        print(f"Script execution failed: {str(e)}")
-        sys.exit(1)
-    finally:
-        print("Cleaning up resources...")
-        tf.keras.backend.clear_session()
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/scripts/inspect_ptycho_data.py b/build/lib/scripts/inspect_ptycho_data.py
deleted file mode 100644
index 008d7f5..0000000
--- a/build/lib/scripts/inspect_ptycho_data.py
+++ /dev/null
@@ -1,73 +0,0 @@
-import numpy as np
-import matplotlib.pyplot as plt
-from ptycho.loader import PtychoDataContainer
-
-def load_ptycho_data(file_path: str) -> PtychoDataContainer:
-    """
-    Load the npz-serialized ptycho data.
-
-    Args:
-        file_path (str): Path to the npz file.
-
-    Returns:
-        PtychoDataContainer: Loaded ptycho data.
-    """
-    data = np.load(file_path, allow_pickle=True)
-    return PtychoDataContainer(
-        X=data['X'],
-        Y_I=data['Y_I'],
-        Y_phi=data['Y_phi'],
-        norm_Y_I=data['norm_Y_I'],
-        YY_full=data['YY_full'],
-        coords_nominal=data['coords_nominal'],
-        coords_true=data['coords_true'],
-        nn_indices=data['nn_indices'],
-        global_offsets=data['global_offsets'],
-        local_offsets=data['local_offsets'],
-        probeGuess=data['probe']
-    )
-
-def inspect_ptycho_frames(data: PtychoDataContainer, num_frames: int = 2):
-    """
-    Visually inspect a couple of frames from X, Y_I, and Y_phi.
-
-    Args:
-        data (PtychoDataContainer): Loaded ptycho data.
-        num_frames (int): Number of frames to display. Defaults to 2.
-    """
-    fig, axes = plt.subplots(3, num_frames, figsize=(5*num_frames, 15))
-    
-    for i in range(num_frames):
-        axes[0, i].imshow(data.X[i, ..., 0], cmap='viridis')
-        axes[0, i].set_title(f'X - Frame {i}')
-        axes[0, i].axis('off')
-        
-        axes[1, i].imshow(data.Y_I[i, ..., 0], cmap='viridis')
-        axes[1, i].set_title(f'Y_I - Frame {i}')
-        axes[1, i].axis('off')
-        
-        axes[2, i].imshow(data.Y_phi[i, ..., 0], cmap='viridis')
-        axes[2, i].set_title(f'Y_phi - Frame {i}')
-        axes[2, i].axis('off')
-    
-    plt.tight_layout()
-    plt.show()
-
-if __name__ == "__main__":
-    import sys
-
-    if len(sys.argv) < 2:
-        print("Usage: python inspect_ptycho_data.py <path_to_npz_file>")
-        sys.exit(1)
-
-    file_path = sys.argv[1]
-    
-    try:
-        # Load the data
-        ptycho_data = load_ptycho_data(file_path)
-        
-        # Inspect the frames
-        inspect_ptycho_frames(ptycho_data)
-    except Exception as e:
-        print(f"An error occurred: {e}")
-        sys.exit(1)
diff --git a/build/lib/scripts/simulation/README.md b/build/lib/scripts/simulation/README.md
deleted file mode 100644
index 35e74cf..0000000
--- a/build/lib/scripts/simulation/README.md
+++ /dev/null
@@ -1,73 +0,0 @@
-# PtychoPINN Simulation Script
-
-This script simulates ptychography data, generates visualizations, and performs a comparison between PtychoPINN and baseline reconstructions.
-
-## Prerequisites
-
-- PtychoPINN package
-
-## Usage
-
-python simulation.py <input_file> <output_dir> [options]
-
-## Arguments
-
-- `input_file`: (Required) Path to the input .npz file containing probe and object guesses.
-- `output_dir`: (Required) Directory to save output visualizations.
-
-## Options
-
-- `--nimages`: Number of images to simulate. Default is 2000.
-- `--seed`: Random seed for reproducibility.
-- `--nepochs`: Number of epochs for training. Default is 50.
-- `--output_prefix`: Prefix for output files. Default is "tmp".
-- `--intensity_scale_trainable`: Make intensity scale trainable. Default is False.
-- `--positions_provided`: Positions are provided. Default is True.
-- `--probe_big`: Use big probe. Default is True.
-- `--probe_mask`: Use probe mask. Default is False.
-- `--data_source`: Data source type. Default is "generic".
-- `--gridsize`: Grid size. Default is 1.
-- `--train_data_file_path`: Path to train data file.
-- `--test_data_file_path`: Path to test data file.
-- `--N`: Size of the simulation grid. Default is 128.
-- `--probe_scale`: Probe scale factor. Default is 4.
-- `--nphotons`: Number of photons. Default is 1e9.
-- `--mae_weight`: Weight for MAE loss. Default is 1.
-- `--nll_weight`: Weight for NLL loss. Default is 0.
-- `--config`: Path to YAML configuration file.
-
-## Example
-
-python simulation.py input_data.npz output_results/ --nimages 1000 --seed 42 --nepochs 100 --N 256 
-
-## Input Data Format
-
-The script expects the input data to be in .npz format with the following arrays:
-
-- `probeGuess`: Initial guess of the probe function
-- `objectGuess`: Initial guess of the object
-
-## Output
-
-The script generates the following outputs in the specified output directory:
-
-1. Simulated data visualization
-2. Random groups visualizations (3 sets)
-3. Reconstruction comparison image
-4. HTML report (`report.html`) containing:
-   - Embedded visualizations
-   - Launch command
-   - Model parameters
-
-## Process
-
-1. The script simulates ptychography data based on the input file and specified parameters.
-2. It generates visualizations of the simulated data and random groups.
-3. The script then runs a CDI example using PtychoPINN and compares it with a baseline reconstruction.
-4. Finally, it generates an HTML report with all visualizations and parameters.
-
-## Notes
-
-- The script uses logging to provide information about the process. Check the console output for details.
-- The HTML report provides a comprehensive overview of the simulation results and parameters used.
-- Adjust the simulation parameters to experiment with different scenarios and data characteristics.
diff --git a/build/lib/scripts/simulation/simulation.py b/build/lib/scripts/simulation/simulation.py
deleted file mode 100644
index 3dbea64..0000000
--- a/build/lib/scripts/simulation/simulation.py
+++ /dev/null
@@ -1,276 +0,0 @@
-#!/usr/bin/env python3
-# ptycho_simulate_cli.py
-
-import argparse
-import os
-import sys
-import matplotlib.pyplot as plt
-from ptycho.workflows.components import (
-    setup_configuration,
-    run_cdi_example,
-    update_params,
-)
-
-def save_plot_to_file(fig, filename):
-    fig.savefig(filename, dpi=300, bbox_inches='tight')
-    plt.close(fig)
-
-def generate_html_report(output_dir, image_files, args, params):
-    import base64
-
-    html_content = """
-    <!DOCTYPE html>
-    <html lang="en">
-    <head>
-        <meta charset="UTF-8">
-        <meta name="viewport" content="width=device-width, initial-scale=1.0">
-        <title>Ptychography Simulation Report</title>
-        <style>
-            body {
-                font-family: Arial, sans-serif;
-                line-height: 1.6;
-                color: #333;
-                max-width: 1000px;
-                margin: 0 auto;
-                padding: 20px;
-            }
-            h1, h2 {
-                color: #2c3e50;
-                text-align: center;
-            }
-            .image-container {
-                margin-bottom: 30px;
-            }
-            img {
-                max-width: 100%;
-                height: auto;
-                display: block;
-                margin: 0 auto;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 5px;
-            }
-            .image-title {
-                font-weight: bold;
-                margin-top: 10px;
-                text-align: center;
-            }
-            .command, .parameters {
-                background-color: #f4f4f4;
-                border: 1px solid #ddd;
-                border-radius: 4px;
-                padding: 10px;
-                margin-bottom: 20px;
-                white-space: pre-wrap;
-                word-wrap: break-word;
-            }
-            .parameter-name {
-                font-weight: bold;
-            }
-            .parameter-description {
-                margin-left: 20px;
-                margin-bottom: 10px;
-            }
-        </style>
-    </head>
-    <body>
-        <h1>Ptychography Simulation Report</h1>
-        
-        <h2>Launch Command</h2>
-        <div class="command">
-        {' '.join(sys.argv)}
-        </div>
-        
-        <h2>Model Parameters</h2>
-        <div class="parameters">
-    """
-
-    for key, value in params.items():
-        html_content += f'<p><span class="parameter-name">{key}:</span> {value}</p>\n'
-        if key == "N":
-            html_content += '<p class="parameter-description">Size of the simulation grid.</p>\n'
-        elif key == "probe_scale":
-            html_content += '<p class="parameter-description">Probe scale factor.</p>\n'
-        elif key == "nphotons":
-            html_content += '<p class="parameter-description">Number of photons.</p>\n'
-        elif key == "mae_weight":
-            html_content += '<p class="parameter-description">Weight for MAE loss.</p>\n'
-        elif key == "nll_weight":
-            html_content += '<p class="parameter-description">Weight for NLL loss.</p>\n'
-        elif key == "nepochs":
-            html_content += '<p class="parameter-description">Number of epochs for training.</p>\n'
-        elif key == "intensity_scale.trainable":
-            html_content += '<p class="parameter-description">Whether intensity scale is trainable.</p>\n'
-        elif key == "positions.provided":
-            html_content += '<p class="parameter-description">Whether positions are provided.</p>\n'
-        elif key == "probe.big":
-            html_content += '<p class="parameter-description">Whether to use a big probe.</p>\n'
-        elif key == "probe.mask":
-            html_content += '<p class="parameter-description">Whether to use a probe mask.</p>\n'
-        elif key == "data_source":
-            html_content += '<p class="parameter-description">Type of data source.</p>\n'
-        elif key == "gridsize":
-            html_content += '<p class="parameter-description">Grid size for simulation.</p>\n'
-
-    html_content += """
-        </div>
-        
-        <h2>Visualizations</h2>
-    """
-
-    for image_file in image_files:
-        image_name = os.path.basename(image_file)
-        image_title = image_name.replace('_', ' ').replace('.png', '').title()
-        
-        # Read the image file and encode it in base64
-        with open(image_file, 'rb') as img_f:
-            image_data = img_f.read()
-            encoded_image = base64.b64encode(image_data).decode('utf-8')
-        
-        # Determine the image's MIME type
-        mime_type = 'image/png'  # Adjust if using other image formats
-        
-        # Embed the image in the HTML using a data URI
-        html_content += f"""
-        <div class="image-container">
-            <img src="data:{mime_type};base64,{encoded_image}" alt="{image_title}">
-            <p class="image-title">{image_title}</p>
-        </div>
-        """
-
-    html_content += """
-    </body>
-    </html>
-    """
-
-    with open(os.path.join(output_dir, 'report.html'), 'w') as f:
-        f.write(html_content)
-
-def main():
-    parser = argparse.ArgumentParser(description="Simulate ptychography data and generate visualizations.")
-    parser.add_argument("input_file", help="Path to the input .npz file containing probe and object guesses.")
-    parser.add_argument("output_dir", help="Directory to save output visualizations.")
-    parser.add_argument("--nimages", type=int, default=2000, help="Number of images to simulate.")
-    parser.add_argument("--seed", type=int, default=None, help="Random seed for reproducibility.")
-    parser.add_argument("--nepochs", type=int, default=50, help="Number of epochs for training.")
-    parser.add_argument("--output_prefix", default="tmp", help="Prefix for output files.")
-    parser.add_argument("--intensity_scale_trainable", action="store_true", default=False, help="Make intensity scale trainable.")
-    parser.add_argument("--positions_provided", action="store_true", default=True, help="Positions are provided.")
-    parser.add_argument("--probe_big", action="store_true", default=True, help="Use big probe.")
-    parser.add_argument("--probe_mask", action="store_true", default=False, help="Use probe mask.")
-    parser.add_argument("--data_source", default="generic", help="Data source type.")
-    parser.add_argument("--gridsize", type=int, default=1, help="Grid size.")
-    parser.add_argument("--train_data_file_path", default=None, help="Path to train data file.")
-    parser.add_argument("--test_data_file_path", default=None, help="Path to test data file.")
-    parser.add_argument("--N", type=int, default=128, help="Size of the simulation grid.")
-    parser.add_argument("--probe_scale", type=int, default=4, help="Probe scale factor.")
-    parser.add_argument("--nphotons", type=float, default=1e9, help="Number of photons.")
-    parser.add_argument("--mae_weight", type=float, default=1, help="Weight for MAE loss.")
-    parser.add_argument("--nll_weight", type=float, default=0, help="Weight for NLL loss.")
-    parser.add_argument("--config", type=str, help="Path to YAML configuration file")
-    args = parser.parse_args()
-
-    os.makedirs(args.output_dir, exist_ok=True)
-
-    params = {
-        "nepochs": args.nepochs,
-        "output_prefix": args.output_prefix,
-        "intensity_scale.trainable": args.intensity_scale_trainable,
-        "positions.provided": args.positions_provided,
-        "probe.big": args.probe_big,
-        "probe.mask": args.probe_mask,
-        "data_source": args.data_source,
-        "gridsize": args.gridsize,
-        "train_data_file_path": args.train_data_file_path,
-        "test_data_file_path": args.test_data_file_path,
-        "N": args.N,
-        "probe_scale": args.probe_scale,
-        "nphotons": args.nphotons,
-        "mae_weight": args.mae_weight,
-        "nll_weight": args.nll_weight,
-    }
-    
-
-    update_params(params)
-    config = setup_configuration(args, args.config)
-
-    from ptycho import probe
-    from ptycho.nongrid_simulation import (
-        simulate_from_npz,
-        visualize_simulated_data,
-        plot_random_groups,
-        compare_reconstructions,
-    )
-    from ptycho import tf_helper as hh
-    from ptycho import baselines as bl
-    from ptycho.workflows.components import create_ptycho_data_container
-
-    # Simulate data
-    simulated_data, ground_truth_patches = simulate_from_npz(
-        args.input_file, args.nimages, random_seed=args.seed
-    )
-
-    # Set the probe
-    probe.set_probe_guess(None, simulated_data.probeGuess)
-
-    # Prepare data for visualization
-    data_for_vis = {
-        'diffraction_patterns': simulated_data.diff3d,
-        'ground_truth_patches': ground_truth_patches,
-        'probe_guess': simulated_data.probeGuess,
-        'object': simulated_data.objectGuess,
-        'x_coordinates': simulated_data.xcoords,
-        'y_coordinates': simulated_data.ycoords,
-    }
-
-    # Generate and save visualizations
-    image_files = []
-
-    # Visualize simulated data
-    #plt.figure(figsize=(20, 20))
-    visualize_simulated_data(data_for_vis, args.output_dir)
-    filename = os.path.join(args.output_dir, "simulated_data_visualization.png")
-    #plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    #plt.close()
-
-    # Plot random groups
-    for i in range(3):  # Generate 3 sets of random groups
-        plt.figure(figsize=(15, 15))
-        plot_random_groups(simulated_data, K=5, seed=args.seed)
-        filename = os.path.join(args.output_dir, f'random_groups_{i+1}.png')
-        plt.savefig(filename, dpi=300, bbox_inches='tight')
-        image_files.append(filename)
-        plt.close()
-
-    # Run CDI example and compare reconstructions
-    config = setup_configuration(args, None)
-    train_data = create_ptycho_data_container(simulated_data, config)
-    recon_amp, recon_phase, results = run_cdi_example(train_data, train_data, config)
-
-    # Train baseline model
-    baseline_model = bl.train(train_data.X[:, :, :, :1], train_data.Y_I[:, :, :, :1], train_data.Y_phi[:, :, :, :1])
-    baseline_pred_I, baseline_pred_phi = baseline_model[0].predict([train_data.X[:, :, :, 0]])
-
-    # Compare reconstructions
-    plt.figure(figsize=(20, 20))
-    compare_reconstructions(
-        results['obj_tensor_full'],
-        results['global_offsets'],
-        simulated_data.objectGuess,
-        hh.combine_complex(baseline_pred_I, baseline_pred_phi)
-    )
-    filename = os.path.join(args.output_dir, 'reconstruction_comparison.png')
-    plt.savefig(filename, dpi=300, bbox_inches='tight')
-    image_files.append(filename)
-    plt.close()
-
-    # Generate HTML report with embedded images, launch command, and model parameters
-    generate_html_report(args.output_dir, image_files, args, params)
-
-    print(f"Simulation and visualization complete. Results saved in {args.output_dir}")
-    print(f"Open {os.path.join(args.output_dir, 'report.html')} to view the visualizations.")
-
-if __name__ == "__main__":
-    main()
-
diff --git a/build/lib/scripts/stitch_patches.py b/build/lib/scripts/stitch_patches.py
deleted file mode 100644
index 4f88936..0000000
--- a/build/lib/scripts/stitch_patches.py
+++ /dev/null
@@ -1,93 +0,0 @@
-import numpy as np
-
-def stitch_patches(patches, *, 
-                  N: int,
-                  gridsize: int,
-                  offset: int,
-                  nimgs_test: int,
-                  outer_offset_test: int = None,
-                  norm_Y_I_test: float = 1.0,
-                  norm: bool = True,
-                  part: str = 'amp') -> np.ndarray:
-    """
-    Stitch NxN patches into full images.
-    
-    Args:
-        patches: numpy array or tensorflow tensor of image patches to stitch
-        N: Size of each square patch
-        gridsize: Grid size for patch arrangement  
-        offset: Spacing between patches
-        nimgs_test: Number of test images
-        outer_offset_test: Offset between outer patches
-        norm_Y_I_test: Normalization factor (default: 1.0)
-        norm: Whether to apply normalization (default: True)
-        part: Which part to extract - 'amp', 'phase', or 'complex' (default: 'amp')
-        
-    Returns:
-        np.ndarray: Stitched image(s) with shape (batch, height, width, 1)
-    """
-    # if the channel dimension exists, its size must be 1
-    if patches.shape[-1] != 1:
-        assert patches.shape[-1] == N
-
-    def get_clip_sizes(outer_offset):
-        """Calculate border sizes for clipping overlapping regions."""
-        bordersize = (N - outer_offset / 2) / 2
-        borderleft = int(np.ceil(bordersize))
-        borderright = int(np.floor(bordersize))
-        clipsize = (bordersize + ((gridsize - 1) * offset) // 2)
-        clipleft = int(np.ceil(clipsize))
-        clipright = int(np.floor(clipsize))
-        return borderleft, borderright, clipleft, clipright
-    
-    # Convert tensorflow tensor to numpy if needed
-    if hasattr(patches, 'numpy'):
-        patches = patches.numpy()
-    
-    # Handle optional parameters
-    nimgs = nimgs_test
-    outer_offset = outer_offset_test if outer_offset_test is not None else offset
-    
-    # Calculate number of segments using numpy's size
-    nsegments = int(np.sqrt((patches.size / nimgs) / (N**2)))
-    
-    # Select extraction function
-    if part == 'amp':
-        getpart = np.absolute
-    elif part == 'phase':
-        getpart = np.angle
-    elif part == 'complex':
-        getpart = lambda x: x
-    else:
-        raise ValueError("part must be 'amp', 'phase', or 'complex'")
-    
-    # Extract and normalize if requested
-    if norm:
-        img_recon = np.reshape((norm_Y_I_test * getpart(patches)), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    else:
-        img_recon = np.reshape(getpart(patches), 
-                              (-1, nsegments, nsegments, N, N, 1))
-    
-    # Clip borders
-    borderleft, borderright, clipleft, clipright = get_clip_sizes(outer_offset)
-    img_recon = img_recon[:, :, :, borderleft:-borderright, borderleft:-borderright, :]
-    
-    # Rearrange and reshape to final form
-    tmp = img_recon.transpose(0, 1, 3, 2, 4, 5)
-    stitched = tmp.reshape(-1, np.prod(tmp.shape[1:3]), np.prod(tmp.shape[1:3]), 1)
-    
-    return stitched
-
-
-# Usage example
-#stitched = stitch_patches(ptycho_dataset.test_data.Y[:, :, :, :1],
-#              N=64,
-#              gridsize=2,
-#              offset=4,
-#              nimgs_test=1,
-#              outer_offset_test=20,
-#              norm_Y_I_test=ptycho_dataset.test_data.norm_Y_I,
-#              norm=True, 
-#              part='complex')
-#plt.imshow(np.abs(stitched[0, :, :, 0]))
diff --git a/build/lib/scripts/training/README.md b/build/lib/scripts/training/README.md
deleted file mode 100644
index e7ee008..0000000
--- a/build/lib/scripts/training/README.md
+++ /dev/null
@@ -1,100 +0,0 @@
-# PtychoPINN Training Script
-
-This script trains PtychoPINN from a .npz input and writes the resulting model artifacts to disk.
-
-## Prerequisites
-
-- PtychoPINN installation
-
-## Input Data Format
-
-The training script expects the input data to be in the following format:
-
-- Coordinates (x, y) of the scan points
-- Diffraction patterns
-- Ground truth of the probe function
-- Scan indices for each diffraction pattern
-- (Optional) Ground truth of the object
-
-The data should be provided as a NumPy `.npz` file with the following keys:
-- `xcoords`: x coordinates of the scan points
-- `ycoords`: y coordinates of the scan points
-- `xcoords_start`: starting x coordinates for the scan (deprecated, same as `xcoords`)
-- `ycoords_start`: starting y coordinates for the scan (deprecated, same as `ycoords`)
-- `diff3d`: diffraction patterns with shape `(num_diffraction_patterns, N, N)`, where `N` is the model parameter (typically 64 or 128)
-- `probeGuess`: complex-valued probe ground truth
-- `scan_index`: array indicating the scan index for each diffraction pattern
-
-Note: The distinction between `xcoords`/`ycoords` and `xcoords_start`/`ycoords_start` is only relevant if the iterative solver used to generate the probe ground truth used position correction. This distinction is deprecated, so `xcoords` and `xcoords_start` (and `ycoords` and `ycoords_start`) can be assumed to be the same.
-
-The height and width of the diffraction patterns are equal and determined by the model parameter `N`, which is typically set to 64 or 128. The value of `N` should be consistent with the model configuration.
-
-## Data Loading
-
-By default, the training script loads up to 512 images from the input data file. This limit is hardcoded but can be modified in the source code if needed.
-
-## Configuration
-
-The training script uses a configuration file (`config.yaml`) to set various parameters. The configuration system supports both new-style configuration and legacy parameters. Key parameters include:
-
-- Number of epochs (`nepochs`)
-- Batch size (`batch_size`)
-- Output directory (`output_dir`)
-- Train data file path (`train_data_file`)
-- Test data file path (`test_data_file`, optional)
-- Model parameters:
-  - N: Size of diffraction patterns (64, 128, or 256)
-  - gridsize: Grid size for model - controls number of images processed per solution region (e.g., gridsize=2 means 2¬≤=4 images at a time)
-  - n_filters_scale: Scale factor for number of filters
-  - model_type: 'pinn' or 'supervised'
-  - amp_activation: Activation function ('sigmoid', 'swish', 'softplus', 'relu')
-  - Various boolean flags for model configuration
-
-You can provide a custom configuration file using the `--config` command-line argument.
-
-## Usage
-
-1. Prepare your ptychographic imaging dataset in the required format.
-
-2. (Optional) Create a configuration file with the desired training parameters.
-
-3. Run the training script:
-   ```
-   python train.py --train_data_file /path/to/your/train_data.npz [--config /path/to/config.yaml]
-   ```
-   Note: The script supports both `--train_data_file` and the legacy `--train_data_file_path` arguments.
-
-4. The script will:
-   - Load and validate the configuration
-   - Load the training data (and test data if specified)
-   - Run the CDI example
-   - Save the model and outputs
-   - Display progress information during training
-
-## Error Handling
-
-The script includes comprehensive error handling:
-- All exceptions during execution are caught and logged
-- Detailed error messages are written to both the debug log and console
-- The script will exit with an error status if any critical errors occur
-
-## Output Structure
-
-The training script generates the following outputs:
-
-- Model artifacts saved to the specified output directory
-- Debug logs written to 'train_debug.log'
-- Console output showing training progress
-- Training results including:
-  - Reconstructed amplitude
-  - Reconstructed phase
-  - Additional training metrics and results
-
-## Logging
-
-The script implements a two-level logging system:
-- Debug information is written to 'train_debug.log'
-- Info level messages are displayed in the console
-
-This dual logging system helps track both detailed debugging information and high-level progress during training.
-
diff --git a/build/lib/scripts/training/train.py b/build/lib/scripts/training/train.py
deleted file mode 100644
index 983f262..0000000
--- a/build/lib/scripts/training/train.py
+++ /dev/null
@@ -1,62 +0,0 @@
-#!/usr/bin/env python
-
-import logging
-import sys
-
-# Set up file handler for debug logging
-file_handler = logging.FileHandler('train_debug.log')
-file_handler.setLevel(logging.DEBUG)
-file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Set up console handler for info logging
-console_handler = logging.StreamHandler(sys.stdout)
-console_handler.setLevel(logging.INFO)
-console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
-
-# Configure root logger
-logging.getLogger().setLevel(logging.DEBUG)
-logging.getLogger().addHandler(file_handler)
-logging.getLogger().addHandler(console_handler)
-
-from ptycho.workflows.components import (
-    parse_arguments,
-    setup_configuration,
-    load_data,
-    run_cdi_example,
-    save_outputs,
-    logger
-)
-from ptycho.config.config import TrainingConfig, update_legacy_dict
-from ptycho import model_manager, params
-def main() -> None:
-    """Main function to orchestrate the CDI example script execution."""
-    args = parse_arguments()
-    
-    # Handle legacy argument name
-    if hasattr(args, 'train_data_file_path'):
-        args.train_data_file = args.train_data_file_path
-        delattr(args, 'train_data_file_path')
-        
-    config = setup_configuration(args, args.config)
-    
-    # Update global params with new-style config at entry point
-    update_legacy_dict(params.cfg, config)
-    
-    try:
-
-        #ptycho_data, ptycho_data_train, obj = load_and_prepare_data(config['train_data_file_path'])
-        ptycho_data = load_data(str(config.train_data_file), n_images = 512)
-        
-        test_data = None
-        if config.test_data_file:
-            test_data = load_data(str(config.test_data_file))
-
-        recon_amp, recon_phase, results = run_cdi_example(ptycho_data, test_data, config)
-        model_manager.save(str(config.output_dir))
-        save_outputs(recon_amp, recon_phase, results, str(config.output_dir))
-    except Exception as e:
-        logger.error(f"An error occurred during execution: {e}")
-        raise
-
-if __name__ == "__main__":
-    main()
diff --git a/build/lib/tests/old_test_tf_helper.py b/build/lib/tests/old_test_tf_helper.py
deleted file mode 100644
index 8e729d2..0000000
--- a/build/lib/tests/old_test_tf_helper.py
+++ /dev/null
@@ -1,49 +0,0 @@
-from ptycho.tf_helper import complexify_function, complexify_amp_phase, combine_complex
-import tensorflow as tf
-import numpy as np
-
-
-# Sample function to be complexified
-def sample_fn(tensor, *args, **kwargs):
-    return tensor * 2
-
-# Complexify the sample function
-complexified_fn = complexify_function(sample_fn)
-complexified_amp_phase_fn = complexify_amp_phase(sample_fn)
-
-def test_complexify_function():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    expected_output = tf.constant([2.0 + 4.0j, 6.0 + 8.0j], dtype=tf.complex64)
-    assert tf.math.reduce_all(complexified_fn(complex_tensor) == expected_output), "Failed on complex tensor"
-
-def test_complexify_amp_phase():
-    # Test with real tensor
-    real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-    assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-
-    # Test with complex tensor
-    complex_tensor = tf.constant([1.0 + 2.0j, 3.0 + 4.0j], dtype=tf.complex64)
-    # Doubling the amplitude
-    expected_amplitude = tf.math.abs(complex_tensor) * 2
-    # Doubling the phase (modulus to keep it within -pi to pi)
-    expected_phase = tf.math.angle(complex_tensor) * 2 % (2 * tf.constant(np.pi))
-    # Construct the expected tensor
-    expected_tensor = combine_complex(expected_amplitude, expected_phase)
-    # Compare the reconstructed tensor to the expected tensor
-    error = tf.math.abs(complexified_amp_phase_fn(complex_tensor) - expected_tensor)
-    assert tf.math.reduce_max(error) < 1e-6, "Failed on complex tensor"
-
-
-# Execute the tests
-test_complexify_function()
-
-with tf.device('/CPU:0'):
-    # Force CPU execution because one of the first two tests fails on GPU
-    test_complexify_amp_phase()
-
-print("All tests passed!")
diff --git a/build/lib/tests/refactoring_todo b/build/lib/tests/refactoring_todo
deleted file mode 100644
index 4dca748..0000000
--- a/build/lib/tests/refactoring_todo
+++ /dev/null
@@ -1,10 +0,0 @@
-Use PtychoData class
-get rid of nominal vs actual coordinates
-move 'lines' simulation into its own file
-split tf_helper into multiple files
-move some of the stuff in loader into tf_helper
-functional interface (probe should be an explicit
-	parameter instead of part of the configuration).
-don't divide by intensity scale, since we then have to multiply it back
-in
-clarify the role of c_outer and all that and clean up model.py
diff --git a/build/lib/tests/test_generate_data.py b/build/lib/tests/test_generate_data.py
deleted file mode 100644
index 405bef0..0000000
--- a/build/lib/tests/test_generate_data.py
+++ /dev/null
@@ -1,7 +0,0 @@
-# Test for generate_data module in the ptycho package
-
-from ptycho import generate_data as init
-
-def test_placeholder():
-    # Placeholder test to ensure the import works
-    assert hasattr(init, 'PtychoData'), "generate_data module should have PtychoData class"
diff --git a/build/lib/tests/test_generic_loader.py b/build/lib/tests/test_generic_loader.py
deleted file mode 100644
index c6f8f9d..0000000
--- a/build/lib/tests/test_generic_loader.py
+++ /dev/null
@@ -1,49 +0,0 @@
-import numpy as np
-import os
-from ptycho.raw_data import RawData
-from ptycho.xpp import load_ptycho_data
-import tensorflow as tf
-import pkg_resources
-os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppresses most TensorFlow warnings
-
-def create_sample_data_file(file_path, xcoords, ycoords, xcoords_start, ycoords_start, diff3d, probeGuess, scan_index):
-    np.savez(file_path, xcoords=xcoords, ycoords=ycoords, xcoords_start=xcoords_start, ycoords_start=ycoords_start, diff3d=diff3d, probeGuess=probeGuess, scan_index=scan_index)
-
-def test_generic_loader(remove=True, data_file_path = None, train_size = 512):
-    if data_file_path is None:
-        data_file_path = pkg_resources.resource_filename('ptycho', 'datasets/Run1084_recon3_postPC_shrunk_3.npz')
-
-    # Load RawData instances using the 'xpp' method
-    test_data, train_data, obj = load_ptycho_data(data_file_path, train_size = train_size)
-
-    # Define file paths for output
-    train_data_file_path = 'train_data.npz'
-    test_data_file_path = 'test_data.npz'
-
-    # Use RawData.to_file() to write them to file
-    train_data.to_file(train_data_file_path)
-    test_data.to_file(test_data_file_path)
-
-    print(f"Train data written to {train_data_file_path}")
-    print(f"Test data written to {test_data_file_path}")
-
-    # Load data using the 'generic' method
-    train_raw_data = RawData.from_file(train_data_file_path)
-    test_raw_data = RawData.from_file(test_data_file_path)
-
-    # Perform assertions to verify the data is loaded correctly
-    assert np.array_equal(train_raw_data.xcoords, train_data.xcoords)
-    assert np.array_equal(train_raw_data.ycoords, train_data.ycoords)
-    assert np.array_equal(train_raw_data.diff3d, train_data.diff3d)
-    assert np.array_equal(train_raw_data.probeGuess, train_data.probeGuess)
-    assert np.array_equal(train_raw_data.scan_index, train_data.scan_index)
-
-    if remove:
-        # Clean up the created files
-        os.remove(train_data_file_path)
-        os.remove(test_data_file_path)
-
-    return train_data, test_data, obj
-
-if __name__ == '__main__':
-    test_generic_loader()
diff --git a/build/lib/tests/test_tf_helper.py b/build/lib/tests/test_tf_helper.py
deleted file mode 100644
index 337e29e..0000000
--- a/build/lib/tests/test_tf_helper.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import unittest
-import tensorflow as tf
-import numpy as np
-from ptycho.tf_helper import get_mask, combine_complex, pad_obj
-
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import tensorflow as tf
-from ptycho.tf_helper import get_mask, _fromgrid, params
-
-class TestFromGrid(unittest.TestCase):
-
-    def test_fromgrid(self):
-        print("Debug: Starting test_fromgrid")
-        # Set up parameters for the test
-        gridsize = params()['gridsize']
-        N = params()['N']
-        print(f"Debug: Test parameters - gridsize = {gridsize}, N = {N}")
-        # Create a sample input tensor in grid format
-        input_tensor = tf.random.uniform((1, gridsize, gridsize, N, N), dtype=tf.float32)
-        print(f"Debug: Input tensor shape = {input_tensor.shape}")
-        # Calculate the expected output shape
-        expected_shape = (1, N, N, 1)
-        print(f"Debug: Expected output shape = {expected_shape}")
-        # Run the _fromgrid function
-        output_tensor = _fromgrid(input_tensor)
-        print(f"Debug: Output tensor shape = {output_tensor.shape}")
-        # Check if the output shape matches the expected shape
-        self.assertEqual(output_tensor.shape, expected_shape)
-
-with tf.device('/CPU:0'):
-    def test_complexify_amp_phase():
-        # Test with real tensor
-        real_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)
-        assert tf.math.reduce_all(complexified_amp_phase_fn(real_tensor) == real_tensor * 2), "Failed on real tensor"
-    def test_get_mask():
-        input_tensor = tf.constant([[0.1, 0.5], [0.9, 0.0]], dtype=tf.float32)
-        expected_output = tf.constant([[0, 1], [1, 0]], dtype=tf.float32)
-        threshold = 0.2
-        output = get_mask(input_tensor, threshold)
-        self.assertTrue(tf.reduce_all(tf.equal(output, expected_output)))
-
-if __name__ == '__main__':
-    unittest.main()
-import unittest
-import numpy as np
-import tensorflow as tf
-from ptycho.tf_helper import combine_complex
-
-class TestCombineComplex(unittest.TestCase):
-
-def test_combine_complex():
-    amp = tf.constant([1.0, 2.0], dtype=tf.float32)
-    phi = tf.constant([0.0, np.pi], dtype=tf.float32)
-    expected_output = tf.constant([1.0 + 0j, -2.0 + 0j], dtype=tf.complex64)
-    output_complex = combine_complex(amp, phi)
-    # Use a tolerance when comparing complex numbers
-    tolerance = 1e-5
-    self.assertTrue(tf.reduce_all(tf.math.abs(output_complex - expected_output) < tolerance))
-
-def test_pad_and_diffract():
-    # Create a sample input tensor
-    input_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]], dtype=tf.float32)
-    input_tensor = tf.reshape(input_tensor, (1, 2, 2, 1))  # Reshape to (batch, height, width, channels)
-    # Define the desired output height and width
-    desired_height = 4
-    desired_width = 4
-    # Expected output tensor values based on provided output
-    expected_output_values = [0.0, 0.70710677, 1.0, 0.70710677, 0.35355338, 1.4577379, 1.9039432, 1.2747549, 0.5, 1.8027756]
-    # Run pad_and_diffract function
-    _, output_tensor = pad_and_diffract(input_tensor, desired_height, desired_width)
-    # Flatten the output tensor and slice the first 10 values for comparison
-    output_values = output_tensor.numpy().flatten()[:10]
-    # Check if the output values match the expected values within a tolerance
-    for expected, actual in zip(expected_output_values, output_values):
-        self.assertAlmostEqual(expected, actual, places=5)
-
-# Execute the tests
-if __name__ == "__main__":
-    test_complexify_function()
-    with tf.device('/CPU:0'):
-        # Force CPU execution because one of the first two tests fails on GPU
-        test_complexify_amp_phase()
-        test_get_mask()
-        test_combine_complex()
-        test_pad_and_diffract()
-
-if __name__ == '__main__':
-    unittest.main()
-
diff --git a/build/lib/torch/tests/test_tf_helper.py b/build/lib/torch/tests/test_tf_helper.py
deleted file mode 100644
index 20e2574..0000000
--- a/build/lib/torch/tests/test_tf_helper.py
+++ /dev/null
@@ -1,326 +0,0 @@
-import torch
-import numpy as np
-from .tf_helper import *
-
-def test_get_mask():
-    input_tensor = torch.tensor([[1.0, 0.5, 0.8], [0.3, 0.9, 0.2]])
-    support_threshold = 0.6
-    expected_output = torch.tensor([[1.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
-    assert torch.all(torch.eq(get_mask(input_tensor, support_threshold), expected_output))
-
-def test_combine_complex():
-    amp = torch.tensor([[1.0, 0.5], [0.8, 0.3]])
-    phi = torch.tensor([[0.0, np.pi/2], [np.pi/4, np.pi]])
-    expected_output = torch.view_as_complex(torch.tensor([[[1.0, 0.0], [0.0, 0.5]], [[0.5657, 0.5657], [-0.3, 0.0]]]))
-    assert torch.allclose(combine_complex(amp, phi), expected_output)
-
-def test_pad_obj():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_obj(input_tensor, h, w), expected_output))
-
-def test__fromgrid():
-    params()['N'] = 2
-    img = torch.ones((1, 2, 2, 2, 2, 1))
-    expected_output = torch.ones((4, 2, 2, 1))
-    assert torch.all(torch.eq(_fromgrid(img), expected_output))
-
-def test__togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img = torch.ones((4, 2, 2, 1))
-    expected_output = torch.ones((1, 2, 2, 2, 2, 1))
-    assert torch.all(torch.eq(_togrid(img), expected_output))
-
-def test_togrid():
-    params()['N'] = 2
-    params()['gridsize'] = 2
-    img1 = torch.ones((4, 2, 2, 1))
-    img2 = torch.ones((4, 2, 2, 1))
-    expected_output = (torch.ones((1, 2, 2, 2, 2, 1)), torch.ones((1, 2, 2, 2, 2, 1)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(togrid(img1, img2), expected_output))
-
-def test__grid_to_channel():
-    params()['gridsize'] = 2
-    grid = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_grid_to_channel(grid), expected_output))
-
-def test_grid_to_channel():
-    params()['gridsize'] = 2
-    grid1 = torch.ones((1, 2, 2, 3, 3, 1))
-    grid2 = torch.ones((1, 2, 2, 3, 3, 1))
-    expected_output = (torch.ones((1, 3, 3, 4)), torch.ones((1, 3, 3, 4)))
-    assert all(torch.all(torch.eq(x, y)) for x, y in zip(grid_to_channel(grid1, grid2), expected_output))
-
-def test__flat_to_channel():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    img = torch.ones((4, 3, 3, 1))
-    expected_output = torch.ones((1, 3, 3, 4))
-    assert torch.all(torch.eq(_flat_to_channel(img), expected_output))
-
-def test__flat_to_channel_2():
-    params()['gridsize'] = 2
-    img = torch.ones((1, 3, 4, 1))
-    expected_output = torch.ones((1, 3, 4, 4))
-    assert torch.all(torch.eq(_flat_to_channel_2(img), expected_output))
-
-def test__channel_to_flat():
-    img = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3, 3, 1))
-    assert torch.all(torch.eq(_channel_to_flat(img), expected_output))
-
-def test__channel_to_patches():
-    params()['gridsize'] = 2
-    params()['N'] = 3
-    channel = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((1, 2, 2, 9))
-    assert torch.all(torch.eq(_channel_to_patches(channel), expected_output))
-
-def test_pad_patches():
-    imgs = torch.ones((1, 4, 4, 1))
-    padded_size = 8
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad_patches(imgs, padded_size), expected_output))
-
-def test_pad():
-    imgs = torch.ones((1, 4, 4, 1))
-    size = 2
-    expected_output = torch.ones((1, 8, 8, 1))
-    assert torch.all(torch.eq(pad(imgs, size), expected_output))
-
-def test_trim_reconstruction():
-    x = torch.ones((1, 8, 8, 1))
-    N = 4
-    expected_output = torch.ones((1, 4, 4, 1))
-    assert torch.all(torch.eq(trim_reconstruction(x, N), expected_output))
-
-def test_flatten_offsets():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 3))
-    assert torch.all(torch.eq(flatten_offsets(channels), expected_output))
-
-def test_pad_reconstruction():
-    channels = torch.ones((1, 3, 3, 4))
-    expected_output = torch.ones((4, 7, 7, 1))
-    assert torch.all(torch.eq(pad_reconstruction(channels), expected_output))
-
-def test_pad_and_diffract():
-    input_tensor = torch.ones((1, 4, 4, 1))
-    h, w = 8, 8
-    padded_expected = torch.ones((1, 8, 8, 1))
-    input_expected = torch.ones((1, 8, 8, 1))
-    padded, input = pad_and_diffract(input_tensor, h, w)
-    assert torch.all(torch.eq(padded, padded_expected))
-    assert torch.allclose(input, input_expected, atol=1e-6)
-
-import torch
-from typing import Callable
-
-def test_mk_centermask():
-    inputs = torch.ones((2, 8, 8, 3))
-    N = 4
-    c = 3
-
-    # Test case 1: Check if the function returns the correct center mask when kind='center'
-    expected_center_mask = torch.zeros((2, 8, 8, 3))
-    expected_center_mask[:, 2:6, 2:6, :] = 1
-    center_mask = mk_centermask(inputs, N, c, kind='center')
-    assert torch.allclose(center_mask, expected_center_mask)
-
-    # Test case 2: Check if the function returns the correct border mask when kind='border'
-    expected_border_mask = torch.ones((2, 8, 8, 3))
-    expected_border_mask[:, 2:6, 2:6, :] = 0
-    border_mask = mk_centermask(inputs, N, c, kind='border')
-    assert torch.allclose(border_mask, expected_border_mask)
-
-    # Test case 3: Check if the function raises a ValueError when kind is not 'center' or 'border'
-    try:
-        mk_centermask(inputs, N, c, kind='invalid')
-        assert False, "Expected ValueError was not raised"
-    except ValueError:
-        pass
-
-def test_mk_norm():
-    channels = torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function returns the correct norm values
-    expected_norm = torch.ones((2, 8, 8, 4)) * 2 + 0.001
-    norm = mk_norm(channels, mock_fn_reassemble_real)
-    assert torch.allclose(norm, expected_norm)
-
-    # Test case 2: Check if the function handles different input shapes correctly
-    channels_2 = torch.ones((4, 16, 16, 8))
-    expected_norm_2 = torch.ones((4, 16, 16, 8)) * 2 + 0.001
-    norm_2 = mk_norm(channels_2, mock_fn_reassemble_real)
-    assert torch.allclose(norm_2, expected_norm_2)
-
-def test_reassemble_patches():
-    channels = torch.ones((2, 8, 8, 4)) + 1j * torch.ones((2, 8, 8, 4))
-
-    # Mock fn_reassemble_real function
-    def mock_fn_reassemble_real(tensor, average=False):
-        return tensor * 2
-
-    # Test case 1: Check if the function correctly reassembles patches when average=False
-    expected_output = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output = reassemble_patches(channels, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the function correctly reassembles patches when average=True
-    expected_output_avg = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 2
-    output_avg = reassemble_patches(channels, mock_fn_reassemble_real, average=True)
-    assert torch.allclose(output_avg, expected_output_avg)
-
-    # Test case 3: Check if the function handles complex input channels correctly
-    channels_real = torch.ones((2, 8, 8, 4))
-    channels_imag = torch.ones((2, 8, 8, 4)) * 2
-    channels_complex = torch.complex(channels_real, channels_imag)
-    expected_output_complex = torch.ones((2, 8, 8, 4)) * 2 + 1j * torch.ones((2, 8, 8, 4)) * 4
-    output_complex = reassemble_patches(channels_complex, mock_fn_reassemble_real, average=False)
-    assert torch.allclose(output_complex, expected_output_complex)
-
-def test__reassemble_patches_position_real():
-    imgs = torch.ones((2, 8, 8, 4))
-    offsets_xy = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-    padded_size = 16
-
-    # Mock Translation class
-    class MockTranslation:
-        def __call__(self, inputs):
-            return inputs[0] + inputs[1].unsqueeze(-1).unsqueeze(-1)
-
-    # Mock helper functions
-    def mock_flatten_offsets(offsets_xy):
-        return offsets_xy.view(-1, 2)
-
-    def mock__channel_to_flat(imgs):
-        return imgs.view(-1, 8, 8, 1)
-
-    def mock_pad_patches(imgs_flat, padded_size):
-        return torch.ones((8, padded_size, padded_size, 1))
-
-    def mock__flat_to_channel(imgs_flat_bigN_translated, N):
-        return imgs_flat_bigN_translated.view(2, N, N, 4)
-
-    # Test case 1: Check if the function correctly reassembles patches when agg=True
-    expected_output_agg = torch.ones((2, padded_size, padded_size, 1)) * 4
-    output_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=True, padded_size=padded_size,
-                                                   flatten_offsets=mock_flatten_offsets,
-                                                   _channel_to_flat=mock__channel_to_flat,
-                                                   pad_patches=mock_pad_patches,
-                                                   Translation=MockTranslation(),
-                                                   _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg, expected_output_agg)
-
-    # Test case 2: Check if the function correctly reassembles patches when agg=False
-    expected_output_no_agg = torch.ones((2, padded_size, padded_size, 4))
-    output_no_agg = _reassemble_patches_position_real(imgs, offsets_xy, agg=False, padded_size=padded_size,
-                                                      flatten_offsets=mock_flatten_offsets,
-                                                      _channel_to_flat=mock__channel_to_flat,
-                                                      pad_patches=mock_pad_patches,
-                                                      Translation=MockTranslation(),
-                                                      _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_no_agg, expected_output_no_agg)
-
-    # Test case 3: Check if the function handles different input shapes and offsets correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    offsets_xy_2 = torch.tensor([[[1, 1], [2, 2], [3, 3], [4, 4]], [[5, 5], [6, 6], [7, 7], [8, 8]]])
-    padded_size_2 = 32
-    expected_output_agg_2 = torch.ones((4, padded_size_2, padded_size_2, 1)) * 8
-    output_agg_2 = _reassemble_patches_position_real(imgs_2, offsets_xy_2, agg=True, padded_size=padded_size_2,
-                                                     flatten_offsets=mock_flatten_offsets,
-                                                     _channel_to_flat=mock__channel_to_flat,
-                                                     pad_patches=mock_pad_patches,
-                                                     Translation=MockTranslation(),
-                                                     _flat_to_channel=mock__flat_to_channel)
-    assert torch.allclose(output_agg_2, expected_output_agg_2)
-
-def test_mk_reassemble_position_real():
-    input_positions = torch.tensor([[[1, 1], [2, 2]], [[3, 3], [4, 4]]])
-
-    # Mock _reassemble_patches_position_real function
-    def mock__reassemble_patches_position_real(imgs, offsets_xy, **kwargs):
-        return imgs + offsets_xy.sum()
-
-    # Test case 1: Check if the function returns a callable that correctly reassembles patches
-    imgs = torch.ones((2, 8, 8, 4))
-    expected_output = imgs + 10
-    reassemble_fn = mk_reassemble_position_real(input_positions)
-    output = reassemble_fn(imgs)
-    assert torch.allclose(output, expected_output)
-
-    # Test case 2: Check if the returned callable handles different input shapes and keyword arguments correctly
-    imgs_2 = torch.ones((4, 16, 16, 8))
-    expected_output_2 = imgs_2 + 10
-    output_2 = reassemble_fn(imgs_2)
-    assert torch.allclose(output_2, expected_output_2)
-
-    import torch
-import numpy as np
-
-def test_translate():
-    # Test case 1: Single input tensor
-    tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    output = translate(tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
-    # Test case 2: Batched input tensors
-    batch_size = 2
-    channels = 3
-    height = 4
-    width = 5
-    imgs = torch.randn(batch_size, channels, height, width)
-    offsets = torch.tensor([[1.0, -1.0], [-2.0, 2.0]], dtype=torch.float32)
-    expected_output = torch.tensor([
-        [
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.1132, 0.1562, 0.1697],
-             [0.0000, 0.7470, 0.8155, 0.1878, 0.4034],
-             [0.0000, 1.3378, 0.9931, 0.2400, 0.2372]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.6398, 0.8829, 0.9593],
-             [0.0000, 1.0086, 1.1025, 0.2537, 0.5450],
-             [0.0000, 0.8617, 0.6401, 0.1547, 0.1529]],
-            [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.2566, 0.3541, 0.3848],
-             [0.0000, 0.5297, 0.5783, 0.1331, 0.2861],
-             [0.0000, 0.6287, 0.4674, 0.1129, 0.1117]]
-        ],
-        [
-            [[0.0000, 0.9102, 0.8985, 0.0256, 0.1092],
-             [0.0000, 0.0082, 0.1560, 0.1651, 0.1176],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.6713, 0.6630, 0.0189, 0.0806],
-             [0.0000, 0.0118, 0.2246, 0.2374, 0.1691],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
-            [[0.0000, 0.5032, 0.4970, 0.0142, 0.0604],
-             [0.0000, 0.0117, 0.2213, 0.2342, 0.1667],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
-             [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]
-        ]
-    ], dtype=torch.float32)
-    output = translate(imgs, offsets)
-    assert torch.allclose(output, expected_output, atol=1e-4)
-
-    # Test case 3: Complex input tensor
-    real_tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
-    imag_tensor = torch.tensor([[0.5, 1.0, 1.5], [2.0, 2.5, 3.0]], dtype=torch.float32)
-    complex_tensor = torch.complex(real_tensor, imag_tensor)
-    translation = torch.tensor([1.0, -1.0], dtype=torch.float32)
-    expected_real_output = torch.tensor([[5.0, 6.0, 0.0], [2.0, 3.0, 0.0]], dtype=torch.float32)
-    expected_imag_output = torch.tensor([[2.5, 3.0, 0.0], [1.0, 1.5, 0.0]], dtype=torch.float32)
-    expected_output = torch.complex(expected_real_output, expected_imag_output)
-    output = translate(complex_tensor.unsqueeze(0), translation.unsqueeze(0)).squeeze(0)
-    assert torch.allclose(output, expected_output, atol=1e-6)
-
diff --git a/build/lib/torch/tests/tf_helper.py b/build/lib/torch/tests/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/torch/tests/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/lib/torch/tf_helper.py b/build/lib/torch/tf_helper.py
deleted file mode 100644
index 09eef00..0000000
--- a/build/lib/torch/tf_helper.py
+++ /dev/null
@@ -1,269 +0,0 @@
-import torch
-import torch.nn.functional as F
-from typing import Tuple
-from .params import params, get_padded_size, cfg
-
-def get_mask(input: torch.Tensor, support_threshold: float) -> torch.Tensor:
-    mask = torch.where(input > support_threshold, torch.ones_like(input), torch.zeros_like(input))
-    return mask
-
-def combine_complex(amp: torch.Tensor, phi: torch.Tensor) -> torch.Tensor:
-    real = amp * torch.cos(phi)
-    imag = amp * torch.sin(phi)
-    complex_tensor = torch.view_as_complex(torch.stack((real, imag), dim=-1))
-    return complex_tensor
-
-def pad_obj(input: torch.Tensor, h: int, w: int) -> torch.Tensor:
-    padding = (w // 4, w // 4, h // 4, h // 4)
-    padded_input = F.pad(input, padding, mode='constant', value=0)
-    return padded_input
-
-def _fromgrid(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, 1)
-    """
-    print("Debug: Entering _fromgrid function")
-    N = params()['N']
-    return torch.reshape(img, (-1, N, N, 1))
-
-def _togrid(img: torch.Tensor, gridsize: int = None, N: int = None) -> torch.Tensor:
-    """
-    Reshape (b * gridsize * gridsize, N, N, 1) to (b, gridsize, gridsize, N, N, 1)
-
-    i.e., from flat format to grid format
-    """
-    if gridsize is None:
-        gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    return torch.reshape(img, (-1, gridsize, gridsize, N, N, 1))
-
-def togrid(*imgs: torch.Tensor) -> tuple:
-    """
-    Reshape (-1, N, N, 1) to (-1, gridsize, gridsize, N, N)
-    """
-    return tuple(_togrid(img) for img in imgs)
-
-def _grid_to_channel(grid: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, gridsize, gridsize, N, N) to (-1, N, N, gridsize * gridsize)
-    """
-    gridsize = params()['gridsize']
-    img = torch.permute(grid, (0, 3, 4, 1, 2, 5))
-    _, hh, ww, _, _, _ = img.shape
-    img = torch.reshape(img, (-1, hh, ww, gridsize**2))
-    return img
-
-def grid_to_channel(*grids: torch.Tensor) -> tuple:
-    return tuple(_grid_to_channel(g) for g in grids)
-
-def _flat_to_channel(img: torch.Tensor, N: int = None) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    if N is None:
-        N = params()['N']
-    img = torch.reshape(img, (-1, gridsize**2, N, N))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _flat_to_channel_2(img: torch.Tensor) -> torch.Tensor:
-    gridsize = params()['gridsize']
-    _, N, M, _ = img.shape
-    img = torch.reshape(img, (-1, gridsize**2, N, M))
-    img = torch.permute(img, (0, 2, 3, 1))
-    return img
-
-def _channel_to_flat(img: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (b, N, N, c) to (b * c, N, N, 1)
-    """
-    _, h, w, c = img.shape
-    img = torch.permute(img, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, h, w, 1))
-    return img
-
-def _channel_to_patches(channel: torch.Tensor) -> torch.Tensor:
-    """
-    Reshape (-1, N, N, gridsize * gridsize) to (-1, gridsize, gridsize, N**2)
-    """
-    gridsize = params()['gridsize']
-    N = params()['N']
-    img = torch.permute(channel, (0, 3, 1, 2))
-    img = torch.reshape(img, (-1, gridsize, gridsize, N**2))
-    return img
-
-def pad_patches(imgs: torch.Tensor, padded_size: int = None) -> torch.Tensor:
-    if padded_size is None:
-        padded_size = get_padded_size()
-    N = cfg['N']
-    padding = (padded_size - N) // 2
-    return F.pad(imgs, (padding, padding, padding, padding))
-
-def pad(imgs: torch.Tensor, size: int) -> torch.Tensor:
-    return F.pad(imgs, (size, size, size, size))
-
-def trim_reconstruction(x: torch.Tensor, N: int = None) -> torch.Tensor:
-    """
-    Trim from shape (_, M, M, _) to (_, N, N, _), where M >= N
-
-    When dealing with an input with a static shape, assume M = get_padded_size()
-    """
-    if N is None:
-        N = cfg['N']
-    shape = x.shape
-    if shape[1] is not None:
-        assert torch.all(torch.eq(shape[1], shape[2]))
-    try:
-        clipsize = (shape[1] - N) // 2
-    except TypeError:
-        clipsize = (get_padded_size() - N) // 2
-    return x[:, clipsize:-clipsize, clipsize:-clipsize, :]
-
-def flatten_offsets(channels: torch.Tensor) -> torch.Tensor:
-    return _channel_to_flat(channels)[:, 0, :, 0]
-
-def pad_reconstruction(channels: torch.Tensor) -> torch.Tensor:
-    padded_size = get_padded_size()
-    imgs_flat = _channel_to_flat(channels)
-    return pad_patches(imgs_flat, padded_size)
-
-def pad_and_diffract(input: torch.Tensor, h: int, w: int, pad: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:
-    """
-    zero-pad the real-space object and then calculate the far field
-    diffraction amplitude.
-
-    Uses symmetric FT - L2 norm is conserved
-    """
-    print('input shape', input.shape)
-    if pad:
-        input = pad_obj(input, h, w)
-    padded = input
-    assert input.shape[-1] == 1
-    input = torch.fft.fft2(torch.tensor(input[..., 0], dtype=torch.cfloat))
-    input = torch.real(torch.conj(input) * input) / (h * w)
-    input = torch.unsqueeze(torch.sqrt(torch.fft.fftshift(input, dim=(-2, -1))), -1)
-    return padded, input
-
-from typing import Callable, Any, Optional
-import torch
-
-def mk_centermask(inputs: torch.Tensor, N: int, c: int, kind: str = 'center') -> torch.Tensor:
-    b = inputs.shape[0]
-    ones = torch.ones((b, N // 2, N // 2, c), dtype=inputs.dtype)
-    padding = (N // 4, N // 4, N // 4, N // 4)
-    ones = F.pad(ones, padding)
-    if kind == 'center':
-        return ones
-    elif kind == 'border':
-        return 1 - ones
-    else:
-        raise ValueError
-
-def mk_norm(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor]) -> torch.Tensor:
-    N = params()['N']
-    gridsize = params()['gridsize']
-    ones = mk_centermask(channels, N, gridsize**2)
-    assembled_ones = fn_reassemble_real(ones, average=False)
-    norm = assembled_ones + .001
-    return norm
-
-def reassemble_patches(channels: torch.Tensor, fn_reassemble_real: Callable[[torch.Tensor], torch.Tensor] = reassemble_patches_real,
-        average: bool = False, **kwargs: Any) -> torch.Tensor:
-    """
-    Given image patches (shaped such that the channel dimension indexes
-    patches within a single solution region), reassemble into an image
-    for the entire solution region. Overlaps between patches are
-    averaged.
-    """
-    real = torch.real(channels)
-    imag = torch.imag(channels)
-    assembled_real = fn_reassemble_real(real, average=average, **kwargs) / mk_norm(real,
-        fn_reassemble_real)
-    assembled_imag = fn_reassemble_real(imag, average=average, **kwargs) / mk_norm(imag,
-        fn_reassemble_real)
-    return torch.complex(assembled_real, assembled_imag)
-
-import torch
-import torch.nn as nn
-
-class Translation(nn.Module):
-    def __init__(self):
-        super().__init__()
-
-    def forward(self, inputs):
-        imgs, offsets, jitter = inputs
-
-        # Apply random jitter to the offsets
-        jitter_noise = torch.normal(mean=0.0, std=jitter, size=offsets.shape, device=offsets.device)
-        offsets_with_jitter = offsets + jitter_noise
-
-        # Call the translated translate function with the appropriate arguments
-        translated_imgs = translate(imgs, offsets_with_jitter, interpolation='bilinear')
-
-        return translated_imgs
-
-def _reassemble_patches_position_real(imgs: torch.Tensor, offsets_xy: torch.Tensor, agg: bool = True, padded_size: Optional[int] = None,
-        **kwargs: Any) -> torch.Tensor:
-    """
-    Pass this function as an argument to reassemble_patches by wrapping it, e.g.:
-        def reassemble_patches_position_real(imgs, **kwargs):
-            return _reassemble_patches_position_real(imgs, coords)
-    """
-    if padded_size is None:
-        padded_size = get_padded_size()
-    offsets_flat = flatten_offsets(offsets_xy)
-    imgs_flat = _channel_to_flat(imgs)
-    imgs_flat_bigN = pad_patches(imgs_flat, padded_size)
-    imgs_flat_bigN_translated = Translation()([imgs_flat_bigN, -offsets_flat, torch.tensor(0.)])
-    if agg:
-        imgs_merged = torch.sum(
-                _flat_to_channel(imgs_flat_bigN_translated, N=padded_size),
-                    dim=3, keepdim=True)
-        return imgs_merged
-    else:
-        print('no aggregation in patch reassembly')
-        return _flat_to_channel(imgs_flat_bigN_translated, N=padded_size)
-
-def mk_reassemble_position_real(input_positions: torch.Tensor, **outer_kwargs: Any) -> Callable[[torch.Tensor], torch.Tensor]:
-    def reassemble_patches_position_real(imgs: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-        return _reassemble_patches_position_real(imgs, input_positions,
-            **outer_kwargs)
-    return reassemble_patches_position_real
-
-import torch
-import torch.nn.functional as F
-from typing import Any
-
-# Translate the @complexify_function decorator to work with PyTorch tensors and functions
-def complexify_function(fn):
-    def wrapped_fn(imgs, offsets, **kwargs):
-        if torch.is_complex(imgs):
-            real_imgs = imgs.real
-            imag_imgs = imgs.imag
-            real_result = fn(real_imgs, offsets, **kwargs)
-            imag_result = fn(imag_imgs, offsets, **kwargs)
-            return torch.complex(real_result, imag_result)
-        else:
-            return fn(imgs, offsets, **kwargs)
-    return wrapped_fn
-
-
-@complexify_function
-@debug
-def translate(imgs: torch.Tensor, offsets: torch.Tensor, **kwargs: Any) -> torch.Tensor:
-    # Assert the dimensionality of translations (offsets) is 2, i.e., (B, 2)
-    assert offsets.dim() == 2 and offsets.size(1) == 2, f"Expected offsets to have shape (B, 2), but got {offsets.size()}"
-
-    # Get the batch size and number of channels from the input images
-    batch_size, _, height, width = imgs.size()
-
-    # Create the affine transformation matrix
-    theta = torch.eye(2, 3, device=imgs.device).unsqueeze(0).repeat(batch_size, 1, 1)
-    theta[:, :, 2] = offsets
-
-    # Generate the sampling grid using the affine transformation matrix
-    grid = F.affine_grid(theta, imgs.size(), align_corners=False)
-
-    # Perform the translation using grid_sample
-    translated_imgs = F.grid_sample(imgs, grid, mode='bilinear', align_corners=False, **kwargs)
-
-    return translated_imgs
diff --git a/build/scripts-3.10/train.py b/build/scripts-3.10/train.py
deleted file mode 100755
index 8a0ec99..0000000
--- a/build/scripts-3.10/train.py
+++ /dev/null
@@ -1,148 +0,0 @@
-import os
-from ptycho.model_manager import ModelManager
-from ptycho.export import save_recons
-from datetime import datetime
-import matplotlib
-import matplotlib.pyplot as plt
-import dill
-import argparse
-from ptycho import params
-from ptycho import misc
-import numpy as np
-import h5py
-
-plt.rcParams["figure.figsize"] = (10, 10)
-matplotlib.rcParams['font.size'] = 12
-
-save_model = True
-save_data = False
-
-parser = argparse.ArgumentParser(description='Script to set attributes for ptycho program')
-
-if __name__ == '__main__':
-    parser = argparse.ArgumentParser(
-                        prog = 'PtychoPINN',
-                        description = 'Generate / load data and train the model',
-                        )
-    parser.add_argument('--model_type', type=str, default='pinn', help='model type (pinn or supervised)')
-    parser.add_argument('--output_prefix', type=str, default='lines2', help='output directory prefix')
-    parser.add_argument('--data_source', type=str, default='lines', help='Dataset specification')
-    parser.add_argument('--set_phi', action='store_true', default=False, help='If true, simulated objects are given non-zero phase')
-    parser.add_argument('--nepochs', type=int, default=60, help='Number of epochs')
-    parser.add_argument('--offset', type=int, default=4, help='Scan point spacing for simulated (grid-sampled) data')
-    parser.add_argument('--gridsize', type=int, default=2, help='Solution region grid size (e.g. 2 -> 2x2, etc.)')
-    parser.add_argument('--object_big', type=bool, default=True, help='If true, reconstruct the entire solution region for each set of patterns, instead of just the central N x N region.')
-    parser.add_argument('--nll_weight', type=float, default=1., help='Diffraction reconstruction NLL loss weight')
-    parser.add_argument('--mae_weight', type=float, default=0., help='Diffraction reconstruction MAE loss weight')
-
-    parser.add_argument('--nimgs_train', type=int, default=params.cfg['nimgs_train'], help='Number of generated training images')
-    parser.add_argument('--nimgs_test', type=int, default=params.cfg['nimgs_test'], help='Number of generated testing images')
-
-    parser.add_argument('--outer_offset_train', type=int, default=None, help='Scan point grid offset for (generated) training datasets')
-    parser.add_argument('--outer_offset_test', type=int, default=None, help='Scan point grid offset for (generated) testing datasets')
-
-    parser.add_argument('--n_filters_scale', type=int, default=2, help='Number of filters scale')
-    parser.add_argument('--max_position_jitter', type=int, default=10, help='Solution region is expanded around the edges by this amount')
-    parser.add_argument('--intensity_scale_trainable', type=bool, default=True, help='If true, sets the model-internal normalization of diffraction amplitudes to trainable')
-
-    parser.add_argument('--positions_provided', type=bool, default=False, help='[deprecated] Whether nominal or true (nominal + jitter) positions are provided in simulation runs')
-    parser.add_argument('--label', type=str, default='', help='[deprecated] Name of this run')
-    args = parser.parse_args()
-
-    # offset between neighboring scan points, in pixels
-    model_type = params.cfg['model_type'] = args.model_type
-    label = params.cfg['label'] = args.label
-    params.cfg['positions.provided'] = args.positions_provided
-    params.cfg['data_source'] = args.data_source
-    params.cfg['set_phi'] = args.set_phi
-    params.cfg['nepochs'] = args.nepochs
-    offset = params.cfg['offset'] = args.offset
-    params.cfg['max_position_jitter'] = args.max_position_jitter
-    params.cfg['output_prefix'] = args.output_prefix
-    params.cfg['gridsize'] = args.gridsize
-    params.cfg['n_filters_scale'] = args.n_filters_scale
-    params.cfg['object.big'] = args.object_big
-    params.cfg['intensity_scale.trainable'] = args.intensity_scale_trainable
-    params.cfg['nll_weight'] = args.nll_weight
-    params.cfg['mae_weight'] = args.mae_weight
-    params.cfg['nimgs_train'] = args.nimgs_train
-    params.cfg['nimgs_test'] = args.nimgs_test
-
-    params.cfg['outer_offset_train'] = args.outer_offset_train
-    params.cfg['outer_offset_test'] = args.outer_offset_test
-    # Update the output_prefix using get_path_prefix
-else:
-    model_type = params.cfg['model_type']
-    label = params.cfg['label']
-    offset = params.cfg['offset']
-params.cfg['output_prefix'] = misc.get_path_prefix()
-
-# TODO this should be a global parameter that's updated once per training and / or evaluation cycle
-out_prefix = params.get('output_prefix')
-os.makedirs(out_prefix, exist_ok=True)
-
-from ptycho import generate_data
-ptycho_dataset = generate_data.ptycho_dataset
-YY_ground_truth = generate_data.YY_ground_truth
-YY_test_full = generate_data.YY_test_full
-Y_I_test = generate_data.Y_I_test
-Y_phi_test = generate_data.Y_phi_test
-X_test = generate_data.X_test
-norm_Y_I_test = generate_data.norm_Y_I_test
-from ptycho import model
-from ptycho.evaluation import save_metrics
-
-if model_type == 'pinn':
-    from ptycho import train_pinn
-    print("DEBUG: generate_data diff norm {}".format(np.mean(np.abs(ptycho_dataset.train_data.X))))
-    train_output = train_pinn.train_eval(ptycho_dataset)
-#    reconstructed_obj_cdi = train_output['reconstructed_obj_cdi']
-#    stitched_obj = train_output['stitched_obj']
-    pred_amp = train_output['pred_amp']
-    history = train_output['history']
-    reconstructed_obj = train_output['reconstructed_obj']
-    stitched_obj = train_output['stitched_obj']
-
-elif model_type == 'supervised':
-    from ptycho.train_supervised import stitched_obj
-    from ptycho import train_supervised
-    history = train_supervised.history
-    reconstructed_obj = train_supervised.reconstructed_obj
-else:
-    raise ValueError
-
-d = save_recons(model_type, stitched_obj)
-
-with open(out_prefix + '/history.dill', 'wb') as file_pi:
-    dill.dump(history.history, file_pi)
-
-if save_model:
-    from ptycho.model import ProbeIllumination, IntensityScaler, IntensityScaler_inv, negloglik
-    from ptycho.tf_helper import Translation
-    from ptycho.tf_helper import realspace_loss as hh_realspace_loss
-    hh = {'realspace_loss': hh_realspace_loss}
-
-    model_path = '{}/{}'.format(out_prefix, params.get('h5_path'))
-    custom_objects = {
-        'ProbeIllumination': ProbeIllumination,
-        'IntensityScaler': IntensityScaler,
-        'IntensityScaler_inv': IntensityScaler_inv,
-        'Translation': Translation,
-        'negloglik': negloglik,
-        'realspace_loss': hh_realspace_loss
-    }
-    try:
-        ModelManager.save_model(model.autoencoder, model_path, custom_objects, params.get('intensity_scale'))
-    except Exception as e:
-        print("model saving failed") # @debug decorators will break this
-    with h5py.File(model_path, 'a') as f:
-        f.attrs['intensity_scale'] = params.get('intensity_scale')
-
-if save_data:
-    with open(out_prefix + '/test_data.dill', 'wb') as f:
-        dill.dump(
-            {'YY_test_full': YY_test_full,
-             'Y_I_test': Y_I_test,
-             'Y_phi_test': Y_phi_test,
-             'X_test': X_test}, f)
-
diff --git a/ptycho/inference.py b/ptycho/inference.py
index 8a73f9d..0af9bf6 100644
--- a/ptycho/inference.py
+++ b/ptycho/inference.py
@@ -1,9 +1,63 @@
 """
-Legacy inference utilities for loading pre-trained models and performing reconstruction.
+Legacy inference utilities for loading pre-trained models and performing ptychographic reconstruction.
 
-Example:
-    >>> results = inference_flow("model.h5", data_container)
-    >>> reconstructed_obj = results['reconstructed_obj']
+This module provides a simplified interface for running inference with pre-trained PtychoPINN models.
+It handles model loading, data preparation, and reconstruction execution in a streamlined workflow.
+The module serves as a bridge between saved model artifacts and the inference pipeline, abstracting
+away the complexities of model initialization and data preprocessing.
+
+Architecture Role:
+    Sits between the training pipeline and end-user inference workflows:
+    Saved Model (.h5) + Test Data ‚Üí Model Loading ‚Üí Data Preparation ‚Üí Inference Execution ‚Üí Reconstruction Results
+    
+    Key responsibilities:
+    - Load pre-trained models via ModelManager
+    - Prepare PtychoDataContainer inputs for inference
+    - Execute model prediction with proper data scaling
+    - Return structured reconstruction results
+    - Provide fallback object stitching capabilities
+
+Public Interface:
+    `inference_flow(model_path, data_container)`
+        - Purpose: Complete end-to-end inference workflow
+        - Critical Behavior: Applies intensity scaling from global params during data preparation
+        - Key Parameters: model_path (H5 file or None for params.h5_path), data_container (preprocessed data)
+    
+    `load_pretrained_model(model_path)`
+        - Purpose: Load saved model weights and architecture via ModelManager
+        - Critical Behavior: Delegates to ModelManager.load_model() for proper model restoration
+        - Key Parameters: model_path (path to .h5 model file)
+    
+    `perform_inference(model, X, coords_nominal)`
+        - Purpose: Execute model prediction on prepared inputs
+        - Critical Behavior: Returns dict with 'reconstructed_obj', 'pred_amp', 'reconstructed_obj_cdi'
+        - Key Parameters: model (loaded Keras model), X (scaled diffraction data), coords_nominal (scan positions)
+
+Workflow Usage Example:
+    ```python
+    from ptycho.loader import PtychoDataContainer
+    from ptycho.inference import inference_flow
+    
+    # Load test data
+    data_container = PtychoDataContainer.from_file("test_data.npz")
+    
+    # Run complete inference pipeline
+    results = inference_flow("trained_model.h5", data_container)
+    
+    # Extract results
+    reconstructed_object = results['reconstructed_obj']
+    predicted_amplitudes = results['pred_amp']
+    cdi_reconstruction = results['reconstructed_obj_cdi']
+    ```
+
+Architectural Notes & Dependencies:
+- ModelManager: Handles model loading/saving with proper weight restoration
+- PtychoDataContainer: Provides preprocessed, model-ready diffraction data and coordinates
+- Global params: Used for intensity scaling factor and fallback model paths
+- ptycho.model: Direct import for accessing model parameters during data preparation
+- ptycho.image: Optional dependency for modern object stitching capabilities
+- State Dependency: Relies on global params configuration for intensity_scale and h5_path defaults
+- Legacy Note: This module uses older parameter access patterns and is marked for consolidation with train_pinn
 """
 from ptycho.model_manager import ModelManager
 from tensorflow.keras.models import Model
diff --git a/ptychoPINN.egg-info/PKG-INFO b/ptychoPINN.egg-info/PKG-INFO
deleted file mode 100644
index ceff57a..0000000
--- a/ptychoPINN.egg-info/PKG-INFO
+++ /dev/null
@@ -1,33 +0,0 @@
-Metadata-Version: 2.4
-Name: ptychoPINN
-Version: 0.0.0
-License-File: LICENSE
-Requires-Dist: dill
-Requires-Dist: numpy
-Requires-Dist: pandas
-Requires-Dist: pandas-datareader
-Requires-Dist: pathos
-Requires-Dist: scikit-learn
-Requires-Dist: scipy==1.13.0
-Requires-Dist: tensorboard
-Requires-Dist: tensorboard-data-server
-Requires-Dist: tensorboard-plugin-wit
-Requires-Dist: tensorflow[and-cuda]
-Requires-Dist: keras==2.14.0
-Requires-Dist: tensorflow-datasets
-Requires-Dist: tensorflow-estimator
-Requires-Dist: tensorflow-hub
-Requires-Dist: tensorflow-probability==0.23.0
-Requires-Dist: ujson
-Requires-Dist: matplotlib
-Requires-Dist: Pillow
-Requires-Dist: imageio
-Requires-Dist: ipywidgets
-Requires-Dist: tqdm
-Requires-Dist: tensorflow-addons
-Requires-Dist: jupyter
-Requires-Dist: globus-compute-endpoint
-Requires-Dist: scikit-image
-Requires-Dist: opencv-python
-Dynamic: license-file
-Dynamic: requires-dist
diff --git a/ptychoPINN.egg-info/SOURCES.txt b/ptychoPINN.egg-info/SOURCES.txt
deleted file mode 100644
index 7629a27..0000000
--- a/ptychoPINN.egg-info/SOURCES.txt
+++ /dev/null
@@ -1,66 +0,0 @@
-LICENSE
-README.md
-setup.py
-ptycho/__init__.py
-ptycho/baselines.py
-ptycho/classes.py
-ptycho/data_preprocessing.py
-ptycho/diffsim.py
-ptycho/evaluation.py
-ptycho/experimental.py
-ptycho/export.py
-ptycho/fourier.py
-ptycho/function_logger.py
-ptycho/generate_data.py
-ptycho/inference.py
-ptycho/loader.py
-ptycho/logging.py
-ptycho/losses.py
-ptycho/misc.py
-ptycho/model.py
-ptycho/model_manager.py
-ptycho/nbutils.py
-ptycho/params.py
-ptycho/physics.py
-ptycho/plotting.py
-ptycho/probe.py
-ptycho/tf_helper.py
-ptycho/train.py
-ptycho/train_pinn.py
-ptycho/train_supervised.py
-ptycho/visualization.py
-ptycho/xpp.py
-ptycho/autotest/__init__.py
-ptycho/autotest/configuration.py
-ptycho/autotest/debug.py
-ptycho/autotest/functionmapping.py
-ptycho/autotest/logger.py
-ptycho/autotest/serializer.py
-ptycho/autotest/testing.py
-ptycho/datagen/__init__.py
-ptycho/datagen/diagonals.py
-ptycho/datagen/grf.py
-ptycho/datagen/points.py
-ptycho/datagen/testimg.py
-ptycho/datagen/vendetta.py
-ptycho/datasets/Run1084_recon3_postPC.npz
-ptycho/datasets/Run1084_recon3_postPC_shrunk_3.npz
-ptychoPINN.egg-info/PKG-INFO
-ptychoPINN.egg-info/SOURCES.txt
-ptychoPINN.egg-info/dependency_links.txt
-ptychoPINN.egg-info/not-zip-safe
-ptychoPINN.egg-info/requires.txt
-ptychoPINN.egg-info/top_level.txt
-ptycho_torch/__init__.py
-ptycho_torch/config_params.py
-ptycho_torch/datagen.py
-ptycho_torch/dset_loader_pt_mmap.py
-ptycho_torch/helper.py
-ptycho_torch/model.py
-ptycho_torch/patch_generator.py
-ptycho_torch/train.py
-ptycho_torch/train_dummy.py
-tests/test_generate_data.py
-tests/test_generic_loader.py
-tests/test_pytorch_tf_wrapper.py
-tests/test_tf_helper.py
\ No newline at end of file
diff --git a/ptychoPINN.egg-info/dependency_links.txt b/ptychoPINN.egg-info/dependency_links.txt
deleted file mode 100644
index 8b13789..0000000
--- a/ptychoPINN.egg-info/dependency_links.txt
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/ptychoPINN.egg-info/not-zip-safe b/ptychoPINN.egg-info/not-zip-safe
deleted file mode 100644
index 8b13789..0000000
--- a/ptychoPINN.egg-info/not-zip-safe
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/ptychoPINN.egg-info/requires.txt b/ptychoPINN.egg-info/requires.txt
deleted file mode 100644
index a46c6c5..0000000
--- a/ptychoPINN.egg-info/requires.txt
+++ /dev/null
@@ -1,27 +0,0 @@
-dill
-numpy
-pandas
-pandas-datareader
-pathos
-scikit-learn
-scipy==1.13.0
-tensorboard
-tensorboard-data-server
-tensorboard-plugin-wit
-tensorflow[and-cuda]
-keras==2.14.0
-tensorflow-datasets
-tensorflow-estimator
-tensorflow-hub
-tensorflow-probability==0.23.0
-ujson
-matplotlib
-Pillow
-imageio
-ipywidgets
-tqdm
-tensorflow-addons
-jupyter
-globus-compute-endpoint
-scikit-image
-opencv-python
diff --git a/ptychoPINN.egg-info/top_level.txt b/ptychoPINN.egg-info/top_level.txt
deleted file mode 100644
index a216bd6..0000000
--- a/ptychoPINN.egg-info/top_level.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-FRC
-ptycho
-ptycho_torch
diff --git a/ptychopinn.egg-info/PKG-INFO b/ptychopinn.egg-info/PKG-INFO
deleted file mode 100644
index 4b2b4b7..0000000
--- a/ptychopinn.egg-info/PKG-INFO
+++ /dev/null
@@ -1,786 +0,0 @@
-Metadata-Version: 2.4
-Name: ptychopinn
-Version: 0.1.dev770+g67874c9.d20250730
-Summary: PtychoPINN is an unsupervised physics-informed neural network reconstruction method for scanning CDI
-License:                     GNU GENERAL PUBLIC LICENSE
-                               Version 3, 29 June 2007
-        
-         Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
-         Everyone is permitted to copy and distribute verbatim copies
-         of this license document, but changing it is not allowed.
-        
-                                    Preamble
-        
-          The GNU General Public License is a free, copyleft license for
-        software and other kinds of works.
-        
-          The licenses for most software and other practical works are designed
-        to take away your freedom to share and change the works.  By contrast,
-        the GNU General Public License is intended to guarantee your freedom to
-        share and change all versions of a program--to make sure it remains free
-        software for all its users.  We, the Free Software Foundation, use the
-        GNU General Public License for most of our software; it applies also to
-        any other work released this way by its authors.  You can apply it to
-        your programs, too.
-        
-          When we speak of free software, we are referring to freedom, not
-        price.  Our General Public Licenses are designed to make sure that you
-        have the freedom to distribute copies of free software (and charge for
-        them if you wish), that you receive source code or can get it if you
-        want it, that you can change the software or use pieces of it in new
-        free programs, and that you know you can do these things.
-        
-          To protect your rights, we need to prevent others from denying you
-        these rights or asking you to surrender the rights.  Therefore, you have
-        certain responsibilities if you distribute copies of the software, or if
-        you modify it: responsibilities to respect the freedom of others.
-        
-          For example, if you distribute copies of such a program, whether
-        gratis or for a fee, you must pass on to the recipients the same
-        freedoms that you received.  You must make sure that they, too, receive
-        or can get the source code.  And you must show them these terms so they
-        know their rights.
-        
-          Developers that use the GNU GPL protect your rights with two steps:
-        (1) assert copyright on the software, and (2) offer you this License
-        giving you legal permission to copy, distribute and/or modify it.
-        
-          For the developers' and authors' protection, the GPL clearly explains
-        that there is no warranty for this free software.  For both users' and
-        authors' sake, the GPL requires that modified versions be marked as
-        changed, so that their problems will not be attributed erroneously to
-        authors of previous versions.
-        
-          Some devices are designed to deny users access to install or run
-        modified versions of the software inside them, although the manufacturer
-        can do so.  This is fundamentally incompatible with the aim of
-        protecting users' freedom to change the software.  The systematic
-        pattern of such abuse occurs in the area of products for individuals to
-        use, which is precisely where it is most unacceptable.  Therefore, we
-        have designed this version of the GPL to prohibit the practice for those
-        products.  If such problems arise substantially in other domains, we
-        stand ready to extend this provision to those domains in future versions
-        of the GPL, as needed to protect the freedom of users.
-        
-          Finally, every program is threatened constantly by software patents.
-        States should not allow patents to restrict development and use of
-        software on general-purpose computers, but in those that do, we wish to
-        avoid the special danger that patents applied to a free program could
-        make it effectively proprietary.  To prevent this, the GPL assures that
-        patents cannot be used to render the program non-free.
-        
-          The precise terms and conditions for copying, distribution and
-        modification follow.
-        
-                               TERMS AND CONDITIONS
-        
-          0. Definitions.
-        
-          "This License" refers to version 3 of the GNU General Public License.
-        
-          "Copyright" also means copyright-like laws that apply to other kinds of
-        works, such as semiconductor masks.
-        
-          "The Program" refers to any copyrightable work licensed under this
-        License.  Each licensee is addressed as "you".  "Licensees" and
-        "recipients" may be individuals or organizations.
-        
-          To "modify" a work means to copy from or adapt all or part of the work
-        in a fashion requiring copyright permission, other than the making of an
-        exact copy.  The resulting work is called a "modified version" of the
-        earlier work or a work "based on" the earlier work.
-        
-          A "covered work" means either the unmodified Program or a work based
-        on the Program.
-        
-          To "propagate" a work means to do anything with it that, without
-        permission, would make you directly or secondarily liable for
-        infringement under applicable copyright law, except executing it on a
-        computer or modifying a private copy.  Propagation includes copying,
-        distribution (with or without modification), making available to the
-        public, and in some countries other activities as well.
-        
-          To "convey" a work means any kind of propagation that enables other
-        parties to make or receive copies.  Mere interaction with a user through
-        a computer network, with no transfer of a copy, is not conveying.
-        
-          An interactive user interface displays "Appropriate Legal Notices"
-        to the extent that it includes a convenient and prominently visible
-        feature that (1) displays an appropriate copyright notice, and (2)
-        tells the user that there is no warranty for the work (except to the
-        extent that warranties are provided), that licensees may convey the
-        work under this License, and how to view a copy of this License.  If
-        the interface presents a list of user commands or options, such as a
-        menu, a prominent item in the list meets this criterion.
-        
-          1. Source Code.
-        
-          The "source code" for a work means the preferred form of the work
-        for making modifications to it.  "Object code" means any non-source
-        form of a work.
-        
-          A "Standard Interface" means an interface that either is an official
-        standard defined by a recognized standards body, or, in the case of
-        interfaces specified for a particular programming language, one that
-        is widely used among developers working in that language.
-        
-          The "System Libraries" of an executable work include anything, other
-        than the work as a whole, that (a) is included in the normal form of
-        packaging a Major Component, but which is not part of that Major
-        Component, and (b) serves only to enable use of the work with that
-        Major Component, or to implement a Standard Interface for which an
-        implementation is available to the public in source code form.  A
-        "Major Component", in this context, means a major essential component
-        (kernel, window system, and so on) of the specific operating system
-        (if any) on which the executable work runs, or a compiler used to
-        produce the work, or an object code interpreter used to run it.
-        
-          The "Corresponding Source" for a work in object code form means all
-        the source code needed to generate, install, and (for an executable
-        work) run the object code and to modify the work, including scripts to
-        control those activities.  However, it does not include the work's
-        System Libraries, or general-purpose tools or generally available free
-        programs which are used unmodified in performing those activities but
-        which are not part of the work.  For example, Corresponding Source
-        includes interface definition files associated with source files for
-        the work, and the source code for shared libraries and dynamically
-        linked subprograms that the work is specifically designed to require,
-        such as by intimate data communication or control flow between those
-        subprograms and other parts of the work.
-        
-          The Corresponding Source need not include anything that users
-        can regenerate automatically from other parts of the Corresponding
-        Source.
-        
-          The Corresponding Source for a work in source code form is that
-        same work.
-        
-          2. Basic Permissions.
-        
-          All rights granted under this License are granted for the term of
-        copyright on the Program, and are irrevocable provided the stated
-        conditions are met.  This License explicitly affirms your unlimited
-        permission to run the unmodified Program.  The output from running a
-        covered work is covered by this License only if the output, given its
-        content, constitutes a covered work.  This License acknowledges your
-        rights of fair use or other equivalent, as provided by copyright law.
-        
-          You may make, run and propagate covered works that you do not
-        convey, without conditions so long as your license otherwise remains
-        in force.  You may convey covered works to others for the sole purpose
-        of having them make modifications exclusively for you, or provide you
-        with facilities for running those works, provided that you comply with
-        the terms of this License in conveying all material for which you do
-        not control copyright.  Those thus making or running the covered works
-        for you must do so exclusively on your behalf, under your direction
-        and control, on terms that prohibit them from making any copies of
-        your copyrighted material outside their relationship with you.
-        
-          Conveying under any other circumstances is permitted solely under
-        the conditions stated below.  Sublicensing is not allowed; section 10
-        makes it unnecessary.
-        
-          3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-        
-          No covered work shall be deemed part of an effective technological
-        measure under any applicable law fulfilling obligations under article
-        11 of the WIPO copyright treaty adopted on 20 December 1996, or
-        similar laws prohibiting or restricting circumvention of such
-        measures.
-        
-          When you convey a covered work, you waive any legal power to forbid
-        circumvention of technological measures to the extent such circumvention
-        is effected by exercising rights under this License with respect to
-        the covered work, and you disclaim any intention to limit operation or
-        modification of the work as a means of enforcing, against the work's
-        users, your or third parties' legal rights to forbid circumvention of
-        technological measures.
-        
-          4. Conveying Verbatim Copies.
-        
-          You may convey verbatim copies of the Program's source code as you
-        receive it, in any medium, provided that you conspicuously and
-        appropriately publish on each copy an appropriate copyright notice;
-        keep intact all notices stating that this License and any
-        non-permissive terms added in accord with section 7 apply to the code;
-        keep intact all notices of the absence of any warranty; and give all
-        recipients a copy of this License along with the Program.
-        
-          You may charge any price or no price for each copy that you convey,
-        and you may offer support or warranty protection for a fee.
-        
-          5. Conveying Modified Source Versions.
-        
-          You may convey a work based on the Program, or the modifications to
-        produce it from the Program, in the form of source code under the
-        terms of section 4, provided that you also meet all of these conditions:
-        
-            a) The work must carry prominent notices stating that you modified
-            it, and giving a relevant date.
-        
-            b) The work must carry prominent notices stating that it is
-            released under this License and any conditions added under section
-            7.  This requirement modifies the requirement in section 4 to
-            "keep intact all notices".
-        
-            c) You must license the entire work, as a whole, under this
-            License to anyone who comes into possession of a copy.  This
-            License will therefore apply, along with any applicable section 7
-            additional terms, to the whole of the work, and all its parts,
-            regardless of how they are packaged.  This License gives no
-            permission to license the work in any other way, but it does not
-            invalidate such permission if you have separately received it.
-        
-            d) If the work has interactive user interfaces, each must display
-            Appropriate Legal Notices; however, if the Program has interactive
-            interfaces that do not display Appropriate Legal Notices, your
-            work need not make them do so.
-        
-          A compilation of a covered work with other separate and independent
-        works, which are not by their nature extensions of the covered work,
-        and which are not combined with it such as to form a larger program,
-        in or on a volume of a storage or distribution medium, is called an
-        "aggregate" if the compilation and its resulting copyright are not
-        used to limit the access or legal rights of the compilation's users
-        beyond what the individual works permit.  Inclusion of a covered work
-        in an aggregate does not cause this License to apply to the other
-        parts of the aggregate.
-        
-          6. Conveying Non-Source Forms.
-        
-          You may convey a covered work in object code form under the terms
-        of sections 4 and 5, provided that you also convey the
-        machine-readable Corresponding Source under the terms of this License,
-        in one of these ways:
-        
-            a) Convey the object code in, or embodied in, a physical product
-            (including a physical distribution medium), accompanied by the
-            Corresponding Source fixed on a durable physical medium
-            customarily used for software interchange.
-        
-            b) Convey the object code in, or embodied in, a physical product
-            (including a physical distribution medium), accompanied by a
-            written offer, valid for at least three years and valid for as
-            long as you offer spare parts or customer support for that product
-            model, to give anyone who possesses the object code either (1) a
-            copy of the Corresponding Source for all the software in the
-            product that is covered by this License, on a durable physical
-            medium customarily used for software interchange, for a price no
-            more than your reasonable cost of physically performing this
-            conveying of source, or (2) access to copy the
-            Corresponding Source from a network server at no charge.
-        
-            c) Convey individual copies of the object code with a copy of the
-            written offer to provide the Corresponding Source.  This
-            alternative is allowed only occasionally and noncommercially, and
-            only if you received the object code with such an offer, in accord
-            with subsection 6b.
-        
-            d) Convey the object code by offering access from a designated
-            place (gratis or for a charge), and offer equivalent access to the
-            Corresponding Source in the same way through the same place at no
-            further charge.  You need not require recipients to copy the
-            Corresponding Source along with the object code.  If the place to
-            copy the object code is a network server, the Corresponding Source
-            may be on a different server (operated by you or a third party)
-            that supports equivalent copying facilities, provided you maintain
-            clear directions next to the object code saying where to find the
-            Corresponding Source.  Regardless of what server hosts the
-            Corresponding Source, you remain obligated to ensure that it is
-            available for as long as needed to satisfy these requirements.
-        
-            e) Convey the object code using peer-to-peer transmission, provided
-            you inform other peers where the object code and Corresponding
-            Source of the work are being offered to the general public at no
-            charge under subsection 6d.
-        
-          A separable portion of the object code, whose source code is excluded
-        from the Corresponding Source as a System Library, need not be
-        included in conveying the object code work.
-        
-          A "User Product" is either (1) a "consumer product", which means any
-        tangible personal property which is normally used for personal, family,
-        or household purposes, or (2) anything designed or sold for incorporation
-        into a dwelling.  In determining whether a product is a consumer product,
-        doubtful cases shall be resolved in favor of coverage.  For a particular
-        product received by a particular user, "normally used" refers to a
-        typical or common use of that class of product, regardless of the status
-        of the particular user or of the way in which the particular user
-        actually uses, or expects or is expected to use, the product.  A product
-        is a consumer product regardless of whether the product has substantial
-        commercial, industrial or non-consumer uses, unless such uses represent
-        the only significant mode of use of the product.
-        
-          "Installation Information" for a User Product means any methods,
-        procedures, authorization keys, or other information required to install
-        and execute modified versions of a covered work in that User Product from
-        a modified version of its Corresponding Source.  The information must
-        suffice to ensure that the continued functioning of the modified object
-        code is in no case prevented or interfered with solely because
-        modification has been made.
-        
-          If you convey an object code work under this section in, or with, or
-        specifically for use in, a User Product, and the conveying occurs as
-        part of a transaction in which the right of possession and use of the
-        User Product is transferred to the recipient in perpetuity or for a
-        fixed term (regardless of how the transaction is characterized), the
-        Corresponding Source conveyed under this section must be accompanied
-        by the Installation Information.  But this requirement does not apply
-        if neither you nor any third party retains the ability to install
-        modified object code on the User Product (for example, the work has
-        been installed in ROM).
-        
-          The requirement to provide Installation Information does not include a
-        requirement to continue to provide support service, warranty, or updates
-        for a work that has been modified or installed by the recipient, or for
-        the User Product in which it has been modified or installed.  Access to a
-        network may be denied when the modification itself materially and
-        adversely affects the operation of the network or violates the rules and
-        protocols for communication across the network.
-        
-          Corresponding Source conveyed, and Installation Information provided,
-        in accord with this section must be in a format that is publicly
-        documented (and with an implementation available to the public in
-        source code form), and must require no special password or key for
-        unpacking, reading or copying.
-        
-          7. Additional Terms.
-        
-          "Additional permissions" are terms that supplement the terms of this
-        License by making exceptions from one or more of its conditions.
-        Additional permissions that are applicable to the entire Program shall
-        be treated as though they were included in this License, to the extent
-        that they are valid under applicable law.  If additional permissions
-        apply only to part of the Program, that part may be used separately
-        under those permissions, but the entire Program remains governed by
-        this License without regard to the additional permissions.
-        
-          When you convey a copy of a covered work, you may at your option
-        remove any additional permissions from that copy, or from any part of
-        it.  (Additional permissions may be written to require their own
-        removal in certain cases when you modify the work.)  You may place
-        additional permissions on material, added by you to a covered work,
-        for which you have or can give appropriate copyright permission.
-        
-          Notwithstanding any other provision of this License, for material you
-        add to a covered work, you may (if authorized by the copyright holders of
-        that material) supplement the terms of this License with terms:
-        
-            a) Disclaiming warranty or limiting liability differently from the
-            terms of sections 15 and 16 of this License; or
-        
-            b) Requiring preservation of specified reasonable legal notices or
-            author attributions in that material or in the Appropriate Legal
-            Notices displayed by works containing it; or
-        
-            c) Prohibiting misrepresentation of the origin of that material, or
-            requiring that modified versions of such material be marked in
-            reasonable ways as different from the original version; or
-        
-            d) Limiting the use for publicity purposes of names of licensors or
-            authors of the material; or
-        
-            e) Declining to grant rights under trademark law for use of some
-            trade names, trademarks, or service marks; or
-        
-            f) Requiring indemnification of licensors and authors of that
-            material by anyone who conveys the material (or modified versions of
-            it) with contractual assumptions of liability to the recipient, for
-            any liability that these contractual assumptions directly impose on
-            those licensors and authors.
-        
-          All other non-permissive additional terms are considered "further
-        restrictions" within the meaning of section 10.  If the Program as you
-        received it, or any part of it, contains a notice stating that it is
-        governed by this License along with a term that is a further
-        restriction, you may remove that term.  If a license document contains
-        a further restriction but permits relicensing or conveying under this
-        License, you may add to a covered work material governed by the terms
-        of that license document, provided that the further restriction does
-        not survive such relicensing or conveying.
-        
-          If you add terms to a covered work in accord with this section, you
-        must place, in the relevant source files, a statement of the
-        additional terms that apply to those files, or a notice indicating
-        where to find the applicable terms.
-        
-          Additional terms, permissive or non-permissive, may be stated in the
-        form of a separately written license, or stated as exceptions;
-        the above requirements apply either way.
-        
-          8. Termination.
-        
-          You may not propagate or modify a covered work except as expressly
-        provided under this License.  Any attempt otherwise to propagate or
-        modify it is void, and will automatically terminate your rights under
-        this License (including any patent licenses granted under the third
-        paragraph of section 11).
-        
-          However, if you cease all violation of this License, then your
-        license from a particular copyright holder is reinstated (a)
-        provisionally, unless and until the copyright holder explicitly and
-        finally terminates your license, and (b) permanently, if the copyright
-        holder fails to notify you of the violation by some reasonable means
-        prior to 60 days after the cessation.
-        
-          Moreover, your license from a particular copyright holder is
-        reinstated permanently if the copyright holder notifies you of the
-        violation by some reasonable means, this is the first time you have
-        received notice of violation of this License (for any work) from that
-        copyright holder, and you cure the violation prior to 30 days after
-        your receipt of the notice.
-        
-          Termination of your rights under this section does not terminate the
-        licenses of parties who have received copies or rights from you under
-        this License.  If your rights have been terminated and not permanently
-        reinstated, you do not qualify to receive new licenses for the same
-        material under section 10.
-        
-          9. Acceptance Not Required for Having Copies.
-        
-          You are not required to accept this License in order to receive or
-        run a copy of the Program.  Ancillary propagation of a covered work
-        occurring solely as a consequence of using peer-to-peer transmission
-        to receive a copy likewise does not require acceptance.  However,
-        nothing other than this License grants you permission to propagate or
-        modify any covered work.  These actions infringe copyright if you do
-        not accept this License.  Therefore, by modifying or propagating a
-        covered work, you indicate your acceptance of this License to do so.
-        
-          10. Automatic Licensing of Downstream Recipients.
-        
-          Each time you convey a covered work, the recipient automatically
-        receives a license from the original licensors, to run, modify and
-        propagate that work, subject to this License.  You are not responsible
-        for enforcing compliance by third parties with this License.
-        
-          An "entity transaction" is a transaction transferring control of an
-        organization, or substantially all assets of one, or subdividing an
-        organization, or merging organizations.  If propagation of a covered
-        work results from an entity transaction, each party to that
-        transaction who receives a copy of the work also receives whatever
-        licenses to the work the party's predecessor in interest had or could
-        give under the previous paragraph, plus a right to possession of the
-        Corresponding Source of the work from the predecessor in interest, if
-        the predecessor has it or can get it with reasonable efforts.
-        
-          You may not impose any further restrictions on the exercise of the
-        rights granted or affirmed under this License.  For example, you may
-        not impose a license fee, royalty, or other charge for exercise of
-        rights granted under this License, and you may not initiate litigation
-        (including a cross-claim or counterclaim in a lawsuit) alleging that
-        any patent claim is infringed by making, using, selling, offering for
-        sale, or importing the Program or any portion of it.
-        
-          11. Patents.
-        
-          A "contributor" is a copyright holder who authorizes use under this
-        License of the Program or a work on which the Program is based.  The
-        work thus licensed is called the contributor's "contributor version".
-        
-          A contributor's "essential patent claims" are all patent claims
-        owned or controlled by the contributor, whether already acquired or
-        hereafter acquired, that would be infringed by some manner, permitted
-        by this License, of making, using, or selling its contributor version,
-        but do not include claims that would be infringed only as a
-        consequence of further modification of the contributor version.  For
-        purposes of this definition, "control" includes the right to grant
-        patent sublicenses in a manner consistent with the requirements of
-        this License.
-        
-          Each contributor grants you a non-exclusive, worldwide, royalty-free
-        patent license under the contributor's essential patent claims, to
-        make, use, sell, offer for sale, import and otherwise run, modify and
-        propagate the contents of its contributor version.
-        
-          In the following three paragraphs, a "patent license" is any express
-        agreement or commitment, however denominated, not to enforce a patent
-        (such as an express permission to practice a patent or covenant not to
-        sue for patent infringement).  To "grant" such a patent license to a
-        party means to make such an agreement or commitment not to enforce a
-        patent against the party.
-        
-          If you convey a covered work, knowingly relying on a patent license,
-        and the Corresponding Source of the work is not available for anyone
-        to copy, free of charge and under the terms of this License, through a
-        publicly available network server or other readily accessible means,
-        then you must either (1) cause the Corresponding Source to be so
-        available, or (2) arrange to deprive yourself of the benefit of the
-        patent license for this particular work, or (3) arrange, in a manner
-        consistent with the requirements of this License, to extend the patent
-        license to downstream recipients.  "Knowingly relying" means you have
-        actual knowledge that, but for the patent license, your conveying the
-        covered work in a country, or your recipient's use of the covered work
-        in a country, would infringe one or more identifiable patents in that
-        country that you have reason to believe are valid.
-        
-          If, pursuant to or in connection with a single transaction or
-        arrangement, you convey, or propagate by procuring conveyance of, a
-        covered work, and grant a patent license to some of the parties
-        receiving the covered work authorizing them to use, propagate, modify
-        or convey a specific copy of the covered work, then the patent license
-        you grant is automatically extended to all recipients of the covered
-        work and works based on it.
-        
-          A patent license is "discriminatory" if it does not include within
-        the scope of its coverage, prohibits the exercise of, or is
-        conditioned on the non-exercise of one or more of the rights that are
-        specifically granted under this License.  You may not convey a covered
-        work if you are a party to an arrangement with a third party that is
-        in the business of distributing software, under which you make payment
-        to the third party based on the extent of your activity of conveying
-        the work, and under which the third party grants, to any of the
-        parties who would receive the covered work from you, a discriminatory
-        patent license (a) in connection with copies of the covered work
-        conveyed by you (or copies made from those copies), or (b) primarily
-        for and in connection with specific products or compilations that
-        contain the covered work, unless you entered into that arrangement,
-        or that patent license was granted, prior to 28 March 2007.
-        
-          Nothing in this License shall be construed as excluding or limiting
-        any implied license or other defenses to infringement that may
-        otherwise be available to you under applicable patent law.
-        
-          12. No Surrender of Others' Freedom.
-        
-          If conditions are imposed on you (whether by court order, agreement or
-        otherwise) that contradict the conditions of this License, they do not
-        excuse you from the conditions of this License.  If you cannot convey a
-        covered work so as to satisfy simultaneously your obligations under this
-        License and any other pertinent obligations, then as a consequence you may
-        not convey it at all.  For example, if you agree to terms that obligate you
-        to collect a royalty for further conveying from those to whom you convey
-        the Program, the only way you could satisfy both those terms and this
-        License would be to refrain entirely from conveying the Program.
-        
-          13. Use with the GNU Affero General Public License.
-        
-          Notwithstanding any other provision of this License, you have
-        permission to link or combine any covered work with a work licensed
-        under version 3 of the GNU Affero General Public License into a single
-        combined work, and to convey the resulting work.  The terms of this
-        License will continue to apply to the part which is the covered work,
-        but the special requirements of the GNU Affero General Public License,
-        section 13, concerning interaction through a network will apply to the
-        combination as such.
-        
-          14. Revised Versions of this License.
-        
-          The Free Software Foundation may publish revised and/or new versions of
-        the GNU General Public License from time to time.  Such new versions will
-        be similar in spirit to the present version, but may differ in detail to
-        address new problems or concerns.
-        
-          Each version is given a distinguishing version number.  If the
-        Program specifies that a certain numbered version of the GNU General
-        Public License "or any later version" applies to it, you have the
-        option of following the terms and conditions either of that numbered
-        version or of any later version published by the Free Software
-        Foundation.  If the Program does not specify a version number of the
-        GNU General Public License, you may choose any version ever published
-        by the Free Software Foundation.
-        
-          If the Program specifies that a proxy can decide which future
-        versions of the GNU General Public License can be used, that proxy's
-        public statement of acceptance of a version permanently authorizes you
-        to choose that version for the Program.
-        
-          Later license versions may give you additional or different
-        permissions.  However, no additional obligations are imposed on any
-        author or copyright holder as a result of your choosing to follow a
-        later version.
-        
-          15. Disclaimer of Warranty.
-        
-          THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-        APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-        HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
-        OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-        THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-        PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-        IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-        ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-        
-          16. Limitation of Liability.
-        
-          IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-        WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-        THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-        GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-        USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-        DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-        PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-        EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-        SUCH DAMAGES.
-        
-          17. Interpretation of Sections 15 and 16.
-        
-          If the disclaimer of warranty and limitation of liability provided
-        above cannot be given local legal effect according to their terms,
-        reviewing courts shall apply local law that most closely approximates
-        an absolute waiver of all civil liability in connection with the
-        Program, unless a warranty or assumption of liability accompanies a
-        copy of the Program in return for a fee.
-        
-                             END OF TERMS AND CONDITIONS
-        
-                    How to Apply These Terms to Your New Programs
-        
-          If you develop a new program, and you want it to be of the greatest
-        possible use to the public, the best way to achieve this is to make it
-        free software which everyone can redistribute and change under these terms.
-        
-          To do so, attach the following notices to the program.  It is safest
-        to attach them to the start of each source file to most effectively
-        state the exclusion of warranty; and each file should have at least
-        the "copyright" line and a pointer to where the full notice is found.
-        
-            <one line to give the program's name and a brief idea of what it does.>
-            Copyright (C) <year>  <name of author>
-        
-            This program is free software: you can redistribute it and/or modify
-            it under the terms of the GNU General Public License as published by
-            the Free Software Foundation, either version 3 of the License, or
-            (at your option) any later version.
-        
-            This program is distributed in the hope that it will be useful,
-            but WITHOUT ANY WARRANTY; without even the implied warranty of
-            MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-            GNU General Public License for more details.
-        
-            You should have received a copy of the GNU General Public License
-            along with this program.  If not, see <https://www.gnu.org/licenses/>.
-        
-        Also add information on how to contact you by electronic and paper mail.
-        
-          If the program does terminal interaction, make it output a short
-        notice like this when it starts in an interactive mode:
-        
-            <program>  Copyright (C) <year>  <name of author>
-            This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-            This is free software, and you are welcome to redistribute it
-            under certain conditions; type `show c' for details.
-        
-        The hypothetical commands `show w' and `show c' should show the appropriate
-        parts of the General Public License.  Of course, your program's commands
-        might be different; for a GUI interface, you would use an "about box".
-        
-          You should also get your employer (if you work as a programmer) or school,
-        if any, to sign a "copyright disclaimer" for the program, if necessary.
-        For more information on this, and how to apply and follow the GNU GPL, see
-        <https://www.gnu.org/licenses/>.
-        
-          The GNU General Public License does not permit incorporating your program
-        into proprietary programs.  If your program is a subroutine library, you
-        may consider it more useful to permit linking proprietary applications with
-        the library.  If this is what you want to do, use the GNU Lesser General
-        Public License instead of this License.  But first, please read
-        <https://www.gnu.org/licenses/why-not-lgpl.html>.
-        
-Requires-Python: <3.12,>=3.10
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: Pillow
-Requires-Dist: dill
-Requires-Dist: imageio
-Requires-Dist: ipywidgets
-Requires-Dist: jupyter
-Requires-Dist: matplotlib
-Requires-Dist: numba
-Requires-Dist: numpy
-Requires-Dist: opencv-python
-Requires-Dist: pandas
-Requires-Dist: pandas-datareader
-Requires-Dist: pathos
-Requires-Dist: scikit-image
-Requires-Dist: scikit-learn
-Requires-Dist: scipy
-Requires-Dist: tensorflow[and-cuda]>=2.13.0
-Requires-Dist: tensorflow-datasets
-Requires-Dist: tensorflow-hub
-Requires-Dist: tensorflow-metadata
-Requires-Dist: tensorflow-probability
-Requires-Dist: torch
-Requires-Dist: tqdm
-Requires-Dist: ujson
-Dynamic: license-file
-
-# Physics constrained machine learning for rapid, high resolution diffractive imaging
-
-This repository contains the codebase for the methods presented in the paper "[Physics Constrained Unsupervised Deep Learning for Rapid, High Resolution Scanning Coherent Diffraction Reconstruction](https://www.nature.com/articles/s41598-023-48351-7)". 
-
-## Overview
-PtychoPINN is an unsupervised physics-informed neural network reconstruction method for scanning CDI designed to improve upon the speed of conventional reconstruction methods without sacrificing image quality. Compared to prior NN approaches, the main source of improvements in image quality are its combination of the diffraction forward map with real-space overlap constraints.
-
-## For Developers
-
-Developers looking to contribute to the codebase or understand its deeper architectural principles should first read the **[Unified Developer Guide](./docs/DEVELOPER_GUIDE.md)**. It contains critical information on the project's design, data pipeline, and best practices.
-
-## Features
-- **Unsupervised / self-supervised learning**: There is no need for extensive labeled training data, making the model more practical to train.
-- **Resolution**: PtychoPINN outperforms existing deep learning models for ptychographic reconstruction in terms of image quality, with a 10 dB PSNR increase and a 3- to 6-fold gain in linear resolution. Generalizability and robustness are also improved.
-- **Scalability and Speed**: PtychoPINN is two or three orders of magnitude as fast as iterative scanning CDI reconstruction.
-
-![Architecture diagram](diagram/lett.png)
-<!---
-*Fig. 1: Caption for the figure.*
- -->
-
-
-## Installation
-`conda create -n ptycho python=3.10`
-
-`conda activate ptycho`
-
-`pip install .`
-
-## Usage
-### Training
-`python scripts/training/train.py --train_data_file <train_path.npz> --test_data_file <test_path.npz>`
-
-
-### Inference 
-`python scripts/inference/inference.py --model_path <model artifact directory path> --test_data <test_path.npz>`
-
-See examples and READMEs under scripts/.
-
-For an example of interactive (Jupyter) usage, see notebooks/nongrid_simulations.ipynb. If you don't have inputs in the right .npz format you can simulate data.
-
-non_grid_CDI_example.ipynb shows interactive usage using a dataset that is provided with the repo.
-
-### Model Evaluation & Generalization Studies
-
-Run comprehensive generalization studies with statistical robustness:
-```bash
-# Multi-trial study with uncertainty quantification
-./scripts/studies/run_complete_generalization_study.sh \
-    --train-sizes "512 1024 2048" \
-    --num-trials 3 \
-    --output-dir robust_study
-```
-
-See `scripts/studies/QUICK_REFERENCE.md` for detailed usage and options.
-
-
-<!-- 
-* subpixel convolution (Depth-to-space)
-* make the model robust to arbitrary scaling/incorrect normalization of the diffracted intensity
-* other ideas: fft based loss, gradient loss, vq-vae https://www.tensorflow.org/tutorials/generative/style_transfer#define_content_and_style_representations
-* probe-based vs reconstruction-based support?
-
-* Fully Convolutional Networks for Semantic Segmentation, explore and discuss. Make a slide explaining the idea.
-* Try MC Dropout https://arxiv.org/pdf/1511.02680.pdf
-* read deep ensembles https://arxiv.org/pdf/1612.01474.pdf
-
-* hard constraint on diffraction norm using projection, consider tf.keras.constraints.MinMaxNorm
-* stochastic probe
-* probe symmetry consequences
-* add an object normalization layer that uses the L2 norm
-* how do super resolution models handle high resolutions?
-* shift invariance
-* grid permutation
-* fourier ring correlation
-
-* characterize robustness impact of Poisson likelihood vs. MAE
- -->
-
diff --git a/ptychopinn.egg-info/SOURCES.txt b/ptychopinn.egg-info/SOURCES.txt
deleted file mode 100644
index 3493cad..0000000
--- a/ptychopinn.egg-info/SOURCES.txt
+++ /dev/null
@@ -1,3495 +0,0 @@
-.gitignore
-.gitmodules
-LICENSE
-README.md
-pyproject.toml
-setup.py
-.claude/settings.local.json
-PlotNeuralNet/pycore/__init__.py
-PlotNeuralNet/pycore/blocks.py
-PlotNeuralNet/pycore/tikzeng.py
-PlotNeuralNet/pyexamples/test_simple.py
-PlotNeuralNet/pyexamples/unet.py
-PtychoNN/keras_helper.py
-PtychoNN/Continual Learning/Inference/helper_small_model.py
-PtychoNN/Continual Learning/Inference/infer_workflow.py
-PtychoNN/Continual Learning/Training/agx_update.py
-PtychoNN/Continual Learning/Training/custom_logger.py
-PtychoNN/Continual Learning/Training/dataPrepPtychoNN_tiff.py
-PtychoNN/Continual Learning/Training/helper_small_model.py
-PtychoNN/Continual Learning/Training/slack_update.py
-PtychoNN/Continual Learning/Training/small_1_ptychonn_model.py
-PtychoNN/PyTorch/CNN_encoder_decoder/train_noplotting.py
-PtychoNN/PyTorch/Inception_encoder_decoder/inception.py
-PtychoNN/TF2/keras_helper.py
-archive/tf_ptycho_autoencoder-overlap-2.ipynb
-archive/tf_ptycho_autoencoder-overlap.ipynb
-archive/tf_ptycho_autoencoder.ipynb
-archive/tfp_vae_mnist.ipynb
-configs/comparison_config.yaml
-datasets/Run1084_recon3_postPC_shrunk_3.npz
-datasets/tike2.py
-diagram/.log
-diagram/lett.png
-diagram/pinn.py
-diagram/pinn_letters.pdf
-diagram/pinn_squidward.pdf
-diagram/tikzeng.py
-docs/mermaid.txt
-docs/tooltips.txt
-loaders/__init__.py
-loaders/als.py
-loaders/xpp.py
-notebooks/als_reconstruction.ipynb
-notebooks/dose.py
-notebooks/dose_dependence.ipynb
-notebooks/inference_workflow.ipynb
-notebooks/mlexchange_demo.ipynb
-notebooks/non_grid_CDI_example-extended.ipynb
-notebooks/non_grid_CDI_example.ipynb
-notebooks/nongrid_simulations.ipynb
-notebooks/ptycho_lines.ipynb
-notebooks/test_generic_loader.py
-notebooks/train_and_infer.py
-notebooks/williamson.jpeg
-notebooks/xppl1026722.ipynb
-notebooks/archive/PtychoNN_overlaps.ipynb
-notebooks/archive/ablation.sh
-notebooks/archive/ablation_nophi.sh
-notebooks/archive/ablation_table.ipynb
-notebooks/archive/ablationtop.sh
-notebooks/archive/amp.jpeg
-notebooks/archive/cameraman.bmp
-notebooks/archive/full_obj.jpeg
-notebooks/archive/generalization_test.ipynb
-notebooks/archive/in1.jpeg
-notebooks/archive/in2.jpeg
-notebooks/archive/in3.jpeg
-notebooks/archive/in4.jpeg
-notebooks/archive/letters.png
-notebooks/archive/out1.jpeg
-notebooks/archive/out2.jpeg
-notebooks/archive/out3.jpeg
-notebooks/archive/out4.jpeg
-notebooks/archive/overlaps.ipynb
-notebooks/archive/paper_figures.ipynb
-notebooks/archive/patch1.jpeg
-notebooks/archive/patch2.jpeg
-notebooks/archive/patch3.jpeg
-notebooks/archive/patch4.jpeg
-notebooks/archive/phase.jpeg
-notebooks/archive/pinn_resolution_accuracy.ipynb
-notebooks/archive/position_correction.ipynb
-notebooks/archive/position_correction_2.ipynb
-notebooks/archive/ptycho_experimental.ipynb
-notebooks/archive/ptycho_grf.ipynb
-notebooks/archive/ptycho_lines.ipynb
-notebooks/archive/ptycho_nphotons.ipynb
-notebooks/archive/ptycho_simulated.ipynb
-notebooks/archive/squidward2.jpeg
-notebooks/archive/xpp_ptycho.ipynb
-notebooks/archive/ePIE_recon_simulation/ePIE_engine.py
-notebooks/archive/ePIE_recon_simulation/run_ePIE_sim.py
-ptycho/__init__.py
-ptycho/baselines.py
-ptycho/classes.py
-ptycho/cli_args.py
-ptycho/custom_layers.py
-ptycho/data_preprocessing.py
-ptycho/diffsim.py
-ptycho/evaluation.py
-ptycho/experimental.py
-ptycho/export.py
-ptycho/fourier.py
-ptycho/function_logger.py
-ptycho/gaussian_filter.py
-ptycho/generate_data.py
-ptycho/inference.py
-ptycho/loader.py
-ptycho/log_config.py
-ptycho/logging.py
-ptycho/losses.py
-ptycho/misc
-ptycho/misc.py
-ptycho/model.py
-ptycho/model_manager.py
-ptycho/nbutils.py
-ptycho/nongrid_simulation.py
-ptycho/params.py
-ptycho/physics.py
-ptycho/plotting.py
-ptycho/probe.py
-ptycho/projective_warp_xla.py
-ptycho/raw_data.py
-ptycho/tf_helper.py
-ptycho/train.py
-ptycho/train_pinn.py
-ptycho/train_supervised.py
-ptycho/visualization.py
-ptycho/xpp.py
-ptycho/FRC/__init__.py
-ptycho/FRC/fourier_ring_corr.py
-ptycho/FRC/spin_average.py
-ptycho/autotest/__init__.py
-ptycho/autotest/configuration.py
-ptycho/autotest/debug.py
-ptycho/autotest/functionmapping.py
-ptycho/autotest/logger.py
-ptycho/autotest/serializer.py
-ptycho/autotest/testing.py
-ptycho/config/__init__.py
-ptycho/config/config.py
-ptycho/datagen/__init__.py
-ptycho/datagen/diagonals.py
-ptycho/datagen/grf.py
-ptycho/datagen/points.py
-ptycho/datagen/testimg.py
-ptycho/datagen/vendetta.py
-ptycho/datasets/Run1084_recon3_postPC.npz
-ptycho/datasets/Run1084_recon3_postPC_shrunk_3.npz
-ptycho/image/__init__.py
-ptycho/image/cropping.py
-ptycho/image/registration.py
-ptycho/image/stitching.py
-ptycho/trash/model2.py
-ptycho/workflows/__init__.py
-ptycho/workflows/components.py
-ptycho/workflows/visualize_results.py
-ptycho_torch/__init__.py
-ptycho_torch/config_params.py
-ptycho_torch/datagen.py
-ptycho_torch/dset_loader_pt_mmap.py
-ptycho_torch/helper.py
-ptycho_torch/model.py
-ptycho_torch/patch_generator.py
-ptycho_torch/train.py
-ptycho_torch/train_dummy.py
-ptychopinn.egg-info/PKG-INFO
-ptychopinn.egg-info/SOURCES.txt
-ptychopinn.egg-info/dependency_links.txt
-ptychopinn.egg-info/entry_points.txt
-ptychopinn.egg-info/not-zip-safe
-ptychopinn.egg-info/requires.txt
-ptychopinn.egg-info/top_level.txt
-scripts/compare_models.py
-scripts/inspect_ptycho_data.py
-scripts/prepare.sh
-scripts/run_baseline.py
-scripts/run_comparison.sh
-scripts/stitch_patches.py
-scripts/tikerecon.py
-scripts/tikerecon_with_update.py
-scripts/inference/README.md
-scripts/inference/baseline_inference.py
-scripts/inference/inference.py
-scripts/reconstruction/README.md
-scripts/reconstruction/run_tike_reconstruction.py
-scripts/simulation/README.md
-scripts/simulation/run_with_synthetic_lines.py
-scripts/simulation/simulate_and_save.py
-scripts/simulation/simulation.py
-scripts/studies/README.md
-scripts/studies/aggregate_and_plot_results.py
-scripts/studies/run_complete_generalization_study.sh
-scripts/studies/run_generalization_study.sh
-scripts/studies/test_aggregate_nan_msssim.py
-scripts/studies/test_filtering_order.py
-scripts/studies/test_mean_vs_median.py
-scripts/tools/README.md
-scripts/tools/downsample_data_tool.py
-scripts/tools/generate_patches_tool.py
-scripts/tools/pad_to_even_tool.py
-scripts/tools/prepare_data_tool.py
-scripts/tools/shuffle_dataset_tool.py
-scripts/tools/split_dataset_tool.py
-scripts/tools/test_update_tool.py
-scripts/tools/transpose_rename_convert_tool.py
-scripts/tools/update_tool.py
-scripts/tools/visualize_dataset.py
-scripts/training/README.md
-scripts/training/train.py
-scripts/training/train_debug.log
-tensorflow/configure.py
-tensorflow/ci/official/utilities/convert_msys_paths_to_win_paths.py
-tensorflow/ci/official/utilities/extract_resultstore_links.py
-tensorflow/tensorflow/__init__.py
-tensorflow/tensorflow/api_template.__init__.py
-tensorflow/tensorflow/api_template_v1.__init__.py
-tensorflow/tensorflow/compat_template.__init__.py
-tensorflow/tensorflow/compat_template_v1.__init__.py
-tensorflow/tensorflow/virtual_root_template_v1.__init__.py
-tensorflow/tensorflow/virtual_root_template_v2.__init__.py
-tensorflow/tensorflow/c/experimental/saved_model/internal/testdata/gen_saved_models.py
-tensorflow/tensorflow/cc/saved_model/testdata/generate_chunked_models.py
-tensorflow/tensorflow/cc/saved_model/testdata/generate_saved_models.py
-tensorflow/tensorflow/compiler/aot/tests/make_test_graphs.py
-tensorflow/tensorflow/compiler/jit/ops/xla_ops_grad.py
-tensorflow/tensorflow/compiler/mlir/runlit.cfg.py
-tensorflow/tensorflow/compiler/mlir/runlit.site.cfg.py
-tensorflow/tensorflow/compiler/mlir/lite/experimental/tac/tac.py
-tensorflow/tensorflow/compiler/mlir/lite/experimental/tac/py_wrapper/_pywrap_tac_wrapper.pyi
-tensorflow/tensorflow/compiler/mlir/lite/python/_pywrap_converter_api.pyi
-tensorflow/tensorflow/compiler/mlir/lite/python/wrap_converter.py
-tensorflow/tensorflow/compiler/mlir/lite/tests/debuginfo/concrete_function_error.py
-tensorflow/tensorflow/compiler/mlir/lite/tests/debuginfo/saved_model_error.py
-tensorflow/tensorflow/compiler/mlir/python/mlir_wrapper/filecheck_wrapper.pyi
-tensorflow/tensorflow/compiler/mlir/python/mlir_wrapper/mlir_wrapper.pyi
-tensorflow/tensorflow/compiler/mlir/quantization/common/python/testing.py
-tensorflow/tensorflow/compiler/mlir/quantization/common/python/testing_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/stablehlo/python/pywrap_quantization.pyi
-tensorflow/tensorflow/compiler/mlir/quantization/stablehlo/python/quantization.py
-tensorflow/tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/stablehlo/python/integration_test/quantize_model_test_base.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/gen_quantized_function_library.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_algorithm.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_algorithm_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/pywrap_calibration.pyi
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/calibrator/integration_test/custom_aggregator_op_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/py_function_lib.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/py_function_lib_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_function_lib.pyi
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model.pyi
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/pywrap_quantize_model_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/quantize_model.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/representative_dataset.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/representative_dataset_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/save_model.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/concurrency_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test.py
-tensorflow/tensorflow/compiler/mlir/quantization/tensorflow/python/integration_test/quantize_model_test_base.py
-tensorflow/tensorflow/compiler/mlir/stablehlo/stablehlo.py
-tensorflow/tensorflow/compiler/mlir/stablehlo/stablehlo_test.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/basic.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/basic_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/basic_v1_no_variable_lifting.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/call_to_exported.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/common.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/common_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/control_flow_duplicate_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/control_flow_upgrade_legacy_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/cyclic_object_graph.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/dag_object_graph.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/debug_info.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/defun_export.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/duplicate_method_names_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/exported_python_args.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/hash_table_asset_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/hash_table_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/import_restore_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/include_variables_in_init_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/keras.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/multi_arguments_results_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/multi_variables_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/no_input_shape_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/partially_shaped_variables.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/remove_init_variable_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/shapes_for_arguments.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/shared_variable_v1.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/structured_input.py
-tensorflow/tensorflow/compiler/mlir/tensorflow/tests/tf_saved_model/structured_output.py
-tensorflow/tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/pywrap_tensorflow_to_stablehlo.pyi
-tensorflow/tensorflow/compiler/mlir/tensorflow_to_stablehlo/python/integration_test/tensorflow_to_stablehlo_test.py
-tensorflow/tensorflow/compiler/mlir/tfr/define_op_template.py
-tensorflow/tensorflow/compiler/mlir/tfr/tfr_wrapper.pyi
-tensorflow/tensorflow/compiler/mlir/tfr/python/composite.py
-tensorflow/tensorflow/compiler/mlir/tfr/python/op_reg_gen.py
-tensorflow/tensorflow/compiler/mlir/tfr/python/op_reg_gen_test.py
-tensorflow/tensorflow/compiler/mlir/tfr/python/test_utils.py
-tensorflow/tensorflow/compiler/mlir/tfr/python/tfr_gen.py
-tensorflow/tensorflow/compiler/mlir/tfr/python/tfr_gen_test.py
-tensorflow/tensorflow/compiler/tests/__init__.py
-tensorflow/tensorflow/compiler/tests/adadelta_test.py
-tensorflow/tensorflow/compiler/tests/adagrad_da_test.py
-tensorflow/tensorflow/compiler/tests/adagrad_test.py
-tensorflow/tensorflow/compiler/tests/adam_test.py
-tensorflow/tensorflow/compiler/tests/add_n_test.py
-tensorflow/tensorflow/compiler/tests/approx_topk_test.py
-tensorflow/tensorflow/compiler/tests/argminmax_test.py
-tensorflow/tensorflow/compiler/tests/async_comp_test.py
-tensorflow/tensorflow/compiler/tests/binary_ops_test.py
-tensorflow/tensorflow/compiler/tests/bincount_op_test.py
-tensorflow/tensorflow/compiler/tests/bucketize_op_test.py
-tensorflow/tensorflow/compiler/tests/case_test.py
-tensorflow/tensorflow/compiler/tests/cast_ops_test.py
-tensorflow/tensorflow/compiler/tests/categorical_op_test.py
-tensorflow/tensorflow/compiler/tests/cholesky_op_test.py
-tensorflow/tensorflow/compiler/tests/clustering_test.py
-tensorflow/tensorflow/compiler/tests/complex_div_test.py
-tensorflow/tensorflow/compiler/tests/concat_ops_test.py
-tensorflow/tensorflow/compiler/tests/cond_test.py
-tensorflow/tensorflow/compiler/tests/const_arg_test.py
-tensorflow/tensorflow/compiler/tests/const_test.py
-tensorflow/tensorflow/compiler/tests/conv2d_test.py
-tensorflow/tensorflow/compiler/tests/conv3d_test.py
-tensorflow/tensorflow/compiler/tests/conv_node_name_test.py
-tensorflow/tensorflow/compiler/tests/data_format_ops_test.py
-tensorflow/tensorflow/compiler/tests/dense_layer_test.py
-tensorflow/tensorflow/compiler/tests/depthwise_conv_op_test.py
-tensorflow/tensorflow/compiler/tests/dynamic_slice_ops_test.py
-tensorflow/tensorflow/compiler/tests/dynamic_stitch_test.py
-tensorflow/tensorflow/compiler/tests/eager_test.py
-tensorflow/tensorflow/compiler/tests/einsum_op_test.py
-tensorflow/tensorflow/compiler/tests/ensure_shape_op_test.py
-tensorflow/tensorflow/compiler/tests/extract_image_patches_op_test.py
-tensorflow/tensorflow/compiler/tests/fake_quant_ops_test.py
-tensorflow/tensorflow/compiler/tests/fft_test.py
-tensorflow/tensorflow/compiler/tests/fifo_queue_test.py
-tensorflow/tensorflow/compiler/tests/ftrl_ops_test.py
-tensorflow/tensorflow/compiler/tests/ftrl_test.py
-tensorflow/tensorflow/compiler/tests/function_test.py
-tensorflow/tensorflow/compiler/tests/fused_batchnorm_test.py
-tensorflow/tensorflow/compiler/tests/gather_nd_op_test.py
-tensorflow/tensorflow/compiler/tests/gather_test.py
-tensorflow/tensorflow/compiler/tests/giant_const_op_test.py
-tensorflow/tensorflow/compiler/tests/image_ops_jit_compile_test.py
-tensorflow/tensorflow/compiler/tests/image_ops_test.py
-tensorflow/tensorflow/compiler/tests/jit_test.py
-tensorflow/tensorflow/compiler/tests/listdiff_op_test.py
-tensorflow/tensorflow/compiler/tests/lrn_ops_test.py
-tensorflow/tensorflow/compiler/tests/lstm.py
-tensorflow/tensorflow/compiler/tests/lstm_test.py
-tensorflow/tensorflow/compiler/tests/manip_ops_test.py
-tensorflow/tensorflow/compiler/tests/matrix_band_part_test.py
-tensorflow/tensorflow/compiler/tests/matrix_diag_ops_test.py
-tensorflow/tensorflow/compiler/tests/matrix_inverse_op_test.py
-tensorflow/tensorflow/compiler/tests/matrix_solve_op_test.py
-tensorflow/tensorflow/compiler/tests/matrix_triangular_solve_op_test.py
-tensorflow/tensorflow/compiler/tests/mean_op_test.py
-tensorflow/tensorflow/compiler/tests/momentum_test.py
-tensorflow/tensorflow/compiler/tests/nary_ops_test.py
-tensorflow/tensorflow/compiler/tests/nullary_ops_test.py
-tensorflow/tensorflow/compiler/tests/placeholder_test.py
-tensorflow/tensorflow/compiler/tests/pooling_ops_3d_test.py
-tensorflow/tensorflow/compiler/tests/pooling_ops_test.py
-tensorflow/tensorflow/compiler/tests/proximal_adagrad_test.py
-tensorflow/tensorflow/compiler/tests/proximal_gradient_descent_test.py
-tensorflow/tensorflow/compiler/tests/qr_op_test.py
-tensorflow/tensorflow/compiler/tests/quantized_ops_test.py
-tensorflow/tensorflow/compiler/tests/random_ops_test.py
-tensorflow/tensorflow/compiler/tests/reduce_ops_test.py
-tensorflow/tensorflow/compiler/tests/reduce_window_test.py
-tensorflow/tensorflow/compiler/tests/repeat_op_test.py
-tensorflow/tensorflow/compiler/tests/reshape_op_test.py
-tensorflow/tensorflow/compiler/tests/reverse_ops_test.py
-tensorflow/tensorflow/compiler/tests/reverse_sequence_op_args_test.py
-tensorflow/tensorflow/compiler/tests/reverse_sequence_op_test.py
-tensorflow/tensorflow/compiler/tests/rmsprop_test.py
-tensorflow/tensorflow/compiler/tests/runtime_shape_check_test.py
-tensorflow/tensorflow/compiler/tests/scan_ops_test.py
-tensorflow/tensorflow/compiler/tests/scatter_nd_op_test.py
-tensorflow/tensorflow/compiler/tests/searchsorted_op_test.py
-tensorflow/tensorflow/compiler/tests/segment_reduction_ops_test.py
-tensorflow/tensorflow/compiler/tests/self_adjoint_eig_op_test.py
-tensorflow/tensorflow/compiler/tests/sharding_util_ops_test.py
-tensorflow/tensorflow/compiler/tests/slice_ops_test.py
-tensorflow/tensorflow/compiler/tests/sort_ops_test.py
-tensorflow/tensorflow/compiler/tests/spacetobatch_op_test.py
-tensorflow/tensorflow/compiler/tests/sparse_to_dense_op_test.py
-tensorflow/tensorflow/compiler/tests/special_math_test.py
-tensorflow/tensorflow/compiler/tests/stack_ops_test.py
-tensorflow/tensorflow/compiler/tests/stateful_random_ops_test.py
-tensorflow/tensorflow/compiler/tests/stateless_random_ops_test.py
-tensorflow/tensorflow/compiler/tests/stochastic_cast_op_test.py
-tensorflow/tensorflow/compiler/tests/svd_op_test.py
-tensorflow/tensorflow/compiler/tests/tensor_array_ops_test.py
-tensorflow/tensorflow/compiler/tests/tensor_float_32_test.py
-tensorflow/tensorflow/compiler/tests/tensor_list_ops_test.py
-tensorflow/tensorflow/compiler/tests/ternary_ops_test.py
-tensorflow/tensorflow/compiler/tests/test_utils.py
-tensorflow/tensorflow/compiler/tests/tridiagonal_matmul_ops_test.py
-tensorflow/tensorflow/compiler/tests/tridiagonal_solve_ops_test.py
-tensorflow/tensorflow/compiler/tests/unary_ops_test.py
-tensorflow/tensorflow/compiler/tests/unique_ops_test.py
-tensorflow/tensorflow/compiler/tests/unstack_test.py
-tensorflow/tensorflow/compiler/tests/variable_ops_test.py
-tensorflow/tensorflow/compiler/tests/where_op_test.py
-tensorflow/tensorflow/compiler/tests/while_test.py
-tensorflow/tensorflow/compiler/tests/xla_call_module_test.py
-tensorflow/tensorflow/compiler/tests/xla_custom_call_ops_test.py
-tensorflow/tensorflow/compiler/tests/xla_device_gpu_test.py
-tensorflow/tensorflow/compiler/tests/xla_device_test.py
-tensorflow/tensorflow/compiler/tests/xla_dump_to_sponge_test.py
-tensorflow/tensorflow/compiler/tests/xla_dump_to_test.py
-tensorflow/tensorflow/compiler/tests/xla_ops_test.py
-tensorflow/tensorflow/compiler/tests/xla_test.py
-tensorflow/tensorflow/compiler/tests/xla_test_test.py
-tensorflow/tensorflow/compiler/tf2tensorrt/_pywrap_py_utils.pyi
-tensorflow/tensorflow/compiler/tf2xla/light_outside_compilation_test.py
-tensorflow/tensorflow/compiler/tf2xla/python/xla.py
-tensorflow/tensorflow/core/config/__init__.py
-tensorflow/tensorflow/core/config/flags.py
-tensorflow/tensorflow/core/config/flags_test.py
-tensorflow/tensorflow/core/function/capture/by_ref_capture_test.py
-tensorflow/tensorflow/core/function/capture/capture_container.py
-tensorflow/tensorflow/core/function/capture/capture_container_test.py
-tensorflow/tensorflow/core/function/capture/free_vars_detect.py
-tensorflow/tensorflow/core/function/capture/free_vars_detect_test.py
-tensorflow/tensorflow/core/function/capture/restore_captures.py
-tensorflow/tensorflow/core/function/integration_test/side_inputs_manual_api_test.py
-tensorflow/tensorflow/core/function/integration_test/side_inputs_test.py
-tensorflow/tensorflow/core/function/polymorphism/function_cache.py
-tensorflow/tensorflow/core/function/polymorphism/function_cache_test.py
-tensorflow/tensorflow/core/function/polymorphism/function_type.py
-tensorflow/tensorflow/core/function/polymorphism/function_type_test.py
-tensorflow/tensorflow/core/function/polymorphism/type_dispatch.py
-tensorflow/tensorflow/core/function/polymorphism/type_dispatch_test.py
-tensorflow/tensorflow/core/function/runtime_client/runtime_client.py
-tensorflow/tensorflow/core/function/runtime_client/runtime_client_pybind.pyi
-tensorflow/tensorflow/core/function/runtime_client/runtime_client_test.py
-tensorflow/tensorflow/core/function/testing/test_pass.py
-tensorflow/tensorflow/core/function/testing/test_pass_pybind.pyi
-tensorflow/tensorflow/core/function/trace_type/__init__.py
-tensorflow/tensorflow/core/function/trace_type/custom_nest_trace_type.py
-tensorflow/tensorflow/core/function/trace_type/custom_nest_trace_type_test.py
-tensorflow/tensorflow/core/function/trace_type/default_types.py
-tensorflow/tensorflow/core/function/trace_type/default_types_test.py
-tensorflow/tensorflow/core/function/trace_type/serialization.py
-tensorflow/tensorflow/core/function/trace_type/serialization_test.py
-tensorflow/tensorflow/core/function/trace_type/trace_type_builder.py
-tensorflow/tensorflow/core/function/trace_type/trace_type_test.py
-tensorflow/tensorflow/core/function/trace_type/util.py
-tensorflow/tensorflow/core/function/transform/transform.py
-tensorflow/tensorflow/core/function/transform/transform_test.py
-tensorflow/tensorflow/core/platform/ram_file_system_test.py
-tensorflow/tensorflow/core/runtime_fallback/test/saved_model/gen_saved_model_v1.py
-tensorflow/tensorflow/core/tfrt/graph_executor/python/_pywrap_graph_execution_options.pyi
-tensorflow/tensorflow/core/tfrt/mlrt/kernel/testdata/gen_checkpoint.py
-tensorflow/tensorflow/core/tfrt/saved_model/python/_pywrap_saved_model.pyi
-tensorflow/tensorflow/core/tfrt/saved_model/python/saved_model_load_and_run_test.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_control_flow_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_data.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_dtype_coverage_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_error_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_hash_table_asset_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_if_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_matmul_gpu.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_pow.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_pow_v2.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_ref_type_tensor_input.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_resource_gather_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_saved_model_v1.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_saved_model_v2.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_sparse_tensor_input.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_variable_on_tpu.py
-tensorflow/tensorflow/core/tfrt/saved_model/tests/gen_while_v1.py
-tensorflow/tensorflow/core/tfrt/tfrt_session/tfrt_session_python_test.py
-tensorflow/tensorflow/dtensor/python/__init__.py
-tensorflow/tensorflow/dtensor/python/accelerator_util.py
-tensorflow/tensorflow/dtensor/python/api.py
-tensorflow/tensorflow/dtensor/python/config.py
-tensorflow/tensorflow/dtensor/python/d_checkpoint.py
-tensorflow/tensorflow/dtensor/python/d_random.py
-tensorflow/tensorflow/dtensor/python/d_variable.py
-tensorflow/tensorflow/dtensor/python/dtensor_device.py
-tensorflow/tensorflow/dtensor/python/heartbeat.py
-tensorflow/tensorflow/dtensor/python/input_util.py
-tensorflow/tensorflow/dtensor/python/layout.py
-tensorflow/tensorflow/dtensor/python/mesh_util.py
-tensorflow/tensorflow/dtensor/python/numpy_util.py
-tensorflow/tensorflow/dtensor/python/save_restore.py
-tensorflow/tensorflow/dtensor/python/tpu_util.py
-tensorflow/tensorflow/dtensor/python/tests/api_test.py
-tensorflow/tensorflow/dtensor/python/tests/array_ops_test.py
-tensorflow/tensorflow/dtensor/python/tests/batchparallel_spmd_test.py
-tensorflow/tensorflow/dtensor/python/tests/cache_test.py
-tensorflow/tensorflow/dtensor/python/tests/collective_test.py
-tensorflow/tensorflow/dtensor/python/tests/config_test.py
-tensorflow/tensorflow/dtensor/python/tests/conv_test.py
-tensorflow/tensorflow/dtensor/python/tests/device_test.py
-tensorflow/tensorflow/dtensor/python/tests/input_util_test.py
-tensorflow/tensorflow/dtensor/python/tests/layout_propagation_test.py
-tensorflow/tensorflow/dtensor/python/tests/layout_test.py
-tensorflow/tensorflow/dtensor/python/tests/mesh_util_test.py
-tensorflow/tensorflow/dtensor/python/tests/mnist_test.py
-tensorflow/tensorflow/dtensor/python/tests/multi_client_input_util_test.py
-tensorflow/tensorflow/dtensor/python/tests/multi_client_test.py
-tensorflow/tensorflow/dtensor/python/tests/multi_client_test_util.py
-tensorflow/tensorflow/dtensor/python/tests/multi_mesh_test.py
-tensorflow/tensorflow/dtensor/python/tests/numerics_test.py
-tensorflow/tensorflow/dtensor/python/tests/numpy_util_test.py
-tensorflow/tensorflow/dtensor/python/tests/rng_test.py
-tensorflow/tensorflow/dtensor/python/tests/save_restore_v2_test.py
-tensorflow/tensorflow/dtensor/python/tests/sparse_test.py
-tensorflow/tensorflow/dtensor/python/tests/spmd_test.py
-tensorflow/tensorflow/dtensor/python/tests/test_backend_name.py
-tensorflow/tensorflow/dtensor/python/tests/test_backend_util.py
-tensorflow/tensorflow/dtensor/python/tests/test_util.py
-tensorflow/tensorflow/dtensor/python/tests/test_util_ops.py
-tensorflow/tensorflow/dtensor/python/tests/tpu_device_assignment_test.py
-tensorflow/tensorflow/dtensor/python/tests/variable_test.py
-tensorflow/tensorflow/examples/__init__.py
-tensorflow/tensorflow/examples/adding_an_op/__init__.py
-tensorflow/tensorflow/examples/adding_an_op/cuda_op.py
-tensorflow/tensorflow/examples/adding_an_op/cuda_op_test.py
-tensorflow/tensorflow/examples/adding_an_op/fact_test.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_1_test.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_2_test.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_3_test.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_grad_2.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_op_1.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_op_2.py
-tensorflow/tensorflow/examples/adding_an_op/zero_out_op_3.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_1/multiplex_1_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_1/multiplex_1_test.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_2/multiplex_2_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_2/multiplex_2_test.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_3/multiplex_3_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_3/multiplex_3_test.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_4/model_using_multiplex.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_4/multiplex_2_save.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_4/multiplex_4_load_use.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_4/multiplex_4_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/multiplex_4/multiplex_4_test.py
-tensorflow/tensorflow/examples/custom_ops_doc/simple_hash_table/simple_hash_table.py
-tensorflow/tensorflow/examples/custom_ops_doc/simple_hash_table/simple_hash_table_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/simple_hash_table/simple_hash_table_test.py
-tensorflow/tensorflow/examples/custom_ops_doc/sleep/sleep_bin.py
-tensorflow/tensorflow/examples/custom_ops_doc/sleep/sleep_op.py
-tensorflow/tensorflow/examples/custom_ops_doc/sleep/sleep_test.py
-tensorflow/tensorflow/examples/label_image/label_image.py
-tensorflow/tensorflow/examples/speech_commands/accuracy_utils.py
-tensorflow/tensorflow/examples/speech_commands/freeze.py
-tensorflow/tensorflow/examples/speech_commands/freeze_test.py
-tensorflow/tensorflow/examples/speech_commands/generate_streaming_test_wav.py
-tensorflow/tensorflow/examples/speech_commands/generate_streaming_test_wav_test.py
-tensorflow/tensorflow/examples/speech_commands/input_data.py
-tensorflow/tensorflow/examples/speech_commands/input_data_test.py
-tensorflow/tensorflow/examples/speech_commands/label_wav.py
-tensorflow/tensorflow/examples/speech_commands/label_wav_dir.py
-tensorflow/tensorflow/examples/speech_commands/label_wav_test.py
-tensorflow/tensorflow/examples/speech_commands/models.py
-tensorflow/tensorflow/examples/speech_commands/models_test.py
-tensorflow/tensorflow/examples/speech_commands/recognize_commands.py
-tensorflow/tensorflow/examples/speech_commands/test_streaming_accuracy.py
-tensorflow/tensorflow/examples/speech_commands/train.py
-tensorflow/tensorflow/examples/speech_commands/train_test.py
-tensorflow/tensorflow/examples/speech_commands/wav_to_features.py
-tensorflow/tensorflow/examples/speech_commands/wav_to_features_test.py
-tensorflow/tensorflow/lite/examples/experimental_new_converter/stack_trace_example.py
-tensorflow/tensorflow/lite/examples/python/label_image.py
-tensorflow/tensorflow/lite/experimental/acceleration/compatibility/convert_binary_to_cc_source.py
-tensorflow/tensorflow/lite/experimental/acceleration/mini_benchmark/copy_associated_files.py
-tensorflow/tensorflow/lite/experimental/acceleration/mini_benchmark/metrics/blazeface_metrics.py
-tensorflow/tensorflow/lite/experimental/acceleration/mini_benchmark/metrics/kl_divergence.py
-tensorflow/tensorflow/lite/experimental/acceleration/mini_benchmark/metrics/mobilenet.py
-tensorflow/tensorflow/lite/experimental/genai/pywrap_genai_ops.pyi
-tensorflow/tensorflow/lite/experimental/microfrontend/python/kernel_tests/audio_microfrontend_op_test.py
-tensorflow/tensorflow/lite/experimental/microfrontend/python/ops/audio_microfrontend_op.py
-tensorflow/tensorflow/lite/g3doc/tools/build_java_api_docs.py
-tensorflow/tensorflow/lite/g3doc/tools/build_py_api_docs.py
-tensorflow/tensorflow/lite/ios/extract_object_files.py
-tensorflow/tensorflow/lite/ios/extract_object_files_main.py
-tensorflow/tensorflow/lite/ios/extract_object_files_test.py
-tensorflow/tensorflow/lite/kernels/pywrap_variable_ops.pyi
-tensorflow/tensorflow/lite/kernels/gradient/pywrap_gradient_ops.pyi
-tensorflow/tensorflow/lite/kernels/perception/pywrap_perception_ops.pyi
-tensorflow/tensorflow/lite/kernels/variants/py/end_to_end_test.py
-tensorflow/tensorflow/lite/kernels/variants/py/register_list_ops_py.pyi
-tensorflow/tensorflow/lite/python/analyzer.py
-tensorflow/tensorflow/lite/python/analyzer_test.py
-tensorflow/tensorflow/lite/python/convert.py
-tensorflow/tensorflow/lite/python/convert_file_to_c_source.py
-tensorflow/tensorflow/lite/python/convert_phase.py
-tensorflow/tensorflow/lite/python/convert_saved_model.py
-tensorflow/tensorflow/lite/python/convert_saved_model_test.py
-tensorflow/tensorflow/lite/python/convert_test.py
-tensorflow/tensorflow/lite/python/interpreter.py
-tensorflow/tensorflow/lite/python/interpreter_test.py
-tensorflow/tensorflow/lite/python/lite.py
-tensorflow/tensorflow/lite/python/lite_constants.py
-tensorflow/tensorflow/lite/python/lite_flex_test.py
-tensorflow/tensorflow/lite/python/lite_test.py
-tensorflow/tensorflow/lite/python/lite_v2_test.py
-tensorflow/tensorflow/lite/python/lite_v2_test_util.py
-tensorflow/tensorflow/lite/python/op_hint.py
-tensorflow/tensorflow/lite/python/schema_util.py
-tensorflow/tensorflow/lite/python/test_util.py
-tensorflow/tensorflow/lite/python/test_util_test.py
-tensorflow/tensorflow/lite/python/tflite_convert.py
-tensorflow/tensorflow/lite/python/tflite_convert_test.py
-tensorflow/tensorflow/lite/python/tflite_keras_util.py
-tensorflow/tensorflow/lite/python/util.py
-tensorflow/tensorflow/lite/python/util_test.py
-tensorflow/tensorflow/lite/python/wrap_toco.py
-tensorflow/tensorflow/lite/python/analyzer_wrapper/_pywrap_analyzer_wrapper.pyi
-tensorflow/tensorflow/lite/python/authoring/authoring.py
-tensorflow/tensorflow/lite/python/authoring/authoring_test.py
-tensorflow/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.pyi
-tensorflow/tensorflow/lite/python/kernel_tests/signal/test_util.py
-tensorflow/tensorflow/lite/python/kernel_tests/signal/window_ops_test.py
-tensorflow/tensorflow/lite/python/metrics/_pywrap_tensorflow_lite_metrics_wrapper.pyi
-tensorflow/tensorflow/lite/python/metrics/metrics_interface.py
-tensorflow/tensorflow/lite/python/metrics/metrics_nonportable.py
-tensorflow/tensorflow/lite/python/metrics/metrics_nonportable_test.py
-tensorflow/tensorflow/lite/python/metrics/metrics_portable.py
-tensorflow/tensorflow/lite/python/metrics/metrics_portable_test.py
-tensorflow/tensorflow/lite/python/metrics/wrapper/metrics_wrapper.py
-tensorflow/tensorflow/lite/python/metrics/wrapper/metrics_wrapper_test.py
-tensorflow/tensorflow/lite/python/optimize/_pywrap_tensorflow_lite_calibration_wrapper.pyi
-tensorflow/tensorflow/lite/python/optimize/calibrator.py
-tensorflow/tensorflow/lite/python/optimize/calibrator_test.py
-tensorflow/tensorflow/lite/python/testdata/_pywrap_test_registerer.pyi
-tensorflow/tensorflow/lite/python/testdata/double_op.py
-tensorflow/tensorflow/lite/schema/upgrade_schema.py
-tensorflow/tensorflow/lite/schema/upgrade_schema_test.py
-tensorflow/tensorflow/lite/testdata/src/intermediate_tensor_output.py
-tensorflow/tensorflow/lite/testing/_pywrap_string_util.pyi
-tensorflow/tensorflow/lite/testing/generate_examples.py
-tensorflow/tensorflow/lite/testing/generate_examples_lib.py
-tensorflow/tensorflow/lite/testing/generate_examples_report.py
-tensorflow/tensorflow/lite/testing/mlir_convert.py
-tensorflow/tensorflow/lite/testing/zip_test_utils.py
-tensorflow/tensorflow/lite/testing/op_tests/abs.py
-tensorflow/tensorflow/lite/testing/op_tests/add_n.py
-tensorflow/tensorflow/lite/testing/op_tests/arg_min_max.py
-tensorflow/tensorflow/lite/testing/op_tests/atan2.py
-tensorflow/tensorflow/lite/testing/op_tests/batch_to_space_nd.py
-tensorflow/tensorflow/lite/testing/op_tests/batchmatmul.py
-tensorflow/tensorflow/lite/testing/op_tests/binary_op.py
-tensorflow/tensorflow/lite/testing/op_tests/bitcast.py
-tensorflow/tensorflow/lite/testing/op_tests/bitwise_xor.py
-tensorflow/tensorflow/lite/testing/op_tests/broadcast_args.py
-tensorflow/tensorflow/lite/testing/op_tests/broadcast_gradient_args.py
-tensorflow/tensorflow/lite/testing/op_tests/broadcast_to.py
-tensorflow/tensorflow/lite/testing/op_tests/cast.py
-tensorflow/tensorflow/lite/testing/op_tests/ceil.py
-tensorflow/tensorflow/lite/testing/op_tests/complex_abs.py
-tensorflow/tensorflow/lite/testing/op_tests/concat.py
-tensorflow/tensorflow/lite/testing/op_tests/cond.py
-tensorflow/tensorflow/lite/testing/op_tests/constant.py
-tensorflow/tensorflow/lite/testing/op_tests/control_dep.py
-tensorflow/tensorflow/lite/testing/op_tests/conv.py
-tensorflow/tensorflow/lite/testing/op_tests/conv2d_transpose.py
-tensorflow/tensorflow/lite/testing/op_tests/conv3d.py
-tensorflow/tensorflow/lite/testing/op_tests/conv3d_transpose.py
-tensorflow/tensorflow/lite/testing/op_tests/conv_activation.py
-tensorflow/tensorflow/lite/testing/op_tests/conv_bias_activation.py
-tensorflow/tensorflow/lite/testing/op_tests/conv_to_depthwiseconv_with_shared_weights.py
-tensorflow/tensorflow/lite/testing/op_tests/conv_with_shared_weights.py
-tensorflow/tensorflow/lite/testing/op_tests/cos.py
-tensorflow/tensorflow/lite/testing/op_tests/cumsum.py
-tensorflow/tensorflow/lite/testing/op_tests/depth_to_space.py
-tensorflow/tensorflow/lite/testing/op_tests/depthwiseconv.py
-tensorflow/tensorflow/lite/testing/op_tests/dynamic_rnn.py
-tensorflow/tensorflow/lite/testing/op_tests/dynamic_update_slice.py
-tensorflow/tensorflow/lite/testing/op_tests/einsum.py
-tensorflow/tensorflow/lite/testing/op_tests/elementwise.py
-tensorflow/tensorflow/lite/testing/op_tests/elu.py
-tensorflow/tensorflow/lite/testing/op_tests/embedding_lookup.py
-tensorflow/tensorflow/lite/testing/op_tests/equal.py
-tensorflow/tensorflow/lite/testing/op_tests/exp.py
-tensorflow/tensorflow/lite/testing/op_tests/expand_dims.py
-tensorflow/tensorflow/lite/testing/op_tests/expm1.py
-tensorflow/tensorflow/lite/testing/op_tests/eye.py
-tensorflow/tensorflow/lite/testing/op_tests/fill.py
-tensorflow/tensorflow/lite/testing/op_tests/floor.py
-tensorflow/tensorflow/lite/testing/op_tests/fully_connected.py
-tensorflow/tensorflow/lite/testing/op_tests/fully_connected_4bit_hybrid.py
-tensorflow/tensorflow/lite/testing/op_tests/fused_batch_norm.py
-tensorflow/tensorflow/lite/testing/op_tests/gather.py
-tensorflow/tensorflow/lite/testing/op_tests/gather_nd.py
-tensorflow/tensorflow/lite/testing/op_tests/gather_with_constant.py
-tensorflow/tensorflow/lite/testing/op_tests/gelu.py
-tensorflow/tensorflow/lite/testing/op_tests/global_batch_norm.py
-tensorflow/tensorflow/lite/testing/op_tests/greater.py
-tensorflow/tensorflow/lite/testing/op_tests/greater_equal.py
-tensorflow/tensorflow/lite/testing/op_tests/hardswish.py
-tensorflow/tensorflow/lite/testing/op_tests/identify_dilated_conv.py
-tensorflow/tensorflow/lite/testing/op_tests/identify_dilated_conv1d.py
-tensorflow/tensorflow/lite/testing/op_tests/identity.py
-tensorflow/tensorflow/lite/testing/op_tests/imag.py
-tensorflow/tensorflow/lite/testing/op_tests/irfft2d.py
-tensorflow/tensorflow/lite/testing/op_tests/is_finite.py
-tensorflow/tensorflow/lite/testing/op_tests/l2norm.py
-tensorflow/tensorflow/lite/testing/op_tests/l2norm_shared_epsilon.py
-tensorflow/tensorflow/lite/testing/op_tests/leaky_relu.py
-tensorflow/tensorflow/lite/testing/op_tests/less.py
-tensorflow/tensorflow/lite/testing/op_tests/less_equal.py
-tensorflow/tensorflow/lite/testing/op_tests/local_response_norm.py
-tensorflow/tensorflow/lite/testing/op_tests/log_softmax.py
-tensorflow/tensorflow/lite/testing/op_tests/logic.py
-tensorflow/tensorflow/lite/testing/op_tests/lstm.py
-tensorflow/tensorflow/lite/testing/op_tests/matrix_band_part.py
-tensorflow/tensorflow/lite/testing/op_tests/matrix_diag.py
-tensorflow/tensorflow/lite/testing/op_tests/matrix_set_diag.py
-tensorflow/tensorflow/lite/testing/op_tests/max_pool_with_argmax.py
-tensorflow/tensorflow/lite/testing/op_tests/maximum.py
-tensorflow/tensorflow/lite/testing/op_tests/minimum.py
-tensorflow/tensorflow/lite/testing/op_tests/mirror_pad.py
-tensorflow/tensorflow/lite/testing/op_tests/multinomial.py
-tensorflow/tensorflow/lite/testing/op_tests/nearest_upsample.py
-tensorflow/tensorflow/lite/testing/op_tests/neg.py
-tensorflow/tensorflow/lite/testing/op_tests/not_equal.py
-tensorflow/tensorflow/lite/testing/op_tests/one_hot.py
-tensorflow/tensorflow/lite/testing/op_tests/pack.py
-tensorflow/tensorflow/lite/testing/op_tests/pad.py
-tensorflow/tensorflow/lite/testing/op_tests/padv2.py
-tensorflow/tensorflow/lite/testing/op_tests/parse_example.py
-tensorflow/tensorflow/lite/testing/op_tests/placeholder_with_default.py
-tensorflow/tensorflow/lite/testing/op_tests/pool.py
-tensorflow/tensorflow/lite/testing/op_tests/pool3d.py
-tensorflow/tensorflow/lite/testing/op_tests/prelu.py
-tensorflow/tensorflow/lite/testing/op_tests/random_standard_normal.py
-tensorflow/tensorflow/lite/testing/op_tests/random_uniform.py
-tensorflow/tensorflow/lite/testing/op_tests/range.py
-tensorflow/tensorflow/lite/testing/op_tests/rank.py
-tensorflow/tensorflow/lite/testing/op_tests/real.py
-tensorflow/tensorflow/lite/testing/op_tests/reciprocal.py
-tensorflow/tensorflow/lite/testing/op_tests/reduce.py
-tensorflow/tensorflow/lite/testing/op_tests/relu.py
-tensorflow/tensorflow/lite/testing/op_tests/relu1.py
-tensorflow/tensorflow/lite/testing/op_tests/relu6.py
-tensorflow/tensorflow/lite/testing/op_tests/reshape.py
-tensorflow/tensorflow/lite/testing/op_tests/resize_bilinear.py
-tensorflow/tensorflow/lite/testing/op_tests/resize_nearest_neighbor.py
-tensorflow/tensorflow/lite/testing/op_tests/resolve_constant_strided_slice.py
-tensorflow/tensorflow/lite/testing/op_tests/reverse_sequence.py
-tensorflow/tensorflow/lite/testing/op_tests/reverse_v2.py
-tensorflow/tensorflow/lite/testing/op_tests/rfft.py
-tensorflow/tensorflow/lite/testing/op_tests/rfft2d.py
-tensorflow/tensorflow/lite/testing/op_tests/right_shift.py
-tensorflow/tensorflow/lite/testing/op_tests/roll.py
-tensorflow/tensorflow/lite/testing/op_tests/round.py
-tensorflow/tensorflow/lite/testing/op_tests/scatter_nd.py
-tensorflow/tensorflow/lite/testing/op_tests/segment_sum.py
-tensorflow/tensorflow/lite/testing/op_tests/shape.py
-tensorflow/tensorflow/lite/testing/op_tests/shape_to_strided_slice.py
-tensorflow/tensorflow/lite/testing/op_tests/sigmoid.py
-tensorflow/tensorflow/lite/testing/op_tests/sigmoid_grad.py
-tensorflow/tensorflow/lite/testing/op_tests/sign.py
-tensorflow/tensorflow/lite/testing/op_tests/slice.py
-tensorflow/tensorflow/lite/testing/op_tests/softmax.py
-tensorflow/tensorflow/lite/testing/op_tests/softplus.py
-tensorflow/tensorflow/lite/testing/op_tests/space_to_batch_nd.py
-tensorflow/tensorflow/lite/testing/op_tests/space_to_depth.py
-tensorflow/tensorflow/lite/testing/op_tests/sparse_to_dense.py
-tensorflow/tensorflow/lite/testing/op_tests/split.py
-tensorflow/tensorflow/lite/testing/op_tests/splitv.py
-tensorflow/tensorflow/lite/testing/op_tests/squeeze.py
-tensorflow/tensorflow/lite/testing/op_tests/squeeze_transpose.py
-tensorflow/tensorflow/lite/testing/op_tests/static_hashtable.py
-tensorflow/tensorflow/lite/testing/op_tests/static_rnn_with_control_flow_v2.py
-tensorflow/tensorflow/lite/testing/op_tests/stft.py
-tensorflow/tensorflow/lite/testing/op_tests/strided_slice.py
-tensorflow/tensorflow/lite/testing/op_tests/strided_slice_np_style.py
-tensorflow/tensorflow/lite/testing/op_tests/tanh.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_concat.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_dynamic_shape.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_get_item.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_length.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_resize.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_list_set_item.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_scatter_add.py
-tensorflow/tensorflow/lite/testing/op_tests/tensor_scatter_update.py
-tensorflow/tensorflow/lite/testing/op_tests/tile.py
-tensorflow/tensorflow/lite/testing/op_tests/topk.py
-tensorflow/tensorflow/lite/testing/op_tests/transpose.py
-tensorflow/tensorflow/lite/testing/op_tests/transpose_conv.py
-tensorflow/tensorflow/lite/testing/op_tests/unfused_gru.py
-tensorflow/tensorflow/lite/testing/op_tests/unique.py
-tensorflow/tensorflow/lite/testing/op_tests/unpack.py
-tensorflow/tensorflow/lite/testing/op_tests/unroll_batch_matmul.py
-tensorflow/tensorflow/lite/testing/op_tests/unsorted_segment.py
-tensorflow/tensorflow/lite/testing/op_tests/where.py
-tensorflow/tensorflow/lite/testing/op_tests/where_v2.py
-tensorflow/tensorflow/lite/testing/op_tests/while_loop.py
-tensorflow/tensorflow/lite/testing/op_tests/zeros_like.py
-tensorflow/tensorflow/lite/toco/logging/gen_html.py
-tensorflow/tensorflow/lite/toco/logging/gen_html_test.py
-tensorflow/tensorflow/lite/toco/python/tensorflow_wrap_toco.py
-tensorflow/tensorflow/lite/tools/convert_image_to_csv.py
-tensorflow/tensorflow/lite/tools/convert_image_to_csv_test.py
-tensorflow/tensorflow/lite/tools/flatbuffer_utils.py
-tensorflow/tensorflow/lite/tools/flatbuffer_utils_test.py
-tensorflow/tensorflow/lite/tools/randomize_weights.py
-tensorflow/tensorflow/lite/tools/reverse_xxd_dump_from_cc.py
-tensorflow/tensorflow/lite/tools/strip_strings.py
-tensorflow/tensorflow/lite/tools/test_utils.py
-tensorflow/tensorflow/lite/tools/visualize.py
-tensorflow/tensorflow/lite/tools/visualize_test.py
-tensorflow/tensorflow/lite/tools/zip_files.py
-tensorflow/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival.py
-tensorflow/tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification/generate_validation_labels.py
-tensorflow/tensorflow/lite/tools/optimize/debugging/python/debugger.py
-tensorflow/tensorflow/lite/tools/optimize/debugging/python/debugger_test.py
-tensorflow/tensorflow/lite/tools/optimize/python/_pywrap_modify_model_interface.pyi
-tensorflow/tensorflow/lite/tools/optimize/python/modify_model_interface.py
-tensorflow/tensorflow/lite/tools/optimize/python/modify_model_interface_constants.py
-tensorflow/tensorflow/lite/tools/optimize/python/modify_model_interface_lib.py
-tensorflow/tensorflow/lite/tools/optimize/python/modify_model_interface_lib_test.py
-tensorflow/tensorflow/lite/tools/optimize/sparsity/format_converter_wrapper_pybind11.pyi
-tensorflow/tensorflow/lite/tools/optimize/sparsity/format_converter_wrapper_pybind11_test.py
-tensorflow/tensorflow/lite/tools/pip_package/setup_with_binary.py
-tensorflow/tensorflow/lite/tools/signature/_pywrap_signature_def_util_wrapper.pyi
-tensorflow/tensorflow/lite/tools/signature/signature_def_utils.py
-tensorflow/tensorflow/lite/tools/signature/signature_def_utils_test.py
-tensorflow/tensorflow/lite/tutorials/dataset.py
-tensorflow/tensorflow/lite/tutorials/mnist_tflite.py
-tensorflow/tensorflow/python/__init__.py
-tensorflow/tensorflow/python/_pywrap_dtensor_device.pyi
-tensorflow/tensorflow/python/_pywrap_mlir.pyi
-tensorflow/tensorflow/python/_pywrap_parallel_device.pyi
-tensorflow/tensorflow/python/_pywrap_py_exception_registry.pyi
-tensorflow/tensorflow/python/_pywrap_quantize_training.pyi
-tensorflow/tensorflow/python/_pywrap_sanitizers.pyi
-tensorflow/tensorflow/python/_pywrap_tfcompile.pyi
-tensorflow/tensorflow/python/_pywrap_tfe.pyi
-tensorflow/tensorflow/python/_pywrap_tfe_monitoring_reader.pyi
-tensorflow/tensorflow/python/_pywrap_toco_api.pyi
-tensorflow/tensorflow/python/flags_pybind.pyi
-tensorflow/tensorflow/python/modules_with_exports.py
-tensorflow/tensorflow/python/proto_exports.py
-tensorflow/tensorflow/python/pywrap_dlopen_global_flags.py
-tensorflow/tensorflow/python/pywrap_mlir.py
-tensorflow/tensorflow/python/pywrap_sanitizers.py
-tensorflow/tensorflow/python/pywrap_tensorflow.py
-tensorflow/tensorflow/python/pywrap_tfe.py
-tensorflow/tensorflow/python/pywrap_tfe_monitoring_reader.py
-tensorflow/tensorflow/python/tf2.py
-tensorflow/tensorflow/python/autograph/__init__.py
-tensorflow/tensorflow/python/autograph/converters/asserts.py
-tensorflow/tensorflow/python/autograph/converters/asserts_test.py
-tensorflow/tensorflow/python/autograph/converters/break_statements.py
-tensorflow/tensorflow/python/autograph/converters/break_statements_test.py
-tensorflow/tensorflow/python/autograph/converters/call_trees.py
-tensorflow/tensorflow/python/autograph/converters/call_trees_test.py
-tensorflow/tensorflow/python/autograph/converters/conditional_expressions.py
-tensorflow/tensorflow/python/autograph/converters/conditional_expressions_test.py
-tensorflow/tensorflow/python/autograph/converters/continue_statements.py
-tensorflow/tensorflow/python/autograph/converters/continue_statements_test.py
-tensorflow/tensorflow/python/autograph/converters/control_flow.py
-tensorflow/tensorflow/python/autograph/converters/control_flow_test.py
-tensorflow/tensorflow/python/autograph/converters/directives.py
-tensorflow/tensorflow/python/autograph/converters/directives_test.py
-tensorflow/tensorflow/python/autograph/converters/functions.py
-tensorflow/tensorflow/python/autograph/converters/functions_test.py
-tensorflow/tensorflow/python/autograph/converters/lists.py
-tensorflow/tensorflow/python/autograph/converters/lists_test.py
-tensorflow/tensorflow/python/autograph/converters/logical_expressions.py
-tensorflow/tensorflow/python/autograph/converters/logical_expressions_test.py
-tensorflow/tensorflow/python/autograph/converters/return_statements.py
-tensorflow/tensorflow/python/autograph/converters/return_statements_test.py
-tensorflow/tensorflow/python/autograph/converters/slices.py
-tensorflow/tensorflow/python/autograph/converters/slices_test.py
-tensorflow/tensorflow/python/autograph/converters/variables.py
-tensorflow/tensorflow/python/autograph/converters/variables_test.py
-tensorflow/tensorflow/python/autograph/core/ag_ctx.py
-tensorflow/tensorflow/python/autograph/core/config.py
-tensorflow/tensorflow/python/autograph/core/config_lib.py
-tensorflow/tensorflow/python/autograph/core/converter.py
-tensorflow/tensorflow/python/autograph/core/converter_test.py
-tensorflow/tensorflow/python/autograph/core/converter_testing.py
-tensorflow/tensorflow/python/autograph/core/function_wrappers.py
-tensorflow/tensorflow/python/autograph/core/function_wrappers_test.py
-tensorflow/tensorflow/python/autograph/core/unsupported_features_checker.py
-tensorflow/tensorflow/python/autograph/impl/api.py
-tensorflow/tensorflow/python/autograph/impl/api_test.py
-tensorflow/tensorflow/python/autograph/impl/conversion.py
-tensorflow/tensorflow/python/autograph/impl/conversion_test.py
-tensorflow/tensorflow/python/autograph/impl/testing/pybind_for_testing.pyi
-tensorflow/tensorflow/python/autograph/lang/directives.py
-tensorflow/tensorflow/python/autograph/lang/special_functions.py
-tensorflow/tensorflow/python/autograph/lang/special_functions_test.py
-tensorflow/tensorflow/python/autograph/operators/__init__.py
-tensorflow/tensorflow/python/autograph/operators/conditional_expressions.py
-tensorflow/tensorflow/python/autograph/operators/conditional_expressions_test.py
-tensorflow/tensorflow/python/autograph/operators/control_flow.py
-tensorflow/tensorflow/python/autograph/operators/control_flow_test.py
-tensorflow/tensorflow/python/autograph/operators/data_structures.py
-tensorflow/tensorflow/python/autograph/operators/data_structures_test.py
-tensorflow/tensorflow/python/autograph/operators/dispatch_context.py
-tensorflow/tensorflow/python/autograph/operators/exceptions.py
-tensorflow/tensorflow/python/autograph/operators/exceptions_test.py
-tensorflow/tensorflow/python/autograph/operators/logical.py
-tensorflow/tensorflow/python/autograph/operators/logical_test.py
-tensorflow/tensorflow/python/autograph/operators/py_builtins.py
-tensorflow/tensorflow/python/autograph/operators/py_builtins_test.py
-tensorflow/tensorflow/python/autograph/operators/slices.py
-tensorflow/tensorflow/python/autograph/operators/slices_test.py
-tensorflow/tensorflow/python/autograph/operators/variables.py
-tensorflow/tensorflow/python/autograph/operators/variables_test.py
-tensorflow/tensorflow/python/autograph/pyct/__init__.py
-tensorflow/tensorflow/python/autograph/pyct/anno.py
-tensorflow/tensorflow/python/autograph/pyct/anno_test.py
-tensorflow/tensorflow/python/autograph/pyct/ast_util.py
-tensorflow/tensorflow/python/autograph/pyct/ast_util_test.py
-tensorflow/tensorflow/python/autograph/pyct/cache.py
-tensorflow/tensorflow/python/autograph/pyct/cache_test.py
-tensorflow/tensorflow/python/autograph/pyct/cfg.py
-tensorflow/tensorflow/python/autograph/pyct/cfg_test.py
-tensorflow/tensorflow/python/autograph/pyct/error_utils.py
-tensorflow/tensorflow/python/autograph/pyct/error_utils_test.py
-tensorflow/tensorflow/python/autograph/pyct/errors.py
-tensorflow/tensorflow/python/autograph/pyct/gast_util.py
-tensorflow/tensorflow/python/autograph/pyct/inspect_utils.py
-tensorflow/tensorflow/python/autograph/pyct/inspect_utils_test.py
-tensorflow/tensorflow/python/autograph/pyct/loader.py
-tensorflow/tensorflow/python/autograph/pyct/loader_test.py
-tensorflow/tensorflow/python/autograph/pyct/naming.py
-tensorflow/tensorflow/python/autograph/pyct/naming_test.py
-tensorflow/tensorflow/python/autograph/pyct/origin_info.py
-tensorflow/tensorflow/python/autograph/pyct/origin_info_test.py
-tensorflow/tensorflow/python/autograph/pyct/parser.py
-tensorflow/tensorflow/python/autograph/pyct/parser_test.py
-tensorflow/tensorflow/python/autograph/pyct/pretty_printer.py
-tensorflow/tensorflow/python/autograph/pyct/pretty_printer_test.py
-tensorflow/tensorflow/python/autograph/pyct/qual_names.py
-tensorflow/tensorflow/python/autograph/pyct/qual_names_test.py
-tensorflow/tensorflow/python/autograph/pyct/templates.py
-tensorflow/tensorflow/python/autograph/pyct/templates_test.py
-tensorflow/tensorflow/python/autograph/pyct/transformer.py
-tensorflow/tensorflow/python/autograph/pyct/transformer_test.py
-tensorflow/tensorflow/python/autograph/pyct/transpiler.py
-tensorflow/tensorflow/python/autograph/pyct/transpiler_test.py
-tensorflow/tensorflow/python/autograph/pyct/common_transformers/__init__.py
-tensorflow/tensorflow/python/autograph/pyct/common_transformers/anf.py
-tensorflow/tensorflow/python/autograph/pyct/common_transformers/anf_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/__init__.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/activity.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/activity_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/annos.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/liveness.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/liveness_py3_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/liveness_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions_py3_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/reaching_fndefs.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/reaching_fndefs_test.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/type_inference.py
-tensorflow/tensorflow/python/autograph/pyct/static_analysis/type_inference_test.py
-tensorflow/tensorflow/python/autograph/pyct/testing/basic_definitions.py
-tensorflow/tensorflow/python/autograph/pyct/testing/codegen.py
-tensorflow/tensorflow/python/autograph/pyct/testing/codegen_test.py
-tensorflow/tensorflow/python/autograph/pyct/testing/decorators.py
-tensorflow/tensorflow/python/autograph/tests/assertion_test.py
-tensorflow/tensorflow/python/autograph/tests/basic_ifexp_test.py
-tensorflow/tensorflow/python/autograph/tests/basic_list_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_builtin_function_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_lambda_function_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_named_tuple_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_numpy_function_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_print_function_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_tf_api_test.py
-tensorflow/tensorflow/python/autograph/tests/call_to_user_function_test.py
-tensorflow/tensorflow/python/autograph/tests/composite_names_in_control_flow_test.py
-tensorflow/tensorflow/python/autograph/tests/cond_basic_test.py
-tensorflow/tensorflow/python/autograph/tests/datasets_test.py
-tensorflow/tensorflow/python/autograph/tests/early_return_test.py
-tensorflow/tensorflow/python/autograph/tests/ext_slice_test.py
-tensorflow/tensorflow/python/autograph/tests/generator_test.py
-tensorflow/tensorflow/python/autograph/tests/logical_expression_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_basic_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_control_flow_illegal_cases_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_control_flow_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_created_variables_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_distributed_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_scoping_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_with_function_call_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_with_variable_type_illegal_cases_test.py
-tensorflow/tensorflow/python/autograph/tests/loop_with_variable_type_test.py
-tensorflow/tensorflow/python/autograph/tests/nested_control_flow_test.py
-tensorflow/tensorflow/python/autograph/tests/reference_test_base.py
-tensorflow/tensorflow/python/autograph/tests/type_annotations_test.py
-tensorflow/tensorflow/python/autograph/utils/__init__.py
-tensorflow/tensorflow/python/autograph/utils/ag_logging.py
-tensorflow/tensorflow/python/autograph/utils/context_managers.py
-tensorflow/tensorflow/python/autograph/utils/context_managers_test.py
-tensorflow/tensorflow/python/autograph/utils/misc.py
-tensorflow/tensorflow/python/autograph/utils/misc_test.py
-tensorflow/tensorflow/python/autograph/utils/tensor_list.py
-tensorflow/tensorflow/python/autograph/utils/tensor_list_test.py
-tensorflow/tensorflow/python/autograph/utils/tensors.py
-tensorflow/tensorflow/python/autograph/utils/tensors_test.py
-tensorflow/tensorflow/python/autograph/utils/testing.py
-tensorflow/tensorflow/python/autograph/utils/type_registry.py
-tensorflow/tensorflow/python/checkpoint/async_checkpoint_helper.py
-tensorflow/tensorflow/python/checkpoint/benchmarks_test.py
-tensorflow/tensorflow/python/checkpoint/checkpoint.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_adapter.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_context.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_management.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_management_test.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_metrics_test.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_options.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_test.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_view.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_view_test.py
-tensorflow/tensorflow/python/checkpoint/checkpoint_with_v1_optimizers_test.py
-tensorflow/tensorflow/python/checkpoint/functional_saver.py
-tensorflow/tensorflow/python/checkpoint/functional_saver_test.py
-tensorflow/tensorflow/python/checkpoint/graph_view.py
-tensorflow/tensorflow/python/checkpoint/restore.py
-tensorflow/tensorflow/python/checkpoint/restore_test.py
-tensorflow/tensorflow/python/checkpoint/save_util.py
-tensorflow/tensorflow/python/checkpoint/save_util_v1.py
-tensorflow/tensorflow/python/checkpoint/save_util_v1_test.py
-tensorflow/tensorflow/python/checkpoint/saveable_compat.py
-tensorflow/tensorflow/python/checkpoint/saveable_compat_test.py
-tensorflow/tensorflow/python/checkpoint/tensor_callable.py
-tensorflow/tensorflow/python/checkpoint/tensor_callable_test.py
-tensorflow/tensorflow/python/checkpoint/trackable_view.py
-tensorflow/tensorflow/python/checkpoint/trackable_view_test.py
-tensorflow/tensorflow/python/checkpoint/util.py
-tensorflow/tensorflow/python/checkpoint/sharding/sharding_policies.py
-tensorflow/tensorflow/python/checkpoint/sharding/sharding_policies_test.py
-tensorflow/tensorflow/python/checkpoint/sharding/sharding_util.py
-tensorflow/tensorflow/python/checkpoint/sharding/sharding_util_test.py
-tensorflow/tensorflow/python/checkpoint/testdata/generate_checkpoint.py
-tensorflow/tensorflow/python/client/__init__.py
-tensorflow/tensorflow/python/client/_pywrap_debug_events_writer.pyi
-tensorflow/tensorflow/python/client/_pywrap_device_lib.pyi
-tensorflow/tensorflow/python/client/_pywrap_events_writer.pyi
-tensorflow/tensorflow/python/client/_pywrap_tf_session.pyi
-tensorflow/tensorflow/python/client/client_lib.py
-tensorflow/tensorflow/python/client/device_lib.py
-tensorflow/tensorflow/python/client/device_lib_test.py
-tensorflow/tensorflow/python/client/events_writer_test.py
-tensorflow/tensorflow/python/client/notebook.py
-tensorflow/tensorflow/python/client/pywrap_tf_session.py
-tensorflow/tensorflow/python/client/session.py
-tensorflow/tensorflow/python/client/session_benchmark.py
-tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py
-tensorflow/tensorflow/python/client/session_list_devices_test.py
-tensorflow/tensorflow/python/client/session_partial_run_test.py
-tensorflow/tensorflow/python/client/session_test.py
-tensorflow/tensorflow/python/client/timeline.py
-tensorflow/tensorflow/python/client/timeline_test.py
-tensorflow/tensorflow/python/client/virtual_gpu_test.py
-tensorflow/tensorflow/python/compat/compat.py
-tensorflow/tensorflow/python/compat/compat_test.py
-tensorflow/tensorflow/python/compat/disable_v2_behavior_test.py
-tensorflow/tensorflow/python/compat/v2_compat.py
-tensorflow/tensorflow/python/compiler/__init__.py
-tensorflow/tensorflow/python/compiler/mlir/mlir.py
-tensorflow/tensorflow/python/compiler/mlir/mlir_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/__init__.py
-tensorflow/tensorflow/python/compiler/tensorrt/trt_convert.py
-tensorflow/tensorflow/python/compiler/tensorrt/trt_convert_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/utils.py
-tensorflow/tensorflow/python/compiler/tensorrt/model_tests/model_handler.py
-tensorflow/tensorflow/python/compiler/tensorrt/model_tests/result_analyzer.py
-tensorflow/tensorflow/python/compiler/tensorrt/model_tests/run_models.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/annotate_max_batch_sizes_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/base_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/batch_matmul_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/biasadd_matmul_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/binary_tensor_weight_broadcast_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/bool_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/cast_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/combined_nms_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/concatenation_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/const_broadcast_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/conv2d_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/data_dependent_shape_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/dynamic_input_shapes_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/identity_output_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/int32_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/lru_cache_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/memory_alignment_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/multi_connection_neighbor_engine_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/neighboring_engine_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/quantization_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/rank_two_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/reshape_transpose_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/shape_output_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/test_utils.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/tf_function_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/tf_trt_integration_test_base.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/topk_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/trt_engine_op_shape_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/trt_mode_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/unary_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/vgg_block_nchw_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/vgg_block_test.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/testdata/gen_tf_readvariableop_model.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/testdata/gen_tf_variablev2_model.py
-tensorflow/tensorflow/python/compiler/tensorrt/test/testdata/gen_tftrt_model.py
-tensorflow/tensorflow/python/compiler/xla/__init__.py
-tensorflow/tensorflow/python/compiler/xla/jit.py
-tensorflow/tensorflow/python/compiler/xla/pjrt_compile_virtual_device_test.py
-tensorflow/tensorflow/python/compiler/xla/xla.py
-tensorflow/tensorflow/python/compiler/xla/experimental/resource_variable_xla_sharding_test.py
-tensorflow/tensorflow/python/compiler/xla/experimental/xla_sharding.py
-tensorflow/tensorflow/python/compiler/xla/experimental/xla_sharding_test.py
-tensorflow/tensorflow/python/compiler/xla/tests/jit_compile_test.py
-tensorflow/tensorflow/python/compiler/xla/tests/jit_test.py
-tensorflow/tensorflow/python/compiler/xla/tests/pjrt_autoclustering_test.py
-tensorflow/tensorflow/python/compiler/xla/tests/pjrt_compile_test.py
-tensorflow/tensorflow/python/compiler/xla/tests/xla_test.py
-tensorflow/tensorflow/python/data/__init__.py
-tensorflow/tensorflow/python/data/benchmarks/batch_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/benchmark_base.py
-tensorflow/tensorflow/python/data/benchmarks/filter_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/from_tensor_slices_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/interleave_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/list_files_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/map_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/meta_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/prefetch_benchmark.py
-tensorflow/tensorflow/python/data/benchmarks/range_benchmark.py
-tensorflow/tensorflow/python/data/experimental/__init__.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/autotune_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/csv_dataset_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/map_and_batch_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/map_defun_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/matching_files_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/optimize_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/parameter_value_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/rejection_resample_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/snapshot_dataset_benchmark.py
-tensorflow/tensorflow/python/data/experimental/benchmarks/unbatch_benchmark.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/assert_cardinality_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/assert_next_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/assert_prev_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/auto_shard_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/compression_ops_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/copy_to_device_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/csv_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/dense_to_sparse_batch_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/from_list_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/global_shuffle_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/group_by_reducer_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/index_flat_map_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/index_shuffle_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/io_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/iterator_model_ops_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/lookup_ops_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/make_batched_features_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/make_csv_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/make_saveable_from_iterator_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/make_tf_record_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/map_and_batch_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/map_defun_op_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/matching_files_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/model_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/non_serializable_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/pad_to_cardinality_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/parallel_interleave_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/parse_example_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/prefetch_to_device_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/prefetch_with_slack_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/rebatch_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/replicate_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/shuffle_and_repeat_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/sleep_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/sql_dataset_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/tf_record_writer_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/variant_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/weighted_flat_map_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/wrap_unwrap_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/filter_fusion_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/filter_parallelization_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/grappler_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/make_deterministic_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/map_and_batch_fusion_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/map_and_filter_fusion_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/map_fusion_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/map_parallelization_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/noop_elimination_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/optimization_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/seq_interleave_prefetch_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/auto_shard_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/coordinated_read_ft_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/coordinated_read_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_ft_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/data_service_ops_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/distributed_save_load_ft_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/distributed_save_load_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/dynamic_sharding_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/fault_tolerance_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/gpu_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/local_workers_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/metadata_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/multi_device_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/multi_process_cluster.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/multi_process_cluster_test.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/test_base.py
-tensorflow/tensorflow/python/data/experimental/kernel_tests/service/worker_tags_test.py
-tensorflow/tensorflow/python/data/experimental/ops/batching.py
-tensorflow/tensorflow/python/data/experimental/ops/cardinality.py
-tensorflow/tensorflow/python/data/experimental/ops/compression_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/counter.py
-tensorflow/tensorflow/python/data/experimental/ops/data_service_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/distribute.py
-tensorflow/tensorflow/python/data/experimental/ops/distributed_save_op.py
-tensorflow/tensorflow/python/data/experimental/ops/enumerate_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/error_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/from_list.py
-tensorflow/tensorflow/python/data/experimental/ops/get_single_element.py
-tensorflow/tensorflow/python/data/experimental/ops/global_shuffle_op.py
-tensorflow/tensorflow/python/data/experimental/ops/grouping.py
-tensorflow/tensorflow/python/data/experimental/ops/index_flat_map_op.py
-tensorflow/tensorflow/python/data/experimental/ops/interleave_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/io.py
-tensorflow/tensorflow/python/data/experimental/ops/iterator_model_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/iterator_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/lookup_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/map_defun.py
-tensorflow/tensorflow/python/data/experimental/ops/matching_files.py
-tensorflow/tensorflow/python/data/experimental/ops/pad_to_cardinality.py
-tensorflow/tensorflow/python/data/experimental/ops/parsing_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/prefetching_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/random_access.py
-tensorflow/tensorflow/python/data/experimental/ops/random_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/readers.py
-tensorflow/tensorflow/python/data/experimental/ops/resampling.py
-tensorflow/tensorflow/python/data/experimental/ops/scan_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/shuffle_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/sleep.py
-tensorflow/tensorflow/python/data/experimental/ops/snapshot.py
-tensorflow/tensorflow/python/data/experimental/ops/take_while_ops.py
-tensorflow/tensorflow/python/data/experimental/ops/testing.py
-tensorflow/tensorflow/python/data/experimental/ops/unique.py
-tensorflow/tensorflow/python/data/experimental/ops/weighted_flat_map_op.py
-tensorflow/tensorflow/python/data/experimental/ops/writers.py
-tensorflow/tensorflow/python/data/experimental/service/__init__.py
-tensorflow/tensorflow/python/data/experimental/service/_pywrap_server_lib.pyi
-tensorflow/tensorflow/python/data/experimental/service/_pywrap_snapshot_utils.pyi
-tensorflow/tensorflow/python/data/experimental/service/_pywrap_utils_exp.pyi
-tensorflow/tensorflow/python/data/experimental/service/server_lib.py
-tensorflow/tensorflow/python/data/experimental/service/server_lib_test.py
-tensorflow/tensorflow/python/data/kernel_tests/as_numpy_iterator_test.py
-tensorflow/tensorflow/python/data/kernel_tests/batch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/bucket_by_sequence_length_test.py
-tensorflow/tensorflow/python/data/kernel_tests/cache_test.py
-tensorflow/tensorflow/python/data/kernel_tests/cardinality_test.py
-tensorflow/tensorflow/python/data/kernel_tests/checkpoint_test.py
-tensorflow/tensorflow/python/data/kernel_tests/checkpoint_test_base.py
-tensorflow/tensorflow/python/data/kernel_tests/choose_from_datasets_test.py
-tensorflow/tensorflow/python/data/kernel_tests/concatenate_test.py
-tensorflow/tensorflow/python/data/kernel_tests/counter_test.py
-tensorflow/tensorflow/python/data/kernel_tests/dataset_spec_test.py
-tensorflow/tensorflow/python/data/kernel_tests/dataset_test.py
-tensorflow/tensorflow/python/data/kernel_tests/enumerate_test.py
-tensorflow/tensorflow/python/data/kernel_tests/filter_test.py
-tensorflow/tensorflow/python/data/kernel_tests/fingerprint_test.py
-tensorflow/tensorflow/python/data/kernel_tests/fixed_length_record_dataset_test.py
-tensorflow/tensorflow/python/data/kernel_tests/flat_map_test.py
-tensorflow/tensorflow/python/data/kernel_tests/from_generator_test.py
-tensorflow/tensorflow/python/data/kernel_tests/from_sparse_tensor_slices_test.py
-tensorflow/tensorflow/python/data/kernel_tests/from_tensor_slices_test.py
-tensorflow/tensorflow/python/data/kernel_tests/from_tensors_test.py
-tensorflow/tensorflow/python/data/kernel_tests/get_single_element_test.py
-tensorflow/tensorflow/python/data/kernel_tests/group_by_window_test.py
-tensorflow/tensorflow/python/data/kernel_tests/ignore_errors_test.py
-tensorflow/tensorflow/python/data/kernel_tests/interleave_test.py
-tensorflow/tensorflow/python/data/kernel_tests/io_test.py
-tensorflow/tensorflow/python/data/kernel_tests/iterator_cluster_test.py
-tensorflow/tensorflow/python/data/kernel_tests/iterator_test.py
-tensorflow/tensorflow/python/data/kernel_tests/len_test.py
-tensorflow/tensorflow/python/data/kernel_tests/list_files_test.py
-tensorflow/tensorflow/python/data/kernel_tests/map_test.py
-tensorflow/tensorflow/python/data/kernel_tests/memory_cleanup_test.py
-tensorflow/tensorflow/python/data/kernel_tests/multi_device_iterator_test.py
-tensorflow/tensorflow/python/data/kernel_tests/optional_test.py
-tensorflow/tensorflow/python/data/kernel_tests/options_test.py
-tensorflow/tensorflow/python/data/kernel_tests/padded_batch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/placement_test.py
-tensorflow/tensorflow/python/data/kernel_tests/prefetch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/ragged_batch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/random_test.py
-tensorflow/tensorflow/python/data/kernel_tests/range_test.py
-tensorflow/tensorflow/python/data/kernel_tests/rebatch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/reduce_test.py
-tensorflow/tensorflow/python/data/kernel_tests/rejection_resample_test.py
-tensorflow/tensorflow/python/data/kernel_tests/repeat_test.py
-tensorflow/tensorflow/python/data/kernel_tests/sample_from_datasets_test.py
-tensorflow/tensorflow/python/data/kernel_tests/scan_test.py
-tensorflow/tensorflow/python/data/kernel_tests/shard_test.py
-tensorflow/tensorflow/python/data/kernel_tests/shuffle_test.py
-tensorflow/tensorflow/python/data/kernel_tests/skip_test.py
-tensorflow/tensorflow/python/data/kernel_tests/snapshot_test.py
-tensorflow/tensorflow/python/data/kernel_tests/sparse_batch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/take_test.py
-tensorflow/tensorflow/python/data/kernel_tests/take_while_test.py
-tensorflow/tensorflow/python/data/kernel_tests/test_base.py
-tensorflow/tensorflow/python/data/kernel_tests/text_line_dataset_test.py
-tensorflow/tensorflow/python/data/kernel_tests/tf_record_dataset_test.py
-tensorflow/tensorflow/python/data/kernel_tests/tf_record_test_base.py
-tensorflow/tensorflow/python/data/kernel_tests/unbatch_test.py
-tensorflow/tensorflow/python/data/kernel_tests/unique_test.py
-tensorflow/tensorflow/python/data/kernel_tests/window_test.py
-tensorflow/tensorflow/python/data/kernel_tests/zip_test.py
-tensorflow/tensorflow/python/data/ops/batch_op.py
-tensorflow/tensorflow/python/data/ops/cache_op.py
-tensorflow/tensorflow/python/data/ops/choose_from_datasets_op.py
-tensorflow/tensorflow/python/data/ops/concatenate_op.py
-tensorflow/tensorflow/python/data/ops/counter_op.py
-tensorflow/tensorflow/python/data/ops/dataset_autograph.py
-tensorflow/tensorflow/python/data/ops/dataset_ops.py
-tensorflow/tensorflow/python/data/ops/debug_mode.py
-tensorflow/tensorflow/python/data/ops/directed_interleave_op.py
-tensorflow/tensorflow/python/data/ops/filter_op.py
-tensorflow/tensorflow/python/data/ops/flat_map_op.py
-tensorflow/tensorflow/python/data/ops/from_generator_op.py
-tensorflow/tensorflow/python/data/ops/from_sparse_tensor_slices_op.py
-tensorflow/tensorflow/python/data/ops/from_tensor_slices_op.py
-tensorflow/tensorflow/python/data/ops/from_tensors_op.py
-tensorflow/tensorflow/python/data/ops/group_by_window_op.py
-tensorflow/tensorflow/python/data/ops/ignore_errors_op.py
-tensorflow/tensorflow/python/data/ops/interleave_op.py
-tensorflow/tensorflow/python/data/ops/iterator_autograph.py
-tensorflow/tensorflow/python/data/ops/iterator_ops.py
-tensorflow/tensorflow/python/data/ops/load_op.py
-tensorflow/tensorflow/python/data/ops/map_op.py
-tensorflow/tensorflow/python/data/ops/multi_device_iterator_ops.py
-tensorflow/tensorflow/python/data/ops/optional_ops.py
-tensorflow/tensorflow/python/data/ops/options.py
-tensorflow/tensorflow/python/data/ops/padded_batch_op.py
-tensorflow/tensorflow/python/data/ops/prefetch_op.py
-tensorflow/tensorflow/python/data/ops/ragged_batch_op.py
-tensorflow/tensorflow/python/data/ops/random_op.py
-tensorflow/tensorflow/python/data/ops/range_op.py
-tensorflow/tensorflow/python/data/ops/readers.py
-tensorflow/tensorflow/python/data/ops/rebatch_op.py
-tensorflow/tensorflow/python/data/ops/repeat_op.py
-tensorflow/tensorflow/python/data/ops/sample_from_datasets_op.py
-tensorflow/tensorflow/python/data/ops/save_op.py
-tensorflow/tensorflow/python/data/ops/scan_op.py
-tensorflow/tensorflow/python/data/ops/shard_op.py
-tensorflow/tensorflow/python/data/ops/shuffle_op.py
-tensorflow/tensorflow/python/data/ops/skip_op.py
-tensorflow/tensorflow/python/data/ops/snapshot_op.py
-tensorflow/tensorflow/python/data/ops/sparse_batch_op.py
-tensorflow/tensorflow/python/data/ops/structured_function.py
-tensorflow/tensorflow/python/data/ops/take_op.py
-tensorflow/tensorflow/python/data/ops/take_while_op.py
-tensorflow/tensorflow/python/data/ops/test_mode.py
-tensorflow/tensorflow/python/data/ops/unbatch_op.py
-tensorflow/tensorflow/python/data/ops/unique_op.py
-tensorflow/tensorflow/python/data/ops/window_op.py
-tensorflow/tensorflow/python/data/ops/zip_op.py
-tensorflow/tensorflow/python/data/util/convert.py
-tensorflow/tensorflow/python/data/util/convert_test.py
-tensorflow/tensorflow/python/data/util/nest.py
-tensorflow/tensorflow/python/data/util/nest_test.py
-tensorflow/tensorflow/python/data/util/options.py
-tensorflow/tensorflow/python/data/util/options_test.py
-tensorflow/tensorflow/python/data/util/random_seed.py
-tensorflow/tensorflow/python/data/util/random_seed_test.py
-tensorflow/tensorflow/python/data/util/sparse.py
-tensorflow/tensorflow/python/data/util/sparse_test.py
-tensorflow/tensorflow/python/data/util/structure.py
-tensorflow/tensorflow/python/data/util/structure_test.py
-tensorflow/tensorflow/python/data/util/traverse.py
-tensorflow/tensorflow/python/data/util/traverse_test.py
-tensorflow/tensorflow/python/debug/__init__.py
-tensorflow/tensorflow/python/debug/cli/__init__.py
-tensorflow/tensorflow/python/debug/cli/analyzer_cli.py
-tensorflow/tensorflow/python/debug/cli/analyzer_cli_test.py
-tensorflow/tensorflow/python/debug/cli/base_ui.py
-tensorflow/tensorflow/python/debug/cli/cli_config.py
-tensorflow/tensorflow/python/debug/cli/cli_config_test.py
-tensorflow/tensorflow/python/debug/cli/cli_shared.py
-tensorflow/tensorflow/python/debug/cli/cli_shared_test.py
-tensorflow/tensorflow/python/debug/cli/cli_test_utils.py
-tensorflow/tensorflow/python/debug/cli/command_parser.py
-tensorflow/tensorflow/python/debug/cli/command_parser_test.py
-tensorflow/tensorflow/python/debug/cli/debugger_cli_common.py
-tensorflow/tensorflow/python/debug/cli/debugger_cli_common_test.py
-tensorflow/tensorflow/python/debug/cli/evaluator.py
-tensorflow/tensorflow/python/debug/cli/evaluator_test.py
-tensorflow/tensorflow/python/debug/cli/offline_analyzer.py
-tensorflow/tensorflow/python/debug/cli/profile_analyzer_cli.py
-tensorflow/tensorflow/python/debug/cli/profile_analyzer_cli_test.py
-tensorflow/tensorflow/python/debug/cli/readline_ui.py
-tensorflow/tensorflow/python/debug/cli/readline_ui_test.py
-tensorflow/tensorflow/python/debug/cli/tensor_format.py
-tensorflow/tensorflow/python/debug/cli/tensor_format_test.py
-tensorflow/tensorflow/python/debug/cli/ui_factory.py
-tensorflow/tensorflow/python/debug/examples/v1/debug_errors.py
-tensorflow/tensorflow/python/debug/examples/v1/debug_fibonacci.py
-tensorflow/tensorflow/python/debug/examples/v1/debug_keras.py
-tensorflow/tensorflow/python/debug/examples/v1/debug_mnist_v1.py
-tensorflow/tensorflow/python/debug/examples/v2/debug_fibonacci_v2.py
-tensorflow/tensorflow/python/debug/examples/v2/debug_mnist_v2.py
-tensorflow/tensorflow/python/debug/lib/__init__.py
-tensorflow/tensorflow/python/debug/lib/check_numerics_callback.py
-tensorflow/tensorflow/python/debug/lib/check_numerics_callback_test.py
-tensorflow/tensorflow/python/debug/lib/common.py
-tensorflow/tensorflow/python/debug/lib/common_test.py
-tensorflow/tensorflow/python/debug/lib/debug_data.py
-tensorflow/tensorflow/python/debug/lib/debug_data_test.py
-tensorflow/tensorflow/python/debug/lib/debug_events_monitors.py
-tensorflow/tensorflow/python/debug/lib/debug_events_monitors_test.py
-tensorflow/tensorflow/python/debug/lib/debug_events_reader.py
-tensorflow/tensorflow/python/debug/lib/debug_events_writer.py
-tensorflow/tensorflow/python/debug/lib/debug_events_writer_test.py
-tensorflow/tensorflow/python/debug/lib/debug_gradients.py
-tensorflow/tensorflow/python/debug/lib/debug_gradients_test.py
-tensorflow/tensorflow/python/debug/lib/debug_graph_reconstruction_test.py
-tensorflow/tensorflow/python/debug/lib/debug_graphs.py
-tensorflow/tensorflow/python/debug/lib/debug_graphs_test.py
-tensorflow/tensorflow/python/debug/lib/debug_grappler_test.py
-tensorflow/tensorflow/python/debug/lib/debug_service_pb2_grpc.py
-tensorflow/tensorflow/python/debug/lib/debug_utils.py
-tensorflow/tensorflow/python/debug/lib/debug_utils_test.py
-tensorflow/tensorflow/python/debug/lib/debug_v2_ops_test.py
-tensorflow/tensorflow/python/debug/lib/dumping_callback.py
-tensorflow/tensorflow/python/debug/lib/dumping_callback_test.py
-tensorflow/tensorflow/python/debug/lib/dumping_callback_test_lib.py
-tensorflow/tensorflow/python/debug/lib/grpc_debug_server.py
-tensorflow/tensorflow/python/debug/lib/grpc_debug_test_server.py
-tensorflow/tensorflow/python/debug/lib/grpc_tensorflow_server.py
-tensorflow/tensorflow/python/debug/lib/op_callbacks_common.py
-tensorflow/tensorflow/python/debug/lib/profiling.py
-tensorflow/tensorflow/python/debug/lib/profiling_test.py
-tensorflow/tensorflow/python/debug/lib/session_debug_file_test.py
-tensorflow/tensorflow/python/debug/lib/session_debug_multi_gpu_test.py
-tensorflow/tensorflow/python/debug/lib/session_debug_testlib.py
-tensorflow/tensorflow/python/debug/lib/source_remote.py
-tensorflow/tensorflow/python/debug/lib/source_remote_test.py
-tensorflow/tensorflow/python/debug/lib/source_utils.py
-tensorflow/tensorflow/python/debug/lib/source_utils_test.py
-tensorflow/tensorflow/python/debug/wrappers/disk_usage_test.py
-tensorflow/tensorflow/python/debug/wrappers/dumping_wrapper.py
-tensorflow/tensorflow/python/debug/wrappers/dumping_wrapper_test.py
-tensorflow/tensorflow/python/debug/wrappers/framework.py
-tensorflow/tensorflow/python/debug/wrappers/framework_test.py
-tensorflow/tensorflow/python/debug/wrappers/grpc_wrapper.py
-tensorflow/tensorflow/python/debug/wrappers/hooks.py
-tensorflow/tensorflow/python/debug/wrappers/local_cli_wrapper.py
-tensorflow/tensorflow/python/debug/wrappers/local_cli_wrapper_test.py
-tensorflow/tensorflow/python/distribute/__init__.py
-tensorflow/tensorflow/python/distribute/central_storage_strategy.py
-tensorflow/tensorflow/python/distribute/checkpoint_utils_test.py
-tensorflow/tensorflow/python/distribute/checkpointing_test.py
-tensorflow/tensorflow/python/distribute/collective_all_reduce_strategy.py
-tensorflow/tensorflow/python/distribute/collective_all_reduce_strategy_test.py
-tensorflow/tensorflow/python/distribute/collective_util.py
-tensorflow/tensorflow/python/distribute/collective_util_test.py
-tensorflow/tensorflow/python/distribute/combinations.py
-tensorflow/tensorflow/python/distribute/combinations_test.py
-tensorflow/tensorflow/python/distribute/cross_device_ops.py
-tensorflow/tensorflow/python/distribute/cross_device_ops_test.py
-tensorflow/tensorflow/python/distribute/cross_device_utils.py
-tensorflow/tensorflow/python/distribute/cross_device_utils_test.py
-tensorflow/tensorflow/python/distribute/custom_training_loop_gradient_test.py
-tensorflow/tensorflow/python/distribute/custom_training_loop_input_test.py
-tensorflow/tensorflow/python/distribute/device_util.py
-tensorflow/tensorflow/python/distribute/device_util_test.py
-tensorflow/tensorflow/python/distribute/distribute_config.py
-tensorflow/tensorflow/python/distribute/distribute_coordinator.py
-tensorflow/tensorflow/python/distribute/distribute_coordinator_context.py
-tensorflow/tensorflow/python/distribute/distribute_coordinator_test.py
-tensorflow/tensorflow/python/distribute/distribute_lib.py
-tensorflow/tensorflow/python/distribute/distribute_lib_test.py
-tensorflow/tensorflow/python/distribute/distribute_utils.py
-tensorflow/tensorflow/python/distribute/distribute_utils_test.py
-tensorflow/tensorflow/python/distribute/distributed_table_test.py
-tensorflow/tensorflow/python/distribute/distributed_variable_test.py
-tensorflow/tensorflow/python/distribute/input_lib.py
-tensorflow/tensorflow/python/distribute/input_lib_test.py
-tensorflow/tensorflow/python/distribute/input_lib_type_spec_test.py
-tensorflow/tensorflow/python/distribute/input_ops.py
-tensorflow/tensorflow/python/distribute/input_ops_test.py
-tensorflow/tensorflow/python/distribute/input_util.py
-tensorflow/tensorflow/python/distribute/load_context.py
-tensorflow/tensorflow/python/distribute/merge_call_interim.py
-tensorflow/tensorflow/python/distribute/metrics_v1_test.py
-tensorflow/tensorflow/python/distribute/mirrored_run.py
-tensorflow/tensorflow/python/distribute/mirrored_strategy.py
-tensorflow/tensorflow/python/distribute/mirrored_strategy_test.py
-tensorflow/tensorflow/python/distribute/mirrored_values_test.py
-tensorflow/tensorflow/python/distribute/mirrored_variable_test.py
-tensorflow/tensorflow/python/distribute/moving_averages_test.py
-tensorflow/tensorflow/python/distribute/multi_process_lib.py
-tensorflow/tensorflow/python/distribute/multi_process_runner.py
-tensorflow/tensorflow/python/distribute/multi_process_runner_no_init_test.py
-tensorflow/tensorflow/python/distribute/multi_process_runner_test.py
-tensorflow/tensorflow/python/distribute/multi_worker_continuous_run_test.py
-tensorflow/tensorflow/python/distribute/multi_worker_test_base.py
-tensorflow/tensorflow/python/distribute/multi_worker_test_base_test.py
-tensorflow/tensorflow/python/distribute/multi_worker_util.py
-tensorflow/tensorflow/python/distribute/multi_worker_util_test.py
-tensorflow/tensorflow/python/distribute/mwms_pjrt_gpu_test.py
-tensorflow/tensorflow/python/distribute/numpy_dataset.py
-tensorflow/tensorflow/python/distribute/numpy_dataset_test.py
-tensorflow/tensorflow/python/distribute/one_device_strategy.py
-tensorflow/tensorflow/python/distribute/one_device_strategy_test.py
-tensorflow/tensorflow/python/distribute/packed_distributed_variable.py
-tensorflow/tensorflow/python/distribute/packed_distributed_variable_test.py
-tensorflow/tensorflow/python/distribute/parameter_server_strategy.py
-tensorflow/tensorflow/python/distribute/parameter_server_strategy_test.py
-tensorflow/tensorflow/python/distribute/parameter_server_strategy_v2.py
-tensorflow/tensorflow/python/distribute/parameter_server_strategy_v2_test.py
-tensorflow/tensorflow/python/distribute/per_replica_test.py
-tensorflow/tensorflow/python/distribute/ps_values.py
-tensorflow/tensorflow/python/distribute/ps_values_test.py
-tensorflow/tensorflow/python/distribute/random_generator_test.py
-tensorflow/tensorflow/python/distribute/reduce_util.py
-tensorflow/tensorflow/python/distribute/remote_mirrored_strategy_eager_test.py
-tensorflow/tensorflow/python/distribute/sharded_variable.py
-tensorflow/tensorflow/python/distribute/sharded_variable_test.py
-tensorflow/tensorflow/python/distribute/shared_variable_creator.py
-tensorflow/tensorflow/python/distribute/shared_variable_creator_test.py
-tensorflow/tensorflow/python/distribute/single_loss_example.py
-tensorflow/tensorflow/python/distribute/step_fn.py
-tensorflow/tensorflow/python/distribute/strategy_combinations.py
-tensorflow/tensorflow/python/distribute/strategy_combinations_test.py
-tensorflow/tensorflow/python/distribute/strategy_common_test.py
-tensorflow/tensorflow/python/distribute/strategy_gather_test.py
-tensorflow/tensorflow/python/distribute/strategy_test_lib.py
-tensorflow/tensorflow/python/distribute/summary_op_util.py
-tensorflow/tensorflow/python/distribute/template_mirrored_strategy_test.py
-tensorflow/tensorflow/python/distribute/test_util.py
-tensorflow/tensorflow/python/distribute/test_util_test.py
-tensorflow/tensorflow/python/distribute/tf_function_test.py
-tensorflow/tensorflow/python/distribute/tpu_replicated_variable.py
-tensorflow/tensorflow/python/distribute/tpu_replicated_variable_test.py
-tensorflow/tensorflow/python/distribute/tpu_strategy.py
-tensorflow/tensorflow/python/distribute/tpu_strategy_compilation_test.py
-tensorflow/tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py
-tensorflow/tensorflow/python/distribute/tpu_strategy_test.py
-tensorflow/tensorflow/python/distribute/tpu_util.py
-tensorflow/tensorflow/python/distribute/tpu_values.py
-tensorflow/tensorflow/python/distribute/values.py
-tensorflow/tensorflow/python/distribute/values_test.py
-tensorflow/tensorflow/python/distribute/values_util.py
-tensorflow/tensorflow/python/distribute/values_v2.py
-tensorflow/tensorflow/python/distribute/values_v2_test.py
-tensorflow/tensorflow/python/distribute/vars_test.py
-tensorflow/tensorflow/python/distribute/warm_starting_util_test.py
-tensorflow/tensorflow/python/distribute/zero_batch_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/__init__.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/kubernetes_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/kubernetes_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/sagemaker_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/sagemaker_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/slurm_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/slurm_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/tfconfig_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/tfconfig_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py
-tensorflow/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver_test.py
-tensorflow/tensorflow/python/distribute/coordinator/cluster_coordinator.py
-tensorflow/tensorflow/python/distribute/coordinator/cluster_coordinator_test.py
-tensorflow/tensorflow/python/distribute/coordinator/coordinator_context.py
-tensorflow/tensorflow/python/distribute/coordinator/fault_tolerance_coordination_service_test.py
-tensorflow/tensorflow/python/distribute/coordinator/fault_tolerance_test.py
-tensorflow/tensorflow/python/distribute/coordinator/fault_tolerance_test_base.py
-tensorflow/tensorflow/python/distribute/coordinator/get_task_states_test.py
-tensorflow/tensorflow/python/distribute/coordinator/metric_utils.py
-tensorflow/tensorflow/python/distribute/coordinator/metric_utils_test.py
-tensorflow/tensorflow/python/distribute/coordinator/remote_value.py
-tensorflow/tensorflow/python/distribute/coordinator/utils.py
-tensorflow/tensorflow/python/distribute/coordinator/values.py
-tensorflow/tensorflow/python/distribute/coordinator/watchdog.py
-tensorflow/tensorflow/python/distribute/coordinator/watchdog_test.py
-tensorflow/tensorflow/python/distribute/experimental/__init__.py
-tensorflow/tensorflow/python/distribute/experimental/dtensor_strategy_extended.py
-tensorflow/tensorflow/python/distribute/experimental/dtensor_util.py
-tensorflow/tensorflow/python/distribute/experimental/dtensor_util_test.py
-tensorflow/tensorflow/python/distribute/experimental/mirrored_strategy.py
-tensorflow/tensorflow/python/distribute/experimental/mirrored_strategy_test.py
-tensorflow/tensorflow/python/distribute/experimental/multi_worker_mirrored_strategy.py
-tensorflow/tensorflow/python/distribute/experimental/multi_worker_mirrored_strategy_test.py
-tensorflow/tensorflow/python/distribute/experimental/rpc/rpc_ops.py
-tensorflow/tensorflow/python/distribute/experimental/rpc/rpc_ops_test.py
-tensorflow/tensorflow/python/distribute/failure_handling/__init__.py
-tensorflow/tensorflow/python/distribute/failure_handling/failure_handler_test.py
-tensorflow/tensorflow/python/distribute/failure_handling/failure_handling.py
-tensorflow/tensorflow/python/distribute/failure_handling/failure_handling_util.py
-tensorflow/tensorflow/python/distribute/failure_handling/gce_failure_handler_test.py
-tensorflow/tensorflow/python/distribute/failure_handling/preemption_watcher.py
-tensorflow/tensorflow/python/distribute/integration_test/mwms_peer_failure_test.py
-tensorflow/tensorflow/python/distribute/integration_test/saved_model_test.py
-tensorflow/tensorflow/python/distribute/integration_test/tpu_memory_test.py
-tensorflow/tensorflow/python/distribute/parallel_device/parallel_device.py
-tensorflow/tensorflow/python/distribute/parallel_device/parallel_device_test.py
-tensorflow/tensorflow/python/distribute/v1/all_reduce.py
-tensorflow/tensorflow/python/distribute/v1/all_reduce_test.py
-tensorflow/tensorflow/python/distribute/v1/cross_device_ops_test.py
-tensorflow/tensorflow/python/distribute/v1/input_lib.py
-tensorflow/tensorflow/python/dlpack/dlpack.py
-tensorflow/tensorflow/python/dlpack/dlpack_test.py
-tensorflow/tensorflow/python/eager/backprop.py
-tensorflow/tensorflow/python/eager/backprop_test.py
-tensorflow/tensorflow/python/eager/backprop_util.py
-tensorflow/tensorflow/python/eager/benchmarks_test.py
-tensorflow/tensorflow/python/eager/benchmarks_test_base.py
-tensorflow/tensorflow/python/eager/cancellation.py
-tensorflow/tensorflow/python/eager/cancellation_test.py
-tensorflow/tensorflow/python/eager/context.py
-tensorflow/tensorflow/python/eager/context_cross_platform_gpu_test.py
-tensorflow/tensorflow/python/eager/context_cross_platform_tpu_test.py
-tensorflow/tensorflow/python/eager/context_test.py
-tensorflow/tensorflow/python/eager/context_tpu_platform_test.py
-tensorflow/tensorflow/python/eager/core.py
-tensorflow/tensorflow/python/eager/core_test.py
-tensorflow/tensorflow/python/eager/custom_device_test.py
-tensorflow/tensorflow/python/eager/custom_device_testutil.pyi
-tensorflow/tensorflow/python/eager/def_function.py
-tensorflow/tensorflow/python/eager/device_placement_test.py
-tensorflow/tensorflow/python/eager/execute.py
-tensorflow/tensorflow/python/eager/executor.py
-tensorflow/tensorflow/python/eager/forwardprop.py
-tensorflow/tensorflow/python/eager/forwardprop_test.py
-tensorflow/tensorflow/python/eager/forwardprop_util.py
-tensorflow/tensorflow/python/eager/function.py
-tensorflow/tensorflow/python/eager/gen_gradient_input_output_exclusions.py
-tensorflow/tensorflow/python/eager/gradient_input_output_exclusions.py
-tensorflow/tensorflow/python/eager/gradient_input_output_exclusions_test.py
-tensorflow/tensorflow/python/eager/graph_only_ops.py
-tensorflow/tensorflow/python/eager/graph_only_ops_test.py
-tensorflow/tensorflow/python/eager/imperative_grad.py
-tensorflow/tensorflow/python/eager/lift_to_graph.py
-tensorflow/tensorflow/python/eager/lift_to_graph_test.py
-tensorflow/tensorflow/python/eager/monitoring.py
-tensorflow/tensorflow/python/eager/monitoring_test.py
-tensorflow/tensorflow/python/eager/ops_test.py
-tensorflow/tensorflow/python/eager/profiler.py
-tensorflow/tensorflow/python/eager/profiler_client.py
-tensorflow/tensorflow/python/eager/profiler_client_test.py
-tensorflow/tensorflow/python/eager/profiler_test.py
-tensorflow/tensorflow/python/eager/pywrap_tensor_test.py
-tensorflow/tensorflow/python/eager/pywrap_tensor_test_util.pyi
-tensorflow/tensorflow/python/eager/pywrap_tfe_test.py
-tensorflow/tensorflow/python/eager/record.py
-tensorflow/tensorflow/python/eager/record_test.py
-tensorflow/tensorflow/python/eager/remote.py
-tensorflow/tensorflow/python/eager/remote_benchmarks_test.py
-tensorflow/tensorflow/python/eager/remote_cloud_tpu_test.py
-tensorflow/tensorflow/python/eager/remote_cluster_test.py
-tensorflow/tensorflow/python/eager/remote_execution_test.py
-tensorflow/tensorflow/python/eager/remote_test.py
-tensorflow/tensorflow/python/eager/run_eager_op_as_function_test.py
-tensorflow/tensorflow/python/eager/run_eager_op_as_function_xla_test.py
-tensorflow/tensorflow/python/eager/small_constants_optimizer_test.py
-tensorflow/tensorflow/python/eager/summary_optimizer_test.py
-tensorflow/tensorflow/python/eager/tape.py
-tensorflow/tensorflow/python/eager/tensor_test.py
-tensorflow/tensorflow/python/eager/test.py
-tensorflow/tensorflow/python/eager/wrap_function.py
-tensorflow/tensorflow/python/eager/wrap_function_device_test.py
-tensorflow/tensorflow/python/eager/wrap_function_test.py
-tensorflow/tensorflow/python/eager/benchmarks/kpi_benchmark_test.py
-tensorflow/tensorflow/python/eager/benchmarks/resnet50/hvp_test.py
-tensorflow/tensorflow/python/eager/benchmarks/resnet50/resnet50.py
-tensorflow/tensorflow/python/eager/benchmarks/resnet50/resnet50_graph_test.py
-tensorflow/tensorflow/python/eager/benchmarks/resnet50/resnet50_test.py
-tensorflow/tensorflow/python/eager/benchmarks/resnet50/resnet50_test_util.py
-tensorflow/tensorflow/python/eager/memory_tests/memory_test.py
-tensorflow/tensorflow/python/eager/memory_tests/memory_test_util.py
-tensorflow/tensorflow/python/eager/memory_tests/remote_memory_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/argument_naming_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/atomic_function.py
-tensorflow/tensorflow/python/eager/polymorphic_function/atomic_function_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/attributes.py
-tensorflow/tensorflow/python/eager/polymorphic_function/autograph_util.py
-tensorflow/tensorflow/python/eager/polymorphic_function/collection_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/compiler_ir.py
-tensorflow/tensorflow/python/eager/polymorphic_function/compiler_ir_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/composite_tensor_utils.py
-tensorflow/tensorflow/python/eager/polymorphic_function/concrete_function.py
-tensorflow/tensorflow/python/eager/polymorphic_function/concrete_function_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/eager_function_run.py
-tensorflow/tensorflow/python/eager/polymorphic_function/function_context.py
-tensorflow/tensorflow/python/eager/polymorphic_function/function_spec_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/function_type_utils.py
-tensorflow/tensorflow/python/eager/polymorphic_function/gradients_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/polymorphic_function.py
-tensorflow/tensorflow/python/eager/polymorphic_function/polymorphic_function_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/polymorphic_function_test_cpu_only.py
-tensorflow/tensorflow/python/eager/polymorphic_function/polymorphic_function_xla_jit_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/polymorphic_function_xla_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py
-tensorflow/tensorflow/python/eager/polymorphic_function/saved_model_utils.py
-tensorflow/tensorflow/python/eager/polymorphic_function/tf_method_target.py
-tensorflow/tensorflow/python/eager/polymorphic_function/tracing_compilation.py
-tensorflow/tensorflow/python/eager/polymorphic_function/tracing_compilation_test.py
-tensorflow/tensorflow/python/eager/polymorphic_function/transform.py
-tensorflow/tensorflow/python/feature_column/__init__.py
-tensorflow/tensorflow/python/feature_column/feature_column.py
-tensorflow/tensorflow/python/feature_column/feature_column_lib.py
-tensorflow/tensorflow/python/feature_column/feature_column_test.py
-tensorflow/tensorflow/python/feature_column/feature_column_v2.py
-tensorflow/tensorflow/python/feature_column/feature_column_v2_test.py
-tensorflow/tensorflow/python/feature_column/feature_column_v2_types.py
-tensorflow/tensorflow/python/feature_column/sequence_feature_column.py
-tensorflow/tensorflow/python/feature_column/sequence_feature_column_integration_test.py
-tensorflow/tensorflow/python/feature_column/sequence_feature_column_test.py
-tensorflow/tensorflow/python/feature_column/serialization.py
-tensorflow/tensorflow/python/feature_column/serialization_test.py
-tensorflow/tensorflow/python/feature_column/utils.py
-tensorflow/tensorflow/python/framework/__init__.py
-tensorflow/tensorflow/python/framework/_dtypes.pyi
-tensorflow/tensorflow/python/framework/_errors_test_helper.pyi
-tensorflow/tensorflow/python/framework/_op_def_library_pybind.pyi
-tensorflow/tensorflow/python/framework/_op_def_registry.pyi
-tensorflow/tensorflow/python/framework/_op_def_util.pyi
-tensorflow/tensorflow/python/framework/_proto_comparators.pyi
-tensorflow/tensorflow/python/framework/_py_context_manager.pyi
-tensorflow/tensorflow/python/framework/_python_memory_checker_helper.pyi
-tensorflow/tensorflow/python/framework/_pywrap_python_api_dispatcher.pyi
-tensorflow/tensorflow/python/framework/_pywrap_python_api_info.pyi
-tensorflow/tensorflow/python/framework/_pywrap_python_api_parameter_converter.pyi
-tensorflow/tensorflow/python/framework/_pywrap_python_op_gen.pyi
-tensorflow/tensorflow/python/framework/_pywrap_python_tensor_converter.pyi
-tensorflow/tensorflow/python/framework/_test_metrics_util.pyi
-tensorflow/tensorflow/python/framework/auto_control_deps.py
-tensorflow/tensorflow/python/framework/auto_control_deps_test.py
-tensorflow/tensorflow/python/framework/auto_control_deps_utils.py
-tensorflow/tensorflow/python/framework/byte_swap_tensor.py
-tensorflow/tensorflow/python/framework/c_api_util.py
-tensorflow/tensorflow/python/framework/c_api_util_test.py
-tensorflow/tensorflow/python/framework/combinations.py
-tensorflow/tensorflow/python/framework/common_shapes.py
-tensorflow/tensorflow/python/framework/common_shapes_test.py
-tensorflow/tensorflow/python/framework/composite_tensor.py
-tensorflow/tensorflow/python/framework/composite_tensor_gradient.py
-tensorflow/tensorflow/python/framework/composite_tensor_test.py
-tensorflow/tensorflow/python/framework/config.py
-tensorflow/tensorflow/python/framework/config_test.py
-tensorflow/tensorflow/python/framework/config_vgpu_test.py
-tensorflow/tensorflow/python/framework/constant_op.py
-tensorflow/tensorflow/python/framework/constant_op_test.py
-tensorflow/tensorflow/python/framework/constant_tensor_conversion.py
-tensorflow/tensorflow/python/framework/convert_to_constants.py
-tensorflow/tensorflow/python/framework/convert_to_constants_test.py
-tensorflow/tensorflow/python/framework/device.py
-tensorflow/tensorflow/python/framework/device_spec.py
-tensorflow/tensorflow/python/framework/device_spec_test.py
-tensorflow/tensorflow/python/framework/device_test.py
-tensorflow/tensorflow/python/framework/dtypes.py
-tensorflow/tensorflow/python/framework/dtypes_test.py
-tensorflow/tensorflow/python/framework/error_interpolation.py
-tensorflow/tensorflow/python/framework/error_interpolation_test.py
-tensorflow/tensorflow/python/framework/errors.py
-tensorflow/tensorflow/python/framework/errors_impl.py
-tensorflow/tensorflow/python/framework/errors_test.py
-tensorflow/tensorflow/python/framework/extension_type.py
-tensorflow/tensorflow/python/framework/extension_type_field.py
-tensorflow/tensorflow/python/framework/extension_type_field_test.py
-tensorflow/tensorflow/python/framework/extension_type_test.py
-tensorflow/tensorflow/python/framework/file_system_test.py
-tensorflow/tensorflow/python/framework/flexible_dtypes.py
-tensorflow/tensorflow/python/framework/flexible_dtypes_test.py
-tensorflow/tensorflow/python/framework/framework_lib.py
-tensorflow/tensorflow/python/framework/func_graph.py
-tensorflow/tensorflow/python/framework/function.py
-tensorflow/tensorflow/python/framework/function_def_to_graph.py
-tensorflow/tensorflow/python/framework/function_def_to_graph_test.py
-tensorflow/tensorflow/python/framework/function_test.py
-tensorflow/tensorflow/python/framework/gpu_util.py
-tensorflow/tensorflow/python/framework/graph_building_benchmark.py
-tensorflow/tensorflow/python/framework/graph_io.py
-tensorflow/tensorflow/python/framework/graph_to_function_def.py
-tensorflow/tensorflow/python/framework/graph_util.py
-tensorflow/tensorflow/python/framework/graph_util_impl.py
-tensorflow/tensorflow/python/framework/graph_util_test.py
-tensorflow/tensorflow/python/framework/immutable_dict.py
-tensorflow/tensorflow/python/framework/immutable_dict_test.py
-tensorflow/tensorflow/python/framework/importer.py
-tensorflow/tensorflow/python/framework/importer_test.py
-tensorflow/tensorflow/python/framework/indexed_slices.py
-tensorflow/tensorflow/python/framework/indexed_slices_test.py
-tensorflow/tensorflow/python/framework/is_mlir_bridge_test_false.py
-tensorflow/tensorflow/python/framework/is_mlir_bridge_test_true.py
-tensorflow/tensorflow/python/framework/is_xla_test_true.py
-tensorflow/tensorflow/python/framework/kernels.py
-tensorflow/tensorflow/python/framework/kernels_test.py
-tensorflow/tensorflow/python/framework/load_library.py
-tensorflow/tensorflow/python/framework/memory_checker.py
-tensorflow/tensorflow/python/framework/memory_checker_test.py
-tensorflow/tensorflow/python/framework/meta_graph.py
-tensorflow/tensorflow/python/framework/meta_graph_test.py
-tensorflow/tensorflow/python/framework/node_file_writer_test.py
-tensorflow/tensorflow/python/framework/none_tensor.py
-tensorflow/tensorflow/python/framework/op_allowlist_namespace_test.py
-tensorflow/tensorflow/python/framework/op_callbacks.py
-tensorflow/tensorflow/python/framework/op_callbacks_test.py
-tensorflow/tensorflow/python/framework/op_def_library.py
-tensorflow/tensorflow/python/framework/op_def_library_pybind.py
-tensorflow/tensorflow/python/framework/op_def_library_test.py
-tensorflow/tensorflow/python/framework/op_def_registry.py
-tensorflow/tensorflow/python/framework/op_def_util_test.py
-tensorflow/tensorflow/python/framework/ops.py
-tensorflow/tensorflow/python/framework/ops_enable_eager_test.py
-tensorflow/tensorflow/python/framework/ops_test.py
-tensorflow/tensorflow/python/framework/override_binary_operator.py
-tensorflow/tensorflow/python/framework/proto_test.py
-tensorflow/tensorflow/python/framework/py_context_manager_test.py
-tensorflow/tensorflow/python/framework/python_api_dispatcher_test.py
-tensorflow/tensorflow/python/framework/python_api_info_test.py
-tensorflow/tensorflow/python/framework/python_api_parameter_converter_test.py
-tensorflow/tensorflow/python/framework/python_memory_checker.py
-tensorflow/tensorflow/python/framework/python_op_gen_annotation_test.py
-tensorflow/tensorflow/python/framework/python_tensor_converter_test.py
-tensorflow/tensorflow/python/framework/random_seed.py
-tensorflow/tensorflow/python/framework/random_seed_test.py
-tensorflow/tensorflow/python/framework/registry.py
-tensorflow/tensorflow/python/framework/registry_test.py
-tensorflow/tensorflow/python/framework/smart_cond.py
-tensorflow/tensorflow/python/framework/smart_cond_test.py
-tensorflow/tensorflow/python/framework/sparse_tensor.py
-tensorflow/tensorflow/python/framework/sparse_tensor_test.py
-tensorflow/tensorflow/python/framework/stack.py
-tensorflow/tensorflow/python/framework/strict_mode.py
-tensorflow/tensorflow/python/framework/subscribe.py
-tensorflow/tensorflow/python/framework/subscribe_test.py
-tensorflow/tensorflow/python/framework/summary_test_util.py
-tensorflow/tensorflow/python/framework/tensor.py
-tensorflow/tensorflow/python/framework/tensor_conversion.py
-tensorflow/tensorflow/python/framework/tensor_conversion_registry.py
-tensorflow/tensorflow/python/framework/tensor_shape.py
-tensorflow/tensorflow/python/framework/tensor_shape_test.py
-tensorflow/tensorflow/python/framework/tensor_spec.py
-tensorflow/tensorflow/python/framework/tensor_test.py
-tensorflow/tensorflow/python/framework/tensor_util.py
-tensorflow/tensorflow/python/framework/tensor_util_test.py
-tensorflow/tensorflow/python/framework/test_combinations.py
-tensorflow/tensorflow/python/framework/test_combinations_test.py
-tensorflow/tensorflow/python/framework/test_util.py
-tensorflow/tensorflow/python/framework/test_util_test.py
-tensorflow/tensorflow/python/framework/tf2_test.py
-tensorflow/tensorflow/python/framework/tfrt_utils.py
-tensorflow/tensorflow/python/framework/traceable_stack.py
-tensorflow/tensorflow/python/framework/traceable_stack_test.py
-tensorflow/tensorflow/python/framework/type_spec.py
-tensorflow/tensorflow/python/framework/type_spec_registry.py
-tensorflow/tensorflow/python/framework/type_spec_test.py
-tensorflow/tensorflow/python/framework/type_utils.py
-tensorflow/tensorflow/python/framework/versions.py
-tensorflow/tensorflow/python/framework/versions_test.py
-tensorflow/tensorflow/python/framework/weak_tensor.py
-tensorflow/tensorflow/python/framework/weak_tensor_test.py
-tensorflow/tensorflow/python/framework/experimental/_math_ops.pyi
-tensorflow/tensorflow/python/framework/experimental/_nn_ops.pyi
-tensorflow/tensorflow/python/framework/experimental/_unified_api.pyi
-tensorflow/tensorflow/python/framework/experimental/context_stack.py
-tensorflow/tensorflow/python/framework/experimental/def_function.py
-tensorflow/tensorflow/python/framework/experimental/gradient_registry.py
-tensorflow/tensorflow/python/framework/experimental/graph_building_test.py
-tensorflow/tensorflow/python/framework/experimental/math_ops.py
-tensorflow/tensorflow/python/framework/experimental/nn_ops.py
-tensorflow/tensorflow/python/framework/experimental/tape.py
-tensorflow/tensorflow/python/framework/experimental/thread_local_stack.py
-tensorflow/tensorflow/python/framework/experimental/unified_api_test.py
-tensorflow/tensorflow/python/grappler/_pywrap_cost_analyzer.pyi
-tensorflow/tensorflow/python/grappler/_pywrap_graph_analyzer.pyi
-tensorflow/tensorflow/python/grappler/_pywrap_model_analyzer.pyi
-tensorflow/tensorflow/python/grappler/_pywrap_tf_cluster.pyi
-tensorflow/tensorflow/python/grappler/_pywrap_tf_item.pyi
-tensorflow/tensorflow/python/grappler/_pywrap_tf_optimizer.pyi
-tensorflow/tensorflow/python/grappler/arithmetic_optimizer_test.py
-tensorflow/tensorflow/python/grappler/auto_mixed_precision_test.py
-tensorflow/tensorflow/python/grappler/cluster.py
-tensorflow/tensorflow/python/grappler/cluster_test.py
-tensorflow/tensorflow/python/grappler/constant_folding_test.py
-tensorflow/tensorflow/python/grappler/cost_analyzer.py
-tensorflow/tensorflow/python/grappler/cost_analyzer_test.py
-tensorflow/tensorflow/python/grappler/cost_analyzer_tool.py
-tensorflow/tensorflow/python/grappler/datasets_test.py
-tensorflow/tensorflow/python/grappler/graph_analyzer.py
-tensorflow/tensorflow/python/grappler/item.py
-tensorflow/tensorflow/python/grappler/item_test.py
-tensorflow/tensorflow/python/grappler/layout_optimizer_test.py
-tensorflow/tensorflow/python/grappler/memory_optimizer_test.py
-tensorflow/tensorflow/python/grappler/model_analyzer.py
-tensorflow/tensorflow/python/grappler/model_analyzer_test.py
-tensorflow/tensorflow/python/grappler/remapper_test.py
-tensorflow/tensorflow/python/grappler/tf_optimizer.py
-tensorflow/tensorflow/python/grappler/tf_optimizer_test.py
-tensorflow/tensorflow/python/keras/__init__.py
-tensorflow/tensorflow/python/keras/activations.py
-tensorflow/tensorflow/python/keras/backend.py
-tensorflow/tensorflow/python/keras/backend_config.py
-tensorflow/tensorflow/python/keras/callbacks.py
-tensorflow/tensorflow/python/keras/callbacks_v1.py
-tensorflow/tensorflow/python/keras/combinations.py
-tensorflow/tensorflow/python/keras/constraints.py
-tensorflow/tensorflow/python/keras/keras_parameterized.py
-tensorflow/tensorflow/python/keras/losses.py
-tensorflow/tensorflow/python/keras/metrics.py
-tensorflow/tensorflow/python/keras/models.py
-tensorflow/tensorflow/python/keras/optimizer_v1.py
-tensorflow/tensorflow/python/keras/optimizers.py
-tensorflow/tensorflow/python/keras/regularizers.py
-tensorflow/tensorflow/python/keras/testing_utils.py
-tensorflow/tensorflow/python/keras/distribute/__init__.py
-tensorflow/tensorflow/python/keras/distribute/distribute_coordinator_utils.py
-tensorflow/tensorflow/python/keras/distribute/distributed_file_utils.py
-tensorflow/tensorflow/python/keras/distribute/distributed_training_utils.py
-tensorflow/tensorflow/python/keras/distribute/distributed_training_utils_v1.py
-tensorflow/tensorflow/python/keras/distribute/optimizer_combinations.py
-tensorflow/tensorflow/python/keras/distribute/worker_training_state.py
-tensorflow/tensorflow/python/keras/engine/__init__.py
-tensorflow/tensorflow/python/keras/engine/base_layer.py
-tensorflow/tensorflow/python/keras/engine/base_layer_utils.py
-tensorflow/tensorflow/python/keras/engine/base_layer_v1.py
-tensorflow/tensorflow/python/keras/engine/base_preprocessing_layer.py
-tensorflow/tensorflow/python/keras/engine/compile_utils.py
-tensorflow/tensorflow/python/keras/engine/data_adapter.py
-tensorflow/tensorflow/python/keras/engine/functional.py
-tensorflow/tensorflow/python/keras/engine/input_layer.py
-tensorflow/tensorflow/python/keras/engine/input_spec.py
-tensorflow/tensorflow/python/keras/engine/keras_tensor.py
-tensorflow/tensorflow/python/keras/engine/node.py
-tensorflow/tensorflow/python/keras/engine/partial_batch_padding_handler.py
-tensorflow/tensorflow/python/keras/engine/saving.py
-tensorflow/tensorflow/python/keras/engine/sequential.py
-tensorflow/tensorflow/python/keras/engine/training.py
-tensorflow/tensorflow/python/keras/engine/training_arrays_v1.py
-tensorflow/tensorflow/python/keras/engine/training_distributed_v1.py
-tensorflow/tensorflow/python/keras/engine/training_eager_v1.py
-tensorflow/tensorflow/python/keras/engine/training_generator_v1.py
-tensorflow/tensorflow/python/keras/engine/training_utils.py
-tensorflow/tensorflow/python/keras/engine/training_utils_v1.py
-tensorflow/tensorflow/python/keras/engine/training_v1.py
-tensorflow/tensorflow/python/keras/initializers/__init__.py
-tensorflow/tensorflow/python/keras/initializers/initializers_v1.py
-tensorflow/tensorflow/python/keras/initializers/initializers_v2.py
-tensorflow/tensorflow/python/keras/layers/__init__.py
-tensorflow/tensorflow/python/keras/layers/advanced_activations.py
-tensorflow/tensorflow/python/keras/layers/convolutional.py
-tensorflow/tensorflow/python/keras/layers/convolutional_recurrent.py
-tensorflow/tensorflow/python/keras/layers/core.py
-tensorflow/tensorflow/python/keras/layers/dense_attention.py
-tensorflow/tensorflow/python/keras/layers/embeddings.py
-tensorflow/tensorflow/python/keras/layers/merge.py
-tensorflow/tensorflow/python/keras/layers/pooling.py
-tensorflow/tensorflow/python/keras/layers/recurrent.py
-tensorflow/tensorflow/python/keras/layers/rnn_cell_wrapper_v2.py
-tensorflow/tensorflow/python/keras/layers/serialization.py
-tensorflow/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py
-tensorflow/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_wrapper_impl.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/__init__.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/base.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/convolutional.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/core.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/pooling.py
-tensorflow/tensorflow/python/keras/legacy_tf_layers/variable_scope_shim.py
-tensorflow/tensorflow/python/keras/mixed_precision/__init__.py
-tensorflow/tensorflow/python/keras/mixed_precision/autocast_variable.py
-tensorflow/tensorflow/python/keras/mixed_precision/device_compatibility_check.py
-tensorflow/tensorflow/python/keras/mixed_precision/get_layer_policy.py
-tensorflow/tensorflow/python/keras/mixed_precision/loss_scale.py
-tensorflow/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py
-tensorflow/tensorflow/python/keras/mixed_precision/policy.py
-tensorflow/tensorflow/python/keras/mixed_precision/test_util.py
-tensorflow/tensorflow/python/keras/optimizer_v2/adadelta.py
-tensorflow/tensorflow/python/keras/optimizer_v2/adagrad.py
-tensorflow/tensorflow/python/keras/optimizer_v2/adam.py
-tensorflow/tensorflow/python/keras/optimizer_v2/adamax.py
-tensorflow/tensorflow/python/keras/optimizer_v2/ftrl.py
-tensorflow/tensorflow/python/keras/optimizer_v2/gradient_descent.py
-tensorflow/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py
-tensorflow/tensorflow/python/keras/optimizer_v2/legacy_learning_rate_decay.py
-tensorflow/tensorflow/python/keras/optimizer_v2/nadam.py
-tensorflow/tensorflow/python/keras/optimizer_v2/optimizer_v2.py
-tensorflow/tensorflow/python/keras/optimizer_v2/rmsprop.py
-tensorflow/tensorflow/python/keras/optimizer_v2/utils.py
-tensorflow/tensorflow/python/keras/saving/__init__.py
-tensorflow/tensorflow/python/keras/saving/hdf5_format.py
-tensorflow/tensorflow/python/keras/saving/model_config.py
-tensorflow/tensorflow/python/keras/saving/save.py
-tensorflow/tensorflow/python/keras/saving/saved_model_experimental.py
-tensorflow/tensorflow/python/keras/saving/saving_utils.py
-tensorflow/tensorflow/python/keras/saving/saved_model/base_serialization.py
-tensorflow/tensorflow/python/keras/saving/saved_model/constants.py
-tensorflow/tensorflow/python/keras/saving/saved_model/json_utils.py
-tensorflow/tensorflow/python/keras/saving/saved_model/layer_serialization.py
-tensorflow/tensorflow/python/keras/saving/saved_model/load.py
-tensorflow/tensorflow/python/keras/saving/saved_model/load_context.py
-tensorflow/tensorflow/python/keras/saving/saved_model/metric_serialization.py
-tensorflow/tensorflow/python/keras/saving/saved_model/model_serialization.py
-tensorflow/tensorflow/python/keras/saving/saved_model/network_serialization.py
-tensorflow/tensorflow/python/keras/saving/saved_model/save.py
-tensorflow/tensorflow/python/keras/saving/saved_model/save_impl.py
-tensorflow/tensorflow/python/keras/saving/saved_model/serialized_attributes.py
-tensorflow/tensorflow/python/keras/saving/saved_model/utils.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/__init__.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/export_output.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/export_utils.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/mode_keys.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/signature_def_utils.py
-tensorflow/tensorflow/python/keras/saving/utils_v1/unexported_constants.py
-tensorflow/tensorflow/python/keras/utils/__init__.py
-tensorflow/tensorflow/python/keras/utils/all_utils.py
-tensorflow/tensorflow/python/keras/utils/control_flow_util.py
-tensorflow/tensorflow/python/keras/utils/conv_utils.py
-tensorflow/tensorflow/python/keras/utils/data_utils.py
-tensorflow/tensorflow/python/keras/utils/dataset_creator.py
-tensorflow/tensorflow/python/keras/utils/generic_utils.py
-tensorflow/tensorflow/python/keras/utils/io_utils.py
-tensorflow/tensorflow/python/keras/utils/kernelized_utils.py
-tensorflow/tensorflow/python/keras/utils/layer_utils.py
-tensorflow/tensorflow/python/keras/utils/losses_utils.py
-tensorflow/tensorflow/python/keras/utils/metrics_utils.py
-tensorflow/tensorflow/python/keras/utils/mode_keys.py
-tensorflow/tensorflow/python/keras/utils/np_utils.py
-tensorflow/tensorflow/python/keras/utils/object_identity.py
-tensorflow/tensorflow/python/keras/utils/tf_contextlib.py
-tensorflow/tensorflow/python/keras/utils/tf_inspect.py
-tensorflow/tensorflow/python/keras/utils/tf_utils.py
-tensorflow/tensorflow/python/keras/utils/version_utils.py
-tensorflow/tensorflow/python/keras/utils/vis_utils.py
-tensorflow/tensorflow/python/kernel_tests/__init__.py
-tensorflow/tensorflow/python/kernel_tests/benchmark_test.py
-tensorflow/tensorflow/python/kernel_tests/check_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/collective_ops_multi_worker_test.py
-tensorflow/tensorflow/python/kernel_tests/collective_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/composite_tensor_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/critical_section_test.py
-tensorflow/tensorflow/python/kernel_tests/garbage_collection_test.py
-tensorflow/tensorflow/python/kernel_tests/gradient_correctness_test.py
-tensorflow/tensorflow/python/kernel_tests/histogram_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/logging_ops_logging_level_test.py
-tensorflow/tensorflow/python/kernel_tests/logging_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/metrics_test.py
-tensorflow/tensorflow/python/kernel_tests/numerics_test.py
-tensorflow/tensorflow/python/kernel_tests/template_test.py
-tensorflow/tensorflow/python/kernel_tests/trace_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/array_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/batch_gather_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/batch_scatter_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/batchtospace_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/bcast_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/bitcast_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/broadcast_to_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/cast_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/concat_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/constant_op_eager_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/constant_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/denormal_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/depthtospace_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/diag_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/edit_distance_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/fingerprint_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/gather_nd_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/gather_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/huge_slice_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/identity_n_op_py_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/identity_op_py_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/init_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/inplace_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/large_concat_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/manip_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/matrix_band_part_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/one_hot_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/pad_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/reshape_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/reverse_sequence_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/scalar_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/scatter_nd_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/scatter_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/shape_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/slice_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/spacetobatch_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/spacetodepth_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/split_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/stack_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/unique_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/unstack_op_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/weights_broadcast_test.py
-tensorflow/tensorflow/python/kernel_tests/array_ops/where_op_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/cond_v2_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/control_flow_ops_py_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/control_flow_util_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/control_flow_util_v2_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/functional_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/map_fn_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/py_func_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/scan_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/control_flow/while_v2_test.py
-tensorflow/tensorflow/python/kernel_tests/custom_ops/ackermann_test.py
-tensorflow/tensorflow/python/kernel_tests/custom_ops/duplicate_op_test.py
-tensorflow/tensorflow/python/kernel_tests/custom_ops/invalid_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/barrier_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/conditional_accumulator_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/dynamic_partition_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/dynamic_stitch_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/fifo_queue_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/list_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/listdiff_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/lookup_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/map_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/map_stage_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/padding_fifo_queue_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/priority_queue_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/stack_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/stage_op_test.py
-tensorflow/tensorflow/python/kernel_tests/data_structures/tensor_array_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/__init__.py
-tensorflow/tensorflow/python/kernel_tests/distributions/bernoulli_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/beta_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/bijector_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/categorical_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/dirichlet_multinomial_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/dirichlet_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/exponential_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/gamma_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/identity_bijector_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/kullback_leibler_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/laplace_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/multinomial_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/normal_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/special_math_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/student_t_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/uniform_test.py
-tensorflow/tensorflow/python/kernel_tests/distributions/util_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/attention_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_bmp_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_compressed_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_image_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_jpeg_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_png_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/decode_raw_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/draw_bounding_box_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/extract_image_patches_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/extract_image_patches_op_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/extract_volume_patches_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/image_ops/extract_volume_patches_op_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/checkpoint_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/decode_csv_op_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/io_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/parse_single_example_op_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/parsing_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/reader_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/record_input_test.py
-tensorflow/tensorflow/python/kernel_tests/io_ops/save_restore_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/__init__.py
-tensorflow/tensorflow/python/kernel_tests/linalg/cholesky_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/determinant_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/eig_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/einsum_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linalg_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linalg_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_addition_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_adjoint_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_block_diag_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_block_lower_triangular_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_circulant_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_diag_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_full_matrix_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_householder_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_identity_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_inversion_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_kronecker_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_low_rank_update_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_lower_triangular_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_permutation_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_toeplitz_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_tridiag_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_util_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/linear_operator_zeros_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/lu_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_exponential_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_inverse_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_logarithm_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_solve_ls_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_solve_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_square_root_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/matrix_triangular_solve_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/norm_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/normalize_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/qr_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/self_adjoint_eig_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/slicing_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/svd_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/tridiagonal_matmul_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/tridiagonal_solve_op_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/conjugate_gradient_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/csr_sparse_matrix_dense_mat_mul_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/csr_sparse_matrix_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/csr_sparse_matrix_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/csr_sparse_matrix_sparse_mat_mul_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/linalg/sparse/csr_sparse_matrix_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/aggregate_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/approx_topk_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/argmax_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/banded_triangular_solve_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/basic_gpu_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/batch_matmul_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/bincount_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/bucketize_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/clip_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/confusion_matrix_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/cross_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/cumulative_logsumexp_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/cwise_ops_binary_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/cwise_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/cwise_ops_unary_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/division_future_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/division_past_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/in_topk_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/matmul_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/reduce_benchmark_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/reduction_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/reduction_ops_test_big.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/segment_reduction_ops_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/segment_reduction_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/sets_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/tensordot_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/topk_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/transpose_op_test.py
-tensorflow/tensorflow/python/kernel_tests/math_ops/zero_division_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/atrous_conv2d_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/atrous_convolution_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/betainc_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/bias_op_base.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/bias_op_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/bias_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv1d_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv1d_transpose_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv2d_backprop_filter_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv2d_transpose_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv3d_backprop_filter_v2_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv3d_transpose_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv_ops_3d_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/conv_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/ctc_decoder_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/ctc_loss_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/cudnn_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/cudnn_deterministic_base.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/cudnn_deterministic_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/depthwise_conv_op_base.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/depthwise_conv_op_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/depthwise_conv_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/embedding_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/fractional_avg_pool_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/fractional_max_pool_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/losses_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/lrn_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/morphological_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/nth_element_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/pool_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/pooling_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/relu_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/rnn_cell_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/rnn_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/softmax_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/softplus_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/softsign_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/xent_op_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/xent_op_test.py
-tensorflow/tensorflow/python/kernel_tests/nn_ops/xent_op_test_base.py
-tensorflow/tensorflow/python/kernel_tests/proto/decode_proto_op_test.py
-tensorflow/tensorflow/python/kernel_tests/proto/decode_proto_op_test_base.py
-tensorflow/tensorflow/python/kernel_tests/proto/descriptor_source_test.py
-tensorflow/tensorflow/python/kernel_tests/proto/descriptor_source_test_base.py
-tensorflow/tensorflow/python/kernel_tests/proto/encode_proto_op_test.py
-tensorflow/tensorflow/python/kernel_tests/proto/encode_proto_op_test_base.py
-tensorflow/tensorflow/python/kernel_tests/proto/proto_op_test_base.py
-tensorflow/tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/random/candidate_sampler_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/random/multinomial_op_big_test.py
-tensorflow/tensorflow/python/kernel_tests/random/multinomial_op_test.py
-tensorflow/tensorflow/python/kernel_tests/random/parameterized_truncated_normal_op_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_binomial_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_crop_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_gamma_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_index_shuffle_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_poisson_test.py
-tensorflow/tensorflow/python/kernel_tests/random/random_shuffle_queue_test.py
-tensorflow/tensorflow/python/kernel_tests/random/stateful_random_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/random/stateless_random_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/random/util.py
-tensorflow/tensorflow/python/kernel_tests/signal/dct_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/fft_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/mel_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/mfcc_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/reconstruction_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/shape_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/spectral_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/signal/test_util.py
-tensorflow/tensorflow/python/kernel_tests/signal/window_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_add_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_concat_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_conditional_accumulator_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_cross_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_matmul_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_reorder_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_reshape_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_serialization_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_slice_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_split_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_tensor_dense_matmul_grad_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_tensor_dense_matmul_op_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_tensor_dense_matmul_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_tensors_map_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_to_dense_op_py_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_xent_op_d9m_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_xent_op_test.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparse_xent_op_test_base.py
-tensorflow/tensorflow/python/kernel_tests/sparse_ops/sparsemask_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/as_string_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/base64_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/reduce_join_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/regex_full_match_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/regex_replace_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_bytes_split_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_format_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_join_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_length_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_lower_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_split_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_strip_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_to_hash_bucket_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_to_number_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/string_upper_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/substr_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/unicode_decode_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/unicode_encode_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/unicode_script_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/unicode_transcode_op_test.py
-tensorflow/tensorflow/python/kernel_tests/strings_ops/unsorted_segment_join_op_test.py
-tensorflow/tensorflow/python/kernel_tests/summary_ops/summary_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/summary_ops/summary_v1_audio_op_test.py
-tensorflow/tensorflow/python/kernel_tests/summary_ops/summary_v1_image_op_test.py
-tensorflow/tensorflow/python/kernel_tests/summary_ops/summary_v1_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/summary_ops/summary_v1_tensor_op_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/array_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/dense_update_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/identity_op_py_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/scatter_nd_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/session_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/v1_compat_tests/stack_op_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/dense_update_ops_no_tsan_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/dense_update_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/partitioned_variables_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/resource_variable_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/variable_ops_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/variable_scope_test.py
-tensorflow/tensorflow/python/kernel_tests/variables/variables_test.py
-tensorflow/tensorflow/python/layers/__init__.py
-tensorflow/tensorflow/python/layers/base.py
-tensorflow/tensorflow/python/layers/convolutional.py
-tensorflow/tensorflow/python/layers/core.py
-tensorflow/tensorflow/python/layers/layers.py
-tensorflow/tensorflow/python/layers/normalization.py
-tensorflow/tensorflow/python/layers/pooling.py
-tensorflow/tensorflow/python/layers/utils.py
-tensorflow/tensorflow/python/layers/utils_test.py
-tensorflow/tensorflow/python/lib/__init__.py
-tensorflow/tensorflow/python/lib/core/__init__.py
-tensorflow/tensorflow/python/lib/core/_pywrap_py_func.pyi
-tensorflow/tensorflow/python/lib/io/__init__.py
-tensorflow/tensorflow/python/lib/io/_pywrap_file_io.pyi
-tensorflow/tensorflow/python/lib/io/_pywrap_record_io.pyi
-tensorflow/tensorflow/python/lib/io/file_io.py
-tensorflow/tensorflow/python/lib/io/file_io_test.py
-tensorflow/tensorflow/python/lib/io/python_io.py
-tensorflow/tensorflow/python/lib/io/tf_record.py
-tensorflow/tensorflow/python/lib/io/tf_record_test.py
-tensorflow/tensorflow/python/module/module.py
-tensorflow/tensorflow/python/module/module_test.py
-tensorflow/tensorflow/python/ops/accumulate_n_benchmark.py
-tensorflow/tensorflow/python/ops/array_grad.py
-tensorflow/tensorflow/python/ops/array_grad_test.py
-tensorflow/tensorflow/python/ops/array_ops.py
-tensorflow/tensorflow/python/ops/array_ops_shape_test.py
-tensorflow/tensorflow/python/ops/array_ops_stack.py
-tensorflow/tensorflow/python/ops/array_ops_test.py
-tensorflow/tensorflow/python/ops/autograph_ops.py
-tensorflow/tensorflow/python/ops/autograph_ops_test.py
-tensorflow/tensorflow/python/ops/batch_norm_benchmark.py
-tensorflow/tensorflow/python/ops/batch_ops.py
-tensorflow/tensorflow/python/ops/batch_ops_test.py
-tensorflow/tensorflow/python/ops/bincount_ops.py
-tensorflow/tensorflow/python/ops/bincount_ops_test.py
-tensorflow/tensorflow/python/ops/bitwise_ops.py
-tensorflow/tensorflow/python/ops/bitwise_ops_test.py
-tensorflow/tensorflow/python/ops/boosted_trees_ops.py
-tensorflow/tensorflow/python/ops/candidate_sampling_ops.py
-tensorflow/tensorflow/python/ops/check_ops.py
-tensorflow/tensorflow/python/ops/clip_ops.py
-tensorflow/tensorflow/python/ops/clip_ops_test.py
-tensorflow/tensorflow/python/ops/clustering_ops.py
-tensorflow/tensorflow/python/ops/clustering_ops_test.py
-tensorflow/tensorflow/python/ops/collective_ops.py
-tensorflow/tensorflow/python/ops/collective_ops_benchmark.py
-tensorflow/tensorflow/python/ops/collective_ops_gpu_test.py
-tensorflow/tensorflow/python/ops/collective_ops_test.py
-tensorflow/tensorflow/python/ops/collective_ops_xla_test.py
-tensorflow/tensorflow/python/ops/compiled_collective_ops_gpu_test.py
-tensorflow/tensorflow/python/ops/composite_tensor_ops.py
-tensorflow/tensorflow/python/ops/concat_benchmark.py
-tensorflow/tensorflow/python/ops/cond.py
-tensorflow/tensorflow/python/ops/cond_v2.py
-tensorflow/tensorflow/python/ops/confusion_matrix.py
-tensorflow/tensorflow/python/ops/control_flow_assert.py
-tensorflow/tensorflow/python/ops/control_flow_case.py
-tensorflow/tensorflow/python/ops/control_flow_grad.py
-tensorflow/tensorflow/python/ops/control_flow_ops.py
-tensorflow/tensorflow/python/ops/control_flow_ops_benchmark.py
-tensorflow/tensorflow/python/ops/control_flow_ops_test.py
-tensorflow/tensorflow/python/ops/control_flow_state.py
-tensorflow/tensorflow/python/ops/control_flow_switch_case.py
-tensorflow/tensorflow/python/ops/control_flow_util.py
-tensorflow/tensorflow/python/ops/control_flow_util_v2.py
-tensorflow/tensorflow/python/ops/control_flow_v2_disable_test.py
-tensorflow/tensorflow/python/ops/control_flow_v2_enable_test.py
-tensorflow/tensorflow/python/ops/control_flow_v2_func_graphs.py
-tensorflow/tensorflow/python/ops/control_flow_v2_toggles.py
-tensorflow/tensorflow/python/ops/control_flow_v2_toggles_test.py
-tensorflow/tensorflow/python/ops/conv2d_benchmark.py
-tensorflow/tensorflow/python/ops/critical_section_ops.py
-tensorflow/tensorflow/python/ops/ctc_ops.py
-tensorflow/tensorflow/python/ops/cudnn_rnn_grad.py
-tensorflow/tensorflow/python/ops/custom_gradient.py
-tensorflow/tensorflow/python/ops/data_flow_grad.py
-tensorflow/tensorflow/python/ops/data_flow_ops.py
-tensorflow/tensorflow/python/ops/default_gradient.py
-tensorflow/tensorflow/python/ops/dequantize_op_test.py
-tensorflow/tensorflow/python/ops/embedding_ops.py
-tensorflow/tensorflow/python/ops/embedding_ops_test.py
-tensorflow/tensorflow/python/ops/factory_ops_test.py
-tensorflow/tensorflow/python/ops/filesystem_ops.py
-tensorflow/tensorflow/python/ops/functional_ops.py
-tensorflow/tensorflow/python/ops/functional_ops_test.py
-tensorflow/tensorflow/python/ops/gradient_checker.py
-tensorflow/tensorflow/python/ops/gradient_checker_v2.py
-tensorflow/tensorflow/python/ops/gradient_checker_v2_test.py
-tensorflow/tensorflow/python/ops/gradients.py
-tensorflow/tensorflow/python/ops/gradients_impl.py
-tensorflow/tensorflow/python/ops/gradients_test.py
-tensorflow/tensorflow/python/ops/gradients_util.py
-tensorflow/tensorflow/python/ops/handle_data_util.py
-tensorflow/tensorflow/python/ops/histogram_ops.py
-tensorflow/tensorflow/python/ops/image_grad.py
-tensorflow/tensorflow/python/ops/image_grad_d9m_test.py
-tensorflow/tensorflow/python/ops/image_grad_test.py
-tensorflow/tensorflow/python/ops/image_grad_test_base.py
-tensorflow/tensorflow/python/ops/image_ops.py
-tensorflow/tensorflow/python/ops/image_ops_impl.py
-tensorflow/tensorflow/python/ops/image_ops_test.py
-tensorflow/tensorflow/python/ops/init_ops.py
-tensorflow/tensorflow/python/ops/init_ops_test.py
-tensorflow/tensorflow/python/ops/init_ops_v2.py
-tensorflow/tensorflow/python/ops/init_ops_v2_test.py
-tensorflow/tensorflow/python/ops/initializers_ns.py
-tensorflow/tensorflow/python/ops/inplace_ops.py
-tensorflow/tensorflow/python/ops/io_ops.py
-tensorflow/tensorflow/python/ops/linalg_grad.py
-tensorflow/tensorflow/python/ops/linalg_ops.py
-tensorflow/tensorflow/python/ops/linalg_ops_impl.py
-tensorflow/tensorflow/python/ops/list_ops.py
-tensorflow/tensorflow/python/ops/logging_ops.py
-tensorflow/tensorflow/python/ops/lookup_grad.py
-tensorflow/tensorflow/python/ops/lookup_ops.py
-tensorflow/tensorflow/python/ops/lookup_ops_async_checkpoint_test.py
-tensorflow/tensorflow/python/ops/manip_grad.py
-tensorflow/tensorflow/python/ops/manip_ops.py
-tensorflow/tensorflow/python/ops/map_fn.py
-tensorflow/tensorflow/python/ops/map_ops.py
-tensorflow/tensorflow/python/ops/math_grad.py
-tensorflow/tensorflow/python/ops/math_grad_test.py
-tensorflow/tensorflow/python/ops/math_ops.py
-tensorflow/tensorflow/python/ops/math_ops_linspace_test.py
-tensorflow/tensorflow/python/ops/math_ops_test.py
-tensorflow/tensorflow/python/ops/matmul_benchmark.py
-tensorflow/tensorflow/python/ops/metrics.py
-tensorflow/tensorflow/python/ops/metrics_impl.py
-tensorflow/tensorflow/python/ops/nccl_ops.py
-tensorflow/tensorflow/python/ops/nccl_ops_test.py
-tensorflow/tensorflow/python/ops/nn.py
-tensorflow/tensorflow/python/ops/nn_batchnorm_test.py
-tensorflow/tensorflow/python/ops/nn_fused_batch_norm_grad.py
-tensorflow/tensorflow/python/ops/nn_fused_batchnorm_d9m_test.py
-tensorflow/tensorflow/python/ops/nn_fused_batchnorm_test.py
-tensorflow/tensorflow/python/ops/nn_grad.py
-tensorflow/tensorflow/python/ops/nn_grad_test.py
-tensorflow/tensorflow/python/ops/nn_impl.py
-tensorflow/tensorflow/python/ops/nn_impl_distribute.py
-tensorflow/tensorflow/python/ops/nn_loss_scaling_utilities_test.py
-tensorflow/tensorflow/python/ops/nn_ops.py
-tensorflow/tensorflow/python/ops/nn_test.py
-tensorflow/tensorflow/python/ops/nn_xent_test.py
-tensorflow/tensorflow/python/ops/numerics.py
-tensorflow/tensorflow/python/ops/op_selector.py
-tensorflow/tensorflow/python/ops/op_selector_test.py
-tensorflow/tensorflow/python/ops/optional_grad.py
-tensorflow/tensorflow/python/ops/parsing_config.py
-tensorflow/tensorflow/python/ops/parsing_grad.py
-tensorflow/tensorflow/python/ops/parsing_ops.py
-tensorflow/tensorflow/python/ops/partitioned_variables.py
-tensorflow/tensorflow/python/ops/proto_ops.py
-tensorflow/tensorflow/python/ops/quantized_conv_ops_test.py
-tensorflow/tensorflow/python/ops/quantized_ops_test.py
-tensorflow/tensorflow/python/ops/random_crop_ops.py
-tensorflow/tensorflow/python/ops/random_grad.py
-tensorflow/tensorflow/python/ops/random_ops.py
-tensorflow/tensorflow/python/ops/random_ops_util.py
-tensorflow/tensorflow/python/ops/raw_ops_test.py
-tensorflow/tensorflow/python/ops/ref_variable.py
-tensorflow/tensorflow/python/ops/resource_variable_ops.py
-tensorflow/tensorflow/python/ops/resource_variables_toggle.py
-tensorflow/tensorflow/python/ops/resources.py
-tensorflow/tensorflow/python/ops/rnn.py
-tensorflow/tensorflow/python/ops/rnn_cell.py
-tensorflow/tensorflow/python/ops/rnn_cell_impl.py
-tensorflow/tensorflow/python/ops/rnn_cell_wrapper_impl.py
-tensorflow/tensorflow/python/ops/rnn_grad.py
-tensorflow/tensorflow/python/ops/rnn_grad_test.py
-tensorflow/tensorflow/python/ops/script_ops.py
-tensorflow/tensorflow/python/ops/script_ops_test.py
-tensorflow/tensorflow/python/ops/sdca_ops.py
-tensorflow/tensorflow/python/ops/session_ops.py
-tensorflow/tensorflow/python/ops/sets.py
-tensorflow/tensorflow/python/ops/sets_impl.py
-tensorflow/tensorflow/python/ops/shape_util.py
-tensorflow/tensorflow/python/ops/sobol_ops_test.py
-tensorflow/tensorflow/python/ops/sort_ops.py
-tensorflow/tensorflow/python/ops/sort_ops_test.py
-tensorflow/tensorflow/python/ops/sparse_bincount_ops_test.py
-tensorflow/tensorflow/python/ops/sparse_grad.py
-tensorflow/tensorflow/python/ops/sparse_ops.py
-tensorflow/tensorflow/python/ops/sparse_ops_test.py
-tensorflow/tensorflow/python/ops/special_math_ops.py
-tensorflow/tensorflow/python/ops/special_math_ops_test.py
-tensorflow/tensorflow/python/ops/split_benchmark.py
-tensorflow/tensorflow/python/ops/standard_ops.py
-tensorflow/tensorflow/python/ops/state_grad.py
-tensorflow/tensorflow/python/ops/state_ops.py
-tensorflow/tensorflow/python/ops/stateful_random_ops.py
-tensorflow/tensorflow/python/ops/stateless_random_ops.py
-tensorflow/tensorflow/python/ops/stochastic_cast_op.py
-tensorflow/tensorflow/python/ops/string_ops.py
-tensorflow/tensorflow/python/ops/summary_op_util.py
-tensorflow/tensorflow/python/ops/summary_ops_v2.py
-tensorflow/tensorflow/python/ops/template.py
-tensorflow/tensorflow/python/ops/tensor_array_grad.py
-tensorflow/tensorflow/python/ops/tensor_array_ops.py
-tensorflow/tensorflow/python/ops/tensor_array_ops_test.py
-tensorflow/tensorflow/python/ops/tensor_getitem_override.py
-tensorflow/tensorflow/python/ops/tensor_math_operator_overrides.py
-tensorflow/tensorflow/python/ops/tensor_math_operator_overrides_test.py
-tensorflow/tensorflow/python/ops/transpose_benchmark.py
-tensorflow/tensorflow/python/ops/unconnected_gradients.py
-tensorflow/tensorflow/python/ops/variable_scope.py
-tensorflow/tensorflow/python/ops/variable_spec_test.py
-tensorflow/tensorflow/python/ops/variable_v1.py
-tensorflow/tensorflow/python/ops/variables.py
-tensorflow/tensorflow/python/ops/weak_tensor_array_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_constant_op_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_image_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_math_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_nn_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_np_array_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_np_math_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_ops.py
-tensorflow/tensorflow/python/ops/weak_tensor_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_special_math_ops_test.py
-tensorflow/tensorflow/python/ops/weak_tensor_test_util.py
-tensorflow/tensorflow/python/ops/weights_broadcast_ops.py
-tensorflow/tensorflow/python/ops/while_loop.py
-tensorflow/tensorflow/python/ops/while_v2.py
-tensorflow/tensorflow/python/ops/while_v2_indexed_slices_rewriter.py
-tensorflow/tensorflow/python/ops/distributions/__init__.py
-tensorflow/tensorflow/python/ops/distributions/bernoulli.py
-tensorflow/tensorflow/python/ops/distributions/beta.py
-tensorflow/tensorflow/python/ops/distributions/bijector.py
-tensorflow/tensorflow/python/ops/distributions/bijector_impl.py
-tensorflow/tensorflow/python/ops/distributions/bijector_test_util.py
-tensorflow/tensorflow/python/ops/distributions/categorical.py
-tensorflow/tensorflow/python/ops/distributions/dirichlet.py
-tensorflow/tensorflow/python/ops/distributions/dirichlet_multinomial.py
-tensorflow/tensorflow/python/ops/distributions/distribution.py
-tensorflow/tensorflow/python/ops/distributions/distributions.py
-tensorflow/tensorflow/python/ops/distributions/exponential.py
-tensorflow/tensorflow/python/ops/distributions/gamma.py
-tensorflow/tensorflow/python/ops/distributions/identity_bijector.py
-tensorflow/tensorflow/python/ops/distributions/kullback_leibler.py
-tensorflow/tensorflow/python/ops/distributions/laplace.py
-tensorflow/tensorflow/python/ops/distributions/multinomial.py
-tensorflow/tensorflow/python/ops/distributions/normal.py
-tensorflow/tensorflow/python/ops/distributions/special_math.py
-tensorflow/tensorflow/python/ops/distributions/student_t.py
-tensorflow/tensorflow/python/ops/distributions/transformed_distribution.py
-tensorflow/tensorflow/python/ops/distributions/uniform.py
-tensorflow/tensorflow/python/ops/distributions/util.py
-tensorflow/tensorflow/python/ops/linalg/__init__.py
-tensorflow/tensorflow/python/ops/linalg/linalg.py
-tensorflow/tensorflow/python/ops/linalg/linalg_impl.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_addition.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_adjoint.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_block_diag.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_block_lower_triangular.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_circulant.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_composition.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_diag.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_full_matrix.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_householder.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_identity.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_inversion.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_kronecker.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_low_rank_update.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_permutation.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_test_util.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_toeplitz.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_tridiag.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_util.py
-tensorflow/tensorflow/python/ops/linalg/linear_operator_zeros.py
-tensorflow/tensorflow/python/ops/linalg/property_hint_util.py
-tensorflow/tensorflow/python/ops/linalg/slicing.py
-tensorflow/tensorflow/python/ops/linalg/sparse/__init__.py
-tensorflow/tensorflow/python/ops/linalg/sparse/conjugate_gradient.py
-tensorflow/tensorflow/python/ops/linalg/sparse/sparse.py
-tensorflow/tensorflow/python/ops/linalg/sparse/sparse_csr_matrix_grad.py
-tensorflow/tensorflow/python/ops/linalg/sparse/sparse_csr_matrix_ops.py
-tensorflow/tensorflow/python/ops/losses/__init__.py
-tensorflow/tensorflow/python/ops/losses/losses.py
-tensorflow/tensorflow/python/ops/losses/losses_impl.py
-tensorflow/tensorflow/python/ops/losses/util.py
-tensorflow/tensorflow/python/ops/losses/util_test.py
-tensorflow/tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/__init__.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_array_ops_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_arrays.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_arrays_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_config.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_dtypes_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_interop_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_logic_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_math_ops.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_math_ops_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_random.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_random_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_utils.py
-tensorflow/tensorflow/python/ops/numpy_ops/np_utils_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/integration_test/np_config_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/integration_test/public_symbol_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/integration_test/benchmarks/micro_benchmarks.py
-tensorflow/tensorflow/python/ops/numpy_ops/integration_test/benchmarks/numpy_mlp.py
-tensorflow/tensorflow/python/ops/numpy_ops/integration_test/benchmarks/tf_numpy_mlp.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/config.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/extensions.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/np_einsum_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/np_indexing_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/np_test.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/np_wrapper.py
-tensorflow/tensorflow/python/ops/numpy_ops/tests/test_util.py
-tensorflow/tensorflow/python/ops/parallel_for/__init__.py
-tensorflow/tensorflow/python/ops/parallel_for/array_test.py
-tensorflow/tensorflow/python/ops/parallel_for/control_flow_ops.py
-tensorflow/tensorflow/python/ops/parallel_for/control_flow_ops_test.py
-tensorflow/tensorflow/python/ops/parallel_for/gradients.py
-tensorflow/tensorflow/python/ops/parallel_for/gradients_test.py
-tensorflow/tensorflow/python/ops/parallel_for/math_test.py
-tensorflow/tensorflow/python/ops/parallel_for/pfor.py
-tensorflow/tensorflow/python/ops/parallel_for/pfor_test.py
-tensorflow/tensorflow/python/ops/parallel_for/test_util.py
-tensorflow/tensorflow/python/ops/parallel_for/xla_control_flow_ops_test.py
-tensorflow/tensorflow/python/ops/ragged/__init__.py
-tensorflow/tensorflow/python/ops/ragged/convert_to_tensor_or_ragged_tensor_op_test.py
-tensorflow/tensorflow/python/ops/ragged/dynamic_ragged_shape.py
-tensorflow/tensorflow/python/ops/ragged/dynamic_ragged_shape_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_array_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_autograph.py
-tensorflow/tensorflow/python/ops/ragged/ragged_batch_gather_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_batch_gather_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py
-tensorflow/tensorflow/python/ops/ragged/ragged_bincount_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_bincount_ops_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_bitcast_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_boolean_mask_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_check_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_concat_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_concat_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_config.py
-tensorflow/tensorflow/python/ops/ragged/ragged_const_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_constant_value_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_conversion_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_cross_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_dispatch.py
-tensorflow/tensorflow/python/ops/ragged/ragged_dispatch_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_dynamic_partition_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_eager_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_embedding_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_expand_dims_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_factory_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_factory_ops_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_fill_empty_rows_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_from_sparse_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_from_tensor_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_functional_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_gather_nd_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_gather_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_gather_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_getitem.py
-tensorflow/tensorflow/python/ops/ragged/ragged_getitem_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_image_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_map_flat_values_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_map_fn_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_map_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_math_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_math_ops_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_matmul_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_merge_dims_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_one_hot_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_operators.py
-tensorflow/tensorflow/python/ops/ragged/ragged_operators_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_placeholder_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_print_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_range_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_rank_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_reduce_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_resize_image_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_reverse_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_row_lengths_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_row_splits_to_segment_ids_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_segment_ids_to_row_splits_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_segment_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_size_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_split_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_squeeze_op.py
-tensorflow/tensorflow/python/ops/ragged/ragged_squeeze_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_stack_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_string_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_bounding_shape_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_shape.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_shape_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_supported_values_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_test_ops.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tensor_value.py
-tensorflow/tensorflow/python/ops/ragged/ragged_tile_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_to_sparse_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_to_tensor_op_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_util.py
-tensorflow/tensorflow/python/ops/ragged/ragged_util_test.py
-tensorflow/tensorflow/python/ops/ragged/ragged_where_op.py
-tensorflow/tensorflow/python/ops/ragged/ragged_where_op_test.py
-tensorflow/tensorflow/python/ops/ragged/row_partition.py
-tensorflow/tensorflow/python/ops/ragged/row_partition_test.py
-tensorflow/tensorflow/python/ops/ragged/segment_id_ops.py
-tensorflow/tensorflow/python/ops/ragged/string_ngrams_op_test.py
-tensorflow/tensorflow/python/ops/ragged/strings_reduce_join_op_test.py
-tensorflow/tensorflow/python/ops/signal/__init__.py
-tensorflow/tensorflow/python/ops/signal/dct_ops.py
-tensorflow/tensorflow/python/ops/signal/fft_ops.py
-tensorflow/tensorflow/python/ops/signal/mel_ops.py
-tensorflow/tensorflow/python/ops/signal/mfcc_ops.py
-tensorflow/tensorflow/python/ops/signal/reconstruction_ops.py
-tensorflow/tensorflow/python/ops/signal/shape_ops.py
-tensorflow/tensorflow/python/ops/signal/signal.py
-tensorflow/tensorflow/python/ops/signal/spectral_ops.py
-tensorflow/tensorflow/python/ops/signal/util_ops.py
-tensorflow/tensorflow/python/ops/signal/window_ops.py
-tensorflow/tensorflow/python/ops/structured/__init__.py
-tensorflow/tensorflow/python/ops/structured/structured_array_ops.py
-tensorflow/tensorflow/python/ops/structured/structured_array_ops_test.py
-tensorflow/tensorflow/python/ops/structured/structured_ops.py
-tensorflow/tensorflow/python/ops/structured/structured_tensor.py
-tensorflow/tensorflow/python/ops/structured/structured_tensor_dynamic.py
-tensorflow/tensorflow/python/ops/structured/structured_tensor_slice_test.py
-tensorflow/tensorflow/python/ops/structured/structured_tensor_spec_test.py
-tensorflow/tensorflow/python/ops/structured/structured_tensor_test.py
-tensorflow/tensorflow/python/ops/v1_compat_tests/gradient_checker_test.py
-tensorflow/tensorflow/python/platform/__init__.py
-tensorflow/tensorflow/python/platform/_pywrap_cpu_feature_guard.pyi
-tensorflow/tensorflow/python/platform/_pywrap_stacktrace_handler.pyi
-tensorflow/tensorflow/python/platform/_pywrap_tf2.pyi
-tensorflow/tensorflow/python/platform/analytics.py
-tensorflow/tensorflow/python/platform/app.py
-tensorflow/tensorflow/python/platform/app_test.py
-tensorflow/tensorflow/python/platform/benchmark.py
-tensorflow/tensorflow/python/platform/benchmark_test.py
-tensorflow/tensorflow/python/platform/build_info_test.py
-tensorflow/tensorflow/python/platform/control_imports.py
-tensorflow/tensorflow/python/platform/device_context.py
-tensorflow/tensorflow/python/platform/flags.py
-tensorflow/tensorflow/python/platform/flags_test.py
-tensorflow/tensorflow/python/platform/gfile.py
-tensorflow/tensorflow/python/platform/googletest.py
-tensorflow/tensorflow/python/platform/logging_test.py
-tensorflow/tensorflow/python/platform/parameterized.py
-tensorflow/tensorflow/python/platform/remote_utils.py
-tensorflow/tensorflow/python/platform/resource_loader.py
-tensorflow/tensorflow/python/platform/resource_loader_test.py
-tensorflow/tensorflow/python/platform/self_check.py
-tensorflow/tensorflow/python/platform/stacktrace_handler_test.py
-tensorflow/tensorflow/python/platform/sysconfig.py
-tensorflow/tensorflow/python/platform/sysconfig_test.py
-tensorflow/tensorflow/python/platform/test.py
-tensorflow/tensorflow/python/platform/tf_logging.py
-tensorflow/tensorflow/python/profiler/__init__.py
-tensorflow/tensorflow/python/profiler/model_analyzer.py
-tensorflow/tensorflow/python/profiler/model_analyzer_test.py
-tensorflow/tensorflow/python/profiler/option_builder.py
-tensorflow/tensorflow/python/profiler/pprof_profiler.py
-tensorflow/tensorflow/python/profiler/pprof_profiler_test.py
-tensorflow/tensorflow/python/profiler/profile_context.py
-tensorflow/tensorflow/python/profiler/profile_context_test.py
-tensorflow/tensorflow/python/profiler/profiler.py
-tensorflow/tensorflow/python/profiler/profiler_client.py
-tensorflow/tensorflow/python/profiler/profiler_client_test.py
-tensorflow/tensorflow/python/profiler/profiler_test.py
-tensorflow/tensorflow/python/profiler/profiler_v2.py
-tensorflow/tensorflow/python/profiler/profiler_v2_test.py
-tensorflow/tensorflow/python/profiler/profiler_wrapper_test.py
-tensorflow/tensorflow/python/profiler/tfprof_logger.py
-tensorflow/tensorflow/python/profiler/tfprof_logger_test.py
-tensorflow/tensorflow/python/profiler/trace.py
-tensorflow/tensorflow/python/profiler/integration_test/mnist_testing_utils.py
-tensorflow/tensorflow/python/profiler/integration_test/profiler_api_test.py
-tensorflow/tensorflow/python/profiler/internal/_pywrap_profiler.pyi
-tensorflow/tensorflow/python/profiler/internal/_pywrap_profiler_plugin.pyi
-tensorflow/tensorflow/python/profiler/internal/_pywrap_traceme.pyi
-tensorflow/tensorflow/python/profiler/internal/flops_registry.py
-tensorflow/tensorflow/python/profiler/internal/flops_registry_test.py
-tensorflow/tensorflow/python/profiler/internal/model_analyzer_testlib.py
-tensorflow/tensorflow/python/profiler/internal/print_model_analysis_test.py
-tensorflow/tensorflow/python/profiler/internal/run_metadata_test.py
-tensorflow/tensorflow/python/saved_model/builder.py
-tensorflow/tensorflow/python/saved_model/builder_impl.py
-tensorflow/tensorflow/python/saved_model/constants.py
-tensorflow/tensorflow/python/saved_model/fingerprinting.py
-tensorflow/tensorflow/python/saved_model/fingerprinting_test.py
-tensorflow/tensorflow/python/saved_model/fingerprinting_utils.py
-tensorflow/tensorflow/python/saved_model/function_deserialization.py
-tensorflow/tensorflow/python/saved_model/function_serialization.py
-tensorflow/tensorflow/python/saved_model/keras_injection_test.py
-tensorflow/tensorflow/python/saved_model/load.py
-tensorflow/tensorflow/python/saved_model/load_optimizer_test.py
-tensorflow/tensorflow/python/saved_model/load_options.py
-tensorflow/tensorflow/python/saved_model/load_test.py
-tensorflow/tensorflow/python/saved_model/load_v1_in_v2.py
-tensorflow/tensorflow/python/saved_model/load_v1_in_v2_test.py
-tensorflow/tensorflow/python/saved_model/loader.py
-tensorflow/tensorflow/python/saved_model/loader_impl.py
-tensorflow/tensorflow/python/saved_model/loader_test.py
-tensorflow/tensorflow/python/saved_model/main_op.py
-tensorflow/tensorflow/python/saved_model/main_op_impl.py
-tensorflow/tensorflow/python/saved_model/method_name_updater.py
-tensorflow/tensorflow/python/saved_model/method_name_updater_test.py
-tensorflow/tensorflow/python/saved_model/metrics_test.py
-tensorflow/tensorflow/python/saved_model/nested_structure_coder.py
-tensorflow/tensorflow/python/saved_model/nested_structure_coder_test.py
-tensorflow/tensorflow/python/saved_model/path_helpers.py
-tensorflow/tensorflow/python/saved_model/proto_splitter_save_test.py
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model_fingerprinting_test.py
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model_metrics_test.py
-tensorflow/tensorflow/python/saved_model/revived_types.py
-tensorflow/tensorflow/python/saved_model/revived_types_test.py
-tensorflow/tensorflow/python/saved_model/save.py
-tensorflow/tensorflow/python/saved_model/save_context.py
-tensorflow/tensorflow/python/saved_model/save_context_test.py
-tensorflow/tensorflow/python/saved_model/save_options.py
-tensorflow/tensorflow/python/saved_model/save_test.py
-tensorflow/tensorflow/python/saved_model/saved_model.py
-tensorflow/tensorflow/python/saved_model/saved_model_test.py
-tensorflow/tensorflow/python/saved_model/signature_constants.py
-tensorflow/tensorflow/python/saved_model/signature_def_utils.py
-tensorflow/tensorflow/python/saved_model/signature_def_utils_impl.py
-tensorflow/tensorflow/python/saved_model/signature_def_utils_test.py
-tensorflow/tensorflow/python/saved_model/signature_serialization.py
-tensorflow/tensorflow/python/saved_model/simple_save.py
-tensorflow/tensorflow/python/saved_model/simple_save_test.py
-tensorflow/tensorflow/python/saved_model/tag_constants.py
-tensorflow/tensorflow/python/saved_model/tracing_utils.py
-tensorflow/tensorflow/python/saved_model/tracing_utils_test.py
-tensorflow/tensorflow/python/saved_model/utils.py
-tensorflow/tensorflow/python/saved_model/utils_impl.py
-tensorflow/tensorflow/python/saved_model/utils_test.py
-tensorflow/tensorflow/python/saved_model/model_utils/__init__.py
-tensorflow/tensorflow/python/saved_model/model_utils/export_output.py
-tensorflow/tensorflow/python/saved_model/model_utils/export_output_test.py
-tensorflow/tensorflow/python/saved_model/model_utils/export_test.py
-tensorflow/tensorflow/python/saved_model/model_utils/export_utils.py
-tensorflow/tensorflow/python/saved_model/model_utils/mode_keys.py
-tensorflow/tensorflow/python/saved_model/model_utils/mode_keys_test.py
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model/__init__.pyi
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model/constants.pyi
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model/fingerprinting.pyi
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model/merger.pyi
-tensorflow/tensorflow/python/saved_model/pywrap_saved_model/metrics.pyi
-tensorflow/tensorflow/python/saved_model/registration/__init__.py
-tensorflow/tensorflow/python/saved_model/registration/registration.py
-tensorflow/tensorflow/python/saved_model/registration/registration_saving_test.py
-tensorflow/tensorflow/python/saved_model/registration/registration_test.py
-tensorflow/tensorflow/python/saved_model/registration/test_util.py
-tensorflow/tensorflow/python/saved_model/registration/tf_registration_test.py
-tensorflow/tensorflow/python/saved_model/tests/variable_wrapper_test.py
-tensorflow/tensorflow/python/summary/__init__.py
-tensorflow/tensorflow/python/summary/plugin_asset.py
-tensorflow/tensorflow/python/summary/plugin_asset_test.py
-tensorflow/tensorflow/python/summary/summary.py
-tensorflow/tensorflow/python/summary/summary_iterator.py
-tensorflow/tensorflow/python/summary/summary_iterator_test.py
-tensorflow/tensorflow/python/summary/summary_test.py
-tensorflow/tensorflow/python/summary/summary_v2_test.py
-tensorflow/tensorflow/python/summary/tb_summary.py
-tensorflow/tensorflow/python/summary/writer/event_file_writer.py
-tensorflow/tensorflow/python/summary/writer/event_file_writer_v2.py
-tensorflow/tensorflow/python/summary/writer/fake_summary_writer.py
-tensorflow/tensorflow/python/summary/writer/writer.py
-tensorflow/tensorflow/python/summary/writer/writer_cache.py
-tensorflow/tensorflow/python/summary/writer/writer_test.py
-tensorflow/tensorflow/python/tools/freeze_graph.py
-tensorflow/tensorflow/python/tools/freeze_graph_test.py
-tensorflow/tensorflow/python/tools/grpc_tpu_worker.py
-tensorflow/tensorflow/python/tools/grpc_tpu_worker_service.py
-tensorflow/tensorflow/python/tools/import_pb_to_tensorboard.py
-tensorflow/tensorflow/python/tools/inspect_checkpoint.py
-tensorflow/tensorflow/python/tools/make_aot_compile_models.py
-tensorflow/tensorflow/python/tools/module_util.py
-tensorflow/tensorflow/python/tools/optimize_for_inference.py
-tensorflow/tensorflow/python/tools/optimize_for_inference_lib.py
-tensorflow/tensorflow/python/tools/optimize_for_inference_test.py
-tensorflow/tensorflow/python/tools/print_selective_registration_header.py
-tensorflow/tensorflow/python/tools/print_selective_registration_header_test.py
-tensorflow/tensorflow/python/tools/saved_model_aot_compile.py
-tensorflow/tensorflow/python/tools/saved_model_cli.py
-tensorflow/tensorflow/python/tools/saved_model_cli_test.py
-tensorflow/tensorflow/python/tools/saved_model_utils.py
-tensorflow/tensorflow/python/tools/saved_model_utils_test.py
-tensorflow/tensorflow/python/tools/selective_registration_header_lib.py
-tensorflow/tensorflow/python/tools/strip_unused.py
-tensorflow/tensorflow/python/tools/strip_unused_lib.py
-tensorflow/tensorflow/python/tools/strip_unused_test.py
-tensorflow/tensorflow/python/tools/tf_import_time.py
-tensorflow/tensorflow/python/tools/api/generator/create_python_api.py
-tensorflow/tensorflow/python/tools/api/generator/create_python_api_test.py
-tensorflow/tensorflow/python/tools/api/generator/doc_srcs.py
-tensorflow/tensorflow/python/tools/api/generator/doc_srcs_test.py
-tensorflow/tensorflow/python/tools/api/generator/output_init_files_test.py
-tensorflow/tensorflow/python/tools/api/generator2/docstrings.py
-tensorflow/tensorflow/python/tools/api/generator2/extractor/extractor.py
-tensorflow/tensorflow/python/tools/api/generator2/extractor/extractor_test.py
-tensorflow/tensorflow/python/tools/api/generator2/extractor/main.py
-tensorflow/tensorflow/python/tools/api/generator2/generator/generator.py
-tensorflow/tensorflow/python/tools/api/generator2/generator/generator_test.py
-tensorflow/tensorflow/python/tools/api/generator2/generator/main.py
-tensorflow/tensorflow/python/tools/api/generator2/shared/exported_api.py
-tensorflow/tensorflow/python/tools/api/generator2/shared/exported_api_test.py
-tensorflow/tensorflow/python/tpu/__init__.py
-tensorflow/tensorflow/python/tpu/_pywrap_sparse_core_layout.pyi
-tensorflow/tensorflow/python/tpu/_pywrap_tpu_embedding.pyi
-tensorflow/tensorflow/python/tpu/api.py
-tensorflow/tensorflow/python/tpu/async_checkpoint.py
-tensorflow/tensorflow/python/tpu/async_checkpoint_test.py
-tensorflow/tensorflow/python/tpu/bfloat16.py
-tensorflow/tensorflow/python/tpu/bfloat16_test.py
-tensorflow/tensorflow/python/tpu/datasets.py
-tensorflow/tensorflow/python/tpu/datasets_test.py
-tensorflow/tensorflow/python/tpu/device_assignment.py
-tensorflow/tensorflow/python/tpu/feature_column.py
-tensorflow/tensorflow/python/tpu/feature_column_test.py
-tensorflow/tensorflow/python/tpu/feature_column_v2.py
-tensorflow/tensorflow/python/tpu/feature_column_v2_test.py
-tensorflow/tensorflow/python/tpu/functional.py
-tensorflow/tensorflow/python/tpu/preempted_hook.py
-tensorflow/tensorflow/python/tpu/tensor_tracer.py
-tensorflow/tensorflow/python/tpu/tensor_tracer_flags.py
-tensorflow/tensorflow/python/tpu/tensor_tracer_report.py
-tensorflow/tensorflow/python/tpu/topology.py
-tensorflow/tensorflow/python/tpu/topology_test.py
-tensorflow/tensorflow/python/tpu/tpu.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_base.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_for_serving.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_for_serving_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v1.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v2.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v2_utils.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v2_utils_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_additional_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_checkpoint_adapter.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_checkpoint_adapter_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_cpu_ops_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_test.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_utils.py
-tensorflow/tensorflow/python/tpu/tpu_embedding_v3_utils_test.py
-tensorflow/tensorflow/python/tpu/tpu_feed.py
-tensorflow/tensorflow/python/tpu/tpu_function.py
-tensorflow/tensorflow/python/tpu/tpu_hardware_feature.py
-tensorflow/tensorflow/python/tpu/tpu_infeed_test.py
-tensorflow/tensorflow/python/tpu/tpu_name_util.py
-tensorflow/tensorflow/python/tpu/tpu_optimizer.py
-tensorflow/tensorflow/python/tpu/tpu_outside_compilation_test.py
-tensorflow/tensorflow/python/tpu/tpu_replication.py
-tensorflow/tensorflow/python/tpu/tpu_sharding.py
-tensorflow/tensorflow/python/tpu/tpu_sharding_test.py
-tensorflow/tensorflow/python/tpu/tpu_strategy_util.py
-tensorflow/tensorflow/python/tpu/tpu_system_metadata.py
-tensorflow/tensorflow/python/tpu/tpu_test.py
-tensorflow/tensorflow/python/tpu/tpu_test_wrapper.py
-tensorflow/tensorflow/python/tpu/tpu_test_wrapper_test.py
-tensorflow/tensorflow/python/tpu/training_loop.py
-tensorflow/tensorflow/python/tpu/client/__init__.py
-tensorflow/tensorflow/python/tpu/client/client.py
-tensorflow/tensorflow/python/tpu/client/client_test.py
-tensorflow/tensorflow/python/tpu/client/version.py
-tensorflow/tensorflow/python/tpu/client/pip_package/setup.py
-tensorflow/tensorflow/python/tpu/experimental/__init__.py
-tensorflow/tensorflow/python/tpu/ops/tpu_ops.py
-tensorflow/tensorflow/python/tpu/ops/tpu_ordinal_selector_op.py
-tensorflow/tensorflow/python/tpu/profiler/__init__.py
-tensorflow/tensorflow/python/tpu/profiler/capture_tpu_profile.py
-tensorflow/tensorflow/python/tpu/profiler/profiler_analysis_pb2_grpc.py
-tensorflow/tensorflow/python/tpu/profiler/version.py
-tensorflow/tensorflow/python/tpu/profiler/pip_package/setup.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_base_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v1_checkpoint_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v1_correctness_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_base_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_dense_lookup_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_hd_ragged_forward_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_hd_ragged_training_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_hd_sparse_forward_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_hd_sparse_training_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_ragged_forward_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_ragged_training_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_sequence_feature_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_sparse_forward_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_correctness_sparse_training_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_enqueue_mode_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_hd_invalid_input_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_hd_valid_input_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_initialization_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_invalid_input_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_mp_strategy_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_sequence_feature_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_embedding_v2_valid_input_test.py
-tensorflow/tensorflow/python/tpu/tests/tpu_initialization_test.py
-tensorflow/tensorflow/python/trackable/__init__.py
-tensorflow/tensorflow/python/trackable/asset.py
-tensorflow/tensorflow/python/trackable/autotrackable.py
-tensorflow/tensorflow/python/trackable/autotrackable_test.py
-tensorflow/tensorflow/python/trackable/base.py
-tensorflow/tensorflow/python/trackable/base_delegate.py
-tensorflow/tensorflow/python/trackable/base_delegate_test.py
-tensorflow/tensorflow/python/trackable/base_test.py
-tensorflow/tensorflow/python/trackable/constants.py
-tensorflow/tensorflow/python/trackable/converter.py
-tensorflow/tensorflow/python/trackable/data_structures.py
-tensorflow/tensorflow/python/trackable/data_structures_test.py
-tensorflow/tensorflow/python/trackable/layer_utils.py
-tensorflow/tensorflow/python/trackable/python_state.py
-tensorflow/tensorflow/python/trackable/python_state_test.py
-tensorflow/tensorflow/python/trackable/resource.py
-tensorflow/tensorflow/python/trackable/resource_test.py
-tensorflow/tensorflow/python/trackable/trackable_utils.py
-tensorflow/tensorflow/python/trackable/trackable_utils_test.py
-tensorflow/tensorflow/python/training/__init__.py
-tensorflow/tensorflow/python/training/adadelta.py
-tensorflow/tensorflow/python/training/adadelta_test.py
-tensorflow/tensorflow/python/training/adagrad.py
-tensorflow/tensorflow/python/training/adagrad_da.py
-tensorflow/tensorflow/python/training/adagrad_da_test.py
-tensorflow/tensorflow/python/training/adagrad_test.py
-tensorflow/tensorflow/python/training/adam.py
-tensorflow/tensorflow/python/training/adam_test.py
-tensorflow/tensorflow/python/training/basic_loops.py
-tensorflow/tensorflow/python/training/basic_loops_test.py
-tensorflow/tensorflow/python/training/basic_session_run_hooks.py
-tensorflow/tensorflow/python/training/basic_session_run_hooks_test.py
-tensorflow/tensorflow/python/training/checkpoint_management.py
-tensorflow/tensorflow/python/training/checkpoint_ops.py
-tensorflow/tensorflow/python/training/checkpoint_ops_test.py
-tensorflow/tensorflow/python/training/checkpoint_utils.py
-tensorflow/tensorflow/python/training/checkpoint_utils_test.py
-tensorflow/tensorflow/python/training/coordinator.py
-tensorflow/tensorflow/python/training/coordinator_test.py
-tensorflow/tensorflow/python/training/device_setter.py
-tensorflow/tensorflow/python/training/device_setter_test.py
-tensorflow/tensorflow/python/training/evaluation.py
-tensorflow/tensorflow/python/training/evaluation_test.py
-tensorflow/tensorflow/python/training/ftrl.py
-tensorflow/tensorflow/python/training/ftrl_test.py
-tensorflow/tensorflow/python/training/gradient_descent.py
-tensorflow/tensorflow/python/training/gradient_descent_test.py
-tensorflow/tensorflow/python/training/input.py
-tensorflow/tensorflow/python/training/input_test.py
-tensorflow/tensorflow/python/training/learning_rate_decay.py
-tensorflow/tensorflow/python/training/localhost_cluster_performance_test.py
-tensorflow/tensorflow/python/training/momentum.py
-tensorflow/tensorflow/python/training/momentum_test.py
-tensorflow/tensorflow/python/training/monitored_session.py
-tensorflow/tensorflow/python/training/monitored_session_test.py
-tensorflow/tensorflow/python/training/moving_averages.py
-tensorflow/tensorflow/python/training/moving_averages_test.py
-tensorflow/tensorflow/python/training/optimizer.py
-tensorflow/tensorflow/python/training/optimizer_test.py
-tensorflow/tensorflow/python/training/proximal_adagrad.py
-tensorflow/tensorflow/python/training/proximal_adagrad_test.py
-tensorflow/tensorflow/python/training/proximal_gradient_descent.py
-tensorflow/tensorflow/python/training/proximal_gradient_descent_test.py
-tensorflow/tensorflow/python/training/py_checkpoint_reader.py
-tensorflow/tensorflow/python/training/quantize_training.py
-tensorflow/tensorflow/python/training/quantize_training_test.py
-tensorflow/tensorflow/python/training/queue_runner.py
-tensorflow/tensorflow/python/training/queue_runner_impl.py
-tensorflow/tensorflow/python/training/queue_runner_test.py
-tensorflow/tensorflow/python/training/rmsprop.py
-tensorflow/tensorflow/python/training/rmsprop_test.py
-tensorflow/tensorflow/python/training/saver.py
-tensorflow/tensorflow/python/training/saver_large_partitioned_variable_test.py
-tensorflow/tensorflow/python/training/saver_large_variable_test.py
-tensorflow/tensorflow/python/training/saver_test.py
-tensorflow/tensorflow/python/training/saver_test_utils.py
-tensorflow/tensorflow/python/training/server_lib.py
-tensorflow/tensorflow/python/training/server_lib_multiple_containers_test.py
-tensorflow/tensorflow/python/training/server_lib_same_variables_clear_container_test.py
-tensorflow/tensorflow/python/training/server_lib_same_variables_clear_test.py
-tensorflow/tensorflow/python/training/server_lib_same_variables_no_clear_test.py
-tensorflow/tensorflow/python/training/server_lib_sparse_job_test.py
-tensorflow/tensorflow/python/training/server_lib_test.py
-tensorflow/tensorflow/python/training/session_manager.py
-tensorflow/tensorflow/python/training/session_manager_test.py
-tensorflow/tensorflow/python/training/session_run_hook.py
-tensorflow/tensorflow/python/training/slot_creator.py
-tensorflow/tensorflow/python/training/slot_creator_test.py
-tensorflow/tensorflow/python/training/summary_io.py
-tensorflow/tensorflow/python/training/supervisor.py
-tensorflow/tensorflow/python/training/supervisor_test.py
-tensorflow/tensorflow/python/training/sync_replicas_optimizer.py
-tensorflow/tensorflow/python/training/sync_replicas_optimizer_test.py
-tensorflow/tensorflow/python/training/training.py
-tensorflow/tensorflow/python/training/training_ops_test.py
-tensorflow/tensorflow/python/training/training_util.py
-tensorflow/tensorflow/python/training/training_util_test.py
-tensorflow/tensorflow/python/training/warm_starting_util.py
-tensorflow/tensorflow/python/training/warm_starting_util_test.py
-tensorflow/tensorflow/python/training/experimental/loss_scale.py
-tensorflow/tensorflow/python/training/experimental/loss_scale_optimizer.py
-tensorflow/tensorflow/python/training/experimental/loss_scale_optimizer_test.py
-tensorflow/tensorflow/python/training/experimental/loss_scale_test.py
-tensorflow/tensorflow/python/training/experimental/mixed_precision.py
-tensorflow/tensorflow/python/training/experimental/mixed_precision_global_state.py
-tensorflow/tensorflow/python/training/experimental/mixed_precision_test.py
-tensorflow/tensorflow/python/training/saving/checkpoint_options.py
-tensorflow/tensorflow/python/training/saving/functional_saver.py
-tensorflow/tensorflow/python/training/saving/saveable_object.py
-tensorflow/tensorflow/python/training/saving/saveable_object_util.py
-tensorflow/tensorflow/python/training/saving/saveable_object_util_test.py
-tensorflow/tensorflow/python/training/saving/trace_saveable_util.py
-tensorflow/tensorflow/python/types/__init__.py
-tensorflow/tensorflow/python/types/core.py
-tensorflow/tensorflow/python/types/data.py
-tensorflow/tensorflow/python/types/distribute.py
-tensorflow/tensorflow/python/types/doc_typealias.py
-tensorflow/tensorflow/python/types/internal.py
-tensorflow/tensorflow/python/types/trace.py
-tensorflow/tensorflow/python/user_ops/__init__.py
-tensorflow/tensorflow/python/user_ops/user_ops.py
-tensorflow/tensorflow/python/util/__init__.py
-tensorflow/tensorflow/python/util/_function_parameter_canonicalizer_binding_for_test.pyi
-tensorflow/tensorflow/python/util/_pywrap_checkpoint_reader.pyi
-tensorflow/tensorflow/python/util/_pywrap_determinism.pyi
-tensorflow/tensorflow/python/util/_pywrap_kernel_registry.pyi
-tensorflow/tensorflow/python/util/_pywrap_nest.pyi
-tensorflow/tensorflow/python/util/_pywrap_stat_summarizer.pyi
-tensorflow/tensorflow/python/util/_pywrap_tensor_float_32_execution.pyi
-tensorflow/tensorflow/python/util/_pywrap_tfprof.pyi
-tensorflow/tensorflow/python/util/_pywrap_transform_graph.pyi
-tensorflow/tensorflow/python/util/_pywrap_util_port.pyi
-tensorflow/tensorflow/python/util/_pywrap_utils.pyi
-tensorflow/tensorflow/python/util/_tf_stack.pyi
-tensorflow/tensorflow/python/util/all_util.py
-tensorflow/tensorflow/python/util/compat.py
-tensorflow/tensorflow/python/util/compat_test.py
-tensorflow/tensorflow/python/util/custom_nest_protocol.py
-tensorflow/tensorflow/python/util/decorator_utils.py
-tensorflow/tensorflow/python/util/decorator_utils_test.py
-tensorflow/tensorflow/python/util/deprecated_module.py
-tensorflow/tensorflow/python/util/deprecated_module_new.py
-tensorflow/tensorflow/python/util/deprecation.py
-tensorflow/tensorflow/python/util/deprecation_test.py
-tensorflow/tensorflow/python/util/dispatch.py
-tensorflow/tensorflow/python/util/dispatch_test.py
-tensorflow/tensorflow/python/util/example_parser_configuration.py
-tensorflow/tensorflow/python/util/example_parser_configuration_test.py
-tensorflow/tensorflow/python/util/fast_module_type.pyi
-tensorflow/tensorflow/python/util/fast_module_type_test.py
-tensorflow/tensorflow/python/util/function_parameter_canonicalizer_test.py
-tensorflow/tensorflow/python/util/function_utils.py
-tensorflow/tensorflow/python/util/function_utils_test.py
-tensorflow/tensorflow/python/util/is_in_graph_mode.py
-tensorflow/tensorflow/python/util/keras_deps.py
-tensorflow/tensorflow/python/util/keyword_args.py
-tensorflow/tensorflow/python/util/keyword_args_test.py
-tensorflow/tensorflow/python/util/lazy_loader.py
-tensorflow/tensorflow/python/util/lazy_loader_test.py
-tensorflow/tensorflow/python/util/lock_util.py
-tensorflow/tensorflow/python/util/lock_util_test.py
-tensorflow/tensorflow/python/util/module_wrapper.py
-tensorflow/tensorflow/python/util/module_wrapper_test.py
-tensorflow/tensorflow/python/util/nest.py
-tensorflow/tensorflow/python/util/nest_test.py
-tensorflow/tensorflow/python/util/nest_util.py
-tensorflow/tensorflow/python/util/numpy_compat.py
-tensorflow/tensorflow/python/util/numpy_compat_test.py
-tensorflow/tensorflow/python/util/object_identity.py
-tensorflow/tensorflow/python/util/object_identity_test.py
-tensorflow/tensorflow/python/util/pywrap_xla_ops.pyi
-tensorflow/tensorflow/python/util/pywrap_xla_ops_test.py
-tensorflow/tensorflow/python/util/serialization.py
-tensorflow/tensorflow/python/util/serialization_test.py
-tensorflow/tensorflow/python/util/tf_contextlib.py
-tensorflow/tensorflow/python/util/tf_contextlib_test.py
-tensorflow/tensorflow/python/util/tf_decorator.py
-tensorflow/tensorflow/python/util/tf_decorator_export.py
-tensorflow/tensorflow/python/util/tf_decorator_test.py
-tensorflow/tensorflow/python/util/tf_export.py
-tensorflow/tensorflow/python/util/tf_export_test.py
-tensorflow/tensorflow/python/util/tf_inspect.py
-tensorflow/tensorflow/python/util/tf_inspect_test.py
-tensorflow/tensorflow/python/util/tf_should_use.py
-tensorflow/tensorflow/python/util/tf_should_use_test.py
-tensorflow/tensorflow/python/util/tf_stack.py
-tensorflow/tensorflow/python/util/tf_stack_test.py
-tensorflow/tensorflow/python/util/traceback_utils.py
-tensorflow/tensorflow/python/util/traceback_utils_test.py
-tensorflow/tensorflow/python/util/type_annotations.py
-tensorflow/tensorflow/python/util/type_annotations_test.py
-tensorflow/tensorflow/python/util/variable_utils.py
-tensorflow/tensorflow/python/util/variable_utils_test.py
-tensorflow/tensorflow/python/util/vlog_test.py
-tensorflow/tensorflow/python/util/protobuf/__init__.py
-tensorflow/tensorflow/python/util/protobuf/compare.py
-tensorflow/tensorflow/python/util/protobuf/compare_test.py
-tensorflow/tensorflow/security/fuzzing/abs_fuzz.py
-tensorflow/tensorflow/security/fuzzing/acos_fuzz.py
-tensorflow/tensorflow/security/fuzzing/acosh_fuzz.py
-tensorflow/tensorflow/security/fuzzing/add_fuzz.py
-tensorflow/tensorflow/security/fuzzing/constant_fuzz.py
-tensorflow/tensorflow/security/fuzzing/dataFormatVecPermute_fuzz.py
-tensorflow/tensorflow/security/fuzzing/immutableConst_fuzz.py
-tensorflow/tensorflow/security/fuzzing/python_fuzzing.py
-tensorflow/tensorflow/security/fuzzing/raggedCountSparseOutput_fuzz.py
-tensorflow/tensorflow/security/fuzzing/sparseCountSparseOutput_fuzz.py
-tensorflow/tensorflow/security/fuzzing/tf2migration_fuzz.py
-tensorflow/tensorflow/security/fuzzing/py/annotation_types.py
-tensorflow/tensorflow/tools/__init__.py
-tensorflow/tensorflow/tools/android/test/__init__.py
-tensorflow/tensorflow/tools/android/test/jni/__init__.py
-tensorflow/tensorflow/tools/api/lib/python_object_to_proto_visitor.py
-tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py
-tensorflow/tensorflow/tools/api/tests/module_test.py
-tensorflow/tensorflow/tools/benchmark/parse_onednn_benchmarks.py
-tensorflow/tensorflow/tools/build_info/gen_build_info.py
-tensorflow/tensorflow/tools/ci_build/copy_binary.py
-tensorflow/tensorflow/tools/ci_build/update_version.py
-tensorflow/tensorflow/tools/ci_build/builds/check_system_libs.py
-tensorflow/tensorflow/tools/ci_build/linux/mkl/set-build-env.py
-tensorflow/tensorflow/tools/ci_build/osx/arm64/tensorflow_metal_plugin_test.py
-tensorflow/tensorflow/tools/common/public_api.py
-tensorflow/tensorflow/tools/common/public_api_test.py
-tensorflow/tensorflow/tools/common/test_module1.py
-tensorflow/tensorflow/tools/common/test_module2.py
-tensorflow/tensorflow/tools/common/traverse.py
-tensorflow/tensorflow/tools/common/traverse_test.py
-tensorflow/tensorflow/tools/compatibility/all_renames_v2.py
-tensorflow/tensorflow/tools/compatibility/all_renames_v2_test.py
-tensorflow/tensorflow/tools/compatibility/ast_edits.py
-tensorflow/tensorflow/tools/compatibility/ast_edits_test.py
-tensorflow/tensorflow/tools/compatibility/ipynb.py
-tensorflow/tensorflow/tools/compatibility/module_deprecations_v2.py
-tensorflow/tensorflow/tools/compatibility/renames_v2.py
-tensorflow/tensorflow/tools/compatibility/reorders_v2.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_test.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_v2.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_v2_main.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_v2_safety.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_v2_safety_test.py
-tensorflow/tensorflow/tools/compatibility/tf_upgrade_v2_test.py
-tensorflow/tensorflow/tools/compatibility/testdata/test_file_v0_11.py
-tensorflow/tensorflow/tools/compatibility/testdata/test_file_v1_12.py
-tensorflow/tensorflow/tools/compatibility/update/generate_v2_renames_map.py
-tensorflow/tensorflow/tools/compatibility/update/generate_v2_reorders_map.py
-tensorflow/tensorflow/tools/docs/base_dir.py
-tensorflow/tensorflow/tools/docs/build_cc_api_headers.py
-tensorflow/tensorflow/tools/docs/build_java_api_docs.py
-tensorflow/tensorflow/tools/docs/doc_controls.py
-tensorflow/tensorflow/tools/docs/fenced_doctest_lib.py
-tensorflow/tensorflow/tools/docs/fenced_doctest_test.py
-tensorflow/tensorflow/tools/docs/generate2.py
-tensorflow/tensorflow/tools/docs/generate2_test.py
-tensorflow/tensorflow/tools/docs/tf_doctest.py
-tensorflow/tensorflow/tools/docs/tf_doctest_lib.py
-tensorflow/tensorflow/tools/docs/tf_doctest_test.py
-tensorflow/tensorflow/tools/gcs_test/python/gcs_smoke.py
-tensorflow/tensorflow/tools/git/gen_git_source.py
-tensorflow/tensorflow/tools/graph_transforms/__init__.py
-tensorflow/tensorflow/tools/graph_transforms/python/transform_graph_test.py
-tensorflow/tensorflow/tools/pip_package/build_pip_package.py
-tensorflow/tensorflow/tools/pip_package/check_load_py_test.py
-tensorflow/tensorflow/tools/pip_package/import_api_packages_test.py
-tensorflow/tensorflow/tools/pip_package/pip_smoke_test.py
-tensorflow/tensorflow/tools/pip_package/setup.py
-tensorflow/tensorflow/tools/pip_package/simple_console.py
-tensorflow/tensorflow/tools/pip_package/simple_console_for_windows.py
-tensorflow/tensorflow/tools/pip_package/redundant_tensorflow_gpu/setup.py
-tensorflow/tensorflow/tools/pip_package/redundant_tf_nightly_gpu/setup.py
-tensorflow/tensorflow/tools/pip_package/utils/utils.py
-tensorflow/tensorflow/tools/proto_splitter/constants.py
-tensorflow/tensorflow/tools/proto_splitter/split.py
-tensorflow/tensorflow/tools/proto_splitter/split_graph_def.py
-tensorflow/tensorflow/tools/proto_splitter/split_graph_def_test.py
-tensorflow/tensorflow/tools/proto_splitter/split_test.py
-tensorflow/tensorflow/tools/proto_splitter/util.py
-tensorflow/tensorflow/tools/proto_splitter/util_test.py
-tensorflow/tensorflow/tools/proto_splitter/version.py
-tensorflow/tensorflow/tools/proto_splitter/python/saved_model.py
-tensorflow/tensorflow/tools/proto_splitter/python/saved_model_test.py
-tensorflow/tensorflow/tools/proto_splitter/python/test_util.py
-tensorflow/tensorflow/tools/proto_splitter/python/test_util_test.py
-tensorflow/tensorflow/tools/proto_splitter/testdata/many_field_gen.py
-tensorflow/tensorflow/tools/proto_splitter/testdata/split_gen.py
-tensorflow/tensorflow/tools/proto_splitter/testdata/split_graph_def_gen.py
-tensorflow/tensorflow/tools/proto_splitter/testdata/split_saved_model_gen.py
-tensorflow/tensorflow/tools/tensorflow_builder/compat_checker/compat_checker.py
-tensorflow/tensorflow/tools/tensorflow_builder/compat_checker/compat_checker_test.py
-tensorflow/tensorflow/tools/tensorflow_builder/config_detector/config_detector.py
-tensorflow/tensorflow/tools/tensorflow_builder/config_detector/data/__init__.py
-tensorflow/tensorflow/tools/tensorflow_builder/config_detector/data/cuda_compute_capability.py
-tensorflow/tensorflow/tools/test/__init__.py
-tensorflow/tensorflow/tools/test/file_name_test.py
-tensorflow/tensorflow/tools/test/gpu_info_lib.py
-tensorflow/tensorflow/tools/test/run_and_gather_logs.py
-tensorflow/tensorflow/tools/test/run_and_gather_logs_lib.py
-tensorflow/tensorflow/tools/test/system_info.py
-tensorflow/tensorflow/tools/test/system_info_lib.py
-tensorflow/tensorflow/tools/test/upload_test_benchmarks.py
-tensorflow/third_party/__init__.py
-tensorflow/third_party/gpus/check_cuda_libs.py
-tensorflow/third_party/gpus/find_cuda_config.py
-tensorflow/third_party/gpus/find_rocm_config.py
-tensorflow/third_party/gpus/find_sycl_config.py
-tensorflow/third_party/implib_so/get_symbols.py
-tensorflow/third_party/implib_so/make_stub.py
-tensorflow/third_party/llvm_openmp/expand_cmake_vars.py
-tensorflow/third_party/xla/build_tools/test_utils.py
-tensorflow/third_party/xla/build_tools/ci/build.py
-tensorflow/third_party/xla/build_tools/configure/configure.py
-tensorflow/third_party/xla/build_tools/configure/configure_test.py
-tensorflow/third_party/xla/build_tools/lint/__init__.py
-tensorflow/third_party/xla/build_tools/lint/check_contents.py
-tensorflow/third_party/xla/build_tools/lint/check_contents_test.py
-tensorflow/third_party/xla/build_tools/lint/diff_parser.py
-tensorflow/third_party/xla/build_tools/lint/diff_parser_test.py
-tensorflow/third_party/xla/build_tools/lint/generate_compile_commands.py
-tensorflow/third_party/xla/build_tools/lint/generate_compile_commands_test.py
-tensorflow/third_party/xla/build_tools/lint/tags.py
-tensorflow/third_party/xla/third_party/__init__.py
-tensorflow/third_party/xla/third_party/implib_so/get_symbols.py
-tensorflow/third_party/xla/third_party/implib_so/make_stub.py
-tensorflow/third_party/xla/third_party/llvm_openmp/expand_cmake_vars.py
-tensorflow/third_party/xla/third_party/tsl/third_party/__init__.py
-tensorflow/third_party/xla/third_party/tsl/third_party/gpus/check_cuda_libs.py
-tensorflow/third_party/xla/third_party/tsl/third_party/gpus/find_cuda_config.py
-tensorflow/third_party/xla/third_party/tsl/third_party/gpus/find_rocm_config.py
-tensorflow/third_party/xla/third_party/tsl/third_party/gpus/find_sycl_config.py
-tensorflow/third_party/xla/third_party/tsl/third_party/implib_so/get_symbols.py
-tensorflow/third_party/xla/third_party/tsl/third_party/implib_so/make_stub.py
-tensorflow/third_party/xla/third_party/tsl/third_party/llvm_openmp/expand_cmake_vars.py
-tensorflow/third_party/xla/third_party/tsl/third_party/py/manylinux_compliance_test.py
-tensorflow/third_party/xla/xla/lit.cfg.py
-tensorflow/third_party/xla/xla/backends/cpu/benchmarks/e2e/gemma2/flax_2b/benchmark.py
-tensorflow/third_party/xla/xla/backends/cpu/benchmarks/e2e/gemma2/keras/benchmark.py
-tensorflow/third_party/xla/xla/backends/cpu/codegen/dot_kernel_emitter_test.py
-tensorflow/third_party/xla/xla/backends/cpu/codegen/elemental/concatenate_kernel_emitter_test.py
-tensorflow/third_party/xla/xla/backends/cpu/testlib/__init__.py
-tensorflow/third_party/xla/xla/backends/cpu/testlib/elemental_kernel_emitter_test.py
-tensorflow/third_party/xla/xla/backends/cpu/testlib/kernel_runner_test.py
-tensorflow/third_party/xla/xla/backends/cpu/testlib/utilities.py
-tensorflow/third_party/xla/xla/backends/gpu/codegen/tools/ncu_rep.py
-tensorflow/third_party/xla/xla/backends/gpu/codegen/tools/ncu_rep_lib.py
-tensorflow/third_party/xla/xla/backends/gpu/codegen/tools/ncu_rep_test.py
-tensorflow/third_party/xla/xla/codegen/testlib/__init__.py
-tensorflow/third_party/xla/xla/codegen/testlib/kernel_runner_test.py
-tensorflow/third_party/xla/xla/codegen/testlib/utilities.py
-tensorflow/third_party/xla/xla/hlo/builder/lib/generate_math_impl.py
-tensorflow/third_party/xla/xla/mlir_hlo/bindings/python/mlir/dialects/mhlo.py
-tensorflow/third_party/xla/xla/mlir_hlo/tests/lit.cfg.py
-tensorflow/third_party/xla/xla/mlir_hlo/tests/python/attributes.py
-tensorflow/third_party/xla/xla/mlir_hlo/tests/python/smoketest.py
-tensorflow/third_party/xla/xla/mlir_hlo/tests/python/types.py
-tensorflow/third_party/xla/xla/python/__init__.py
-tensorflow/third_party/xla/xla/python/config_test.py
-tensorflow/third_party/xla/xla/python/jax_jit_test.py
-tensorflow/third_party/xla/xla/python/pytree_test.py
-tensorflow/third_party/xla/xla/python/status_casters_test.py
-tensorflow/third_party/xla/xla/python/weakref_lru_cache_test.py
-tensorflow/third_party/xla/xla/python/xla_client.py
-tensorflow/third_party/xla/xla/python/xla_client.pyi
-tensorflow/third_party/xla/xla/python/xla_client_backend_independent_test.py
-tensorflow/third_party/xla/xla/python/xla_client_test.py
-tensorflow/third_party/xla/xla/python/xla_compiler_test.py
-tensorflow/third_party/xla/xla/python/ifrt_proxy/jax/ifrt_proxy_internal.py
-tensorflow/third_party/xla/xla/python/profiler/profile_data.pyi
-tensorflow/third_party/xla/xla/python/profiler/profile_data_test.py
-tensorflow/third_party/xla/xla/python/tools/__init__.py
-tensorflow/third_party/xla/xla/python/tools/_types.pyi
-tensorflow/third_party/xla/xla/python/tools/types.py
-tensorflow/third_party/xla/xla/python/tools/types_test.py
-tensorflow/third_party/xla/xla/python/xla_extension/__init__.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/config.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/guard_lib.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/ifrt_programs.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/ifrt_proxy.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/jax_jit.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/mlir.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/ops.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/pmap_lib.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/profiler.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/pytree.pyi
-tensorflow/third_party/xla/xla/python/xla_extension/transfer_guard_lib.pyi
-tensorflow/third_party/xla/xla/python_api/types_.py
-tensorflow/third_party/xla/xla/python_api/xla_literal.py
-tensorflow/third_party/xla/xla/python_api/xla_literal_test.py
-tensorflow/third_party/xla/xla/python_api/xla_shape.py
-tensorflow/third_party/xla/xla/python_api/xla_shape_test.py
-tensorflow/third_party/xla/xla/service/algebraic_simplifier_proof_distributive_property.py
-tensorflow/third_party/xla/xla/service/generate_test_hlo_checks.py
-tensorflow/third_party/xla/xla/service/generate_test_hlo_checks_test.py
-tensorflow/third_party/xla/xla/tests/generate_complex_unary_op_samples.py
-tests/__init__.py
-tests/old_test_tf_helper.py
-tests/refactoring_todo
-tests/test_dataloader.ipynb
-tests/test_generate_data.py
-tests/test_generic_loader.py
-tests/test_grid_sample.ipynb
-tests/test_misc.py
-tests/test_model.ipynb
-tests/test_model_manager.py
-tests/test_projective_warp_xla.py
-tests/test_pt_tf_model_consistency.ipynb
-tests/test_ptychotorch_model.ipynb
-tests/test_ptychotorch_train.ipynb
-tests/test_pytorch.ipynb
-tests/test_pytorch_replicability.ipynb
-tests/test_pytorch_tf_wrapper.py
-tests/test_scratch.ipynb
-tests/test_simulate_and_save.py
-tests/test_simulate_and_save_simple.py
-tests/test_tf_helper.py
-tests/test_tf_helper_edge_aware.py
-tests/test_tf_model.ipynb
-tests/test_wrapper.ipynb
-tests/image/__init__.py
-tests/image/test_cropping.py
-tests/image/test_registration.py
-tests/workflows/__init__.py
-torch/tf_helper.py
-torch/tests/test_tf_helper.py
-torch/tests/tf_helper.py
\ No newline at end of file
diff --git a/ptychopinn.egg-info/dependency_links.txt b/ptychopinn.egg-info/dependency_links.txt
deleted file mode 100644
index 8b13789..0000000
--- a/ptychopinn.egg-info/dependency_links.txt
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/ptychopinn.egg-info/entry_points.txt b/ptychopinn.egg-info/entry_points.txt
deleted file mode 100644
index 5564204..0000000
--- a/ptychopinn.egg-info/entry_points.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-[console_scripts]
-ptycho_inference = scripts.inference.inference:main
-ptycho_train = scripts.training.train:main
diff --git a/ptychopinn.egg-info/not-zip-safe b/ptychopinn.egg-info/not-zip-safe
deleted file mode 100644
index 8b13789..0000000
--- a/ptychopinn.egg-info/not-zip-safe
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/ptychopinn.egg-info/requires.txt b/ptychopinn.egg-info/requires.txt
deleted file mode 100644
index fd1c58c..0000000
--- a/ptychopinn.egg-info/requires.txt
+++ /dev/null
@@ -1,23 +0,0 @@
-Pillow
-dill
-imageio
-ipywidgets
-jupyter
-matplotlib
-numba
-numpy
-opencv-python
-pandas
-pandas-datareader
-pathos
-scikit-image
-scikit-learn
-scipy
-tensorflow[and-cuda]>=2.13.0
-tensorflow-datasets
-tensorflow-hub
-tensorflow-metadata
-tensorflow-probability
-torch
-tqdm
-ujson
diff --git a/ptychopinn.egg-info/top_level.txt b/ptychopinn.egg-info/top_level.txt
deleted file mode 100644
index cebba3f..0000000
--- a/ptychopinn.egg-info/top_level.txt
+++ /dev/null
@@ -1,33 +0,0 @@
-PlotNeuralNet
-PtychoNN
-archive
-build
-configs
-data
-datasets
-diagram
-docs
-fly64_pinn_gridsize2_final
-fly64_pinn_gridsize2_final_jit
-inference_output
-loaders
-memoized_data
-newnew
-notebooks
-ptycho
-ptycho_torch
-scripts
-tensorflow
-test_3way_fix_complete
-test_3way_fix_complete_2
-test_custom_layers_model
-test_fast_impl
-test_model_for_inference
-test_no_xla_model
-test_xla_50imgs
-test_xla_enabled_50imgs
-tests
-torch
-trained_model
-training_outputs
-verification_test
```

## Summary of Final Phase Changes

The Final Phase successfully completed all deprecation, documentation, and cleanup tasks:

1. **Deprecation Implementation**
   - Added proper DeprecationWarning to RawData.from_simulation method
   - Documented legacy usage in other files (nongrid_simulation.py, simulate_full_frame.py)

2. **Documentation Updates**
   - Updated scripts/simulation/CLAUDE.md with new architecture notes
   - Enhanced scripts/simulation/README.md with GridSize support and migration guide
   - Updated docs/TOOL_SELECTION_GUIDE.md to highlight gridsize > 1 support
   - Updated docs/PROJECT_STATUS.md to mark initiative as complete

3. **Success Criteria Verification**
   - Verified no crashes with gridsize=1,2
   - Confirmed data contract compliance
   - Performance benchmarks acceptable (~11s for 1000 images)

4. **Code Quality**
   - Added version comments to refactored code
   - Ensured proper error messages
   - Created comprehensive implementation summary

All tasks from phase_final_checklist.md are marked as [D] (Done).
EOF < /dev/null
