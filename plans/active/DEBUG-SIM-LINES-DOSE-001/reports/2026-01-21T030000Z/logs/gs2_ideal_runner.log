2026-01-21 12:46:41.415365: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1769028401.426154 2055861 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1769028401.429733 2055861 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1769028401.439359 2055861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769028401.439368 2055861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769028401.439370 2055861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1769028401.439371 2055861 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-21 12:46:41.442073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1769028404.274983 2055861 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1769028404.276216 2055861 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1769028405.037576 2055861 service.cc:152] XLA service 0x21647fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1769028405.037598 2055861 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-21 12:46:45.057302: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1769028405.075580 2055861 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1769028405.229398 2055861 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[runner][profile] Applied stable_profile_gs2_ideal: {'base_total_images': 256, 'neighbor_count': 4, 'group_count': 128, 'batch_size': 4}
[runner] Scenario=gs2_ideal gridsize=2 probe_mode=idealized probe_scale=10.0
[runner] total_images=1024 train_count=512 test_count=512 group_count=128 nepochs=5
DEBUG: Setting data_source to lines in params
DEBUG: Setting data_source to generic in params
diff3d shape: (1024, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (1024,)
objectGuess shape: (392, 392)
xcoords shape: (1024,)
ycoords shape: (1024,)
xcoords_start shape: (1024,)
ycoords_start shape: (1024,)
diff3d shape: (512, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (512,)
objectGuess shape: (392, 392)
xcoords shape: (512,)
ycoords shape: (512,)
xcoords_start shape: (512,)
ycoords_start shape: (512,)
diff3d shape: (512, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (512,)
objectGuess shape: (392, 392)
xcoords shape: (512,)
ycoords shape: (512,)
xcoords_start shape: (512,)
ycoords_start shape: (512,)
[runner][D5] Train dataset scale: 543.2838 (batch_mean=3388.02, n=512)
[runner][D5] Test dataset scale: 577.7380 (batch_mean=2995.97, n=512)
[runner][D5] Train/test scale ratio: 0.9404 (deviation: 5.96%) [âš ï¸ EXCEEDS 5%]
DEBUG: nsamples: 128, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (128, 64, 64, 4)
loader: computed raw diffraction stats: batch_mean_sum_intensity=13383.235771, n_samples=128
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 4) mean=0.085 Y_I=(128, 64, 64, 4) mean=2.672 Y_phi=(128, 64, 64, 4) mean=0.000 coords_nominal=(128, 1, 2, 4) mean=-0.000 coords_true=(128, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(128, 4) global_offsets=(128, 1, 2, 1) local_offsets=(128, 1, 2, 4)>
DEBUG: nsamples: 128, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (128, 64, 64, 4)
loader: computed raw diffraction stats: batch_mean_sum_intensity=12256.886218, n_samples=128
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 4) mean=0.085 Y_I=(128, 64, 64, 4) mean=2.588 Y_phi=(128, 64, 64, 4) mean=0.000 coords_nominal=(128, 1, 2, 4) mean=0.000 coords_true=(128, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(128, 4) global_offsets=(128, 1, 2, 1) local_offsets=(128, 1, 2, 4)>
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
calculate_intensity_scale: using dataset_intensity_stats (batch_mean=13383.235771) -> scale=273.350225
DEBUG: Setting intensity_scale to 273.3502248877305 in params
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
backend: tensorflow
batch_size: 4
bigN: 68
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
enable_oversampling: False
gaussian_smoothing_sigma: 0.0
gridsize: 2
h5_path: wts.h5
intensity_scale: 273.3502248877305
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 754
model_type: pinn
n_filters_scale: 2
n_groups: 128
neighbor_count: 4
nepochs: 5
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-21T030000Z/gs2_ideal/train_outputs
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.100+0.000j
  std: 0.296
  min: 0.000+0.000j
  max: 1.089+0.000j
probe.big: False
probe.mask: True
probe.trainable: False
probe_scale: 10.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from global params: 64
DEBUG _flat_to_channel: input shape=(512, 64, 64, 1), reshaping to (-1, 4, 64, 64)
Epoch 1/5
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:33[0m 5s/step - intensity_scaler_inv_loss: 17.5622 - loss: -262289.3125 - pred_intensity_loss: -262289.3125 - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 48ms/step - intensity_scaler_inv_loss: 16.8183 - loss: -261246.2500 - pred_intensity_loss: -261246.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 15.8268 - loss: -254833.8906 - pred_intensity_loss: -254833.8906 - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 15.0958 - loss: -253299.4375 - pred_intensity_loss: -253299.4375 - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 14.6186 - loss: -250653.8594 - pred_intensity_loss: -250653.8594 - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: 14.4148 - loss: -249461.1719 - pred_intensity_loss: -249461.1719 - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.3124 - loss: -249092.8438 - pred_intensity_loss: -249092.8438 - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.2415 - loss: -248626.2188 - pred_intensity_loss: -248626.2188 - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.2003 - loss: -248031.8125 - pred_intensity_loss: -248031.8125 - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.1532 - loss: -247376.4688 - pred_intensity_loss: -247376.4688 - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.1133 - loss: -246853.0156 - pred_intensity_loss: -246853.0156 - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.0903 - loss: -246687.9531 - pred_intensity_loss: -246687.9531 - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.0695 - loss: -246561.7656 - pred_intensity_loss: -246561.7656 - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 14.0353 - loss: -246433.2812 - pred_intensity_loss: -246433.2812 - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: 13.9950 - loss: -246307.2031 - pred_intensity_loss: -246307.2031 - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step - intensity_scaler_inv_loss: 13.9536 - loss: -246312.7188 - pred_intensity_loss: -246322.5312 - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 113ms/step - intensity_scaler_inv_loss: 13.3366 - loss: -246444.9844 - pred_intensity_loss: -246748.8594 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 11.0453 - val_loss: -282911.8125 - val_pred_intensity_loss: -275799.0938 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 64ms/step - intensity_scaler_inv_loss: 16.6502 - loss: -197331.0938 - pred_intensity_loss: -197331.0938 - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 15.0526 - loss: -222934.9062 - pred_intensity_loss: -222934.9062 - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 14.5165 - loss: -230241.6250 - pred_intensity_loss: -230241.6250 - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 14.4758 - loss: -234823.1875 - pred_intensity_loss: -234823.1875 - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00                      [1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 63ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 63ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (128, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(128, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 1s/step[1m3/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 30ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 38ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 43ms/step
Object stitching failed: cannot reshape array of size 524288 into shape (6,6,64,64,1)
cannot reshape array of size 524288 into shape (6,6,64,64,1)
[runner] Training complete in 22.13s; bundle saved to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-21T030000Z/gs2_ideal/train_outputs
[runner][scaler] exp(log_scale)=273.35026999353613 vs params.cfg=273.3502248877305 (delta=4.510580561145616e-05)
[runner][history][warn] Metric 'intensity_scaler_inv_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'pred_intensity_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'val_intensity_scaler_inv_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'val_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'val_pred_intensity_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] Metric 'train_loss' reported NaN/inf at step 1 (epoch 1.0)
[runner][history][warn] NaN/inf detected in metrics: intensity_scaler_inv_loss, loss, pred_intensity_loss, train_loss, val_intensity_scaler_inv_loss, val_loss, val_pred_intensity_loss
[runner][scale] dataset_scale=577.738050 vs fallback=988.211769 (ratio=0.584630)
DEBUG: nsamples: 64, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (64, 64, 64, 4)
loader: computed raw diffraction stats: batch_mean_sum_intensity=12285.223214, n_samples=64
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(64, 64, 64, 4) mean=0.085 Y_I=(64, 64, 64, 4) mean=2.587 Y_phi=(64, 64, 64, 4) mean=0.000 coords_nominal=(64, 1, 2, 4) mean=-0.000 coords_true=(64, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(64, 4) global_offsets=(64, 1, 2, 1) local_offsets=(64, 1, 2, 4)>
[runner][D5b] external_intensity_scale=273.350281
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
[1m1/2[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2s/step[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 17ms/step
[runner][D5b] obj_mean=nan, input_mean=0.085087
[runner][D5b] amplification_ratio (obj_mean / input_mean) = nan
[runner][D5b] model_exp_log_scale=273.350270 vs external=273.350281 (match=100.00%) âœ“ OK
[runner][D5b] ground_truth_mean=2.708247, output_vs_truth_ratio=nan
[runner] Inference complete; stats saved to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-21T030000Z/gs2_ideal/inference_outputs/stats.json
[runner] Outputs written to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-21T030000Z/gs2_ideal
