2026-01-20 15:24:40.647408: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1768951480.658275 1667154 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1768951480.661831 1667154 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1768951480.672753 1667154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768951480.672763 1667154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768951480.672764 1667154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1768951480.672765 1667154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-01-20 15:24:40.675608: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1768951483.482536 1667154 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1768951483.483761 1667154 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1768951484.250469 1667154 service.cc:152] XLA service 0x1ff998d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1768951484.250489 1667154 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2026-01-20 15:24:44.270165: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1768951484.289561 1667154 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1768951484.446688 1667154 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[runner][profile] Applied stable_profile_gs2_ideal: {'base_total_images': 256, 'neighbor_count': 4, 'group_count': 128, 'batch_size': 4}
[runner] Scenario=gs2_ideal gridsize=2 probe_mode=idealized probe_scale=10.0
[runner] total_images=1024 train_count=512 test_count=512 group_count=128 nepochs=5
DEBUG: Setting data_source to lines in params
DEBUG: Setting data_source to generic in params
diff3d shape: (1024, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (1024,)
objectGuess shape: (392, 392)
xcoords shape: (1024,)
ycoords shape: (1024,)
xcoords_start shape: (1024,)
ycoords_start shape: (1024,)
diff3d shape: (512, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (512,)
objectGuess shape: (392, 392)
xcoords shape: (512,)
ycoords shape: (512,)
xcoords_start shape: (512,)
ycoords_start shape: (512,)
diff3d shape: (512, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (512,)
objectGuess shape: (392, 392)
xcoords shape: (512,)
ycoords shape: (512,)
xcoords_start shape: (512,)
ycoords_start shape: (512,)
DEBUG: nsamples: 128, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (128, 64, 64, 4)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 4) mean=0.085 Y_I=(128, 64, 64, 4) mean=2.672 Y_phi=(128, 64, 64, 4) mean=0.000 coords_nominal=(128, 1, 2, 4) mean=-0.000 coords_true=(128, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(128, 4) global_offsets=(128, 1, 2, 1) local_offsets=(128, 1, 2, 4)>
DEBUG: nsamples: 128, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (128, 64, 64, 4)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 4) mean=0.085 Y_I=(128, 64, 64, 4) mean=2.588 Y_phi=(128, 64, 64, 4) mean=0.000 coords_nominal=(128, 1, 2, 4) mean=0.000 coords_true=(128, 1, 2, 4) mean=0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(128, 4) global_offsets=(128, 1, 2, 1) local_offsets=(128, 1, 2, 4)>
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 988.21173 in params
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
backend: tensorflow
batch_size: 4
bigN: 68
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
enable_oversampling: False
gaussian_smoothing_sigma: 0.0
gridsize: 2
h5_path: wts.h5
intensity_scale: 988.2117309570312
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 754
model_type: pinn
n_filters_scale: 2
n_groups: 128
neighbor_count: 4
nepochs: 5
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T231745Z/gs2_ideal/train_outputs
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: 0.100+0.000j
  std: 0.296
  min: 0.000+0.000j
  max: 1.089+0.000j
probe.big: False
probe.mask: True
probe.trainable: False
probe_scale: 10.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
torch_loss_mode: poisson
tv_weight: 0.0
use_xla_translate: True
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from global params: 64
DEBUG _flat_to_channel: input shape=(512, 64, 64, 1), reshaping to (-1, 4, 64, 64)
Epoch 1/5
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2:34[0m 5s/step - intensity_scaler_inv_loss: 55.2620 - loss: -3432474.0000 - pred_intensity_loss: -3432474.0000 - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 55.0291 - loss: -3609902.2500 - pred_intensity_loss: -3609902.2500 - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 53.8471 - loss: -3634360.2500 - pred_intensity_loss: -3634360.2500 - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 53.0405 - loss: -3661983.7500 - pred_intensity_loss: -3661983.7500 - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: 52.5375 - loss: -3696527.5000 - pred_intensity_loss: -3696527.5000 - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: 52.0517 - loss: -3719272.0000 - pred_intensity_loss: -3719272.0000 - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00                        [1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 79ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(None, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (None, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(None, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 114ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 63ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 62ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 45ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/5
[1m 1/31[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 62ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 3/31[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 5/31[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 7/31[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m 9/31[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m11/31[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m13/31[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m15/31[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m17/31[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m19/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m21/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m23/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m25/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m27/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m29/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 47ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 46ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00[1m31/31[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 48ms/step - intensity_scaler_inv_loss: nan - loss: nan - pred_intensity_loss: nan - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: nan - val_loss: nan - val_pred_intensity_loss: nan - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 ...

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]

 [[1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  ...
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]
  [1.0893617e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
input shape (128, 64, 64, 1)
DEBUG _flat_to_channel: gridsize from parameter: 2
DEBUG _flat_to_channel: N from parameter: 64
DEBUG _flat_to_channel: input shape=(128, 64, 64, 1), reshaping to (-1, 4, 64, 64)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3s[0m 1s/step[1m3/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 30ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 39ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 43ms/step
/home/ollie/Documents/tmp/PtychoPINN/plans/active/DEBUG-SIM-LINES-DOSE-001/bin/run_phase_c2_scenario.py:1087: RuntimeWarning: All-NaN slice encountered
  min_val = float(np.nanmin(arr))
/home/ollie/Documents/tmp/PtychoPINN/plans/active/DEBUG-SIM-LINES-DOSE-001/bin/run_phase_c2_scenario.py:1091: RuntimeWarning: All-NaN slice encountered
  max_val = float(np.nanmax(arr))
Object stitching failed: cannot reshape array of size 524288 into shape (6,6,64,64,1)
cannot reshape array of size 524288 into shape (6,6,64,64,1)
[runner] Training complete in 22.17s; bundle saved to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T231745Z/gs2_ideal/train_outputs
[runner][scaler] exp(log_scale)=988.2116659768321 vs params.cfg=988.2117309570312 (delta=-6.498019911305164e-05)
[runner][history][warn] Metric 'intensity_scaler_inv_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'pred_intensity_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'val_intensity_scaler_inv_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'val_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'val_pred_intensity_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] Metric 'train_loss' reported NaN/inf at step 0 (epoch 0.0)
[runner][history][warn] NaN/inf detected in metrics: intensity_scaler_inv_loss, loss, pred_intensity_loss, train_loss, val_intensity_scaler_inv_loss, val_loss, val_pred_intensity_loss
[runner][scale] dataset_scale=577.738050 vs fallback=988.211769 (ratio=0.584630)
DEBUG: nsamples: 64, gridsize: 2 (using efficient random sample-then-group strategy)
INFO: 'Y' array not found. Generating ground truth patches from 'objectGuess' as a fallback.
neighbor-sampled diffraction shape (64, 64, 64, 4)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(64, 64, 64, 4) mean=0.085 Y_I=(64, 64, 64, 4) mean=2.587 Y_phi=(64, 64, 64, 4) mean=0.000 coords_nominal=(64, 1, 2, 4) mean=-0.000 coords_true=(64, 1, 2, 4) mean=-0.000 probe=(64, 64) mean_amplitude=0.100 norm_Y_I=<scalar> nn_indices=(64, 4) global_offsets=(64, 1, 2, 1) local_offsets=(64, 1, 2, 4)>
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
DEBUG _flat_to_channel: gridsize from global params: 2
DEBUG _flat_to_channel: N from parameter: 822
DEBUG _flat_to_channel: input shape=(128, 822, 822, 1), reshaping to (-1, 4, 822, 822)
[1m1/2[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2s/step[1m2/2[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m2s[0m 18ms/step
[runner] Inference complete; stats saved to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T231745Z/gs2_ideal/inference_outputs/stats.json
[runner] Outputs written to plans/active/DEBUG-SIM-LINES-DOSE-001/reports/2026-01-20T231745Z/gs2_ideal
