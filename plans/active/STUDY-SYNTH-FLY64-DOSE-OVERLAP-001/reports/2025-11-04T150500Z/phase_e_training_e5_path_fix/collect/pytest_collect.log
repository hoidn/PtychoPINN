============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 8 items

<Dir PtychoPINN2>
  <Package tests>
    <Package study>
      <Module test_dose_overlap_training.py>
        Tests for Phase E training job matrix builder.
        
        Validates that build_training_jobs() correctly enumerates 9 jobs per dose
        (3 doses × 3 variants: baseline gs1, dense gs2, sparse gs2) with proper
        metadata and dataset path validation.
        
        Test tier: Unit
        Test strategy: plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md
        <Function test_build_training_jobs_matrix>
          RED → GREEN TDD test for Phase E job matrix enumeration.
          
          Validates that build_training_jobs() produces exactly 9 jobs per dose:
          - 1 baseline job (gs1, Phase C patched_train.npz/patched_test.npz)
          - 2 overlap jobs (gs2, Phase D dense/sparse NPZs)
          
          Each TrainingJob must contain:
          - dose (float, from StudyDesign.dose_list)
          - view (str, one of {"baseline", "dense", "sparse"})
          - gridsize (int, 1 or 2)
          - train_data_path (str, validated existence)
          - test_data_path (str, validated existence)
          - artifact_dir (Path, deterministic from dose/view/gridsize)
          - log_path (Path, derived from artifact_dir)
          
          References:
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/implementation.md:133-144
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-115
          - specs/data_contracts.md:190-260 (DATA-001 keys)
        <Function test_run_training_job_invokes_runner>
          RED → GREEN TDD test for run_training_job runner invocation.
          
          Validates that run_training_job():
          - Creates artifact and log directories before execution
          - Constructs a TrainingConfig dataclass with job metadata
          - Calls update_legacy_dict(params.cfg, config) with the TrainingConfig instance
          - Invokes the injected runner callable with (config, job, log_path) kwargs
          - Touches/writes to job.log_path to ensure logging infrastructure ready
          - Returns useful metadata (e.g., runner result or summary dict)
          
          Test strategy: Use monkeypatch to spy on update_legacy_dict call and inject
          a stub runner that records its invocation signature. Validate call ordering
          (bridge before runner) and parameter passing.
          
          References:
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-123
          - docs/DEVELOPER_GUIDE.md:68-104 (CONFIG-001 ordering)
          - input.md:8-11 (task E4 tightened requirements: assert TrainingConfig)
        <Function test_run_training_job_dry_run>
          RED → GREEN TDD test for run_training_job dry-run mode.
          
          Validates that run_training_job(dry_run=True):
          - Creates artifact and log directories
          - Calls update_legacy_dict to prepare params.cfg
          - Does NOT invoke the runner callable
          - Returns a summary dict describing what would have been executed
          - Summary includes: dose, view, gridsize, dataset paths, log_path
          
          Test strategy: Inject a sentinel runner that raises AssertionError if called.
          Validate that dry_run prevents execution while still returning useful metadata.
          
          References:
          - input.md:10 (honor dry_run by summarizing without executing)
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-123
        <Function test_training_cli_filters_jobs>
          RED → GREEN TDD test for training CLI job filtering.
          
          Validates that the training CLI main() function:
          - Parses command-line arguments (--phase-c-root, --phase-d-root, --artifact-root)
          - Accepts optional filter flags (--dose, --view, --gridsize)
          - Calls build_training_jobs() to enumerate full job matrix
          - Filters jobs based on provided CLI flags
          - Invokes run_training_job() only for matching jobs
          - Handles gracefully when filters match nothing (informative error)
          
          Test strategy: Mock sys.argv to inject CLI arguments, monkeypatch build_training_jobs
          and run_training_job to return predictable stubs, validate filtering logic.
          
          References:
          - input.md:10 (CLI filtering requirements for Phase E4)
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-115
        <Function test_training_cli_manifest_and_bridging>
          RED → GREEN TDD test for training CLI manifest emission and CONFIG-001 bridging.
          
          Validates that the training CLI main() function:
          - Emits a training_manifest.json file under --artifact-root
          - Manifest contains job metadata (dose, view, gridsize, dataset paths, log paths)
          - Ensures run_training_job is called with proper CONFIG-001 bridge
          - Writes CLI stdout/stderr log to --artifact-root for traceability
          
          Test strategy: Mock run_training_job to verify it's called (CONFIG-001 handled internally),
          execute CLI with --dry-run, validate manifest JSON structure and content.
          
          References:
          - input.md:10 (manifest emission requirement for Phase E4)
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-115
        <Function test_execute_training_job_delegates_to_pytorch_trainer>
          RED → GREEN TDD test for Phase E5 execute_training_job backend delegation.
          
          Validates that execute_training_job():
          - Loads NPZ datasets from job.train_data_path and job.test_data_path
          - Uses the provided TrainingConfig (CONFIG-001 bridge already done by caller)
          - Calls ptycho_torch.workflows.components.train_cdi_model_torch with:
            - train_data: RawData or container loaded from job.train_data_path
            - test_data: RawData or container loaded from job.test_data_path
            - config: The TrainingConfig instance passed to execute_training_job
          - Writes logs/artifacts to job.log_path and job.artifact_dir
          - Returns training metrics (status, final_loss, epochs_completed, checkpoint_path)
          
          Test strategy: Monkeypatch train_cdi_model_torch to spy on invocation.
          Use minimal Phase C/D fixture NPZs (DATA-001 compliant) to avoid heavy I/O.
          Validate that the spy receives correct data containers and config.
          
          References:
          - input.md:9 (Phase E5 RED test requirements)
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:163-166
          - docs/DEVELOPER_GUIDE.md:68-104 (CONFIG-001 compliance assumed by caller)
          - docs/workflows/pytorch.md §12 (train_cdi_model_torch signature)
        <Function test_training_cli_invokes_real_runner>
          RED → GREEN TDD test for Phase E5 real training runner integration.
          
          Validates that the training CLI main() function, when invoked without --dry-run:
          - Invokes a production runner helper (execute_training_job) instead of stub_runner
          - Passes resolved TrainingJob and TrainingConfig to the runner
          - Runner helper performs CONFIG-001 bridging (update_legacy_dict)
          - Runner helper delegates to actual backend trainer (e.g., train_cdi_model_torch)
          - Artifacts (logs, manifests) are written under --artifact-root
          
          Test strategy: Monkeypatch execute_training_job to spy on invocation without
          executing full training. Validate that CLI calls the real runner with proper
          parameters when --dry-run is NOT set.
          
          References:
          - input.md:10 (Phase E5: wire CLI to real runner with deterministic execution)
          - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md Phase E future item 0
          - docs/DEVELOPER_GUIDE.md:68-104 (CONFIG-001 bridging)
          - docs/workflows/pytorch.md §12 (canonical PyTorch training invocation)
        <Function test_build_training_jobs_skips_missing_view>
          RED → GREEN TDD test for build_training_jobs with missing overlap view.
          
          Validates that build_training_jobs(..., allow_missing_phase_d=True):
          - Skips overlap jobs (dense/sparse) when their NPZ files are missing
          - Logs the omission with clear messaging
          - Still returns baseline jobs (Phase C always complete)
          - Does NOT raise FileNotFoundError when allow_missing_phase_d=True
          
          This scenario occurs when:
          - Phase C completed successfully for all doses
          - Phase D overlap filtering rejected some views due to spacing threshold
            (e.g., sparse view with too few positions after filtering)
          
          Expected behavior:
          - With allow_missing_phase_d=False (default): FileNotFoundError raised
          - With allow_missing_phase_d=True: missing views logged and skipped
          
          References:
              - input.md:10 (Phase E5 task: add allow_missing_phase_d switch)
              - docs/fix_plan.md:33 (Attempt #20 CLI failure on sparse view rejection)
              - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:163
                (Phase E exit criteria: CLI must handle missing overlap data gracefully)

========================== 8 tests collected in 3.63s ==========================
