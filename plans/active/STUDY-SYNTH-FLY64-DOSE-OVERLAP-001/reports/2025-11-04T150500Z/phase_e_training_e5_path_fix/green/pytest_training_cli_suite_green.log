============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /home/ollie/miniconda3/envs/ptycho311/bin/python3.11
cachedir: .pytest_cache
PyTorch: available
PyTorch version: 2.8.0+cu128
rootdir: /home/ollie/Documents/PtychoPINN2
configfile: pyproject.toml
plugins: anyio-4.9.0
collecting ... collected 8 items / 5 deselected / 3 selected

tests/study/test_dose_overlap_training.py::test_training_cli_filters_jobs FAILED [ 33%]
tests/study/test_dose_overlap_training.py::test_training_cli_manifest_and_bridging FAILED [ 66%]
tests/study/test_dose_overlap_training.py::test_training_cli_invokes_real_runner PASSED [100%]

=================================== FAILURES ===================================
________________________ test_training_cli_filters_jobs ________________________

tmp_path = PosixPath('/tmp/pytest-of-ollie/pytest-98/test_training_cli_filters_jobs0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x77ab80521c10>

    def test_training_cli_filters_jobs(tmp_path, monkeypatch):
        """
        RED → GREEN TDD test for training CLI job filtering.
    
        Validates that the training CLI main() function:
        - Parses command-line arguments (--phase-c-root, --phase-d-root, --artifact-root)
        - Accepts optional filter flags (--dose, --view, --gridsize)
        - Calls build_training_jobs() to enumerate full job matrix
        - Filters jobs based on provided CLI flags
        - Invokes run_training_job() only for matching jobs
        - Handles gracefully when filters match nothing (informative error)
    
        Test strategy: Mock sys.argv to inject CLI arguments, monkeypatch build_training_jobs
        and run_training_job to return predictable stubs, validate filtering logic.
    
        References:
        - input.md:10 (CLI filtering requirements for Phase E4)
        - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-115
        """
        import sys
        import json
        from studies.fly64_dose_overlap import training
    
        # Setup: Create mock Phase C and Phase D directories
        phase_c_root = tmp_path / "phase_c"
        phase_d_root = tmp_path / "phase_d"
        artifact_root = tmp_path / "artifacts"
    
        phase_c_root.mkdir()
        phase_d_root.mkdir()
    
        # Create minimal dataset structure (empty files suffice for CLI test)
        for dose in [1000, 10000, 100000]:
            dose_dir_c = phase_c_root / f"dose_{dose}"
            dose_dir_d = phase_d_root / f"dose_{dose}"
            dose_dir_c.mkdir()
            dose_dir_d.mkdir()
    
            # Phase C patched datasets
            (dose_dir_c / "patched_train.npz").touch()
            (dose_dir_c / "patched_test.npz").touch()
    
            # Phase D overlap views
            for view in ['dense', 'sparse']:
                (dose_dir_d / f"{view}_train.npz").touch()
                (dose_dir_d / f"{view}_test.npz").touch()
    
        # Spy: Track which jobs were executed
        executed_jobs = []
    
        def mock_run_training_job(job, runner, dry_run=False):
            executed_jobs.append({
                'dose': job.dose,
                'view': job.view,
                'gridsize': job.gridsize,
                'dry_run': dry_run,
            })
            return {'status': 'mock_success'}
    
        monkeypatch.setattr(training, 'run_training_job', mock_run_training_job)
    
        # Test case 1: No filters (all 9 jobs executed)
        executed_jobs.clear()
        test_argv = [
            'training.py',
            '--phase-c-root', str(phase_c_root),
            '--phase-d-root', str(phase_d_root),
            '--artifact-root', str(artifact_root),
            '--dry-run',
        ]
        monkeypatch.setattr(sys, 'argv', test_argv)
    
        training.main()
    
>       assert len(executed_jobs) == 9, \
            f"Expected 9 jobs without filters, got {len(executed_jobs)}"
E       AssertionError: Expected 9 jobs without filters, got 3
E       assert 3 == 9
E        +  where 3 = len([{'dose': 1000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}, {'dose': 10000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}, {'dose': 100000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}])

tests/study/test_dose_overlap_training.py:507: AssertionError
----------------------------- Captured stdout call -----------------------------
Enumerating training jobs from Phase C (/tmp/pytest-of-ollie/pytest-98/test_training_cli_filters_jobs0/phase_c) and Phase D (/tmp/pytest-of-ollie/pytest-98/test_training_cli_filters_jobs0/phase_d)...
  → 3 total jobs enumerated

Executing 3 training job(s)...
  [1/3] baseline (dose=1e+03, gridsize=1)
  [2/3] baseline (dose=1e+04, gridsize=1)
  [3/3] baseline (dose=1e+05, gridsize=1)

✓ Training manifest written to /tmp/pytest-of-ollie/pytest-98/test_training_cli_filters_jobs0/artifacts/training_manifest.json
  → 3 job(s) completed
___________________ test_training_cli_manifest_and_bridging ____________________

tmp_path = PosixPath('/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x77ab801f8350>

    def test_training_cli_manifest_and_bridging(tmp_path, monkeypatch):
        """
        RED → GREEN TDD test for training CLI manifest emission and CONFIG-001 bridging.
    
        Validates that the training CLI main() function:
        - Emits a training_manifest.json file under --artifact-root
        - Manifest contains job metadata (dose, view, gridsize, dataset paths, log paths)
        - Ensures run_training_job is called with proper CONFIG-001 bridge
        - Writes CLI stdout/stderr log to --artifact-root for traceability
    
        Test strategy: Mock run_training_job to verify it's called (CONFIG-001 handled internally),
        execute CLI with --dry-run, validate manifest JSON structure and content.
    
        References:
        - input.md:10 (manifest emission requirement for Phase E4)
        - plans/active/STUDY-SYNTH-FLY64-DOSE-OVERLAP-001/test_strategy.md:84-115
        """
        import sys
        import json
        from studies.fly64_dose_overlap import training
    
        # Setup: Create mock Phase C and Phase D directories
        phase_c_root = tmp_path / "phase_c"
        phase_d_root = tmp_path / "phase_d"
        artifact_root = tmp_path / "artifacts"
    
        phase_c_root.mkdir()
        phase_d_root.mkdir()
    
        # Create minimal dataset structure for all doses (to match StudyDesign defaults)
        for dose in [1000, 10000, 100000]:
            dose_dir_c = phase_c_root / f"dose_{dose}"
            dose_dir_d = phase_d_root / f"dose_{dose}"
            dose_dir_c.mkdir()
            dose_dir_d.mkdir()
    
            # Phase C patched datasets
            (dose_dir_c / "patched_train.npz").touch()
            (dose_dir_c / "patched_test.npz").touch()
    
            # Phase D overlap views
            for view in ['dense', 'sparse']:
                (dose_dir_d / f"{view}_train.npz").touch()
                (dose_dir_d / f"{view}_test.npz").touch()
    
        # Spy: Track run_training_job calls
        run_calls = []
    
        def mock_run_training_job(job, runner, dry_run=False):
            run_calls.append({
                'dose': job.dose,
                'view': job.view,
                'gridsize': job.gridsize,
            })
            return {'status': 'mock_success'}
    
        monkeypatch.setattr(training, 'run_training_job', mock_run_training_job)
    
        # Execute CLI with dose filter to reduce output
        test_argv = [
            'training.py',
            '--phase-c-root', str(phase_c_root),
            '--phase-d-root', str(phase_d_root),
            '--artifact-root', str(artifact_root),
            '--dose', '1000',
            '--dry-run',
        ]
        monkeypatch.setattr(sys, 'argv', test_argv)
    
        training.main()
    
        # Assertions: manifest file created
        manifest_path = artifact_root / "training_manifest.json"
        assert manifest_path.exists(), \
            f"training_manifest.json not found at {manifest_path}"
    
        # Assertions: manifest content is valid JSON
        with manifest_path.open('r') as f:
            manifest = json.load(f)
    
        assert isinstance(manifest, dict), \
            f"Manifest must be a dict, got {type(manifest)}"
    
        # Assertions: manifest contains expected keys
        required_keys = {'timestamp', 'phase_c_root', 'phase_d_root', 'artifact_root', 'jobs'}
        missing_keys = required_keys - manifest.keys()
        assert not missing_keys, \
            f"Manifest missing keys: {missing_keys}"
    
        # Assertions: jobs list matches executed jobs (3 for dose=1000)
        assert isinstance(manifest['jobs'], list), \
            f"Manifest 'jobs' must be a list, got {type(manifest['jobs'])}"
>       assert len(manifest['jobs']) == 3, \
            f"Expected 3 jobs in manifest for dose=1000, got {len(manifest['jobs'])}"
E       AssertionError: Expected 3 jobs in manifest for dose=1000, got 1
E       assert 1 == 3
E        +  where 1 = len([{'dose': 1000.0, 'view': 'baseline', 'gridsize': 1, 'train_data_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_c/dose_1000/patched_train.npz', 'test_data_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_c/dose_1000/patched_test.npz', 'log_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/artifacts/dose_1000/baseline/gs1/train.log', 'artifact_dir': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/artifacts/dose_1000/baseline/gs1', 'result': {'status': 'mock_success'}}])

tests/study/test_dose_overlap_training.py:689: AssertionError
----------------------------- Captured stdout call -----------------------------
Enumerating training jobs from Phase C (/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_c) and Phase D (/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_d)...
  → 3 total jobs enumerated
  → Filtered by dose=1000.0: 1 jobs remain

Executing 1 training job(s)...
  [1/1] baseline (dose=1e+03, gridsize=1)

✓ Training manifest written to /tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/artifacts/training_manifest.json
  → 1 job(s) completed
=========================== short test summary info ============================
FAILED tests/study/test_dose_overlap_training.py::test_training_cli_filters_jobs - AssertionError: Expected 9 jobs without filters, got 3
assert 3 == 9
 +  where 3 = len([{'dose': 1000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}, {'dose': 10000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}, {'dose': 100000.0, 'view': 'baseline', 'gridsize': 1, 'dry_run': True}])
FAILED tests/study/test_dose_overlap_training.py::test_training_cli_manifest_and_bridging - AssertionError: Expected 3 jobs in manifest for dose=1000, got 1
assert 1 == 3
 +  where 1 = len([{'dose': 1000.0, 'view': 'baseline', 'gridsize': 1, 'train_data_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_c/dose_1000/patched_train.npz', 'test_data_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/phase_c/dose_1000/patched_test.npz', 'log_path': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/artifacts/dose_1000/baseline/gs1/train.log', 'artifact_dir': '/tmp/pytest-of-ollie/pytest-98/test_training_cli_manifest_and0/artifacts/dose_1000/baseline/gs1', 'result': {'status': 'mock_success'}}])
================== 2 failed, 1 passed, 5 deselected in 3.92s ===================
