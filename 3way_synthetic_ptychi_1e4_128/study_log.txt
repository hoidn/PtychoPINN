[2025-08-26 17:46:51] === Starting Complete Generalization Study ===
[2025-08-26 17:46:51] Training sizes: 128
[2025-08-26 17:46:51] Number of trials per size: 1
[2025-08-26 17:46:51] Output directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 17:46:51] Total training runs planned: 2
[2025-08-26 17:46:51] Validating environment...
[2025-08-26 17:46:51] Environment validation passed
[2025-08-26 17:46:51] Configuration saved to: 3way_synthetic_ptychi_1e4_128/study_config.txt
[2025-08-26 17:46:51] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 17:46:51] === STEP 2: Model Training ===
[2025-08-26 17:46:51] Training models sequentially with 1 trials per training size
[2025-08-26 17:46:51] Starting training for train_size=128, test_size=128 (1 trials)
[2025-08-26 17:46:51] Training models for train_size=128, test_size=128 (Trial 1/1)
[2025-08-26 17:46:51] EXECUTING: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 17:46:51] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 17:46:52.015967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756255612.028158 3426510 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756255612.031963 3426510 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756255612.043911 3426510 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255612.043922 3426510 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255612.043924 3426510 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255612.043925 3426510 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:46:52.047134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:46:54,989 - INFO - Configuration setup complete
2025-08-26 17:46:54,989 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 17:46:54,989 - INFO - Parameter interpretation: --n-images=128 refers to individual images (gridsize=1)
2025-08-26 17:46:54,989 - INFO - Starting training with n_images=128, stitching=disabled
2025-08-26 17:46:54,989 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 17:46:55,312 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
2025-08-26 17:46:55,639 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 17:46:55,639 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 17:46:55,951 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
2025-08-26 17:46:55,951 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/test.npz
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:46:55,952 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:46:55,952 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 17:46:55,952 - INFO - Using all 128 points as seeds
2025-08-26 17:46:55,952 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:46:55,952 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:46:55,952 - INFO - Generated 128 groups efficiently
I0000 00:00:1756255616.080512 3426510 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756255616.081753 3426510 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:46:56,485 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:46:56,485 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 17:46:56,485 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 17:46:56,485 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:46:56,485 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:46:56,485 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1268.789 global_offsets=(128, 1, 2, 1) mean=138.554 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:46:57.179143: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:46:57.179154: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756255617.179170 3426510 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756255617.196731 3426510 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:46:57.196839: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756255617.196916 3426510 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756255617.927836 3426510 service.cc:152] XLA service 0x18369010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756255617.927856 3426510 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:46:57.958287: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756255617.976604 3426510 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756255618.549786 3426510 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 17:46:59,073 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 17:47:00,997 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 17:47:04.617245: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:47:04.699403: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:47:04.720008: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:47:05.012644: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m49s[0m 7s/step - intensity_scaler_inv_loss: 0.6327 - loss: 0.6163 - pred_intensity_loss: 0.6163 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 2.0332 - loss: 19.4334 - pred_intensity_loss: 19.4334 - trimmed_obj_loss: 0.0000e+002025-08-26 17:47:07.316833: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:47:07.320084: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:47:07.322443: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:47:07.521160: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 342ms/step - intensity_scaler_inv_loss: 1.8322 - loss: 16.4684 - pred_intensity_loss: 16.4032 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 17:47:08,493 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m11s[0m 526ms/step - intensity_scaler_inv_loss: 1.4083 - loss: 10.4273 - pred_intensity_loss: 9.9060 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.6482 - val_loss: 0.1981 - val_pred_intensity_loss: 0.1981 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.6463 - loss: 0.1834 - pred_intensity_loss: 0.1834 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.6148 - loss: 0.1185 - pred_intensity_loss: 0.1185 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5928 - loss: 0.0270 - pred_intensity_loss: 0.0148 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5228 - val_loss: -0.1951 - val_pred_intensity_loss: -0.1951 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.5113 - loss: -0.2795 - pred_intensity_loss: -0.2795 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5228 - loss: -0.2134 - pred_intensity_loss: -0.2134 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.5296 - loss: -0.1958 - pred_intensity_loss: -0.1947 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5369 - val_loss: -0.1848 - val_pred_intensity_loss: -0.1848 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5296 - loss: -0.2037 - pred_intensity_loss: -0.2037 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5220 - loss: -0.2259 - pred_intensity_loss: -0.2259 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5106 - loss: -0.2357 - pred_intensity_loss: -0.2399 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5163 - val_loss: -0.1960 - val_pred_intensity_loss: -0.1960 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5011 - loss: -0.2194 - pred_intensity_loss: -0.2194 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5040 - loss: -0.2368 - pred_intensity_loss: -0.2368 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5066 - loss: -0.2430 - pred_intensity_loss: -0.2426 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5108 - val_loss: -0.2176 - val_pred_intensity_loss: -0.2176 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5171 - loss: -0.2327 - pred_intensity_loss: -0.2327 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.5073 - loss: -0.2594 - pred_intensity_loss: -0.2594 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 24ms/step - intensity_scaler_inv_loss: 0.5038 - loss: -0.2529 - pred_intensity_loss: -0.2538 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5017 - val_loss: -0.2257 - val_pred_intensity_loss: -0.2257 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4975 - loss: -0.2530 - pred_intensity_loss: -0.2530 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4974 - loss: -0.2589 - pred_intensity_loss: -0.2589 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4976 - loss: -0.2607 - pred_intensity_loss: -0.2611 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4993 - val_loss: -0.2362 - val_pred_intensity_loss: -0.2362 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4945 - loss: -0.3139 - pred_intensity_loss: -0.3139 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4970 - loss: -0.2808 - pred_intensity_loss: -0.2808 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4969 - loss: -0.2683 - pred_intensity_loss: -0.2693 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4923 - val_loss: -0.2449 - val_pred_intensity_loss: -0.2449 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5050 - loss: -0.2948 - pred_intensity_loss: -0.2948 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4971 - loss: -0.2880 - pred_intensity_loss: -0.2880 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4942 - loss: -0.2736 - pred_intensity_loss: -0.2733 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4990 - val_loss: -0.2522 - val_pred_intensity_loss: -0.2522 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4996 - loss: -0.2558 - pred_intensity_loss: -0.2558 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4960 - loss: -0.2772 - pred_intensity_loss: -0.2772 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4958 - loss: -0.2799 - pred_intensity_loss: -0.2794 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4913 - val_loss: -0.2622 - val_pred_intensity_loss: -0.2622 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4815 - loss: -0.3506 - pred_intensity_loss: -0.3506 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4902 - loss: -0.2921 - pred_intensity_loss: -0.2921 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4935 - loss: -0.2851 - pred_intensity_loss: -0.2862 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4911 - val_loss: -0.2694 - val_pred_intensity_loss: -0.2694 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5047 - loss: -0.2869 - pred_intensity_loss: -0.2869 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4966 - loss: -0.2816 - pred_intensity_loss: -0.2816 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4906 - loss: -0.2924 - pred_intensity_loss: -0.2954 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4876 - val_loss: -0.2789 - val_pred_intensity_loss: -0.2789 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4893 - loss: -0.2685 - pred_intensity_loss: -0.2685 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4862 - loss: -0.2979 - pred_intensity_loss: -0.2979 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4872 - loss: -0.3045 - pred_intensity_loss: -0.3071 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4831 - val_loss: -0.2963 - val_pred_intensity_loss: -0.2963 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4847 - loss: -0.3085 - pred_intensity_loss: -0.3085 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4874 - loss: -0.3032 - pred_intensity_loss: -0.3032 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4818 - loss: -0.3179 - pred_intensity_loss: -0.3213 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4771 - val_loss: -0.3085 - val_pred_intensity_loss: -0.3085 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4921 - loss: -0.3074 - pred_intensity_loss: -0.3074 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4841 - loss: -0.3061 - pred_intensity_loss: -0.3061 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4769 - loss: -0.3294 - pred_intensity_loss: -0.3328 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4845 - val_loss: -0.3125 - val_pred_intensity_loss: -0.3125 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4851 - loss: -0.3067 - pred_intensity_loss: -0.3067 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4801 - loss: -0.3295 - pred_intensity_loss: -0.3295 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4724 - loss: -0.3414 - pred_intensity_loss: -0.3449 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4727 - val_loss: -0.3326 - val_pred_intensity_loss: -0.3326 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4861 - loss: -0.3050 - pred_intensity_loss: -0.3050 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4751 - loss: -0.3359 - pred_intensity_loss: -0.3359 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4675 - loss: -0.3592 - pred_intensity_loss: -0.3620 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4610 - val_loss: -0.3494 - val_pred_intensity_loss: -0.3494 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 35ms/step - intensity_scaler_inv_loss: 0.4570 - loss: -0.4017 - pred_intensity_loss: -0.4017 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4632 - loss: -0.3868 - pred_intensity_loss: -0.3868 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4632 - loss: -0.3757 - pred_intensity_loss: -0.3753 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4576 - val_loss: -0.3609 - val_pred_intensity_loss: -0.3609 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4627 - loss: -0.3886 - pred_intensity_loss: -0.3886 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4606 - loss: -0.3821 - pred_intensity_loss: -0.3821 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4591 - loss: -0.3861 - pred_intensity_loss: -0.3844 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4566 - val_loss: -0.3685 - val_pred_intensity_loss: -0.3685 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4565 - loss: -0.4105 - pred_intensity_loss: -0.4105 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4550 - loss: -0.4172 - pred_intensity_loss: -0.4172 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4580 - loss: -0.3955 - pred_intensity_loss: -0.3924 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4577 - val_loss: -0.3309 - val_pred_intensity_loss: -0.3309 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4533 - loss: -0.3368 - pred_intensity_loss: -0.3368 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4593 - loss: -0.3692 - pred_intensity_loss: -0.3692 - trimmed_obj_loss: 0.0000e+00
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4600 - loss: -0.3819 - pred_intensity_loss: -0.3838 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4515 - val_loss: -0.3649 - val_pred_intensity_loss: -0.3649 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4095 - pred_intensity_loss: -0.4095 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4522 - loss: -0.4034 - pred_intensity_loss: -0.4034 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4549 - loss: -0.3982 - pred_intensity_loss: -0.3980 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4516 - val_loss: -0.3753 - val_pred_intensity_loss: -0.3753 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.3992 - pred_intensity_loss: -0.3992 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4519 - loss: -0.4133 - pred_intensity_loss: -0.4133 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4537 - loss: -0.4040 - pred_intensity_loss: -0.4034 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4533 - val_loss: -0.3812 - val_pred_intensity_loss: -0.3812 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4299 - pred_intensity_loss: -0.4299 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4518 - loss: -0.4055 - pred_intensity_loss: -0.4055 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4538 - loss: -0.4080 - pred_intensity_loss: -0.4085 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4545 - val_loss: -0.3834 - val_pred_intensity_loss: -0.3834 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4570 - loss: -0.3532 - pred_intensity_loss: -0.3532 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4550 - loss: -0.3893 - pred_intensity_loss: -0.3893 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4524 - loss: -0.4108 - pred_intensity_loss: -0.4105 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4494 - val_loss: -0.3863 - val_pred_intensity_loss: -0.3863 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 36ms/step - intensity_scaler_inv_loss: 0.4529 - loss: -0.3837 - pred_intensity_loss: -0.3837 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4502 - loss: -0.4123 - pred_intensity_loss: -0.4123 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4516 - loss: -0.4132 - pred_intensity_loss: -0.4135 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4509 - val_loss: -0.3900 - val_pred_intensity_loss: -0.3900 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4558 - loss: -0.3667 - pred_intensity_loss: -0.3667 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4514 - loss: -0.3981 - pred_intensity_loss: -0.3981 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4520 - loss: -0.4159 - pred_intensity_loss: -0.4127 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4487 - val_loss: -0.3907 - val_pred_intensity_loss: -0.3907 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.3863 - pred_intensity_loss: -0.3863 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4472 - loss: -0.4152 - pred_intensity_loss: -0.4152 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4507 - loss: -0.4170 - pred_intensity_loss: -0.4150 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4514 - val_loss: -0.3923 - val_pred_intensity_loss: -0.3923 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4606 - loss: -0.3758 - pred_intensity_loss: -0.3758 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4542 - loss: -0.3978 - pred_intensity_loss: -0.3978 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4499 - loss: -0.4187 - pred_intensity_loss: -0.4192 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4529 - val_loss: -0.3936 - val_pred_intensity_loss: -0.3936 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4488 - loss: -0.3975 - pred_intensity_loss: -0.3975 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4508 - loss: -0.4073 - pred_intensity_loss: -0.4073 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4501 - loss: -0.4204 - pred_intensity_loss: -0.4184 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4473 - val_loss: -0.3960 - val_pred_intensity_loss: -0.3960 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4134 - pred_intensity_loss: -0.4134 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.3952 - pred_intensity_loss: -0.3952 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4499 - loss: -0.4226 - pred_intensity_loss: -0.4221 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4475 - val_loss: -0.3970 - val_pred_intensity_loss: -0.3970 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 35ms/step - intensity_scaler_inv_loss: 0.4538 - loss: -0.3987 - pred_intensity_loss: -0.3987 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4523 - loss: -0.4159 - pred_intensity_loss: -0.4159 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4492 - loss: -0.4242 - pred_intensity_loss: -0.4259 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4490 - val_loss: -0.3996 - val_pred_intensity_loss: -0.3996 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4545 - loss: -0.4242 - pred_intensity_loss: -0.4242 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4527 - loss: -0.4240 - pred_intensity_loss: -0.4240 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.4253 - pred_intensity_loss: -0.4245 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4487 - val_loss: -0.4013 - val_pred_intensity_loss: -0.4013 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4550 - loss: -0.4216 - pred_intensity_loss: -0.4216 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4513 - loss: -0.4293 - pred_intensity_loss: -0.4293 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.4257 - pred_intensity_loss: -0.4292 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4457 - val_loss: -0.4003 - val_pred_intensity_loss: -0.4003 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4481 - loss: -0.4335 - pred_intensity_loss: -0.4335 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4476 - loss: -0.4263 - pred_intensity_loss: -0.4263 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4263 - pred_intensity_loss: -0.4248 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4451 - val_loss: -0.4020 - val_pred_intensity_loss: -0.4020 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4076 - pred_intensity_loss: -0.4076 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4197 - pred_intensity_loss: -0.4197 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4279 - pred_intensity_loss: -0.4278 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4445 - val_loss: -0.4035 - val_pred_intensity_loss: -0.4035 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4416 - loss: -0.4794 - pred_intensity_loss: -0.4794 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4405 - pred_intensity_loss: -0.4405 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4293 - pred_intensity_loss: -0.4279 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4459 - val_loss: -0.4061 - val_pred_intensity_loss: -0.4061 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4414 - loss: -0.4196 - pred_intensity_loss: -0.4196 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4212 - pred_intensity_loss: -0.4212 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4310 - pred_intensity_loss: -0.4289 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4461 - val_loss: -0.4080 - val_pred_intensity_loss: -0.4080 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4577 - pred_intensity_loss: -0.4577 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4469 - loss: -0.4380 - pred_intensity_loss: -0.4380 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4320 - pred_intensity_loss: -0.4332 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4456 - val_loss: -0.4084 - val_pred_intensity_loss: -0.4084 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4387 - pred_intensity_loss: -0.4387 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4352 - pred_intensity_loss: -0.4352 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4472 - loss: -0.4323 - pred_intensity_loss: -0.4339 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4479 - val_loss: -0.4092 - val_pred_intensity_loss: -0.4092 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4495 - loss: -0.4220 - pred_intensity_loss: -0.4220 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4470 - loss: -0.4300 - pred_intensity_loss: -0.4300 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4470 - loss: -0.4337 - pred_intensity_loss: -0.4333 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4469 - val_loss: -0.4109 - val_pred_intensity_loss: -0.4109 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4516 - pred_intensity_loss: -0.4516 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4376 - pred_intensity_loss: -0.4376 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4346 - pred_intensity_loss: -0.4338 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4450 - val_loss: -0.4118 - val_pred_intensity_loss: -0.4118 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4894 - pred_intensity_loss: -0.4894 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4471 - loss: -0.4524 - pred_intensity_loss: -0.4524 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4350 - pred_intensity_loss: -0.4357 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4443 - val_loss: -0.4125 - val_pred_intensity_loss: -0.4125 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4451 - loss: -0.4025 - pred_intensity_loss: -0.4025 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4461 - loss: -0.4401 - pred_intensity_loss: -0.4401 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4456 - loss: -0.4360 - pred_intensity_loss: -0.4336 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4454 - val_loss: -0.4132 - val_pred_intensity_loss: -0.4132 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4439 - pred_intensity_loss: -0.4439 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4393 - pred_intensity_loss: -0.4393 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4367 - pred_intensity_loss: -0.4348 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4478 - val_loss: -0.4117 - val_pred_intensity_loss: -0.4117 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4461 - loss: -0.4071 - pred_intensity_loss: -0.4071 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4465 - loss: -0.4239 - pred_intensity_loss: -0.4239 - trimmed_obj_loss: 0.0000e+00
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4342 - pred_intensity_loss: -0.4370 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4424 - val_loss: -0.4112 - val_pred_intensity_loss: -0.4112 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4240 - pred_intensity_loss: -0.4240 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4389 - pred_intensity_loss: -0.4389 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4366 - pred_intensity_loss: -0.4406 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4467 - val_loss: -0.4132 - val_pred_intensity_loss: -0.4132 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4466 - pred_intensity_loss: -0.4466 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4326 - pred_intensity_loss: -0.4326 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4378 - pred_intensity_loss: -0.4400 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4440 - val_loss: -0.4159 - val_pred_intensity_loss: -0.4159 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4478 - loss: -0.4544 - pred_intensity_loss: -0.4544 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4466 - pred_intensity_loss: -0.4466 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4388 - pred_intensity_loss: -0.4367 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4450 - val_loss: -0.4164 - val_pred_intensity_loss: -0.4164 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4415 - loss: -0.4379 - pred_intensity_loss: -0.4379 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4461 - pred_intensity_loss: -0.4461 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4393 - pred_intensity_loss: -0.4386 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4440 - val_loss: -0.4163 - val_pred_intensity_loss: -0.4163 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 983ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 524288 into shape (6,6,64,64,1)
2025-08-26 17:47:19,922 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 17:47:21,353 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
[2025-08-26 17:47:22] SUCCESS: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 17:47:22] EXECUTING: Baseline training (n_images=128, trial=1)
[2025-08-26 17:47:22] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 17:47:23.068011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756255643.079700 3434243 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756255643.083541 3434243 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756255643.094594 3434243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255643.094604 3434243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255643.094605 3434243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255643.094607 3434243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:47:23.097487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:47:25,861 - INFO - Configuration setup complete
2025-08-26 17:47:25,861 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 17:47:25,861 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 17:47:25,861 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 17:47:25,861 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/
2025-08-26 17:47:25,861 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756255645.971943 3434243 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756255645.973272 3434243 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 17:47:26,008 - INFO - 
[2/6] Loading data...
2025-08-26 17:47:26,008 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 17:47:26,008 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 17:47:26,341 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
2025-08-26 17:47:26,341 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 17:47:26,652 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 17:47:26,652 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:47:26,652 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 17:47:26,653 - INFO - Using all 128 points as seeds
2025-08-26 17:47:26,653 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:47:26,653 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:47:26,653 - INFO - Generated 128 groups efficiently
2025-08-26 17:47:27,041 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:47:27,042 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 17:47:27,042 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 17:47:27,042 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:47:27,042 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:47:27,042 - INFO - Generated 128 groups efficiently
2025-08-26 17:47:27,053 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-08-26 17:47:27,053 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 17:47:27,054 - INFO - Final training input shape: (128, 64, 64, 1)
2025-08-26 17:47:27,054 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 17:47:27,054 - INFO - Training with 128 images
DEBUG: Setting timestamp to 08/26/2025, 17:47:25 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
timestamp: 08/26/2025, 17:47:25
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1297.438 global_offsets=(128, 1, 2, 1) mean=136.741 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756255650.032334 3434391 service.cc:152] XLA service 0x702864022780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756255650.032357 3434391 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:47:30.105096: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756255650.534623 3434391 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756255653.528707 3434391 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m40s[0m 6s/step - conv2d_12_loss: 0.5633 - conv2d_19_loss: 0.2193 - loss: 0.7825[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.4592 - conv2d_19_loss: 0.2182 - loss: 0.6774[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 430ms/step - conv2d_12_loss: 0.4690 - conv2d_19_loss: 0.2216 - loss: 0.6917[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m10s[0m 552ms/step - conv2d_12_loss: 0.4897 - conv2d_19_loss: 0.2304 - loss: 0.7283 - val_conv2d_12_loss: 0.4234 - val_conv2d_19_loss: 0.2312 - val_loss: 0.6546 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.4246 - conv2d_19_loss: 0.2182 - loss: 0.6428[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.4300 - conv2d_19_loss: 0.2149 - loss: 0.6449[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.4008 - conv2d_19_loss: 0.2136 - loss: 0.6207 - val_conv2d_12_loss: 0.1913 - val_conv2d_19_loss: 0.2287 - val_loss: 0.4200 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1923 - conv2d_19_loss: 0.2157 - loss: 0.4081[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.1582 - conv2d_19_loss: 0.2140 - loss: 0.3721[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.1227 - conv2d_19_loss: 0.2132 - loss: 0.3377 - val_conv2d_12_loss: 0.0972 - val_conv2d_19_loss: 0.2287 - val_loss: 0.3259 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0946 - conv2d_19_loss: 0.2027 - loss: 0.2974[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0862 - conv2d_19_loss: 0.2081 - loss: 0.2942[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0780 - conv2d_19_loss: 0.2124 - loss: 0.2906 - val_conv2d_12_loss: 0.0659 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2944 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0611 - conv2d_19_loss: 0.1934 - loss: 0.2545[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0628 - conv2d_19_loss: 0.2042 - loss: 0.2669[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0618 - conv2d_19_loss: 0.2126 - loss: 0.2742 - val_conv2d_12_loss: 0.0573 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2858 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0569 - conv2d_19_loss: 0.2209 - loss: 0.2779[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0569 - conv2d_19_loss: 0.2158 - loss: 0.2727[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0550 - conv2d_19_loss: 0.2124 - loss: 0.2674 - val_conv2d_12_loss: 0.0542 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2828 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.2003 - loss: 0.2512[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0513 - conv2d_19_loss: 0.2086 - loss: 0.2599[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0510 - conv2d_19_loss: 0.2127 - loss: 0.2633 - val_conv2d_12_loss: 0.0510 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2794 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.2169 - loss: 0.2669[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0493 - conv2d_19_loss: 0.2143 - loss: 0.2636[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0483 - conv2d_19_loss: 0.2123 - loss: 0.2606 - val_conv2d_12_loss: 0.0488 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2773 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0475 - conv2d_19_loss: 0.2127 - loss: 0.2601[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.2107 - loss: 0.2571[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0461 - conv2d_19_loss: 0.2124 - loss: 0.2584 - val_conv2d_12_loss: 0.0467 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2752 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0460 - conv2d_19_loss: 0.2145 - loss: 0.2605[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.2135 - loss: 0.2585[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0440 - conv2d_19_loss: 0.2126 - loss: 0.2562 - val_conv2d_12_loss: 0.0446 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2730 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0434 - conv2d_19_loss: 0.2121 - loss: 0.2556[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0431 - conv2d_19_loss: 0.2143 - loss: 0.2574[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0420 - conv2d_19_loss: 0.2125 - loss: 0.2543 - val_conv2d_12_loss: 0.0429 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2713 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2078 - loss: 0.2477[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.2120 - loss: 0.2526[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2128 - loss: 0.2526 - val_conv2d_12_loss: 0.0413 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2697 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.2235 - loss: 0.2658[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2157 - loss: 0.2558[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2121 - loss: 0.2515 - val_conv2d_12_loss: 0.0408 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2693 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2139 - loss: 0.2523[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2123 - loss: 0.2510[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2131 - loss: 0.2510 - val_conv2d_12_loss: 0.0405 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2688 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2056 - loss: 0.2430[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2089 - loss: 0.2470[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2134 - loss: 0.2508 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2689 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2120 - loss: 0.2505[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2102 - loss: 0.2486[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2122 - loss: 0.2510 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2686 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.1984 - loss: 0.2342[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2088 - loss: 0.2469[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2120 - loss: 0.2510 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2687 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2107 - loss: 0.2489[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2135 - loss: 0.2524[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2108 - loss: 0.2506 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2684 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2079 - loss: 0.2452[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2108 - loss: 0.2488[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2126 - loss: 0.2506 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2141 - loss: 0.2530[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2130 - loss: 0.2516[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2127 - loss: 0.2504 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2685 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2133 - loss: 0.2507[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2123 - loss: 0.2501
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2121 - loss: 0.2504 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2684 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2163 - loss: 0.2556[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2105 - loss: 0.2487[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2121 - loss: 0.2503 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2681 - learning_rate: 5.0000e-04
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2141 - loss: 0.2525[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2123 - loss: 0.2502
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2128 - loss: 0.2502 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2682 - learning_rate: 5.0000e-04
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 29ms/step - conv2d_12_loss: 0.0371 - conv2d_19_loss: 0.2061 - loss: 0.2432[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2087 - loss: 0.2463[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2121 - loss: 0.2502 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2681 - learning_rate: 2.5000e-04
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 29ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2176 - loss: 0.2559[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2150 - loss: 0.2532
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2120 - loss: 0.2502 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2682 - learning_rate: 2.5000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 29ms/step - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.2065 - loss: 0.2433[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2082 - loss: 0.2455[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2125 - loss: 0.2502 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.2500e-04
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.1980 - loss: 0.2343[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2076 - loss: 0.2451
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2118 - loss: 0.2502 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.2500e-04
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.2002 - loss: 0.2364[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2087 - loss: 0.2462[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2120 - loss: 0.2502 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2072 - loss: 0.2445[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2116 - loss: 0.2499[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2118 - loss: 0.2502 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2173 - loss: 0.2563[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2178 - loss: 0.2569[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2113 - loss: 0.2502 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.2186 - loss: 0.2583[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2139 - loss: 0.2527[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2120 - loss: 0.2501 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 29ms/step - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.2018 - loss: 0.2388[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2107 - loss: 0.2489[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2115 - loss: 0.2502 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2121 - loss: 0.2509[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2114 - loss: 0.2496[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2122 - loss: 0.2501 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.2027 - loss: 0.2389[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2099 - loss: 0.2475[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2130 - loss: 0.2501 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2077 - loss: 0.2452[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2108 - loss: 0.2489[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2123 - loss: 0.2501 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0367 - conv2d_19_loss: 0.2019 - loss: 0.2386[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2100 - loss: 0.2478[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2118 - loss: 0.2501 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2681 - learning_rate: 1.0000e-04
2025-08-26 17:47:42,588 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 17:47:42,712 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/baseline_model.h5
2025-08-26 17:47:42,712 - INFO - 
[5/6] Performing inference and stitching...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 830ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
2025-08-26 17:47:46,166 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-08-26 17:47:46,166 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 17:47:46,167 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 17:47:46,167 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:47:46,167 - INFO - Calculated ground truth crop region: rows [106:209], cols [22:209]
2025-08-26 17:47:46,167 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(103, 187)
2025-08-26 17:47:46,167 - INFO - Center-cropping from (188, 188) to (103, 187)
2025-08-26 17:47:46,167 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:47:46,167 - INFO - --- Alignment complete ---
2025-08-26 17:47:46,167 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 187, 1), Ground Truth=(103, 187, 1)
2025-08-26 17:47:46,188 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 17:47:46,188 - INFO -   MAE:  (np.float32(0.09695795), np.float64(0.24309945559283339))
2025-08-26 17:47:46,188 - INFO -   PSNR: (63.197344422213106, 59.39010808189746)
2025-08-26 17:47:46,225 - INFO - Metrics and reconstruction images saved.
2025-08-26 17:47:46,225 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.067065
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.527960, std=0.159200, shape=(99, 183, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.020568, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.067065
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.527960, std=0.159200, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.020568, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
[2025-08-26 17:47:47] SUCCESS: Baseline training (n_images=128, trial=1)
[2025-08-26 17:47:47] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 17:47:47] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/test.npz' \
                '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 128 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 17:48:04] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 17:48:04] Completed training for train_size=128 (Trial 1/1)
[2025-08-26 17:48:04] Completed all trials for train_size=128
[2025-08-26 17:48:04] Model training phase completed
[2025-08-26 17:48:04] === STEP 3: Model Comparison ===
[2025-08-26 17:48:04] Running comparisons for train_size=128, test_size=128 (1 trials)
[2025-08-26 17:48:04] Using test subset size 128 (3-way comparison mode with Pty-chi)
[2025-08-26 17:48:04] EXECUTING: Model comparison (train_size=128, trial=1)
[2025-08-26 17:48:04] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/test.npz' --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1' --skip-registration --tike_recon_path '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 128
2025-08-26 17:48:05.346433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756255685.359119 3439900 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756255685.362998 3439900 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756255685.374229 3439900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255685.374240 3439900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255685.374242 3439900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756255685.374243 3439900 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:48:05.377216: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:48:07,802 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 17:48:07,802 - INFO - Registration: disabled
2025-08-26 17:48:07,802 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 17:48:07,802 - INFO - Initializing configuration before data loading...
2025-08-26 17:48:07,802 - INFO - Initialized with gridsize=1, n_images=128
2025-08-26 17:48:07,802 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/test.npz...
2025-08-26 17:48:07,802 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=128
2025-08-26 17:48:08,118 - INFO - Using specified subset of 128 images from 2424 total (gridsize=1)
diff3d shape: (128, 64, 64)2025-08-26 17:48:08,118 - INFO - diff3d shape: (128, 64, 64)

probeGuess shape: (64, 64)2025-08-26 17:48:08,118 - INFO - probeGuess shape: (64, 64)

scan_index shape: (128,)2025-08-26 17:48:08,118 - INFO - scan_index shape: (128,)

objectGuess shape: (232, 232)2025-08-26 17:48:08,118 - INFO - objectGuess shape: (232, 232)

xcoords shape: (128,)2025-08-26 17:48:08,118 - INFO - xcoords shape: (128,)

ycoords shape: (128,)2025-08-26 17:48:08,118 - INFO - ycoords shape: (128,)

xcoords_start shape: (128,)2025-08-26 17:48:08,118 - INFO - xcoords_start shape: (128,)

ycoords_start shape: (128,)2025-08-26 17:48:08,118 - INFO - ycoords_start shape: (128,)

2025-08-26 17:48:08,118 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 17:48:08,118 - INFO - DEBUG:
 nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 17:48:08,118 - INFO - nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 17:48:08,118 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:48:08,118 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 17:48:08,118 - INFO - Using all 128 points as seeds
2025-08-26 17:48:08,118 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:48:08,118 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 17:48:08,118 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 17:48:08,119 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756255688.239612 3439900 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756255688.240906 3439900 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 17:48:08,270 - INFO - neighbor-sampled diffraction shape
 (128, 64, 64, 1)2025-08-26 17:48:08,270 - INFO - (128, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 17:48:08,278 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 17:48:08,688 - INFO - INFO:
 None2025-08-26 17:48:08,688 - INFO - None

<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 17:48:08,688 - INFO - <PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 17:48:08,689 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run...
2025-08-26 17:48:08,689 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
Model: "functional"
2025-08-26 17:48:09,483 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 17:48:09,505 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 17:48:09,506 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 17:48:09,506 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:48:09,506 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 17:48:09,506 - INFO - None

2025-08-26 17:48:09.506648: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:48:09.506664: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756255689.506679 3439900 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756255689.524071 3439900 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:48:09.524161: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756255689.524235 3439900 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:48:09,674 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:48:09,675 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:48:10,182 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
2025-08-26 17:48:10,183 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1...
2025-08-26 17:48:10,183 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/baseline_model.h5
2025-08-26 17:48:10,282 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 17:48:10,287 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 17:48:10,289 - INFO - Loaded Pty-chi (ePIE) reconstruction: (197, 279) (complex64)
2025-08-26 17:48:10,289 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 17:48:10,289 - INFO - Pty-chi (ePIE) computation time: 13.02s
2025-08-26 17:48:10,289 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756255691.409976 3440044 service.cc:152] XLA service 0x7a2748004310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756255691.409996 3440044 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:48:11.496216: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756255691.653283 3440044 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756255693.024353 3440044 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m8s[0m 3s/step2025-08-26 17:48:13,032 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m8s[0m 3s/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 10ms/step
2025-08-26 17:48:13,061 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 10ms/step
2025-08-26 17:48:13,074 - INFO - PtychoPINN inference completed in 2.79s
2025-08-26 17:48:13,074 - INFO - Reassembling PtychoPINN patches...
2025-08-26 17:48:14,599 - INFO - Running inference with Baseline model...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 583ms/step2025-08-26 17:48:15,198 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 583ms/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
2025-08-26 17:48:15,221 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step
2025-08-26 17:48:15,233 - INFO - Baseline inference completed in 0.63s
2025-08-26 17:48:15,237 - INFO - Reassembling baseline patches...
2025-08-26 17:48:15,240 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 17:48:15,294 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions.npz
2025-08-26 17:48:15,294 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_metadata.txt
2025-08-26 17:48:15,294 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 17:48:15,294 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 17:48:15,294 - INFO - Ground truth original shape: (232, 232)
2025-08-26 17:48:15,294 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:48:15,294 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 17:48:15,294 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 17:48:15,294 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 17:48:15,294 - INFO - Final aligned shape: (101, 185)
2025-08-26 17:48:15,294 - INFO - --- Alignment complete ---
2025-08-26 17:48:15,295 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:48:15,295 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 17:48:15,295 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 17:48:15,295 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 17:48:15,295 - INFO - Final aligned shape: (101, 185)
2025-08-26 17:48:15,295 - INFO - --- Alignment complete ---
2025-08-26 17:48:15,295 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:48:15,295 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 17:48:15,295 - INFO - Initial shapes: Recon=(197, 279), Cropped GT=(101, 185)
2025-08-26 17:48:15,295 - INFO - Center-cropping from (197, 279) to (101, 185)
2025-08-26 17:48:15,295 - INFO - Final aligned shape: (101, 185)
2025-08-26 17:48:15,295 - INFO - --- Alignment complete ---
2025-08-26 17:48:15,295 - INFO - Skipping registration (--skip-registration specified)
2025-08-26 17:48:15,295 - INFO - Final evaluation shapes: PINN (101, 185), Baseline (101, 185), Pty-chi (ePIE) (101, 185), GT (101, 185)
Amplitude normalization scale factor: 0.7767102025-08-26 17:48:15,298 - INFO - Amplitude normalization scale factor: 0.776710

mean scale adjustment:2025-08-26 17:48:15,298 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,298 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,298 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,298 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 17:48:15,299 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.725304, std=0.210998, shape=(97, 181, 1)2025-08-26 17:48:15,299 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.725304, std=0.210998, shape=(97, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 17:48:15,299 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.245952, shape=(97, 181)2025-08-26 17:48:15,299 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.245952, shape=(97, 181)

performed by index method2025-08-26 17:48:15,301 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,303 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,305 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:48:15,307 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,307 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,307 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,307 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 17:48:15,307 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

performed by index method2025-08-26 17:48:15,311 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,313 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,315 - INFO - performed by index method

2025-08-26 17:48:15,317 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.311, phase=0.624, MS-SSIM: amp=0.278, phase=0.402
Amplitude normalization scale factor: 1.0550802025-08-26 17:48:15,319 - INFO - Amplitude normalization scale factor: 1.055080

mean scale adjustment:2025-08-26 17:48:15,319 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,319 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,319 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,319 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 17:48:15,319 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.533941, std=0.149794, shape=(97, 181, 1)2025-08-26 17:48:15,320 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.533941, std=0.149794, shape=(97, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 17:48:15,320 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.019470, shape=(97, 181)2025-08-26 17:48:15,320 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.019470, shape=(97, 181)

performed by index method2025-08-26 17:48:15,321 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,323 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,324 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:48:15,326 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,326 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,326 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,326 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 17:48:15,326 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

performed by index method2025-08-26 17:48:15,330 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,332 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,334 - INFO - performed by index method

2025-08-26 17:48:15,336 - INFO - Baseline evaluation complete. SSIM: amp=0.061, phase=0.524, MS-SSIM: amp=0.094, phase=0.024
Amplitude normalization scale factor: 0.4797892025-08-26 17:48:15,338 - INFO - Amplitude normalization scale factor: 0.479789

mean scale adjustment:2025-08-26 17:48:15,338 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,338 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,338 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,338 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 17:48:15,339 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.174164, std=0.335448, shape=(97, 181, 1)2025-08-26 17:48:15,339 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.174164, std=0.335448, shape=(97, 181, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 17:48:15,339 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.281595, shape=(97, 181)2025-08-26 17:48:15,339 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.281595, shape=(97, 181)

performed by index method2025-08-26 17:48:15,340 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,342 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,344 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:48:15,345 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,345 - INFO - 1

mean scale adjustment:2025-08-26 17:48:15,346 - INFO - mean scale adjustment:
 12025-08-26 17:48:15,346 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 17:48:15,346 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
2025-08-26 17:48:15,347 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
performed by index method2025-08-26 17:48:15,350 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,352 - INFO - performed by index method

performed by index method2025-08-26 17:48:15,354 - INFO - performed by index method

2025-08-26 17:48:15,355 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=-0.079, phase=0.224, MS-SSIM: amp=nan, phase=nan
2025-08-26 17:48:15,357 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 17:48:15,357 - INFO - --- Comparison Metrics ---

         model             metric  amplitude     phase     value
    PtychoPINN                mae   0.091572  0.206764       NaN
    PtychoPINN                mse   0.027660  0.071230       NaN
    PtychoPINN               psnr  63.712251 59.604187       NaN
    PtychoPINN               ssim   0.311014  0.624030       NaN
    PtychoPINN            ms_ssim   0.278280  0.402074       NaN
    PtychoPINN              frc50   2.000000  1.000000       NaN
      Baseline                mae   0.088256  0.242961       NaN
      Baseline                mse   0.027669  0.074981       NaN
      Baseline               psnr  63.710916 59.381279       NaN
      Baseline               ssim   0.061324  0.523762       NaN
      Baseline            ms_ssim   0.094202  0.023777       NaN
      Baseline              frc50   2.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.125722  0.331920       NaN
Pty-chi (ePIE)                mse   0.029127  0.171540       NaN
Pty-chi (ePIE)               psnr  63.487831 55.787147       NaN
Pty-chi (ePIE)               ssim  -0.078708  0.224346       NaN
Pty-chi (ePIE)            ms_ssim        NaN       NaN       NaN
Pty-chi (ePIE)              frc50   1.000000  1.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  2.785268
      Baseline computation_time_s        NaN       NaN  0.633507
Pty-chi (ePIE) computation_time_s        NaN       NaN 13.0190522025-08-26 17:48:15,358 - INFO - model             metric  amplitude     phase     value
    PtychoPINN                mae   0.091572  0.206764       NaN
    PtychoPINN                mse   0.027660  0.071230       NaN
    PtychoPINN               psnr  63.712251 59.604187       NaN
    PtychoPINN               ssim   0.311014  0.624030       NaN
    PtychoPINN            ms_ssim   0.278280  0.402074       NaN
    PtychoPINN              frc50   2.000000  1.000000       NaN
      Baseline                mae   0.088256  0.242961       NaN
      Baseline                mse   0.027669  0.074981       NaN
      Baseline               psnr  63.710916 59.381279       NaN
      Baseline               ssim   0.061324  0.523762       NaN
      Baseline            ms_ssim   0.094202  0.023777       NaN
      Baseline              frc50   2.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.125722  0.331920       NaN
Pty-chi (ePIE)                mse   0.029127  0.171540       NaN
Pty-chi (ePIE)               psnr  63.487831 55.787147       NaN
Pty-chi (ePIE)               ssim  -0.078708  0.224346       NaN
Pty-chi (ePIE)            ms_ssim        NaN       NaN       NaN
Pty-chi (ePIE)              frc50   1.000000  1.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  2.785268
      Baseline computation_time_s        NaN       NaN  0.633507
Pty-chi (ePIE) computation_time_s        NaN       NaN 13.019052

2025-08-26 17:48:15,359 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_frc_curves.csv
2025-08-26 17:48:15,360 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_frc_curves.csv
2025-08-26 17:48:15,360 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 17:48:15,392 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned.npz
2025-08-26 17:48:15,392 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 17:48:15,392 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 17:48:15,429 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.000, 0.858) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,430 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.000, 0.576) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,430 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.759, 0.000) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,431 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.000, 0.075) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,431 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.843, 1.774) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,431 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.453, 0.278) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,440 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.501, 0.619) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:15,440 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.464, 0.271) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:48:16,007 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_plot.png
2025-08-26 17:48:16,007 - INFO - 
Comparison complete!
2025-08-26 17:48:16,007 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1
[2025-08-26 17:48:17] SUCCESS: Model comparison (train_size=128, trial=1)
[2025-08-26 17:48:17] Completed comparisons for train_size=128
[2025-08-26 17:48:17] Model comparison phase completed
[2025-08-26 17:48:17] === STEP 4: Results Aggregation ===
[2025-08-26 17:48:17] EXECUTING: PSNR phase generalization plot
[2025-08-26 17:48:17] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
17:48:17 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:17 - INFO - Analyzing psnr_phase
17:48:17 - INFO - Discovered 1 comparison files
17:48:17 - INFO - Single-trial data detected - using legacy aggregation
17:48:17 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:17 - INFO - Made 1 out-of-range replacements with NaN
17:48:17 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:17 - INFO - Loaded 3 trial records
17:48:17 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:17 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:17 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:17 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:17 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:17 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:17 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:17 - INFO - NaN exclusion summary:
17:48:17 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:17 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:17 - INFO - Extracted 1 data points for psnr_phase (using mean)
17:48:17 - WARNING - Missing expected model types: {'baseline'}
17:48:17 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
17:48:17 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:17 - INFO - Processing complete!
17:48:17 - INFO - Outputs:
17:48:17 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
17:48:17 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:17 - INFO - Summary: 1 models, 1 training sizes
17:48:17 - INFO - Training sizes: [np.int64(128)]
17:48:17 - INFO - Model types: ['pinn']
[2025-08-26 17:48:17] SUCCESS: PSNR phase generalization plot
[2025-08-26 17:48:17] EXECUTING: FRC amplitude generalization plot
[2025-08-26 17:48:17] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
17:48:18 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:18 - INFO - Analyzing frc50_amp
17:48:18 - INFO - Discovered 1 comparison files
17:48:18 - INFO - Single-trial data detected - using legacy aggregation
17:48:18 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:18 - INFO - Made 1 out-of-range replacements with NaN
17:48:18 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:18 - INFO - Loaded 3 trial records
17:48:18 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:18 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:18 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:18 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:18 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:18 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:18 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:18 - INFO - NaN exclusion summary:
17:48:18 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:18 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:18 - INFO - Extracted 1 data points for frc50_amp (using mean)
17:48:18 - WARNING - Missing expected model types: {'baseline'}
17:48:18 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
17:48:18 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:18 - INFO - Processing complete!
17:48:18 - INFO - Outputs:
17:48:18 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
17:48:18 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:18 - INFO - Summary: 1 models, 1 training sizes
17:48:18 - INFO - Training sizes: [np.int64(128)]
17:48:18 - INFO - Model types: ['pinn']
[2025-08-26 17:48:18] SUCCESS: FRC amplitude generalization plot
[2025-08-26 17:48:18] EXECUTING: MAE amplitude generalization plot
[2025-08-26 17:48:18] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
17:48:18 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:18 - INFO - Analyzing mae_amp
17:48:18 - INFO - Discovered 1 comparison files
17:48:18 - INFO - Single-trial data detected - using legacy aggregation
17:48:18 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:18 - INFO - Made 1 out-of-range replacements with NaN
17:48:18 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:18 - INFO - Loaded 3 trial records
17:48:18 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:18 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:18 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:18 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:18 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:18 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:18 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:18 - INFO - NaN exclusion summary:
17:48:18 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:18 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:18 - INFO - Extracted 1 data points for mae_amp (using mean)
17:48:18 - WARNING - Missing expected model types: {'baseline'}
17:48:19 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
17:48:19 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:19 - INFO - Processing complete!
17:48:19 - INFO - Outputs:
17:48:19 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
17:48:19 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:19 - INFO - Summary: 1 models, 1 training sizes
17:48:19 - INFO - Training sizes: [np.int64(128)]
17:48:19 - INFO - Model types: ['pinn']
[2025-08-26 17:48:19] SUCCESS: MAE amplitude generalization plot
[2025-08-26 17:48:19] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 17:48:19] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
17:48:19 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:19 - INFO - Analyzing ssim_amp
17:48:19 - INFO - Discovered 1 comparison files
17:48:19 - INFO - Single-trial data detected - using legacy aggregation
17:48:19 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:19 - INFO - Made 1 out-of-range replacements with NaN
17:48:19 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:19 - INFO - Loaded 3 trial records
17:48:19 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:19 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:19 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:19 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:19 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:19 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:19 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:19 - INFO - NaN exclusion summary:
17:48:19 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:19 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:19 - INFO - Extracted 1 data points for ssim_amp (using mean)
17:48:19 - WARNING - Missing expected model types: {'baseline'}
17:48:19 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
17:48:19 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:19 - INFO - Processing complete!
17:48:19 - INFO - Outputs:
17:48:19 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
17:48:19 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:19 - INFO - Summary: 1 models, 1 training sizes
17:48:19 - INFO - Training sizes: [np.int64(128)]
17:48:19 - INFO - Model types: ['pinn']
[2025-08-26 17:48:19] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 17:48:19] EXECUTING: SSIM phase generalization plot
[2025-08-26 17:48:19] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
17:48:20 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:20 - INFO - Analyzing ssim_phase
17:48:20 - INFO - Discovered 1 comparison files
17:48:20 - INFO - Single-trial data detected - using legacy aggregation
17:48:20 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:20 - INFO - Made 1 out-of-range replacements with NaN
17:48:20 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:20 - INFO - Loaded 3 trial records
17:48:20 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:20 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:20 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:20 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:20 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:20 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:20 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:20 - INFO - NaN exclusion summary:
17:48:20 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:20 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:20 - INFO - Extracted 1 data points for ssim_phase (using mean)
17:48:20 - WARNING - Missing expected model types: {'baseline'}
17:48:20 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
17:48:20 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:20 - INFO - Processing complete!
17:48:20 - INFO - Outputs:
17:48:20 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
17:48:20 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:20 - INFO - Summary: 1 models, 1 training sizes
17:48:20 - INFO - Training sizes: [np.int64(128)]
17:48:20 - INFO - Model types: ['pinn']
[2025-08-26 17:48:20] SUCCESS: SSIM phase generalization plot
[2025-08-26 17:48:20] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 17:48:20] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
17:48:21 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:21 - INFO - Analyzing ms_ssim_amp
17:48:21 - INFO - Discovered 1 comparison files
17:48:21 - INFO - Single-trial data detected - using legacy aggregation
17:48:21 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:21 - INFO - Made 1 out-of-range replacements with NaN
17:48:21 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:21 - INFO - Loaded 3 trial records
17:48:21 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:21 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:21 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:21 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:21 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:21 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:21 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:21 - INFO - NaN exclusion summary:
17:48:21 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:21 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:21 - INFO - Extracted 1 data points for ms_ssim_amp (using mean)
17:48:21 - WARNING - Missing expected model types: {'baseline'}
17:48:21 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
17:48:21 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:21 - INFO - Processing complete!
17:48:21 - INFO - Outputs:
17:48:21 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
17:48:21 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:21 - INFO - Summary: 1 models, 1 training sizes
17:48:21 - INFO - Training sizes: [np.int64(128)]
17:48:21 - INFO - Model types: ['pinn']
[2025-08-26 17:48:21] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 17:48:21] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 17:48:21] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
17:48:21 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
17:48:21 - INFO - Analyzing ms_ssim_phase
17:48:21 - INFO - Discovered 1 comparison files
17:48:21 - INFO - Single-trial data detected - using legacy aggregation
17:48:21 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
17:48:21 - INFO - Made 1 out-of-range replacements with NaN
17:48:21 - INFO - Total NaN values in data: 9 (1 new, 8 preserved)
17:48:21 - INFO - Loaded 3 trial records
17:48:21 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
17:48:21 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
17:48:21 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
17:48:21 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
17:48:21 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
17:48:21 - INFO - Computed statistics for 1 (train_size, model_type) combinations
17:48:21 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
17:48:21 - INFO - NaN exclusion summary:
17:48:21 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
17:48:21 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
17:48:21 - INFO - Extracted 1 data points for ms_ssim_phase (using mean)
17:48:21 - WARNING - Missing expected model types: {'baseline'}
17:48:21 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
17:48:21 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
17:48:21 - INFO - Processing complete!
17:48:21 - INFO - Outputs:
17:48:21 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
17:48:21 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
17:48:21 - INFO - Summary: 1 models, 1 training sizes
17:48:21 - INFO - Training sizes: [np.int64(128)]
17:48:21 - INFO - Model types: ['pinn']
[2025-08-26 17:48:22] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 17:48:22] Results aggregation completed
[2025-08-26 17:48:22] === Generating Summary Report ===
[2025-08-26 17:48:22] Summary report generated: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 17:48:22] === Study Completed Successfully ===
[2025-08-26 17:48:22] Training sizes tested: 1
[2025-08-26 17:48:22] Trials per size: 1
[2025-08-26 17:48:22] Total trials completed: 1
[2025-08-26 17:48:22] Total runtime: 00:01:31
[2025-08-26 17:48:22] Results directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 17:48:22] Summary report: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 21:41:41] === Starting Complete Generalization Study ===
[2025-08-26 21:41:41] Training sizes: 128
[2025-08-26 21:41:41] Number of trials per size: 1
[2025-08-26 21:41:41] Output directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 21:41:41] Total training runs planned: 2
[2025-08-26 21:41:41] Validating environment...
[2025-08-26 21:41:41] Environment validation passed
[2025-08-26 21:41:41] Configuration saved to: 3way_synthetic_ptychi_1e4_128/study_config.txt
[2025-08-26 21:41:41] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 21:41:41] === STEP 2: Model Training ===
[2025-08-26 21:41:41] Training models sequentially with 1 trials per training size
[2025-08-26 21:41:41] Starting training for train_size=128, test_size=128 (1 trials)
[2025-08-26 21:41:41] Training models for train_size=128, test_size=128 (Trial 1/1)
[2025-08-26 21:41:41] EXECUTING: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 21:41:41] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 21:41:42.108700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269702.120423 3481074 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269702.124211 3481074 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269702.135333 3481074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269702.135343 3481074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269702.135344 3481074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269702.135345 3481074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:41:42.138447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:41:44,965 - INFO - Configuration setup complete
2025-08-26 21:41:44,965 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 21:41:44,965 - INFO - Parameter interpretation: --n-images=128 refers to individual images (gridsize=1)
2025-08-26 21:41:44,965 - INFO - Starting training with n_images=128, stitching=disabled
2025-08-26 21:41:44,965 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 21:41:45,291 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
2025-08-26 21:41:45,614 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 21:41:45,614 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 21:41:45,919 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
2025-08-26 21:41:45,920 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/test.npz
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 21:41:45,920 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:41:45,920 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:41:45,920 - INFO - Using all 128 points as seeds
2025-08-26 21:41:45,920 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:41:45,920 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:41:45,920 - INFO - Generated 128 groups efficiently
I0000 00:00:1756269706.051057 3481074 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269706.052424 3481074 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 21:41:46,481 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:41:46,481 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 21:41:46,481 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 21:41:46,481 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:41:46,481 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:41:46,481 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1243.180 global_offsets=(128, 1, 2, 1) mean=132.089 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”
â”ƒ Layer (type)        â”ƒ O
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”
â”‚ input (InputLayer)  â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ intensity_scaler    â”‚ (
â”‚ (IntensityScaler)   â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d (Conv2D)     â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_1 (Conv2D)   â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ max_pooling2d       â”‚ (
â”‚ (MaxPooling2D)      â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_2 (Conv2D)   â”‚ (
â”‚                     â”‚ 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_3 (Conv2D)   â”‚ (
â”‚                     â”‚ 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ max_pooling2d_1     â”‚ (
â”‚ (MaxPooling2D)      â”‚ 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_4 (Conv2D)   â”‚ (
â”‚                     â”‚ 2
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_5 (Conv2D)   â”‚ (
â”‚                     â”‚ 2
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ max_pooling2d_2     â”‚ (
â”‚ (MaxPooling2D)      â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_8 (Conv2D)   â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_16 (Conv2D)  â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_9 (Conv2D)   â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_17 (Conv2D)  â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d       â”‚ (
â”‚ (UpSampling2D)      â”‚ 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d_3     â”‚ (
â”‚ (UpSampling2D)      â”‚ 1
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_10 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_18 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_11 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_19 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d_1     â”‚ (
â”‚ (UpSampling2D)      â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d_4     â”‚ (
â”‚ (UpSampling2D)      â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ get_item_1          â”‚ (
â”‚ (GetItem)           â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ get_item_3          â”‚ (
â”‚ (GetItem)           â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_12 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_20 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_13 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_21 (Conv2D)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d_2     â”‚ (
â”‚ (UpSampling2D)      â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ up_sampling2d_5     â”‚ (
â”‚ (UpSampling2D)      â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ get_item (GetItem)  â”‚ (
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_7 (Conv2D)   â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ get_item_2          â”‚ (
â”‚ (GetItem)           â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_15 (Conv2D)  â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_6 (Conv2D)   â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ silu (Silu)         â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ conv2d_14 (Conv2D)  â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ silu_1 (Silu)       â”‚ (
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ amp                 â”‚ (
â”‚ (ActivationLayer)   â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ center_mask_layer   â”‚ (
â”‚ (CenterMaskLayer)   â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ phi                 â”‚ (
â”‚ (ActivationLayer)   â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ center_mask_layer_1 â”‚ (
â”‚ (CenterMaskLayer)   â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ amp_padded          â”‚ (
â”‚ (ZeroPadding2D)     â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ multiply (Multiply) â”‚ (
â”‚                     â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ phase_padded        â”‚ (
â”‚ (ZeroPadding2D)     â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ multiply_1          â”‚ (
â”‚ (Multiply)          â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ add (Add)           â”‚ (
â”‚                     â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ add_1 (Add)         â”‚ (
â”‚                     â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ obj                 â”‚ (
â”‚ (CombineComplexLayâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ input_positions     â”‚ (
â”‚ (InputLayer)        â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ padded_obj_2        â”‚ (
â”‚ (ReassemblePatchesâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ padded_objs_with_oâ€¦ â”‚ (
â”‚ (ExtractPatchesPosâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ probe_illumination  â”‚ [
â”‚ (ProbeIllumination) â”‚ 1
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ pred_amplitude      â”‚ [
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1
â”‚                     â”‚ 6
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ pred_diff_channels  â”‚ (
â”‚ (FlatToChannelLayeâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ intensity_scaler_iâ€¦ â”‚ (
â”‚ (IntensityScaler_iâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ trimmed_obj         â”‚ (
â”‚ (TrimReconstructioâ€¦ â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€
â”‚ pred_intensity      â”‚ (
â”‚ (SquareLayer)       â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€
 Total params: 2,331,772 
(8.90 MB)
 Trainable params: 
2,331,772 (8.90 MB)
 Non-trainable params: 0 
(0.00 B)
2025-08-26 21:41:47.153809: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 21:41:47.153825: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269707.153841 3481074 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756269707.171318 3481074 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 21:41:47.171396: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756269707.171473 3481074 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756269707.890512 3481074 service.cc:152] XLA service 0x3910b480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269707.890530 3481074 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:41:47.920624: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269707.939450 3481074 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269708.486545 3481074 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 21:41:49,011 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 21:41:51,007 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 21:41:54.925292: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:41:54.927392: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:41:54.948206: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 21:41:55.201423: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m51s[0m 7s/step - intensity_scaler_inv_loss: 0.6402 - loss: 0.5706 - pred_intensity_loss: 0.5706 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 2.8922 - loss: 43.1244 - pred_intensity_loss: 43.1244 - trimmed_obj_loss: 0.0000e+002025-08-26 21:41:57.500207: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:41:57.521603: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:41:57.571278: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 21:41:57.810459: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 354ms/step - intensity_scaler_inv_loss: 2.5458 - loss: 36.3760 - pred_intensity_loss: 36.2260 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 21:41:58,767 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m11s[0m 534ms/step - intensity_scaler_inv_loss: 1.8036 - loss: 22.6491 - pred_intensity_loss: 21.4495 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.7031 - val_loss: 0.3815 - val_pred_intensity_loss: 0.3815 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.7018 - loss: 0.3652 - pred_intensity_loss: 0.3652 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.7534 - loss: 0.4646 - pred_intensity_loss: 0.4646 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.6529 - loss: 0.2430 - pred_intensity_loss: 0.2290 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5317 - val_loss: -0.0570 - val_pred_intensity_loss: -0.0570 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5242 - loss: -0.0686 - pred_intensity_loss: -0.0686 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5339 - loss: -0.1200 - pred_intensity_loss: -0.1200 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.5538 - loss: -0.1424 - pred_intensity_loss: -0.1489 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5137 - val_loss: -0.2072 - val_pred_intensity_loss: -0.2072 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5176 - loss: -0.2530 - pred_intensity_loss: -0.2530 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5074 - loss: -0.2491 - pred_intensity_loss: -0.2491 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5098 - loss: -0.2358 - pred_intensity_loss: -0.2338 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5312 - val_loss: -0.1933 - val_pred_intensity_loss: -0.1933 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.5248 - loss: -0.1955 - pred_intensity_loss: -0.1955 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5215 - loss: -0.2248 - pred_intensity_loss: -0.2248 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5154 - loss: -0.2400 - pred_intensity_loss: -0.2433 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5055 - val_loss: -0.2200 - val_pred_intensity_loss: -0.2200 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.5165 - loss: -0.2206 - pred_intensity_loss: -0.2206 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5087 - loss: -0.2412 - pred_intensity_loss: -0.2412 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5060 - loss: -0.2524 - pred_intensity_loss: -0.2533 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5115 - val_loss: -0.2196 - val_pred_intensity_loss: -0.2196 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5038 - loss: -0.2661 - pred_intensity_loss: -0.2661 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5036 - loss: -0.2542 - pred_intensity_loss: -0.2542 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5022 - loss: -0.2564 - pred_intensity_loss: -0.2599 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5073 - val_loss: -0.2261 - val_pred_intensity_loss: -0.2261 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.5040 - loss: -0.2429 - pred_intensity_loss: -0.2429 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5039 - loss: -0.2595 - pred_intensity_loss: -0.2595 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5031 - loss: -0.2595 - pred_intensity_loss: -0.2625 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5042 - val_loss: -0.2306 - val_pred_intensity_loss: -0.2306 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5046 - loss: -0.2422 - pred_intensity_loss: -0.2422 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5019 - loss: -0.2582 - pred_intensity_loss: -0.2582 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5008 - loss: -0.2639 - pred_intensity_loss: -0.2632 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5029 - val_loss: -0.2374 - val_pred_intensity_loss: -0.2374 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5084 - loss: -0.2442 - pred_intensity_loss: -0.2442 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5037 - loss: -0.2647 - pred_intensity_loss: -0.2647 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5006 - loss: -0.2696 - pred_intensity_loss: -0.2665 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5014 - val_loss: -0.2473 - val_pred_intensity_loss: -0.2473 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5003 - loss: -0.2707 - pred_intensity_loss: -0.2707 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5008 - loss: -0.2604 - pred_intensity_loss: -0.2604 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5001 - loss: -0.2748 - pred_intensity_loss: -0.2765 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4994 - val_loss: -0.2512 - val_pred_intensity_loss: -0.2512 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4868 - loss: -0.2686 - pred_intensity_loss: -0.2686 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4948 - loss: -0.2764 - pred_intensity_loss: -0.2764 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5001 - loss: -0.2765 - pred_intensity_loss: -0.2777 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5048 - val_loss: -0.2537 - val_pred_intensity_loss: -0.2537 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4998 - loss: -0.2906 - pred_intensity_loss: -0.2906 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4991 - loss: -0.2804 - pred_intensity_loss: -0.2804 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4998 - loss: -0.2782 - pred_intensity_loss: -0.2792 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4991 - val_loss: -0.2548 - val_pred_intensity_loss: -0.2548 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5033 - loss: -0.2681 - pred_intensity_loss: -0.2681 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5026 - loss: -0.2626 - pred_intensity_loss: -0.2626 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4992 - loss: -0.2803 - pred_intensity_loss: -0.2801 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4999 - val_loss: -0.2555 - val_pred_intensity_loss: -0.2555 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4971 - loss: -0.2656 - pred_intensity_loss: -0.2656 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5006 - loss: -0.2693 - pred_intensity_loss: -0.2693 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5006 - loss: -0.2812 - pred_intensity_loss: -0.2792 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5003 - val_loss: -0.2576 - val_pred_intensity_loss: -0.2576 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5007 - loss: -0.2927 - pred_intensity_loss: -0.2927 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5004 - loss: -0.2842 - pred_intensity_loss: -0.2842 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4987 - loss: -0.2828 - pred_intensity_loss: -0.2807 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4970 - val_loss: -0.2633 - val_pred_intensity_loss: -0.2633 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4955 - loss: -0.3009 - pred_intensity_loss: -0.3009 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4941 - loss: -0.2941 - pred_intensity_loss: -0.2941 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4964 - loss: -0.2881 - pred_intensity_loss: -0.2896 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4931 - val_loss: -0.2682 - val_pred_intensity_loss: -0.2682 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4996 - loss: -0.2637 - pred_intensity_loss: -0.2637 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4961 - loss: -0.2739 - pred_intensity_loss: -0.2739 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4935 - loss: -0.2973 - pred_intensity_loss: -0.3009 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4867 - val_loss: -0.2894 - val_pred_intensity_loss: -0.2894 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.5008 - loss: -0.3211 - pred_intensity_loss: -0.3211 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4897 - loss: -0.3246 - pred_intensity_loss: -0.3246 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4879 - loss: -0.3146 - pred_intensity_loss: -0.3167 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4805 - val_loss: -0.3108 - val_pred_intensity_loss: -0.3108 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4703 - loss: -0.2921 - pred_intensity_loss: -0.2921 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4766 - loss: -0.3133 - pred_intensity_loss: -0.3133 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4815 - loss: -0.3265 - pred_intensity_loss: -0.3285 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4911 - val_loss: -0.3066 - val_pred_intensity_loss: -0.3066 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5132 - loss: -0.2866 - pred_intensity_loss: -0.2866 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4933 - loss: -0.3104 - pred_intensity_loss: -0.3104 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4826 - loss: -0.3268 - pred_intensity_loss: -0.3255 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4785 - val_loss: -0.3257 - val_pred_intensity_loss: -0.3257 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4809 - loss: -0.3430 - pred_intensity_loss: -0.3430 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4780 - loss: -0.3313 - pred_intensity_loss: -0.3313 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4782 - loss: -0.3419 - pred_intensity_loss: -0.3390 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4702 - val_loss: -0.3374 - val_pred_intensity_loss: -0.3374 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4801 - loss: -0.3800 - pred_intensity_loss: -0.3800 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4767 - loss: -0.3589 - pred_intensity_loss: -0.3589 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4754 - loss: -0.3555 - pred_intensity_loss: -0.3566 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4665 - val_loss: -0.3371 - val_pred_intensity_loss: -0.3371 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4726 - loss: -0.4098 - pred_intensity_loss: -0.4098 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4785 - loss: -0.3603 - pred_intensity_loss: -0.3603 - trimmed_obj_loss: 0.0000e+00
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4814 - loss: -0.3281 - pred_intensity_loss: -0.3277 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4837 - val_loss: -0.3102 - val_pred_intensity_loss: -0.3102 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4929 - loss: -0.3416 - pred_intensity_loss: -0.3416 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4892 - loss: -0.3428 - pred_intensity_loss: -0.3428 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4812 - loss: -0.3305 - pred_intensity_loss: -0.3321 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4747 - val_loss: -0.3246 - val_pred_intensity_loss: -0.3246 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4655 - loss: -0.3385 - pred_intensity_loss: -0.3385 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4741 - loss: -0.3406 - pred_intensity_loss: -0.3406 - trimmed_obj_loss: 0.0000e+00
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4759 - loss: -0.3425 - pred_intensity_loss: -0.3431 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4706 - val_loss: -0.3350 - val_pred_intensity_loss: -0.3350 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 946ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 9ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 524288 into shape (6,6,64,64,1)
2025-08-26 21:42:05,308 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 21:42:06,715 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
[2025-08-26 21:42:08] SUCCESS: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 21:42:08] EXECUTING: Baseline training (n_images=128, trial=1)
[2025-08-26 21:42:08] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 21:42:08.313635: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269728.325516 3485549 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269728.329311 3485549 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269728.340480 3485549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269728.340490 3485549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269728.340491 3485549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269728.340493 3485549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:42:08.343348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:42:10,941 - INFO - Configuration setup complete
2025-08-26 21:42:10,941 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 21:42:10,942 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 21:42:10,942 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 21:42:10,942 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.42.10_baseline_gs1/
2025-08-26 21:42:10,942 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756269731.056446 3485549 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269731.057668 3485549 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 21:42:11,092 - INFO - 
[2/6] Loading data...
2025-08-26 21:42:11,092 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 21:42:11,092 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 21:42:11,415 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
2025-08-26 21:42:11,415 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 21:42:11,717 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 21:42:11,717 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:42:11,717 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:42:11,718 - INFO - Using all 128 points as seeds
2025-08-26 21:42:11,718 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:42:11,718 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:42:11,718 - INFO - Generated 128 groups efficiently
2025-08-26 21:42:12,086 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:42:12,086 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 21:42:12,086 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 21:42:12,086 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:42:12,086 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:42:12,086 - INFO - Generated 128 groups efficiently
2025-08-26 21:42:12,098 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-08-26 21:42:12,098 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 21:42:12,100 - INFO - Final training input shape: (128, 64, 64, 1)
2025-08-26 21:42:12,100 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 21:42:12,100 - INFO - Training with 128 images
DEBUG: Setting timestamp to 08/26/2025, 21:42:10 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.42.10_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
timestamp: 08/26/2025, 21:42:10
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1297.438 global_offsets=(128, 1, 2, 1) mean=136.741 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269734.928029 3485689 service.cc:152] XLA service 0x74456400fa20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269734.928051 3485689 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:42:15.000266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269735.416871 3485689 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269738.381970 3485689 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m39s[0m 6s/step - conv2d_12_loss: 0.5634 - conv2d_19_loss: 0.2101 - loss: 0.7735[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.5471 - conv2d_19_loss: 0.2512 - loss: 0.7983[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 419ms/step - conv2d_12_loss: 0.5599 - conv2d_19_loss: 0.2474 - loss: 0.8081[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 537ms/step - conv2d_12_loss: 0.5917 - conv2d_19_loss: 0.2342 - loss: 0.8326 - val_conv2d_12_loss: 0.5013 - val_conv2d_19_loss: 0.2311 - val_loss: 0.7324 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.5028 - conv2d_19_loss: 0.2199 - loss: 0.7227[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.4962 - conv2d_19_loss: 0.2179 - loss: 0.7141[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.4719 - conv2d_19_loss: 0.2123 - loss: 0.6885 - val_conv2d_12_loss: 0.3324 - val_conv2d_19_loss: 0.2294 - val_loss: 0.5618 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.3337 - conv2d_19_loss: 0.2062 - loss: 0.5399[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2893 - conv2d_19_loss: 0.2092 - loss: 0.4985[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.2564 - conv2d_19_loss: 0.2130 - loss: 0.4726 - val_conv2d_12_loss: 0.1236 - val_conv2d_19_loss: 0.2288 - val_loss: 0.3524 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.1239 - conv2d_19_loss: 0.2078 - loss: 0.3317[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.1365 - conv2d_19_loss: 0.2126 - loss: 0.3491[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.1231 - conv2d_19_loss: 0.2125 - loss: 0.3383 - val_conv2d_12_loss: 0.0893 - val_conv2d_19_loss: 0.2295 - val_loss: 0.3188 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0886 - conv2d_19_loss: 0.2186 - loss: 0.3072[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2161 - loss: 0.3017[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0768 - conv2d_19_loss: 0.2130 - loss: 0.2896 - val_conv2d_12_loss: 0.0675 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2959 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0653 - conv2d_19_loss: 0.2057 - loss: 0.2711[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0634 - conv2d_19_loss: 0.2106 - loss: 0.2740[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0613 - conv2d_19_loss: 0.2129 - loss: 0.2737 - val_conv2d_12_loss: 0.0581 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2868 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0562 - conv2d_19_loss: 0.2154 - loss: 0.2715[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0564 - conv2d_19_loss: 0.2147 - loss: 0.2711[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0549 - conv2d_19_loss: 0.2119 - loss: 0.2673 - val_conv2d_12_loss: 0.0548 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2832 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0522 - conv2d_19_loss: 0.2065 - loss: 0.2587[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0520 - conv2d_19_loss: 0.2088 - loss: 0.2608[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0518 - conv2d_19_loss: 0.2120 - loss: 0.2642 - val_conv2d_12_loss: 0.0521 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2806 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0511 - conv2d_19_loss: 0.2154 - loss: 0.2664[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.2109 - loss: 0.2609[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0495 - conv2d_19_loss: 0.2130 - loss: 0.2618 - val_conv2d_12_loss: 0.0497 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2781 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0491 - conv2d_19_loss: 0.2160 - loss: 0.2651[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.2129 - loss: 0.2610[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0473 - conv2d_19_loss: 0.2123 - loss: 0.2595 - val_conv2d_12_loss: 0.0475 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2759 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0450 - conv2d_19_loss: 0.2082 - loss: 0.2531[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0454 - conv2d_19_loss: 0.2120 - loss: 0.2574[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0448 - conv2d_19_loss: 0.2119 - loss: 0.2571 - val_conv2d_12_loss: 0.0451 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2733 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0439 - conv2d_19_loss: 0.2112 - loss: 0.2551[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0437 - conv2d_19_loss: 0.2140 - loss: 0.2577[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.2121 - loss: 0.2546 - val_conv2d_12_loss: 0.0432 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2716 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0434 - conv2d_19_loss: 0.2215 - loss: 0.2649[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0421 - conv2d_19_loss: 0.2158 - loss: 0.2578[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.2123 - loss: 0.2533 - val_conv2d_12_loss: 0.0424 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2705 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0405 - conv2d_19_loss: 0.2114 - loss: 0.2518[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0404 - conv2d_19_loss: 0.2127 - loss: 0.2531[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2127 - loss: 0.2524 - val_conv2d_12_loss: 0.0416 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2695 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2111 - loss: 0.2502[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2136 - loss: 0.2533[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2124 - loss: 0.2515 - val_conv2d_12_loss: 0.0411 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2691 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.2004 - loss: 0.2374[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2093 - loss: 0.2476[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2123 - loss: 0.2510 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2686 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2113 - loss: 0.2491[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2136 - loss: 0.2520[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2126 - loss: 0.2506 - val_conv2d_12_loss: 0.0406 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2684 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.2245 - loss: 0.2646[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2169 - loss: 0.2563[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2122 - loss: 0.2506 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2094 - loss: 0.2482[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2085 - loss: 0.2469[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2121 - loss: 0.2506 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2105 - loss: 0.2487[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2125 - loss: 0.2508
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2116 - loss: 0.2503 - val_conv2d_12_loss: 0.0404 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2681 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0354 - conv2d_19_loss: 0.2005 - loss: 0.2359[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2105 - loss: 0.2483[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2129 - loss: 0.2501 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 5.0000e-04
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0396 - conv2d_19_loss: 0.2138 - loss: 0.2533[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2120 - loss: 0.2505[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2116 - loss: 0.2501 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 5.0000e-04
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.2037 - loss: 0.2407[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2090 - loss: 0.2469[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2121 - loss: 0.2500 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 5.0000e-04
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2016 - loss: 0.2388[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2065 - loss: 0.2439
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2128 - loss: 0.2500 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2682 - learning_rate: 5.0000e-04
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2146 - loss: 0.2537[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2118 - loss: 0.2504[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2122 - loss: 0.2499 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 2.5000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2102 - loss: 0.2488[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2112 - loss: 0.2494
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2123 - loss: 0.2498 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 2.5000e-04
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2035 - loss: 0.2414[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2065 - loss: 0.2441[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2120 - loss: 0.2497 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.2500e-04
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2181 - loss: 0.2578[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2131 - loss: 0.2517
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2114 - loss: 0.2497 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.2500e-04
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2098 - loss: 0.2478[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2114 - loss: 0.2494[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2118 - loss: 0.2497 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0359 - conv2d_19_loss: 0.2017 - loss: 0.2376[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0372 - conv2d_19_loss: 0.2076 - loss: 0.2448[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2124 - loss: 0.2496 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2163 - loss: 0.2550[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2126 - loss: 0.2509[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2107 - loss: 0.2496 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2181 - loss: 0.2583[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2145 - loss: 0.2531[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2112 - loss: 0.2496 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2143 - loss: 0.2532[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2143 - loss: 0.2529[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2105 - loss: 0.2496 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2154 - loss: 0.2532[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2136 - loss: 0.2517[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2109 - loss: 0.2496 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2186 - loss: 0.2584[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2135 - loss: 0.2520[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2117 - loss: 0.2495 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2140 - loss: 0.2520[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2111 - loss: 0.2492[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2121 - loss: 0.2495 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0346 - conv2d_19_loss: 0.1912 - loss: 0.2259[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.2052 - loss: 0.2422[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2125 - loss: 0.2495 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2136 - loss: 0.2523[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2085 - loss: 0.2461[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2115 - loss: 0.2495 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0352 - conv2d_19_loss: 0.1993 - loss: 0.2345[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0372 - conv2d_19_loss: 0.2082 - loss: 0.2454[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2112 - loss: 0.2495 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0369 - conv2d_19_loss: 0.2081 - loss: 0.2449[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2120 - loss: 0.2499[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2113 - loss: 0.2495 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0346 - conv2d_19_loss: 0.1884 - loss: 0.2230[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0369 - conv2d_19_loss: 0.2032 - loss: 0.2401[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2124 - loss: 0.2495 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 1.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2129 - loss: 0.2508[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2145 - loss: 0.2532[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2111 - loss: 0.2495 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2254 - loss: 0.2641[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2177 - loss: 0.2563[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2112 - loss: 0.2494 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0365 - conv2d_19_loss: 0.2018 - loss: 0.2383[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2097 - loss: 0.2475[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2118 - loss: 0.2494 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2076 - loss: 0.2448[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2135 - loss: 0.2518[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2114 - loss: 0.2494 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.2107 - loss: 0.2470[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0371 - conv2d_19_loss: 0.2097 - loss: 0.2469[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2107 - loss: 0.2494 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0372 - conv2d_19_loss: 0.2060 - loss: 0.2432[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2094 - loss: 0.2472[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2126 - loss: 0.2493 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.2031 - loss: 0.2392[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2086 - loss: 0.2459[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2113 - loss: 0.2493 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2091 - loss: 0.2466[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2108 - loss: 0.2482[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2114 - loss: 0.2493 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2680 - learning_rate: 1.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2150 - loss: 0.2527[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2140 - loss: 0.2522[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2124 - loss: 0.2493 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 1.0000e-04
2025-08-26 21:42:29,228 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 21:42:29,342 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.42.10_baseline_gs1/baseline_model.h5
2025-08-26 21:42:29,342 - INFO - 
[5/6] Performing inference and stitching...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 798ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 7ms/step  
2025-08-26 21:42:32,730 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-08-26 21:42:32,731 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 21:42:32,731 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 21:42:32,731 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:42:32,731 - INFO - Calculated ground truth crop region: rows [106:209], cols [22:209]
2025-08-26 21:42:32,731 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(103, 187)
2025-08-26 21:42:32,731 - INFO - Center-cropping from (188, 188) to (103, 187)
2025-08-26 21:42:32,731 - INFO - Final aligned shape: (103, 187)
2025-08-26 21:42:32,731 - INFO - --- Alignment complete ---
2025-08-26 21:42:32,731 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 187, 1), Ground Truth=(103, 187, 1)
2025-08-26 21:42:32,751 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 21:42:32,751 - INFO -   MAE:  (np.float32(0.097025156), np.float64(0.24285432149138858))
2025-08-26 21:42:32,751 - INFO -   PSNR: (63.19621763454673, 59.39168871671989)
2025-08-26 21:42:32,790 - INFO - Metrics and reconstruction images saved.
2025-08-26 21:42:32,790 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.066616
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.528182, std=0.159297, shape=(99, 183, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.021176, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.066616
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.528182, std=0.159297, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.021176, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
[2025-08-26 21:42:33] SUCCESS: Baseline training (n_images=128, trial=1)
[2025-08-26 21:42:33] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 21:42:33] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/test.npz' \
                '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 128 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 21:42:50] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 21:42:50] Completed training for train_size=128 (Trial 1/1)
[2025-08-26 21:42:50] Completed all trials for train_size=128
[2025-08-26 21:42:50] Model training phase completed
[2025-08-26 21:42:50] === STEP 3: Model Comparison ===
[2025-08-26 21:42:50] Running comparisons for train_size=128, test_size=128 (1 trials)
[2025-08-26 21:42:50] Using test subset size 128 (3-way comparison mode with Pty-chi)
[2025-08-26 21:42:50] EXECUTING: Model comparison (train_size=128, trial=1)
[2025-08-26 21:42:50] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/test.npz' --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1' --tike_recon_path '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 128
2025-08-26 21:42:51.298066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269771.310025 3493054 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269771.314111 3493054 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269771.325547 3493054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269771.325558 3493054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269771.325560 3493054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269771.325561 3493054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:42:51.328468: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:42:53,648 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 21:42:53,648 - INFO - Registration: enabled
2025-08-26 21:42:53,648 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 21:42:53,648 - INFO - Initializing configuration before data loading...
2025-08-26 21:42:53,648 - INFO - Initialized with gridsize=1, n_images=128
2025-08-26 21:42:53,648 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/test.npz...
2025-08-26 21:42:53,648 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=128
2025-08-26 21:42:53,953 - INFO - Using specified subset of 128 images from 2424 total (gridsize=1)
diff3d shape: (128, 64, 64)2025-08-26 21:42:53,953 - INFO - diff3d shape: (128, 64, 64)

probeGuess shape: (64, 64)2025-08-26 21:42:53,953 - INFO - probeGuess shape: (64, 64)

scan_index shape: (128,)2025-08-26 21:42:53,953 - INFO - scan_index shape: (128,)

objectGuess shape: (232, 232)2025-08-26 21:42:53,954 - INFO - objectGuess shape: (232, 232)

xcoords shape: (128,)2025-08-26 21:42:53,954 - INFO - xcoords shape: (128,)

ycoords shape: (128,)2025-08-26 21:42:53,954 - INFO - ycoords shape: (128,)

xcoords_start shape: (128,)2025-08-26 21:42:53,954 - INFO - xcoords_start shape: (128,)

ycoords_start shape: (128,)2025-08-26 21:42:53,954 - INFO - ycoords_start shape: (128,)

2025-08-26 21:42:53,954 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 21:42:53,954 - INFO - DEBUG:
 nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 21:42:53,954 - INFO - nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 21:42:53,954 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:42:53,954 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:42:53,954 - INFO - Using all 128 points as seeds
2025-08-26 21:42:53,954 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:42:53,954 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:42:53,954 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 21:42:53,955 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756269774.074436 3493054 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269774.075682 3493054 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 21:42:54,105 - INFO - neighbor-sampled diffraction shape
 (128, 64, 64, 1)2025-08-26 21:42:54,105 - INFO - (128, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 21:42:54,113 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 21:42:54,478 - INFO - INFO:
 None2025-08-26 21:42:54,478 - INFO - None

<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 21:42:54,478 - INFO - <PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 21:42:54,479 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run...
2025-08-26 21:42:54,479 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
Model: "functional"
2025-08-26 21:42:55,255 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 21:42:55,276 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 21:42:55,276 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 21:42:55,276 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 21:42:55,277 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 21:42:55,277 - INFO - None

2025-08-26 21:42:55.277188: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 21:42:55.277197: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269775.277211 3493054 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756269775.294665 3493054 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 21:42:55.294744: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756269775.294816 3493054 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:42:55,439 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:42:55,440 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:42:55,915 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
2025-08-26 21:42:55,915 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1...
2025-08-26 21:42:55,915 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/baseline_model.h5
2025-08-26 21:42:56,006 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 21:42:56,011 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 21:42:56,012 - INFO - Loaded Pty-chi (ePIE) reconstruction: (197, 279) (complex64)
2025-08-26 21:42:56,012 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 21:42:56,012 - INFO - Pty-chi (ePIE) computation time: 12.75s
2025-08-26 21:42:56,012 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756269777.090730 3493190 service.cc:152] XLA service 0x70fd2c002490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269777.090751 3493190 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:42:57.176087: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269777.327730 3493190 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269778.678835 3493190 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step2025-08-26 21:42:58,687 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 21:42:58,714 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 21:42:58,726 - INFO - PtychoPINN inference completed in 2.71s
2025-08-26 21:42:58,726 - INFO - Reassembling PtychoPINN patches...
2025-08-26 21:43:00,227 - INFO - Running inference with Baseline model...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 575ms/step2025-08-26 21:43:00,817 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 575ms/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 7ms/step  
2025-08-26 21:43:00,839 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 7ms/step
2025-08-26 21:43:00,850 - INFO - Baseline inference completed in 0.62s
2025-08-26 21:43:00,855 - INFO - Reassembling baseline patches...
2025-08-26 21:43:00,858 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 21:43:00,911 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions.npz
2025-08-26 21:43:00,911 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_metadata.txt
2025-08-26 21:43:00,911 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 21:43:00,911 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 21:43:00,911 - INFO - Ground truth original shape: (232, 232)
2025-08-26 21:43:00,911 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:43:00,911 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:43:00,911 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 21:43:00,911 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 21:43:00,911 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:43:00,911 - INFO - --- Alignment complete ---
2025-08-26 21:43:00,911 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:43:00,911 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:43:00,911 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 21:43:00,911 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 21:43:00,911 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:43:00,911 - INFO - --- Alignment complete ---
2025-08-26 21:43:00,911 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:43:00,911 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:43:00,911 - INFO - Initial shapes: Recon=(197, 279), Cropped GT=(101, 185)
2025-08-26 21:43:00,911 - INFO - Center-cropping from (197, 279) to (101, 185)
2025-08-26 21:43:00,911 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:43:00,911 - INFO - --- Alignment complete ---
2025-08-26 21:43:00,911 - INFO - Performing fine-scale registration to correct pixel-level misalignments...
2025-08-26 21:43:00,913 - INFO - PtychoPINN detected offset: (34.060, -17.960)
2025-08-26 21:43:00,916 - INFO - Baseline detected offset: (34.020, -17.960)
2025-08-26 21:43:00,919 - INFO - Tike detected offset: (0.780, 7.080)
2025-08-26 21:43:00,920 - INFO - Registration completed. PtychoPINN offset: (34.060001373291016, -17.959999084472656), Baseline offset: (34.02000045776367, -17.959999084472656), Pty-chi (ePIE) offset: (0.7799999713897705, 7.079999923706055)
2025-08-26 21:43:00,920 - INFO - Final aligned shapes - PINN: (97, 181), Baseline: (97, 181), Pty-chi (ePIE): (97, 181), GT: (97, 181)
2025-08-26 21:43:00,920 - INFO - Final evaluation shapes: PINN (97, 181), Baseline (97, 181), Pty-chi (ePIE) (97, 181), GT (97, 181)
Amplitude normalization scale factor: 0.8195882025-08-26 21:43:00,923 - INFO - Amplitude normalization scale factor: 0.819588

mean scale adjustment:2025-08-26 21:43:00,923 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,923 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,923 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,923 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:43:00,924 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.687689, std=0.249892, shape=(93, 177, 1)2025-08-26 21:43:00,924 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.687689, std=0.249892, shape=(93, 177, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:43:00,924 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.697542, shape=(93, 177)2025-08-26 21:43:00,924 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.697542, shape=(93, 177)

performed by index method2025-08-26 21:43:00,925 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,927 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,929 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:43:00,930 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,930 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,930 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,930 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:43:00,930 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

performed by index method2025-08-26 21:43:00,934 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,936 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,937 - INFO - performed by index method

2025-08-26 21:43:00,939 - INFO - PtychoPINN evaluation complete. SSIM: amp=-0.012, phase=0.396, MS-SSIM: amp=0.053, phase=0.172
Amplitude normalization scale factor: 1.0978542025-08-26 21:43:00,941 - INFO - Amplitude normalization scale factor: 1.097854

mean scale adjustment:2025-08-26 21:43:00,941 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,941 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,941 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,941 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:43:00,942 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.513385, std=0.178134, shape=(93, 177, 1)2025-08-26 21:43:00,942 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.513385, std=0.178134, shape=(93, 177, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:43:00,942 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.702938, shape=(93, 177)2025-08-26 21:43:00,942 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.702938, shape=(93, 177)

performed by index method2025-08-26 21:43:00,942 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,944 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,946 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:43:00,948 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,948 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,948 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,948 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:43:00,948 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

performed by index method2025-08-26 21:43:00,951 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,953 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,955 - INFO - performed by index method

2025-08-26 21:43:00,956 - INFO - Baseline evaluation complete. SSIM: amp=0.057, phase=0.410, MS-SSIM: amp=0.085, phase=0.227
Amplitude normalization scale factor: 0.4883102025-08-26 21:43:00,958 - INFO - Amplitude normalization scale factor: 0.488310

mean scale adjustment:2025-08-26 21:43:00,958 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,958 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,958 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,958 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:43:00,959 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.154230, std=0.311312, shape=(93, 177, 1)2025-08-26 21:43:00,959 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.154230, std=0.311312, shape=(93, 177, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:43:00,959 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.282608, shape=(93, 177)2025-08-26 21:43:00,959 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.282608, shape=(93, 177)

performed by index method2025-08-26 21:43:00,960 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,962 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,963 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:43:00,965 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,965 - INFO - 1

mean scale adjustment:2025-08-26 21:43:00,965 - INFO - mean scale adjustment:
 12025-08-26 21:43:00,965 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:43:00,965 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

performed by index method2025-08-26 21:43:00,968 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,970 - INFO - performed by index method

performed by index method2025-08-26 21:43:00,972 - INFO - performed by index method

2025-08-26 21:43:00,973 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=0.334, phase=0.783, MS-SSIM: amp=0.685, phase=0.808
2025-08-26 21:43:00,975 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 21:43:00,975 - INFO - --- Comparison Metrics ---

         model                 metric  amplitude     phase      value
    PtychoPINN                    mae   0.139081  0.416817        NaN
    PtychoPINN                    mse   0.043870  0.565614        NaN
    PtychoPINN                   psnr  61.709139 50.605603        NaN
    PtychoPINN                   ssim  -0.011809  0.396252        NaN
    PtychoPINN                ms_ssim   0.052587  0.172228        NaN
    PtychoPINN                  frc50   1.000000  1.000000        NaN
      Baseline                    mae   0.122256  0.396257        NaN
      Baseline                    mse   0.040120  0.563587        NaN
      Baseline                   psnr  62.097227 50.621196        NaN
      Baseline                   ssim   0.056928  0.410153        NaN
      Baseline                ms_ssim   0.084711  0.226750        NaN
      Baseline                  frc50   1.000000  1.000000        NaN
Pty-chi (ePIE)                    mae   0.091905  0.152665        NaN
Pty-chi (ePIE)                    mse   0.019366  0.043322        NaN
Pty-chi (ePIE)                   psnr  65.260345 61.763706        NaN
Pty-chi (ePIE)                   ssim   0.333555  0.783219        NaN
Pty-chi (ePIE)                ms_ssim   0.685400  0.808381        NaN
Pty-chi (ePIE)                  frc50   1.000000  1.000000        NaN
    PtychoPINN registration_offset_dy        NaN       NaN  34.060001
    PtychoPINN registration_offset_dx        NaN       NaN -17.959999
      Baseline registration_offset_dy        NaN       NaN  34.020000
      Baseline registration_offset_dx        NaN       NaN -17.959999
Pty-chi (ePIE) registration_offset_dy        NaN       NaN   0.780000
Pty-chi (ePIE) registration_offset_dx        NaN       NaN   7.080000
    PtychoPINN     computation_time_s        NaN       NaN   2.713909
      Baseline     computation_time_s        NaN       NaN   0.623418
Pty-chi (ePIE)     computation_time_s        NaN       NaN  12.7549222025-08-26 21:43:00,977 - INFO - model                 metric  amplitude     phase      value
    PtychoPINN                    mae   0.139081  0.416817        NaN
    PtychoPINN                    mse   0.043870  0.565614        NaN
    PtychoPINN                   psnr  61.709139 50.605603        NaN
    PtychoPINN                   ssim  -0.011809  0.396252        NaN
    PtychoPINN                ms_ssim   0.052587  0.172228        NaN
    PtychoPINN                  frc50   1.000000  1.000000        NaN
      Baseline                    mae   0.122256  0.396257        NaN
      Baseline                    mse   0.040120  0.563587        NaN
      Baseline                   psnr  62.097227 50.621196        NaN
      Baseline                   ssim   0.056928  0.410153        NaN
      Baseline                ms_ssim   0.084711  0.226750        NaN
      Baseline                  frc50   1.000000  1.000000        NaN
Pty-chi (ePIE)                    mae   0.091905  0.152665        NaN
Pty-chi (ePIE)                    mse   0.019366  0.043322        NaN
Pty-chi (ePIE)                   psnr  65.260345 61.763706        NaN
Pty-chi (ePIE)                   ssim   0.333555  0.783219        NaN
Pty-chi (ePIE)                ms_ssim   0.685400  0.808381        NaN
Pty-chi (ePIE)                  frc50   1.000000  1.000000        NaN
    PtychoPINN registration_offset_dy        NaN       NaN  34.060001
    PtychoPINN registration_offset_dx        NaN       NaN -17.959999
      Baseline registration_offset_dy        NaN       NaN  34.020000
      Baseline registration_offset_dx        NaN       NaN -17.959999
Pty-chi (ePIE) registration_offset_dy        NaN       NaN   0.780000
Pty-chi (ePIE) registration_offset_dx        NaN       NaN   7.080000
    PtychoPINN     computation_time_s        NaN       NaN   2.713909
      Baseline     computation_time_s        NaN       NaN   0.623418
Pty-chi (ePIE)     computation_time_s        NaN       NaN  12.754922

2025-08-26 21:43:00,977 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_frc_curves.csv
2025-08-26 21:43:00,978 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_frc_curves.csv
2025-08-26 21:43:00,978 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 21:43:01,026 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned.npz
2025-08-26 21:43:01,026 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 21:43:01,026 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 21:43:01,063 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.043, 0.886) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,064 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.018, 0.578) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,064 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.105, 0.024) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,065 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.075, 0.075) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,065 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.840, 1.599) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,065 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.457, 0.277) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,074 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.501, 0.619) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,074 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.465, 0.273) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:43:01,760 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_plot.png
2025-08-26 21:43:01,760 - INFO - 
Comparison complete!
2025-08-26 21:43:01,760 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1
[2025-08-26 21:43:02] SUCCESS: Model comparison (train_size=128, trial=1)
[2025-08-26 21:43:02] Completed comparisons for train_size=128
[2025-08-26 21:43:02] Model comparison phase completed
[2025-08-26 21:43:02] === STEP 4: Results Aggregation ===
[2025-08-26 21:43:02] EXECUTING: PSNR phase generalization plot
[2025-08-26 21:43:02] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
21:43:03 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:03 - INFO - Analyzing psnr_phase
21:43:03 - INFO - Discovered 1 comparison files
21:43:03 - INFO - Single-trial data detected - using legacy aggregation
21:43:03 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:03 - INFO - Made 1 out-of-range replacements with NaN
21:43:03 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:03 - INFO - Loaded 3 trial records
21:43:03 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:03 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:03 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:03 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:03 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:03 - INFO - NaN exclusion summary:
21:43:03 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO - Extracted 1 data points for psnr_phase (using mean)
21:43:03 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:43:03 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
21:43:03 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:03 - INFO - Processing complete!
21:43:03 - INFO - Outputs:
21:43:03 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
21:43:03 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:03 - INFO - Summary: 1 models, 1 training sizes
21:43:03 - INFO - Training sizes: [np.int64(128)]
21:43:03 - INFO - Model types: ['iterative']
[2025-08-26 21:43:03] SUCCESS: PSNR phase generalization plot
[2025-08-26 21:43:03] EXECUTING: FRC amplitude generalization plot
[2025-08-26 21:43:03] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
21:43:03 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:03 - INFO - Analyzing frc50_amp
21:43:03 - INFO - Discovered 1 comparison files
21:43:03 - INFO - Single-trial data detected - using legacy aggregation
21:43:03 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:03 - INFO - Made 1 out-of-range replacements with NaN
21:43:03 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:03 - INFO - Loaded 3 trial records
21:43:03 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:03 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:03 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:03 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:03 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:03 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:03 - INFO - NaN exclusion summary:
21:43:03 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:03 - INFO - Extracted 1 data points for frc50_amp (using mean)
21:43:03 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:43:04 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
21:43:04 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:04 - INFO - Processing complete!
21:43:04 - INFO - Outputs:
21:43:04 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
21:43:04 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:04 - INFO - Summary: 1 models, 1 training sizes
21:43:04 - INFO - Training sizes: [np.int64(128)]
21:43:04 - INFO - Model types: ['iterative']
[2025-08-26 21:43:04] SUCCESS: FRC amplitude generalization plot
[2025-08-26 21:43:04] EXECUTING: MAE amplitude generalization plot
[2025-08-26 21:43:04] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
21:43:04 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:04 - INFO - Analyzing mae_amp
21:43:04 - INFO - Discovered 1 comparison files
21:43:04 - INFO - Single-trial data detected - using legacy aggregation
21:43:04 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:04 - INFO - Made 1 out-of-range replacements with NaN
21:43:04 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:04 - INFO - Loaded 3 trial records
21:43:04 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:04 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:04 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:04 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:04 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:04 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:04 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:04 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:04 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:04 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:04 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:04 - INFO - NaN exclusion summary:
21:43:04 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:04 - INFO - Extracted 1 data points for mae_amp (using mean)
21:43:04 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:43:04 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
21:43:04 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:04 - INFO - Processing complete!
21:43:04 - INFO - Outputs:
21:43:04 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
21:43:04 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:04 - INFO - Summary: 1 models, 1 training sizes
21:43:04 - INFO - Training sizes: [np.int64(128)]
21:43:04 - INFO - Model types: ['iterative']
[2025-08-26 21:43:04] SUCCESS: MAE amplitude generalization plot
[2025-08-26 21:43:04] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 21:43:04] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
21:43:05 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:05 - INFO - Analyzing ssim_amp
21:43:05 - INFO - Discovered 1 comparison files
21:43:05 - INFO - Single-trial data detected - using legacy aggregation
21:43:05 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:05 - INFO - Made 1 out-of-range replacements with NaN
21:43:05 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:05 - INFO - Loaded 3 trial records
21:43:05 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:05 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:05 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:05 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:05 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:05 - INFO - NaN exclusion summary:
21:43:05 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO - Extracted 1 data points for ssim_amp (using mean)
21:43:05 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:43:05 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
21:43:05 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:05 - INFO - Processing complete!
21:43:05 - INFO - Outputs:
21:43:05 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
21:43:05 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:05 - INFO - Summary: 1 models, 1 training sizes
21:43:05 - INFO - Training sizes: [np.int64(128)]
21:43:05 - INFO - Model types: ['iterative']
[2025-08-26 21:43:05] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 21:43:05] EXECUTING: SSIM phase generalization plot
[2025-08-26 21:43:05] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
21:43:05 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:05 - INFO - Analyzing ssim_phase
21:43:05 - INFO - Discovered 1 comparison files
21:43:05 - INFO - Single-trial data detected - using legacy aggregation
21:43:05 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:05 - INFO - Made 1 out-of-range replacements with NaN
21:43:05 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:05 - INFO - Loaded 3 trial records
21:43:05 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:05 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:05 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:05 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:05 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:05 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:05 - INFO - NaN exclusion summary:
21:43:05 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:05 - INFO - Extracted 1 data points for ssim_phase (using mean)
21:43:05 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:43:05 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
21:43:05 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:05 - INFO - Processing complete!
21:43:05 - INFO - Outputs:
21:43:05 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
21:43:05 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:05 - INFO - Summary: 1 models, 1 training sizes
21:43:05 - INFO - Training sizes: [np.int64(128)]
21:43:05 - INFO - Model types: ['iterative']
[2025-08-26 21:43:06] SUCCESS: SSIM phase generalization plot
[2025-08-26 21:43:06] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 21:43:06] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
21:43:06 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:06 - INFO - Analyzing ms_ssim_amp
21:43:06 - INFO - Discovered 1 comparison files
21:43:06 - INFO - Single-trial data detected - using legacy aggregation
21:43:06 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:06 - INFO - Made 1 out-of-range replacements with NaN
21:43:06 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:06 - INFO - Loaded 3 trial records
21:43:06 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:06 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:06 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:06 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:06 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:06 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:06 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:06 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:06 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:06 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:06 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:06 - INFO - NaN exclusion summary:
21:43:06 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:06 - INFO - Extracted 1 data points for ms_ssim_amp (using mean)
21:43:06 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:43:06 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
21:43:06 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:06 - INFO - Processing complete!
21:43:06 - INFO - Outputs:
21:43:06 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
21:43:06 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:06 - INFO - Summary: 1 models, 1 training sizes
21:43:06 - INFO - Training sizes: [np.int64(128)]
21:43:06 - INFO - Model types: ['iterative']
[2025-08-26 21:43:06] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 21:43:06] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 21:43:06] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
21:43:07 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:43:07 - INFO - Analyzing ms_ssim_phase
21:43:07 - INFO - Discovered 1 comparison files
21:43:07 - INFO - Single-trial data detected - using legacy aggregation
21:43:07 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.011809]
21:43:07 - INFO - Made 1 out-of-range replacements with NaN
21:43:07 - INFO - Total NaN values in data: 19 (1 new, 18 preserved)
21:43:07 - INFO - Loaded 3 trial records
21:43:07 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:43:07 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:43:07 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:43:07 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:43:07 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:43:07 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:43:07 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:43:07 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:43:07 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:43:07 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:43:07 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:43:07 - INFO - NaN exclusion summary:
21:43:07 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:43:07 - INFO - Extracted 1 data points for ms_ssim_phase (using mean)
21:43:07 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:43:07 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
21:43:07 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:43:07 - INFO - Processing complete!
21:43:07 - INFO - Outputs:
21:43:07 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
21:43:07 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:43:07 - INFO - Summary: 1 models, 1 training sizes
21:43:07 - INFO - Training sizes: [np.int64(128)]
21:43:07 - INFO - Model types: ['iterative']
[2025-08-26 21:43:07] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 21:43:07] Results aggregation completed
[2025-08-26 21:43:07] === Generating Summary Report ===
[2025-08-26 21:43:07] Summary report generated: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 21:43:07] === Study Completed Successfully ===
[2025-08-26 21:43:07] Training sizes tested: 1
[2025-08-26 21:43:07] Trials per size: 1
[2025-08-26 21:43:07] Total trials completed: 1
[2025-08-26 21:43:07] Total runtime: 00:01:26
[2025-08-26 21:43:07] Results directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 21:43:07] Summary report: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 21:43:59] === Starting Complete Generalization Study ===
[2025-08-26 21:43:59] Training sizes: 128
[2025-08-26 21:43:59] Number of trials per size: 1
[2025-08-26 21:43:59] Output directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 21:43:59] Total training runs planned: 2
[2025-08-26 21:43:59] Validating environment...
[2025-08-26 21:43:59] Environment validation passed
[2025-08-26 21:44:00] Configuration saved to: 3way_synthetic_ptychi_1e4_128/study_config.txt
[2025-08-26 21:44:00] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 21:44:00] === STEP 2: Model Training ===
[2025-08-26 21:44:00] Training models sequentially with 1 trials per training size
[2025-08-26 21:44:00] Starting training for train_size=128, test_size=128 (1 trials)
[2025-08-26 21:44:00] Training models for train_size=128, test_size=128 (Trial 1/1)
[2025-08-26 21:44:00] EXECUTING: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 21:44:00] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 21:44:00.305980: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269840.317713 3494233 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269840.321722 3494233 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269840.332851 3494233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269840.332861 3494233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269840.332863 3494233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269840.332864 3494233 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:44:00.335746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:44:03,157 - INFO - Configuration setup complete
2025-08-26 21:44:03,157 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 21:44:03,157 - INFO - Parameter interpretation: --n-images=128 refers to individual images (gridsize=1)
2025-08-26 21:44:03,157 - INFO - Starting training with n_images=128, stitching=disabled
2025-08-26 21:44:03,157 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 21:44:03,478 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
2025-08-26 21:44:03,800 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 21:44:03,800 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 21:44:04,102 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
2025-08-26 21:44:04,102 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/test.npz
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 21:44:04,103 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:44:04,103 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:44:04,103 - INFO - Using all 128 points as seeds
2025-08-26 21:44:04,103 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:44:04,103 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:44:04,103 - INFO - Generated 128 groups efficiently
I0000 00:00:1756269844.236519 3494233 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269844.237798 3494233 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 21:44:04,637 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:44:04,637 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 21:44:04,637 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 21:44:04,637 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:44:04,637 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:44:04,637 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1148.375 global_offsets=(128, 1, 2, 1) mean=141.600 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 21:44:05.315932: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 21:44:05.315940: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269845.315954 3494233 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756269845.332946 3494233 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 21:44:05.333017: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756269845.333086 3494233 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756269846.045406 3494233 service.cc:152] XLA service 0x29e3bb60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269846.045424 3494233 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:44:06.075556: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269846.094161 3494233 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269846.656168 3494233 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 21:44:07,201 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 21:44:09,118 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 21:44:12.752297: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:44:12.790561: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:44:12.792520: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 21:44:13.059899: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m49s[0m 7s/step - intensity_scaler_inv_loss: 0.6457 - loss: 0.5982 - pred_intensity_loss: 0.5982 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.8012 - loss: 1.0815 - pred_intensity_loss: 1.0815 - trimmed_obj_loss: 0.0000e+002025-08-26 21:44:15.269330: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:44:15.322209: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 21:44:15.347356: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 21:44:15.592727: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 345ms/step - intensity_scaler_inv_loss: 0.8063 - loss: 1.0463 - pred_intensity_loss: 1.0430 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 21:44:16,549 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m11s[0m 525ms/step - intensity_scaler_inv_loss: 0.7939 - loss: 0.9323 - pred_intensity_loss: 0.9064 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.6425 - val_loss: 0.4412 - val_pred_intensity_loss: 0.4412 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.6505 - loss: 0.4389 - pred_intensity_loss: 0.4389 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.6181 - loss: 0.3295 - pred_intensity_loss: 0.3295 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5711 - loss: 0.0857 - pred_intensity_loss: 0.0742 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.6079 - val_loss: -0.0209 - val_pred_intensity_loss: -0.0209 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5920 - loss: -0.0966 - pred_intensity_loss: -0.0966 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5752 - loss: -0.1278 - pred_intensity_loss: -0.1278 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5413 - loss: -0.1764 - pred_intensity_loss: -0.1773 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5099 - val_loss: -0.1905 - val_pred_intensity_loss: -0.1905 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5117 - loss: -0.2071 - pred_intensity_loss: -0.2071 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5058 - loss: -0.2264 - pred_intensity_loss: -0.2264 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4972 - loss: -0.2391 - pred_intensity_loss: -0.2389 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5109 - val_loss: -0.2080 - val_pred_intensity_loss: -0.2080 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4957 - loss: -0.2601 - pred_intensity_loss: -0.2601 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5007 - loss: -0.2495 - pred_intensity_loss: -0.2495 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5058 - loss: -0.2482 - pred_intensity_loss: -0.2483 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5031 - val_loss: -0.2226 - val_pred_intensity_loss: -0.2226 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4964 - loss: -0.2520 - pred_intensity_loss: -0.2520 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4999 - loss: -0.2503 - pred_intensity_loss: -0.2503 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4956 - loss: -0.2543 - pred_intensity_loss: -0.2543 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5031 - val_loss: -0.2228 - val_pred_intensity_loss: -0.2228 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4976 - loss: -0.2549 - pred_intensity_loss: -0.2549 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5022 - loss: -0.2433 - pred_intensity_loss: -0.2433 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5000 - loss: -0.2571 - pred_intensity_loss: -0.2607 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5020 - val_loss: -0.2260 - val_pred_intensity_loss: -0.2260 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4930 - loss: -0.2742 - pred_intensity_loss: -0.2742 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4951 - loss: -0.2619 - pred_intensity_loss: -0.2619 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4985 - loss: -0.2594 - pred_intensity_loss: -0.2607 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5033 - val_loss: -0.2291 - val_pred_intensity_loss: -0.2291 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5138 - loss: -0.2475 - pred_intensity_loss: -0.2475 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5020 - loss: -0.2580 - pred_intensity_loss: -0.2580 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4993 - loss: -0.2623 - pred_intensity_loss: -0.2631 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5004 - val_loss: -0.2327 - val_pred_intensity_loss: -0.2327 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4974 - loss: -0.3251 - pred_intensity_loss: -0.3251 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4980 - loss: -0.2827 - pred_intensity_loss: -0.2827 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4975 - loss: -0.2659 - pred_intensity_loss: -0.2660 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4990 - val_loss: -0.2404 - val_pred_intensity_loss: -0.2404 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4936 - loss: -0.2739 - pred_intensity_loss: -0.2739 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4975 - loss: -0.2570 - pred_intensity_loss: -0.2570 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4948 - loss: -0.2701 - pred_intensity_loss: -0.2725 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4987 - val_loss: -0.2446 - val_pred_intensity_loss: -0.2446 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4906 - loss: -0.2788 - pred_intensity_loss: -0.2788 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4940 - loss: -0.2758 - pred_intensity_loss: -0.2758 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4955 - loss: -0.2733 - pred_intensity_loss: -0.2740 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4982 - val_loss: -0.2459 - val_pred_intensity_loss: -0.2459 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.5054 - loss: -0.2502 - pred_intensity_loss: -0.2502 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4987 - loss: -0.2739 - pred_intensity_loss: -0.2739 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4941 - loss: -0.2755 - pred_intensity_loss: -0.2766 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4976 - val_loss: -0.2498 - val_pred_intensity_loss: -0.2498 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4926 - loss: -0.2901 - pred_intensity_loss: -0.2901 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4967 - loss: -0.2863 - pred_intensity_loss: -0.2863 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4948 - loss: -0.2778 - pred_intensity_loss: -0.2786 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4972 - val_loss: -0.2538 - val_pred_intensity_loss: -0.2538 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4875 - loss: -0.2920 - pred_intensity_loss: -0.2920 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4929 - loss: -0.2741 - pred_intensity_loss: -0.2741 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4960 - loss: -0.2810 - pred_intensity_loss: -0.2808 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4969 - val_loss: -0.2595 - val_pred_intensity_loss: -0.2595 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.5055 - loss: -0.2746 - pred_intensity_loss: -0.2746 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5008 - loss: -0.2796 - pred_intensity_loss: -0.2796 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4951 - loss: -0.2846 - pred_intensity_loss: -0.2824 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4928 - val_loss: -0.2690 - val_pred_intensity_loss: -0.2690 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4930 - loss: -0.2860 - pred_intensity_loss: -0.2860 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4928 - loss: -0.2876 - pred_intensity_loss: -0.2876 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4934 - loss: -0.2958 - pred_intensity_loss: -0.2944 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4859 - val_loss: -0.2913 - val_pred_intensity_loss: -0.2913 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4913 - loss: -0.2890 - pred_intensity_loss: -0.2890 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4917 - loss: -0.3032 - pred_intensity_loss: -0.3032 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4891 - loss: -0.3079 - pred_intensity_loss: -0.3095 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4827 - val_loss: -0.3071 - val_pred_intensity_loss: -0.3071 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4791 - loss: -0.3797 - pred_intensity_loss: -0.3797 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4848 - loss: -0.3378 - pred_intensity_loss: -0.3378 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4841 - loss: -0.3221 - pred_intensity_loss: -0.3240 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4834 - val_loss: -0.3157 - val_pred_intensity_loss: -0.3157 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4908 - loss: -0.3295 - pred_intensity_loss: -0.3295 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4817 - loss: -0.3443 - pred_intensity_loss: -0.3443 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4747 - loss: -0.3517 - pred_intensity_loss: -0.3495 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4758 - val_loss: -0.3449 - val_pred_intensity_loss: -0.3449 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4754 - loss: -0.3481 - pred_intensity_loss: -0.3481 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4706 - loss: -0.3660 - pred_intensity_loss: -0.3660 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4674 - loss: -0.3722 - pred_intensity_loss: -0.3727 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4620 - val_loss: -0.3636 - val_pred_intensity_loss: -0.3636 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4601 - loss: -0.3714 - pred_intensity_loss: -0.3714 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4627 - loss: -0.3781 - pred_intensity_loss: -0.3781 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4616 - loss: -0.3883 - pred_intensity_loss: -0.3887 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4644 - val_loss: -0.3667 - val_pred_intensity_loss: -0.3667 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4611 - loss: -0.3839 - pred_intensity_loss: -0.3839 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4612 - loss: -0.3874 - pred_intensity_loss: -0.3874 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4597 - loss: -0.3956 - pred_intensity_loss: -0.3938 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4600 - val_loss: -0.3760 - val_pred_intensity_loss: -0.3760 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4600 - loss: -0.4189 - pred_intensity_loss: -0.4189 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4576 - loss: -0.4034 - pred_intensity_loss: -0.4034 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4567 - loss: -0.4012 - pred_intensity_loss: -0.4050 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4657 - val_loss: -0.3727 - val_pred_intensity_loss: -0.3727 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4657 - loss: -0.4068 - pred_intensity_loss: -0.4068 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4601 - loss: -0.3921 - pred_intensity_loss: -0.3921 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4567 - loss: -0.4053 - pred_intensity_loss: -0.4051 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4576 - val_loss: -0.3850 - val_pred_intensity_loss: -0.3850 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4490 - loss: -0.5002 - pred_intensity_loss: -0.5002 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4379 - pred_intensity_loss: -0.4379 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4531 - loss: -0.4119 - pred_intensity_loss: -0.4110 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4545 - val_loss: -0.3892 - val_pred_intensity_loss: -0.3892 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4498 - loss: -0.4268 - pred_intensity_loss: -0.4268 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4492 - loss: -0.4165 - pred_intensity_loss: -0.4165 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4520 - loss: -0.4158 - pred_intensity_loss: -0.4155 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4532 - val_loss: -0.3933 - val_pred_intensity_loss: -0.3933 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4477 - pred_intensity_loss: -0.4477 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4500 - loss: -0.4171 - pred_intensity_loss: -0.4171 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4509 - loss: -0.4187 - pred_intensity_loss: -0.4203 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4528 - val_loss: -0.3952 - val_pred_intensity_loss: -0.3952 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.3974 - pred_intensity_loss: -0.3974 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4095 - pred_intensity_loss: -0.4095 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4498 - loss: -0.4217 - pred_intensity_loss: -0.4190 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4523 - val_loss: -0.3976 - val_pred_intensity_loss: -0.3976 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4476 - loss: -0.4200 - pred_intensity_loss: -0.4200 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4493 - loss: -0.4237 - pred_intensity_loss: -0.4237 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 23ms/step - intensity_scaler_inv_loss: 0.4489 - loss: -0.4244 - pred_intensity_loss: -0.4255 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4497 - val_loss: -0.4003 - val_pred_intensity_loss: -0.4003 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4487 - loss: -0.3901 - pred_intensity_loss: -0.3901 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4477 - loss: -0.4142 - pred_intensity_loss: -0.4142 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4259 - pred_intensity_loss: -0.4252 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4481 - val_loss: -0.4008 - val_pred_intensity_loss: -0.4008 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4204 - pred_intensity_loss: -0.4204 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4476 - loss: -0.4219 - pred_intensity_loss: -0.4219 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4262 - pred_intensity_loss: -0.4287 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4529 - val_loss: -0.3990 - val_pred_intensity_loss: -0.3990 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4514 - loss: -0.4123 - pred_intensity_loss: -0.4123 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.4231 - pred_intensity_loss: -0.4231 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4477 - loss: -0.4284 - pred_intensity_loss: -0.4277 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4485 - val_loss: -0.4044 - val_pred_intensity_loss: -0.4044 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4387 - pred_intensity_loss: -0.4387 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4465 - loss: -0.4207 - pred_intensity_loss: -0.4207 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4296 - pred_intensity_loss: -0.4284 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4485 - val_loss: -0.4046 - val_pred_intensity_loss: -0.4046 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4338 - pred_intensity_loss: -0.4338 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4461 - loss: -0.4223 - pred_intensity_loss: -0.4223 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4317 - pred_intensity_loss: -0.4352 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4477 - val_loss: -0.4086 - val_pred_intensity_loss: -0.4086 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4466 - pred_intensity_loss: -0.4466 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4347 - pred_intensity_loss: -0.4347 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4331 - pred_intensity_loss: -0.4305 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4472 - val_loss: -0.4091 - val_pred_intensity_loss: -0.4091 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4170 - pred_intensity_loss: -0.4170 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4465 - loss: -0.4197 - pred_intensity_loss: -0.4197 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4319 - pred_intensity_loss: -0.4338 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4503 - val_loss: -0.4055 - val_pred_intensity_loss: -0.4055 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4510 - loss: -0.3903 - pred_intensity_loss: -0.3903 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4477 - loss: -0.4197 - pred_intensity_loss: -0.4197 - trimmed_obj_loss: 0.0000e+00
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4458 - loss: -0.4334 - pred_intensity_loss: -0.4335 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4481 - val_loss: -0.4086 - val_pred_intensity_loss: -0.4086 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4172 - pred_intensity_loss: -0.4172 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4293 - pred_intensity_loss: -0.4293 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4451 - loss: -0.4359 - pred_intensity_loss: -0.4357 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4462 - val_loss: -0.4121 - val_pred_intensity_loss: -0.4121 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4458 - loss: -0.4458 - pred_intensity_loss: -0.4458 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4351 - pred_intensity_loss: -0.4351 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4451 - loss: -0.4364 - pred_intensity_loss: -0.4365 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4464 - val_loss: -0.4123 - val_pred_intensity_loss: -0.4123 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4503 - pred_intensity_loss: -0.4503 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4402 - pred_intensity_loss: -0.4402 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4372 - pred_intensity_loss: -0.4363 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4476 - val_loss: -0.4114 - val_pred_intensity_loss: -0.4114 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.4406 - pred_intensity_loss: -0.4406 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4481 - loss: -0.4366 - pred_intensity_loss: -0.4366 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4377 - pred_intensity_loss: -0.4372 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4128 - val_pred_intensity_loss: -0.4128 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4542 - pred_intensity_loss: -0.4542 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4451 - pred_intensity_loss: -0.4451 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4381 - pred_intensity_loss: -0.4403 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4458 - val_loss: -0.4138 - val_pred_intensity_loss: -0.4138 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4391 - loss: -0.4154 - pred_intensity_loss: -0.4154 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4346 - pred_intensity_loss: -0.4346 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4386 - pred_intensity_loss: -0.4368 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4449 - val_loss: -0.4140 - val_pred_intensity_loss: -0.4140 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4416 - loss: -0.4315 - pred_intensity_loss: -0.4315 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4425 - loss: -0.4244 - pred_intensity_loss: -0.4244 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4389 - pred_intensity_loss: -0.4404 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4461 - val_loss: -0.4143 - val_pred_intensity_loss: -0.4143 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4510 - loss: -0.4267 - pred_intensity_loss: -0.4267 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4476 - loss: -0.4356 - pred_intensity_loss: -0.4356 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4394 - pred_intensity_loss: -0.4394 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4150 - val_pred_intensity_loss: -0.4150 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4319 - pred_intensity_loss: -0.4319 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4400 - pred_intensity_loss: -0.4400 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4397 - pred_intensity_loss: -0.4403 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4454 - val_loss: -0.4150 - val_pred_intensity_loss: -0.4150 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4463 - loss: -0.4092 - pred_intensity_loss: -0.4092 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4311 - pred_intensity_loss: -0.4311 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4401 - pred_intensity_loss: -0.4397 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4155 - val_pred_intensity_loss: -0.4155 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4400 - loss: -0.4521 - pred_intensity_loss: -0.4521 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4421 - pred_intensity_loss: -0.4421 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4404 - pred_intensity_loss: -0.4393 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4452 - val_loss: -0.4157 - val_pred_intensity_loss: -0.4157 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4742 - pred_intensity_loss: -0.4742 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4453 - pred_intensity_loss: -0.4453 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4407 - pred_intensity_loss: -0.4432 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4454 - val_loss: -0.4160 - val_pred_intensity_loss: -0.4160 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 941ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 524288 into shape (6,6,64,64,1)
2025-08-26 21:44:27,560 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 21:44:28,977 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
[2025-08-26 21:44:30] SUCCESS: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 21:44:30] EXECUTING: Baseline training (n_images=128, trial=1)
[2025-08-26 21:44:30] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 21:44:30.515245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269870.527030 3501988 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269870.531033 3501988 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269870.541908 3501988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269870.541917 3501988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269870.541918 3501988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269870.541919 3501988 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:44:30.545009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:44:33,094 - INFO - Configuration setup complete
2025-08-26 21:44:33,094 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 21:44:33,094 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 21:44:33,094 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 21:44:33,094 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.44.33_baseline_gs1/
2025-08-26 21:44:33,095 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756269873.203712 3501988 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269873.205006 3501988 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 21:44:33,239 - INFO - 
[2/6] Loading data...
2025-08-26 21:44:33,239 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 21:44:33,239 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 21:44:33,560 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
2025-08-26 21:44:33,560 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 21:44:33,862 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 21:44:33,862 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:44:33,862 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:44:33,862 - INFO - Using all 128 points as seeds
2025-08-26 21:44:33,862 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:44:33,862 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:44:33,862 - INFO - Generated 128 groups efficiently
2025-08-26 21:44:34,230 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:44:34,230 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 21:44:34,230 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 21:44:34,230 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:44:34,230 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:44:34,230 - INFO - Generated 128 groups efficiently
2025-08-26 21:44:34,242 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-08-26 21:44:34,242 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 21:44:34,244 - INFO - Final training input shape: (128, 64, 64, 1)
2025-08-26 21:44:34,244 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 21:44:34,244 - INFO - Training with 128 images
DEBUG: Setting timestamp to 08/26/2025, 21:44:33 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.44.33_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
timestamp: 08/26/2025, 21:44:33
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1297.438 global_offsets=(128, 1, 2, 1) mean=136.741 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269877.063812 3502124 service.cc:152] XLA service 0x7daa08005000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269877.063831 3502124 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:44:37.134724: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269877.549068 3502124 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269880.451925 3502124 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m39s[0m 6s/step - conv2d_12_loss: 0.5620 - conv2d_19_loss: 0.2230 - loss: 0.7850[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.5505 - conv2d_19_loss: 0.2467 - loss: 0.7972[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 416ms/step - conv2d_12_loss: 0.5381 - conv2d_19_loss: 0.2432 - loss: 0.7823[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 534ms/step - conv2d_12_loss: 0.4928 - conv2d_19_loss: 0.2323 - loss: 0.7323 - val_conv2d_12_loss: 0.2015 - val_conv2d_19_loss: 0.2310 - val_loss: 0.4324 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.2016 - conv2d_19_loss: 0.2227 - loss: 0.4243[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2049 - conv2d_19_loss: 0.2201 - loss: 0.4250[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.1768 - conv2d_19_loss: 0.2159 - loss: 0.3957 - val_conv2d_12_loss: 0.1319 - val_conv2d_19_loss: 0.2318 - val_loss: 0.3637 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.1305 - conv2d_19_loss: 0.2215 - loss: 0.3520[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.1198 - conv2d_19_loss: 0.2165 - loss: 0.3362[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.1045 - conv2d_19_loss: 0.2132 - loss: 0.3196 - val_conv2d_12_loss: 0.0813 - val_conv2d_19_loss: 0.2288 - val_loss: 0.3101 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0793 - conv2d_19_loss: 0.1994 - loss: 0.2787[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0729 - conv2d_19_loss: 0.2068 - loss: 0.2797[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0691 - conv2d_19_loss: 0.2139 - loss: 0.2815 - val_conv2d_12_loss: 0.0582 - val_conv2d_19_loss: 0.2289 - val_loss: 0.2871 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0581 - conv2d_19_loss: 0.2195 - loss: 0.2776[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0618 - conv2d_19_loss: 0.2132 - loss: 0.2749[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0590 - conv2d_19_loss: 0.2116 - loss: 0.2719 - val_conv2d_12_loss: 0.0552 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2838 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0526 - conv2d_19_loss: 0.2093 - loss: 0.2620[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0528 - conv2d_19_loss: 0.2099 - loss: 0.2627[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0525 - conv2d_19_loss: 0.2126 - loss: 0.2648 - val_conv2d_12_loss: 0.0516 - val_conv2d_19_loss: 0.2287 - val_loss: 0.2803 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0514 - conv2d_19_loss: 0.2148 - loss: 0.2662[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0502 - conv2d_19_loss: 0.2111 - loss: 0.2614[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0496 - conv2d_19_loss: 0.2130 - loss: 0.2618 - val_conv2d_12_loss: 0.0497 - val_conv2d_19_loss: 0.2285 - val_loss: 0.2782 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0496 - conv2d_19_loss: 0.2258 - loss: 0.2754[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0474 - conv2d_19_loss: 0.2137 - loss: 0.2611[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0467 - conv2d_19_loss: 0.2125 - loss: 0.2590 - val_conv2d_12_loss: 0.0473 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2759 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.2119 - loss: 0.2571[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0442 - conv2d_19_loss: 0.2107 - loss: 0.2549[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0436 - conv2d_19_loss: 0.2117 - loss: 0.2560 - val_conv2d_12_loss: 0.0442 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2725 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.2110 - loss: 0.2528[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0414 - conv2d_19_loss: 0.2120 - loss: 0.2534[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.2120 - loss: 0.2534 - val_conv2d_12_loss: 0.0433 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2717 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2092 - loss: 0.2490[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2102 - loss: 0.2502[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0402 - conv2d_19_loss: 0.2127 - loss: 0.2523 - val_conv2d_12_loss: 0.0423 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2705 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.2150 - loss: 0.2556[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2102 - loss: 0.2495[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2126 - loss: 0.2515 - val_conv2d_12_loss: 0.0414 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2697 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2029 - loss: 0.2416[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2131 - loss: 0.2530[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2110 - loss: 0.2512 - val_conv2d_12_loss: 0.0417 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2698 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2140 - loss: 0.2539[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2116 - loss: 0.2505[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2117 - loss: 0.2512 - val_conv2d_12_loss: 0.0406 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2689 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2208 - loss: 0.2610[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2150 - loss: 0.2537[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2113 - loss: 0.2505 - val_conv2d_12_loss: 0.0405 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2687 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0361 - conv2d_19_loss: 0.2058 - loss: 0.2419[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2093 - loss: 0.2469[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2123 - loss: 0.2506 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2684 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2199 - loss: 0.2602[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2130 - loss: 0.2519[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2113 - loss: 0.2505 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2681 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2164 - loss: 0.2549[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2113 - loss: 0.2493[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2125 - loss: 0.2502 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2684 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0407 - conv2d_19_loss: 0.2233 - loss: 0.2640[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2151 - loss: 0.2539
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2126 - loss: 0.2503 - val_conv2d_12_loss: 0.0408 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2686 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2153 - loss: 0.2553[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0392 - conv2d_19_loss: 0.2147 - loss: 0.2539[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2112 - loss: 0.2505 - val_conv2d_12_loss: 0.0408 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2688 - learning_rate: 5.0000e-04
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2091 - loss: 0.2470[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2097 - loss: 0.2479
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2130 - loss: 0.2504 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2681 - learning_rate: 5.0000e-04
2025-08-26 21:44:47,088 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 21:44:47,204 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-21.44.33_baseline_gs1/baseline_model.h5
2025-08-26 21:44:47,204 - INFO - 
[5/6] Performing inference and stitching...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 796ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 7ms/step  
2025-08-26 21:44:50,465 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-08-26 21:44:50,465 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 21:44:50,466 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 21:44:50,466 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:44:50,466 - INFO - Calculated ground truth crop region: rows [106:209], cols [22:209]
2025-08-26 21:44:50,466 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(103, 187)
2025-08-26 21:44:50,466 - INFO - Center-cropping from (188, 188) to (103, 187)
2025-08-26 21:44:50,466 - INFO - Final aligned shape: (103, 187)
2025-08-26 21:44:50,466 - INFO - --- Alignment complete ---
2025-08-26 21:44:50,466 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 187, 1), Ground Truth=(103, 187, 1)
2025-08-26 21:44:50,486 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 21:44:50,486 - INFO -   MAE:  (np.float32(0.09690987), np.float64(0.24318861110744783))
2025-08-26 21:44:50,486 - INFO -   PSNR: (63.19861633410001, 59.38766924203978)
2025-08-26 21:44:50,524 - INFO - Metrics and reconstruction images saved.
2025-08-26 21:44:50,524 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.085467
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.519010, std=0.156502, shape=(99, 183, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.020947, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.085467
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.519010, std=0.156502, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.020947, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
[2025-08-26 21:44:51] SUCCESS: Baseline training (n_images=128, trial=1)
[2025-08-26 21:44:51] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 21:44:51] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/test.npz' \
                '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 128 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 21:45:08] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 21:45:08] Completed training for train_size=128 (Trial 1/1)
[2025-08-26 21:45:08] Completed all trials for train_size=128
[2025-08-26 21:45:08] Model training phase completed
[2025-08-26 21:45:08] === STEP 3: Model Comparison ===
[2025-08-26 21:45:08] Running comparisons for train_size=128, test_size=128 (1 trials)
[2025-08-26 21:45:08] Using test subset size 128 (3-way comparison mode with Pty-chi)
[2025-08-26 21:45:08] EXECUTING: Model comparison (train_size=128, trial=1)
[2025-08-26 21:45:08] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/test.npz' --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1' --tike_recon_path '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 128
2025-08-26 21:45:08.796055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756269908.807726 3505516 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756269908.811461 3505516 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756269908.822698 3505516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269908.822709 3505516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269908.822710 3505516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756269908.822711 3505516 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 21:45:08.825562: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 21:45:11,097 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 21:45:11,097 - INFO - Registration: enabled
2025-08-26 21:45:11,097 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 21:45:11,097 - INFO - Initializing configuration before data loading...
2025-08-26 21:45:11,097 - INFO - Initialized with gridsize=1, n_images=128
2025-08-26 21:45:11,097 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/test.npz...
2025-08-26 21:45:11,097 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=128
2025-08-26 21:45:11,401 - INFO - Using specified subset of 128 images from 2424 total (gridsize=1)
diff3d shape: (128, 64, 64)2025-08-26 21:45:11,401 - INFO - diff3d shape: (128, 64, 64)

probeGuess shape: (64, 64)2025-08-26 21:45:11,401 - INFO - probeGuess shape: (64, 64)

scan_index shape: (128,)2025-08-26 21:45:11,401 - INFO - scan_index shape: (128,)

objectGuess shape: (232, 232)2025-08-26 21:45:11,401 - INFO - objectGuess shape: (232, 232)

xcoords shape: (128,)2025-08-26 21:45:11,401 - INFO - xcoords shape: (128,)

ycoords shape: (128,)2025-08-26 21:45:11,401 - INFO - ycoords shape: (128,)

xcoords_start shape: (128,)2025-08-26 21:45:11,402 - INFO - xcoords_start shape: (128,)

ycoords_start shape: (128,)2025-08-26 21:45:11,402 - INFO - ycoords_start shape: (128,)

2025-08-26 21:45:11,402 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 21:45:11,402 - INFO - DEBUG:
 nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 21:45:11,402 - INFO - nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 21:45:11,402 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 21:45:11,402 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 21:45:11,402 - INFO - Using all 128 points as seeds
2025-08-26 21:45:11,402 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 21:45:11,402 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 21:45:11,402 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 21:45:11,403 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756269911.521128 3505516 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756269911.522371 3505516 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 21:45:11,550 - INFO - neighbor-sampled diffraction shape
 (128, 64, 64, 1)2025-08-26 21:45:11,550 - INFO - (128, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 21:45:11,558 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 21:45:11,949 - INFO - INFO:
 None2025-08-26 21:45:11,949 - INFO - None

<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 21:45:11,950 - INFO - <PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 21:45:11,950 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run...
2025-08-26 21:45:11,950 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
Model: "functional"
2025-08-26 21:45:12,714 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 21:45:12,735 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 21:45:12,735 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 21:45:12,735 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 21:45:12,736 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 21:45:12,736 - INFO - None

2025-08-26 21:45:12.736211: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 21:45:12.736220: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756269912.736233 3505516 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756269912.753379 3505516 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 21:45:12.753456: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756269912.753527 3505516 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:45:12,900 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:45:12,901 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 21:45:13,376 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
2025-08-26 21:45:13,377 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1...
2025-08-26 21:45:13,377 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/baseline_model.h5
2025-08-26 21:45:13,465 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 21:45:13,470 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 21:45:13,471 - INFO - Loaded Pty-chi (ePIE) reconstruction: (197, 279) (complex64)
2025-08-26 21:45:13,471 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 21:45:13,471 - INFO - Pty-chi (ePIE) computation time: 12.65s
2025-08-26 21:45:13,471 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756269914.531172 3505651 service.cc:152] XLA service 0x7153e8001a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756269914.531193 3505651 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 21:45:14.612530: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756269914.760366 3505651 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756269916.073305 3505651 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step2025-08-26 21:45:16,082 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 21:45:16,110 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 21:45:16,122 - INFO - PtychoPINN inference completed in 2.65s
2025-08-26 21:45:16,122 - INFO - Reassembling PtychoPINN patches...
2025-08-26 21:45:17,608 - INFO - Running inference with Baseline model...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 565ms/step2025-08-26 21:45:18,188 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 565ms/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
2025-08-26 21:45:18,210 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step
2025-08-26 21:45:18,222 - INFO - Baseline inference completed in 0.61s
2025-08-26 21:45:18,226 - INFO - Reassembling baseline patches...
2025-08-26 21:45:18,229 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 21:45:18,282 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions.npz
2025-08-26 21:45:18,282 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_metadata.txt
2025-08-26 21:45:18,282 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 21:45:18,282 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 21:45:18,282 - INFO - Ground truth original shape: (232, 232)
2025-08-26 21:45:18,282 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:45:18,282 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:45:18,282 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 21:45:18,282 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 21:45:18,282 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:45:18,282 - INFO - --- Alignment complete ---
2025-08-26 21:45:18,282 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:45:18,282 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:45:18,282 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 21:45:18,283 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 21:45:18,283 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:45:18,283 - INFO - --- Alignment complete ---
2025-08-26 21:45:18,283 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 21:45:18,283 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 21:45:18,283 - INFO - Initial shapes: Recon=(197, 279), Cropped GT=(101, 185)
2025-08-26 21:45:18,283 - INFO - Center-cropping from (197, 279) to (101, 185)
2025-08-26 21:45:18,283 - INFO - Final aligned shape: (101, 185)
2025-08-26 21:45:18,283 - INFO - --- Alignment complete ---
2025-08-26 21:45:18,283 - INFO - Performing fine-scale registration to correct pixel-level misalignments...
2025-08-26 21:45:18,285 - INFO - PtychoPINN detected offset: (45.040, -34.200)
2025-08-26 21:45:18,288 - INFO - Baseline detected offset: (34.020, -17.960)
2025-08-26 21:45:18,290 - INFO - Tike detected offset: (0.780, 7.080)
2025-08-26 21:45:18,291 - INFO - Registration completed. PtychoPINN offset: (45.040000915527344, -34.20000076293945), Baseline offset: (34.02000045776367, -17.959999084472656), Pty-chi (ePIE) offset: (0.7799999713897705, 7.079999923706055)
2025-08-26 21:45:18,291 - INFO - Final aligned shapes - PINN: (97, 181), Baseline: (97, 181), Pty-chi (ePIE): (97, 181), GT: (97, 181)
2025-08-26 21:45:18,291 - INFO - Final evaluation shapes: PINN (97, 181), Baseline (97, 181), Pty-chi (ePIE) (97, 181), GT (97, 181)
Amplitude normalization scale factor: 0.8149482025-08-26 21:45:18,294 - INFO - Amplitude normalization scale factor: 0.814948

mean scale adjustment:2025-08-26 21:45:18,294 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,294 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,294 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,294 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:45:18,295 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.691605, std=0.238189, shape=(93, 177, 1)2025-08-26 21:45:18,295 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.691605, std=0.238189, shape=(93, 177, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:45:18,295 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.715972, shape=(93, 177)2025-08-26 21:45:18,296 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=0.000000, std=0.715972, shape=(93, 177)

performed by index method2025-08-26 21:45:18,296 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,298 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,300 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:45:18,302 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,302 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,302 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,302 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:45:18,302 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0210) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 21:45:18,304 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0210) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
performed by index method2025-08-26 21:45:18,305 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,307 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,309 - INFO - performed by index method

2025-08-26 21:45:18,310 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.021, phase=0.293, MS-SSIM: amp=0.021, phase=0.237
Amplitude normalization scale factor: 1.0978542025-08-26 21:45:18,312 - INFO - Amplitude normalization scale factor: 1.097854

mean scale adjustment:2025-08-26 21:45:18,312 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,312 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,312 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,312 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:45:18,313 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.513385, std=0.178134, shape=(93, 177, 1)2025-08-26 21:45:18,313 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.513385, std=0.178134, shape=(93, 177, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:45:18,313 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.702938, shape=(93, 177)2025-08-26 21:45:18,313 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=0.000000, std=0.702938, shape=(93, 177)

performed by index method2025-08-26 21:45:18,314 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,316 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,317 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:45:18,319 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,319 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,319 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,319 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:45:18,319 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

performed by index method2025-08-26 21:45:18,323 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,324 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,326 - INFO - performed by index method

2025-08-26 21:45:18,328 - INFO - Baseline evaluation complete. SSIM: amp=0.057, phase=0.410, MS-SSIM: amp=0.085, phase=0.227
Amplitude normalization scale factor: 0.4883102025-08-26 21:45:18,330 - INFO - Amplitude normalization scale factor: 0.488310

mean scale adjustment:2025-08-26 21:45:18,330 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,330 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,330 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,330 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)2025-08-26 21:45:18,331 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563622, std=0.045567, shape=(93, 177, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.154230, std=0.311312, shape=(93, 177, 1)2025-08-26 21:45:18,331 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.154230, std=0.311312, shape=(93, 177, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)2025-08-26 21:45:18,331 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.271600, shape=(93, 177)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.282608, shape=(93, 177)2025-08-26 21:45:18,331 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.282608, shape=(93, 177)

performed by index method2025-08-26 21:45:18,331 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,333 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,335 - INFO - performed by index method

mean scale adjustment:2025-08-26 21:45:18,336 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,336 - INFO - 1

mean scale adjustment:2025-08-26 21:45:18,336 - INFO - mean scale adjustment:
 12025-08-26 21:45:18,336 - INFO - 1

Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]2025-08-26 21:45:18,337 - INFO - Phase preprocessing: plane-fitted range [-0.683, 0.413] -> scaled range [0.391, 0.566]

performed by index method2025-08-26 21:45:18,340 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,342 - INFO - performed by index method

performed by index method2025-08-26 21:45:18,343 - INFO - performed by index method

2025-08-26 21:45:18,345 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=0.334, phase=0.783, MS-SSIM: amp=0.685, phase=0.808
2025-08-26 21:45:18,346 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 21:45:18,346 - INFO - --- Comparison Metrics ---

         model                 metric  amplitude     phase      value
    PtychoPINN                    mae   0.127221  0.435157        NaN
    PtychoPINN                    mse   0.040135  0.588002        NaN
    PtychoPINN                   psnr  62.095599 50.437014        NaN
    PtychoPINN                   ssim   0.020692  0.292592        NaN
    PtychoPINN                ms_ssim   0.020987  0.236945        NaN
    PtychoPINN                  frc50   1.000000  1.000000        NaN
      Baseline                    mae   0.122256  0.396257        NaN
      Baseline                    mse   0.040120  0.563587        NaN
      Baseline                   psnr  62.097227 50.621196        NaN
      Baseline                   ssim   0.056928  0.410153        NaN
      Baseline                ms_ssim   0.084711  0.226750        NaN
      Baseline                  frc50   1.000000  1.000000        NaN
Pty-chi (ePIE)                    mae   0.091905  0.152665        NaN
Pty-chi (ePIE)                    mse   0.019366  0.043322        NaN
Pty-chi (ePIE)                   psnr  65.260345 61.763706        NaN
Pty-chi (ePIE)                   ssim   0.333555  0.783219        NaN
Pty-chi (ePIE)                ms_ssim   0.685400  0.808381        NaN
Pty-chi (ePIE)                  frc50   1.000000  1.000000        NaN
    PtychoPINN registration_offset_dy        NaN       NaN  45.040001
    PtychoPINN registration_offset_dx        NaN       NaN -34.200001
      Baseline registration_offset_dy        NaN       NaN  34.020000
      Baseline registration_offset_dx        NaN       NaN -17.959999
Pty-chi (ePIE) registration_offset_dy        NaN       NaN   0.780000
Pty-chi (ePIE) registration_offset_dx        NaN       NaN   7.080000
    PtychoPINN     computation_time_s        NaN       NaN   2.650565
      Baseline     computation_time_s        NaN       NaN   0.613855
Pty-chi (ePIE)     computation_time_s        NaN       NaN  12.6511672025-08-26 21:45:18,348 - INFO - model                 metric  amplitude     phase      value
    PtychoPINN                    mae   0.127221  0.435157        NaN
    PtychoPINN                    mse   0.040135  0.588002        NaN
    PtychoPINN                   psnr  62.095599 50.437014        NaN
    PtychoPINN                   ssim   0.020692  0.292592        NaN
    PtychoPINN                ms_ssim   0.020987  0.236945        NaN
    PtychoPINN                  frc50   1.000000  1.000000        NaN
      Baseline                    mae   0.122256  0.396257        NaN
      Baseline                    mse   0.040120  0.563587        NaN
      Baseline                   psnr  62.097227 50.621196        NaN
      Baseline                   ssim   0.056928  0.410153        NaN
      Baseline                ms_ssim   0.084711  0.226750        NaN
      Baseline                  frc50   1.000000  1.000000        NaN
Pty-chi (ePIE)                    mae   0.091905  0.152665        NaN
Pty-chi (ePIE)                    mse   0.019366  0.043322        NaN
Pty-chi (ePIE)                   psnr  65.260345 61.763706        NaN
Pty-chi (ePIE)                   ssim   0.333555  0.783219        NaN
Pty-chi (ePIE)                ms_ssim   0.685400  0.808381        NaN
Pty-chi (ePIE)                  frc50   1.000000  1.000000        NaN
    PtychoPINN registration_offset_dy        NaN       NaN  45.040001
    PtychoPINN registration_offset_dx        NaN       NaN -34.200001
      Baseline registration_offset_dy        NaN       NaN  34.020000
      Baseline registration_offset_dx        NaN       NaN -17.959999
Pty-chi (ePIE) registration_offset_dy        NaN       NaN   0.780000
Pty-chi (ePIE) registration_offset_dx        NaN       NaN   7.080000
    PtychoPINN     computation_time_s        NaN       NaN   2.650565
      Baseline     computation_time_s        NaN       NaN   0.613855
Pty-chi (ePIE)     computation_time_s        NaN       NaN  12.651167

2025-08-26 21:45:18,349 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_frc_curves.csv
2025-08-26 21:45:18,349 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_frc_curves.csv
2025-08-26 21:45:18,349 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 21:45:18,398 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned.npz
2025-08-26 21:45:18,398 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 21:45:18,398 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 21:45:18,435 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.123, 0.850) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,435 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.018, 0.578) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,436 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.237, 0.443) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,436 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.075, 0.075) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,437 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.840, 1.599) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,437 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.457, 0.277) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,445 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.501, 0.619) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:18,446 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.465, 0.273) using 10.0/90.0 percentiles [per-panel].
2025-08-26 21:45:19,121 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_plot.png
2025-08-26 21:45:19,121 - INFO - 
Comparison complete!
2025-08-26 21:45:19,121 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1
[2025-08-26 21:45:20] SUCCESS: Model comparison (train_size=128, trial=1)
[2025-08-26 21:45:20] Completed comparisons for train_size=128
[2025-08-26 21:45:20] Model comparison phase completed
[2025-08-26 21:45:20] === STEP 4: Results Aggregation ===
[2025-08-26 21:45:20] EXECUTING: PSNR phase generalization plot
[2025-08-26 21:45:20] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
21:45:20 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:20 - INFO - Analyzing psnr_phase
21:45:20 - INFO - Discovered 1 comparison files
21:45:20 - INFO - Single-trial data detected - using legacy aggregation
21:45:20 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:20 - INFO - Loaded 3 trial records
21:45:20 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:20 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:20 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:20 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:20 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:20 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:20 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:20 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:20 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:20 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:20 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:20 - INFO - NaN exclusion summary:
21:45:20 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:20 - INFO - Extracted 1 data points for psnr_phase (using mean)
21:45:20 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:45:20 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
21:45:20 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:20 - INFO - Processing complete!
21:45:20 - INFO - Outputs:
21:45:20 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
21:45:20 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:20 - INFO - Summary: 1 models, 1 training sizes
21:45:20 - INFO - Training sizes: [np.int64(128)]
21:45:20 - INFO - Model types: ['iterative']
[2025-08-26 21:45:20] SUCCESS: PSNR phase generalization plot
[2025-08-26 21:45:20] EXECUTING: FRC amplitude generalization plot
[2025-08-26 21:45:20] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
21:45:21 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:21 - INFO - Analyzing frc50_amp
21:45:21 - INFO - Discovered 1 comparison files
21:45:21 - INFO - Single-trial data detected - using legacy aggregation
21:45:21 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:21 - INFO - Loaded 3 trial records
21:45:21 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:21 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:21 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:21 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:21 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:21 - INFO - NaN exclusion summary:
21:45:21 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO - Extracted 1 data points for frc50_amp (using mean)
21:45:21 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:45:21 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
21:45:21 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:21 - INFO - Processing complete!
21:45:21 - INFO - Outputs:
21:45:21 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
21:45:21 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:21 - INFO - Summary: 1 models, 1 training sizes
21:45:21 - INFO - Training sizes: [np.int64(128)]
21:45:21 - INFO - Model types: ['iterative']
[2025-08-26 21:45:21] SUCCESS: FRC amplitude generalization plot
[2025-08-26 21:45:21] EXECUTING: MAE amplitude generalization plot
[2025-08-26 21:45:21] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
21:45:21 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:21 - INFO - Analyzing mae_amp
21:45:21 - INFO - Discovered 1 comparison files
21:45:21 - INFO - Single-trial data detected - using legacy aggregation
21:45:21 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:21 - INFO - Loaded 3 trial records
21:45:21 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:21 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:21 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:21 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:21 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:21 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:21 - INFO - NaN exclusion summary:
21:45:21 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:21 - INFO - Extracted 1 data points for mae_amp (using mean)
21:45:21 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:45:21 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
21:45:21 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:21 - INFO - Processing complete!
21:45:21 - INFO - Outputs:
21:45:21 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
21:45:21 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:21 - INFO - Summary: 1 models, 1 training sizes
21:45:21 - INFO - Training sizes: [np.int64(128)]
21:45:21 - INFO - Model types: ['iterative']
[2025-08-26 21:45:22] SUCCESS: MAE amplitude generalization plot
[2025-08-26 21:45:22] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 21:45:22] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
21:45:22 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:22 - INFO - Analyzing ssim_amp
21:45:22 - INFO - Discovered 1 comparison files
21:45:22 - INFO - Single-trial data detected - using legacy aggregation
21:45:22 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:22 - INFO - Loaded 3 trial records
21:45:22 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:22 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:22 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:22 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:22 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:22 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:22 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:22 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:22 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:22 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:22 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:22 - INFO - NaN exclusion summary:
21:45:22 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:22 - INFO - Extracted 1 data points for ssim_amp (using mean)
21:45:22 - WARNING - Missing expected model types: {'pinn', 'baseline'}
21:45:22 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
21:45:22 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:22 - INFO - Processing complete!
21:45:22 - INFO - Outputs:
21:45:22 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
21:45:22 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:22 - INFO - Summary: 1 models, 1 training sizes
21:45:22 - INFO - Training sizes: [np.int64(128)]
21:45:22 - INFO - Model types: ['iterative']
[2025-08-26 21:45:22] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 21:45:22] EXECUTING: SSIM phase generalization plot
[2025-08-26 21:45:22] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
21:45:23 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:23 - INFO - Analyzing ssim_phase
21:45:23 - INFO - Discovered 1 comparison files
21:45:23 - INFO - Single-trial data detected - using legacy aggregation
21:45:23 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:23 - INFO - Loaded 3 trial records
21:45:23 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:23 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:23 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:23 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:23 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:23 - INFO - NaN exclusion summary:
21:45:23 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO - Extracted 1 data points for ssim_phase (using mean)
21:45:23 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:45:23 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
21:45:23 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:23 - INFO - Processing complete!
21:45:23 - INFO - Outputs:
21:45:23 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
21:45:23 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:23 - INFO - Summary: 1 models, 1 training sizes
21:45:23 - INFO - Training sizes: [np.int64(128)]
21:45:23 - INFO - Model types: ['iterative']
[2025-08-26 21:45:23] SUCCESS: SSIM phase generalization plot
[2025-08-26 21:45:23] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 21:45:23] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
21:45:23 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:23 - INFO - Analyzing ms_ssim_amp
21:45:23 - INFO - Discovered 1 comparison files
21:45:23 - INFO - Single-trial data detected - using legacy aggregation
21:45:23 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:23 - INFO - Loaded 3 trial records
21:45:23 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:23 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:23 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:23 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:23 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:23 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:23 - INFO - NaN exclusion summary:
21:45:23 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:23 - INFO - Extracted 1 data points for ms_ssim_amp (using mean)
21:45:23 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:45:23 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
21:45:23 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:23 - INFO - Processing complete!
21:45:23 - INFO - Outputs:
21:45:23 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
21:45:23 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:23 - INFO - Summary: 1 models, 1 training sizes
21:45:23 - INFO - Training sizes: [np.int64(128)]
21:45:23 - INFO - Model types: ['iterative']
[2025-08-26 21:45:23] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 21:45:23] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 21:45:23] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
21:45:24 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
21:45:24 - INFO - Analyzing ms_ssim_phase
21:45:24 - INFO - Discovered 1 comparison files
21:45:24 - INFO - Single-trial data detected - using legacy aggregation
21:45:24 - INFO - Total NaN values in data: 18 (0 new, 18 preserved)
21:45:24 - INFO - Loaded 3 trial records
21:45:24 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
21:45:24 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
21:45:24 - WARNING - Only 1 trials for train_size=128, model=iterative. Percentile calculations may be unreliable.
21:45:24 - WARNING - All 1 trials have NaN for registration_offset_dy_amp (train_size=128, model=iterative)
21:45:24 - WARNING - All 1 trials have NaN for registration_offset_dy_phase (train_size=128, model=iterative)
21:45:24 - WARNING - All 1 trials have NaN for registration_offset_dx_amp (train_size=128, model=iterative)
21:45:24 - WARNING - All 1 trials have NaN for registration_offset_dx_phase (train_size=128, model=iterative)
21:45:24 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=iterative)
21:45:24 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=iterative)
21:45:24 - INFO - Computed statistics for 1 (train_size, model_type) combinations
21:45:24 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
21:45:24 - INFO - NaN exclusion summary:
21:45:24 - INFO -   registration_offset_dy_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO -   registration_offset_dy_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO -   registration_offset_dx_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO -   registration_offset_dx_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
21:45:24 - INFO - Extracted 1 data points for ms_ssim_phase (using mean)
21:45:24 - WARNING - Missing expected model types: {'baseline', 'pinn'}
21:45:24 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
21:45:24 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
21:45:24 - INFO - Processing complete!
21:45:24 - INFO - Outputs:
21:45:24 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
21:45:24 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
21:45:24 - INFO - Summary: 1 models, 1 training sizes
21:45:24 - INFO - Training sizes: [np.int64(128)]
21:45:24 - INFO - Model types: ['iterative']
[2025-08-26 21:45:24] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 21:45:24] Results aggregation completed
[2025-08-26 21:45:24] === Generating Summary Report ===
[2025-08-26 21:45:24] Summary report generated: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 21:45:24] === Study Completed Successfully ===
[2025-08-26 21:45:24] Training sizes tested: 1
[2025-08-26 21:45:24] Trials per size: 1
[2025-08-26 21:45:24] Total trials completed: 1
[2025-08-26 21:45:24] Total runtime: 00:01:25
[2025-08-26 21:45:24] Results directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 21:45:24] Summary report: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 23:38:08] === Starting Complete Generalization Study ===
[2025-08-26 23:38:08] Training sizes: 128
[2025-08-26 23:38:08] Number of trials per size: 1
[2025-08-26 23:38:08] Output directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 23:38:08] Total training runs planned: 2
[2025-08-26 23:38:08] Validating environment...
[2025-08-26 23:38:08] Environment validation passed
[2025-08-26 23:38:08] Configuration saved to: 3way_synthetic_ptychi_1e4_128/study_config.txt
[2025-08-26 23:38:08] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 23:38:08] === STEP 2: Model Training ===
[2025-08-26 23:38:08] Training models sequentially with 1 trials per training size
[2025-08-26 23:38:08] Starting training for train_size=128, test_size=128 (1 trials)
[2025-08-26 23:38:08] Training models for train_size=128, test_size=128 (Trial 1/1)
[2025-08-26 23:38:08] EXECUTING: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 23:38:08] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 23:38:09.078512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756276689.090456 3524881 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756276689.094231 3524881 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756276689.105264 3524881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276689.105274 3524881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276689.105275 3524881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276689.105277 3524881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 23:38:09.108119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 23:38:11,907 - INFO - Configuration setup complete
2025-08-26 23:38:11,907 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 23:38:11,907 - INFO - Parameter interpretation: --n-images=128 refers to individual images (gridsize=1)
2025-08-26 23:38:11,907 - INFO - Starting training with n_images=128, stitching=disabled
2025-08-26 23:38:11,907 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 23:38:12,224 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
2025-08-26 23:38:12,543 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 23:38:12,543 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 23:38:12,841 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
2025-08-26 23:38:12,841 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/test.npz
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 23:38:12,841 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 23:38:12,841 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 23:38:12,841 - INFO - Using all 128 points as seeds
2025-08-26 23:38:12,842 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 23:38:12,842 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 23:38:12,842 - INFO - Generated 128 groups efficiently
I0000 00:00:1756276692.973771 3524881 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756276692.975048 3524881 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 23:38:13,368 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 23:38:13,368 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 23:38:13,369 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 23:38:13,369 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 23:38:13,369 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 23:38:13,369 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1233.258 global_offsets=(128, 1, 2, 1) mean=131.873 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 23:38:14.034931: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 23:38:14.034942: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756276694.034955 3524881 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756276694.051928 3524881 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 23:38:14.052003: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756276694.052260 3524881 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756276694.741625 3524881 service.cc:152] XLA service 0x2f446430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756276694.741643 3524881 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 23:38:14.771970: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756276694.790132 3524881 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756276695.342080 3524881 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 23:38:15,854 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 23:38:17,723 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 23:38:21.293544: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 23:38:21.350408: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 23:38:21.394485: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 23:38:21.576210: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m47s[0m 7s/step - intensity_scaler_inv_loss: 0.6342 - loss: 0.5962 - pred_intensity_loss: 0.5962 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 2.7741 - loss: 39.3451 - pred_intensity_loss: 39.3451 - trimmed_obj_loss: 0.0000e+002025-08-26 23:38:23.739051: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 23:38:23.764151: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 23:38:23.768199: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 23:38:24.035508: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 335ms/step - intensity_scaler_inv_loss: 2.4324 - loss: 33.1237 - pred_intensity_loss: 32.9836 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 23:38:24,971 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m10s[0m 513ms/step - intensity_scaler_inv_loss: 1.6982 - loss: 20.4569 - pred_intensity_loss: 19.3359 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5726 - val_loss: 0.0344 - val_pred_intensity_loss: 0.0344 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.5630 - loss: 0.0067 - pred_intensity_loss: 0.0067 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5566 - loss: -0.0207 - pred_intensity_loss: -0.0207 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5546 - loss: -0.1054 - pred_intensity_loss: -0.1092 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5447 - val_loss: -0.1613 - val_pred_intensity_loss: -0.1613 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5388 - loss: -0.1741 - pred_intensity_loss: -0.1741 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5231 - loss: -0.2009 - pred_intensity_loss: -0.2009 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5184 - loss: -0.2227 - pred_intensity_loss: -0.2229 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5133 - val_loss: -0.2282 - val_pred_intensity_loss: -0.2282 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.5173 - loss: -0.2565 - pred_intensity_loss: -0.2565 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5137 - loss: -0.2555 - pred_intensity_loss: -0.2555 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5134 - loss: -0.2529 - pred_intensity_loss: -0.2504 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5140 - val_loss: -0.2231 - val_pred_intensity_loss: -0.2231 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5120 - loss: -0.2112 - pred_intensity_loss: -0.2112 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5097 - loss: -0.2413 - pred_intensity_loss: -0.2413 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5084 - loss: -0.2628 - pred_intensity_loss: -0.2642 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5063 - val_loss: -0.2391 - val_pred_intensity_loss: -0.2391 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5039 - loss: -0.3171 - pred_intensity_loss: -0.3171 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5067 - loss: -0.2778 - pred_intensity_loss: -0.2778 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.5030 - loss: -0.2732 - pred_intensity_loss: -0.2752 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5086 - val_loss: -0.2477 - val_pred_intensity_loss: -0.2477 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5062 - loss: -0.2474 - pred_intensity_loss: -0.2474 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5053 - loss: -0.2670 - pred_intensity_loss: -0.2670 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5028 - loss: -0.2797 - pred_intensity_loss: -0.2810 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5032 - val_loss: -0.2584 - val_pred_intensity_loss: -0.2584 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4913 - loss: -0.3209 - pred_intensity_loss: -0.3209 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4968 - loss: -0.2986 - pred_intensity_loss: -0.2986 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.5004 - loss: -0.2876 - pred_intensity_loss: -0.2852 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4972 - val_loss: -0.2711 - val_pred_intensity_loss: -0.2711 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4986 - loss: -0.2709 - pred_intensity_loss: -0.2709 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4993 - loss: -0.2880 - pred_intensity_loss: -0.2880 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4977 - loss: -0.2959 - pred_intensity_loss: -0.2966 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4919 - val_loss: -0.2814 - val_pred_intensity_loss: -0.2814 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4950 - loss: -0.2937 - pred_intensity_loss: -0.2937 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4919 - loss: -0.3154 - pred_intensity_loss: -0.3154 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4949 - loss: -0.3045 - pred_intensity_loss: -0.3017 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4926 - val_loss: -0.2121 - val_pred_intensity_loss: -0.2121 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4990 - loss: -0.2430 - pred_intensity_loss: -0.2430 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4974 - loss: -0.2453 - pred_intensity_loss: -0.2453 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4940 - loss: -0.2850 - pred_intensity_loss: -0.2855 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4875 - val_loss: -0.2880 - val_pred_intensity_loss: -0.2880 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4751 - loss: -0.3788 - pred_intensity_loss: -0.3788 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4887 - loss: -0.3362 - pred_intensity_loss: -0.3362 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4907 - loss: -0.3133 - pred_intensity_loss: -0.3115 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4895 - val_loss: -0.3013 - val_pred_intensity_loss: -0.3013 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4934 - loss: -0.3566 - pred_intensity_loss: -0.3566 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4899 - loss: -0.3399 - pred_intensity_loss: -0.3399 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4848 - loss: -0.3282 - pred_intensity_loss: -0.3266 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4800 - val_loss: -0.3192 - val_pred_intensity_loss: -0.3192 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4811 - loss: -0.3473 - pred_intensity_loss: -0.3473 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4834 - loss: -0.3380 - pred_intensity_loss: -0.3380 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4801 - loss: -0.3401 - pred_intensity_loss: -0.3394 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4749 - val_loss: -0.3251 - val_pred_intensity_loss: -0.3251 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4770 - loss: -0.3469 - pred_intensity_loss: -0.3469 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4762 - loss: -0.3493 - pred_intensity_loss: -0.3493 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4760 - loss: -0.3477 - pred_intensity_loss: -0.3481 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4762 - val_loss: -0.3317 - val_pred_intensity_loss: -0.3317 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4831 - loss: -0.3771 - pred_intensity_loss: -0.3771 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4799 - loss: -0.3483 - pred_intensity_loss: -0.3483 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4744 - loss: -0.3551 - pred_intensity_loss: -0.3558 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4700 - val_loss: -0.3378 - val_pred_intensity_loss: -0.3378 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4700 - loss: -0.3739 - pred_intensity_loss: -0.3739 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4721 - loss: -0.3644 - pred_intensity_loss: -0.3644 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4710 - loss: -0.3628 - pred_intensity_loss: -0.3668 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4731 - val_loss: -0.3419 - val_pred_intensity_loss: -0.3419 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4733 - loss: -0.3389 - pred_intensity_loss: -0.3389 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4702 - loss: -0.3563 - pred_intensity_loss: -0.3563 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4686 - loss: -0.3705 - pred_intensity_loss: -0.3708 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4747 - val_loss: -0.3456 - val_pred_intensity_loss: -0.3456 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4622 - loss: -0.3586 - pred_intensity_loss: -0.3586 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4651 - loss: -0.3683 - pred_intensity_loss: -0.3683 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4672 - loss: -0.3782 - pred_intensity_loss: -0.3808 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4672 - val_loss: -0.3566 - val_pred_intensity_loss: -0.3566 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4622 - loss: -0.3933 - pred_intensity_loss: -0.3933 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4613 - loss: -0.3947 - pred_intensity_loss: -0.3947 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4634 - loss: -0.3867 - pred_intensity_loss: -0.3885 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4622 - val_loss: -0.3624 - val_pred_intensity_loss: -0.3624 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4545 - loss: -0.4244 - pred_intensity_loss: -0.4244 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4581 - loss: -0.4081 - pred_intensity_loss: -0.4081 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4603 - loss: -0.3942 - pred_intensity_loss: -0.3953 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4643 - val_loss: -0.3680 - val_pred_intensity_loss: -0.3680 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4626 - loss: -0.3961 - pred_intensity_loss: -0.3961 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4611 - loss: -0.4044 - pred_intensity_loss: -0.4044 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4586 - loss: -0.3991 - pred_intensity_loss: -0.3981 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4568 - val_loss: -0.3763 - val_pred_intensity_loss: -0.3763 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4563 - loss: -0.3953 - pred_intensity_loss: -0.3953 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4586 - loss: -0.4175 - pred_intensity_loss: -0.4175 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4572 - loss: -0.4036 - pred_intensity_loss: -0.4015 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4544 - val_loss: -0.3821 - val_pred_intensity_loss: -0.3821 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4533 - loss: -0.3896 - pred_intensity_loss: -0.3896 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4541 - loss: -0.4133 - pred_intensity_loss: -0.4133 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4552 - loss: -0.4073 - pred_intensity_loss: -0.4053 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4539 - val_loss: -0.3845 - val_pred_intensity_loss: -0.3845 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4498 - loss: -0.4174 - pred_intensity_loss: -0.4174 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4552 - loss: -0.4147 - pred_intensity_loss: -0.4147 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4546 - loss: -0.4084 - pred_intensity_loss: -0.4062 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4556 - val_loss: -0.3879 - val_pred_intensity_loss: -0.3879 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4551 - loss: -0.4143 - pred_intensity_loss: -0.4143 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4559 - loss: -0.4157 - pred_intensity_loss: -0.4157 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4530 - loss: -0.4145 - pred_intensity_loss: -0.4082 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4513 - val_loss: -0.3924 - val_pred_intensity_loss: -0.3924 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4518 - loss: -0.3982 - pred_intensity_loss: -0.3982 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4071 - pred_intensity_loss: -0.4071 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4511 - loss: -0.4188 - pred_intensity_loss: -0.4166 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4516 - val_loss: -0.3967 - val_pred_intensity_loss: -0.3967 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4533 - loss: -0.4140 - pred_intensity_loss: -0.4140 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4289 - pred_intensity_loss: -0.4289 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4504 - loss: -0.4224 - pred_intensity_loss: -0.4212 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4517 - val_loss: -0.3972 - val_pred_intensity_loss: -0.3972 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4561 - loss: -0.4132 - pred_intensity_loss: -0.4132 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4517 - loss: -0.4157 - pred_intensity_loss: -0.4157 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4502 - loss: -0.4238 - pred_intensity_loss: -0.4264 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4512 - val_loss: -0.3986 - val_pred_intensity_loss: -0.3986 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4493 - loss: -0.4208 - pred_intensity_loss: -0.4208 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4282 - pred_intensity_loss: -0.4282 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4500 - loss: -0.4236 - pred_intensity_loss: -0.4229 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4508 - val_loss: -0.4008 - val_pred_intensity_loss: -0.4008 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4519 - loss: -0.3811 - pred_intensity_loss: -0.3811 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4517 - loss: -0.4022 - pred_intensity_loss: -0.4022 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4487 - loss: -0.4266 - pred_intensity_loss: -0.4261 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4496 - val_loss: -0.4043 - val_pred_intensity_loss: -0.4043 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4494 - loss: -0.4456 - pred_intensity_loss: -0.4456 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4494 - loss: -0.4378 - pred_intensity_loss: -0.4378 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4288 - pred_intensity_loss: -0.4311 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4501 - val_loss: -0.4046 - val_pred_intensity_loss: -0.4046 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4465 - loss: -0.4592 - pred_intensity_loss: -0.4592 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4378 - pred_intensity_loss: -0.4378 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4483 - loss: -0.4295 - pred_intensity_loss: -0.4323 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4498 - val_loss: -0.4071 - val_pred_intensity_loss: -0.4071 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.3976 - pred_intensity_loss: -0.3976 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4492 - loss: -0.4189 - pred_intensity_loss: -0.4189 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4310 - pred_intensity_loss: -0.4322 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4504 - val_loss: -0.4032 - val_pred_intensity_loss: -0.4032 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4506 - loss: -0.4194 - pred_intensity_loss: -0.4194 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4324 - pred_intensity_loss: -0.4324 - trimmed_obj_loss: 0.0000e+00
Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4283 - pred_intensity_loss: -0.4294 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4469 - val_loss: -0.4063 - val_pred_intensity_loss: -0.4063 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4407 - pred_intensity_loss: -0.4407 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4308 - pred_intensity_loss: -0.4308 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4470 - loss: -0.4323 - pred_intensity_loss: -0.4324 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4486 - val_loss: -0.4096 - val_pred_intensity_loss: -0.4096 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4375 - pred_intensity_loss: -0.4375 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4258 - pred_intensity_loss: -0.4258 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4456 - loss: -0.4349 - pred_intensity_loss: -0.4367 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4482 - val_loss: -0.4099 - val_pred_intensity_loss: -0.4099 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4384 - pred_intensity_loss: -0.4384 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4317 - pred_intensity_loss: -0.4317 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4353 - pred_intensity_loss: -0.4376 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4468 - val_loss: -0.4112 - val_pred_intensity_loss: -0.4112 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4659 - pred_intensity_loss: -0.4659 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4469 - loss: -0.4495 - pred_intensity_loss: -0.4495 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4356 - pred_intensity_loss: -0.4355 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4478 - val_loss: -0.4114 - val_pred_intensity_loss: -0.4114 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4456 - loss: -0.4174 - pred_intensity_loss: -0.4174 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4211 - pred_intensity_loss: -0.4211 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4363 - pred_intensity_loss: -0.4386 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4471 - val_loss: -0.4121 - val_pred_intensity_loss: -0.4121 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4511 - pred_intensity_loss: -0.4511 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4483 - pred_intensity_loss: -0.4483 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4370 - pred_intensity_loss: -0.4362 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4464 - val_loss: -0.4124 - val_pred_intensity_loss: -0.4124 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4198 - pred_intensity_loss: -0.4198 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4451 - loss: -0.4282 - pred_intensity_loss: -0.4282 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4375 - pred_intensity_loss: -0.4389 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4472 - val_loss: -0.4126 - val_pred_intensity_loss: -0.4126 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4360 - pred_intensity_loss: -0.4360 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4326 - pred_intensity_loss: -0.4326 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4379 - pred_intensity_loss: -0.4355 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4467 - val_loss: -0.4125 - val_pred_intensity_loss: -0.4125 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4546 - pred_intensity_loss: -0.4546 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4469 - pred_intensity_loss: -0.4469 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4383 - pred_intensity_loss: -0.4368 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4454 - val_loss: -0.4132 - val_pred_intensity_loss: -0.4132 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4422 - pred_intensity_loss: -0.4422 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4354 - pred_intensity_loss: -0.4354 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4388 - pred_intensity_loss: -0.4412 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4457 - val_loss: -0.4134 - val_pred_intensity_loss: -0.4134 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.4168 - pred_intensity_loss: -0.4168 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4472 - loss: -0.4255 - pred_intensity_loss: -0.4255 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4393 - pred_intensity_loss: -0.4385 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4461 - val_loss: -0.4136 - val_pred_intensity_loss: -0.4136 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4469 - loss: -0.4637 - pred_intensity_loss: -0.4637 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4459 - pred_intensity_loss: -0.4459 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4399 - pred_intensity_loss: -0.4389 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4138 - val_pred_intensity_loss: -0.4138 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 30ms/step - intensity_scaler_inv_loss: 0.4402 - loss: -0.4569 - pred_intensity_loss: -0.4569 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4420 - loss: -0.4451 - pred_intensity_loss: -0.4451 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4396 - pred_intensity_loss: -0.4385 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4468 - val_loss: -0.4147 - val_pred_intensity_loss: -0.4147 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4488 - loss: -0.4600 - pred_intensity_loss: -0.4600 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4458 - loss: -0.4483 - pred_intensity_loss: -0.4483 - trimmed_obj_loss: 0.0000e+00[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 21ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4398 - pred_intensity_loss: -0.4377 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4479 - val_loss: -0.4134 - val_pred_intensity_loss: -0.4134 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4485 - pred_intensity_loss: -0.4485 - trimmed_obj_loss: 0.0000e+00[1m5/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4512 - pred_intensity_loss: -0.4512 - trimmed_obj_loss: 0.0000e+00
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 22ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4395 - pred_intensity_loss: -0.4370 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4501 - val_loss: -0.4101 - val_pred_intensity_loss: -0.4101 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 931ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 524288 into shape (6,6,64,64,1)
2025-08-26 23:38:35,839 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 23:38:37,212 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
[2025-08-26 23:38:38] SUCCESS: PtychoPINN training (n_images=128, trial=1)
[2025-08-26 23:38:38] EXECUTING: Baseline training (n_images=128, trial=1)
[2025-08-26 23:38:38] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/test.npz' \
            --n_images 128 \
            --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 23:38:38.718461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756276718.730281 3532524 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756276718.734035 3532524 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756276718.745053 3532524 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276718.745063 3532524 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276718.745064 3532524 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276718.745065 3532524 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 23:38:38.747907: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 23:38:41,270 - INFO - Configuration setup complete
2025-08-26 23:38:41,270 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/test.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=128, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 23:38:41,270 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 23:38:41,270 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 23:38:41,270 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-23.38.41_baseline_gs1/
2025-08-26 23:38:41,271 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756276721.380323 3532524 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756276721.381532 3532524 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 23:38:41,416 - INFO - 
[2/6] Loading data...
2025-08-26 23:38:41,416 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 23:38:41,416 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=128
2025-08-26 23:38:41,735 - INFO - Using specified subset of 128 images from 2576 total (gridsize=1)
2025-08-26 23:38:41,735 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=None
2025-08-26 23:38:42,035 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 23:38:42,036 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 23:38:42,036 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 23:38:42,036 - INFO - Using all 128 points as seeds
2025-08-26 23:38:42,036 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 23:38:42,036 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 23:38:42,036 - INFO - Generated 128 groups efficiently
2025-08-26 23:38:42,404 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 23:38:42,404 - INFO - Generating 128 groups efficiently from 2424 points (K=4, C=1)
2025-08-26 23:38:42,405 - INFO - Sampled 128 seed points from 2424 total points
2025-08-26 23:38:42,405 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 23:38:42,405 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 23:38:42,405 - INFO - Generated 128 groups efficiently
2025-08-26 23:38:42,415 - INFO - Globally set intensity_scale to: 988.2117309570312
2025-08-26 23:38:42,415 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 23:38:42,417 - INFO - Final training input shape: (128, 64, 64, 1)
2025-08-26 23:38:42,417 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 23:38:42,417 - INFO - Training with 128 images
DEBUG: Setting timestamp to 08/26/2025, 23:38:41 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 128
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-23.38.41_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/test.npz
timestamp: 08/26/2025, 23:38:41
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (128, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (128,)
objectGuess shape: (232, 232)
xcoords shape: (128,)
ycoords shape: (128,)
xcoords_start shape: (128,)
ycoords_start shape: (128,)
diff3d shape: (2424, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2424,)
objectGuess shape: (232, 232)
xcoords shape: (2424,)
ycoords shape: (2424,)
xcoords_start shape: (2424,)
ycoords_start shape: (2424,)
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=93.085 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (128, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=1297.438 global_offsets=(128, 1, 2, 1) mean=136.741 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.21173, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756276725.192738 3532660 service.cc:152] XLA service 0x7c1be0004d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756276725.192758 3532660 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 23:38:45.261491: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756276725.669423 3532660 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756276728.558568 3532660 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m38s[0m 6s/step - conv2d_12_loss: 0.5642 - conv2d_19_loss: 0.2156 - loss: 0.7798[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.9566 - conv2d_19_loss: 0.2445 - loss: 1.2011[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 414ms/step - conv2d_12_loss: 0.9386 - conv2d_19_loss: 0.2411 - loss: 1.1822[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 531ms/step - conv2d_12_loss: 0.8605 - conv2d_19_loss: 0.2302 - loss: 1.1107 - val_conv2d_12_loss: 0.5186 - val_conv2d_19_loss: 0.2291 - val_loss: 0.7478 - learning_rate: 0.0010
Epoch 2/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.5203 - conv2d_19_loss: 0.2099 - loss: 0.7303[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.5080 - conv2d_19_loss: 0.2123 - loss: 0.7204[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.4704 - conv2d_19_loss: 0.2130 - loss: 0.6881 - val_conv2d_12_loss: 0.3164 - val_conv2d_19_loss: 0.2290 - val_loss: 0.5454 - learning_rate: 0.0010
Epoch 3/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.3176 - conv2d_19_loss: 0.2080 - loss: 0.5255[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2263 - conv2d_19_loss: 0.2107 - loss: 0.4369[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.1535 - conv2d_19_loss: 0.2124 - loss: 0.3691 - val_conv2d_12_loss: 0.0849 - val_conv2d_19_loss: 0.2288 - val_loss: 0.3137 - learning_rate: 0.0010
Epoch 4/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0853 - conv2d_19_loss: 0.2207 - loss: 0.3060[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0878 - conv2d_19_loss: 0.2156 - loss: 0.3034[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0838 - conv2d_19_loss: 0.2126 - loss: 0.2967 - val_conv2d_12_loss: 0.0782 - val_conv2d_19_loss: 0.2287 - val_loss: 0.3070 - learning_rate: 0.0010
Epoch 5/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0744 - conv2d_19_loss: 0.2079 - loss: 0.2822[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0752 - conv2d_19_loss: 0.2135 - loss: 0.2887[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0727 - conv2d_19_loss: 0.2124 - loss: 0.2852 - val_conv2d_12_loss: 0.0715 - val_conv2d_19_loss: 0.2286 - val_loss: 0.3001 - learning_rate: 0.0010
Epoch 6/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0687 - conv2d_19_loss: 0.2069 - loss: 0.2756[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0680 - conv2d_19_loss: 0.2116 - loss: 0.2797[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0663 - conv2d_19_loss: 0.2125 - loss: 0.2786 - val_conv2d_12_loss: 0.0660 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2946 - learning_rate: 0.0010
Epoch 7/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0659 - conv2d_19_loss: 0.2176 - loss: 0.2834[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0632 - conv2d_19_loss: 0.2119 - loss: 0.2751[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0617 - conv2d_19_loss: 0.2125 - loss: 0.2741 - val_conv2d_12_loss: 0.0618 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2902 - learning_rate: 0.0010
Epoch 8/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0597 - conv2d_19_loss: 0.2097 - loss: 0.2693[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0592 - conv2d_19_loss: 0.2122 - loss: 0.2715[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0579 - conv2d_19_loss: 0.2122 - loss: 0.2703 - val_conv2d_12_loss: 0.0588 - val_conv2d_19_loss: 0.2286 - val_loss: 0.2874 - learning_rate: 0.0010
Epoch 9/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0569 - conv2d_19_loss: 0.2137 - loss: 0.2705[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0554 - conv2d_19_loss: 0.2112 - loss: 0.2665[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0548 - conv2d_19_loss: 0.2121 - loss: 0.2671 - val_conv2d_12_loss: 0.0555 - val_conv2d_19_loss: 0.2287 - val_loss: 0.2842 - learning_rate: 0.0010
Epoch 10/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0556 - conv2d_19_loss: 0.2203 - loss: 0.2759[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0535 - conv2d_19_loss: 0.2135 - loss: 0.2670[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0523 - conv2d_19_loss: 0.2122 - loss: 0.2647 - val_conv2d_12_loss: 0.0531 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2814 - learning_rate: 0.0010
Epoch 11/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.2148 - loss: 0.2657[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.2140 - loss: 0.2649[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0504 - conv2d_19_loss: 0.2130 - loss: 0.2626 - val_conv2d_12_loss: 0.0511 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2793 - learning_rate: 0.0010
Epoch 12/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0490 - conv2d_19_loss: 0.2111 - loss: 0.2600[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0489 - conv2d_19_loss: 0.2129 - loss: 0.2618[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0481 - conv2d_19_loss: 0.2114 - loss: 0.2605 - val_conv2d_12_loss: 0.0491 - val_conv2d_19_loss: 0.2281 - val_loss: 0.2772 - learning_rate: 0.0010
Epoch 13/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0464 - conv2d_19_loss: 0.2070 - loss: 0.2534[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0468 - conv2d_19_loss: 0.2121 - loss: 0.2589[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0462 - conv2d_19_loss: 0.2121 - loss: 0.2584 - val_conv2d_12_loss: 0.0468 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2752 - learning_rate: 0.0010
Epoch 14/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0453 - conv2d_19_loss: 0.2132 - loss: 0.2585[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0449 - conv2d_19_loss: 0.2127 - loss: 0.2575[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0441 - conv2d_19_loss: 0.2125 - loss: 0.2562 - val_conv2d_12_loss: 0.0455 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2736 - learning_rate: 0.0010
Epoch 15/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0419 - conv2d_19_loss: 0.2050 - loss: 0.2469[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0423 - conv2d_19_loss: 0.2093 - loss: 0.2516[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0426 - conv2d_19_loss: 0.2134 - loss: 0.2548 - val_conv2d_12_loss: 0.0435 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2718 - learning_rate: 0.0010
Epoch 16/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.2154 - loss: 0.2578[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0416 - conv2d_19_loss: 0.2133 - loss: 0.2548[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.2119 - loss: 0.2533 - val_conv2d_12_loss: 0.0417 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2699 - learning_rate: 0.0010
Epoch 17/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0424 - conv2d_19_loss: 0.2243 - loss: 0.2667[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0412 - conv2d_19_loss: 0.2187 - loss: 0.2599[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0396 - conv2d_19_loss: 0.2126 - loss: 0.2521 - val_conv2d_12_loss: 0.0409 - val_conv2d_19_loss: 0.2287 - val_loss: 0.2695 - learning_rate: 0.0010
Epoch 18/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2133 - loss: 0.2514[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2118 - loss: 0.2506[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2116 - loss: 0.2513 - val_conv2d_12_loss: 0.0416 - val_conv2d_19_loss: 0.2282 - val_loss: 0.2698 - learning_rate: 0.0010
Epoch 19/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0418 - conv2d_19_loss: 0.2154 - loss: 0.2571[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2120 - loss: 0.2515[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2128 - loss: 0.2512 - val_conv2d_12_loss: 0.0406 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2688 - learning_rate: 0.0010
Epoch 20/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2166 - loss: 0.2566[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2125 - loss: 0.2514[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2121 - loss: 0.2509 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2283 - val_loss: 0.2686 - learning_rate: 0.0010
Epoch 21/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0362 - conv2d_19_loss: 0.1977 - loss: 0.2339[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2079 - loss: 0.2457[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2120 - loss: 0.2506 - val_conv2d_12_loss: 0.0407 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2686 - learning_rate: 0.0010
Epoch 22/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2109 - loss: 0.2494[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2129 - loss: 0.2516[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2119 - loss: 0.2506 - val_conv2d_12_loss: 0.0406 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2683 - learning_rate: 0.0010
Epoch 23/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0358 - conv2d_19_loss: 0.1980 - loss: 0.2337[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0370 - conv2d_19_loss: 0.2051 - loss: 0.2421[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2124 - loss: 0.2504 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2284 - val_loss: 0.2685 - learning_rate: 0.0010
Epoch 24/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2191 - loss: 0.2590[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2154 - loss: 0.2542
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2121 - loss: 0.2504 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2280 - val_loss: 0.2682 - learning_rate: 0.0010
Epoch 25/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2123 - loss: 0.2514[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2129 - loss: 0.2515[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2118 - loss: 0.2503 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2681 - learning_rate: 5.0000e-04
Epoch 26/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2101 - loss: 0.2476[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2096 - loss: 0.2475[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2124 - loss: 0.2503 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2279 - val_loss: 0.2680 - learning_rate: 5.0000e-04
Epoch 27/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2124 - loss: 0.2498[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2140 - loss: 0.2524
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2120 - loss: 0.2501 - val_conv2d_12_loss: 0.0403 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2681 - learning_rate: 5.0000e-04
Epoch 28/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2156 - loss: 0.2543[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2136 - loss: 0.2520[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2115 - loss: 0.2501 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 2.5000e-04
Epoch 29/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2111 - loss: 0.2486[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2120 - loss: 0.2503[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2121 - loss: 0.2501 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 2.5000e-04
Epoch 30/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2111 - loss: 0.2488[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2101 - loss: 0.2478
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2119 - loss: 0.2501 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 2.5000e-04
Epoch 31/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2182 - loss: 0.2576[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2116 - loss: 0.2497[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2122 - loss: 0.2500 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.2500e-04
Epoch 32/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2203 - loss: 0.2598[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2154 - loss: 0.2542
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2118 - loss: 0.2500 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.2500e-04
Epoch 33/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2110 - loss: 0.2487[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2126 - loss: 0.2508[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2125 - loss: 0.2500 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 34/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2189 - loss: 0.2578[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2122 - loss: 0.2503[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2126 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 35/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2103 - loss: 0.2493[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2084 - loss: 0.2462[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2124 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 36/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2154 - loss: 0.2543[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2133 - loss: 0.2518[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2120 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 37/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2099 - loss: 0.2473[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0374 - conv2d_19_loss: 0.2088 - loss: 0.2462[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2110 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 38/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.2000 - loss: 0.2360[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2079 - loss: 0.2454[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2110 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 39/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.2192 - loss: 0.2598[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2148 - loss: 0.2538[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2116 - loss: 0.2499 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 40/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2094 - loss: 0.2477[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2096 - loss: 0.2473[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2116 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 41/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0406 - conv2d_19_loss: 0.2194 - loss: 0.2601[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2130 - loss: 0.2516[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2129 - loss: 0.2499 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 42/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.2086 - loss: 0.2446[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2112 - loss: 0.2487[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2121 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 43/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.1966 - loss: 0.2326[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0372 - conv2d_19_loss: 0.2069 - loss: 0.2441[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2112 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 44/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0397 - conv2d_19_loss: 0.2194 - loss: 0.2591[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2174 - loss: 0.2565[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2119 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2278 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 45/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0395 - conv2d_19_loss: 0.2187 - loss: 0.2581[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2126 - loss: 0.2507[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2119 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 46/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0396 - conv2d_19_loss: 0.2175 - loss: 0.2572[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2144 - loss: 0.2529[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2115 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 47/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0398 - conv2d_19_loss: 0.2182 - loss: 0.2580[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2124 - loss: 0.2507[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2127 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 48/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2189 - loss: 0.2570[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2143 - loss: 0.2523[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2109 - loss: 0.2499 - val_conv2d_12_loss: 0.0402 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2679 - learning_rate: 1.0000e-04
Epoch 49/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2183 - loss: 0.2584[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2124 - loss: 0.2509[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2118 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2277 - val_loss: 0.2678 - learning_rate: 1.0000e-04
Epoch 50/50
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.2051 - loss: 0.2414[1m6/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2095 - loss: 0.2471[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 16ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2121 - loss: 0.2499 - val_conv2d_12_loss: 0.0401 - val_conv2d_19_loss: 0.2276 - val_loss: 0.2678 - learning_rate: 1.0000e-04
2025-08-26 23:38:59,247 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 23:38:59,366 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-23.38.41_baseline_gs1/baseline_model.h5
2025-08-26 23:38:59,366 - INFO - 
[5/6] Performing inference and stitching...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 788ms/step[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 7ms/step  
2025-08-26 23:39:02,569 - INFO - Stitched object shape: (1, 188, 188, 1, 1)
2025-08-26 23:39:02,569 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 23:39:02,569 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 23:39:02,569 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 23:39:02,569 - INFO - Calculated ground truth crop region: rows [106:209], cols [22:209]
2025-08-26 23:39:02,569 - INFO - Initial shapes: Recon=(188, 188), Cropped GT=(103, 187)
2025-08-26 23:39:02,569 - INFO - Center-cropping from (188, 188) to (103, 187)
2025-08-26 23:39:02,569 - INFO - Final aligned shape: (103, 187)
2025-08-26 23:39:02,569 - INFO - --- Alignment complete ---
2025-08-26 23:39:02,569 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 187, 1), Ground Truth=(103, 187, 1)
2025-08-26 23:39:02,589 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 23:39:02,589 - INFO -   MAE:  (np.float32(0.09695249), np.float64(0.24308763757540758))
2025-08-26 23:39:02,589 - INFO -   PSNR: (63.197581862915726, 59.39253028199069)
2025-08-26 23:39:02,628 - INFO - Metrics and reconstruction images saved.
2025-08-26 23:39:02,628 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.065381
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.528795, std=0.159452, shape=(99, 183, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.020231, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.065381
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.563368, std=0.045052, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.528795, std=0.159452, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=-0.000000, std=0.272714, shape=(99, 183)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.020231, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.671, 0.469] -> scaled range [0.393, 0.575]
performed by index method
performed by index method
performed by index method
[2025-08-26 23:39:03] SUCCESS: Baseline training (n_images=128, trial=1)
[2025-08-26 23:39:03] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 23:39:03] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/test.npz' \
                '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 128 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 23:39:20] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=128, trial=1)
[2025-08-26 23:39:20] Completed training for train_size=128 (Trial 1/1)
[2025-08-26 23:39:20] Completed all trials for train_size=128
[2025-08-26 23:39:20] Model training phase completed
[2025-08-26 23:39:20] === STEP 3: Model Comparison ===
[2025-08-26 23:39:20] Running comparisons for train_size=128, test_size=128 (1 trials)
[2025-08-26 23:39:20] Using test subset size 128 (3-way comparison mode with Pty-chi)
[2025-08-26 23:39:20] EXECUTING: Model comparison (train_size=128, trial=1)
[2025-08-26 23:39:20] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/test.npz' --output_dir '3way_synthetic_ptychi_1e4_128/train_128/trial_1' --skip-registration --tike_recon_path '3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 128
2025-08-26 23:39:20.773606: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756276760.785425 3539978 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756276760.789235 3539978 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756276760.800322 3539978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276760.800331 3539978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276760.800333 3539978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756276760.800334 3539978 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 23:39:20.803196: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 23:39:23,061 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 23:39:23,061 - INFO - Registration: disabled
2025-08-26 23:39:23,061 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 23:39:23,061 - INFO - Initializing configuration before data loading...
2025-08-26 23:39:23,062 - INFO - Initialized with gridsize=1, n_images=128
2025-08-26 23:39:23,062 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/test.npz...
2025-08-26 23:39:23,062 - INFO - Loading data from prepare_1e4_photons_5k/dataset/test.npz with n_images=128
2025-08-26 23:39:23,363 - INFO - Using specified subset of 128 images from 2424 total (gridsize=1)
diff3d shape: (128, 64, 64)2025-08-26 23:39:23,364 - INFO - diff3d shape: (128, 64, 64)

probeGuess shape: (64, 64)2025-08-26 23:39:23,364 - INFO - probeGuess shape: (64, 64)

scan_index shape: (128,)2025-08-26 23:39:23,364 - INFO - scan_index shape: (128,)

objectGuess shape: (232, 232)2025-08-26 23:39:23,364 - INFO - objectGuess shape: (232, 232)

xcoords shape: (128,)2025-08-26 23:39:23,364 - INFO - xcoords shape: (128,)

ycoords shape: (128,)2025-08-26 23:39:23,364 - INFO - ycoords shape: (128,)

xcoords_start shape: (128,)2025-08-26 23:39:23,364 - INFO - xcoords_start shape: (128,)

ycoords_start shape: (128,)2025-08-26 23:39:23,364 - INFO - ycoords_start shape: (128,)

2025-08-26 23:39:23,364 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 23:39:23,364 - INFO - DEBUG:
 nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 23:39:23,364 - INFO - nsamples: 128, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 23:39:23,364 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 23:39:23,364 - INFO - Generating 128 groups efficiently from 128 points (K=4, C=1)
2025-08-26 23:39:23,364 - INFO - Using all 128 points as seeds
2025-08-26 23:39:23,364 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 23:39:23,364 - INFO - Successfully generated 128 groups with shape (128, 1)
2025-08-26 23:39:23,364 - INFO - Generated 128 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 23:39:23,365 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756276763.484106 3539978 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756276763.485389 3539978 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 23:39:23,514 - INFO - neighbor-sampled diffraction shape
 (128, 64, 64, 1)2025-08-26 23:39:23,514 - INFO - (128, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 23:39:23,522 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 23:39:23,906 - INFO - INFO:
 None2025-08-26 23:39:23,906 - INFO - None

<PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 23:39:23,906 - INFO - <PtychoDataContainer X=(128, 64, 64, 1) Y_I=(128, 64, 64, 1) Y_phi=(128, 64, 64, 1) norm_Y_I=() coords_nominal=(128, 1, 2, 1) coords_true=(128, 1, 2, 1) nn_indices=(128, 1) mean=63.500 global_offsets=(128, 1, 2, 1) mean=137.007 local_offsets=(128, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 23:39:23,906 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run...
2025-08-26 23:39:23,906 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
Model: "functional"
2025-08-26 23:39:24,673 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 23:39:24,694 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 23:39:24,694 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 23:39:24,694 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 23:39:24,695 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 23:39:24,695 - INFO - None

2025-08-26 23:39:24.695245: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 23:39:24.695253: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756276764.695267 3539978 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756276764.712302 3539978 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 23:39:24.712378: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756276764.712732 3539978 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 23:39:24,858 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 23:39:24,859 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 23:39:25,337 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_run
2025-08-26 23:39:25,338 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1...
2025-08-26 23:39:25,338 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_run/08-26-2025-17.47.25_baseline_gs1/baseline_model.h5
2025-08-26 23:39:25,427 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 23:39:25,431 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_128/train_128/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 23:39:25,433 - INFO - Loaded Pty-chi (ePIE) reconstruction: (197, 279) (complex64)
2025-08-26 23:39:25,433 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 23:39:25,433 - INFO - Pty-chi (ePIE) computation time: 12.57s
2025-08-26 23:39:25,433 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756276766.489886 3540111 service.cc:152] XLA service 0x704f8800bec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756276766.489909 3540111 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 23:39:26.570472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756276766.718754 3540111 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756276768.052384 3540111 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step2025-08-26 23:39:28,060 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 3s/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 23:39:28,086 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m3s[0m 9ms/step
2025-08-26 23:39:28,098 - INFO - PtychoPINN inference completed in 2.67s
2025-08-26 23:39:28,098 - INFO - Reassembling PtychoPINN patches...
2025-08-26 23:39:29,549 - INFO - Running inference with Baseline model...
[1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 568ms/step2025-08-26 23:39:30,132 - INFO - [1m1/4[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 568ms/step
[1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step  
2025-08-26 23:39:30,156 - INFO - [1m4/4[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 8ms/step
2025-08-26 23:39:30,168 - INFO - Baseline inference completed in 0.62s
2025-08-26 23:39:30,172 - INFO - Reassembling baseline patches...
2025-08-26 23:39:30,175 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 23:39:30,227 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions.npz
2025-08-26 23:39:30,228 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_metadata.txt
2025-08-26 23:39:30,228 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 23:39:30,228 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 23:39:30,228 - INFO - Ground truth original shape: (232, 232)
2025-08-26 23:39:30,228 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 23:39:30,228 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 23:39:30,228 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 23:39:30,228 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 23:39:30,228 - INFO - Final aligned shape: (101, 185)
2025-08-26 23:39:30,228 - INFO - --- Alignment complete ---
2025-08-26 23:39:30,228 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 23:39:30,228 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 23:39:30,228 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(101, 185)
2025-08-26 23:39:30,228 - INFO - Center-cropping from (192, 192) to (101, 185)
2025-08-26 23:39:30,228 - INFO - Final aligned shape: (101, 185)
2025-08-26 23:39:30,228 - INFO - --- Alignment complete ---
2025-08-26 23:39:30,228 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 23:39:30,228 - INFO - Calculated ground truth crop region: rows [106:207], cols [22:207]
2025-08-26 23:39:30,228 - INFO - Initial shapes: Recon=(197, 279), Cropped GT=(101, 185)
2025-08-26 23:39:30,228 - INFO - Center-cropping from (197, 279) to (101, 185)
2025-08-26 23:39:30,228 - INFO - Final aligned shape: (101, 185)
2025-08-26 23:39:30,228 - INFO - --- Alignment complete ---
2025-08-26 23:39:30,228 - INFO - Skipping registration (--skip-registration specified)
2025-08-26 23:39:30,228 - INFO - Final evaluation shapes: PINN (101, 185), Baseline (101, 185), Pty-chi (ePIE) (101, 185), GT (101, 185)
Amplitude normalization scale factor: 0.7622992025-08-26 23:39:30,231 - INFO - Amplitude normalization scale factor: 0.762299

mean scale adjustment:2025-08-26 23:39:30,231 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,231 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,231 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,231 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 23:39:30,232 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.739016, std=0.215971, shape=(97, 181, 1)2025-08-26 23:39:30,232 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.739016, std=0.215971, shape=(97, 181, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 23:39:30,232 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.233796, shape=(97, 181)2025-08-26 23:39:30,232 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.233796, shape=(97, 181)

performed by index method2025-08-26 23:39:30,233 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,235 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,237 - INFO - performed by index method

mean scale adjustment:2025-08-26 23:39:30,239 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,239 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,239 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,239 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 23:39:30,239 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

performed by index method2025-08-26 23:39:30,243 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,245 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,247 - INFO - performed by index method

2025-08-26 23:39:30,248 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.328, phase=0.621, MS-SSIM: amp=0.278, phase=0.407
Amplitude normalization scale factor: 1.0550802025-08-26 23:39:30,250 - INFO - Amplitude normalization scale factor: 1.055080

mean scale adjustment:2025-08-26 23:39:30,250 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,250 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,250 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,250 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 23:39:30,251 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.533941, std=0.149794, shape=(97, 181, 1)2025-08-26 23:39:30,251 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.533941, std=0.149794, shape=(97, 181, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 23:39:30,251 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.019470, shape=(97, 181)2025-08-26 23:39:30,251 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.019470, shape=(97, 181)

performed by index method2025-08-26 23:39:30,252 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,254 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,256 - INFO - performed by index method

mean scale adjustment:2025-08-26 23:39:30,257 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,258 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,258 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,258 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 23:39:30,258 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

performed by index method2025-08-26 23:39:30,262 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,263 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,265 - INFO - performed by index method

2025-08-26 23:39:30,267 - INFO - Baseline evaluation complete. SSIM: amp=0.061, phase=0.524, MS-SSIM: amp=0.094, phase=0.024
Amplitude normalization scale factor: 0.4797892025-08-26 23:39:30,269 - INFO - Amplitude normalization scale factor: 0.479789

mean scale adjustment:2025-08-26 23:39:30,269 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,269 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,269 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,269 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)2025-08-26 23:39:30,270 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.563351, std=0.045256, shape=(97, 181, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.174164, std=0.335448, shape=(97, 181, 1)2025-08-26 23:39:30,270 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.174164, std=0.335448, shape=(97, 181, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)2025-08-26 23:39:30,270 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=-0.000000, std=0.272665, shape=(97, 181)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.281595, shape=(97, 181)2025-08-26 23:39:30,270 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.281595, shape=(97, 181)

performed by index method2025-08-26 23:39:30,271 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,273 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,274 - INFO - performed by index method

mean scale adjustment:2025-08-26 23:39:30,276 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,276 - INFO - 1

mean scale adjustment:2025-08-26 23:39:30,276 - INFO - mean scale adjustment:
 12025-08-26 23:39:30,276 - INFO - 1

Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]2025-08-26 23:39:30,276 - INFO - Phase preprocessing: plane-fitted range [-0.673, 0.413] -> scaled range [0.393, 0.566]

/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0104) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,278 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0104) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0864) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,278 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0864) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1303) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,278 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1303) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1208) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,279 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1208) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0390) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,279 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0390) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0901) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,279 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.0901) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1330) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,280 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1330) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1424) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,280 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1424) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1247) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
2025-08-26 23:39:30,280 - ERROR - /home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:168: RuntimeWarning: Negative SSIM value (-0.1247) encountered in MS-SSIM calculation. Clamping to 0.0001 to avoid NaN.
  warnings.warn(f"Negative SSIM value ({ssim_val:.4f}) encountered in MS-SSIM calculation. "
performed by index method2025-08-26 23:39:30,281 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,283 - INFO - performed by index method

performed by index method2025-08-26 23:39:30,284 - INFO - performed by index method

2025-08-26 23:39:30,286 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=-0.079, phase=0.224, MS-SSIM: amp=0.000, phase=0.000
2025-08-26 23:39:30,288 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 23:39:30,288 - INFO - --- Comparison Metrics ---

         model             metric  amplitude     phase     value
    PtychoPINN                mae   0.091758  0.201691       NaN
    PtychoPINN                mse   0.027824  0.069995       NaN
    PtychoPINN               psnr  63.686545 59.680114       NaN
    PtychoPINN               ssim   0.328046  0.621142       NaN
    PtychoPINN            ms_ssim   0.278457  0.406547       NaN
    PtychoPINN              frc50   2.000000  1.000000       NaN
      Baseline                mae   0.088256  0.242961       NaN
      Baseline                mse   0.027669  0.074981       NaN
      Baseline               psnr  63.710916 59.381279       NaN
      Baseline               ssim   0.061324  0.523762       NaN
      Baseline            ms_ssim   0.094202  0.023777       NaN
      Baseline              frc50   2.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.125722  0.331920       NaN
Pty-chi (ePIE)                mse   0.029127  0.171540       NaN
Pty-chi (ePIE)               psnr  63.487832 55.787147       NaN
Pty-chi (ePIE)               ssim  -0.078708  0.224346       NaN
Pty-chi (ePIE)            ms_ssim   0.000135  0.000100       NaN
Pty-chi (ePIE)              frc50   1.000000  1.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  2.665302
      Baseline computation_time_s        NaN       NaN  0.618526
Pty-chi (ePIE) computation_time_s        NaN       NaN 12.5744562025-08-26 23:39:30,289 - INFO - model             metric  amplitude     phase     value
    PtychoPINN                mae   0.091758  0.201691       NaN
    PtychoPINN                mse   0.027824  0.069995       NaN
    PtychoPINN               psnr  63.686545 59.680114       NaN
    PtychoPINN               ssim   0.328046  0.621142       NaN
    PtychoPINN            ms_ssim   0.278457  0.406547       NaN
    PtychoPINN              frc50   2.000000  1.000000       NaN
      Baseline                mae   0.088256  0.242961       NaN
      Baseline                mse   0.027669  0.074981       NaN
      Baseline               psnr  63.710916 59.381279       NaN
      Baseline               ssim   0.061324  0.523762       NaN
      Baseline            ms_ssim   0.094202  0.023777       NaN
      Baseline              frc50   2.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.125722  0.331920       NaN
Pty-chi (ePIE)                mse   0.029127  0.171540       NaN
Pty-chi (ePIE)               psnr  63.487832 55.787147       NaN
Pty-chi (ePIE)               ssim  -0.078708  0.224346       NaN
Pty-chi (ePIE)            ms_ssim   0.000135  0.000100       NaN
Pty-chi (ePIE)              frc50   1.000000  1.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  2.665302
      Baseline computation_time_s        NaN       NaN  0.618526
Pty-chi (ePIE) computation_time_s        NaN       NaN 12.574456

2025-08-26 23:39:30,290 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/pinn_frc_curves.csv
2025-08-26 23:39:30,290 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/baseline_frc_curves.csv
2025-08-26 23:39:30,291 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 23:39:30,322 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned.npz
2025-08-26 23:39:30,322 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 23:39:30,322 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 23:39:30,357 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.000, 0.881) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,358 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.000, 0.576) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,358 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.022, 0.551) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,358 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.000, 0.075) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,359 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.843, 1.774) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,359 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.453, 0.278) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,367 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.501, 0.619) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,367 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.464, 0.271) using 10.0/90.0 percentiles [per-panel].
2025-08-26 23:39:30,899 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_128/train_128/trial_1/comparison_plot.png
2025-08-26 23:39:30,899 - INFO - 
Comparison complete!
2025-08-26 23:39:30,899 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_128/train_128/trial_1
[2025-08-26 23:39:31] SUCCESS: Model comparison (train_size=128, trial=1)
[2025-08-26 23:39:31] Completed comparisons for train_size=128
[2025-08-26 23:39:31] Model comparison phase completed
[2025-08-26 23:39:31] === STEP 4: Results Aggregation ===
[2025-08-26 23:39:31] EXECUTING: PSNR phase generalization plot
[2025-08-26 23:39:31] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
23:39:32 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:32 - INFO - Analyzing psnr_phase
23:39:32 - INFO - Discovered 1 comparison files
23:39:32 - INFO - Single-trial data detected - using legacy aggregation
23:39:32 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:32 - INFO - Made 1 out-of-range replacements with NaN
23:39:32 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:32 - INFO - Loaded 3 trial records
23:39:32 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:32 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:32 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:32 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:32 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:32 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:32 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:32 - INFO - NaN exclusion summary:
23:39:32 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:32 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:32 - INFO - Extracted 1 data points for psnr_phase (using mean)
23:39:32 - WARNING - Missing expected model types: {'baseline'}
23:39:32 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
23:39:32 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:32 - INFO - Processing complete!
23:39:32 - INFO - Outputs:
23:39:32 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/psnr_phase_generalization.png
23:39:32 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:32 - INFO - Summary: 1 models, 1 training sizes
23:39:32 - INFO - Training sizes: [np.int64(128)]
23:39:32 - INFO - Model types: ['pinn']
[2025-08-26 23:39:32] SUCCESS: PSNR phase generalization plot
[2025-08-26 23:39:32] EXECUTING: FRC amplitude generalization plot
[2025-08-26 23:39:32] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
23:39:32 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:32 - INFO - Analyzing frc50_amp
23:39:32 - INFO - Discovered 1 comparison files
23:39:32 - INFO - Single-trial data detected - using legacy aggregation
23:39:32 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:32 - INFO - Made 1 out-of-range replacements with NaN
23:39:32 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:32 - INFO - Loaded 3 trial records
23:39:32 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:32 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:32 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:32 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:32 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:32 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:32 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:32 - INFO - NaN exclusion summary:
23:39:32 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:32 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:32 - INFO - Extracted 1 data points for frc50_amp (using mean)
23:39:32 - WARNING - Missing expected model types: {'baseline'}
23:39:33 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
23:39:33 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:33 - INFO - Processing complete!
23:39:33 - INFO - Outputs:
23:39:33 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/frc50_amp_generalization.png
23:39:33 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:33 - INFO - Summary: 1 models, 1 training sizes
23:39:33 - INFO - Training sizes: [np.int64(128)]
23:39:33 - INFO - Model types: ['pinn']
[2025-08-26 23:39:33] SUCCESS: FRC amplitude generalization plot
[2025-08-26 23:39:33] EXECUTING: MAE amplitude generalization plot
[2025-08-26 23:39:33] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
23:39:33 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:33 - INFO - Analyzing mae_amp
23:39:33 - INFO - Discovered 1 comparison files
23:39:33 - INFO - Single-trial data detected - using legacy aggregation
23:39:33 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:33 - INFO - Made 1 out-of-range replacements with NaN
23:39:33 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:33 - INFO - Loaded 3 trial records
23:39:33 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:33 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:33 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:33 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:33 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:33 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:33 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:33 - INFO - NaN exclusion summary:
23:39:33 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:33 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:33 - INFO - Extracted 1 data points for mae_amp (using mean)
23:39:33 - WARNING - Missing expected model types: {'baseline'}
23:39:33 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
23:39:33 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:33 - INFO - Processing complete!
23:39:33 - INFO - Outputs:
23:39:33 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/mae_amp_generalization.png
23:39:33 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:33 - INFO - Summary: 1 models, 1 training sizes
23:39:33 - INFO - Training sizes: [np.int64(128)]
23:39:33 - INFO - Model types: ['pinn']
[2025-08-26 23:39:33] SUCCESS: MAE amplitude generalization plot
[2025-08-26 23:39:33] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 23:39:33] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
23:39:34 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:34 - INFO - Analyzing ssim_amp
23:39:34 - INFO - Discovered 1 comparison files
23:39:34 - INFO - Single-trial data detected - using legacy aggregation
23:39:34 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:34 - INFO - Made 1 out-of-range replacements with NaN
23:39:34 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:34 - INFO - Loaded 3 trial records
23:39:34 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:34 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:34 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:34 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:34 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:34 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:34 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:34 - INFO - NaN exclusion summary:
23:39:34 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:34 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:34 - INFO - Extracted 1 data points for ssim_amp (using mean)
23:39:34 - WARNING - Missing expected model types: {'baseline'}
23:39:34 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
23:39:34 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:34 - INFO - Processing complete!
23:39:34 - INFO - Outputs:
23:39:34 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_amp_generalization.png
23:39:34 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:34 - INFO - Summary: 1 models, 1 training sizes
23:39:34 - INFO - Training sizes: [np.int64(128)]
23:39:34 - INFO - Model types: ['pinn']
[2025-08-26 23:39:34] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 23:39:34] EXECUTING: SSIM phase generalization plot
[2025-08-26 23:39:34] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
23:39:34 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:34 - INFO - Analyzing ssim_phase
23:39:34 - INFO - Discovered 1 comparison files
23:39:34 - INFO - Single-trial data detected - using legacy aggregation
23:39:34 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:34 - INFO - Made 1 out-of-range replacements with NaN
23:39:34 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:34 - INFO - Loaded 3 trial records
23:39:34 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:34 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:34 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:34 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:34 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:34 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:34 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:34 - INFO - NaN exclusion summary:
23:39:34 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:34 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:34 - INFO - Extracted 1 data points for ssim_phase (using mean)
23:39:34 - WARNING - Missing expected model types: {'baseline'}
23:39:35 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
23:39:35 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:35 - INFO - Processing complete!
23:39:35 - INFO - Outputs:
23:39:35 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ssim_phase_generalization.png
23:39:35 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:35 - INFO - Summary: 1 models, 1 training sizes
23:39:35 - INFO - Training sizes: [np.int64(128)]
23:39:35 - INFO - Model types: ['pinn']
[2025-08-26 23:39:35] SUCCESS: SSIM phase generalization plot
[2025-08-26 23:39:35] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 23:39:35] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
23:39:35 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:35 - INFO - Analyzing ms_ssim_amp
23:39:35 - INFO - Discovered 1 comparison files
23:39:35 - INFO - Single-trial data detected - using legacy aggregation
23:39:35 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:35 - INFO - Made 1 out-of-range replacements with NaN
23:39:35 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:35 - INFO - Loaded 3 trial records
23:39:35 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:35 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:35 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:35 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:35 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:35 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:35 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:35 - INFO - NaN exclusion summary:
23:39:35 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:35 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:35 - INFO - Extracted 1 data points for ms_ssim_amp (using mean)
23:39:35 - WARNING - Missing expected model types: {'baseline'}
23:39:35 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
23:39:35 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:35 - INFO - Processing complete!
23:39:35 - INFO - Outputs:
23:39:35 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_amp_generalization.png
23:39:35 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:35 - INFO - Summary: 1 models, 1 training sizes
23:39:35 - INFO - Training sizes: [np.int64(128)]
23:39:35 - INFO - Model types: ['pinn']
[2025-08-26 23:39:35] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 23:39:35] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 23:39:35] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_128' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
23:39:36 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_128
23:39:36 - INFO - Analyzing ms_ssim_phase
23:39:36 - INFO - Discovered 1 comparison files
23:39:36 - INFO - Single-trial data detected - using legacy aggregation
23:39:36 - WARNING - Replaced 1 out-of-range values in ssim_amp with NaN. Invalid values: [-0.078708]
23:39:36 - INFO - Made 1 out-of-range replacements with NaN
23:39:36 - INFO - Total NaN values in data: 7 (1 new, 6 preserved)
23:39:36 - INFO - Loaded 3 trial records
23:39:36 - INFO - Filtered out 2 trial records with MS-SSIM (phase) < 0.3
23:39:36 - INFO - Proceeding to aggregation with 1 trial records (after any filtering applied)
23:39:36 - WARNING - Only 1 trials for train_size=128, model=pinn. Percentile calculations may be unreliable.
23:39:36 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=128, model=pinn)
23:39:36 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=128, model=pinn)
23:39:36 - INFO - Computed statistics for 1 (train_size, model_type) combinations
23:39:36 - INFO - Train size 128: 1.0-1.0 trials (avg: 1.0)
23:39:36 - INFO - NaN exclusion summary:
23:39:36 - INFO -   computation_time_s_amp: 1 NaN values excluded (100.0% of 1 total trials)
23:39:36 - INFO -   computation_time_s_phase: 1 NaN values excluded (100.0% of 1 total trials)
23:39:36 - INFO - Extracted 1 data points for ms_ssim_phase (using mean)
23:39:36 - WARNING - Missing expected model types: {'baseline'}
23:39:36 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
23:39:36 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_128/results.csv (13 metric entries)
23:39:36 - INFO - Processing complete!
23:39:36 - INFO - Outputs:
23:39:36 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_128/ms_ssim_phase_generalization.png
23:39:36 - INFO -   - Data: 3way_synthetic_ptychi_1e4_128/results.csv
23:39:36 - INFO - Summary: 1 models, 1 training sizes
23:39:36 - INFO - Training sizes: [np.int64(128)]
23:39:36 - INFO - Model types: ['pinn']
[2025-08-26 23:39:36] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 23:39:36] Results aggregation completed
[2025-08-26 23:39:36] === Generating Summary Report ===
[2025-08-26 23:39:36] Summary report generated: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
[2025-08-26 23:39:36] === Study Completed Successfully ===
[2025-08-26 23:39:36] Training sizes tested: 1
[2025-08-26 23:39:36] Trials per size: 1
[2025-08-26 23:39:36] Total trials completed: 1
[2025-08-26 23:39:36] Total runtime: 00:01:28
[2025-08-26 23:39:36] Results directory: 3way_synthetic_ptychi_1e4_128
[2025-08-26 23:39:36] Summary report: 3way_synthetic_ptychi_1e4_128/STUDY_SUMMARY.md
