[2025-08-26 17:23:59] === Starting Complete Generalization Study ===
[2025-08-26 17:23:59] Training sizes: 256
[2025-08-26 17:23:59] Number of trials per size: 1
[2025-08-26 17:23:59] Output directory: 3way_synthetic_ptychi_1e4_cheat_256
[2025-08-26 17:23:59] Total training runs planned: 2
[2025-08-26 17:23:59] Validating environment...
[2025-08-26 17:23:59] Environment validation passed
[2025-08-26 17:23:59] Configuration saved to: 3way_synthetic_ptychi_1e4_cheat_256/study_config.txt
[2025-08-26 17:23:59] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 17:23:59] === STEP 2: Model Training ===
[2025-08-26 17:23:59] Training models sequentially with 1 trials per training size
[2025-08-26 17:23:59] Starting training for train_size=256, test_size=256 (1 trials)
[2025-08-26 17:23:59] Training models for train_size=256, test_size=256 (Trial 1/1)
[2025-08-26 17:23:59] EXECUTING: PtychoPINN training (n_images=256, trial=1)
[2025-08-26 17:23:59] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --n_images 256 \
            --output_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 17:23:59.382205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254239.393782 3363694 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254239.397566 3363694 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254239.408704 3363694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254239.408713 3363694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254239.408715 3363694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254239.408716 3363694 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:23:59.411574: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:24:02,268 - INFO - Configuration setup complete
2025-08-26 17:24:02,268 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 17:24:02,269 - INFO - Parameter interpretation: --n-images=256 refers to individual images (gridsize=1)
2025-08-26 17:24:02,269 - INFO - Starting training with n_images=256, stitching=disabled
2025-08-26 17:24:02,269 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=256
2025-08-26 17:24:02,590 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:24:02,912 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 17:24:02,912 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=None
2025-08-26 17:24:03,233 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:24:03,233 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/train.npz
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:24:03,233 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:24:03,233 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:24:03,233 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:24:03,233 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:24:03,233 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:24:03,233 - INFO - Generated 256 groups efficiently
I0000 00:00:1756254243.365503 3363694 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254243.366766 3363694 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1253.797 global_offsets=(256, 1, 2, 1) mean=93.953 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:24:03,798 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:24:03,798 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:24:03,798 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:24:03,798 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:24:03,798 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:24:03,798 - INFO - Generated 256 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1307.414 global_offsets=(256, 1, 2, 1) mean=94.665 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:24:04.475743: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:24:04.475753: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254244.475770 3363694 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756254244.489818 3363694 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:24:04.489893: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756254244.489961 3363694 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756254245.185488 3363694 service.cc:152] XLA service 0x12855c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254245.185505 3363694 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:24:05.197698: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254245.216457 3363694 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254245.753280 3363694 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 17:24:06,268 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 17:24:08,150 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 17:24:11.822708: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:24:11.853204: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:24:11.878211: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:24:12.106872: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:44[0m 7s/step - intensity_scaler_inv_loss: 0.6633 - loss: 0.6851 - pred_intensity_loss: 0.6851 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 0.8235 - loss: 1.3023 - pred_intensity_loss: 1.3023 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.8701 - loss: 1.5116 - pred_intensity_loss: 1.5116 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.8581 - loss: 1.4561 - pred_intensity_loss: 1.4561 - trimmed_obj_loss: 0.0000e+002025-08-26 17:24:14.369317: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:24:14.397309: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:24:14.413933: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:24:14.747946: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 163ms/step - intensity_scaler_inv_loss: 0.8429 - loss: 1.3941 - pred_intensity_loss: 1.3914 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 17:24:15,607 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m11s[0m 249ms/step - intensity_scaler_inv_loss: 0.7643 - loss: 1.1002 - pred_intensity_loss: 1.0575 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5789 - val_loss: 0.1608 - val_pred_intensity_loss: 0.1608 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5750 - loss: 0.1589 - pred_intensity_loss: 0.1589 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5603 - loss: 0.0417 - pred_intensity_loss: 0.0417 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5528 - loss: -0.0174 - pred_intensity_loss: -0.0174 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5449 - loss: -0.0568 - pred_intensity_loss: -0.0568 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.5222 - loss: -0.1698 - pred_intensity_loss: -0.1751 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5167 - val_loss: -0.2387 - val_pred_intensity_loss: -0.2387 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5090 - loss: -0.2453 - pred_intensity_loss: -0.2453 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5081 - loss: -0.2420 - pred_intensity_loss: -0.2420 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5043 - loss: -0.2420 - pred_intensity_loss: -0.2420 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5026 - loss: -0.2419 - pred_intensity_loss: -0.2419 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4990 - loss: -0.2480 - pred_intensity_loss: -0.2503 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5088 - val_loss: -0.2572 - val_pred_intensity_loss: -0.2572 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5032 - loss: -0.2646 - pred_intensity_loss: -0.2646 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5069 - loss: -0.2501 - pred_intensity_loss: -0.2501 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5047 - loss: -0.2514 - pred_intensity_loss: -0.2514 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5037 - loss: -0.2517 - pred_intensity_loss: -0.2517 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.5010 - loss: -0.2546 - pred_intensity_loss: -0.2503 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5061 - val_loss: -0.2627 - val_pred_intensity_loss: -0.2627 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5098 - loss: -0.2351 - pred_intensity_loss: -0.2351 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5105 - loss: -0.2491 - pred_intensity_loss: -0.2491 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5091 - loss: -0.2511 - pred_intensity_loss: -0.2511 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5090 - loss: -0.2508 - pred_intensity_loss: -0.2508 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.5041 - loss: -0.2522 - pred_intensity_loss: -0.2506 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5079 - val_loss: -0.2636 - val_pred_intensity_loss: -0.2636 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5020 - loss: -0.3002 - pred_intensity_loss: -0.3002 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5033 - loss: -0.2631 - pred_intensity_loss: -0.2631 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5030 - loss: -0.2607 - pred_intensity_loss: -0.2607 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5023 - loss: -0.2600 - pred_intensity_loss: -0.2600 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.5001 - loss: -0.2633 - pred_intensity_loss: -0.2661 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5018 - val_loss: -0.2759 - val_pred_intensity_loss: -0.2759 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5085 - loss: -0.2357 - pred_intensity_loss: -0.2357 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5033 - loss: -0.2455 - pred_intensity_loss: -0.2455 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5010 - loss: -0.2565 - pred_intensity_loss: -0.2565 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4993 - loss: -0.2630 - pred_intensity_loss: -0.2630 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4900 - loss: -0.2829 - pred_intensity_loss: -0.2874 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4903 - val_loss: -0.3052 - val_pred_intensity_loss: -0.3052 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4874 - loss: -0.2669 - pred_intensity_loss: -0.2669 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4873 - loss: -0.2897 - pred_intensity_loss: -0.2897 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4865 - loss: -0.2944 - pred_intensity_loss: -0.2944 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4852 - loss: -0.2975 - pred_intensity_loss: -0.2975 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4787 - loss: -0.3172 - pred_intensity_loss: -0.3233 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4739 - val_loss: -0.3442 - val_pred_intensity_loss: -0.3442 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4709 - loss: -0.3648 - pred_intensity_loss: -0.3648 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4710 - loss: -0.3499 - pred_intensity_loss: -0.3499 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4711 - loss: -0.3497 - pred_intensity_loss: -0.3497 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4704 - loss: -0.3511 - pred_intensity_loss: -0.3511 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4683 - loss: -0.3536 - pred_intensity_loss: -0.3538 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4621 - val_loss: -0.3900 - val_pred_intensity_loss: -0.3900 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4642 - loss: -0.3781 - pred_intensity_loss: -0.3781 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4616 - loss: -0.3691 - pred_intensity_loss: -0.3691 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4612 - loss: -0.3733 - pred_intensity_loss: -0.3733 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4609 - loss: -0.3764 - pred_intensity_loss: -0.3764 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4597 - loss: -0.3833 - pred_intensity_loss: -0.3839 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4556 - val_loss: -0.4119 - val_pred_intensity_loss: -0.4119 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4616 - loss: -0.4032 - pred_intensity_loss: -0.4032 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4570 - loss: -0.3904 - pred_intensity_loss: -0.3904 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4561 - loss: -0.3892 - pred_intensity_loss: -0.3892 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4558 - loss: -0.3900 - pred_intensity_loss: -0.3900 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4562 - loss: -0.3980 - pred_intensity_loss: -0.4042 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4599 - val_loss: -0.4171 - val_pred_intensity_loss: -0.4171 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4588 - loss: -0.4372 - pred_intensity_loss: -0.4372 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4572 - loss: -0.4221 - pred_intensity_loss: -0.4221 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4561 - loss: -0.4196 - pred_intensity_loss: -0.4196 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4554 - loss: -0.4159 - pred_intensity_loss: -0.4159 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4525 - loss: -0.4077 - pred_intensity_loss: -0.4066 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4539 - val_loss: -0.4294 - val_pred_intensity_loss: -0.4294 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4133 - pred_intensity_loss: -0.4133 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4513 - loss: -0.4125 - pred_intensity_loss: -0.4125 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4514 - loss: -0.4109 - pred_intensity_loss: -0.4109 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4513 - loss: -0.4114 - pred_intensity_loss: -0.4114 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4507 - loss: -0.4152 - pred_intensity_loss: -0.4169 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4513 - val_loss: -0.4347 - val_pred_intensity_loss: -0.4347 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4472 - loss: -0.4290 - pred_intensity_loss: -0.4290 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4495 - loss: -0.4327 - pred_intensity_loss: -0.4327 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.4301 - pred_intensity_loss: -0.4301 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.4286 - pred_intensity_loss: -0.4286 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4488 - loss: -0.4197 - pred_intensity_loss: -0.4214 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4523 - val_loss: -0.4379 - val_pred_intensity_loss: -0.4379 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4520 - loss: -0.4514 - pred_intensity_loss: -0.4514 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4508 - loss: -0.4429 - pred_intensity_loss: -0.4429 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4503 - loss: -0.4360 - pred_intensity_loss: -0.4360 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4497 - loss: -0.4316 - pred_intensity_loss: -0.4316 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4227 - pred_intensity_loss: -0.4200 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4488 - val_loss: -0.4413 - val_pred_intensity_loss: -0.4413 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4557 - loss: -0.4046 - pred_intensity_loss: -0.4046 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4524 - loss: -0.4175 - pred_intensity_loss: -0.4175 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4506 - loss: -0.4222 - pred_intensity_loss: -0.4222 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4499 - loss: -0.4248 - pred_intensity_loss: -0.4248 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4249 - pred_intensity_loss: -0.4243 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4495 - val_loss: -0.4434 - val_pred_intensity_loss: -0.4434 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4490 - loss: -0.4263 - pred_intensity_loss: -0.4263 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4478 - loss: -0.4238 - pred_intensity_loss: -0.4238 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4253 - pred_intensity_loss: -0.4253 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4260 - pred_intensity_loss: -0.4260 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4279 - pred_intensity_loss: -0.4289 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4506 - val_loss: -0.4445 - val_pred_intensity_loss: -0.4445 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.4254 - pred_intensity_loss: -0.4254 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4216 - pred_intensity_loss: -0.4216 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4484 - loss: -0.4224 - pred_intensity_loss: -0.4224 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4479 - loss: -0.4233 - pred_intensity_loss: -0.4233 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4298 - pred_intensity_loss: -0.4251 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4460 - val_loss: -0.4434 - val_pred_intensity_loss: -0.4434 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4406 - loss: -0.4671 - pred_intensity_loss: -0.4671 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4353 - pred_intensity_loss: -0.4353 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4356 - pred_intensity_loss: -0.4356 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4356 - pred_intensity_loss: -0.4356 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4299 - pred_intensity_loss: -0.4261 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4491 - val_loss: -0.4455 - val_pred_intensity_loss: -0.4455 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4516 - loss: -0.4710 - pred_intensity_loss: -0.4710 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4519 - pred_intensity_loss: -0.4519 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4434 - pred_intensity_loss: -0.4434 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4397 - pred_intensity_loss: -0.4397 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4463 - loss: -0.4320 - pred_intensity_loss: -0.4319 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4464 - val_loss: -0.4493 - val_pred_intensity_loss: -0.4493 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4391 - loss: -0.4815 - pred_intensity_loss: -0.4815 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4421 - loss: -0.4465 - pred_intensity_loss: -0.4465 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4390 - pred_intensity_loss: -0.4390 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4435 - loss: -0.4371 - pred_intensity_loss: -0.4371 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4344 - pred_intensity_loss: -0.4378 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4502 - val_loss: -0.4492 - val_pred_intensity_loss: -0.4492 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 22/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4499 - loss: -0.4994 - pred_intensity_loss: -0.4994 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4470 - loss: -0.4657 - pred_intensity_loss: -0.4657 - trimmed_obj_loss: 0.0000e+00[2025-08-26 17:24:23] Study interrupted by user
[2025-08-26 17:25:10] === Starting Complete Generalization Study ===
[2025-08-26 17:25:10] Training sizes: 256
[2025-08-26 17:25:10] Number of trials per size: 1
[2025-08-26 17:25:10] Output directory: 3way_synthetic_ptychi_1e4_cheat_256
[2025-08-26 17:25:10] Total training runs planned: 2
[2025-08-26 17:25:10] Validating environment...
[2025-08-26 17:25:10] Environment validation passed
[2025-08-26 17:25:10] Configuration saved to: 3way_synthetic_ptychi_1e4_cheat_256/study_config.txt
[2025-08-26 17:25:10] Skipping dataset preparation (--skip-data-prep)
[2025-08-26 17:25:10] === STEP 2: Model Training ===
[2025-08-26 17:25:10] Training models sequentially with 1 trials per training size
[2025-08-26 17:25:10] Starting training for train_size=256, test_size=256 (1 trials)
[2025-08-26 17:25:10] Training models for train_size=256, test_size=256 (Trial 1/1)
[2025-08-26 17:25:10] EXECUTING: PtychoPINN training (n_images=256, trial=1)
[2025-08-26 17:25:10] COMMAND: python scripts/training/train.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --n_images 256 \
            --output_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run' \
            --nepochs 50
2025-08-26 17:25:11.172045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254311.184129 3367449 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254311.187901 3367449 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254311.199000 3367449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254311.199010 3367449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254311.199012 3367449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254311.199013 3367449 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:25:11.201871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:25:14,031 - INFO - Configuration setup complete
2025-08-26 17:25:14,031 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run'), sequential_sampling=False)
2025-08-26 17:25:14,031 - INFO - Parameter interpretation: --n-images=256 refers to individual images (gridsize=1)
2025-08-26 17:25:14,031 - INFO - Starting training with n_images=256, stitching=disabled
2025-08-26 17:25:14,031 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=256
2025-08-26 17:25:14,351 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:25:14,671 - INFO - Overriding nphotons from config (1.0e+09) with value from dataset metadata: 1.0e+04
2025-08-26 17:25:14,671 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=None
2025-08-26 17:25:14,989 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
2025-08-26 17:25:14,989 - INFO - Loaded test data from prepare_1e4_photons_5k/dataset/train.npz
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:25:14,990 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:25:14,990 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:25:14,990 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:25:14,990 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:25:14,990 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:25:14,990 - INFO - Generated 256 groups efficiently
I0000 00:00:1756254315.125481 3367449 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254315.126700 3367449 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1250.922 global_offsets=(256, 1, 2, 1) mean=95.515 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
2025-08-26 17:25:15,524 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:25:15,524 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:25:15,524 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:25:15,524 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:25:15,524 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:25:15,524 - INFO - Generated 256 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1307.246 global_offsets=(256, 1, 2, 1) mean=95.824 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
DEBUG: Setting intensity_scale to 3.125 in params
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:25:16.201598: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:25:16.201608: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254316.201622 3367449 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756254316.215566 3367449 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:25:16.215643: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756254316.215719 3367449 cupti_tracer.cc:1249] CUPTI activity buffer flushed
I0000 00:00:1756254316.901674 3367449 service.cc:152] XLA service 0x244e28c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254316.901693 3367449 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:25:16.913795: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254316.932345 3367449 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254317.469366 3367449 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
None
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale: 3.125
intensity_scale.trainable: True
label: 
mae_weight: 0.0
max_position_jitter: 10
model_type: pinn
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 10000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run
pad_object: True
positions.provided: True
probe:
  shape: (64, 64, 1)
  mean: -0.000-0.000j
  std: 0.627
  min: -2.156-0.387j
  max: 2.182-0.308j
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
Epoch 1/50
input shape (None, 64, 64, 1)
2025-08-26 17:25:17,986 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
input shape (None, 64, 64, 1)
2025-08-26 17:25:19,863 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
2025-08-26 17:25:23.476958: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:25:23.492335: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:25:23.560278: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:25:23.755655: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:43[0m 7s/step - intensity_scaler_inv_loss: 0.6274 - loss: 0.5714 - pred_intensity_loss: 0.5714 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 16ms/step - intensity_scaler_inv_loss: 1.4569 - loss: 8.4416 - pred_intensity_loss: 8.4416 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 1.3107 - loss: 6.8568 - pred_intensity_loss: 6.8568 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 1.2002 - loss: 5.7309 - pred_intensity_loss: 5.7309 - trimmed_obj_loss: 0.0000e+002025-08-26 17:25:26.084944: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:25:26.085003: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 180 bytes spill stores, 180 bytes spill loads

2025-08-26 17:25:26.125463: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1', 120 bytes spill stores, 120 bytes spill loads

2025-08-26 17:25:26.374404: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 3712 bytes spill stores, 3712 bytes spill loads

[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 161ms/step - intensity_scaler_inv_loss: 1.1338 - loss: 5.1121 - pred_intensity_loss: 5.1034 - trimmed_obj_loss: 0.0000e+00input shape (None, 64, 64, 1)
2025-08-26 17:25:27,234 - WARNING - You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m11s[0m 245ms/step - intensity_scaler_inv_loss: 0.8238 - loss: 2.3459 - pred_intensity_loss: 2.2060 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.5477 - val_loss: -0.2013 - val_pred_intensity_loss: -0.2013 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 2/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5493 - loss: -0.2327 - pred_intensity_loss: -0.2327 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5373 - loss: -0.2151 - pred_intensity_loss: -0.2151 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5283 - loss: -0.2148 - pred_intensity_loss: -0.2148 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5239 - loss: -0.2164 - pred_intensity_loss: -0.2164 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.5105 - loss: -0.2301 - pred_intensity_loss: -0.2341 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4864 - val_loss: -0.2925 - val_pred_intensity_loss: -0.2925 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 3/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.5081 - loss: -0.1884 - pred_intensity_loss: -0.1884 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4992 - loss: -0.2388 - pred_intensity_loss: -0.2388 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5004 - loss: -0.2425 - pred_intensity_loss: -0.2425 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5001 - loss: -0.2459 - pred_intensity_loss: -0.2459 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4984 - loss: -0.2528 - pred_intensity_loss: -0.2581 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4901 - val_loss: -0.2960 - val_pred_intensity_loss: -0.2960 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 4/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4925 - loss: -0.2732 - pred_intensity_loss: -0.2732 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4987 - loss: -0.2552 - pred_intensity_loss: -0.2552 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5005 - loss: -0.2540 - pred_intensity_loss: -0.2540 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.5005 - loss: -0.2548 - pred_intensity_loss: -0.2548 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.5006 - loss: -0.2582 - pred_intensity_loss: -0.2512 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4859 - val_loss: -0.3003 - val_pred_intensity_loss: -0.3003 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 5/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4867 - loss: -0.3166 - pred_intensity_loss: -0.3166 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4912 - loss: -0.2850 - pred_intensity_loss: -0.2850 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4940 - loss: -0.2739 - pred_intensity_loss: -0.2739 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4957 - loss: -0.2683 - pred_intensity_loss: -0.2683 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4973 - loss: -0.2645 - pred_intensity_loss: -0.2693 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4879 - val_loss: -0.3093 - val_pred_intensity_loss: -0.3093 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 6/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.5059 - loss: -0.2842 - pred_intensity_loss: -0.2842 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.5006 - loss: -0.2636 - pred_intensity_loss: -0.2636 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4990 - loss: -0.2670 - pred_intensity_loss: -0.2670 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4980 - loss: -0.2694 - pred_intensity_loss: -0.2694 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4970 - loss: -0.2725 - pred_intensity_loss: -0.2726 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4819 - val_loss: -0.3192 - val_pred_intensity_loss: -0.3192 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 7/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.5013 - loss: -0.2630 - pred_intensity_loss: -0.2630 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4950 - loss: -0.2830 - pred_intensity_loss: -0.2830 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4932 - loss: -0.2857 - pred_intensity_loss: -0.2857 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4922 - loss: -0.2857 - pred_intensity_loss: -0.2857 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4893 - loss: -0.2926 - pred_intensity_loss: -0.3009 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4895 - val_loss: -0.3294 - val_pred_intensity_loss: -0.3294 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 8/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4978 - loss: -0.2863 - pred_intensity_loss: -0.2863 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4901 - loss: -0.2980 - pred_intensity_loss: -0.2980 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4886 - loss: -0.2988 - pred_intensity_loss: -0.2988 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4874 - loss: -0.3014 - pred_intensity_loss: -0.3014 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4828 - loss: -0.3132 - pred_intensity_loss: -0.3158 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4711 - val_loss: -0.3656 - val_pred_intensity_loss: -0.3656 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 9/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4818 - loss: -0.3428 - pred_intensity_loss: -0.3428 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4796 - loss: -0.3413 - pred_intensity_loss: -0.3413 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4779 - loss: -0.3444 - pred_intensity_loss: -0.3444 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4765 - loss: -0.3458 - pred_intensity_loss: -0.3458 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4738 - loss: -0.3479 - pred_intensity_loss: -0.3481 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4642 - val_loss: -0.3914 - val_pred_intensity_loss: -0.3914 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 10/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4742 - loss: -0.3844 - pred_intensity_loss: -0.3844 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4714 - loss: -0.3669 - pred_intensity_loss: -0.3669 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4704 - loss: -0.3673 - pred_intensity_loss: -0.3673 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4699 - loss: -0.3688 - pred_intensity_loss: -0.3688 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4664 - loss: -0.3749 - pred_intensity_loss: -0.3728 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4566 - val_loss: -0.4034 - val_pred_intensity_loss: -0.4034 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 11/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4486 - loss: -0.4036 - pred_intensity_loss: -0.4036 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4559 - loss: -0.3945 - pred_intensity_loss: -0.3945 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4574 - loss: -0.3905 - pred_intensity_loss: -0.3905 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4580 - loss: -0.3908 - pred_intensity_loss: -0.3908 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4589 - loss: -0.3908 - pred_intensity_loss: -0.3903 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4537 - val_loss: -0.4137 - val_pred_intensity_loss: -0.4137 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 12/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4590 - loss: -0.3920 - pred_intensity_loss: -0.3920 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4561 - loss: -0.3967 - pred_intensity_loss: -0.3967 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4556 - loss: -0.3981 - pred_intensity_loss: -0.3981 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4552 - loss: -0.3998 - pred_intensity_loss: -0.3998 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4541 - loss: -0.4031 - pred_intensity_loss: -0.4000 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4509 - val_loss: -0.4194 - val_pred_intensity_loss: -0.4194 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 13/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4549 - loss: -0.4027 - pred_intensity_loss: -0.4027 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4009 - pred_intensity_loss: -0.4009 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4524 - loss: -0.4027 - pred_intensity_loss: -0.4027 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4527 - loss: -0.4056 - pred_intensity_loss: -0.4056 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4531 - loss: -0.4090 - pred_intensity_loss: -0.4089 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4529 - val_loss: -0.4215 - val_pred_intensity_loss: -0.4215 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 14/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4550 - loss: -0.3765 - pred_intensity_loss: -0.3765 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4537 - loss: -0.3951 - pred_intensity_loss: -0.3951 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4532 - loss: -0.3974 - pred_intensity_loss: -0.3974 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4528 - loss: -0.4012 - pred_intensity_loss: -0.4012 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4506 - loss: -0.4146 - pred_intensity_loss: -0.4212 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4528 - val_loss: -0.4202 - val_pred_intensity_loss: -0.4202 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 15/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4568 - loss: -0.4330 - pred_intensity_loss: -0.4330 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4536 - loss: -0.4163 - pred_intensity_loss: -0.4163 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4528 - loss: -0.4122 - pred_intensity_loss: -0.4122 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4521 - loss: -0.4127 - pred_intensity_loss: -0.4127 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4510 - loss: -0.4169 - pred_intensity_loss: -0.4116 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4476 - val_loss: -0.4244 - val_pred_intensity_loss: -0.4244 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 16/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4500 - loss: -0.4362 - pred_intensity_loss: -0.4362 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4490 - loss: -0.4324 - pred_intensity_loss: -0.4324 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4290 - pred_intensity_loss: -0.4290 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4491 - loss: -0.4266 - pred_intensity_loss: -0.4266 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4494 - loss: -0.4193 - pred_intensity_loss: -0.4198 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4495 - val_loss: -0.4289 - val_pred_intensity_loss: -0.4289 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 17/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4506 - loss: -0.4034 - pred_intensity_loss: -0.4034 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4487 - loss: -0.4119 - pred_intensity_loss: -0.4119 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4488 - loss: -0.4148 - pred_intensity_loss: -0.4148 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4487 - loss: -0.4180 - pred_intensity_loss: -0.4180 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4474 - loss: -0.4228 - pred_intensity_loss: -0.4224 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4464 - val_loss: -0.4342 - val_pred_intensity_loss: -0.4342 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 18/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.4932 - pred_intensity_loss: -0.4932 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4480 - loss: -0.4453 - pred_intensity_loss: -0.4453 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4380 - pred_intensity_loss: -0.4380 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4473 - loss: -0.4336 - pred_intensity_loss: -0.4336 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4467 - loss: -0.4262 - pred_intensity_loss: -0.4311 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4442 - val_loss: -0.4373 - val_pred_intensity_loss: -0.4373 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 19/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4508 - loss: -0.4272 - pred_intensity_loss: -0.4272 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.4366 - pred_intensity_loss: -0.4366 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4475 - loss: -0.4353 - pred_intensity_loss: -0.4353 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4471 - loss: -0.4340 - pred_intensity_loss: -0.4340 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4468 - loss: -0.4276 - pred_intensity_loss: -0.4259 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4453 - val_loss: -0.4346 - val_pred_intensity_loss: -0.4346 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 20/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4484 - loss: -0.4316 - pred_intensity_loss: -0.4316 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4288 - pred_intensity_loss: -0.4288 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4463 - loss: -0.4312 - pred_intensity_loss: -0.4312 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4463 - loss: -0.4305 - pred_intensity_loss: -0.4305 - trimmed_obj_loss: 0.0000e+00
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4466 - loss: -0.4271 - pred_intensity_loss: -0.4258 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4451 - val_loss: -0.4350 - val_pred_intensity_loss: -0.4350 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 0.0010
Epoch 21/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4616 - pred_intensity_loss: -0.4616 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4438 - pred_intensity_loss: -0.4438 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4389 - pred_intensity_loss: -0.4389 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4356 - pred_intensity_loss: -0.4356 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4461 - loss: -0.4297 - pred_intensity_loss: -0.4327 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4441 - val_loss: -0.4397 - val_pred_intensity_loss: -0.4397 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 22/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4460 - loss: -0.3904 - pred_intensity_loss: -0.3904 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4237 - pred_intensity_loss: -0.4237 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4280 - pred_intensity_loss: -0.4280 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4272 - pred_intensity_loss: -0.4272 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4317 - pred_intensity_loss: -0.4313 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4468 - val_loss: -0.4393 - val_pred_intensity_loss: -0.4393 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 23/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4589 - pred_intensity_loss: -0.4589 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4457 - loss: -0.4470 - pred_intensity_loss: -0.4470 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4426 - pred_intensity_loss: -0.4426 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4397 - pred_intensity_loss: -0.4397 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4323 - pred_intensity_loss: -0.4335 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4441 - val_loss: -0.4417 - val_pred_intensity_loss: -0.4417 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 24/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4384 - loss: -0.4324 - pred_intensity_loss: -0.4324 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4179 - pred_intensity_loss: -0.4179 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4233 - pred_intensity_loss: -0.4233 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4256 - pred_intensity_loss: -0.4256 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4333 - pred_intensity_loss: -0.4334 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4443 - val_loss: -0.4415 - val_pred_intensity_loss: -0.4415 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 25/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4470 - pred_intensity_loss: -0.4470 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4263 - pred_intensity_loss: -0.4263 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4263 - pred_intensity_loss: -0.4263 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4265 - pred_intensity_loss: -0.4265 - trimmed_obj_loss: 0.0000e+00
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4340 - pred_intensity_loss: -0.4361 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4445 - val_loss: -0.4408 - val_pred_intensity_loss: -0.4408 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 5.0000e-04
Epoch 26/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4464 - loss: -0.4360 - pred_intensity_loss: -0.4360 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4394 - pred_intensity_loss: -0.4394 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4348 - pred_intensity_loss: -0.4348 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4354 - pred_intensity_loss: -0.4354 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4345 - pred_intensity_loss: -0.4353 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4431 - val_loss: -0.4425 - val_pred_intensity_loss: -0.4425 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 27/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4068 - pred_intensity_loss: -0.4068 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4435 - loss: -0.4178 - pred_intensity_loss: -0.4178 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4228 - pred_intensity_loss: -0.4228 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4435 - loss: -0.4257 - pred_intensity_loss: -0.4257 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4352 - pred_intensity_loss: -0.4333 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4433 - val_loss: -0.4428 - val_pred_intensity_loss: -0.4428 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 28/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4404 - loss: -0.4254 - pred_intensity_loss: -0.4254 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4424 - loss: -0.4254 - pred_intensity_loss: -0.4254 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4432 - loss: -0.4297 - pred_intensity_loss: -0.4297 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4310 - pred_intensity_loss: -0.4310 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4355 - pred_intensity_loss: -0.4434 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4442 - val_loss: -0.4427 - val_pred_intensity_loss: -0.4427 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 29/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4455 - loss: -0.4856 - pred_intensity_loss: -0.4856 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4506 - pred_intensity_loss: -0.4506 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4425 - pred_intensity_loss: -0.4425 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4384 - pred_intensity_loss: -0.4384 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4354 - pred_intensity_loss: -0.4346 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4413 - val_loss: -0.4432 - val_pred_intensity_loss: -0.4432 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 30/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4412 - loss: -0.4835 - pred_intensity_loss: -0.4835 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4576 - pred_intensity_loss: -0.4576 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4463 - pred_intensity_loss: -0.4463 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4428 - pred_intensity_loss: -0.4428 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4360 - pred_intensity_loss: -0.4333 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4433 - val_loss: -0.4437 - val_pred_intensity_loss: -0.4437 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 31/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.5030 - pred_intensity_loss: -0.5030 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4432 - loss: -0.4619 - pred_intensity_loss: -0.4619 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4513 - pred_intensity_loss: -0.4513 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4465 - pred_intensity_loss: -0.4465 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4364 - pred_intensity_loss: -0.4364 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4431 - val_loss: -0.4439 - val_pred_intensity_loss: -0.4439 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 32/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4485 - loss: -0.4691 - pred_intensity_loss: -0.4691 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4453 - loss: -0.4442 - pred_intensity_loss: -0.4442 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4372 - pred_intensity_loss: -0.4372 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4445 - loss: -0.4359 - pred_intensity_loss: -0.4359 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4365 - pred_intensity_loss: -0.4395 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4413 - val_loss: -0.4441 - val_pred_intensity_loss: -0.4441 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 33/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4454 - loss: -0.4309 - pred_intensity_loss: -0.4309 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4292 - pred_intensity_loss: -0.4292 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4340 - pred_intensity_loss: -0.4340 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4373 - pred_intensity_loss: -0.4373 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4367 - pred_intensity_loss: -0.4376 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4427 - val_loss: -0.4446 - val_pred_intensity_loss: -0.4446 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 34/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4504 - loss: -0.4697 - pred_intensity_loss: -0.4697 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4510 - pred_intensity_loss: -0.4510 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4435 - pred_intensity_loss: -0.4435 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4396 - pred_intensity_loss: -0.4396 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4370 - pred_intensity_loss: -0.4352 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4423 - val_loss: -0.4444 - val_pred_intensity_loss: -0.4444 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 35/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4416 - loss: -0.4711 - pred_intensity_loss: -0.4711 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.4454 - pred_intensity_loss: -0.4454 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4436 - loss: -0.4399 - pred_intensity_loss: -0.4399 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4386 - pred_intensity_loss: -0.4386 - trimmed_obj_loss: 0.0000e+00
Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4371 - pred_intensity_loss: -0.4373 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4426 - val_loss: -0.4446 - val_pred_intensity_loss: -0.4446 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 2.5000e-04
Epoch 36/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4412 - loss: -0.4350 - pred_intensity_loss: -0.4350 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4409 - pred_intensity_loss: -0.4409 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.4363 - pred_intensity_loss: -0.4363 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4362 - pred_intensity_loss: -0.4362 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4376 - pred_intensity_loss: -0.4368 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4424 - val_loss: -0.4450 - val_pred_intensity_loss: -0.4450 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 37/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4370 - pred_intensity_loss: -0.4370 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4450 - loss: -0.4225 - pred_intensity_loss: -0.4225 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4252 - pred_intensity_loss: -0.4252 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4279 - pred_intensity_loss: -0.4279 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4442 - loss: -0.4378 - pred_intensity_loss: -0.4370 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4430 - val_loss: -0.4448 - val_pred_intensity_loss: -0.4448 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 38/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4496 - loss: -0.3944 - pred_intensity_loss: -0.3944 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4448 - loss: -0.4105 - pred_intensity_loss: -0.4105 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4215 - pred_intensity_loss: -0.4215 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4270 - pred_intensity_loss: -0.4270 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4379 - pred_intensity_loss: -0.4346 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4422 - val_loss: -0.4452 - val_pred_intensity_loss: -0.4452 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 39/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 34ms/step - intensity_scaler_inv_loss: 0.4459 - loss: -0.4638 - pred_intensity_loss: -0.4638 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4597 - pred_intensity_loss: -0.4597 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4551 - pred_intensity_loss: -0.4551 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4513 - pred_intensity_loss: -0.4513 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4427 - loss: -0.4379 - pred_intensity_loss: -0.4414 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4422 - val_loss: -0.4453 - val_pred_intensity_loss: -0.4453 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 40/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4403 - loss: -0.4232 - pred_intensity_loss: -0.4232 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4439 - loss: -0.4272 - pred_intensity_loss: -0.4272 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4304 - pred_intensity_loss: -0.4304 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4440 - loss: -0.4347 - pred_intensity_loss: -0.4347 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4382 - pred_intensity_loss: -0.4419 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4424 - val_loss: -0.4454 - val_pred_intensity_loss: -0.4454 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 41/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4385 - loss: -0.4920 - pred_intensity_loss: -0.4920 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4425 - loss: -0.4569 - pred_intensity_loss: -0.4569 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4483 - pred_intensity_loss: -0.4483 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4454 - pred_intensity_loss: -0.4454 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4383 - pred_intensity_loss: -0.4392 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4425 - val_loss: -0.4454 - val_pred_intensity_loss: -0.4454 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 42/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4387 - pred_intensity_loss: -0.4387 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4449 - loss: -0.4402 - pred_intensity_loss: -0.4402 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4444 - loss: -0.4432 - pred_intensity_loss: -0.4432 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4422 - pred_intensity_loss: -0.4422 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4423 - loss: -0.4384 - pred_intensity_loss: -0.4409 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4430 - val_loss: -0.4453 - val_pred_intensity_loss: -0.4453 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 43/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4497 - loss: -0.3711 - pred_intensity_loss: -0.3711 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4446 - loss: -0.4063 - pred_intensity_loss: -0.4063 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4435 - loss: -0.4152 - pred_intensity_loss: -0.4152 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4433 - loss: -0.4217 - pred_intensity_loss: -0.4217 - trimmed_obj_loss: 0.0000e+00
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4434 - loss: -0.4384 - pred_intensity_loss: -0.4424 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4427 - val_loss: -0.4452 - val_pred_intensity_loss: -0.4452 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.2500e-04
Epoch 44/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4381 - loss: -0.4659 - pred_intensity_loss: -0.4659 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4423 - loss: -0.4511 - pred_intensity_loss: -0.4511 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4470 - pred_intensity_loss: -0.4470 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4453 - pred_intensity_loss: -0.4453 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4427 - loss: -0.4386 - pred_intensity_loss: -0.4395 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4424 - val_loss: -0.4455 - val_pred_intensity_loss: -0.4455 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 45/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4627 - pred_intensity_loss: -0.4627 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4443 - loss: -0.4463 - pred_intensity_loss: -0.4463 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4438 - loss: -0.4466 - pred_intensity_loss: -0.4466 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4460 - pred_intensity_loss: -0.4460 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4430 - loss: -0.4387 - pred_intensity_loss: -0.4340 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4417 - val_loss: -0.4457 - val_pred_intensity_loss: -0.4457 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 46/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4375 - loss: -0.4787 - pred_intensity_loss: -0.4787 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4417 - loss: -0.4544 - pred_intensity_loss: -0.4544 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4424 - loss: -0.4502 - pred_intensity_loss: -0.4502 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4469 - pred_intensity_loss: -0.4469 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4388 - pred_intensity_loss: -0.4410 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4426 - val_loss: -0.4457 - val_pred_intensity_loss: -0.4457 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 47/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 32ms/step - intensity_scaler_inv_loss: 0.4452 - loss: -0.4618 - pred_intensity_loss: -0.4618 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4447 - loss: -0.4404 - pred_intensity_loss: -0.4404 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4441 - loss: -0.4404 - pred_intensity_loss: -0.4404 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4407 - pred_intensity_loss: -0.4407 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4389 - pred_intensity_loss: -0.4357 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4423 - val_loss: -0.4458 - val_pred_intensity_loss: -0.4458 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 48/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 33ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4536 - pred_intensity_loss: -0.4536 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4372 - pred_intensity_loss: -0.4372 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4386 - pred_intensity_loss: -0.4386 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4398 - pred_intensity_loss: -0.4398 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4390 - pred_intensity_loss: -0.4434 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4419 - val_loss: -0.4456 - val_pred_intensity_loss: -0.4456 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 49/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4412 - loss: -0.4012 - pred_intensity_loss: -0.4012 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4420 - loss: -0.4221 - pred_intensity_loss: -0.4221 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4426 - loss: -0.4355 - pred_intensity_loss: -0.4355 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4429 - loss: -0.4389 - pred_intensity_loss: -0.4389 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 17ms/step - intensity_scaler_inv_loss: 0.4428 - loss: -0.4390 - pred_intensity_loss: -0.4397 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4417 - val_loss: -0.4460 - val_pred_intensity_loss: -0.4460 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
Epoch 50/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 31ms/step - intensity_scaler_inv_loss: 0.4437 - loss: -0.4403 - pred_intensity_loss: -0.4403 - trimmed_obj_loss: 0.0000e+00[1m 5/16[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 14ms/step - intensity_scaler_inv_loss: 0.4425 - loss: -0.4502 - pred_intensity_loss: -0.4502 - trimmed_obj_loss: 0.0000e+00[1m 9/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4423 - loss: -0.4470 - pred_intensity_loss: -0.4470 - trimmed_obj_loss: 0.0000e+00[1m13/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 15ms/step - intensity_scaler_inv_loss: 0.4425 - loss: -0.4446 - pred_intensity_loss: -0.4446 - trimmed_obj_loss: 0.0000e+00[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 18ms/step - intensity_scaler_inv_loss: 0.4431 - loss: -0.4390 - pred_intensity_loss: -0.4388 - trimmed_obj_loss: 0.0000e+00 - val_intensity_scaler_inv_loss: 0.4418 - val_loss: -0.4461 - val_pred_intensity_loss: -0.4461 - val_trimmed_obj_loss: 0.0000e+00 - learning_rate: 1.0000e-04
DEBUG: Setting probe to tf.Tensor(
[[[ 0.13510734-0.08366051j]
  [-0.08103182-0.0294797j ]
  [ 0.0637618 +0.02550233j]
  ...
  [-0.05742923+0.10465012j]
  [ 0.061039  +0.02731375j]
  [-0.07001488-0.0336627j ]]

 [[-0.08103182-0.0294797j ]
  [ 0.11364837-0.04388378j]
  [-0.08643168+0.03117809j]
  ...
  [ 0.02872955+0.03712314j]
  [-0.08476108+0.03176096j]
  [ 0.10533146-0.04452544j]]

 [[ 0.0637618 +0.02550233j]
  [-0.08643168+0.03117809j]
  [ 0.06238977-0.04183936j]
  ...
  [-0.01890127-0.04941669j]
  [ 0.06107059-0.04259919j]
  [-0.07948506+0.03188787j]]

 ...

 [[-0.05742923+0.10465012j]
  [ 0.02872955+0.03712314j]
  [-0.01890127-0.04941669j]
  ...
  [-0.00577373-0.08714116j]
  [-0.01781569-0.0517069j ]
  [ 0.02285527+0.04448525j]]

 [[ 0.061039  +0.02731375j]
  [-0.08476108+0.03176096j]
  [ 0.06107059-0.04259919j]
  ...
  [-0.01781569-0.0517069j ]
  [ 0.05980607-0.0434007j ]
  [-0.07803912+0.03257083j]]

 [[-0.07001488-0.0336627j ]
  [ 0.10533146-0.04452544j]
  [-0.07948506+0.03188787j]
  ...
  [ 0.02285527+0.04448525j]
  [-0.07803912+0.03257083j]
  [ 0.09786177-0.04529788j]]], shape=(64, 64, 1), dtype=complex64) in params
INFO: setting probe from test data container. It MUST be consistent with the training probe
input shape (32, 64, 64, 1)
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m6s[0m 930ms/step[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 6ms/step  
Object stitching failed: Grid-based stitching is not supported for gridsize=1 (non-grid mode). Individual patches cannot be arranged in a regular grid.
cannot reshape array of size 1048576 into shape (9,9,64,64,1)
2025-08-26 17:25:43,807 - INFO - Skipping image stitching (disabled or no test data available)
2025-08-26 17:25:45,258 - INFO - Outputs saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run
[2025-08-26 17:25:46] SUCCESS: PtychoPINN training (n_images=256, trial=1)
[2025-08-26 17:25:46] EXECUTING: Baseline training (n_images=256, trial=1)
[2025-08-26 17:25:46] COMMAND: python scripts/run_baseline.py \
            --train_data_file 'prepare_1e4_photons_5k/dataset/train.npz' \
            --test_data 'prepare_1e4_photons_5k/dataset/train.npz' \
            --n_images 256 \
            --output_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run' \
            --nepochs 50
2025-08-26 17:25:46.773694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254346.785503 3375139 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254346.789529 3375139 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254346.800376 3375139 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254346.800386 3375139 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254346.800387 3375139 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254346.800388 3375139 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:25:46.803473: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:25:49,349 - INFO - Configuration setup complete
2025-08-26 17:25:49,349 - INFO - Final configuration: TrainingConfig(model=ModelConfig(N=64, gridsize=1, n_filters_scale=2, model_type='pinn', amp_activation='sigmoid', object_big=True, probe_big=True, probe_mask=False, pad_object=True, probe_scale=4.0, gaussian_smoothing_sigma=0.0), train_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), test_data_file=PosixPath('prepare_1e4_photons_5k/dataset/train.npz'), batch_size=16, nepochs=50, mae_weight=0.0, nll_weight=1.0, realspace_mae_weight=0.0, realspace_weight=0.0, nphotons=1000000000.0, n_images=256, positions_provided=True, probe_trainable=False, intensity_scale_trainable=True, output_dir=PosixPath('3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run'), sequential_sampling=False)
2025-08-26 17:25:49,349 - INFO - âœ… Validated model_type = 'supervised' for baseline training
2025-08-26 17:25:49,349 - INFO - --- Starting Supervised Baseline Run ---
2025-08-26 17:25:49,349 - INFO - Results will be saved to: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1/
2025-08-26 17:25:49,349 - INFO - 
[1/6] Initializing probe...
I0000 00:00:1756254349.458986 3375139 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254349.460259 3375139 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
2025-08-26 17:25:49,495 - INFO - 
[2/6] Loading data...
2025-08-26 17:25:49,495 - INFO - Loading from .npz files: prepare_1e4_photons_5k/dataset/train.npz
2025-08-26 17:25:49,495 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=256
2025-08-26 17:25:49,815 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 17:25:49,815 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=None
2025-08-26 17:25:50,135 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
2025-08-26 17:25:50,135 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:25:50,135 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:25:50,136 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:25:50,136 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:25:50,136 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:25:50,136 - INFO - Generated 256 groups efficiently
2025-08-26 17:25:50,546 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:25:50,546 - INFO - Generating 256 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:25:50,547 - INFO - Sampled 256 seed points from 2576 total points
2025-08-26 17:25:50,547 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:25:50,547 - INFO - Successfully generated 256 groups with shape (256, 1)
2025-08-26 17:25:50,547 - INFO - Generated 256 groups efficiently
2025-08-26 17:25:50,567 - INFO - Globally set intensity_scale to: 988.2117919921875
2025-08-26 17:25:50,567 - INFO - 
[3/6] Shaping data for the baseline model...
2025-08-26 17:25:50,569 - INFO - Final training input shape: (256, 64, 64, 1)
2025-08-26 17:25:50,569 - INFO - 
[4/6] Training the baseline model for 50 epochs with batch size 16...
2025-08-26 17:25:50,569 - INFO - Training with 256 images
DEBUG: Setting timestamp to 08/26/2025, 17:25:49 in params
Current Parameters:
--------------------
N: 64
amp_activation: sigmoid
batch_size: 16
bigN: 64
big_gridsize: 10
data_source: generic
debug: True
default_probe_scale: 0.7
gaussian_smoothing_sigma: 0.0
gridsize: 1
h5_path: wts.h5
intensity_scale.trainable: True
label: baseline_gs1
mae_weight: 0.0
max_position_jitter: 10
model_type: supervised
n_filters_scale: 2
n_images: 256
nepochs: 50
nimgs_test: 3
nimgs_train: 9
nll_weight: 1.0
nphotons: 1000000000.0
npseed: 42
object.big: True
offset: 4
outer_offset_test: None
outer_offset_train: None
output_prefix: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1/
pad_object: True
positions.provided: True
probe.big: True
probe.mask: False
probe.trainable: False
probe_scale: 4.0
realspace_mae_weight: 0.0
realspace_weight: 0.0
sequential_sampling: False
set_phi: False
sim_jitter_scale: 0.0
size: 392
test_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
timestamp: 08/26/2025, 17:25:49
train_data_file_path: prepare_1e4_photons_5k/dataset/train.npz
tv_weight: 0.0
use_xla_translate: True
DEBUG: Setting probe to tf.Tensor(
[[[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 ...

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]

 [[2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  ...
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]
  [2.7234042e-09+0.j]]], shape=(64, 64, 1), dtype=complex64) in params
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
diff3d shape: (2576, 64, 64)
probeGuess shape: (64, 64)
scan_index shape: (2576,)
objectGuess shape: (232, 232)
xcoords shape: (2576,)
ycoords shape: (2576,)
xcoords_start shape: (2576,)
ycoords_start shape: (2576,)
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1284.574 global_offsets=(256, 1, 2, 1) mean=93.958 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: nsamples: 256, gridsize: 1 (using efficient random sample-then-group strategy)
INFO: Using pre-computed 'Y' array from the input file.
neighbor-sampled diffraction shape (256, 64, 64, 1)
loader: using provided ground truth patches.
INFO: None
<PtychoDataContainer X=(256, 64, 64, 1) Y_I=(256, 64, 64, 1) Y_phi=(256, 64, 64, 1) norm_Y_I=() coords_nominal=(256, 1, 2, 1) coords_true=(256, 1, 2, 1) nn_indices=(256, 1) mean=1356.418 global_offsets=(256, 1, 2, 1) mean=94.634 local_offsets=(256, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>
DEBUG: Setting intensity_scale to tf.Tensor(988.2118, shape=(), dtype=float32) in params
Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_6[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 256) â”‚    590,080 â”‚ conv2d_13[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 16, 16,    â”‚    295,040 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 16, 16,    â”‚    147,584 â”‚ conv2d_15[0][0]   â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_16[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 32, 32,    â”‚     73,792 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_17[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_18[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 4,612,418 (17.59 MB)
 Trainable params: 4,612,418 (17.59 MB)
 Non-trainable params: 0 (0.00 B)
None
Training with 50 epochs and batch size 16
Epoch 1/50
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254353.400872 3375279 service.cc:152] XLA service 0x7de17c003470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254353.400893 3375279 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:25:53.469234: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254353.882666 3375279 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254356.789411 3375279 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:24[0m 6s/step - conv2d_12_loss: 0.5655 - conv2d_19_loss: 0.2065 - loss: 0.7720[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 1.1246 - conv2d_19_loss: 0.3790 - loss: 1.5036[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 1.0447 - conv2d_19_loss: 0.3595 - loss: 1.4042[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 192ms/step - conv2d_12_loss: 0.9639 - conv2d_19_loss: 0.3386 - loss: 1.3038[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m9s[0m 249ms/step - conv2d_12_loss: 0.7412 - conv2d_19_loss: 0.2829 - loss: 1.0439 - val_conv2d_12_loss: 0.3179 - val_conv2d_19_loss: 0.2135 - val_loss: 0.5314 - learning_rate: 0.0010
Epoch 2/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.3176 - conv2d_19_loss: 0.2172 - loss: 0.5348[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2768 - conv2d_19_loss: 0.2145 - loss: 0.4913[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.2638 - conv2d_19_loss: 0.2144 - loss: 0.4782[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.1975 - conv2d_19_loss: 0.2146 - loss: 0.4176 - val_conv2d_12_loss: 0.1134 - val_conv2d_19_loss: 0.2080 - val_loss: 0.3214 - learning_rate: 0.0010
Epoch 3/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.1142 - conv2d_19_loss: 0.2101 - loss: 0.3243[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.1062 - conv2d_19_loss: 0.2120 - loss: 0.3182[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.1005 - conv2d_19_loss: 0.2122 - loss: 0.3127[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0856 - conv2d_19_loss: 0.2138 - loss: 0.2997 - val_conv2d_12_loss: 0.0670 - val_conv2d_19_loss: 0.2080 - val_loss: 0.2750 - learning_rate: 0.0010
Epoch 4/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0698 - conv2d_19_loss: 0.2248 - loss: 0.2946[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0687 - conv2d_19_loss: 0.2162 - loss: 0.2849[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0677 - conv2d_19_loss: 0.2145 - loss: 0.2822[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0644 - conv2d_19_loss: 0.2153 - loss: 0.2781 - val_conv2d_12_loss: 0.0577 - val_conv2d_19_loss: 0.2079 - val_loss: 0.2656 - learning_rate: 0.0010
Epoch 5/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0572 - conv2d_19_loss: 0.2055 - loss: 0.2627[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0578 - conv2d_19_loss: 0.2142 - loss: 0.2720[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0572 - conv2d_19_loss: 0.2138 - loss: 0.2710[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0548 - conv2d_19_loss: 0.2122 - loss: 0.2687 - val_conv2d_12_loss: 0.0497 - val_conv2d_19_loss: 0.2079 - val_loss: 0.2575 - learning_rate: 0.0010
Epoch 6/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0500 - conv2d_19_loss: 0.2046 - loss: 0.2546[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0509 - conv2d_19_loss: 0.2124 - loss: 0.2632[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0506 - conv2d_19_loss: 0.2132 - loss: 0.2638[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0494 - conv2d_19_loss: 0.2146 - loss: 0.2626 - val_conv2d_12_loss: 0.0446 - val_conv2d_19_loss: 0.2078 - val_loss: 0.2525 - learning_rate: 0.0010
Epoch 7/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0446 - conv2d_19_loss: 0.2069 - loss: 0.2515[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.2084 - loss: 0.2536[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0451 - conv2d_19_loss: 0.2096 - loss: 0.2546[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0442 - conv2d_19_loss: 0.2121 - loss: 0.2577 - val_conv2d_12_loss: 0.0400 - val_conv2d_19_loss: 0.2077 - val_loss: 0.2477 - learning_rate: 0.0010
Epoch 8/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0422 - conv2d_19_loss: 0.2099 - loss: 0.2521[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0413 - conv2d_19_loss: 0.2106 - loss: 0.2519[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0411 - conv2d_19_loss: 0.2116 - loss: 0.2528[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2127 - loss: 0.2537 - val_conv2d_12_loss: 0.0376 - val_conv2d_19_loss: 0.2077 - val_loss: 0.2453 - learning_rate: 0.0010
Epoch 9/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2082 - loss: 0.2461[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2076 - loss: 0.2458[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2088 - loss: 0.2472[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2140 - loss: 0.2524 - val_conv2d_12_loss: 0.0370 - val_conv2d_19_loss: 0.2078 - val_loss: 0.2449 - learning_rate: 0.0010
Epoch 10/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2150 - loss: 0.2540[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0393 - conv2d_19_loss: 0.2150 - loss: 0.2543[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2145 - loss: 0.2536[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2136 - loss: 0.2520 - val_conv2d_12_loss: 0.0368 - val_conv2d_19_loss: 0.2078 - val_loss: 0.2445 - learning_rate: 0.0010
Epoch 11/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0401 - conv2d_19_loss: 0.2179 - loss: 0.2580[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0399 - conv2d_19_loss: 0.2182 - loss: 0.2581[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0394 - conv2d_19_loss: 0.2163 - loss: 0.2557[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2132 - loss: 0.2520 - val_conv2d_12_loss: 0.0368 - val_conv2d_19_loss: 0.2077 - val_loss: 0.2445 - learning_rate: 0.0010
Epoch 12/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2176 - loss: 0.2561[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2155 - loss: 0.2542[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2150 - loss: 0.2538[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2134 - loss: 0.2518 - val_conv2d_12_loss: 0.0367 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2443 - learning_rate: 0.0010
Epoch 13/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.2054 - loss: 0.2418[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0371 - conv2d_19_loss: 0.2068 - loss: 0.2439[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2087 - loss: 0.2463[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2133 - loss: 0.2517 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.2079 - val_loss: 0.2445 - learning_rate: 0.0010
Epoch 14/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0387 - conv2d_19_loss: 0.2177 - loss: 0.2564[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2131 - loss: 0.2517[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2128 - loss: 0.2513
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2135 - loss: 0.2516 - val_conv2d_12_loss: 0.0367 - val_conv2d_19_loss: 0.2077 - val_loss: 0.2445 - learning_rate: 0.0010
Epoch 15/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 28ms/step - conv2d_12_loss: 0.0366 - conv2d_19_loss: 0.2074 - loss: 0.2441[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2107 - loss: 0.2487[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2112 - loss: 0.2493[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2124 - loss: 0.2517 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2442 - learning_rate: 5.0000e-04
Epoch 16/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0364 - conv2d_19_loss: 0.2011 - loss: 0.2375[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0377 - conv2d_19_loss: 0.2058 - loss: 0.2435[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2087 - loss: 0.2467[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2136 - loss: 0.2516 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2442 - learning_rate: 5.0000e-04
Epoch 17/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2125 - loss: 0.2506[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2146 - loss: 0.2531[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2141 - loss: 0.2526
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0383 - conv2d_19_loss: 0.2128 - loss: 0.2516 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2078 - val_loss: 0.2443 - learning_rate: 5.0000e-04
Epoch 18/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2125 - loss: 0.2503[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2113 - loss: 0.2491[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0381 - conv2d_19_loss: 0.2125 - loss: 0.2506[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2136 - loss: 0.2516 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 2.5000e-04
Epoch 19/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0363 - conv2d_19_loss: 0.2038 - loss: 0.2401[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0376 - conv2d_19_loss: 0.2110 - loss: 0.2485[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2127 - loss: 0.2507
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2134 - loss: 0.2516 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 2.5000e-04
Epoch 20/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0388 - conv2d_19_loss: 0.2193 - loss: 0.2581[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0391 - conv2d_19_loss: 0.2189 - loss: 0.2580[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0390 - conv2d_19_loss: 0.2177 - loss: 0.2567[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2136 - loss: 0.2515 - val_conv2d_12_loss: 0.0366 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2442 - learning_rate: 1.2500e-04
Epoch 21/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0371 - conv2d_19_loss: 0.2069 - loss: 0.2440[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2089 - loss: 0.2467[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2099 - loss: 0.2479[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2132 - loss: 0.2515 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 1.2500e-04
Epoch 22/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2126 - loss: 0.2502[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0378 - conv2d_19_loss: 0.2120 - loss: 0.2498[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0380 - conv2d_19_loss: 0.2126 - loss: 0.2506[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0384 - conv2d_19_loss: 0.2134 - loss: 0.2514 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 1.2500e-04
Epoch 23/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 25ms/step - conv2d_12_loss: 0.0369 - conv2d_19_loss: 0.2058 - loss: 0.2428[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0375 - conv2d_19_loss: 0.2094 - loss: 0.2469[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0379 - conv2d_19_loss: 0.2114 - loss: 0.2494
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001.
[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2134 - loss: 0.2515 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 1.2500e-04
Epoch 24/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step - conv2d_12_loss: 0.0360 - conv2d_19_loss: 0.2013 - loss: 0.2373[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 11ms/step - conv2d_12_loss: 0.0368 - conv2d_19_loss: 0.2054 - loss: 0.2422[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0373 - conv2d_19_loss: 0.2084 - loss: 0.2457[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0385 - conv2d_19_loss: 0.2149 - loss: 0.2515 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 1.0000e-04
Epoch 25/50
[1m 1/16[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 26ms/step - conv2d_12_loss: 0.0403 - conv2d_19_loss: 0.2235 - loss: 0.2638[1m 6/16[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0389 - conv2d_19_loss: 0.2158 - loss: 0.2546[1m11/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 10ms/step - conv2d_12_loss: 0.0386 - conv2d_19_loss: 0.2145 - loss: 0.2531[1m16/16[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 13ms/step - conv2d_12_loss: 0.0382 - conv2d_19_loss: 0.2125 - loss: 0.2514 - val_conv2d_12_loss: 0.0365 - val_conv2d_19_loss: 0.2076 - val_loss: 0.2441 - learning_rate: 1.0000e-04
2025-08-26 17:26:05,955 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
2025-08-26 17:26:06,067 - INFO - Trained model saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1/baseline_model.h5
2025-08-26 17:26:06,067 - INFO - 
[5/6] Performing inference and stitching...
[1m1/8[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 795ms/step[1m8/8[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 5ms/step  
2025-08-26 17:26:09,412 - INFO - Stitched object shape: (1, 192, 192, 1, 1)
2025-08-26 17:26:09,412 - INFO - 
[6/6] Evaluating reconstruction and saving results...
2025-08-26 17:26:09,413 - INFO - Aligning ground truth to match reconstruction bounds...
2025-08-26 17:26:09,413 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:26:09,413 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:26:09,413 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 187)
2025-08-26 17:26:09,413 - INFO - Center-cropping from (192, 192) to (103, 187)
2025-08-26 17:26:09,413 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:26:09,413 - INFO - --- Alignment complete ---
2025-08-26 17:26:09,413 - INFO - Final evaluation shapes: Reconstruction=(1, 103, 187, 1), Ground Truth=(103, 187, 1)
/home/ollie/Documents/PtychoPINN/ptycho/evaluation.py:160: RuntimeWarning: invalid value encountered in scalar power
  ms_ssim_val *= (ssim_val ** weights[level])
2025-08-26 17:26:09,433 - INFO - Evaluation Metrics (Amplitude, Phase):
2025-08-26 17:26:09,433 - INFO -   MAE:  (np.float32(0.05768307), np.float64(0.23231778903473566))
2025-08-26 17:26:09,433 - INFO -   PSNR: (66.64922947980654, 59.65645516731739)
2025-08-26 17:26:09,473 - INFO - Metrics and reconstruction images saved.
2025-08-26 17:26:09,474 - INFO - 
--- Baseline script finished successfully. ---
Amplitude normalization scale factor: 1.014738
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction []: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)
DEBUG eval_reconstruction []: amp_pred stats: mean=0.557027, std=0.108138, shape=(99, 183, 1)
DEBUG eval_reconstruction []: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)
DEBUG eval_reconstruction []: phi_pred stats: mean=-0.000000, std=0.015231, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]
performed by index method
performed by index method
performed by index method
Amplitude normalization scale factor: 1.014738
mean scale adjustment: 1
mean scale adjustment: 1
DEBUG eval_reconstruction [baseline_gs1]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: amp_pred stats: mean=0.557027, std=0.108138, shape=(99, 183, 1)
DEBUG eval_reconstruction [baseline_gs1]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)
DEBUG eval_reconstruction [baseline_gs1]: phi_pred stats: mean=-0.000000, std=0.015231, shape=(99, 183)
performed by index method
performed by index method
performed by index method
mean scale adjustment: 1
mean scale adjustment: 1
Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]
performed by index method
performed by index method
performed by index method
[2025-08-26 17:26:10] SUCCESS: Baseline training (n_images=256, trial=1)
[2025-08-26 17:26:10] EXECUTING: Pty-chi reconstruction (algorithm=ePIE, n_images=256, trial=1)
[2025-08-26 17:26:10] COMMAND: python scripts/reconstruction/run_ptychi_reconstruction.py \
                'prepare_1e4_photons_5k/dataset/train.npz' \
                '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/ptychi_run' \
                --algorithm ePIE \
                --n-images 256 \
                --iterations 200 \
                --batch-size 8 \
                --quiet
[2025-08-26 17:26:39] SUCCESS: Pty-chi reconstruction (algorithm=ePIE, n_images=256, trial=1)
[2025-08-26 17:26:39] Completed training for train_size=256 (Trial 1/1)
[2025-08-26 17:26:39] Completed all trials for train_size=256
[2025-08-26 17:26:39] Model training phase completed
[2025-08-26 17:26:39] === STEP 3: Model Comparison ===
[2025-08-26 17:26:39] Running comparisons for train_size=256, test_size=256 (1 trials)
[2025-08-26 17:26:39] Using test subset size 256 (3-way comparison mode with Pty-chi)
[2025-08-26 17:26:39] EXECUTING: Model comparison (train_size=256, trial=1)
[2025-08-26 17:26:39] COMMAND: python scripts/compare_models.py --pinn_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run' --baseline_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1' --test_data 'prepare_1e4_photons_5k/dataset/train.npz' --output_dir '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1' --skip-registration --tike_recon_path '3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/ptychi_run/ptychi_reconstruction.npz' --n-test-images 256
2025-08-26 17:26:39.817136: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1756254399.829059 3379259 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1756254399.832937 3379259 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1756254399.844184 3379259 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254399.844194 3379259 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254399.844196 3379259 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1756254399.844197 3379259 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-08-26 17:26:39.847100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-08-26 17:26:42,109 - INFO - Configuration: phase_align_method='plane', frc_sigma=0.0
2025-08-26 17:26:42,109 - INFO - Registration: disabled
2025-08-26 17:26:42,109 - INFO - NPZ output: raw=enabled, aligned=enabled
2025-08-26 17:26:42,109 - INFO - Initializing configuration before data loading...
2025-08-26 17:26:42,109 - INFO - Initialized with gridsize=1, n_images=256
2025-08-26 17:26:42,109 - INFO - Loading test data from prepare_1e4_photons_5k/dataset/train.npz...
2025-08-26 17:26:42,109 - INFO - Loading data from prepare_1e4_photons_5k/dataset/train.npz with n_images=256
2025-08-26 17:26:42,431 - INFO - Passing full dataset to RawData for unified sampling (gridsize=1)
diff3d shape: (2576, 64, 64)2025-08-26 17:26:42,431 - INFO - diff3d shape: (2576, 64, 64)

probeGuess shape: (64, 64)2025-08-26 17:26:42,431 - INFO - probeGuess shape: (64, 64)

scan_index shape: (2576,)2025-08-26 17:26:42,431 - INFO - scan_index shape: (2576,)

objectGuess shape: (232, 232)2025-08-26 17:26:42,431 - INFO - objectGuess shape: (232, 232)

xcoords shape: (2576,)2025-08-26 17:26:42,431 - INFO - xcoords shape: (2576,)

ycoords shape: (2576,)2025-08-26 17:26:42,431 - INFO - ycoords shape: (2576,)

xcoords_start shape: (2576,)2025-08-26 17:26:42,431 - INFO - xcoords_start shape: (2576,)

ycoords_start shape: (2576,)2025-08-26 17:26:42,431 - INFO - ycoords_start shape: (2576,)

2025-08-26 17:26:42,431 - INFO - Using stitch_crop_size M=20 (N=64)
DEBUG:2025-08-26 17:26:42,431 - INFO - DEBUG:
 nsamples: 2576, gridsize: 1 (using efficient random sample-then-group strategy)2025-08-26 17:26:42,431 - INFO - nsamples: 2576, gridsize: 1 (using efficient random sample-then-group strategy)

2025-08-26 17:26:42,431 - INFO - Using efficient random sampling strategy for gridsize=1
2025-08-26 17:26:42,431 - INFO - Generating 2576 groups efficiently from 2576 points (K=4, C=1)
2025-08-26 17:26:42,431 - INFO - Using all 2576 points as seeds
2025-08-26 17:26:42,431 - INFO - Using seed indices directly for C=1 (gridsize=1) - no neighbor search needed
2025-08-26 17:26:42,431 - INFO - Successfully generated 2576 groups with shape (2576, 1)
2025-08-26 17:26:42,431 - INFO - Generated 2576 groups efficiently
INFO: Using pre-computed 'Y' array from the input file.2025-08-26 17:26:42,438 - INFO - INFO: Using pre-computed 'Y' array from the input file.

I0000 00:00:1756254402.576120 3379259 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0
I0000 00:00:1756254402.577340 3379259 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22211 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:04:00.0, compute capability: 8.6
neighbor-sampled diffraction shape2025-08-26 17:26:42,661 - INFO - neighbor-sampled diffraction shape
 (2576, 64, 64, 1)2025-08-26 17:26:42,661 - INFO - (2576, 64, 64, 1)

loader: using provided ground truth patches.2025-08-26 17:26:42,833 - INFO - loader: using provided ground truth patches.

INFO:2025-08-26 17:26:43,226 - INFO - INFO:
 None2025-08-26 17:26:43,226 - INFO - None

<PtychoDataContainer X=(2576, 64, 64, 1) Y_I=(2576, 64, 64, 1) Y_phi=(2576, 64, 64, 1) norm_Y_I=() coords_nominal=(2576, 1, 2, 1) coords_true=(2576, 1, 2, 1) nn_indices=(2576, 1) mean=1287.500 global_offsets=(2576, 1, 2, 1) mean=94.803 local_offsets=(2576, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>2025-08-26 17:26:43,226 - INFO - <PtychoDataContainer X=(2576, 64, 64, 1) Y_I=(2576, 64, 64, 1) Y_phi=(2576, 64, 64, 1) norm_Y_I=() coords_nominal=(2576, 1, 2, 1) coords_true=(2576, 1, 2, 1) nn_indices=(2576, 1) mean=1287.500 global_offsets=(2576, 1, 2, 1) mean=94.803 local_offsets=(2576, 1, 2, 1) mean=0.000 probe=(64, 64) mean_amplitude=0.006>

2025-08-26 17:26:43,227 - INFO - Loading PtychoPINN model from 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run...
2025-08-26 17:26:43,227 - INFO - Loading model from: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run
Model: "functional"
2025-08-26 17:26:43,997 - INFO - Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-08-26 17:26:44,018 - INFO - â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input (InputLayer)  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ -                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler    â”‚ (None, 64, 64, 1) â”‚          0 â”‚ input[0][0]       â”‚
â”‚ (IntensityScaler)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 64, 64,    â”‚        640 â”‚ intensity_scalerâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 64, 64,    â”‚     36,928 â”‚ conv2d[0][0]      â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d       â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_1[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚     73,856 â”‚ max_pooling2d[0]â€¦ â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚    147,584 â”‚ conv2d_2[0][0]    â”‚
â”‚                     â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_3[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 16, 16,    â”‚    295,168 â”‚ max_pooling2d_1[â€¦ â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 16, 16,    â”‚    590,080 â”‚ conv2d_4[0][0]    â”‚
â”‚                     â”‚ 256)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2     â”‚ (None, 8, 8, 256) â”‚          0 â”‚ conv2d_5[0][0]    â”‚
â”‚ (MaxPooling2D)      â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    295,040 â”‚ max_pooling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_8[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d       â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_9[0][0]    â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_3     â”‚ (None, 16, 16,    â”‚          0 â”‚ conv2d_17[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 128)              â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 16, 16,    â”‚     73,792 â”‚ up_sampling2d_3[â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_10[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ conv2d_18[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_1     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_11[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_4     â”‚ (None, 32, 32,    â”‚          0 â”‚ conv2d_19[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_1          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_3          â”‚ (None, 32, 32, 4) â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_1[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,368 â”‚ get_item_3[0][0]  â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_12[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚     36,928 â”‚ conv2d_20[0][0]   â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_2     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_13[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ up_sampling2d_5     â”‚ (None, 64, 64,    â”‚          0 â”‚ conv2d_21[0][0]   â”‚
â”‚ (UpSampling2D)      â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item (GetItem)  â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_1[â€¦ â”‚
â”‚                     â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_2[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ get_item_2          â”‚ (None, 32, 32,    â”‚          0 â”‚ up_sampling2d_4[â€¦ â”‚
â”‚ (GetItem)           â”‚ 60)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 64, 64, 1) â”‚        577 â”‚ up_sampling2d_5[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu (Silu)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_7[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 32, 32, 1) â”‚        541 â”‚ get_item_2[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ silu_1 (Silu)       â”‚ (None, 64, 64, 1) â”‚          0 â”‚ conv2d_15[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_6[0][0]    â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer   â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0]        â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phi                 â”‚ (None, 32, 32, 1) â”‚          0 â”‚ conv2d_14[0][0]   â”‚
â”‚ (ActivationLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ center_mask_layer_1 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0]      â”‚
â”‚ (CenterMaskLayer)   â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ amp_padded          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply (Multiply) â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu[0][0],       â”‚
â”‚                     â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ phase_padded        â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phi[0][0]         â”‚
â”‚ (ZeroPadding2D)     â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ multiply_1          â”‚ (None, 64, 64, 1) â”‚          0 â”‚ silu_1[0][0],     â”‚
â”‚ (Multiply)          â”‚                   â”‚            â”‚ center_mask_layeâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 64, 64, 1) â”‚          0 â”‚ amp_padded[0][0], â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ phase_padded[0][â€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ multiply_1[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ obj                 â”‚ (None, 64, 64, 1) â”‚          0 â”‚ add[0][0],        â”‚
â”‚ (CombineComplexLayâ€¦ â”‚                   â”‚            â”‚ add_1[0][0]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ input_positions     â”‚ (None, 1, 2, 1)   â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_obj_2        â”‚ (None, 74, 74, 1) â”‚          0 â”‚ obj[0][0],        â”‚
â”‚ (ReassemblePatchesâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ padded_objs_with_oâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (ExtractPatchesPosâ€¦ â”‚                   â”‚            â”‚ input_positions[â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ probe_illumination  â”‚ [(None, 64, 64,   â”‚          0 â”‚ padded_objs_withâ€¦ â”‚
â”‚ (ProbeIllumination) â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_amplitude      â”‚ [(None, 64, 64,   â”‚          0 â”‚ probe_illuminatiâ€¦ â”‚
â”‚ (PadAndDiffractLayâ€¦ â”‚ 1), (None, 64,    â”‚            â”‚                   â”‚
â”‚                     â”‚ 64, 1)]           â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_diff_channels  â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_amplitude[0â€¦ â”‚
â”‚ (FlatToChannelLayeâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ intensity_scaler_iâ€¦ â”‚ (None, 64, 64, 1) â”‚          0 â”‚ pred_diff_channeâ€¦ â”‚
â”‚ (IntensityScaler_iâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ trimmed_obj         â”‚ (None, 64, 64, 1) â”‚          0 â”‚ padded_obj_2[0][â€¦ â”‚
â”‚ (TrimReconstructioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pred_intensity      â”‚ (None, 64, 64, 1) â”‚          0 â”‚ intensity_scalerâ€¦ â”‚
â”‚ (SquareLayer)       â”‚                   â”‚            â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,331,772 (8.90 MB)
2025-08-26 17:26:44,018 - INFO - Total params: 2,331,772 (8.90 MB)
 Trainable params: 2,331,772 (8.90 MB)
2025-08-26 17:26:44,018 - INFO - Trainable params: 2,331,772 (8.90 MB)
 Non-trainable params: 0 (0.00 B)
2025-08-26 17:26:44,019 - INFO - Non-trainable params: 0 (0.00 B)
None2025-08-26 17:26:44,019 - INFO - None

2025-08-26 17:26:44.019249: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:103] Profiler session initializing.
2025-08-26 17:26:44.019258: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:118] Profiler session started.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1756254404.019271 3379259 cupti_tracer.cc:1026] Profiler found 1 GPUs
W0000 00:00:1756254404.036546 3379259 cupti_tracer.cc:1213] Fail to use per-thread activity buffer, cupti trace overhead may be big. CUPTI ERROR CODE:1
2025-08-26 17:26:44.036620: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:130] Profiler session tear down.
I0000 00:00:1756254404.036690 3379259 cupti_tracer.cc:1249] CUPTI activity buffer flushed
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:26:44,181 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
/home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:26:44,182 - ERROR - /home/ollie/miniconda3/envs/ptycho311/lib/python3.11/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'center_mask_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.
  warnings.warn(
2025-08-26 17:26:44,666 - INFO - Successfully loaded model from 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_run
2025-08-26 17:26:44,666 - INFO - Loading Baseline model from 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1...
2025-08-26 17:26:44,666 - INFO - Found baseline model at: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_run/08-26-2025-17.25.49_baseline_gs1/baseline_model.h5
2025-08-26 17:26:44,757 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2025-08-26 17:26:44,762 - INFO - Loading iterative reconstruction from 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/ptychi_run/ptychi_reconstruction.npz...
2025-08-26 17:26:44,764 - INFO - Loaded Pty-chi (ePIE) reconstruction: (198, 282) (complex64)
2025-08-26 17:26:44,764 - INFO - Pty-chi (ePIE) reconstruction loaded for three-way comparison
2025-08-26 17:26:44,764 - INFO - Pty-chi (ePIE) computation time: 24.73s
2025-08-26 17:26:44,764 - INFO - Running inference with PtychoPINN...
I0000 00:00:1756254405.848939 3379403 service.cc:152] XLA service 0x7eeab800e4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1756254405.848960 3379403 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6
2025-08-26 17:26:45.930009: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1756254406.081979 3379403 cuda_dnn.cc:529] Loaded cuDNN version 91002
I0000 00:00:1756254407.405727 3379403 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3:28[0m 3s/step2025-08-26 17:26:47,414 - INFO - [1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m3:28[0m 3s/step
[1m12/81[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step 2025-08-26 17:26:47,466 - INFO - [1m12/81[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m23/81[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,517 - INFO - [1m23/81[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m34/81[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,567 - INFO - [1m34/81[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m45/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,618 - INFO - [1m45/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m56/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,668 - INFO - [1m56/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 5ms/step
[1m67/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,718 - INFO - [1m67/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 5ms/step
[1m78/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 5ms/step2025-08-26 17:26:47,768 - INFO - [1m78/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 5ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 25ms/step2025-08-26 17:26:49,412 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 25ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m5s[0m 25ms/step
2025-08-26 17:26:49,425 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m5s[0m 25ms/step
2025-08-26 17:26:49,516 - INFO - PtychoPINN inference completed in 4.75s
2025-08-26 17:26:49,517 - INFO - Reassembling PtychoPINN patches...
2025-08-26 17:26:51,462 - INFO - Running inference with Baseline model...
[1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m45s[0m 567ms/step2025-08-26 17:26:52,065 - INFO - [1m 1/81[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m45s[0m 567ms/step
[1m14/81[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step   2025-08-26 17:26:52,116 - INFO - [1m14/81[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m27/81[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:26:52,169 - INFO - [1m27/81[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m40/81[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:26:52,222 - INFO - [1m40/81[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m53/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:26:52,274 - INFO - [1m53/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 4ms/step
[1m66/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step2025-08-26 17:26:52,327 - INFO - [1m66/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 4ms/step
[1m79/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step2025-08-26 17:26:52,380 - INFO - [1m79/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 4ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step2025-08-26 17:26:52,910 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 11ms/step
[1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step
2025-08-26 17:26:52,923 - INFO - [1m81/81[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 11ms/step
2025-08-26 17:26:53,019 - INFO - Baseline inference completed in 1.56s
2025-08-26 17:26:53,134 - INFO - Reassembling baseline patches...
2025-08-26 17:26:53,165 - INFO - Saving NPZ files of raw reconstructions...
2025-08-26 17:26:53,242 - INFO - Unified reconstructions saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/reconstructions.npz
2025-08-26 17:26:53,243 - INFO - Metadata saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/reconstructions_metadata.txt
2025-08-26 17:26:53,243 - INFO - Unified NPZ reconstruction file saved successfully!
2025-08-26 17:26:53,243 - INFO - Performing coordinate-based alignment of ground truth...
2025-08-26 17:26:53,243 - INFO - Ground truth original shape: (232, 232)
2025-08-26 17:26:53,243 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:26:53,243 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:26:53,243 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 187)
2025-08-26 17:26:53,243 - INFO - Center-cropping from (192, 192) to (103, 187)
2025-08-26 17:26:53,243 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:26:53,243 - INFO - --- Alignment complete ---
2025-08-26 17:26:53,243 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:26:53,243 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:26:53,243 - INFO - Initial shapes: Recon=(192, 192), Cropped GT=(103, 187)
2025-08-26 17:26:53,243 - INFO - Center-cropping from (192, 192) to (103, 187)
2025-08-26 17:26:53,243 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:26:53,243 - INFO - --- Alignment complete ---
2025-08-26 17:26:53,243 - INFO - --- Aligning reconstruction with ground truth for evaluation ---
2025-08-26 17:26:53,243 - INFO - Calculated ground truth crop region: rows [22:125], cols [22:209]
2025-08-26 17:26:53,243 - INFO - Initial shapes: Recon=(198, 282), Cropped GT=(103, 187)
2025-08-26 17:26:53,243 - INFO - Center-cropping from (198, 282) to (103, 187)
2025-08-26 17:26:53,243 - INFO - Final aligned shape: (103, 187)
2025-08-26 17:26:53,243 - INFO - --- Alignment complete ---
2025-08-26 17:26:53,243 - INFO - Skipping registration (--skip-registration specified)
2025-08-26 17:26:53,243 - INFO - Final evaluation shapes: PINN (103, 187), Baseline (103, 187), Pty-chi (ePIE) (103, 187), GT (103, 187)
Amplitude normalization scale factor: 0.7180402025-08-26 17:26:53,246 - INFO - Amplitude normalization scale factor: 0.718040

mean scale adjustment:2025-08-26 17:26:53,246 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,246 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,246 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,246 - INFO - 1

DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:26:53,247 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.787193, std=0.051569, shape=(99, 183, 1)2025-08-26 17:26:53,247 - INFO - DEBUG eval_reconstruction [PtychoPINN]: amp_pred stats: mean=0.787193, std=0.051569, shape=(99, 183, 1)

DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:26:53,247 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.226276, shape=(99, 183)2025-08-26 17:26:53,247 - INFO - DEBUG eval_reconstruction [PtychoPINN]: phi_pred stats: mean=-0.000000, std=0.226276, shape=(99, 183)

performed by index method2025-08-26 17:26:53,248 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,250 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,252 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:26:53,254 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,254 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,254 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,254 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:26:53,254 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

performed by index method2025-08-26 17:26:53,258 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,260 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,262 - INFO - performed by index method

2025-08-26 17:26:53,264 - INFO - PtychoPINN evaluation complete. SSIM: amp=0.653, phase=0.911, MS-SSIM: amp=0.823, phase=0.856
Amplitude normalization scale factor: 0.9779932025-08-26 17:26:53,266 - INFO - Amplitude normalization scale factor: 0.977993

mean scale adjustment:2025-08-26 17:26:53,266 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,266 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,266 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,266 - INFO - 1

DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:26:53,266 - INFO - DEBUG eval_reconstruction [Baseline]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.577955, std=0.006073, shape=(99, 183, 1)2025-08-26 17:26:53,267 - INFO - DEBUG eval_reconstruction [Baseline]: amp_pred stats: mean=0.577955, std=0.006073, shape=(99, 183, 1)

DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:26:53,267 - INFO - DEBUG eval_reconstruction [Baseline]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.002145, shape=(99, 183)2025-08-26 17:26:53,267 - INFO - DEBUG eval_reconstruction [Baseline]: phi_pred stats: mean=-0.000000, std=0.002145, shape=(99, 183)

performed by index method2025-08-26 17:26:53,267 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,269 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,271 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:26:53,273 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,273 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,273 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,273 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:26:53,273 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

performed by index method2025-08-26 17:26:53,276 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,278 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,280 - INFO - performed by index method

2025-08-26 17:26:53,282 - INFO - Baseline evaluation complete. SSIM: amp=0.095, phase=0.563, MS-SSIM: amp=0.094, phase=0.027
Amplitude normalization scale factor: 0.5491962025-08-26 17:26:53,284 - INFO - Amplitude normalization scale factor: 0.549196

mean scale adjustment:2025-08-26 17:26:53,284 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,284 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,284 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,284 - INFO - 1

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)2025-08-26 17:26:53,285 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_target stats: mean=0.565236, std=0.044040, shape=(99, 183, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.029206, std=0.174654, shape=(99, 183, 1)2025-08-26 17:26:53,285 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: amp_pred stats: mean=1.029206, std=0.174654, shape=(99, 183, 1)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)2025-08-26 17:26:53,285 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_target stats: mean=0.000000, std=0.264979, shape=(99, 183)

DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.254569, shape=(99, 183)2025-08-26 17:26:53,285 - INFO - DEBUG eval_reconstruction [Pty-chi (ePIE)]: phi_pred stats: mean=0.000000, std=0.254569, shape=(99, 183)

performed by index method2025-08-26 17:26:53,285 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,287 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,289 - INFO - performed by index method

mean scale adjustment:2025-08-26 17:26:53,291 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,291 - INFO - 1

mean scale adjustment:2025-08-26 17:26:53,291 - INFO - mean scale adjustment:
 12025-08-26 17:26:53,291 - INFO - 1

Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]2025-08-26 17:26:53,291 - INFO - Phase preprocessing: plane-fitted range [-0.635, 0.361] -> scaled range [0.399, 0.557]

performed by index method2025-08-26 17:26:53,294 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,296 - INFO - performed by index method

performed by index method2025-08-26 17:26:53,298 - INFO - performed by index method

2025-08-26 17:26:53,300 - INFO - Pty-chi (ePIE) evaluation complete. SSIM: amp=0.205, phase=0.584, MS-SSIM: amp=0.451, phase=0.368
2025-08-26 17:26:53,302 - INFO - Metrics saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/comparison_metrics.csv

--- Comparison Metrics ---2025-08-26 17:26:53,302 - INFO - --- Comparison Metrics ---

         model             metric  amplitude     phase     value
    PtychoPINN                mae   0.019149  0.086719       NaN
    PtychoPINN                mse   0.000682  0.013412       NaN
    PtychoPINN               psnr  79.791748 66.855822       NaN
    PtychoPINN               ssim   0.652559  0.911417       NaN
    PtychoPINN            ms_ssim   0.822989  0.855595       NaN
    PtychoPINN              frc50  13.000000 21.000000       NaN
      Baseline                mae   0.038469  0.232186       NaN
      Baseline                mse   0.001977  0.070168       NaN
      Baseline               psnr  75.170897 59.669410       NaN
      Baseline               ssim   0.094535  0.563309       NaN
      Baseline            ms_ssim   0.094147  0.027359       NaN
      Baseline              frc50   1.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.064653  0.202358       NaN
Pty-chi (ePIE)                mse   0.007727  0.072197       NaN
Pty-chi (ePIE)               psnr  69.250920 59.545615       NaN
Pty-chi (ePIE)               ssim   0.205105  0.584327       NaN
Pty-chi (ePIE)            ms_ssim   0.451096  0.368220       NaN
Pty-chi (ePIE)              frc50   6.000000  4.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  4.752606
      Baseline computation_time_s        NaN       NaN  1.557223
Pty-chi (ePIE) computation_time_s        NaN       NaN 24.7301542025-08-26 17:26:53,303 - INFO - model             metric  amplitude     phase     value
    PtychoPINN                mae   0.019149  0.086719       NaN
    PtychoPINN                mse   0.000682  0.013412       NaN
    PtychoPINN               psnr  79.791748 66.855822       NaN
    PtychoPINN               ssim   0.652559  0.911417       NaN
    PtychoPINN            ms_ssim   0.822989  0.855595       NaN
    PtychoPINN              frc50  13.000000 21.000000       NaN
      Baseline                mae   0.038469  0.232186       NaN
      Baseline                mse   0.001977  0.070168       NaN
      Baseline               psnr  75.170897 59.669410       NaN
      Baseline               ssim   0.094535  0.563309       NaN
      Baseline            ms_ssim   0.094147  0.027359       NaN
      Baseline              frc50   1.000000  1.000000       NaN
Pty-chi (ePIE)                mae   0.064653  0.202358       NaN
Pty-chi (ePIE)                mse   0.007727  0.072197       NaN
Pty-chi (ePIE)               psnr  69.250920 59.545615       NaN
Pty-chi (ePIE)               ssim   0.205105  0.584327       NaN
Pty-chi (ePIE)            ms_ssim   0.451096  0.368220       NaN
Pty-chi (ePIE)              frc50   6.000000  4.000000       NaN
    PtychoPINN computation_time_s        NaN       NaN  4.752606
      Baseline computation_time_s        NaN       NaN  1.557223
Pty-chi (ePIE) computation_time_s        NaN       NaN 24.730154

2025-08-26 17:26:53,304 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/pinn_frc_curves.csv
2025-08-26 17:26:53,304 - INFO - FRC curves saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/baseline_frc_curves.csv
2025-08-26 17:26:53,304 - INFO - Saving NPZ files of aligned reconstructions...
2025-08-26 17:26:53,335 - INFO - Unified aligned reconstructions saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/reconstructions_aligned.npz
2025-08-26 17:26:53,335 - INFO - Aligned metadata saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/reconstructions_aligned_metadata.txt
2025-08-26 17:26:53,335 - INFO - Unified aligned NPZ reconstruction file saved successfully!
2025-08-26 17:26:53,540 - INFO - PtychoPINN amplitude color scale (vmin, vmax) set to: (0.719, 0.862) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,541 - INFO - Baseline amplitude color scale (vmin, vmax) set to: (0.578, 0.578) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,541 - INFO - PtychoPINN phase color scale (vmin, vmax) set to: (-0.348, 0.250) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,541 - INFO - Baseline phase color scale (vmin, vmax) set to: (0.079, 0.087) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,542 - INFO - Pty-chi (ePIE) amplitude color scale (vmin, vmax) set to: (0.813, 1.236) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,542 - INFO - Pty-chi (ePIE) phase color scale (vmin, vmax) set to: (-0.445, 0.225) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,550 - INFO - Ground Truth amplitude color scale (vmin, vmax) set to: (0.502, 0.617) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:53,551 - INFO - Ground Truth phase color scale (vmin, vmax) set to: (-0.482, 0.215) using 10.0/90.0 percentiles [per-panel].
2025-08-26 17:26:54,283 - INFO - Visual comparison saved to 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1/comparison_plot.png
2025-08-26 17:26:54,283 - INFO - 
Comparison complete!
2025-08-26 17:26:54,283 - INFO - Results saved to: 3way_synthetic_ptychi_1e4_cheat_256/train_256/trial_1
[2025-08-26 17:26:55] SUCCESS: Model comparison (train_size=256, trial=1)
[2025-08-26 17:26:55] Completed comparisons for train_size=256
[2025-08-26 17:26:55] Model comparison phase completed
[2025-08-26 17:26:55] === STEP 4: Results Aggregation ===
[2025-08-26 17:26:55] EXECUTING: PSNR phase generalization plot
[2025-08-26 17:26:55] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric psnr \
        --part phase \
        --output psnr_phase_generalization.png
17:26:55 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:55 - INFO - Analyzing psnr_phase
17:26:55 - INFO - Discovered 1 comparison files
17:26:55 - INFO - Single-trial data detected - using legacy aggregation
17:26:55 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:55 - INFO - Loaded 3 trial records
17:26:55 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:55 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:55 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:55 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:55 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:55 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:55 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:55 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:55 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:55 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:55 - INFO - NaN exclusion summary:
17:26:55 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:55 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:55 - INFO - Extracted 2 data points for psnr_phase (using mean)
17:26:55 - WARNING - Missing expected model types: {'baseline'}
17:26:55 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/psnr_phase_generalization.png
17:26:55 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:55 - INFO - Processing complete!
17:26:55 - INFO - Outputs:
17:26:55 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/psnr_phase_generalization.png
17:26:55 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:55 - INFO - Summary: 2 models, 1 training sizes
17:26:55 - INFO - Training sizes: [np.int64(256)]
17:26:55 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:55] SUCCESS: PSNR phase generalization plot
[2025-08-26 17:26:55] EXECUTING: FRC amplitude generalization plot
[2025-08-26 17:26:55] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric frc50 \
        --part amp \
        --output frc50_amp_generalization.png
17:26:56 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:56 - INFO - Analyzing frc50_amp
17:26:56 - INFO - Discovered 1 comparison files
17:26:56 - INFO - Single-trial data detected - using legacy aggregation
17:26:56 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:56 - INFO - Loaded 3 trial records
17:26:56 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:56 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:56 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:56 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:56 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:56 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:56 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:56 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:56 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:56 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:56 - INFO - NaN exclusion summary:
17:26:56 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:56 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:56 - INFO - Extracted 2 data points for frc50_amp (using mean)
17:26:56 - WARNING - Missing expected model types: {'baseline'}
17:26:56 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/frc50_amp_generalization.png
17:26:56 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:56 - INFO - Processing complete!
17:26:56 - INFO - Outputs:
17:26:56 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/frc50_amp_generalization.png
17:26:56 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:56 - INFO - Summary: 2 models, 1 training sizes
17:26:56 - INFO - Training sizes: [np.int64(256)]
17:26:56 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:56] SUCCESS: FRC amplitude generalization plot
[2025-08-26 17:26:56] EXECUTING: MAE amplitude generalization plot
[2025-08-26 17:26:56] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric mae \
        --part amp \
        --output mae_amp_generalization.png
17:26:57 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:57 - INFO - Analyzing mae_amp
17:26:57 - INFO - Discovered 1 comparison files
17:26:57 - INFO - Single-trial data detected - using legacy aggregation
17:26:57 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:57 - INFO - Loaded 3 trial records
17:26:57 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:57 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:57 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:57 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:57 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:57 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:57 - INFO - NaN exclusion summary:
17:26:57 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:57 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:57 - INFO - Extracted 2 data points for mae_amp (using mean)
17:26:57 - WARNING - Missing expected model types: {'baseline'}
17:26:57 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/mae_amp_generalization.png
17:26:57 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:57 - INFO - Processing complete!
17:26:57 - INFO - Outputs:
17:26:57 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/mae_amp_generalization.png
17:26:57 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:57 - INFO - Summary: 2 models, 1 training sizes
17:26:57 - INFO - Training sizes: [np.int64(256)]
17:26:57 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:57] SUCCESS: MAE amplitude generalization plot
[2025-08-26 17:26:57] EXECUTING: SSIM amplitude generalization plot
[2025-08-26 17:26:57] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric ssim \
        --part amp \
        --output ssim_amp_generalization.png
17:26:57 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:57 - INFO - Analyzing ssim_amp
17:26:57 - INFO - Discovered 1 comparison files
17:26:57 - INFO - Single-trial data detected - using legacy aggregation
17:26:57 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:57 - INFO - Loaded 3 trial records
17:26:57 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:57 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:57 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:57 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:57 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:57 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:57 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:57 - INFO - NaN exclusion summary:
17:26:57 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:57 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:57 - INFO - Extracted 2 data points for ssim_amp (using mean)
17:26:57 - WARNING - Missing expected model types: {'baseline'}
17:26:57 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/ssim_amp_generalization.png
17:26:57 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:57 - INFO - Processing complete!
17:26:57 - INFO - Outputs:
17:26:57 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/ssim_amp_generalization.png
17:26:57 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:57 - INFO - Summary: 2 models, 1 training sizes
17:26:57 - INFO - Training sizes: [np.int64(256)]
17:26:57 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:57] SUCCESS: SSIM amplitude generalization plot
[2025-08-26 17:26:57] EXECUTING: SSIM phase generalization plot
[2025-08-26 17:26:57] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric ssim \
        --part phase \
        --output ssim_phase_generalization.png
17:26:58 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:58 - INFO - Analyzing ssim_phase
17:26:58 - INFO - Discovered 1 comparison files
17:26:58 - INFO - Single-trial data detected - using legacy aggregation
17:26:58 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:58 - INFO - Loaded 3 trial records
17:26:58 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:58 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:58 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:58 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:58 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:58 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:58 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:58 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:58 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:58 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:58 - INFO - NaN exclusion summary:
17:26:58 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:58 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:58 - INFO - Extracted 2 data points for ssim_phase (using mean)
17:26:58 - WARNING - Missing expected model types: {'baseline'}
17:26:58 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/ssim_phase_generalization.png
17:26:58 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:58 - INFO - Processing complete!
17:26:58 - INFO - Outputs:
17:26:58 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/ssim_phase_generalization.png
17:26:58 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:58 - INFO - Summary: 2 models, 1 training sizes
17:26:58 - INFO - Training sizes: [np.int64(256)]
17:26:58 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:58] SUCCESS: SSIM phase generalization plot
[2025-08-26 17:26:58] EXECUTING: MS-SSIM amplitude generalization plot
[2025-08-26 17:26:58] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric ms_ssim \
        --part amp \
        --output ms_ssim_amp_generalization.png
17:26:59 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:59 - INFO - Analyzing ms_ssim_amp
17:26:59 - INFO - Discovered 1 comparison files
17:26:59 - INFO - Single-trial data detected - using legacy aggregation
17:26:59 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:59 - INFO - Loaded 3 trial records
17:26:59 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:59 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:59 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:59 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:59 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:59 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:59 - INFO - NaN exclusion summary:
17:26:59 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:59 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:59 - INFO - Extracted 2 data points for ms_ssim_amp (using mean)
17:26:59 - WARNING - Missing expected model types: {'baseline'}
17:26:59 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/ms_ssim_amp_generalization.png
17:26:59 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:59 - INFO - Processing complete!
17:26:59 - INFO - Outputs:
17:26:59 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/ms_ssim_amp_generalization.png
17:26:59 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:59 - INFO - Summary: 2 models, 1 training sizes
17:26:59 - INFO - Training sizes: [np.int64(256)]
17:26:59 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:59] SUCCESS: MS-SSIM amplitude generalization plot
[2025-08-26 17:26:59] EXECUTING: MS-SSIM phase generalization plot
[2025-08-26 17:26:59] COMMAND: python scripts/studies/aggregate_and_plot_results.py \
        '3way_synthetic_ptychi_1e4_cheat_256' \
        --metric ms_ssim \
        --part phase \
        --output ms_ssim_phase_generalization.png
17:26:59 - INFO - Processing study directory: 3way_synthetic_ptychi_1e4_cheat_256
17:26:59 - INFO - Analyzing ms_ssim_phase
17:26:59 - INFO - Discovered 1 comparison files
17:26:59 - INFO - Single-trial data detected - using legacy aggregation
17:26:59 - INFO - Total NaN values in data: 6 (0 new, 6 preserved)
17:26:59 - INFO - Loaded 3 trial records
17:26:59 - INFO - Filtered out 1 trial records with MS-SSIM (phase) < 0.3
17:26:59 - INFO - Proceeding to aggregation with 2 trial records (after any filtering applied)
17:26:59 - WARNING - Only 1 trials for train_size=256, model=iterative. Percentile calculations may be unreliable.
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=iterative)
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=iterative)
17:26:59 - WARNING - Only 1 trials for train_size=256, model=pinn. Percentile calculations may be unreliable.
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_amp (train_size=256, model=pinn)
17:26:59 - WARNING - All 1 trials have NaN for computation_time_s_phase (train_size=256, model=pinn)
17:26:59 - INFO - Computed statistics for 2 (train_size, model_type) combinations
17:26:59 - INFO - Train size 256: 1.0-1.0 trials (avg: 1.0)
17:26:59 - INFO - NaN exclusion summary:
17:26:59 - INFO -   computation_time_s_amp: 2 NaN values excluded (100.0% of 2 total trials)
17:26:59 - INFO -   computation_time_s_phase: 2 NaN values excluded (100.0% of 2 total trials)
17:26:59 - INFO - Extracted 2 data points for ms_ssim_phase (using mean)
17:26:59 - WARNING - Missing expected model types: {'baseline'}
17:26:59 - INFO - Plot saved to: 3way_synthetic_ptychi_1e4_cheat_256/ms_ssim_phase_generalization.png
17:26:59 - INFO - Results exported to: 3way_synthetic_ptychi_1e4_cheat_256/results.csv (26 metric entries)
17:26:59 - INFO - Processing complete!
17:26:59 - INFO - Outputs:
17:26:59 - INFO -   - Plot: 3way_synthetic_ptychi_1e4_cheat_256/ms_ssim_phase_generalization.png
17:26:59 - INFO -   - Data: 3way_synthetic_ptychi_1e4_cheat_256/results.csv
17:26:59 - INFO - Summary: 2 models, 1 training sizes
17:26:59 - INFO - Training sizes: [np.int64(256)]
17:26:59 - INFO - Model types: ['iterative', 'pinn']
[2025-08-26 17:26:59] SUCCESS: MS-SSIM phase generalization plot
[2025-08-26 17:26:59] Results aggregation completed
[2025-08-26 17:26:59] === Generating Summary Report ===
[2025-08-26 17:26:59] Summary report generated: 3way_synthetic_ptychi_1e4_cheat_256/STUDY_SUMMARY.md
[2025-08-26 17:26:59] === Study Completed Successfully ===
[2025-08-26 17:26:59] Training sizes tested: 1
[2025-08-26 17:26:59] Trials per size: 1
[2025-08-26 17:26:59] Total trials completed: 1
[2025-08-26 17:26:59] Total runtime: 00:01:49
[2025-08-26 17:26:59] Results directory: 3way_synthetic_ptychi_1e4_cheat_256
[2025-08-26 17:26:59] Summary report: 3way_synthetic_ptychi_1e4_cheat_256/STUDY_SUMMARY.md
